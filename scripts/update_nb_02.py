
import json

def update_notebook(filepath):
    with open(filepath, 'r') as f:
        nb = json.load(f)

    # 1. Update Header (Cell 0 - Insert at top)
    header_cell = {
        "cell_type": "markdown",
        "metadata": {},
        "source": [
            "#  Entrenamiento del Modelo Predictivo (PyCaret)\n",
            "\n",
            "##  Objetivo\n",
            "Este notebook orquesta el pipeline de entrenamiento de Machine Learning utilizando **PyCaret**.\n",
            "El objetivo es encontrar y optimizar el mejor algoritmo capaz de predecir la probabilidad de **Enfermedad Card铆aca** bas谩ndose en biomarcadores cl铆nicos.\n",
            "\n",
            "## 锔 Estrategia de Modelado\n",
            "1. **Preprocesamiento Robusto**: Normalizaci贸n y manejo de outliers.\n",
            "2. **Balanceo de Clases**: Uso de t茅cnicas (SMOTE) para mitigar el desbalance entre pacientes sanos y enfermos.\n",
            "3. **Optimizaci贸n de Recall**: Priorizamos la **Sensibilidad (Recall)** sobre la Precisi贸n.\n",
            "   - *Contexto M茅dico*: Es peor no detectar a un enfermo (Falso Negativo) que alarmar a un sano (Falso Positivo).\n",
            "4. **Selecci贸n de Modelos**: Comparaci贸n autom谩tica de +15 algoritmos.\n",
            "\n",
            "##  Entradas y Salidas\n",
            "- **Input**: `data/02_intermediate/process_data.parquet` (Datos limpios).\n",
            "- **Output**: `models/best_pipeline.pkl` (Modelo serializado listo para producci贸n)."
        ]
    }

    # We will rebuild the cells list to ensure order
    new_cells = [header_cell]

    # Iterate through existing cells and add/replace markdown
    for cell in nb['cells']:
        source_text = "".join(cell['source'])

        # Check Configuration code block
        if "SAMPLE_FRAC =" in source_text and "DATA_PATH =" in source_text:
            new_cells.append({
                "cell_type": "markdown",
                "metadata": {},
                "source": [
                    "## 1. Configuraci贸n del Entorno\n",
                    "\n",
                    "Definimos par谩metros globales.\n",
                    "- **SAMPLE_FRAC**: Porcentaje de datos a usar. Para pruebas r谩pidas usamos `0.5`, para el modelo final debe ser `1.0`.\n",
                    "- **Rutas**: Ubicaci贸n de datos y donde se guardar谩n los artefactos."
                ]
            })
            new_cells.append(cell)

        # Check Load Data code block
        elif "# 1. LOAD DATA" in source_text:
            new_cells.append({
                "cell_type": "markdown",
                "metadata": {},
                "source": [
                    "## 2. Carga y Filtrado de Datos\n",
                    "\n",
                    "Cargamos el dataset y aplicamos el esquema definido en `model_config.json`.\n",
                    "Es vital entrenar **solo** con las columnas que estar谩n disponibles en la aplicaci贸n final (Features + Target), descartando metadatos o IDs que causar铆an *data leakage*."
                ]
            })
            new_cells.append(cell)

        # Check Setup PyCaret code block
        elif "# 2. SETUP PYCARET" in source_text:
            new_cells.append({
                "cell_type": "markdown",
                "metadata": {},
                "source": [
                    "## 3. Configuraci贸n del Experimento (Setup)\n",
                    "\n",
                    "La funci贸n `setup()` inicializa el entorno de PyCaret y crea el pipeline de transformaci贸n.\n",
                    "- **normalize=True**: Escala las variables para que tengan rangos comparables. Usamos `RobustScaler` para ser resilientes a outliers.\n",
                    "- **remove_outliers=True**: Elimina anomal铆as estad铆sticas que podr铆an sesgar el modelo.\n",
                    "- **fix_imbalance=True**: Aplica SMOTE para generar muestras sint茅ticas de la clase minoritaria (Enfermos), mejorando el aprendizaje."
                ]
            })
            new_cells.append(cell)

        # Check Compare Models code block
        elif "# 3. COMPARE & TRAIN" in source_text:
            new_cells.append({
                "cell_type": "markdown",
                "metadata": {},
                "source": [
                    "## 4. Comparaci贸n y Selecci贸n de Modelos\n",
                    "\n",
                    "Entrenamos m煤ltiples algoritmos (Logistic Regression, XGBoost, Random Forest, etc.) con validaci贸n cruzada (Cross-Validation).\n",
                    "**M茅trica Clave: Recall**. Buscamos maximizar la capacidad del modelo para detectar casos positivos reales."
                ]
            })
            new_cells.append(cell)

        # Check Finalize code block
        elif "# 4. FINALIZE & SAVE" in source_text:
            new_cells.append({
                "cell_type": "markdown",
                "metadata": {},
                "source": [
                    "## 5. Finalizaci贸n y Persistencia\n",
                    "\n",
                    "Una vez seleccionado el mejor modelo:\n",
                    "1. **Finalize**: Se re-entrena el modelo utilizando el 100% de los datos (incluyendo el set de prueba reservado anteriormente).\n",
                    "2. **Save**: Se guarda el pipeline completo (preprocesamiento + modelo) en un archivo `.pkl` para su despliegue en la API/Streamlit."
                ]
            })
            new_cells.append(cell)

        else:
            # Append other cells if any (though looking at the file, we covered all code blocks)
            # To be safe, avoid duplicates if I manually inserted headers inside code cells in previous attempts (which I didn't)
            # But the original file has code cells with comments. We keep them.
            pass

    nb['cells'] = new_cells

    with open(filepath, 'w') as f:
        json.dump(nb, f, indent=1)

if __name__ == "__main__":
    update_notebook("notebooks/02_Training_PyCaret.ipynb")
