{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "71dac5fd",
   "metadata": {
    "tags": [
     "papermill-error-cell-tag"
    ]
   },
   "source": [
    "<span style=\"color:red; font-family:Helvetica Neue, Helvetica, Arial, sans-serif; font-size:2em;\">An Exception was encountered at '<a href=\"#papermill-error-cell\">In [1]</a>'.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d0bfc81",
   "metadata": {
    "papermill": {
     "duration": 0.003253,
     "end_time": "2025-11-28T22:34:53.837962",
     "exception": false,
     "start_time": "2025-11-28T22:34:53.834709",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Sprint 6: Análisis de Interpretabilidad (SHAP) y Ética (Fairness)\n",
    "\n",
    "Este notebook implementa las recomendaciones técnicas para el Sprint 6, enfocándose en:\n",
    "1.  **Interpretabilidad Eficiente:** Uso de SHAP con sampling del dataset de entrenamiento.\n",
    "2.  **Análisis de Ética:** Evaluación de sesgos utilizando `fairlearn` (FNR Parity).\n",
    "\n",
    "**Nota:** Se utiliza una muestra del dataset para demostración, pero el código está preparado para escalar."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8b091a4",
   "metadata": {
    "tags": [
     "papermill-error-cell-tag"
    ]
   },
   "source": [
    "<span id=\"papermill-error-cell\" style=\"color:red; font-family:Helvetica Neue, Helvetica, Arial, sans-serif; font-size:2em;\">Execution using papermill encountered an exception here and stopped:</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98a98687",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-28T22:34:53.845764Z",
     "iopub.status.busy": "2025-11-28T22:34:53.845420Z",
     "iopub.status.idle": "2025-11-28T22:34:57.414475Z",
     "shell.execute_reply": "2025-11-28T22:34:57.412014Z"
    },
    "papermill": {
     "duration": 3.574528,
     "end_time": "2025-11-28T22:34:57.415642",
     "exception": true,
     "start_time": "2025-11-28T22:34:53.841114",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "('Pycaret only supports python 3.9, 3.10, 3.11. Your actual Python version: ', sys.version_info(major=3, minor=12, micro=12, releaselevel='final', serial=0), 'Please DOWNGRADE your Python version.')",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mseaborn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msns\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpycaret\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mclassification\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m load_model, predict_model, get_config\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mfairlearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmetrics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m MetricFrame\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmetrics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m recall_score, accuracy_score, confusion_matrix\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.12.12/lib/python3.12/site-packages/pycaret/__init__.py:22\u001b[39m\n\u001b[32m     16\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m     17\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mPycaret only supports python 3.9, 3.10, 3.11. Your actual Python version: \u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     18\u001b[39m         sys.version_info,\n\u001b[32m     19\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mPlease UPGRADE your Python version.\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     20\u001b[39m     )\n\u001b[32m     21\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m sys.version_info >= (\u001b[32m3\u001b[39m, \u001b[32m12\u001b[39m):\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m     23\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mPycaret only supports python 3.9, 3.10, 3.11. Your actual Python version: \u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     24\u001b[39m         sys.version_info,\n\u001b[32m     25\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mPlease DOWNGRADE your Python version.\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     26\u001b[39m     )\n",
      "\u001b[31mRuntimeError\u001b[39m: ('Pycaret only supports python 3.9, 3.10, 3.11. Your actual Python version: ', sys.version_info(major=3, minor=12, micro=12, releaselevel='final', serial=0), 'Please DOWNGRADE your Python version.')"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import shap\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pycaret.classification import load_model, predict_model, get_config\n",
    "from fairlearn.metrics import MetricFrame\n",
    "from sklearn.metrics import recall_score, accuracy_score, confusion_matrix\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Ensure project root is in path\n",
    "sys.path.append(os.path.abspath('..'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fa414cd",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## 1. Cargar Modelo y Datos\n",
    "Cargamos el pipeline final y el dataset de prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e150172",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the finalized pipeline\n",
    "try:\n",
    "    pipeline = load_model('../models/best_pipeline')\n",
    "    print(\"Pipeline loaded successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading pipeline: {e}\")\n",
    "    # Fallback for dev environment if model doesn't exist yet\n",
    "    pipeline = None\n",
    "\n",
    "# Load processed data (Simulating fetching X_test)\n",
    "try:\n",
    "    data = pd.read_parquet('../data/02_intermediate/processed_data.parquet')\n",
    "    # Split for demonstration (In real scenario, use the split saved during training)\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    train_data, test_data = train_test_split(data, test_size=0.2, random_state=42)\n",
    "    \n",
    "    X_train = train_data.drop(columns=['CVDINFR4'])\n",
    "    y_train = train_data['CVDINFR4']\n",
    "    X_test = test_data.drop(columns=['CVDINFR4'])\n",
    "    y_test = test_data['CVDINFR4']\n",
    "    \n",
    "    print(f\"Data loaded. Train shape: {X_train.shape}, Test shape: {X_test.shape}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading data: {e}\")\n",
    "    X_train, X_test, y_test = None, None, None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c47557f6",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## 2. Interpretabilidad con SHAP (Optimizado)\n",
    "Calculamos los valores SHAP utilizando una muestra del set de entrenamiento como background data para eficiencia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "469ca06e",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if pipeline and X_train is not None:\n",
    "    # Extract the model from the pipeline (assuming PyCaret structure)\n",
    "    # Note: PyCaret pipeline steps usually include 'trained_model'\n",
    "    try:\n",
    "        model = pipeline.named_steps['trained_model']\n",
    "    except:\n",
    "        # If not in named_steps, might be the last step\n",
    "        model = pipeline[-1]\n",
    "\n",
    "    # Sampling background data (Optimization for Large Datasets)\n",
    "    background_sample = X_train.sample(n=min(100, len(X_train)), random_state=42)\n",
    "    \n",
    "    # Initialize Explainer\n",
    "    # Note: For Tree models use TreeExplainer. For others, KernelExplainer (slower).\n",
    "    try:\n",
    "        explainer = shap.TreeExplainer(model)\n",
    "        shap_values = explainer.shap_values(X_test)\n",
    "        print(\"SHAP values calculated.\")\n",
    "    except Exception as e:\n",
    "        print(f\"TreeExplainer failed (model might not be tree-based or compatible): {e}\")\n",
    "        print(\"Attempting KernelExplainer (slower)...\")\n",
    "        explainer = shap.KernelExplainer(model.predict, background_sample)\n",
    "        shap_values = explainer.shap_values(X_test.sample(n=min(50, len(X_test)), random_state=42)) # Test on small sample for speed in dev\n",
    "\n",
    "    # Summary Plot\n",
    "    plt.figure()\n",
    "    shap.summary_plot(shap_values, X_test)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e97657be",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## 3. Análisis de Casos (Waterfall)\n",
    "Identificamos casos específicos: TP, TN, FP, FN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4647b32",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if pipeline and X_test is not None:\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "    \n",
    "    results_df = X_test.copy()\n",
    "    results_df['Actual'] = y_test\n",
    "    results_df['Predicted'] = y_pred\n",
    "    \n",
    "    # Find indices for each case\n",
    "    tp_idx = results_df[(results_df['Actual'] == 1) & (results_df['Predicted'] == 1)].index\n",
    "    tn_idx = results_df[(results_df['Actual'] == 0) & (results_df['Predicted'] == 0)].index\n",
    "    fp_idx = results_df[(results_df['Actual'] == 0) & (results_df['Predicted'] == 1)].index\n",
    "    fn_idx = results_df[(results_df['Actual'] == 1) & (results_df['Predicted'] == 0)].index\n",
    "    \n",
    "    print(f\"Found: {len(tp_idx)} TP, {len(tn_idx)} TN, {len(fp_idx)} FP, {len(fn_idx)} FN\")\n",
    "    \n",
    "    # Function to plot waterfall\n",
    "    def plot_waterfall(index, title):\n",
    "        if len(index) > 0:\n",
    "            idx = index[0]\n",
    "            # Locating the position in X_test to match shap_values index if numpy array\n",
    "            # But shap_values might be list of arrays for classification\n",
    "            # Assuming binary classification, shap_values[1] is for positive class\n",
    "            \n",
    "            # Need numeric index for shap_values\n",
    "            numeric_idx = X_test.index.get_loc(idx)\n",
    "            \n",
    "            print(f\"--- {title} (Index: {idx}) ---\")\n",
    "            # Handle shap_values structure (list for classification vs array for regression)\n",
    "            sv = shap_values[1][numeric_idx] if isinstance(shap_values, list) else shap_values[numeric_idx]\n",
    "            exp_val = explainer.expected_value[1] if isinstance(explainer.expected_value, list) else explainer.expected_value\n",
    "            \n",
    "            shap.waterfall_plot(\n",
    "                shap.Explanation(values=sv, \n",
    "                                 base_values=exp_val, \n",
    "                                 data=X_test.iloc[numeric_idx],\n",
    "                                 feature_names=X_test.columns)\n",
    "            )\n",
    "            plt.show()\n",
    "    \n",
    "    # Plotting one of each\n",
    "    plot_waterfall(fn_idx, \"False Negative (Critical)\")\n",
    "    plot_waterfall(fp_idx, \"False Positive\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6cdeb4e",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## 4. Ética y Sesgos (Fairlearn)\n",
    "Evaluamos la paridad de Tasa de Falsos Negativos (FNR) en grupos protegidos (Sexo)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2425fed",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if pipeline and X_test is not None and 'SEXVAR' in X_test.columns: # Assuming SEXVAR is the column name\n",
    "    # Map SEXVAR back to readable if encoded (assuming 1=Male, 2=Female based on BRFSS usually)\n",
    "    # Adjust column name based on actual data schema\n",
    "    sensitive_feature = X_test['SEXVAR'] \n",
    "    \n",
    "    # MetricFrame\n",
    "    # We focus on Recall (Sensitivity). Low recall = High FNR.\n",
    "    metric_frame = MetricFrame(\n",
    "        metrics=recall_score,\n",
    "        y_true=y_test,\n",
    "        y_pred=y_pred,\n",
    "        sensitive_features=sensitive_feature\n",
    "    )\n",
    "    \n",
    "    print(\"Recall per group:\")\n",
    "    print(metric_frame.by_group)\n",
    "    \n",
    "    # Plot\n",
    "    metric_frame.by_group.plot(kind='bar', title='Recall by Sex')\n",
    "    plt.ylabel('Recall')\n",
    "    plt.show()\n",
    "    \n",
    "    # FNR Calculation (1 - Recall)\n",
    "    fnr_frame = MetricFrame(\n",
    "        metrics=lambda y_t, y_p: 1 - recall_score(y_t, y_p),\n",
    "        y_true=y_test,\n",
    "        y_pred=y_pred,\n",
    "        sensitive_features=sensitive_feature\n",
    "    )\n",
    "    print(\"\\nFalse Negative Rate (FNR) per group:\")\n",
    "    print(fnr_frame.by_group)\n",
    "else:\n",
    "    print(\"Skipping Fairness analysis: Pipeline, Data or 'SEXVAR' column missing.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 8.484621,
   "end_time": "2025-11-28T22:35:00.823712",
   "environment_variables": {},
   "exception": true,
   "input_path": "notebooks/06_sprint6_analysis.ipynb",
   "output_path": "notebooks/06_sprint6_analysis_output.ipynb",
   "parameters": {},
   "start_time": "2025-11-28T22:34:52.339091",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}