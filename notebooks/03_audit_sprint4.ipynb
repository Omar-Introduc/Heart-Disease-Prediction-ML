{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Audit Sprint 4: Functional Prototype Verification\n",
    "\n",
    "This notebook audits the current state of the project (Sprint 4). It verifies:\n",
    "1. **Environment**: Correct installation of key libraries.\n",
    "2. **Data Ingestion**: Processing of raw SAS/XPT files.\n",
    "3. **Scratch Implementation**: Functionality of the custom XGBoost class.\n",
    "4. **Productive Pipeline**: Baseline training with PyCaret (Note: May skip on Python 3.12).\n",
    "5. **Application**: UI component readiness."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Environment Verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import streamlit as st\n",
    "import sys\n",
    "import os\n",
    "\n",
    "pycaret_available = False\n",
    "try:\n",
    "    import pycaret\n",
    "    pycaret_available = True\n",
    "    print(f\"PyCaret Version: {pycaret.__version__}\")\n",
    "except (ImportError, RuntimeError) as e:\n",
    "    print(f\"⚠️ PyCaret not available (likely Python 3.12 issue): {e}\")\n",
    "\n",
    "print(f\"Python Version: {sys.version}\")\n",
    "print(f\"Pandas Version: {pd.__version__}\")\n",
    "print(f\"Numpy Version: {np.__version__}\")\n",
    "print(f\"XGBoost Version: {xgb.__version__}\")\n",
    "print(f\"Streamlit Version: {st.__version__}\")\n",
    "\n",
    "# Ensure project root is in path\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n",
    "    print(f\"Added {project_root} to sys.path\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Ingestion Audit\n",
    "Verifying `src/data_ingestion.py`. We will use the sample file `LLCP2022_10rows.xpt`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data_ingestion import load_and_process_data, split_data\n",
    "import os\n",
    "\n",
    "# Paths\n",
    "raw_path = \"../data/01_raw/LLCP2022_10rows.xpt\"\n",
    "output_dir = \"../data/02_intermediate\"\n",
    "processed_path = os.path.join(output_dir, \"processed_data.parquet\")\n",
    "\n",
    "if not os.path.exists(raw_path):\n",
    "    print(f\"⚠️ Warning: Raw file {raw_path} not found. Using mock data for audit.\")\n",
    "else:\n",
    "    print(f\"Found raw file at {raw_path}\")\n",
    "    \n",
    "    try:\n",
    "        # Run Ingestion\n",
    "        df = load_and_process_data(raw_path, output_dir)\n",
    "        \n",
    "        if df is not None:\n",
    "            print(\"✅ Data loaded successfully.\")\n",
    "            print(f\"Shape: {df.shape}\")\n",
    "            \n",
    "            # Check for Target\n",
    "            if 'CVDINFR4' in df.columns or 'CVDCRHD4' in df.columns:\n",
    "                 print(\"✅ Target variable found (CVDINFR4 or CVDCRHD4).\")\n",
    "            else:\n",
    "                 print(\"❌ Target variable NOT found.\")\n",
    "                 \n",
    "            # Check SEQNO index\n",
    "            if df.index.name == 'SEQNO':\n",
    "                print(\"✅ Index is correctly set to SEQNO.\")\n",
    "            else:\n",
    "                 print(f\"⚠️ Index is {df.index.name}, expected SEQNO.\")\n",
    "                 \n",
    "            # Verify Parquet creation\n",
    "            if os.path.exists(processed_path):\n",
    "                print(f\"✅ Parquet file created at {processed_path}\")\n",
    "            else:\n",
    "                print(\"❌ Parquet file NOT created.\")\n",
    "        else:\n",
    "            print(\"❌ Data ingestion failed (returned None).\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Data ingestion raised error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Scratch Model Implementation Audit\n",
    "Verifying `src/model.py` (XGBoost from scratch) using synthetic data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.model import XGBoostScratch\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Generate synthetic data\n",
    "X, y = make_classification(n_samples=100, n_features=10, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Training Scratch Model on {len(X_train)} samples...\")\n",
    "\n",
    "try:\n",
    "    # Instantiate\n",
    "    model_scratch = XGBoostScratch(n_estimators=5, max_depth=2, learning_rate=0.1)\n",
    "    \n",
    "    # Fit\n",
    "    model_scratch.fit(X_train, y_train)\n",
    "    print(\"✅ Model fitted successfully.\")\n",
    "    \n",
    "    # Predict\n",
    "    y_pred = model_scratch.predict(X_test)\n",
    "    y_proba = model_scratch.predict_proba(X_test)\n",
    "    \n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    print(f\"✅ Prediction successful. Accuracy: {acc:.2f}\")\n",
    "    print(f\"Probabilities sample: {y_proba[:5]}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ Scratch Model verification failed: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Productive Pipeline (PyCaret) Audit\n",
    "Verifying `src/train_pycaret.py`. \n",
    "**Note:** Errors here are caught so they don't stop the whole notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load data\n",
    "data_path = \"../data/02_intermediate/processed_data.parquet\"\n",
    "\n",
    "if os.path.exists(data_path) and pycaret_available:\n",
    "    try:\n",
    "        from pycaret.classification import setup, compare_models, pull\n",
    "        df = pd.read_parquet(data_path)\n",
    "        target_col = 'CVDINFR4'\n",
    "        if target_col not in df.columns and 'CVDCRHD4' in df.columns:\n",
    "            target_col = 'CVDCRHD4'\n",
    "        \n",
    "        print(f\"Using target: {target_col}\")\n",
    "        \n",
    "        # Minimal PyCaret Setup\n",
    "        print(\"Initializing PyCaret Setup...\")\n",
    "        # Use a small sample to speed up audit\n",
    "        sample_df = df.head(50) if len(df) > 50 else df\n",
    "        \n",
    "        exp = setup(data=sample_df, target=target_col, session_id=123, verbose=False, html=False)\n",
    "        print(\"✅ PyCaret Setup initialized.\")\n",
    "        \n",
    "        # Compare Models\n",
    "        print(\"Running compare_models (budget mode)...\")\n",
    "        best = compare_models(include=['lr', 'dt'], n_select=1)\n",
    "        \n",
    "        print(\"✅ compare_models execution finished.\")\n",
    "        print(pull())\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ PyCaret execution failed: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "else:\n",
    "    print(\"⚠️ Skipping PyCaret audit (Data missing or Library unavailable).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. UI Application Check\n",
    "Verifying `src/app.py` dependencies and `src/adapters.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.adapters import PyCaretAdapter\n",
    "import pickle\n",
    "\n",
    "# Check Adapter\n",
    "try:\n",
    "    # Mock a model object with predict_proba\n",
    "    class MockModel:\n",
    "        def predict_proba(self, X):\n",
    "            return np.array([[0.1, 0.9]] * len(X))\n",
    "            \n",
    "    adapter = PyCaretAdapter(MockModel())\n",
    "    X_mock = pd.DataFrame(np.random.rand(5, 5))\n",
    "    probs = adapter.predict_proba(X_mock)\n",
    "    preds = adapter.predict(X_mock, threshold=0.5)\n",
    "    \n",
    "    print(\"✅ PyCaretAdapter works with mock model.\")\n",
    "    print(f\"Probs shape: {probs.shape}, Preds shape: {preds.shape}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"❌ Adapter verification failed: {e}\")\n",
    "\n",
    "print(\"\\nTo run the UI, execute command in terminal:\")\n",
    "print(\"streamlit run src/app.py\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
