{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sprint 6: Clinical Model Training (PyCaret)\n",
    "\n",
    "**Objective:** Train and optimize the machine learning model using the new NHANES clinical biomarkers.\n",
    "**Key Changes:**\n",
    "- Uses `SAMPLE_FRAC = 0.005` for development speed.\n",
    "- Explicitly defines **numeric** (Biomarkers) and **categorical** features.\n",
    "- Applies `RobustScaler` to handle varying clinical scales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pycaret.classification import setup, compare_models, save_model, pull\n",
    "import os\n",
    "\n",
    "# --- PERFORMANCE CRITICAL CONFIG ---\n",
    "SAMPLE_FRAC = 0.005 # 0.5% of data\n",
    "# CAMBIAR SAMPLE_FRAC a 1.0 para el entrenamiento final con todos los datos\n",
    "# -----------------------------------\n",
    "\n",
    "print(f\"⚙️ Config: Using {SAMPLE_FRAC*100}% of available data.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load and Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"../data/02_intermediate/process_data.parquet\"\n",
    "\n",
    "# Fallback path check\n",
    "if not os.path.exists(data_path):\n",
    "    data_path = \"data/02_intermediate/process_data.parquet\"\n",
    "\n",
    "if os.path.exists(data_path):\n",
    "    df = pd.read_parquet(data_path)\n",
    "    \n",
    "    # Rename Spanish columns to English Schema\n",
    "    col_map = {\n",
    "        'Presion_Sistolica': 'SystolicBP', 'Colesterol_Total': 'TotalCholesterol',\n",
    "        'LDL': 'LDL', 'Triglycerides': 'Triglycerides', 'HbA1c': 'HbA1c',\n",
    "        'Glucosa': 'Glucose', 'Acido_Urico': 'UricAcid', 'Creatinina': 'Creatinine',\n",
    "        'BMI': 'BMI', 'Cintura': 'WaistCircumference', 'Sexo': 'Sex',\n",
    "        'Fumador': 'Smoking', 'Actividad_Fisica': 'PhysicalActivity',\n",
    "        'TARGET': 'HeartDisease'\n",
    "    }\n",
    "    df.rename(columns=col_map, inplace=True)\n",
    "    \n",
    "    # Handle missing Alcohol column if strictly required by new schema\n",
    "    if 'Alcohol' not in df.columns:\n",
    "        # Placeholder: Assuming 0 if not present, or drop from features list if not available\n",
    "        # For now, we add it as 0 to avoid errors if prompted\n",
    "        df['Alcohol'] = 0\n",
    "\n",
    "    # --- SAMPLING ---\n",
    "    df = df.sample(frac=SAMPLE_FRAC, random_state=42).reset_index(drop=True)\n",
    "    print(f\"✅ Data loaded & Sampled. Active Shape: {df.shape}\")\n",
    "    print(f\"Target distribution:\\n{df['HeartDisease'].value_counts(normalize=True)}\")\n",
    "    \n",
    "else:\n",
    "    print(\"❌ Data file not found.\")\n",
    "    df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. PyCaret Setup\n",
    "Configuring the experiment with specific variable types and robust scaling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not df.empty and 'HeartDisease' in df.columns:\n",
    "    # Define Features explicitly\n",
    "    numeric_feats = [\n",
    "        'SystolicBP', 'TotalCholesterol', 'LDL', 'Triglycerides', \n",
    "        'HbA1c', 'Glucose', 'UricAcid', 'Creatinine', \n",
    "        'BMI', 'WaistCircumference'\n",
    "    ]\n",
    "    \n",
    "    # Filter only those present in DF\n",
    "    numeric_feats = [c for c in numeric_feats if c in df.columns]\n",
    "    \n",
    "    categorical_feats = [\n",
    "        'Sex', 'Smoking', 'Alcohol', 'PhysicalActivity'\n",
    "    ]\n",
    "    categorical_feats = [c for c in categorical_feats if c in df.columns]\n",
    "\n",
    "    # Setup\n",
    "    exp = setup(\n",
    "        data=df,\n",
    "        target='HeartDisease',\n",
    "        numeric_features=numeric_feats,\n",
    "        categorical_features=categorical_feats,\n",
    "        normalize=True,\n",
    "        normalize_method='robust', # Critical for biological outliers\n",
    "        session_id=42,\n",
    "        verbose=True,\n",
    "        html=False\n",
    "    )\n",
    "    \n",
    "    print(\"✅ PyCaret Setup Complete.\")\n",
    "else:\n",
    "    print(\"❌ Setup skipped (No data or target).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Compare Models & Save Best Pipeline\n",
    "Evaluating baseline performance across different algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not df.empty:\n",
    "    # Compare models (budget friendly)\n",
    "    best_model = compare_models(sort='Recall', n_select=1)\n",
    "    \n",
    "    # Print Leaderboard\n",
    "    print(pull())\n",
    "    \n",
    "    # Save Model\n",
    "    save_path = \"../models/best_pipeline\"\n",
    "    # Ensure models dir exists\n",
    "    os.makedirs(\"../models\", exist_ok=True)\n",
    "    \n",
    "    save_model(best_model, save_path)\n",
    "    print(f\"✅ Best pipeline saved to {save_path}.pkl\")"
   ]
  }\n ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
