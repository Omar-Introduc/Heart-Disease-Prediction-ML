{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sprint 6: Clinical Model Training (PyCaret)\n",
    "\n",
    "**Objective:** Train and optimize the machine learning model using the new NHANES clinical biomarkers.\n",
    "**Key Changes:**\n",
    "- Uses `SAMPLE_FRAC = 0.005` for development speed.\n",
    "- Explicitly defines **numeric** and **categorical** features from `models/model_config.json`.\n",
    "- Applies `RobustScaler` to handle varying clinical scales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pycaret.classification import setup, compare_models, save_model, pull\n",
    "import os\n",
    "import json\n",
    "\n",
    "# --- PERFORMANCE CRITICAL CONFIG ---\n",
    "SAMPLE_FRAC = 0.005 \n",
    "# -----------------------------------\n",
    "\n",
    "print(f\"⚙️ Config: Using {SAMPLE_FRAC*100}% of available data.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path = \"../models/model_config.json\"\n",
    "if not os.path.exists(config_path):\n",
    "    config_path = \"models/model_config.json\"\n",
    "\n",
    "try:\n",
    "    with open(config_path, 'r') as f:\n",
    "        config = json.load(f)\n",
    "    print(\"✅ Configuration loaded.\")\n",
    "    numeric_feats = config['numeric_features']\n",
    "    categorical_feats = config['categorical_features']\n",
    "    target = config['target']\n",
    "except Exception as e:\n",
    "    print(f\"❌ Error loading config: {e}\")\n",
    "    numeric_feats = []\n",
    "    categorical_feats = []\n",
    "    target = 'HeartDisease'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load and Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"../data/02_intermediate/process_data.parquet\"\n",
    "if not os.path.exists(data_path):\n",
    "    data_path = \"data/02_intermediate/process_data.parquet\"\n",
    "\n",
    "if os.path.exists(data_path):\n",
    "    df = pd.read_parquet(data_path)\n",
    "    \n",
    "    # Rename Spanish columns to English Schema\n",
    "    col_map = {\n",
    "        'Presion_Sistolica': 'SystolicBP', 'Colesterol_Total': 'TotalCholesterol',\n",
    "        'LDL': 'LDL', 'Triglycerides': 'Triglycerides', 'HbA1c': 'HbA1c',\n",
    "        'Glucosa': 'Glucose', 'Acido_Urico': 'UricAcid', 'Creatinina': 'Creatinine',\n",
    "        'BMI': 'BMI', 'Cintura': 'WaistCircumference', 'Sexo': 'Sex',\n",
    "        'Fumador': 'Smoking', 'Actividad_Fisica': 'PhysicalActivity',\n",
    "        'TARGET': 'HeartDisease'\n",
    "    }\n",
    "    df.rename(columns=col_map, inplace=True)\n",
    "    \n",
    "    # Ensure missing categorical features exist (imputation fallback)\n",
    "    for col in categorical_feats:\n",
    "        if col not in df.columns:\n",
    "            df[col] = 0 # Default for binary/categorical\n",
    "            \n",
    "    # Handle missing numeric features (simple imputation before sampling)\n",
    "    for col in numeric_feats:\n",
    "        if col not in df.columns:\n",
    "             df[col] = np.nan\n",
    "\n",
    "    # --- SAMPLING ---\n",
    "    df = df.sample(frac=SAMPLE_FRAC, random_state=42).reset_index(drop=True)\n",
    "    print(f\"✅ Data loaded & Sampled. Active Shape: {df.shape}\")\n",
    "    \n",
    "else:\n",
    "    print(\"❌ Data file not found.\")\n",
    "    df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. PyCaret Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not df.empty and target in df.columns:\n",
    "    # Verify features exist in sampled DF\n",
    "    valid_numeric = [c for c in numeric_feats if c in df.columns]\n",
    "    valid_categorical = [c for c in categorical_feats if c in df.columns]\n",
    "\n",
    "    # Setup\n",
    "    exp = setup(\n",
    "        data=df,\n",
    "        target=target,\n",
    "        numeric_features=valid_numeric,\n",
    "        categorical_features=valid_categorical,\n",
    "        normalize=True,\n",
    "        normalize_method='robust', \n",
    "        imputation_type='simple',\n",
    "        numeric_imputation='mean',\n",
    "        categorical_imputation='constant',\n",
    "        session_id=42,\n",
    "        verbose=True,\n",
    "        html=False\n",
    "    )\n",
    "    \n",
    "    print(\"✅ PyCaret Setup Complete.\")\n",
    "else:\n",
    "    print(\"❌ Setup skipped (No data or target).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Compare Models & Save Best Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not df.empty:\n",
    "    best_model = compare_models(sort='Recall', n_select=1)\n",
    "    print(pull())\n",
    "    \n",
    "    save_path = \"../models/best_pipeline\"\n",
    "    os.makedirs(\"../models\", exist_ok=True)\n",
    "    save_model(best_model, save_path)\n",
    "    print(f\"✅ Best pipeline saved to {save_path}.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
