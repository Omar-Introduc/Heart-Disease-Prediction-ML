2025-11-27 21:35:32,191:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-11-27 21:35:32,191:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-11-27 21:35:32,191:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-11-27 21:35:32,191:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-11-27 21:35:33,204:INFO:PyCaret ClassificationExperiment
2025-11-27 21:35:33,204:INFO:Logging name: clf-default-name
2025-11-27 21:35:33,204:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-11-27 21:35:33,204:INFO:version 3.3.2
2025-11-27 21:35:33,204:INFO:Initializing setup()
2025-11-27 21:35:33,204:INFO:self.USI: b0f4
2025-11-27 21:35:33,204:INFO:self._variable_keys: {'seed', 'logging_param', 'html_param', 'X', 'USI', 'is_multiclass', 'X_train', 'data', 'fold_generator', 'exp_id', 'idx', 'log_plots_param', 'fold_groups_param', 'X_test', 'pipeline', 'gpu_param', 'fix_imbalance', 'target_param', 'y_train', 'exp_name_log', 'y_test', 'y', 'fold_shuffle_param', 'n_jobs_param', 'memory', 'gpu_n_jobs_param', '_available_plots', '_ml_usecase'}
2025-11-27 21:35:33,204:INFO:Checking environment
2025-11-27 21:35:33,204:INFO:python_version: 3.10.19
2025-11-27 21:35:33,204:INFO:python_build: ('main', 'Oct 22 2025 22:23:22')
2025-11-27 21:35:33,204:INFO:machine: AMD64
2025-11-27 21:35:33,204:INFO:platform: Windows-10-10.0.26100-SP0
2025-11-27 21:35:33,204:INFO:Memory: svmem(total=16282144768, available=5985746944, percent=63.2, used=10296397824, free=5985746944)
2025-11-27 21:35:33,204:INFO:Physical Core: 6
2025-11-27 21:35:33,204:INFO:Logical Core: 12
2025-11-27 21:35:33,204:INFO:Checking libraries
2025-11-27 21:35:33,204:INFO:System:
2025-11-27 21:35:33,204:INFO:    python: 3.10.19 | packaged by conda-forge | (main, Oct 22 2025, 22:23:22) [MSC v.1944 64 bit (AMD64)]
2025-11-27 21:35:33,204:INFO:executable: c:\Users\OMAR\miniconda3\envs\xgb_env\python.exe
2025-11-27 21:35:33,204:INFO:   machine: Windows-10-10.0.26100-SP0
2025-11-27 21:35:33,204:INFO:PyCaret required dependencies:
2025-11-27 21:35:33,204:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-27 21:35:33,268:INFO:                 pip: 25.3
2025-11-27 21:35:33,268:INFO:          setuptools: 80.9.0
2025-11-27 21:35:33,268:INFO:             pycaret: 3.3.2
2025-11-27 21:35:33,268:INFO:             IPython: 8.37.0
2025-11-27 21:35:33,268:INFO:          ipywidgets: 8.1.8
2025-11-27 21:35:33,268:INFO:                tqdm: 4.67.1
2025-11-27 21:35:33,268:INFO:               numpy: 1.26.4
2025-11-27 21:35:33,268:INFO:              pandas: 2.1.4
2025-11-27 21:35:33,268:INFO:              jinja2: 3.1.6
2025-11-27 21:35:33,268:INFO:               scipy: 1.11.4
2025-11-27 21:35:33,268:INFO:              joblib: 1.3.2
2025-11-27 21:35:33,268:INFO:             sklearn: 1.4.2
2025-11-27 21:35:33,268:INFO:                pyod: 2.0.5
2025-11-27 21:35:33,268:INFO:            imblearn: 0.14.0
2025-11-27 21:35:33,268:INFO:   category_encoders: 2.7.0
2025-11-27 21:35:33,272:INFO:            lightgbm: 4.6.0
2025-11-27 21:35:33,272:INFO:               numba: 0.62.1
2025-11-27 21:35:33,272:INFO:            requests: 2.32.5
2025-11-27 21:35:33,272:INFO:          matplotlib: 3.7.5
2025-11-27 21:35:33,272:INFO:          scikitplot: 0.3.7
2025-11-27 21:35:33,272:INFO:         yellowbrick: 1.5
2025-11-27 21:35:33,272:INFO:              plotly: 6.5.0
2025-11-27 21:35:33,272:INFO:    plotly-resampler: Not installed
2025-11-27 21:35:33,272:INFO:             kaleido: 1.2.0
2025-11-27 21:35:33,272:INFO:           schemdraw: 0.15
2025-11-27 21:35:33,272:INFO:         statsmodels: 0.14.5
2025-11-27 21:35:33,272:INFO:              sktime: 0.26.0
2025-11-27 21:35:33,272:INFO:               tbats: 1.1.3
2025-11-27 21:35:33,272:INFO:            pmdarima: 2.0.4
2025-11-27 21:35:33,272:INFO:              psutil: 7.1.3
2025-11-27 21:35:33,272:INFO:          markupsafe: 3.0.3
2025-11-27 21:35:33,272:INFO:             pickle5: Not installed
2025-11-27 21:35:33,272:INFO:         cloudpickle: 3.1.2
2025-11-27 21:35:33,272:INFO:         deprecation: 2.1.0
2025-11-27 21:35:33,272:INFO:              xxhash: 3.6.0
2025-11-27 21:35:33,272:INFO:           wurlitzer: Not installed
2025-11-27 21:35:33,272:INFO:PyCaret optional dependencies:
2025-11-27 21:35:33,279:INFO:                shap: 0.48.0
2025-11-27 21:35:33,279:INFO:           interpret: Not installed
2025-11-27 21:35:33,279:INFO:                umap: Not installed
2025-11-27 21:35:33,279:INFO:     ydata_profiling: Not installed
2025-11-27 21:35:33,279:INFO:  explainerdashboard: Not installed
2025-11-27 21:35:33,279:INFO:             autoviz: Not installed
2025-11-27 21:35:33,279:INFO:           fairlearn: 0.12.0.dev0
2025-11-27 21:35:33,279:INFO:          deepchecks: Not installed
2025-11-27 21:35:33,279:INFO:             xgboost: 3.1.2
2025-11-27 21:35:33,279:INFO:            catboost: Not installed
2025-11-27 21:35:33,279:INFO:              kmodes: Not installed
2025-11-27 21:35:33,279:INFO:             mlxtend: Not installed
2025-11-27 21:35:33,279:INFO:       statsforecast: Not installed
2025-11-27 21:35:33,279:INFO:        tune_sklearn: Not installed
2025-11-27 21:35:33,279:INFO:                 ray: Not installed
2025-11-27 21:35:33,279:INFO:            hyperopt: Not installed
2025-11-27 21:35:33,279:INFO:              optuna: Not installed
2025-11-27 21:35:33,279:INFO:               skopt: Not installed
2025-11-27 21:35:33,279:INFO:              mlflow: Not installed
2025-11-27 21:35:33,279:INFO:              gradio: Not installed
2025-11-27 21:35:33,279:INFO:             fastapi: Not installed
2025-11-27 21:35:33,279:INFO:             uvicorn: Not installed
2025-11-27 21:35:33,279:INFO:              m2cgen: Not installed
2025-11-27 21:35:33,279:INFO:           evidently: Not installed
2025-11-27 21:35:33,279:INFO:               fugue: Not installed
2025-11-27 21:35:33,281:INFO:           streamlit: 1.51.0
2025-11-27 21:35:33,281:INFO:             prophet: Not installed
2025-11-27 21:35:33,281:INFO:None
2025-11-27 21:35:33,281:INFO:Set up data.
2025-11-27 21:35:33,317:INFO:Set up folding strategy.
2025-11-27 21:35:33,317:INFO:Set up train/test split.
2025-11-27 21:35:33,344:INFO:Set up index.
2025-11-27 21:35:33,344:INFO:Assigning column types.
2025-11-27 21:35:33,365:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-11-27 21:35:33,390:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-11-27 21:35:33,395:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-11-27 21:35:33,414:INFO:Soft dependency imported: xgboost: 3.1.2
2025-11-27 21:35:33,418:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-27 21:35:33,445:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-11-27 21:35:33,445:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-11-27 21:35:33,459:INFO:Soft dependency imported: xgboost: 3.1.2
2025-11-27 21:35:33,459:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-27 21:35:33,459:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-11-27 21:35:33,488:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-11-27 21:35:33,504:INFO:Soft dependency imported: xgboost: 3.1.2
2025-11-27 21:35:33,506:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-27 21:35:33,531:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-11-27 21:35:33,545:INFO:Soft dependency imported: xgboost: 3.1.2
2025-11-27 21:35:33,547:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-27 21:35:33,547:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-11-27 21:35:33,580:INFO:Soft dependency imported: xgboost: 3.1.2
2025-11-27 21:35:33,588:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-27 21:35:33,628:INFO:Soft dependency imported: xgboost: 3.1.2
2025-11-27 21:35:33,628:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-27 21:35:33,628:INFO:Preparing preprocessing pipeline...
2025-11-27 21:35:33,637:INFO:Set up simple imputation.
2025-11-27 21:35:33,645:INFO:Set up encoding of ordinal features.
2025-11-27 21:35:33,651:INFO:Set up encoding of categorical features.
2025-11-27 21:35:33,747:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'SAFETIME' 'CTELNUM1' 'CELLFON5' 'CADULT1'
 'CELLSEX1' 'PVTRESD3' 'CCLGHOUS' 'CSTATE1' 'LANDLINE' 'HHADULT'
 'LASTDEN4' 'RMVTETH4' 'BLDSTFIT' 'SDNATES1' 'PDIABTS1' 'PREDIAB2'
 'DIABTYPE' 'INSULIN1' 'CHKHEMO3' 'EYEEXAM1' 'DIABEYE1' 'DIABEDU1'
 'FEETSORE' 'TOLDCFS' 'HAVECFS' 'WORKCFS' 'IMFVPLA3' 'HPVADVC4' 'HPVADSHT'
 'SHINGLE2' 'COVIDVA1' 'COVACGET' 'COVIDNU1' 'COVIDINT' 'COVIDFS1'
 'COVIDSE1' 'COPDCOGH' 'COPDFLEM' 'COPDBRTH' 'COPDBTST' 'COPDSMOK'
 'CNCRDIFF' 'CNCRAGE' 'CNCRTYP2' 'CSRVTRT3' 'CSRVDOC1' 'CSRVSUM'
 'CSRVRTRN' 'CSRVINST' 'CSRVINSR' 'CSRVDEIN' 'CSRVCLIN' 'CSRVPAIN'
 'CSRVCTL2' 'PSATEST1' 'PSATIME1' 'PCPSARS2' 'PSASUGST' 'PCSTALK1'
 'CIMEMLOS' 'CDHOUSE' 'CDASSIST' 'CDHELP' 'CDSOCIAL' 'CDDISCUS' 'CAREGIV1'
 'CRGVREL4' 'CRGVLNG1' 'CRGVHRS1' 'CRGVPRB3' 'CRGVALZD' 'CRGVPER1'
 'CRGVHOU1' 'CRGVEXPT' 'ACEDEPRS' 'ACEDRINK' 'ACEDRUGS' 'ACEPRISN'
 'ACEDIVRC' 'ACEPUNCH' 'ACEHURT1' 'ACESWEAR' 'ACETOUCH' 'ACETTHEM'
 'ACEHVSEX' 'ACEADSAF' 'ACEADNED' 'MARIJAN1' 'MARJSMOK' 'MARJEAT'
 'MARJVAPE' 'MARJDAB' 'MARJOTHR' 'USEMRJN4' 'LASTSMK2' 'STOPSMK2'
 'MENTCIGS' 'MENTECIG' 'HEATTBCO' 'ASBIALCH' 'ASBIDRNK' 'ASBIBING'
 'ASBIADVC' 'ASBIRDUC' 'FIREARM5' 'GUNLOAD' 'LOADULK2' 'RCSXBRTH'
 'CASTHNO2' 'BIRTHSEX' 'SOMALE' 'SOFEMALE' 'TRNSGNDR' 'HADSEX' 'PFPPRVN4'
 'TYPCNTR9' 'BRTHCNT4' 'WHEREGET' 'NOBCUSE8' 'BCPREFER' 'RRCLASS3'
 'RRCOGNT2' 'RRTREAT' 'RRATWRK2' 'RRHCARE4' 'RRPHYSM2' 'CAGEG']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-27 21:35:33,806:INFO:Finished creating preprocessing pipeline.
2025-11-27 21:35:33,817:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\OMAR\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['STATE', 'FMONTH', 'DISPCODE',
                                             'PSU', 'CTELENM1', 'PVTRESD1',
                                             'COLGHOUS', 'STATERE1', 'CELPHON1',
                                             'LADULT1', 'COLGSEX1', 'NUMADULT',
                                             'LANDSEX1', 'NUMMEN', 'NUMWOMEN',
                                             'RESPSLCT', 'SAFETIME', 'CTELNUM1',
                                             'CELLFON5', 'CADULT1...
                                                                         'data_type': dtype('O'),
                                                                         'mapping': 02     0
03     1
NaN   -1
dtype: int64}],
                                                               return_df=True,
                                                               verbose=0))),
                ('onehot_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['IDATE', 'IDAY', 'IYEAR'],
                                    transformer=OneHotEncoder(cols=['IDATE',
                                                                    'IDAY',
                                                                    'IYEAR'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False)
2025-11-27 21:35:33,817:INFO:Creating final display dataframe.
2025-11-27 21:35:34,009:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'SAFETIME' 'CTELNUM1' 'CELLFON5' 'CADULT1'
 'CELLSEX1' 'PVTRESD3' 'CCLGHOUS' 'CSTATE1' 'LANDLINE' 'HHADULT'
 'LASTDEN4' 'RMVTETH4' 'BLDSTFIT' 'SDNATES1' 'PDIABTS1' 'PREDIAB2'
 'DIABTYPE' 'INSULIN1' 'CHKHEMO3' 'EYEEXAM1' 'DIABEYE1' 'DIABEDU1'
 'FEETSORE' 'TOLDCFS' 'HAVECFS' 'WORKCFS' 'IMFVPLA3' 'HPVADVC4' 'HPVADSHT'
 'SHINGLE2' 'COVIDVA1' 'COVACGET' 'COVIDNU1' 'COVIDINT' 'COVIDFS1'
 'COVIDSE1' 'COPDCOGH' 'COPDFLEM' 'COPDBRTH' 'COPDBTST' 'COPDSMOK'
 'CNCRDIFF' 'CNCRAGE' 'CNCRTYP2' 'CSRVTRT3' 'CSRVDOC1' 'CSRVSUM'
 'CSRVRTRN' 'CSRVINST' 'CSRVINSR' 'CSRVDEIN' 'CSRVCLIN' 'CSRVPAIN'
 'CSRVCTL2' 'PSATEST1' 'PSATIME1' 'PCPSARS2' 'PSASUGST' 'PCSTALK1'
 'CIMEMLOS' 'CDHOUSE' 'CDASSIST' 'CDHELP' 'CDSOCIAL' 'CDDISCUS' 'CAREGIV1'
 'CRGVREL4' 'CRGVLNG1' 'CRGVHRS1' 'CRGVPRB3' 'CRGVALZD' 'CRGVPER1'
 'CRGVHOU1' 'CRGVEXPT' 'ACEDEPRS' 'ACEDRINK' 'ACEDRUGS' 'ACEPRISN'
 'ACEDIVRC' 'ACEPUNCH' 'ACEHURT1' 'ACESWEAR' 'ACETOUCH' 'ACETTHEM'
 'ACEHVSEX' 'ACEADSAF' 'ACEADNED' 'MARIJAN1' 'MARJSMOK' 'MARJEAT'
 'MARJVAPE' 'MARJDAB' 'MARJOTHR' 'USEMRJN4' 'LASTSMK2' 'STOPSMK2'
 'MENTCIGS' 'MENTECIG' 'HEATTBCO' 'ASBIALCH' 'ASBIDRNK' 'ASBIBING'
 'ASBIADVC' 'ASBIRDUC' 'FIREARM5' 'GUNLOAD' 'LOADULK2' 'RCSXBRTH'
 'CASTHNO2' 'BIRTHSEX' 'SOMALE' 'SOFEMALE' 'TRNSGNDR' 'HADSEX' 'PFPPRVN4'
 'TYPCNTR9' 'BRTHCNT4' 'WHEREGET' 'NOBCUSE8' 'BCPREFER' 'RRCLASS3'
 'RRCOGNT2' 'RRTREAT' 'RRATWRK2' 'RRHCARE4' 'RRPHYSM2' 'CAGEG']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-27 21:35:34,131:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'SAFETIME' 'CTELNUM1' 'CELLFON5' 'CADULT1'
 'CELLSEX1' 'PVTRESD3' 'CCLGHOUS' 'CSTATE1' 'LANDLINE' 'HHADULT'
 'LASTDEN4' 'RMVTETH4' 'BLDSTFIT' 'SDNATES1' 'PDIABTS1' 'PREDIAB2'
 'DIABTYPE' 'INSULIN1' 'CHKHEMO3' 'EYEEXAM1' 'DIABEYE1' 'DIABEDU1'
 'FEETSORE' 'TOLDCFS' 'HAVECFS' 'WORKCFS' 'IMFVPLA3' 'HPVADVC4' 'HPVADSHT'
 'SHINGLE2' 'COVIDVA1' 'COVACGET' 'COVIDNU1' 'COVIDINT' 'COVIDFS1'
 'COVIDSE1' 'COPDCOGH' 'COPDFLEM' 'COPDBRTH' 'COPDBTST' 'COPDSMOK'
 'CNCRDIFF' 'CNCRAGE' 'CNCRTYP2' 'CSRVTRT3' 'CSRVDOC1' 'CSRVSUM'
 'CSRVRTRN' 'CSRVINST' 'CSRVINSR' 'CSRVDEIN' 'CSRVCLIN' 'CSRVPAIN'
 'CSRVCTL2' 'PSATEST1' 'PSATIME1' 'PCPSARS2' 'PSASUGST' 'PCSTALK1'
 'CIMEMLOS' 'CDHOUSE' 'CDASSIST' 'CDHELP' 'CDSOCIAL' 'CDDISCUS' 'CAREGIV1'
 'CRGVREL4' 'CRGVLNG1' 'CRGVHRS1' 'CRGVPRB3' 'CRGVALZD' 'CRGVPER1'
 'CRGVHOU1' 'CRGVEXPT' 'ACEDEPRS' 'ACEDRINK' 'ACEDRUGS' 'ACEPRISN'
 'ACEDIVRC' 'ACEPUNCH' 'ACEHURT1' 'ACESWEAR' 'ACETOUCH' 'ACETTHEM'
 'ACEHVSEX' 'ACEADSAF' 'ACEADNED' 'MARIJAN1' 'MARJSMOK' 'MARJEAT'
 'MARJVAPE' 'MARJDAB' 'MARJOTHR' 'USEMRJN4' 'LASTSMK2' 'STOPSMK2'
 'MENTCIGS' 'MENTECIG' 'HEATTBCO' 'ASBIALCH' 'ASBIDRNK' 'ASBIBING'
 'ASBIADVC' 'ASBIRDUC' 'FIREARM5' 'GUNLOAD' 'LOADULK2' 'RCSXBRTH'
 'CASTHNO2' 'BIRTHSEX' 'SOMALE' 'SOFEMALE' 'TRNSGNDR' 'HADSEX' 'PFPPRVN4'
 'TYPCNTR9' 'BRTHCNT4' 'WHEREGET' 'NOBCUSE8' 'BCPREFER' 'RRCLASS3'
 'RRCOGNT2' 'RRTREAT' 'RRATWRK2' 'RRHCARE4' 'RRPHYSM2' 'CAGEG']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-27 21:35:34,254:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'SAFETIME' 'CTELNUM1' 'CELLFON5' 'CADULT1'
 'CELLSEX1' 'PVTRESD3' 'CCLGHOUS' 'CSTATE1' 'LANDLINE' 'HHADULT'
 'LASTDEN4' 'RMVTETH4' 'BLDSTFIT' 'SDNATES1' 'PDIABTS1' 'PREDIAB2'
 'DIABTYPE' 'INSULIN1' 'CHKHEMO3' 'EYEEXAM1' 'DIABEYE1' 'DIABEDU1'
 'FEETSORE' 'TOLDCFS' 'HAVECFS' 'WORKCFS' 'IMFVPLA3' 'HPVADVC4' 'HPVADSHT'
 'SHINGLE2' 'COVIDVA1' 'COVACGET' 'COVIDNU1' 'COVIDINT' 'COVIDFS1'
 'COVIDSE1' 'COPDCOGH' 'COPDFLEM' 'COPDBRTH' 'COPDBTST' 'COPDSMOK'
 'CNCRDIFF' 'CNCRAGE' 'CNCRTYP2' 'CSRVTRT3' 'CSRVDOC1' 'CSRVSUM'
 'CSRVRTRN' 'CSRVINST' 'CSRVINSR' 'CSRVDEIN' 'CSRVCLIN' 'CSRVPAIN'
 'CSRVCTL2' 'PSATEST1' 'PSATIME1' 'PCPSARS2' 'PSASUGST' 'PCSTALK1'
 'CIMEMLOS' 'CDHOUSE' 'CDASSIST' 'CDHELP' 'CDSOCIAL' 'CDDISCUS' 'CAREGIV1'
 'CRGVREL4' 'CRGVLNG1' 'CRGVHRS1' 'CRGVPRB3' 'CRGVALZD' 'CRGVPER1'
 'CRGVHOU1' 'CRGVEXPT' 'ACEDEPRS' 'ACEDRINK' 'ACEDRUGS' 'ACEPRISN'
 'ACEDIVRC' 'ACEPUNCH' 'ACEHURT1' 'ACESWEAR' 'ACETOUCH' 'ACETTHEM'
 'ACEHVSEX' 'ACEADSAF' 'ACEADNED' 'MARIJAN1' 'MARJSMOK' 'MARJEAT'
 'MARJVAPE' 'MARJDAB' 'MARJOTHR' 'USEMRJN4' 'LASTSMK2' 'STOPSMK2'
 'MENTCIGS' 'MENTECIG' 'HEATTBCO' 'ASBIALCH' 'ASBIDRNK' 'ASBIBING'
 'ASBIADVC' 'ASBIRDUC' 'FIREARM5' 'GUNLOAD' 'LOADULK2' 'RCSXBRTH'
 'CASTHNO2' 'BIRTHSEX' 'SOMALE' 'SOFEMALE' 'TRNSGNDR' 'HADSEX' 'PFPPRVN4'
 'TYPCNTR9' 'BRTHCNT4' 'WHEREGET' 'NOBCUSE8' 'BCPREFER' 'RRCLASS3'
 'RRCOGNT2' 'RRTREAT' 'RRATWRK2' 'RRHCARE4' 'RRPHYSM2' 'CAGEG']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-27 21:35:34,381:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'SAFETIME' 'CTELNUM1' 'CELLFON5' 'CADULT1'
 'CELLSEX1' 'PVTRESD3' 'CCLGHOUS' 'CSTATE1' 'LANDLINE' 'HHADULT'
 'LASTDEN4' 'RMVTETH4' 'BLDSTFIT' 'SDNATES1' 'PDIABTS1' 'PREDIAB2'
 'DIABTYPE' 'INSULIN1' 'CHKHEMO3' 'EYEEXAM1' 'DIABEYE1' 'DIABEDU1'
 'FEETSORE' 'TOLDCFS' 'HAVECFS' 'WORKCFS' 'IMFVPLA3' 'HPVADVC4' 'HPVADSHT'
 'SHINGLE2' 'COVIDVA1' 'COVACGET' 'COVIDNU1' 'COVIDINT' 'COVIDFS1'
 'COVIDSE1' 'COPDCOGH' 'COPDFLEM' 'COPDBRTH' 'COPDBTST' 'COPDSMOK'
 'CNCRDIFF' 'CNCRAGE' 'CNCRTYP2' 'CSRVTRT3' 'CSRVDOC1' 'CSRVSUM'
 'CSRVRTRN' 'CSRVINST' 'CSRVINSR' 'CSRVDEIN' 'CSRVCLIN' 'CSRVPAIN'
 'CSRVCTL2' 'PSATEST1' 'PSATIME1' 'PCPSARS2' 'PSASUGST' 'PCSTALK1'
 'CIMEMLOS' 'CDHOUSE' 'CDASSIST' 'CDHELP' 'CDSOCIAL' 'CDDISCUS' 'CAREGIV1'
 'CRGVREL4' 'CRGVLNG1' 'CRGVHRS1' 'CRGVPRB3' 'CRGVALZD' 'CRGVPER1'
 'CRGVHOU1' 'CRGVEXPT' 'ACEDEPRS' 'ACEDRINK' 'ACEDRUGS' 'ACEPRISN'
 'ACEDIVRC' 'ACEPUNCH' 'ACEHURT1' 'ACESWEAR' 'ACETOUCH' 'ACETTHEM'
 'ACEHVSEX' 'ACEADSAF' 'ACEADNED' 'MARIJAN1' 'MARJSMOK' 'MARJEAT'
 'MARJVAPE' 'MARJDAB' 'MARJOTHR' 'USEMRJN4' 'LASTSMK2' 'STOPSMK2'
 'MENTCIGS' 'MENTECIG' 'HEATTBCO' 'ASBIALCH' 'ASBIDRNK' 'ASBIBING'
 'ASBIADVC' 'ASBIRDUC' 'FIREARM5' 'GUNLOAD' 'LOADULK2' 'RCSXBRTH'
 'CASTHNO2' 'BIRTHSEX' 'SOMALE' 'SOFEMALE' 'TRNSGNDR' 'HADSEX' 'PFPPRVN4'
 'TYPCNTR9' 'BRTHCNT4' 'WHEREGET' 'NOBCUSE8' 'BCPREFER' 'RRCLASS3'
 'RRCOGNT2' 'RRTREAT' 'RRATWRK2' 'RRHCARE4' 'RRPHYSM2' 'CAGEG']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-27 21:35:34,432:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target          CVDINFR4
2                   Target type            Binary
3           Original data shape         (50, 327)
4        Transformed data shape         (50, 226)
5   Transformed train set shape         (35, 226)
6    Transformed test set shape         (15, 226)
7              Numeric features               322
8          Categorical features                 4
9      Rows with missing values            100.0%
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16               Fold Generator   StratifiedKFold
17                  Fold Number                10
18                     CPU Jobs                -1
19                      Use GPU             False
20               Log Experiment             False
21              Experiment Name  clf-default-name
22                          USI              b0f4
2025-11-27 21:35:34,475:INFO:Soft dependency imported: xgboost: 3.1.2
2025-11-27 21:35:34,475:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-27 21:35:34,516:INFO:Soft dependency imported: xgboost: 3.1.2
2025-11-27 21:35:34,517:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-27 21:35:34,518:INFO:setup() successfully completed in 1.31s...............
2025-11-27 21:35:34,518:INFO:Initializing compare_models()
2025-11-27 21:35:34,518:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024612C71C30>, include=['lr', 'dt'], fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000024612C71C30>, 'include': ['lr', 'dt'], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2025-11-27 21:35:34,518:INFO:Checking exceptions
2025-11-27 21:35:34,534:INFO:Preparing display monitor
2025-11-27 21:35:34,534:INFO:Initializing Logistic Regression
2025-11-27 21:35:34,534:INFO:Total runtime is 0.0 minutes
2025-11-27 21:35:34,534:INFO:SubProcess create_model() called ==================================
2025-11-27 21:35:34,534:INFO:Initializing create_model()
2025-11-27 21:35:34,534:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024612C71C30>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024612C71090>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-27 21:35:34,534:INFO:Checking exceptions
2025-11-27 21:35:34,534:INFO:Importing libraries
2025-11-27 21:35:34,534:INFO:Copying training dataset
2025-11-27 21:35:34,558:INFO:Defining folds
2025-11-27 21:35:34,558:INFO:Declaring metric variables
2025-11-27 21:35:34,558:INFO:Importing untrained model
2025-11-27 21:35:34,558:INFO:Logistic Regression Imported successfully
2025-11-27 21:35:34,558:INFO:Starting cross validation
2025-11-27 21:35:34,560:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-27 21:35:34,569:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\model_selection\_split.py:737: UserWarning: The least populated class in y has only 6 members, which is less than n_splits=10.
  warnings.warn(

2025-11-27 21:35:38,294:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-27 21:35:38,309:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-27 21:35:38,309:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-27 21:35:38,316:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-27 21:35:38,316:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-27 21:35:38,318:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-27 21:35:38,318:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-27 21:35:38,321:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-27 21:35:38,321:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-27 21:35:38,321:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-27 21:35:38,542:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'SAFETIME' 'CTELNUM1' 'CELLFON5' 'CADULT1'
 'CELLSEX1' 'PVTRESD3' 'CCLGHOUS' 'CSTATE1' 'LANDLINE' 'HHADULT'
 'LASTDEN4' 'RMVTETH4' 'LASTSIG4' 'BLDSTFIT' 'SDNATES1' 'PDIABTS1'
 'PREDIAB2' 'DIABTYPE' 'INSULIN1' 'CHKHEMO3' 'EYEEXAM1' 'DIABEYE1'
 'DIABEDU1' 'FEETSORE' 'TOLDCFS' 'HAVECFS' 'WORKCFS' 'IMFVPLA3' 'HPVADVC4'
 'HPVADSHT' 'SHINGLE2' 'COVIDVA1' 'COVACGET' 'COVIDNU1' 'COVIDINT'
 'COVIDFS1' 'COVIDSE1' 'COPDCOGH' 'COPDFLEM' 'COPDBRTH' 'COPDBTST'
 'COPDSMOK' 'CNCRDIFF' 'CNCRAGE' 'CNCRTYP2' 'CSRVTRT3' 'CSRVDOC1'
 'CSRVSUM' 'CSRVRTRN' 'CSRVINST' 'CSRVINSR' 'CSRVDEIN' 'CSRVCLIN'
 'CSRVPAIN' 'CSRVCTL2' 'PSATEST1' 'PSATIME1' 'PCPSARS2' 'PSASUGST'
 'PCSTALK1' 'CIMEMLOS' 'CDHOUSE' 'CDASSIST' 'CDHELP' 'CDSOCIAL' 'CDDISCUS'
 'CAREGIV1' 'CRGVREL4' 'CRGVLNG1' 'CRGVHRS1' 'CRGVPRB3' 'CRGVALZD'
 'CRGVPER1' 'CRGVHOU1' 'CRGVEXPT' 'ACEDEPRS' 'ACEDRINK' 'ACEDRUGS'
 'ACEPRISN' 'ACEDIVRC' 'ACEPUNCH' 'ACEHURT1' 'ACESWEAR' 'ACETOUCH'
 'ACETTHEM' 'ACEHVSEX' 'ACEADSAF' 'ACEADNED' 'MARIJAN1' 'MARJSMOK'
 'MARJEAT' 'MARJVAPE' 'MARJDAB' 'MARJOTHR' 'USEMRJN4' 'LASTSMK2'
 'STOPSMK2' 'MENTCIGS' 'MENTECIG' 'HEATTBCO' 'ASBIALCH' 'ASBIDRNK'
 'ASBIBING' 'ASBIADVC' 'ASBIRDUC' 'FIREARM5' 'GUNLOAD' 'LOADULK2'
 'RCSXBRTH' 'CASTHNO2' 'BIRTHSEX' 'SOMALE' 'SOFEMALE' 'TRNSGNDR' 'HADSEX'
 'PFPPRVN4' 'TYPCNTR9' 'BRTHCNT4' 'WHEREGET' 'NOBCUSE8' 'BCPREFER'
 'RRCLASS3' 'RRCOGNT2' 'RRTREAT' 'RRATWRK2' 'RRHCARE4' 'RRPHYSM2' 'CAGEG']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-27 21:35:38,544:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'SAFETIME' 'CTELNUM1' 'CELLFON5' 'CADULT1'
 'CELLSEX1' 'PVTRESD3' 'CCLGHOUS' 'CSTATE1' 'LANDLINE' 'HHADULT'
 'LASTDEN4' 'RMVTETH4' 'BLDSTFIT' 'SDNATES1' 'PDIABTS1' 'PREDIAB2'
 'DIABTYPE' 'INSULIN1' 'CHKHEMO3' 'EYEEXAM1' 'DIABEYE1' 'DIABEDU1'
 'FEETSORE' 'TOLDCFS' 'HAVECFS' 'WORKCFS' 'IMFVPLA3' 'HPVADVC4' 'HPVADSHT'
 'SHINGLE2' 'COVIDVA1' 'COVACGET' 'COVIDNU1' 'COVIDINT' 'COVIDFS1'
 'COVIDSE1' 'COPDCOGH' 'COPDFLEM' 'COPDBRTH' 'COPDBTST' 'COPDSMOK'
 'CNCRDIFF' 'CNCRAGE' 'CNCRTYP2' 'CSRVTRT3' 'CSRVDOC1' 'CSRVSUM'
 'CSRVRTRN' 'CSRVINST' 'CSRVINSR' 'CSRVDEIN' 'CSRVCLIN' 'CSRVPAIN'
 'CSRVCTL2' 'PSATEST1' 'PSATIME1' 'PCPSARS2' 'PSASUGST' 'PCSTALK1'
 'CIMEMLOS' 'CDHOUSE' 'CDASSIST' 'CDHELP' 'CDSOCIAL' 'CDDISCUS' 'CAREGIV1'
 'CRGVREL4' 'CRGVLNG1' 'CRGVHRS1' 'CRGVPRB3' 'CRGVALZD' 'CRGVPER1'
 'CRGVHOU1' 'CRGVEXPT' 'ACEDEPRS' 'ACEDRINK' 'ACEDRUGS' 'ACEPRISN'
 'ACEDIVRC' 'ACEPUNCH' 'ACEHURT1' 'ACESWEAR' 'ACETOUCH' 'ACETTHEM'
 'ACEHVSEX' 'ACEADSAF' 'ACEADNED' 'MARIJAN1' 'MARJSMOK' 'MARJEAT'
 'MARJVAPE' 'MARJDAB' 'MARJOTHR' 'USEMRJN4' 'LASTSMK2' 'STOPSMK2'
 'MENTCIGS' 'MENTECIG' 'HEATTBCO' 'ASBIALCH' 'ASBIDRNK' 'ASBIBING'
 'ASBIADVC' 'ASBIRDUC' 'FIREARM5' 'GUNLOAD' 'LOADULK2' 'RCSXBRTH'
 'CASTHNO2' 'BIRTHSEX' 'SOMALE' 'SOFEMALE' 'TRNSGNDR' 'HADSEX' 'PFPPRVN4'
 'TYPCNTR9' 'BRTHCNT4' 'WHEREGET' 'NOBCUSE8' 'BCPREFER' 'RRCLASS3'
 'RRCOGNT2' 'RRTREAT' 'RRATWRK2' 'RRHCARE4' 'RRPHYSM2' 'CAGEG']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-27 21:35:38,547:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'SAFETIME' 'CTELNUM1' 'CELLFON5' 'CADULT1'
 'CELLSEX1' 'PVTRESD3' 'CCLGHOUS' 'CSTATE1' 'LANDLINE' 'HHADULT'
 'LASTDEN4' 'RMVTETH4' 'BLDSTFIT' 'SDNATES1' 'PDIABTS1' 'PREDIAB2'
 'DIABTYPE' 'INSULIN1' 'CHKHEMO3' 'EYEEXAM1' 'DIABEYE1' 'DIABEDU1'
 'FEETSORE' 'TOLDCFS' 'HAVECFS' 'WORKCFS' 'IMFVPLA3' 'HPVADVC4' 'HPVADSHT'
 'SHINGLE2' 'COVIDVA1' 'COVACGET' 'COVIDNU1' 'COVIDINT' 'COVIDFS1'
 'COVIDSE1' 'COPDCOGH' 'COPDFLEM' 'COPDBRTH' 'COPDBTST' 'COPDSMOK'
 'CNCRDIFF' 'CNCRAGE' 'CNCRTYP2' 'CSRVTRT3' 'CSRVDOC1' 'CSRVSUM'
 'CSRVRTRN' 'CSRVINST' 'CSRVINSR' 'CSRVDEIN' 'CSRVCLIN' 'CSRVPAIN'
 'CSRVCTL2' 'PSATEST1' 'PSATIME1' 'PCPSARS2' 'PSASUGST' 'PCSTALK1'
 'CIMEMLOS' 'CDHOUSE' 'CDASSIST' 'CDHELP' 'CDSOCIAL' 'CDDISCUS' 'CAREGIV1'
 'CRGVREL4' 'CRGVLNG1' 'CRGVHRS1' 'CRGVPRB3' 'CRGVALZD' 'CRGVPER1'
 'CRGVHOU1' 'CRGVEXPT' 'ACEDEPRS' 'ACEDRINK' 'ACEDRUGS' 'ACEPRISN'
 'ACEDIVRC' 'ACEPUNCH' 'ACEHURT1' 'ACESWEAR' 'ACETOUCH' 'ACETTHEM'
 'ACEHVSEX' 'ACEADSAF' 'ACEADNED' 'MARIJAN1' 'MARJSMOK' 'MARJEAT'
 'MARJVAPE' 'MARJDAB' 'MARJOTHR' 'USEMRJN4' 'LASTSMK2' 'STOPSMK2'
 'MENTCIGS' 'MENTECIG' 'HEATTBCO' 'ASBIALCH' 'ASBIDRNK' 'ASBIBING'
 'ASBIADVC' 'ASBIRDUC' 'FIREARM5' 'GUNLOAD' 'LOADULK2' 'RCSXBRTH'
 'CASTHNO2' 'BIRTHSEX' 'SOMALE' 'SOFEMALE' 'TRNSGNDR' 'HADSEX' 'PFPPRVN4'
 'TYPCNTR9' 'BRTHCNT4' 'WHEREGET' 'NOBCUSE8' 'BCPREFER' 'RRCLASS3'
 'RRCOGNT2' 'RRTREAT' 'RRATWRK2' 'RRHCARE4' 'RRPHYSM2' 'CAGEG']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-27 21:35:38,547:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'SAFETIME' 'CTELNUM1' 'CELLFON5' 'CADULT1'
 'CELLSEX1' 'PVTRESD3' 'CCLGHOUS' 'CSTATE1' 'LANDLINE' 'HHADULT'
 'LASTDEN4' 'RMVTETH4' 'BLDSTFIT' 'SDNATES1' 'PDIABTS1' 'PREDIAB2'
 'DIABTYPE' 'INSULIN1' 'CHKHEMO3' 'EYEEXAM1' 'DIABEYE1' 'DIABEDU1'
 'FEETSORE' 'TOLDCFS' 'HAVECFS' 'WORKCFS' 'IMFVPLA3' 'HPVADVC4' 'HPVADSHT'
 'SHINGLE2' 'COVIDVA1' 'COVACGET' 'COVIDNU1' 'COVIDINT' 'COVIDFS1'
 'COVIDSE1' 'COPDCOGH' 'COPDFLEM' 'COPDBRTH' 'COPDBTST' 'COPDSMOK'
 'CNCRDIFF' 'CNCRAGE' 'CNCRTYP2' 'CSRVTRT3' 'CSRVDOC1' 'CSRVSUM'
 'CSRVRTRN' 'CSRVINST' 'CSRVINSR' 'CSRVDEIN' 'CSRVCLIN' 'CSRVPAIN'
 'CSRVCTL2' 'PSATEST1' 'PSATIME1' 'PCPSARS2' 'PSASUGST' 'PCSTALK1'
 'CIMEMLOS' 'CDHOUSE' 'CDASSIST' 'CDHELP' 'CDSOCIAL' 'CDDISCUS' 'CAREGIV1'
 'CRGVREL4' 'CRGVLNG1' 'CRGVHRS1' 'CRGVPRB3' 'CRGVALZD' 'CRGVPER1'
 'CRGVHOU1' 'CRGVEXPT' 'ACEDEPRS' 'ACEDRINK' 'ACEDRUGS' 'ACEPRISN'
 'ACEDIVRC' 'ACEPUNCH' 'ACEHURT1' 'ACESWEAR' 'ACETOUCH' 'ACETTHEM'
 'ACEHVSEX' 'ACEADSAF' 'ACEADNED' 'MARIJAN1' 'MARJSMOK' 'MARJEAT'
 'MARJVAPE' 'MARJDAB' 'MARJOTHR' 'USEMRJN4' 'LASTSMK2' 'STOPSMK2'
 'MENTCIGS' 'MENTECIG' 'HEATTBCO' 'ASBIALCH' 'ASBIDRNK' 'ASBIBING'
 'ASBIADVC' 'ASBIRDUC' 'FIREARM5' 'GUNLOAD' 'LOADULK2' 'RCSXBRTH'
 'CASTHNO2' 'BIRTHSEX' 'SOMALE' 'SOFEMALE' 'TRNSGNDR' 'HADSEX' 'PFPPRVN4'
 'TYPCNTR9' 'BRTHCNT4' 'WHEREGET' 'NOBCUSE8' 'BCPREFER' 'RRCLASS3'
 'RRCOGNT2' 'RRTREAT' 'RRATWRK2' 'RRHCARE4' 'RRPHYSM2' 'CAGEG']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-27 21:35:38,552:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'SAFETIME' 'CTELNUM1' 'CELLFON5' 'CADULT1'
 'CELLSEX1' 'PVTRESD3' 'CCLGHOUS' 'CSTATE1' 'LANDLINE' 'HHADULT'
 'LASTDEN4' 'RMVTETH4' 'BLDSTFIT' 'SDNATES1' 'PDIABTS1' 'PREDIAB2'
 'DIABTYPE' 'INSULIN1' 'CHKHEMO3' 'EYEEXAM1' 'DIABEYE1' 'DIABEDU1'
 'FEETSORE' 'TOLDCFS' 'HAVECFS' 'WORKCFS' 'IMFVPLA3' 'HPVADVC4' 'HPVADSHT'
 'SHINGLE2' 'COVIDVA1' 'COVACGET' 'COVIDNU1' 'COVIDINT' 'COVIDFS1'
 'COVIDSE1' 'COPDCOGH' 'COPDFLEM' 'COPDBRTH' 'COPDBTST' 'COPDSMOK'
 'CNCRDIFF' 'CNCRAGE' 'CNCRTYP2' 'CSRVTRT3' 'CSRVDOC1' 'CSRVSUM'
 'CSRVRTRN' 'CSRVINST' 'CSRVINSR' 'CSRVDEIN' 'CSRVCLIN' 'CSRVPAIN'
 'CSRVCTL2' 'PSATEST1' 'PSATIME1' 'PCPSARS2' 'PSASUGST' 'PCSTALK1'
 'CIMEMLOS' 'CDHOUSE' 'CDASSIST' 'CDHELP' 'CDSOCIAL' 'CDDISCUS' 'CAREGIV1'
 'CRGVREL4' 'CRGVLNG1' 'CRGVHRS1' 'CRGVPRB3' 'CRGVALZD' 'CRGVPER1'
 'CRGVHOU1' 'CRGVEXPT' 'ACEDEPRS' 'ACEDRINK' 'ACEDRUGS' 'ACEPRISN'
 'ACEDIVRC' 'ACEPUNCH' 'ACEHURT1' 'ACESWEAR' 'ACETOUCH' 'ACETTHEM'
 'ACEHVSEX' 'ACEADSAF' 'ACEADNED' 'MARIJAN1' 'MARJSMOK' 'MARJEAT'
 'MARJVAPE' 'MARJDAB' 'MARJOTHR' 'USEMRJN4' 'LASTSMK2' 'STOPSMK2'
 'MENTCIGS' 'MENTECIG' 'HEATTBCO' 'ASBIALCH' 'ASBIDRNK' 'ASBIBING'
 'ASBIADVC' 'ASBIRDUC' 'FIREARM5' 'GUNLOAD' 'LOADULK2' 'RCSXBRTH'
 'CASTHNO2' 'BIRTHSEX' 'SOMALE' 'SOFEMALE' 'TRNSGNDR' 'HADSEX' 'PFPPRVN4'
 'TYPCNTR9' 'BRTHCNT4' 'WHEREGET' 'NOBCUSE8' 'BCPREFER' 'RRCLASS3'
 'RRCOGNT2' 'RRTREAT' 'RRATWRK2' 'RRHCARE4' 'RRPHYSM2' 'CAGEG']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-27 21:35:38,554:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'SAFETIME' 'CTELNUM1' 'CELLFON5' 'CADULT1'
 'CELLSEX1' 'PVTRESD3' 'CCLGHOUS' 'CSTATE1' 'LANDLINE' 'HHADULT'
 'LASTDEN4' 'RMVTETH4' 'BLDSTFIT' 'SDNATES1' 'COVIDPRM' 'PDIABTS1'
 'PREDIAB2' 'DIABTYPE' 'INSULIN1' 'CHKHEMO3' 'EYEEXAM1' 'DIABEYE1'
 'DIABEDU1' 'FEETSORE' 'TOLDCFS' 'HAVECFS' 'WORKCFS' 'IMFVPLA3' 'HPVADVC4'
 'HPVADSHT' 'SHINGLE2' 'COVIDVA1' 'COVACGET' 'COVIDNU1' 'COVIDINT'
 'COVIDFS1' 'COVIDSE1' 'COPDCOGH' 'COPDFLEM' 'COPDBRTH' 'COPDBTST'
 'COPDSMOK' 'CNCRDIFF' 'CNCRAGE' 'CNCRTYP2' 'CSRVTRT3' 'CSRVDOC1'
 'CSRVSUM' 'CSRVRTRN' 'CSRVINST' 'CSRVINSR' 'CSRVDEIN' 'CSRVCLIN'
 'CSRVPAIN' 'CSRVCTL2' 'PSATEST1' 'PSATIME1' 'PCPSARS2' 'PSASUGST'
 'PCSTALK1' 'CIMEMLOS' 'CDHOUSE' 'CDASSIST' 'CDHELP' 'CDSOCIAL' 'CDDISCUS'
 'CAREGIV1' 'CRGVREL4' 'CRGVLNG1' 'CRGVHRS1' 'CRGVPRB3' 'CRGVALZD'
 'CRGVPER1' 'CRGVHOU1' 'CRGVEXPT' 'ACEDEPRS' 'ACEDRINK' 'ACEDRUGS'
 'ACEPRISN' 'ACEDIVRC' 'ACEPUNCH' 'ACEHURT1' 'ACESWEAR' 'ACETOUCH'
 'ACETTHEM' 'ACEHVSEX' 'ACEADSAF' 'ACEADNED' 'MARIJAN1' 'MARJSMOK'
 'MARJEAT' 'MARJVAPE' 'MARJDAB' 'MARJOTHR' 'USEMRJN4' 'LASTSMK2'
 'STOPSMK2' 'MENTCIGS' 'MENTECIG' 'HEATTBCO' 'ASBIALCH' 'ASBIDRNK'
 'ASBIBING' 'ASBIADVC' 'ASBIRDUC' 'FIREARM5' 'GUNLOAD' 'LOADULK2'
 'RCSXBRTH' 'CASTHNO2' 'BIRTHSEX' 'SOMALE' 'SOFEMALE' 'TRNSGNDR' 'HADSEX'
 'PFPPRVN4' 'TYPCNTR9' 'BRTHCNT4' 'WHEREGET' 'NOBCUSE8' 'BCPREFER'
 'RRCLASS3' 'RRCOGNT2' 'RRTREAT' 'RRATWRK2' 'RRHCARE4' 'RRPHYSM2' 'CAGEG']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-27 21:35:38,558:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'SAFETIME' 'CTELNUM1' 'CELLFON5' 'CADULT1'
 'CELLSEX1' 'PVTRESD3' 'CCLGHOUS' 'CSTATE1' 'LANDLINE' 'HHADULT'
 'LASTDEN4' 'RMVTETH4' 'BLDSTFIT' 'SDNATES1' 'PDIABTS1' 'PREDIAB2'
 'DIABTYPE' 'INSULIN1' 'CHKHEMO3' 'EYEEXAM1' 'DIABEYE1' 'DIABEDU1'
 'FEETSORE' 'TOLDCFS' 'HAVECFS' 'WORKCFS' 'IMFVPLA3' 'HPVADVC4' 'HPVADSHT'
 'SHINGLE2' 'COVIDVA1' 'COVACGET' 'COVIDNU1' 'COVIDINT' 'COVIDFS1'
 'COVIDSE1' 'COPDCOGH' 'COPDFLEM' 'COPDBRTH' 'COPDBTST' 'COPDSMOK'
 'CNCRDIFF' 'CNCRAGE' 'CNCRTYP2' 'CSRVTRT3' 'CSRVDOC1' 'CSRVSUM'
 'CSRVRTRN' 'CSRVINST' 'CSRVINSR' 'CSRVDEIN' 'CSRVCLIN' 'CSRVPAIN'
 'CSRVCTL2' 'PSATEST1' 'PSATIME1' 'PCPSARS2' 'PSASUGST' 'PCSTALK1'
 'CIMEMLOS' 'CDHOUSE' 'CDASSIST' 'CDHELP' 'CDSOCIAL' 'CDDISCUS' 'CAREGIV1'
 'CRGVREL4' 'CRGVLNG1' 'CRGVHRS1' 'CRGVPRB3' 'CRGVALZD' 'CRGVPER1'
 'CRGVHOU1' 'CRGVEXPT' 'ACEDEPRS' 'ACEDRINK' 'ACEDRUGS' 'ACEPRISN'
 'ACEDIVRC' 'ACEPUNCH' 'ACEHURT1' 'ACESWEAR' 'ACETOUCH' 'ACETTHEM'
 'ACEHVSEX' 'ACEADSAF' 'ACEADNED' 'MARIJAN1' 'MARJSMOK' 'MARJEAT'
 'MARJVAPE' 'MARJDAB' 'MARJOTHR' 'USEMRJN4' 'LASTSMK2' 'STOPSMK2'
 'MENTCIGS' 'MENTECIG' 'HEATTBCO' 'ASBIALCH' 'ASBIDRNK' 'ASBIBING'
 'ASBIADVC' 'ASBIRDUC' 'FIREARM5' 'GUNLOAD' 'LOADULK2' 'RCSGEND1'
 'RCSXBRTH' 'RCSRLTN2' 'CASTHDX2' 'CASTHNO2' 'BIRTHSEX' 'SOMALE'
 'SOFEMALE' 'TRNSGNDR' 'HADSEX' 'PFPPRVN4' 'TYPCNTR9' 'BRTHCNT4'
 'WHEREGET' 'NOBCUSE8' 'BCPREFER' 'RRCLASS3' 'RRCOGNT2' 'RRTREAT'
 'RRATWRK2' 'RRHCARE4' 'RRPHYSM2' 'CRACE2' 'CPRACE2' 'CAGEG' 'CLLCPWT']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-27 21:35:38,560:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'SAFETIME' 'CTELNUM1' 'CELLFON5' 'CADULT1'
 'CELLSEX1' 'PVTRESD3' 'CCLGHOUS' 'CSTATE1' 'LANDLINE' 'HHADULT'
 'LASTDEN4' 'RMVTETH4' 'VCLNTES2' 'BLDSTFIT' 'SDNATES1' 'PDIABTS1'
 'PREDIAB2' 'DIABTYPE' 'INSULIN1' 'CHKHEMO3' 'EYEEXAM1' 'DIABEYE1'
 'DIABEDU1' 'FEETSORE' 'TOLDCFS' 'HAVECFS' 'WORKCFS' 'IMFVPLA3' 'HPVADVC4'
 'HPVADSHT' 'SHINGLE2' 'COVIDVA1' 'COVACGET' 'COVIDNU1' 'COVIDINT'
 'COVIDFS1' 'COVIDSE1' 'COPDCOGH' 'COPDFLEM' 'COPDBRTH' 'COPDBTST'
 'COPDSMOK' 'CNCRDIFF' 'CNCRAGE' 'CNCRTYP2' 'CSRVTRT3' 'CSRVDOC1'
 'CSRVSUM' 'CSRVRTRN' 'CSRVINST' 'CSRVINSR' 'CSRVDEIN' 'CSRVCLIN'
 'CSRVPAIN' 'CSRVCTL2' 'PSATEST1' 'PSATIME1' 'PCPSARS2' 'PSASUGST'
 'PCSTALK1' 'CIMEMLOS' 'CDHOUSE' 'CDASSIST' 'CDHELP' 'CDSOCIAL' 'CDDISCUS'
 'CAREGIV1' 'CRGVREL4' 'CRGVLNG1' 'CRGVHRS1' 'CRGVPRB3' 'CRGVALZD'
 'CRGVPER1' 'CRGVHOU1' 'CRGVEXPT' 'ACEDEPRS' 'ACEDRINK' 'ACEDRUGS'
 'ACEPRISN' 'ACEDIVRC' 'ACEPUNCH' 'ACEHURT1' 'ACESWEAR' 'ACETOUCH'
 'ACETTHEM' 'ACEHVSEX' 'ACEADSAF' 'ACEADNED' 'MARIJAN1' 'MARJSMOK'
 'MARJEAT' 'MARJVAPE' 'MARJDAB' 'MARJOTHR' 'USEMRJN4' 'LASTSMK2'
 'STOPSMK2' 'MENTCIGS' 'MENTECIG' 'HEATTBCO' 'ASBIALCH' 'ASBIDRNK'
 'ASBIBING' 'ASBIADVC' 'ASBIRDUC' 'FIREARM5' 'GUNLOAD' 'LOADULK2'
 'RCSXBRTH' 'CASTHNO2' 'BIRTHSEX' 'SOMALE' 'SOFEMALE' 'TRNSGNDR' 'HADSEX'
 'PFPPRVN4' 'TYPCNTR9' 'BRTHCNT4' 'WHEREGET' 'NOBCUSE8' 'BCPREFER'
 'RRCLASS3' 'RRCOGNT2' 'RRTREAT' 'RRATWRK2' 'RRHCARE4' 'RRPHYSM2' 'CAGEG']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-27 21:35:38,567:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'SAFETIME' 'CTELNUM1' 'CELLFON5' 'CADULT1'
 'CELLSEX1' 'PVTRESD3' 'CCLGHOUS' 'CSTATE1' 'LANDLINE' 'HHADULT'
 'LASTDEN4' 'RMVTETH4' 'BLDSTFIT' 'SDNATES1' 'PDIABTS1' 'PREDIAB2'
 'DIABTYPE' 'INSULIN1' 'CHKHEMO3' 'EYEEXAM1' 'DIABEYE1' 'DIABEDU1'
 'FEETSORE' 'TOLDCFS' 'HAVECFS' 'WORKCFS' 'IMFVPLA3' 'HPVADVC4' 'HPVADSHT'
 'SHINGLE2' 'COVIDVA1' 'COVACGET' 'COVIDNU1' 'COVIDINT' 'COVIDFS1'
 'COVIDSE1' 'COPDCOGH' 'COPDFLEM' 'COPDBRTH' 'COPDBTST' 'COPDSMOK'
 'CNCRDIFF' 'CNCRAGE' 'CNCRTYP2' 'CSRVTRT3' 'CSRVDOC1' 'CSRVSUM'
 'CSRVRTRN' 'CSRVINST' 'CSRVINSR' 'CSRVDEIN' 'CSRVCLIN' 'CSRVPAIN'
 'CSRVCTL2' 'PSATEST1' 'PSATIME1' 'PCPSARS2' 'PSASUGST' 'PCSTALK1'
 'CIMEMLOS' 'CDHOUSE' 'CDASSIST' 'CDHELP' 'CDSOCIAL' 'CDDISCUS' 'CAREGIV1'
 'CRGVREL4' 'CRGVLNG1' 'CRGVHRS1' 'CRGVPRB3' 'CRGVALZD' 'CRGVPER1'
 'CRGVHOU1' 'CRGVEXPT' 'ACEDEPRS' 'ACEDRINK' 'ACEDRUGS' 'ACEPRISN'
 'ACEDIVRC' 'ACEPUNCH' 'ACEHURT1' 'ACESWEAR' 'ACETOUCH' 'ACETTHEM'
 'ACEHVSEX' 'ACEADSAF' 'ACEADNED' 'MARIJAN1' 'MARJSMOK' 'MARJEAT'
 'MARJVAPE' 'MARJDAB' 'MARJOTHR' 'USEMRJN4' 'LASTSMK2' 'STOPSMK2'
 'MENTCIGS' 'MENTECIG' 'HEATTBCO' 'ASBIALCH' 'ASBIDRNK' 'ASBIBING'
 'ASBIADVC' 'ASBIRDUC' 'FIREARM5' 'GUNLOAD' 'LOADULK2' 'RCSXBRTH'
 'CASTHNO2' 'BIRTHSEX' 'SOMALE' 'SOFEMALE' 'TRNSGNDR' 'HADSEX' 'PFPPRVN4'
 'TYPCNTR9' 'BRTHCNT4' 'WHEREGET' 'NOBCUSE8' 'BCPREFER' 'RRCLASS3'
 'RRCOGNT2' 'RRTREAT' 'RRATWRK2' 'RRHCARE4' 'RRPHYSM2' 'CAGEG']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-27 21:35:38,569:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'SAFETIME' 'CTELNUM1' 'CELLFON5' 'CADULT1'
 'CELLSEX1' 'PVTRESD3' 'CCLGHOUS' 'CSTATE1' 'LANDLINE' 'HHADULT'
 'LASTDEN4' 'RMVTETH4' 'NUMPHON4' 'BLDSTFIT' 'SDNATES1' 'PDIABTS1'
 'PREDIAB2' 'DIABTYPE' 'INSULIN1' 'CHKHEMO3' 'EYEEXAM1' 'DIABEYE1'
 'DIABEDU1' 'FEETSORE' 'TOLDCFS' 'HAVECFS' 'WORKCFS' 'IMFVPLA3' 'HPVADVC4'
 'HPVADSHT' 'SHINGLE2' 'COVIDVA1' 'COVACGET' 'COVIDNU1' 'COVIDINT'
 'COVIDFS1' 'COVIDSE1' 'COPDCOGH' 'COPDFLEM' 'COPDBRTH' 'COPDBTST'
 'COPDSMOK' 'CNCRDIFF' 'CNCRAGE' 'CNCRTYP2' 'CSRVTRT3' 'CSRVDOC1'
 'CSRVSUM' 'CSRVRTRN' 'CSRVINST' 'CSRVINSR' 'CSRVDEIN' 'CSRVCLIN'
 'CSRVPAIN' 'CSRVCTL2' 'PSATEST1' 'PSATIME1' 'PCPSARS2' 'PSASUGST'
 'PCSTALK1' 'CIMEMLOS' 'CDHOUSE' 'CDASSIST' 'CDHELP' 'CDSOCIAL' 'CDDISCUS'
 'CAREGIV1' 'CRGVREL4' 'CRGVLNG1' 'CRGVHRS1' 'CRGVPRB3' 'CRGVALZD'
 'CRGVPER1' 'CRGVHOU1' 'CRGVEXPT' 'ACEDEPRS' 'ACEDRINK' 'ACEDRUGS'
 'ACEPRISN' 'ACEDIVRC' 'ACEPUNCH' 'ACEHURT1' 'ACESWEAR' 'ACETOUCH'
 'ACETTHEM' 'ACEHVSEX' 'ACEADSAF' 'ACEADNED' 'MARIJAN1' 'MARJSMOK'
 'MARJEAT' 'MARJVAPE' 'MARJDAB' 'MARJOTHR' 'USEMRJN4' 'LASTSMK2'
 'STOPSMK2' 'MENTCIGS' 'MENTECIG' 'HEATTBCO' 'ASBIALCH' 'ASBIDRNK'
 'ASBIBING' 'ASBIADVC' 'ASBIRDUC' 'FIREARM5' 'GUNLOAD' 'LOADULK2'
 'RCSXBRTH' 'CASTHNO2' 'BIRTHSEX' 'SOMALE' 'SOFEMALE' 'TRNSGNDR' 'HADSEX'
 'PFPPRVN4' 'TYPCNTR9' 'BRTHCNT4' 'WHEREGET' 'NOBCUSE8' 'BCPREFER'
 'RRCLASS3' 'RRCOGNT2' 'RRTREAT' 'RRATWRK2' 'RRHCARE4' 'RRPHYSM2' 'CAGEG']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-27 21:35:38,654:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'SAFETIME' 'CTELNUM1' 'CELLFON5' 'CADULT1'
 'CELLSEX1' 'PVTRESD3' 'CCLGHOUS' 'CSTATE1' 'LANDLINE' 'HHADULT'
 'LASTDEN4' 'RMVTETH4' 'BLDSTFIT' 'SDNATES1' 'PDIABTS1' 'PREDIAB2'
 'DIABTYPE' 'INSULIN1' 'CHKHEMO3' 'EYEEXAM1' 'DIABEYE1' 'DIABEDU1'
 'FEETSORE' 'TOLDCFS' 'HAVECFS' 'WORKCFS' 'IMFVPLA3' 'HPVADVC4' 'HPVADSHT'
 'SHINGLE2' 'COVIDVA1' 'COVACGET' 'COVIDNU1' 'COVIDINT' 'COVIDFS1'
 'COVIDSE1' 'COPDCOGH' 'COPDFLEM' 'COPDBRTH' 'COPDBTST' 'COPDSMOK'
 'CNCRDIFF' 'CNCRAGE' 'CNCRTYP2' 'CSRVTRT3' 'CSRVDOC1' 'CSRVSUM'
 'CSRVRTRN' 'CSRVINST' 'CSRVINSR' 'CSRVDEIN' 'CSRVCLIN' 'CSRVPAIN'
 'CSRVCTL2' 'PSATEST1' 'PSATIME1' 'PCPSARS2' 'PSASUGST' 'PCSTALK1'
 'CIMEMLOS' 'CDHOUSE' 'CDASSIST' 'CDHELP' 'CDSOCIAL' 'CDDISCUS' 'CAREGIV1'
 'CRGVREL4' 'CRGVLNG1' 'CRGVHRS1' 'CRGVPRB3' 'CRGVALZD' 'CRGVPER1'
 'CRGVHOU1' 'CRGVEXPT' 'ACEDEPRS' 'ACEDRINK' 'ACEDRUGS' 'ACEPRISN'
 'ACEDIVRC' 'ACEPUNCH' 'ACEHURT1' 'ACESWEAR' 'ACETOUCH' 'ACETTHEM'
 'ACEHVSEX' 'ACEADSAF' 'ACEADNED' 'MARIJAN1' 'MARJSMOK' 'MARJEAT'
 'MARJVAPE' 'MARJDAB' 'MARJOTHR' 'USEMRJN4' 'LASTSMK2' 'STOPSMK2'
 'MENTCIGS' 'MENTECIG' 'HEATTBCO' 'ASBIALCH' 'ASBIDRNK' 'ASBIBING'
 'ASBIADVC' 'ASBIRDUC' 'FIREARM5' 'GUNLOAD' 'LOADULK2' 'RCSXBRTH'
 'CASTHNO2' 'BIRTHSEX' 'SOMALE' 'SOFEMALE' 'TRNSGNDR' 'HADSEX' 'PFPPRVN4'
 'TYPCNTR9' 'BRTHCNT4' 'WHEREGET' 'NOBCUSE8' 'BCPREFER' 'RRCLASS3'
 'RRCOGNT2' 'RRTREAT' 'RRATWRK2' 'RRHCARE4' 'RRPHYSM2' 'CAGEG']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-27 21:35:38,660:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'SAFETIME' 'CTELNUM1' 'CELLFON5' 'CADULT1'
 'CELLSEX1' 'PVTRESD3' 'CCLGHOUS' 'CSTATE1' 'LANDLINE' 'HHADULT'
 'LASTDEN4' 'RMVTETH4' 'BLDSTFIT' 'SDNATES1' 'PDIABTS1' 'PREDIAB2'
 'DIABTYPE' 'INSULIN1' 'CHKHEMO3' 'EYEEXAM1' 'DIABEYE1' 'DIABEDU1'
 'FEETSORE' 'TOLDCFS' 'HAVECFS' 'WORKCFS' 'IMFVPLA3' 'HPVADVC4' 'HPVADSHT'
 'SHINGLE2' 'COVIDVA1' 'COVACGET' 'COVIDNU1' 'COVIDINT' 'COVIDFS1'
 'COVIDSE1' 'COPDCOGH' 'COPDFLEM' 'COPDBRTH' 'COPDBTST' 'COPDSMOK'
 'CNCRDIFF' 'CNCRAGE' 'CNCRTYP2' 'CSRVTRT3' 'CSRVDOC1' 'CSRVSUM'
 'CSRVRTRN' 'CSRVINST' 'CSRVINSR' 'CSRVDEIN' 'CSRVCLIN' 'CSRVPAIN'
 'CSRVCTL2' 'PSATEST1' 'PSATIME1' 'PCPSARS2' 'PSASUGST' 'PCSTALK1'
 'CIMEMLOS' 'CDHOUSE' 'CDASSIST' 'CDHELP' 'CDSOCIAL' 'CDDISCUS' 'CAREGIV1'
 'CRGVREL4' 'CRGVLNG1' 'CRGVHRS1' 'CRGVPRB3' 'CRGVALZD' 'CRGVPER1'
 'CRGVHOU1' 'CRGVEXPT' 'ACEDEPRS' 'ACEDRINK' 'ACEDRUGS' 'ACEPRISN'
 'ACEDIVRC' 'ACEPUNCH' 'ACEHURT1' 'ACESWEAR' 'ACETOUCH' 'ACETTHEM'
 'ACEHVSEX' 'ACEADSAF' 'ACEADNED' 'MARIJAN1' 'MARJSMOK' 'MARJEAT'
 'MARJVAPE' 'MARJDAB' 'MARJOTHR' 'USEMRJN4' 'LASTSMK2' 'STOPSMK2'
 'MENTCIGS' 'MENTECIG' 'HEATTBCO' 'ASBIALCH' 'ASBIDRNK' 'ASBIBING'
 'ASBIADVC' 'ASBIRDUC' 'FIREARM5' 'GUNLOAD' 'LOADULK2' 'RCSGEND1'
 'RCSXBRTH' 'RCSRLTN2' 'CASTHDX2' 'CASTHNO2' 'BIRTHSEX' 'SOMALE'
 'SOFEMALE' 'TRNSGNDR' 'HADSEX' 'PFPPRVN4' 'TYPCNTR9' 'BRTHCNT4'
 'WHEREGET' 'NOBCUSE8' 'BCPREFER' 'RRCLASS3' 'RRCOGNT2' 'RRTREAT'
 'RRATWRK2' 'RRHCARE4' 'RRPHYSM2' 'CRACE2' 'CPRACE2' 'CAGEG' 'CLLCPWT']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-27 21:35:38,672:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'SAFETIME' 'CTELNUM1' 'CELLFON5' 'CADULT1'
 'CELLSEX1' 'PVTRESD3' 'CCLGHOUS' 'CSTATE1' 'LANDLINE' 'HHADULT'
 'LASTDEN4' 'RMVTETH4' 'BLDSTFIT' 'SDNATES1' 'PDIABTS1' 'PREDIAB2'
 'DIABTYPE' 'INSULIN1' 'CHKHEMO3' 'EYEEXAM1' 'DIABEYE1' 'DIABEDU1'
 'FEETSORE' 'TOLDCFS' 'HAVECFS' 'WORKCFS' 'IMFVPLA3' 'HPVADVC4' 'HPVADSHT'
 'SHINGLE2' 'COVIDVA1' 'COVACGET' 'COVIDNU1' 'COVIDINT' 'COVIDFS1'
 'COVIDSE1' 'COPDCOGH' 'COPDFLEM' 'COPDBRTH' 'COPDBTST' 'COPDSMOK'
 'CNCRDIFF' 'CNCRAGE' 'CNCRTYP2' 'CSRVTRT3' 'CSRVDOC1' 'CSRVSUM'
 'CSRVRTRN' 'CSRVINST' 'CSRVINSR' 'CSRVDEIN' 'CSRVCLIN' 'CSRVPAIN'
 'CSRVCTL2' 'PSATEST1' 'PSATIME1' 'PCPSARS2' 'PSASUGST' 'PCSTALK1'
 'CIMEMLOS' 'CDHOUSE' 'CDASSIST' 'CDHELP' 'CDSOCIAL' 'CDDISCUS' 'CAREGIV1'
 'CRGVREL4' 'CRGVLNG1' 'CRGVHRS1' 'CRGVPRB3' 'CRGVALZD' 'CRGVPER1'
 'CRGVHOU1' 'CRGVEXPT' 'ACEDEPRS' 'ACEDRINK' 'ACEDRUGS' 'ACEPRISN'
 'ACEDIVRC' 'ACEPUNCH' 'ACEHURT1' 'ACESWEAR' 'ACETOUCH' 'ACETTHEM'
 'ACEHVSEX' 'ACEADSAF' 'ACEADNED' 'MARIJAN1' 'MARJSMOK' 'MARJEAT'
 'MARJVAPE' 'MARJDAB' 'MARJOTHR' 'USEMRJN4' 'LASTSMK2' 'STOPSMK2'
 'MENTCIGS' 'MENTECIG' 'HEATTBCO' 'ASBIALCH' 'ASBIDRNK' 'ASBIBING'
 'ASBIADVC' 'ASBIRDUC' 'FIREARM5' 'GUNLOAD' 'LOADULK2' 'RCSXBRTH'
 'CASTHNO2' 'BIRTHSEX' 'SOMALE' 'SOFEMALE' 'TRNSGNDR' 'HADSEX' 'PFPPRVN4'
 'TYPCNTR9' 'BRTHCNT4' 'WHEREGET' 'NOBCUSE8' 'BCPREFER' 'RRCLASS3'
 'RRCOGNT2' 'RRTREAT' 'RRATWRK2' 'RRHCARE4' 'RRPHYSM2' 'CAGEG']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-27 21:35:38,672:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'SAFETIME' 'CTELNUM1' 'CELLFON5' 'CADULT1'
 'CELLSEX1' 'PVTRESD3' 'CCLGHOUS' 'CSTATE1' 'LANDLINE' 'HHADULT'
 'LASTDEN4' 'RMVTETH4' 'BLDSTFIT' 'SDNATES1' 'PDIABTS1' 'PREDIAB2'
 'DIABTYPE' 'INSULIN1' 'CHKHEMO3' 'EYEEXAM1' 'DIABEYE1' 'DIABEDU1'
 'FEETSORE' 'TOLDCFS' 'HAVECFS' 'WORKCFS' 'IMFVPLA3' 'HPVADVC4' 'HPVADSHT'
 'SHINGLE2' 'COVIDVA1' 'COVACGET' 'COVIDNU1' 'COVIDINT' 'COVIDFS1'
 'COVIDSE1' 'COPDCOGH' 'COPDFLEM' 'COPDBRTH' 'COPDBTST' 'COPDSMOK'
 'CNCRDIFF' 'CNCRAGE' 'CNCRTYP2' 'CSRVTRT3' 'CSRVDOC1' 'CSRVSUM'
 'CSRVRTRN' 'CSRVINST' 'CSRVINSR' 'CSRVDEIN' 'CSRVCLIN' 'CSRVPAIN'
 'CSRVCTL2' 'PSATEST1' 'PSATIME1' 'PCPSARS2' 'PSASUGST' 'PCSTALK1'
 'CIMEMLOS' 'CDHOUSE' 'CDASSIST' 'CDHELP' 'CDSOCIAL' 'CDDISCUS' 'CAREGIV1'
 'CRGVREL4' 'CRGVLNG1' 'CRGVHRS1' 'CRGVPRB3' 'CRGVALZD' 'CRGVPER1'
 'CRGVHOU1' 'CRGVEXPT' 'ACEDEPRS' 'ACEDRINK' 'ACEDRUGS' 'ACEPRISN'
 'ACEDIVRC' 'ACEPUNCH' 'ACEHURT1' 'ACESWEAR' 'ACETOUCH' 'ACETTHEM'
 'ACEHVSEX' 'ACEADSAF' 'ACEADNED' 'MARIJAN1' 'MARJSMOK' 'MARJEAT'
 'MARJVAPE' 'MARJDAB' 'MARJOTHR' 'USEMRJN4' 'LASTSMK2' 'STOPSMK2'
 'MENTCIGS' 'MENTECIG' 'HEATTBCO' 'ASBIALCH' 'ASBIDRNK' 'ASBIBING'
 'ASBIADVC' 'ASBIRDUC' 'FIREARM5' 'GUNLOAD' 'LOADULK2' 'RCSXBRTH'
 'CASTHNO2' 'BIRTHSEX' 'SOMALE' 'SOFEMALE' 'TRNSGNDR' 'HADSEX' 'PFPPRVN4'
 'TYPCNTR9' 'BRTHCNT4' 'WHEREGET' 'NOBCUSE8' 'BCPREFER' 'RRCLASS3'
 'RRCOGNT2' 'RRTREAT' 'RRATWRK2' 'RRHCARE4' 'RRPHYSM2' 'CAGEG']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-27 21:35:38,686:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'SAFETIME' 'CTELNUM1' 'CELLFON5' 'CADULT1'
 'CELLSEX1' 'PVTRESD3' 'CCLGHOUS' 'CSTATE1' 'LANDLINE' 'HHADULT'
 'LASTDEN4' 'RMVTETH4' 'NUMPHON4' 'BLDSTFIT' 'SDNATES1' 'PDIABTS1'
 'PREDIAB2' 'DIABTYPE' 'INSULIN1' 'CHKHEMO3' 'EYEEXAM1' 'DIABEYE1'
 'DIABEDU1' 'FEETSORE' 'TOLDCFS' 'HAVECFS' 'WORKCFS' 'IMFVPLA3' 'HPVADVC4'
 'HPVADSHT' 'SHINGLE2' 'COVIDVA1' 'COVACGET' 'COVIDNU1' 'COVIDINT'
 'COVIDFS1' 'COVIDSE1' 'COPDCOGH' 'COPDFLEM' 'COPDBRTH' 'COPDBTST'
 'COPDSMOK' 'CNCRDIFF' 'CNCRAGE' 'CNCRTYP2' 'CSRVTRT3' 'CSRVDOC1'
 'CSRVSUM' 'CSRVRTRN' 'CSRVINST' 'CSRVINSR' 'CSRVDEIN' 'CSRVCLIN'
 'CSRVPAIN' 'CSRVCTL2' 'PSATEST1' 'PSATIME1' 'PCPSARS2' 'PSASUGST'
 'PCSTALK1' 'CIMEMLOS' 'CDHOUSE' 'CDASSIST' 'CDHELP' 'CDSOCIAL' 'CDDISCUS'
 'CAREGIV1' 'CRGVREL4' 'CRGVLNG1' 'CRGVHRS1' 'CRGVPRB3' 'CRGVALZD'
 'CRGVPER1' 'CRGVHOU1' 'CRGVEXPT' 'ACEDEPRS' 'ACEDRINK' 'ACEDRUGS'
 'ACEPRISN' 'ACEDIVRC' 'ACEPUNCH' 'ACEHURT1' 'ACESWEAR' 'ACETOUCH'
 'ACETTHEM' 'ACEHVSEX' 'ACEADSAF' 'ACEADNED' 'MARIJAN1' 'MARJSMOK'
 'MARJEAT' 'MARJVAPE' 'MARJDAB' 'MARJOTHR' 'USEMRJN4' 'LASTSMK2'
 'STOPSMK2' 'MENTCIGS' 'MENTECIG' 'HEATTBCO' 'ASBIALCH' 'ASBIDRNK'
 'ASBIBING' 'ASBIADVC' 'ASBIRDUC' 'FIREARM5' 'GUNLOAD' 'LOADULK2'
 'RCSXBRTH' 'CASTHNO2' 'BIRTHSEX' 'SOMALE' 'SOFEMALE' 'TRNSGNDR' 'HADSEX'
 'PFPPRVN4' 'TYPCNTR9' 'BRTHCNT4' 'WHEREGET' 'NOBCUSE8' 'BCPREFER'
 'RRCLASS3' 'RRCOGNT2' 'RRTREAT' 'RRATWRK2' 'RRHCARE4' 'RRPHYSM2' 'CAGEG']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-27 21:35:38,686:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'SAFETIME' 'CTELNUM1' 'CELLFON5' 'CADULT1'
 'CELLSEX1' 'PVTRESD3' 'CCLGHOUS' 'CSTATE1' 'LANDLINE' 'HHADULT'
 'LASTDEN4' 'RMVTETH4' 'LASTSIG4' 'BLDSTFIT' 'SDNATES1' 'PDIABTS1'
 'PREDIAB2' 'DIABTYPE' 'INSULIN1' 'CHKHEMO3' 'EYEEXAM1' 'DIABEYE1'
 'DIABEDU1' 'FEETSORE' 'TOLDCFS' 'HAVECFS' 'WORKCFS' 'IMFVPLA3' 'HPVADVC4'
 'HPVADSHT' 'SHINGLE2' 'COVIDVA1' 'COVACGET' 'COVIDNU1' 'COVIDINT'
 'COVIDFS1' 'COVIDSE1' 'COPDCOGH' 'COPDFLEM' 'COPDBRTH' 'COPDBTST'
 'COPDSMOK' 'CNCRDIFF' 'CNCRAGE' 'CNCRTYP2' 'CSRVTRT3' 'CSRVDOC1'
 'CSRVSUM' 'CSRVRTRN' 'CSRVINST' 'CSRVINSR' 'CSRVDEIN' 'CSRVCLIN'
 'CSRVPAIN' 'CSRVCTL2' 'PSATEST1' 'PSATIME1' 'PCPSARS2' 'PSASUGST'
 'PCSTALK1' 'CIMEMLOS' 'CDHOUSE' 'CDASSIST' 'CDHELP' 'CDSOCIAL' 'CDDISCUS'
 'CAREGIV1' 'CRGVREL4' 'CRGVLNG1' 'CRGVHRS1' 'CRGVPRB3' 'CRGVALZD'
 'CRGVPER1' 'CRGVHOU1' 'CRGVEXPT' 'ACEDEPRS' 'ACEDRINK' 'ACEDRUGS'
 'ACEPRISN' 'ACEDIVRC' 'ACEPUNCH' 'ACEHURT1' 'ACESWEAR' 'ACETOUCH'
 'ACETTHEM' 'ACEHVSEX' 'ACEADSAF' 'ACEADNED' 'MARIJAN1' 'MARJSMOK'
 'MARJEAT' 'MARJVAPE' 'MARJDAB' 'MARJOTHR' 'USEMRJN4' 'LASTSMK2'
 'STOPSMK2' 'MENTCIGS' 'MENTECIG' 'HEATTBCO' 'ASBIALCH' 'ASBIDRNK'
 'ASBIBING' 'ASBIADVC' 'ASBIRDUC' 'FIREARM5' 'GUNLOAD' 'LOADULK2'
 'RCSXBRTH' 'CASTHNO2' 'BIRTHSEX' 'SOMALE' 'SOFEMALE' 'TRNSGNDR' 'HADSEX'
 'PFPPRVN4' 'TYPCNTR9' 'BRTHCNT4' 'WHEREGET' 'NOBCUSE8' 'BCPREFER'
 'RRCLASS3' 'RRCOGNT2' 'RRTREAT' 'RRATWRK2' 'RRHCARE4' 'RRPHYSM2' 'CAGEG']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-27 21:35:38,686:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-27 21:35:38,694:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'SAFETIME' 'CTELNUM1' 'CELLFON5' 'CADULT1'
 'CELLSEX1' 'PVTRESD3' 'CCLGHOUS' 'CSTATE1' 'LANDLINE' 'HHADULT'
 'LASTDEN4' 'RMVTETH4' 'BLDSTFIT' 'SDNATES1' 'COVIDPRM' 'PDIABTS1'
 'PREDIAB2' 'DIABTYPE' 'INSULIN1' 'CHKHEMO3' 'EYEEXAM1' 'DIABEYE1'
 'DIABEDU1' 'FEETSORE' 'TOLDCFS' 'HAVECFS' 'WORKCFS' 'IMFVPLA3' 'HPVADVC4'
 'HPVADSHT' 'SHINGLE2' 'COVIDVA1' 'COVACGET' 'COVIDNU1' 'COVIDINT'
 'COVIDFS1' 'COVIDSE1' 'COPDCOGH' 'COPDFLEM' 'COPDBRTH' 'COPDBTST'
 'COPDSMOK' 'CNCRDIFF' 'CNCRAGE' 'CNCRTYP2' 'CSRVTRT3' 'CSRVDOC1'
 'CSRVSUM' 'CSRVRTRN' 'CSRVINST' 'CSRVINSR' 'CSRVDEIN' 'CSRVCLIN'
 'CSRVPAIN' 'CSRVCTL2' 'PSATEST1' 'PSATIME1' 'PCPSARS2' 'PSASUGST'
 'PCSTALK1' 'CIMEMLOS' 'CDHOUSE' 'CDASSIST' 'CDHELP' 'CDSOCIAL' 'CDDISCUS'
 'CAREGIV1' 'CRGVREL4' 'CRGVLNG1' 'CRGVHRS1' 'CRGVPRB3' 'CRGVALZD'
 'CRGVPER1' 'CRGVHOU1' 'CRGVEXPT' 'ACEDEPRS' 'ACEDRINK' 'ACEDRUGS'
 'ACEPRISN' 'ACEDIVRC' 'ACEPUNCH' 'ACEHURT1' 'ACESWEAR' 'ACETOUCH'
 'ACETTHEM' 'ACEHVSEX' 'ACEADSAF' 'ACEADNED' 'MARIJAN1' 'MARJSMOK'
 'MARJEAT' 'MARJVAPE' 'MARJDAB' 'MARJOTHR' 'USEMRJN4' 'LASTSMK2'
 'STOPSMK2' 'MENTCIGS' 'MENTECIG' 'HEATTBCO' 'ASBIALCH' 'ASBIDRNK'
 'ASBIBING' 'ASBIADVC' 'ASBIRDUC' 'FIREARM5' 'GUNLOAD' 'LOADULK2'
 'RCSXBRTH' 'CASTHNO2' 'BIRTHSEX' 'SOMALE' 'SOFEMALE' 'TRNSGNDR' 'HADSEX'
 'PFPPRVN4' 'TYPCNTR9' 'BRTHCNT4' 'WHEREGET' 'NOBCUSE8' 'BCPREFER'
 'RRCLASS3' 'RRCOGNT2' 'RRTREAT' 'RRATWRK2' 'RRHCARE4' 'RRPHYSM2' 'CAGEG']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-27 21:35:38,699:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-27 21:35:38,703:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'SAFETIME' 'CTELNUM1' 'CELLFON5' 'CADULT1'
 'CELLSEX1' 'PVTRESD3' 'CCLGHOUS' 'CSTATE1' 'LANDLINE' 'HHADULT'
 'LASTDEN4' 'RMVTETH4' 'VCLNTES2' 'BLDSTFIT' 'SDNATES1' 'PDIABTS1'
 'PREDIAB2' 'DIABTYPE' 'INSULIN1' 'CHKHEMO3' 'EYEEXAM1' 'DIABEYE1'
 'DIABEDU1' 'FEETSORE' 'TOLDCFS' 'HAVECFS' 'WORKCFS' 'IMFVPLA3' 'HPVADVC4'
 'HPVADSHT' 'SHINGLE2' 'COVIDVA1' 'COVACGET' 'COVIDNU1' 'COVIDINT'
 'COVIDFS1' 'COVIDSE1' 'COPDCOGH' 'COPDFLEM' 'COPDBRTH' 'COPDBTST'
 'COPDSMOK' 'CNCRDIFF' 'CNCRAGE' 'CNCRTYP2' 'CSRVTRT3' 'CSRVDOC1'
 'CSRVSUM' 'CSRVRTRN' 'CSRVINST' 'CSRVINSR' 'CSRVDEIN' 'CSRVCLIN'
 'CSRVPAIN' 'CSRVCTL2' 'PSATEST1' 'PSATIME1' 'PCPSARS2' 'PSASUGST'
 'PCSTALK1' 'CIMEMLOS' 'CDHOUSE' 'CDASSIST' 'CDHELP' 'CDSOCIAL' 'CDDISCUS'
 'CAREGIV1' 'CRGVREL4' 'CRGVLNG1' 'CRGVHRS1' 'CRGVPRB3' 'CRGVALZD'
 'CRGVPER1' 'CRGVHOU1' 'CRGVEXPT' 'ACEDEPRS' 'ACEDRINK' 'ACEDRUGS'
 'ACEPRISN' 'ACEDIVRC' 'ACEPUNCH' 'ACEHURT1' 'ACESWEAR' 'ACETOUCH'
 'ACETTHEM' 'ACEHVSEX' 'ACEADSAF' 'ACEADNED' 'MARIJAN1' 'MARJSMOK'
 'MARJEAT' 'MARJVAPE' 'MARJDAB' 'MARJOTHR' 'USEMRJN4' 'LASTSMK2'
 'STOPSMK2' 'MENTCIGS' 'MENTECIG' 'HEATTBCO' 'ASBIALCH' 'ASBIDRNK'
 'ASBIBING' 'ASBIADVC' 'ASBIRDUC' 'FIREARM5' 'GUNLOAD' 'LOADULK2'
 'RCSXBRTH' 'CASTHNO2' 'BIRTHSEX' 'SOMALE' 'SOFEMALE' 'TRNSGNDR' 'HADSEX'
 'PFPPRVN4' 'TYPCNTR9' 'BRTHCNT4' 'WHEREGET' 'NOBCUSE8' 'BCPREFER'
 'RRCLASS3' 'RRCOGNT2' 'RRTREAT' 'RRATWRK2' 'RRHCARE4' 'RRPHYSM2' 'CAGEG']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-27 21:35:38,706:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'SAFETIME' 'CTELNUM1' 'CELLFON5' 'CADULT1'
 'CELLSEX1' 'PVTRESD3' 'CCLGHOUS' 'CSTATE1' 'LANDLINE' 'HHADULT'
 'LASTDEN4' 'RMVTETH4' 'BLDSTFIT' 'SDNATES1' 'PDIABTS1' 'PREDIAB2'
 'DIABTYPE' 'INSULIN1' 'CHKHEMO3' 'EYEEXAM1' 'DIABEYE1' 'DIABEDU1'
 'FEETSORE' 'TOLDCFS' 'HAVECFS' 'WORKCFS' 'IMFVPLA3' 'HPVADVC4' 'HPVADSHT'
 'SHINGLE2' 'COVIDVA1' 'COVACGET' 'COVIDNU1' 'COVIDINT' 'COVIDFS1'
 'COVIDSE1' 'COPDCOGH' 'COPDFLEM' 'COPDBRTH' 'COPDBTST' 'COPDSMOK'
 'CNCRDIFF' 'CNCRAGE' 'CNCRTYP2' 'CSRVTRT3' 'CSRVDOC1' 'CSRVSUM'
 'CSRVRTRN' 'CSRVINST' 'CSRVINSR' 'CSRVDEIN' 'CSRVCLIN' 'CSRVPAIN'
 'CSRVCTL2' 'PSATEST1' 'PSATIME1' 'PCPSARS2' 'PSASUGST' 'PCSTALK1'
 'CIMEMLOS' 'CDHOUSE' 'CDASSIST' 'CDHELP' 'CDSOCIAL' 'CDDISCUS' 'CAREGIV1'
 'CRGVREL4' 'CRGVLNG1' 'CRGVHRS1' 'CRGVPRB3' 'CRGVALZD' 'CRGVPER1'
 'CRGVHOU1' 'CRGVEXPT' 'ACEDEPRS' 'ACEDRINK' 'ACEDRUGS' 'ACEPRISN'
 'ACEDIVRC' 'ACEPUNCH' 'ACEHURT1' 'ACESWEAR' 'ACETOUCH' 'ACETTHEM'
 'ACEHVSEX' 'ACEADSAF' 'ACEADNED' 'MARIJAN1' 'MARJSMOK' 'MARJEAT'
 'MARJVAPE' 'MARJDAB' 'MARJOTHR' 'USEMRJN4' 'LASTSMK2' 'STOPSMK2'
 'MENTCIGS' 'MENTECIG' 'HEATTBCO' 'ASBIALCH' 'ASBIDRNK' 'ASBIBING'
 'ASBIADVC' 'ASBIRDUC' 'FIREARM5' 'GUNLOAD' 'LOADULK2' 'RCSXBRTH'
 'CASTHNO2' 'BIRTHSEX' 'SOMALE' 'SOFEMALE' 'TRNSGNDR' 'HADSEX' 'PFPPRVN4'
 'TYPCNTR9' 'BRTHCNT4' 'WHEREGET' 'NOBCUSE8' 'BCPREFER' 'RRCLASS3'
 'RRCOGNT2' 'RRTREAT' 'RRATWRK2' 'RRHCARE4' 'RRPHYSM2' 'CAGEG']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-27 21:35:38,708:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-11-27 21:35:38,710:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-11-27 21:35:38,713:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-11-27 21:35:38,713:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-27 21:35:38,723:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'SAFETIME' 'CTELNUM1' 'CELLFON5' 'CADULT1'
 'CELLSEX1' 'PVTRESD3' 'CCLGHOUS' 'CSTATE1' 'LANDLINE' 'HHADULT'
 'LASTDEN4' 'RMVTETH4' 'BLDSTFIT' 'SDNATES1' 'PDIABTS1' 'PREDIAB2'
 'DIABTYPE' 'INSULIN1' 'CHKHEMO3' 'EYEEXAM1' 'DIABEYE1' 'DIABEDU1'
 'FEETSORE' 'TOLDCFS' 'HAVECFS' 'WORKCFS' 'IMFVPLA3' 'HPVADVC4' 'HPVADSHT'
 'SHINGLE2' 'COVIDVA1' 'COVACGET' 'COVIDNU1' 'COVIDINT' 'COVIDFS1'
 'COVIDSE1' 'COPDCOGH' 'COPDFLEM' 'COPDBRTH' 'COPDBTST' 'COPDSMOK'
 'CNCRDIFF' 'CNCRAGE' 'CNCRTYP2' 'CSRVTRT3' 'CSRVDOC1' 'CSRVSUM'
 'CSRVRTRN' 'CSRVINST' 'CSRVINSR' 'CSRVDEIN' 'CSRVCLIN' 'CSRVPAIN'
 'CSRVCTL2' 'PSATEST1' 'PSATIME1' 'PCPSARS2' 'PSASUGST' 'PCSTALK1'
 'CIMEMLOS' 'CDHOUSE' 'CDASSIST' 'CDHELP' 'CDSOCIAL' 'CDDISCUS' 'CAREGIV1'
 'CRGVREL4' 'CRGVLNG1' 'CRGVHRS1' 'CRGVPRB3' 'CRGVALZD' 'CRGVPER1'
 'CRGVHOU1' 'CRGVEXPT' 'ACEDEPRS' 'ACEDRINK' 'ACEDRUGS' 'ACEPRISN'
 'ACEDIVRC' 'ACEPUNCH' 'ACEHURT1' 'ACESWEAR' 'ACETOUCH' 'ACETTHEM'
 'ACEHVSEX' 'ACEADSAF' 'ACEADNED' 'MARIJAN1' 'MARJSMOK' 'MARJEAT'
 'MARJVAPE' 'MARJDAB' 'MARJOTHR' 'USEMRJN4' 'LASTSMK2' 'STOPSMK2'
 'MENTCIGS' 'MENTECIG' 'HEATTBCO' 'ASBIALCH' 'ASBIDRNK' 'ASBIBING'
 'ASBIADVC' 'ASBIRDUC' 'FIREARM5' 'GUNLOAD' 'LOADULK2' 'RCSXBRTH'
 'CASTHNO2' 'BIRTHSEX' 'SOMALE' 'SOFEMALE' 'TRNSGNDR' 'HADSEX' 'PFPPRVN4'
 'TYPCNTR9' 'BRTHCNT4' 'WHEREGET' 'NOBCUSE8' 'BCPREFER' 'RRCLASS3'
 'RRCOGNT2' 'RRTREAT' 'RRATWRK2' 'RRHCARE4' 'RRPHYSM2' 'CAGEG']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-27 21:35:38,725:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-11-27 21:35:38,733:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-11-27 21:35:38,736:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-11-27 21:35:38,739:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-11-27 21:35:38,741:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-11-27 21:35:38,741:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-27 21:35:38,743:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-27 21:35:38,743:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-11-27 21:35:38,743:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-27 21:35:38,744:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-11-27 21:35:38,751:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-11-27 21:35:38,777:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-11-27 21:35:38,782:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-11-27 21:35:38,804:INFO:Calculating mean and std
2025-11-27 21:35:38,806:INFO:Creating metrics dataframe
2025-11-27 21:35:38,808:INFO:Uploading results into container
2025-11-27 21:35:38,808:INFO:Uploading model into container now
2025-11-27 21:35:38,809:INFO:_master_model_container: 1
2025-11-27 21:35:38,809:INFO:_display_container: 2
2025-11-27 21:35:38,809:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-11-27 21:35:38,809:INFO:create_model() successfully completed......................................
2025-11-27 21:35:38,919:INFO:SubProcess create_model() end ==================================
2025-11-27 21:35:38,919:INFO:Creating metrics dataframe
2025-11-27 21:35:38,919:INFO:Initializing Decision Tree Classifier
2025-11-27 21:35:38,919:INFO:Total runtime is 0.07307968934377035 minutes
2025-11-27 21:35:38,919:INFO:SubProcess create_model() called ==================================
2025-11-27 21:35:38,919:INFO:Initializing create_model()
2025-11-27 21:35:38,919:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024612C71C30>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024612C71090>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-27 21:35:38,919:INFO:Checking exceptions
2025-11-27 21:35:38,919:INFO:Importing libraries
2025-11-27 21:35:38,919:INFO:Copying training dataset
2025-11-27 21:35:38,941:INFO:Defining folds
2025-11-27 21:35:38,941:INFO:Declaring metric variables
2025-11-27 21:35:38,941:INFO:Importing untrained model
2025-11-27 21:35:38,941:INFO:Decision Tree Classifier Imported successfully
2025-11-27 21:35:38,941:INFO:Starting cross validation
2025-11-27 21:35:38,944:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-27 21:35:38,944:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\model_selection\_split.py:737: UserWarning: The least populated class in y has only 6 members, which is less than n_splits=10.
  warnings.warn(

2025-11-27 21:35:38,994:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'SAFETIME' 'CTELNUM1' 'CELLFON5' 'CADULT1'
 'CELLSEX1' 'PVTRESD3' 'CCLGHOUS' 'CSTATE1' 'LANDLINE' 'HHADULT'
 'LASTDEN4' 'RMVTETH4' 'BLDSTFIT' 'SDNATES1' 'PDIABTS1' 'PREDIAB2'
 'DIABTYPE' 'INSULIN1' 'CHKHEMO3' 'EYEEXAM1' 'DIABEYE1' 'DIABEDU1'
 'FEETSORE' 'TOLDCFS' 'HAVECFS' 'WORKCFS' 'IMFVPLA3' 'HPVADVC4' 'HPVADSHT'
 'SHINGLE2' 'COVIDVA1' 'COVACGET' 'COVIDNU1' 'COVIDINT' 'COVIDFS1'
 'COVIDSE1' 'COPDCOGH' 'COPDFLEM' 'COPDBRTH' 'COPDBTST' 'COPDSMOK'
 'CNCRDIFF' 'CNCRAGE' 'CNCRTYP2' 'CSRVTRT3' 'CSRVDOC1' 'CSRVSUM'
 'CSRVRTRN' 'CSRVINST' 'CSRVINSR' 'CSRVDEIN' 'CSRVCLIN' 'CSRVPAIN'
 'CSRVCTL2' 'PSATEST1' 'PSATIME1' 'PCPSARS2' 'PSASUGST' 'PCSTALK1'
 'CIMEMLOS' 'CDHOUSE' 'CDASSIST' 'CDHELP' 'CDSOCIAL' 'CDDISCUS' 'CAREGIV1'
 'CRGVREL4' 'CRGVLNG1' 'CRGVHRS1' 'CRGVPRB3' 'CRGVALZD' 'CRGVPER1'
 'CRGVHOU1' 'CRGVEXPT' 'ACEDEPRS' 'ACEDRINK' 'ACEDRUGS' 'ACEPRISN'
 'ACEDIVRC' 'ACEPUNCH' 'ACEHURT1' 'ACESWEAR' 'ACETOUCH' 'ACETTHEM'
 'ACEHVSEX' 'ACEADSAF' 'ACEADNED' 'MARIJAN1' 'MARJSMOK' 'MARJEAT'
 'MARJVAPE' 'MARJDAB' 'MARJOTHR' 'USEMRJN4' 'LASTSMK2' 'STOPSMK2'
 'MENTCIGS' 'MENTECIG' 'HEATTBCO' 'ASBIALCH' 'ASBIDRNK' 'ASBIBING'
 'ASBIADVC' 'ASBIRDUC' 'FIREARM5' 'GUNLOAD' 'LOADULK2' 'RCSXBRTH'
 'CASTHNO2' 'BIRTHSEX' 'SOMALE' 'SOFEMALE' 'TRNSGNDR' 'HADSEX' 'PFPPRVN4'
 'TYPCNTR9' 'BRTHCNT4' 'WHEREGET' 'NOBCUSE8' 'BCPREFER' 'RRCLASS3'
 'RRCOGNT2' 'RRTREAT' 'RRATWRK2' 'RRHCARE4' 'RRPHYSM2' 'CAGEG']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-27 21:35:39,004:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'SAFETIME' 'CTELNUM1' 'CELLFON5' 'CADULT1'
 'CELLSEX1' 'PVTRESD3' 'CCLGHOUS' 'CSTATE1' 'LANDLINE' 'HHADULT'
 'LASTDEN4' 'RMVTETH4' 'VCLNTES2' 'BLDSTFIT' 'SDNATES1' 'PDIABTS1'
 'PREDIAB2' 'DIABTYPE' 'INSULIN1' 'CHKHEMO3' 'EYEEXAM1' 'DIABEYE1'
 'DIABEDU1' 'FEETSORE' 'TOLDCFS' 'HAVECFS' 'WORKCFS' 'IMFVPLA3' 'HPVADVC4'
 'HPVADSHT' 'SHINGLE2' 'COVIDVA1' 'COVACGET' 'COVIDNU1' 'COVIDINT'
 'COVIDFS1' 'COVIDSE1' 'COPDCOGH' 'COPDFLEM' 'COPDBRTH' 'COPDBTST'
 'COPDSMOK' 'CNCRDIFF' 'CNCRAGE' 'CNCRTYP2' 'CSRVTRT3' 'CSRVDOC1'
 'CSRVSUM' 'CSRVRTRN' 'CSRVINST' 'CSRVINSR' 'CSRVDEIN' 'CSRVCLIN'
 'CSRVPAIN' 'CSRVCTL2' 'PSATEST1' 'PSATIME1' 'PCPSARS2' 'PSASUGST'
 'PCSTALK1' 'CIMEMLOS' 'CDHOUSE' 'CDASSIST' 'CDHELP' 'CDSOCIAL' 'CDDISCUS'
 'CAREGIV1' 'CRGVREL4' 'CRGVLNG1' 'CRGVHRS1' 'CRGVPRB3' 'CRGVALZD'
 'CRGVPER1' 'CRGVHOU1' 'CRGVEXPT' 'ACEDEPRS' 'ACEDRINK' 'ACEDRUGS'
 'ACEPRISN' 'ACEDIVRC' 'ACEPUNCH' 'ACEHURT1' 'ACESWEAR' 'ACETOUCH'
 'ACETTHEM' 'ACEHVSEX' 'ACEADSAF' 'ACEADNED' 'MARIJAN1' 'MARJSMOK'
 'MARJEAT' 'MARJVAPE' 'MARJDAB' 'MARJOTHR' 'USEMRJN4' 'LASTSMK2'
 'STOPSMK2' 'MENTCIGS' 'MENTECIG' 'HEATTBCO' 'ASBIALCH' 'ASBIDRNK'
 'ASBIBING' 'ASBIADVC' 'ASBIRDUC' 'FIREARM5' 'GUNLOAD' 'LOADULK2'
 'RCSXBRTH' 'CASTHNO2' 'BIRTHSEX' 'SOMALE' 'SOFEMALE' 'TRNSGNDR' 'HADSEX'
 'PFPPRVN4' 'TYPCNTR9' 'BRTHCNT4' 'WHEREGET' 'NOBCUSE8' 'BCPREFER'
 'RRCLASS3' 'RRCOGNT2' 'RRTREAT' 'RRATWRK2' 'RRHCARE4' 'RRPHYSM2' 'CAGEG']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-27 21:35:39,004:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'SAFETIME' 'CTELNUM1' 'CELLFON5' 'CADULT1'
 'CELLSEX1' 'PVTRESD3' 'CCLGHOUS' 'CSTATE1' 'LANDLINE' 'HHADULT'
 'LASTDEN4' 'RMVTETH4' 'BLDSTFIT' 'SDNATES1' 'PDIABTS1' 'PREDIAB2'
 'DIABTYPE' 'INSULIN1' 'CHKHEMO3' 'EYEEXAM1' 'DIABEYE1' 'DIABEDU1'
 'FEETSORE' 'TOLDCFS' 'HAVECFS' 'WORKCFS' 'IMFVPLA3' 'HPVADVC4' 'HPVADSHT'
 'SHINGLE2' 'COVIDVA1' 'COVACGET' 'COVIDNU1' 'COVIDINT' 'COVIDFS1'
 'COVIDSE1' 'COPDCOGH' 'COPDFLEM' 'COPDBRTH' 'COPDBTST' 'COPDSMOK'
 'CNCRDIFF' 'CNCRAGE' 'CNCRTYP2' 'CSRVTRT3' 'CSRVDOC1' 'CSRVSUM'
 'CSRVRTRN' 'CSRVINST' 'CSRVINSR' 'CSRVDEIN' 'CSRVCLIN' 'CSRVPAIN'
 'CSRVCTL2' 'PSATEST1' 'PSATIME1' 'PCPSARS2' 'PSASUGST' 'PCSTALK1'
 'CIMEMLOS' 'CDHOUSE' 'CDASSIST' 'CDHELP' 'CDSOCIAL' 'CDDISCUS' 'CAREGIV1'
 'CRGVREL4' 'CRGVLNG1' 'CRGVHRS1' 'CRGVPRB3' 'CRGVALZD' 'CRGVPER1'
 'CRGVHOU1' 'CRGVEXPT' 'ACEDEPRS' 'ACEDRINK' 'ACEDRUGS' 'ACEPRISN'
 'ACEDIVRC' 'ACEPUNCH' 'ACEHURT1' 'ACESWEAR' 'ACETOUCH' 'ACETTHEM'
 'ACEHVSEX' 'ACEADSAF' 'ACEADNED' 'MARIJAN1' 'MARJSMOK' 'MARJEAT'
 'MARJVAPE' 'MARJDAB' 'MARJOTHR' 'USEMRJN4' 'LASTSMK2' 'STOPSMK2'
 'MENTCIGS' 'MENTECIG' 'HEATTBCO' 'ASBIALCH' 'ASBIDRNK' 'ASBIBING'
 'ASBIADVC' 'ASBIRDUC' 'FIREARM5' 'GUNLOAD' 'LOADULK2' 'RCSXBRTH'
 'CASTHNO2' 'BIRTHSEX' 'SOMALE' 'SOFEMALE' 'TRNSGNDR' 'HADSEX' 'PFPPRVN4'
 'TYPCNTR9' 'BRTHCNT4' 'WHEREGET' 'NOBCUSE8' 'BCPREFER' 'RRCLASS3'
 'RRCOGNT2' 'RRTREAT' 'RRATWRK2' 'RRHCARE4' 'RRPHYSM2' 'CAGEG']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-27 21:35:39,020:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'SAFETIME' 'CTELNUM1' 'CELLFON5' 'CADULT1'
 'CELLSEX1' 'PVTRESD3' 'CCLGHOUS' 'CSTATE1' 'LANDLINE' 'HHADULT'
 'LASTDEN4' 'RMVTETH4' 'BLDSTFIT' 'SDNATES1' 'PDIABTS1' 'PREDIAB2'
 'DIABTYPE' 'INSULIN1' 'CHKHEMO3' 'EYEEXAM1' 'DIABEYE1' 'DIABEDU1'
 'FEETSORE' 'TOLDCFS' 'HAVECFS' 'WORKCFS' 'IMFVPLA3' 'HPVADVC4' 'HPVADSHT'
 'SHINGLE2' 'COVIDVA1' 'COVACGET' 'COVIDNU1' 'COVIDINT' 'COVIDFS1'
 'COVIDSE1' 'COPDCOGH' 'COPDFLEM' 'COPDBRTH' 'COPDBTST' 'COPDSMOK'
 'CNCRDIFF' 'CNCRAGE' 'CNCRTYP2' 'CSRVTRT3' 'CSRVDOC1' 'CSRVSUM'
 'CSRVRTRN' 'CSRVINST' 'CSRVINSR' 'CSRVDEIN' 'CSRVCLIN' 'CSRVPAIN'
 'CSRVCTL2' 'PSATEST1' 'PSATIME1' 'PCPSARS2' 'PSASUGST' 'PCSTALK1'
 'CIMEMLOS' 'CDHOUSE' 'CDASSIST' 'CDHELP' 'CDSOCIAL' 'CDDISCUS' 'CAREGIV1'
 'CRGVREL4' 'CRGVLNG1' 'CRGVHRS1' 'CRGVPRB3' 'CRGVALZD' 'CRGVPER1'
 'CRGVHOU1' 'CRGVEXPT' 'ACEDEPRS' 'ACEDRINK' 'ACEDRUGS' 'ACEPRISN'
 'ACEDIVRC' 'ACEPUNCH' 'ACEHURT1' 'ACESWEAR' 'ACETOUCH' 'ACETTHEM'
 'ACEHVSEX' 'ACEADSAF' 'ACEADNED' 'MARIJAN1' 'MARJSMOK' 'MARJEAT'
 'MARJVAPE' 'MARJDAB' 'MARJOTHR' 'USEMRJN4' 'LASTSMK2' 'STOPSMK2'
 'MENTCIGS' 'MENTECIG' 'HEATTBCO' 'ASBIALCH' 'ASBIDRNK' 'ASBIBING'
 'ASBIADVC' 'ASBIRDUC' 'FIREARM5' 'GUNLOAD' 'LOADULK2' 'RCSXBRTH'
 'CASTHNO2' 'BIRTHSEX' 'SOMALE' 'SOFEMALE' 'TRNSGNDR' 'HADSEX' 'PFPPRVN4'
 'TYPCNTR9' 'BRTHCNT4' 'WHEREGET' 'NOBCUSE8' 'BCPREFER' 'RRCLASS3'
 'RRCOGNT2' 'RRTREAT' 'RRATWRK2' 'RRHCARE4' 'RRPHYSM2' 'CAGEG']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-27 21:35:39,025:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'SAFETIME' 'CTELNUM1' 'CELLFON5' 'CADULT1'
 'CELLSEX1' 'PVTRESD3' 'CCLGHOUS' 'CSTATE1' 'LANDLINE' 'HHADULT'
 'LASTDEN4' 'RMVTETH4' 'NUMPHON4' 'BLDSTFIT' 'SDNATES1' 'PDIABTS1'
 'PREDIAB2' 'DIABTYPE' 'INSULIN1' 'CHKHEMO3' 'EYEEXAM1' 'DIABEYE1'
 'DIABEDU1' 'FEETSORE' 'TOLDCFS' 'HAVECFS' 'WORKCFS' 'IMFVPLA3' 'HPVADVC4'
 'HPVADSHT' 'SHINGLE2' 'COVIDVA1' 'COVACGET' 'COVIDNU1' 'COVIDINT'
 'COVIDFS1' 'COVIDSE1' 'COPDCOGH' 'COPDFLEM' 'COPDBRTH' 'COPDBTST'
 'COPDSMOK' 'CNCRDIFF' 'CNCRAGE' 'CNCRTYP2' 'CSRVTRT3' 'CSRVDOC1'
 'CSRVSUM' 'CSRVRTRN' 'CSRVINST' 'CSRVINSR' 'CSRVDEIN' 'CSRVCLIN'
 'CSRVPAIN' 'CSRVCTL2' 'PSATEST1' 'PSATIME1' 'PCPSARS2' 'PSASUGST'
 'PCSTALK1' 'CIMEMLOS' 'CDHOUSE' 'CDASSIST' 'CDHELP' 'CDSOCIAL' 'CDDISCUS'
 'CAREGIV1' 'CRGVREL4' 'CRGVLNG1' 'CRGVHRS1' 'CRGVPRB3' 'CRGVALZD'
 'CRGVPER1' 'CRGVHOU1' 'CRGVEXPT' 'ACEDEPRS' 'ACEDRINK' 'ACEDRUGS'
 'ACEPRISN' 'ACEDIVRC' 'ACEPUNCH' 'ACEHURT1' 'ACESWEAR' 'ACETOUCH'
 'ACETTHEM' 'ACEHVSEX' 'ACEADSAF' 'ACEADNED' 'MARIJAN1' 'MARJSMOK'
 'MARJEAT' 'MARJVAPE' 'MARJDAB' 'MARJOTHR' 'USEMRJN4' 'LASTSMK2'
 'STOPSMK2' 'MENTCIGS' 'MENTECIG' 'HEATTBCO' 'ASBIALCH' 'ASBIDRNK'
 'ASBIBING' 'ASBIADVC' 'ASBIRDUC' 'FIREARM5' 'GUNLOAD' 'LOADULK2'
 'RCSXBRTH' 'CASTHNO2' 'BIRTHSEX' 'SOMALE' 'SOFEMALE' 'TRNSGNDR' 'HADSEX'
 'PFPPRVN4' 'TYPCNTR9' 'BRTHCNT4' 'WHEREGET' 'NOBCUSE8' 'BCPREFER'
 'RRCLASS3' 'RRCOGNT2' 'RRTREAT' 'RRATWRK2' 'RRHCARE4' 'RRPHYSM2' 'CAGEG']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-27 21:35:39,036:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'SAFETIME' 'CTELNUM1' 'CELLFON5' 'CADULT1'
 'CELLSEX1' 'PVTRESD3' 'CCLGHOUS' 'CSTATE1' 'LANDLINE' 'HHADULT'
 'LASTDEN4' 'RMVTETH4' 'BLDSTFIT' 'SDNATES1' 'PDIABTS1' 'PREDIAB2'
 'DIABTYPE' 'INSULIN1' 'CHKHEMO3' 'EYEEXAM1' 'DIABEYE1' 'DIABEDU1'
 'FEETSORE' 'TOLDCFS' 'HAVECFS' 'WORKCFS' 'IMFVPLA3' 'HPVADVC4' 'HPVADSHT'
 'SHINGLE2' 'COVIDVA1' 'COVACGET' 'COVIDNU1' 'COVIDINT' 'COVIDFS1'
 'COVIDSE1' 'COPDCOGH' 'COPDFLEM' 'COPDBRTH' 'COPDBTST' 'COPDSMOK'
 'CNCRDIFF' 'CNCRAGE' 'CNCRTYP2' 'CSRVTRT3' 'CSRVDOC1' 'CSRVSUM'
 'CSRVRTRN' 'CSRVINST' 'CSRVINSR' 'CSRVDEIN' 'CSRVCLIN' 'CSRVPAIN'
 'CSRVCTL2' 'PSATEST1' 'PSATIME1' 'PCPSARS2' 'PSASUGST' 'PCSTALK1'
 'CIMEMLOS' 'CDHOUSE' 'CDASSIST' 'CDHELP' 'CDSOCIAL' 'CDDISCUS' 'CAREGIV1'
 'CRGVREL4' 'CRGVLNG1' 'CRGVHRS1' 'CRGVPRB3' 'CRGVALZD' 'CRGVPER1'
 'CRGVHOU1' 'CRGVEXPT' 'ACEDEPRS' 'ACEDRINK' 'ACEDRUGS' 'ACEPRISN'
 'ACEDIVRC' 'ACEPUNCH' 'ACEHURT1' 'ACESWEAR' 'ACETOUCH' 'ACETTHEM'
 'ACEHVSEX' 'ACEADSAF' 'ACEADNED' 'MARIJAN1' 'MARJSMOK' 'MARJEAT'
 'MARJVAPE' 'MARJDAB' 'MARJOTHR' 'USEMRJN4' 'LASTSMK2' 'STOPSMK2'
 'MENTCIGS' 'MENTECIG' 'HEATTBCO' 'ASBIALCH' 'ASBIDRNK' 'ASBIBING'
 'ASBIADVC' 'ASBIRDUC' 'FIREARM5' 'GUNLOAD' 'LOADULK2' 'RCSXBRTH'
 'CASTHNO2' 'BIRTHSEX' 'SOMALE' 'SOFEMALE' 'TRNSGNDR' 'HADSEX' 'PFPPRVN4'
 'TYPCNTR9' 'BRTHCNT4' 'WHEREGET' 'NOBCUSE8' 'BCPREFER' 'RRCLASS3'
 'RRCOGNT2' 'RRTREAT' 'RRATWRK2' 'RRHCARE4' 'RRPHYSM2' 'CAGEG']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-27 21:35:39,042:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'SAFETIME' 'CTELNUM1' 'CELLFON5' 'CADULT1'
 'CELLSEX1' 'PVTRESD3' 'CCLGHOUS' 'CSTATE1' 'LANDLINE' 'HHADULT'
 'LASTDEN4' 'RMVTETH4' 'LASTSIG4' 'BLDSTFIT' 'SDNATES1' 'PDIABTS1'
 'PREDIAB2' 'DIABTYPE' 'INSULIN1' 'CHKHEMO3' 'EYEEXAM1' 'DIABEYE1'
 'DIABEDU1' 'FEETSORE' 'TOLDCFS' 'HAVECFS' 'WORKCFS' 'IMFVPLA3' 'HPVADVC4'
 'HPVADSHT' 'SHINGLE2' 'COVIDVA1' 'COVACGET' 'COVIDNU1' 'COVIDINT'
 'COVIDFS1' 'COVIDSE1' 'COPDCOGH' 'COPDFLEM' 'COPDBRTH' 'COPDBTST'
 'COPDSMOK' 'CNCRDIFF' 'CNCRAGE' 'CNCRTYP2' 'CSRVTRT3' 'CSRVDOC1'
 'CSRVSUM' 'CSRVRTRN' 'CSRVINST' 'CSRVINSR' 'CSRVDEIN' 'CSRVCLIN'
 'CSRVPAIN' 'CSRVCTL2' 'PSATEST1' 'PSATIME1' 'PCPSARS2' 'PSASUGST'
 'PCSTALK1' 'CIMEMLOS' 'CDHOUSE' 'CDASSIST' 'CDHELP' 'CDSOCIAL' 'CDDISCUS'
 'CAREGIV1' 'CRGVREL4' 'CRGVLNG1' 'CRGVHRS1' 'CRGVPRB3' 'CRGVALZD'
 'CRGVPER1' 'CRGVHOU1' 'CRGVEXPT' 'ACEDEPRS' 'ACEDRINK' 'ACEDRUGS'
 'ACEPRISN' 'ACEDIVRC' 'ACEPUNCH' 'ACEHURT1' 'ACESWEAR' 'ACETOUCH'
 'ACETTHEM' 'ACEHVSEX' 'ACEADSAF' 'ACEADNED' 'MARIJAN1' 'MARJSMOK'
 'MARJEAT' 'MARJVAPE' 'MARJDAB' 'MARJOTHR' 'USEMRJN4' 'LASTSMK2'
 'STOPSMK2' 'MENTCIGS' 'MENTECIG' 'HEATTBCO' 'ASBIALCH' 'ASBIDRNK'
 'ASBIBING' 'ASBIADVC' 'ASBIRDUC' 'FIREARM5' 'GUNLOAD' 'LOADULK2'
 'RCSXBRTH' 'CASTHNO2' 'BIRTHSEX' 'SOMALE' 'SOFEMALE' 'TRNSGNDR' 'HADSEX'
 'PFPPRVN4' 'TYPCNTR9' 'BRTHCNT4' 'WHEREGET' 'NOBCUSE8' 'BCPREFER'
 'RRCLASS3' 'RRCOGNT2' 'RRTREAT' 'RRATWRK2' 'RRHCARE4' 'RRPHYSM2' 'CAGEG']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-27 21:35:39,052:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'SAFETIME' 'CTELNUM1' 'CELLFON5' 'CADULT1'
 'CELLSEX1' 'PVTRESD3' 'CCLGHOUS' 'CSTATE1' 'LANDLINE' 'HHADULT'
 'LASTDEN4' 'RMVTETH4' 'BLDSTFIT' 'SDNATES1' 'PDIABTS1' 'PREDIAB2'
 'DIABTYPE' 'INSULIN1' 'CHKHEMO3' 'EYEEXAM1' 'DIABEYE1' 'DIABEDU1'
 'FEETSORE' 'TOLDCFS' 'HAVECFS' 'WORKCFS' 'IMFVPLA3' 'HPVADVC4' 'HPVADSHT'
 'SHINGLE2' 'COVIDVA1' 'COVACGET' 'COVIDNU1' 'COVIDINT' 'COVIDFS1'
 'COVIDSE1' 'COPDCOGH' 'COPDFLEM' 'COPDBRTH' 'COPDBTST' 'COPDSMOK'
 'CNCRDIFF' 'CNCRAGE' 'CNCRTYP2' 'CSRVTRT3' 'CSRVDOC1' 'CSRVSUM'
 'CSRVRTRN' 'CSRVINST' 'CSRVINSR' 'CSRVDEIN' 'CSRVCLIN' 'CSRVPAIN'
 'CSRVCTL2' 'PSATEST1' 'PSATIME1' 'PCPSARS2' 'PSASUGST' 'PCSTALK1'
 'CIMEMLOS' 'CDHOUSE' 'CDASSIST' 'CDHELP' 'CDSOCIAL' 'CDDISCUS' 'CAREGIV1'
 'CRGVREL4' 'CRGVLNG1' 'CRGVHRS1' 'CRGVPRB3' 'CRGVALZD' 'CRGVPER1'
 'CRGVHOU1' 'CRGVEXPT' 'ACEDEPRS' 'ACEDRINK' 'ACEDRUGS' 'ACEPRISN'
 'ACEDIVRC' 'ACEPUNCH' 'ACEHURT1' 'ACESWEAR' 'ACETOUCH' 'ACETTHEM'
 'ACEHVSEX' 'ACEADSAF' 'ACEADNED' 'MARIJAN1' 'MARJSMOK' 'MARJEAT'
 'MARJVAPE' 'MARJDAB' 'MARJOTHR' 'USEMRJN4' 'LASTSMK2' 'STOPSMK2'
 'MENTCIGS' 'MENTECIG' 'HEATTBCO' 'ASBIALCH' 'ASBIDRNK' 'ASBIBING'
 'ASBIADVC' 'ASBIRDUC' 'FIREARM5' 'GUNLOAD' 'LOADULK2' 'RCSGEND1'
 'RCSXBRTH' 'RCSRLTN2' 'CASTHDX2' 'CASTHNO2' 'BIRTHSEX' 'SOMALE'
 'SOFEMALE' 'TRNSGNDR' 'HADSEX' 'PFPPRVN4' 'TYPCNTR9' 'BRTHCNT4'
 'WHEREGET' 'NOBCUSE8' 'BCPREFER' 'RRCLASS3' 'RRCOGNT2' 'RRTREAT'
 'RRATWRK2' 'RRHCARE4' 'RRPHYSM2' 'CRACE2' 'CPRACE2' 'CAGEG' 'CLLCPWT']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-27 21:35:39,085:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'SAFETIME' 'CTELNUM1' 'CELLFON5' 'CADULT1'
 'CELLSEX1' 'PVTRESD3' 'CCLGHOUS' 'CSTATE1' 'LANDLINE' 'HHADULT'
 'LASTDEN4' 'RMVTETH4' 'VCLNTES2' 'BLDSTFIT' 'SDNATES1' 'PDIABTS1'
 'PREDIAB2' 'DIABTYPE' 'INSULIN1' 'CHKHEMO3' 'EYEEXAM1' 'DIABEYE1'
 'DIABEDU1' 'FEETSORE' 'TOLDCFS' 'HAVECFS' 'WORKCFS' 'IMFVPLA3' 'HPVADVC4'
 'HPVADSHT' 'SHINGLE2' 'COVIDVA1' 'COVACGET' 'COVIDNU1' 'COVIDINT'
 'COVIDFS1' 'COVIDSE1' 'COPDCOGH' 'COPDFLEM' 'COPDBRTH' 'COPDBTST'
 'COPDSMOK' 'CNCRDIFF' 'CNCRAGE' 'CNCRTYP2' 'CSRVTRT3' 'CSRVDOC1'
 'CSRVSUM' 'CSRVRTRN' 'CSRVINST' 'CSRVINSR' 'CSRVDEIN' 'CSRVCLIN'
 'CSRVPAIN' 'CSRVCTL2' 'PSATEST1' 'PSATIME1' 'PCPSARS2' 'PSASUGST'
 'PCSTALK1' 'CIMEMLOS' 'CDHOUSE' 'CDASSIST' 'CDHELP' 'CDSOCIAL' 'CDDISCUS'
 'CAREGIV1' 'CRGVREL4' 'CRGVLNG1' 'CRGVHRS1' 'CRGVPRB3' 'CRGVALZD'
 'CRGVPER1' 'CRGVHOU1' 'CRGVEXPT' 'ACEDEPRS' 'ACEDRINK' 'ACEDRUGS'
 'ACEPRISN' 'ACEDIVRC' 'ACEPUNCH' 'ACEHURT1' 'ACESWEAR' 'ACETOUCH'
 'ACETTHEM' 'ACEHVSEX' 'ACEADSAF' 'ACEADNED' 'MARIJAN1' 'MARJSMOK'
 'MARJEAT' 'MARJVAPE' 'MARJDAB' 'MARJOTHR' 'USEMRJN4' 'LASTSMK2'
 'STOPSMK2' 'MENTCIGS' 'MENTECIG' 'HEATTBCO' 'ASBIALCH' 'ASBIDRNK'
 'ASBIBING' 'ASBIADVC' 'ASBIRDUC' 'FIREARM5' 'GUNLOAD' 'LOADULK2'
 'RCSXBRTH' 'CASTHNO2' 'BIRTHSEX' 'SOMALE' 'SOFEMALE' 'TRNSGNDR' 'HADSEX'
 'PFPPRVN4' 'TYPCNTR9' 'BRTHCNT4' 'WHEREGET' 'NOBCUSE8' 'BCPREFER'
 'RRCLASS3' 'RRCOGNT2' 'RRTREAT' 'RRATWRK2' 'RRHCARE4' 'RRPHYSM2' 'CAGEG']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-27 21:35:39,087:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'SAFETIME' 'CTELNUM1' 'CELLFON5' 'CADULT1'
 'CELLSEX1' 'PVTRESD3' 'CCLGHOUS' 'CSTATE1' 'LANDLINE' 'HHADULT'
 'LASTDEN4' 'RMVTETH4' 'BLDSTFIT' 'SDNATES1' 'PDIABTS1' 'PREDIAB2'
 'DIABTYPE' 'INSULIN1' 'CHKHEMO3' 'EYEEXAM1' 'DIABEYE1' 'DIABEDU1'
 'FEETSORE' 'TOLDCFS' 'HAVECFS' 'WORKCFS' 'IMFVPLA3' 'HPVADVC4' 'HPVADSHT'
 'SHINGLE2' 'COVIDVA1' 'COVACGET' 'COVIDNU1' 'COVIDINT' 'COVIDFS1'
 'COVIDSE1' 'COPDCOGH' 'COPDFLEM' 'COPDBRTH' 'COPDBTST' 'COPDSMOK'
 'CNCRDIFF' 'CNCRAGE' 'CNCRTYP2' 'CSRVTRT3' 'CSRVDOC1' 'CSRVSUM'
 'CSRVRTRN' 'CSRVINST' 'CSRVINSR' 'CSRVDEIN' 'CSRVCLIN' 'CSRVPAIN'
 'CSRVCTL2' 'PSATEST1' 'PSATIME1' 'PCPSARS2' 'PSASUGST' 'PCSTALK1'
 'CIMEMLOS' 'CDHOUSE' 'CDASSIST' 'CDHELP' 'CDSOCIAL' 'CDDISCUS' 'CAREGIV1'
 'CRGVREL4' 'CRGVLNG1' 'CRGVHRS1' 'CRGVPRB3' 'CRGVALZD' 'CRGVPER1'
 'CRGVHOU1' 'CRGVEXPT' 'ACEDEPRS' 'ACEDRINK' 'ACEDRUGS' 'ACEPRISN'
 'ACEDIVRC' 'ACEPUNCH' 'ACEHURT1' 'ACESWEAR' 'ACETOUCH' 'ACETTHEM'
 'ACEHVSEX' 'ACEADSAF' 'ACEADNED' 'MARIJAN1' 'MARJSMOK' 'MARJEAT'
 'MARJVAPE' 'MARJDAB' 'MARJOTHR' 'USEMRJN4' 'LASTSMK2' 'STOPSMK2'
 'MENTCIGS' 'MENTECIG' 'HEATTBCO' 'ASBIALCH' 'ASBIDRNK' 'ASBIBING'
 'ASBIADVC' 'ASBIRDUC' 'FIREARM5' 'GUNLOAD' 'LOADULK2' 'RCSXBRTH'
 'CASTHNO2' 'BIRTHSEX' 'SOMALE' 'SOFEMALE' 'TRNSGNDR' 'HADSEX' 'PFPPRVN4'
 'TYPCNTR9' 'BRTHCNT4' 'WHEREGET' 'NOBCUSE8' 'BCPREFER' 'RRCLASS3'
 'RRCOGNT2' 'RRTREAT' 'RRATWRK2' 'RRHCARE4' 'RRPHYSM2' 'CAGEG']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-27 21:35:39,090:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'SAFETIME' 'CTELNUM1' 'CELLFON5' 'CADULT1'
 'CELLSEX1' 'PVTRESD3' 'CCLGHOUS' 'CSTATE1' 'LANDLINE' 'HHADULT'
 'LASTDEN4' 'RMVTETH4' 'BLDSTFIT' 'SDNATES1' 'PDIABTS1' 'PREDIAB2'
 'DIABTYPE' 'INSULIN1' 'CHKHEMO3' 'EYEEXAM1' 'DIABEYE1' 'DIABEDU1'
 'FEETSORE' 'TOLDCFS' 'HAVECFS' 'WORKCFS' 'IMFVPLA3' 'HPVADVC4' 'HPVADSHT'
 'SHINGLE2' 'COVIDVA1' 'COVACGET' 'COVIDNU1' 'COVIDINT' 'COVIDFS1'
 'COVIDSE1' 'COPDCOGH' 'COPDFLEM' 'COPDBRTH' 'COPDBTST' 'COPDSMOK'
 'CNCRDIFF' 'CNCRAGE' 'CNCRTYP2' 'CSRVTRT3' 'CSRVDOC1' 'CSRVSUM'
 'CSRVRTRN' 'CSRVINST' 'CSRVINSR' 'CSRVDEIN' 'CSRVCLIN' 'CSRVPAIN'
 'CSRVCTL2' 'PSATEST1' 'PSATIME1' 'PCPSARS2' 'PSASUGST' 'PCSTALK1'
 'CIMEMLOS' 'CDHOUSE' 'CDASSIST' 'CDHELP' 'CDSOCIAL' 'CDDISCUS' 'CAREGIV1'
 'CRGVREL4' 'CRGVLNG1' 'CRGVHRS1' 'CRGVPRB3' 'CRGVALZD' 'CRGVPER1'
 'CRGVHOU1' 'CRGVEXPT' 'ACEDEPRS' 'ACEDRINK' 'ACEDRUGS' 'ACEPRISN'
 'ACEDIVRC' 'ACEPUNCH' 'ACEHURT1' 'ACESWEAR' 'ACETOUCH' 'ACETTHEM'
 'ACEHVSEX' 'ACEADSAF' 'ACEADNED' 'MARIJAN1' 'MARJSMOK' 'MARJEAT'
 'MARJVAPE' 'MARJDAB' 'MARJOTHR' 'USEMRJN4' 'LASTSMK2' 'STOPSMK2'
 'MENTCIGS' 'MENTECIG' 'HEATTBCO' 'ASBIALCH' 'ASBIDRNK' 'ASBIBING'
 'ASBIADVC' 'ASBIRDUC' 'FIREARM5' 'GUNLOAD' 'LOADULK2' 'RCSXBRTH'
 'CASTHNO2' 'BIRTHSEX' 'SOMALE' 'SOFEMALE' 'TRNSGNDR' 'HADSEX' 'PFPPRVN4'
 'TYPCNTR9' 'BRTHCNT4' 'WHEREGET' 'NOBCUSE8' 'BCPREFER' 'RRCLASS3'
 'RRCOGNT2' 'RRTREAT' 'RRATWRK2' 'RRHCARE4' 'RRPHYSM2' 'CAGEG']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-27 21:35:39,104:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'SAFETIME' 'CTELNUM1' 'CELLFON5' 'CADULT1'
 'CELLSEX1' 'PVTRESD3' 'CCLGHOUS' 'CSTATE1' 'LANDLINE' 'HHADULT'
 'LASTDEN4' 'RMVTETH4' 'BLDSTFIT' 'SDNATES1' 'PDIABTS1' 'PREDIAB2'
 'DIABTYPE' 'INSULIN1' 'CHKHEMO3' 'EYEEXAM1' 'DIABEYE1' 'DIABEDU1'
 'FEETSORE' 'TOLDCFS' 'HAVECFS' 'WORKCFS' 'IMFVPLA3' 'HPVADVC4' 'HPVADSHT'
 'SHINGLE2' 'COVIDVA1' 'COVACGET' 'COVIDNU1' 'COVIDINT' 'COVIDFS1'
 'COVIDSE1' 'COPDCOGH' 'COPDFLEM' 'COPDBRTH' 'COPDBTST' 'COPDSMOK'
 'CNCRDIFF' 'CNCRAGE' 'CNCRTYP2' 'CSRVTRT3' 'CSRVDOC1' 'CSRVSUM'
 'CSRVRTRN' 'CSRVINST' 'CSRVINSR' 'CSRVDEIN' 'CSRVCLIN' 'CSRVPAIN'
 'CSRVCTL2' 'PSATEST1' 'PSATIME1' 'PCPSARS2' 'PSASUGST' 'PCSTALK1'
 'CIMEMLOS' 'CDHOUSE' 'CDASSIST' 'CDHELP' 'CDSOCIAL' 'CDDISCUS' 'CAREGIV1'
 'CRGVREL4' 'CRGVLNG1' 'CRGVHRS1' 'CRGVPRB3' 'CRGVALZD' 'CRGVPER1'
 'CRGVHOU1' 'CRGVEXPT' 'ACEDEPRS' 'ACEDRINK' 'ACEDRUGS' 'ACEPRISN'
 'ACEDIVRC' 'ACEPUNCH' 'ACEHURT1' 'ACESWEAR' 'ACETOUCH' 'ACETTHEM'
 'ACEHVSEX' 'ACEADSAF' 'ACEADNED' 'MARIJAN1' 'MARJSMOK' 'MARJEAT'
 'MARJVAPE' 'MARJDAB' 'MARJOTHR' 'USEMRJN4' 'LASTSMK2' 'STOPSMK2'
 'MENTCIGS' 'MENTECIG' 'HEATTBCO' 'ASBIALCH' 'ASBIDRNK' 'ASBIBING'
 'ASBIADVC' 'ASBIRDUC' 'FIREARM5' 'GUNLOAD' 'LOADULK2' 'RCSXBRTH'
 'CASTHNO2' 'BIRTHSEX' 'SOMALE' 'SOFEMALE' 'TRNSGNDR' 'HADSEX' 'PFPPRVN4'
 'TYPCNTR9' 'BRTHCNT4' 'WHEREGET' 'NOBCUSE8' 'BCPREFER' 'RRCLASS3'
 'RRCOGNT2' 'RRTREAT' 'RRATWRK2' 'RRHCARE4' 'RRPHYSM2' 'CAGEG']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-27 21:35:39,105:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'SAFETIME' 'CTELNUM1' 'CELLFON5' 'CADULT1'
 'CELLSEX1' 'PVTRESD3' 'CCLGHOUS' 'CSTATE1' 'LANDLINE' 'HHADULT'
 'LASTDEN4' 'RMVTETH4' 'NUMPHON4' 'BLDSTFIT' 'SDNATES1' 'PDIABTS1'
 'PREDIAB2' 'DIABTYPE' 'INSULIN1' 'CHKHEMO3' 'EYEEXAM1' 'DIABEYE1'
 'DIABEDU1' 'FEETSORE' 'TOLDCFS' 'HAVECFS' 'WORKCFS' 'IMFVPLA3' 'HPVADVC4'
 'HPVADSHT' 'SHINGLE2' 'COVIDVA1' 'COVACGET' 'COVIDNU1' 'COVIDINT'
 'COVIDFS1' 'COVIDSE1' 'COPDCOGH' 'COPDFLEM' 'COPDBRTH' 'COPDBTST'
 'COPDSMOK' 'CNCRDIFF' 'CNCRAGE' 'CNCRTYP2' 'CSRVTRT3' 'CSRVDOC1'
 'CSRVSUM' 'CSRVRTRN' 'CSRVINST' 'CSRVINSR' 'CSRVDEIN' 'CSRVCLIN'
 'CSRVPAIN' 'CSRVCTL2' 'PSATEST1' 'PSATIME1' 'PCPSARS2' 'PSASUGST'
 'PCSTALK1' 'CIMEMLOS' 'CDHOUSE' 'CDASSIST' 'CDHELP' 'CDSOCIAL' 'CDDISCUS'
 'CAREGIV1' 'CRGVREL4' 'CRGVLNG1' 'CRGVHRS1' 'CRGVPRB3' 'CRGVALZD'
 'CRGVPER1' 'CRGVHOU1' 'CRGVEXPT' 'ACEDEPRS' 'ACEDRINK' 'ACEDRUGS'
 'ACEPRISN' 'ACEDIVRC' 'ACEPUNCH' 'ACEHURT1' 'ACESWEAR' 'ACETOUCH'
 'ACETTHEM' 'ACEHVSEX' 'ACEADSAF' 'ACEADNED' 'MARIJAN1' 'MARJSMOK'
 'MARJEAT' 'MARJVAPE' 'MARJDAB' 'MARJOTHR' 'USEMRJN4' 'LASTSMK2'
 'STOPSMK2' 'MENTCIGS' 'MENTECIG' 'HEATTBCO' 'ASBIALCH' 'ASBIDRNK'
 'ASBIBING' 'ASBIADVC' 'ASBIRDUC' 'FIREARM5' 'GUNLOAD' 'LOADULK2'
 'RCSXBRTH' 'CASTHNO2' 'BIRTHSEX' 'SOMALE' 'SOFEMALE' 'TRNSGNDR' 'HADSEX'
 'PFPPRVN4' 'TYPCNTR9' 'BRTHCNT4' 'WHEREGET' 'NOBCUSE8' 'BCPREFER'
 'RRCLASS3' 'RRCOGNT2' 'RRTREAT' 'RRATWRK2' 'RRHCARE4' 'RRPHYSM2' 'CAGEG']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-27 21:35:39,114:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'SAFETIME' 'CTELNUM1' 'CELLFON5' 'CADULT1'
 'CELLSEX1' 'PVTRESD3' 'CCLGHOUS' 'CSTATE1' 'LANDLINE' 'HHADULT'
 'LASTDEN4' 'RMVTETH4' 'BLDSTFIT' 'SDNATES1' 'PDIABTS1' 'PREDIAB2'
 'DIABTYPE' 'INSULIN1' 'CHKHEMO3' 'EYEEXAM1' 'DIABEYE1' 'DIABEDU1'
 'FEETSORE' 'TOLDCFS' 'HAVECFS' 'WORKCFS' 'IMFVPLA3' 'HPVADVC4' 'HPVADSHT'
 'SHINGLE2' 'COVIDVA1' 'COVACGET' 'COVIDNU1' 'COVIDINT' 'COVIDFS1'
 'COVIDSE1' 'COPDCOGH' 'COPDFLEM' 'COPDBRTH' 'COPDBTST' 'COPDSMOK'
 'CNCRDIFF' 'CNCRAGE' 'CNCRTYP2' 'CSRVTRT3' 'CSRVDOC1' 'CSRVSUM'
 'CSRVRTRN' 'CSRVINST' 'CSRVINSR' 'CSRVDEIN' 'CSRVCLIN' 'CSRVPAIN'
 'CSRVCTL2' 'PSATEST1' 'PSATIME1' 'PCPSARS2' 'PSASUGST' 'PCSTALK1'
 'CIMEMLOS' 'CDHOUSE' 'CDASSIST' 'CDHELP' 'CDSOCIAL' 'CDDISCUS' 'CAREGIV1'
 'CRGVREL4' 'CRGVLNG1' 'CRGVHRS1' 'CRGVPRB3' 'CRGVALZD' 'CRGVPER1'
 'CRGVHOU1' 'CRGVEXPT' 'ACEDEPRS' 'ACEDRINK' 'ACEDRUGS' 'ACEPRISN'
 'ACEDIVRC' 'ACEPUNCH' 'ACEHURT1' 'ACESWEAR' 'ACETOUCH' 'ACETTHEM'
 'ACEHVSEX' 'ACEADSAF' 'ACEADNED' 'MARIJAN1' 'MARJSMOK' 'MARJEAT'
 'MARJVAPE' 'MARJDAB' 'MARJOTHR' 'USEMRJN4' 'LASTSMK2' 'STOPSMK2'
 'MENTCIGS' 'MENTECIG' 'HEATTBCO' 'ASBIALCH' 'ASBIDRNK' 'ASBIBING'
 'ASBIADVC' 'ASBIRDUC' 'FIREARM5' 'GUNLOAD' 'LOADULK2' 'RCSXBRTH'
 'CASTHNO2' 'BIRTHSEX' 'SOMALE' 'SOFEMALE' 'TRNSGNDR' 'HADSEX' 'PFPPRVN4'
 'TYPCNTR9' 'BRTHCNT4' 'WHEREGET' 'NOBCUSE8' 'BCPREFER' 'RRCLASS3'
 'RRCOGNT2' 'RRTREAT' 'RRATWRK2' 'RRHCARE4' 'RRPHYSM2' 'CAGEG']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-27 21:35:39,126:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'SAFETIME' 'CTELNUM1' 'CELLFON5' 'CADULT1'
 'CELLSEX1' 'PVTRESD3' 'CCLGHOUS' 'CSTATE1' 'LANDLINE' 'HHADULT'
 'LASTDEN4' 'RMVTETH4' 'LASTSIG4' 'BLDSTFIT' 'SDNATES1' 'PDIABTS1'
 'PREDIAB2' 'DIABTYPE' 'INSULIN1' 'CHKHEMO3' 'EYEEXAM1' 'DIABEYE1'
 'DIABEDU1' 'FEETSORE' 'TOLDCFS' 'HAVECFS' 'WORKCFS' 'IMFVPLA3' 'HPVADVC4'
 'HPVADSHT' 'SHINGLE2' 'COVIDVA1' 'COVACGET' 'COVIDNU1' 'COVIDINT'
 'COVIDFS1' 'COVIDSE1' 'COPDCOGH' 'COPDFLEM' 'COPDBRTH' 'COPDBTST'
 'COPDSMOK' 'CNCRDIFF' 'CNCRAGE' 'CNCRTYP2' 'CSRVTRT3' 'CSRVDOC1'
 'CSRVSUM' 'CSRVRTRN' 'CSRVINST' 'CSRVINSR' 'CSRVDEIN' 'CSRVCLIN'
 'CSRVPAIN' 'CSRVCTL2' 'PSATEST1' 'PSATIME1' 'PCPSARS2' 'PSASUGST'
 'PCSTALK1' 'CIMEMLOS' 'CDHOUSE' 'CDASSIST' 'CDHELP' 'CDSOCIAL' 'CDDISCUS'
 'CAREGIV1' 'CRGVREL4' 'CRGVLNG1' 'CRGVHRS1' 'CRGVPRB3' 'CRGVALZD'
 'CRGVPER1' 'CRGVHOU1' 'CRGVEXPT' 'ACEDEPRS' 'ACEDRINK' 'ACEDRUGS'
 'ACEPRISN' 'ACEDIVRC' 'ACEPUNCH' 'ACEHURT1' 'ACESWEAR' 'ACETOUCH'
 'ACETTHEM' 'ACEHVSEX' 'ACEADSAF' 'ACEADNED' 'MARIJAN1' 'MARJSMOK'
 'MARJEAT' 'MARJVAPE' 'MARJDAB' 'MARJOTHR' 'USEMRJN4' 'LASTSMK2'
 'STOPSMK2' 'MENTCIGS' 'MENTECIG' 'HEATTBCO' 'ASBIALCH' 'ASBIDRNK'
 'ASBIBING' 'ASBIADVC' 'ASBIRDUC' 'FIREARM5' 'GUNLOAD' 'LOADULK2'
 'RCSXBRTH' 'CASTHNO2' 'BIRTHSEX' 'SOMALE' 'SOFEMALE' 'TRNSGNDR' 'HADSEX'
 'PFPPRVN4' 'TYPCNTR9' 'BRTHCNT4' 'WHEREGET' 'NOBCUSE8' 'BCPREFER'
 'RRCLASS3' 'RRCOGNT2' 'RRTREAT' 'RRATWRK2' 'RRHCARE4' 'RRPHYSM2' 'CAGEG']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-27 21:35:39,168:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'SAFETIME' 'CTELNUM1' 'CELLFON5' 'CADULT1'
 'CELLSEX1' 'PVTRESD3' 'CCLGHOUS' 'CSTATE1' 'LANDLINE' 'HHADULT'
 'LASTDEN4' 'RMVTETH4' 'BLDSTFIT' 'SDNATES1' 'PDIABTS1' 'PREDIAB2'
 'DIABTYPE' 'INSULIN1' 'CHKHEMO3' 'EYEEXAM1' 'DIABEYE1' 'DIABEDU1'
 'FEETSORE' 'TOLDCFS' 'HAVECFS' 'WORKCFS' 'IMFVPLA3' 'HPVADVC4' 'HPVADSHT'
 'SHINGLE2' 'COVIDVA1' 'COVACGET' 'COVIDNU1' 'COVIDINT' 'COVIDFS1'
 'COVIDSE1' 'COPDCOGH' 'COPDFLEM' 'COPDBRTH' 'COPDBTST' 'COPDSMOK'
 'CNCRDIFF' 'CNCRAGE' 'CNCRTYP2' 'CSRVTRT3' 'CSRVDOC1' 'CSRVSUM'
 'CSRVRTRN' 'CSRVINST' 'CSRVINSR' 'CSRVDEIN' 'CSRVCLIN' 'CSRVPAIN'
 'CSRVCTL2' 'PSATEST1' 'PSATIME1' 'PCPSARS2' 'PSASUGST' 'PCSTALK1'
 'CIMEMLOS' 'CDHOUSE' 'CDASSIST' 'CDHELP' 'CDSOCIAL' 'CDDISCUS' 'CAREGIV1'
 'CRGVREL4' 'CRGVLNG1' 'CRGVHRS1' 'CRGVPRB3' 'CRGVALZD' 'CRGVPER1'
 'CRGVHOU1' 'CRGVEXPT' 'ACEDEPRS' 'ACEDRINK' 'ACEDRUGS' 'ACEPRISN'
 'ACEDIVRC' 'ACEPUNCH' 'ACEHURT1' 'ACESWEAR' 'ACETOUCH' 'ACETTHEM'
 'ACEHVSEX' 'ACEADSAF' 'ACEADNED' 'MARIJAN1' 'MARJSMOK' 'MARJEAT'
 'MARJVAPE' 'MARJDAB' 'MARJOTHR' 'USEMRJN4' 'LASTSMK2' 'STOPSMK2'
 'MENTCIGS' 'MENTECIG' 'HEATTBCO' 'ASBIALCH' 'ASBIDRNK' 'ASBIBING'
 'ASBIADVC' 'ASBIRDUC' 'FIREARM5' 'GUNLOAD' 'LOADULK2' 'RCSGEND1'
 'RCSXBRTH' 'RCSRLTN2' 'CASTHDX2' 'CASTHNO2' 'BIRTHSEX' 'SOMALE'
 'SOFEMALE' 'TRNSGNDR' 'HADSEX' 'PFPPRVN4' 'TYPCNTR9' 'BRTHCNT4'
 'WHEREGET' 'NOBCUSE8' 'BCPREFER' 'RRCLASS3' 'RRCOGNT2' 'RRTREAT'
 'RRATWRK2' 'RRHCARE4' 'RRPHYSM2' 'CRACE2' 'CPRACE2' 'CAGEG' 'CLLCPWT']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-27 21:35:39,190:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-11-27 21:35:39,192:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-11-27 21:35:39,192:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-11-27 21:35:39,195:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-11-27 21:35:39,195:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-11-27 21:35:39,196:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-11-27 21:35:39,198:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-27 21:35:39,198:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-27 21:35:39,198:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-27 21:35:39,204:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-11-27 21:35:39,204:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-11-27 21:35:39,210:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-11-27 21:35:39,210:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-11-27 21:35:39,210:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-27 21:35:39,210:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-27 21:35:39,210:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-27 21:35:39,214:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-11-27 21:35:39,217:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-11-27 21:35:39,218:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-11-27 21:35:39,220:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-11-27 21:35:39,220:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-27 21:35:39,220:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-27 21:35:39,220:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-27 21:35:40,931:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-27 21:35:40,937:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-27 21:35:41,075:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'SAFETIME' 'CTELNUM1' 'CELLFON5' 'CADULT1'
 'CELLSEX1' 'PVTRESD3' 'CCLGHOUS' 'CSTATE1' 'LANDLINE' 'HHADULT'
 'LASTDEN4' 'RMVTETH4' 'BLDSTFIT' 'SDNATES1' 'COVIDPRM' 'PDIABTS1'
 'PREDIAB2' 'DIABTYPE' 'INSULIN1' 'CHKHEMO3' 'EYEEXAM1' 'DIABEYE1'
 'DIABEDU1' 'FEETSORE' 'TOLDCFS' 'HAVECFS' 'WORKCFS' 'IMFVPLA3' 'HPVADVC4'
 'HPVADSHT' 'SHINGLE2' 'COVIDVA1' 'COVACGET' 'COVIDNU1' 'COVIDINT'
 'COVIDFS1' 'COVIDSE1' 'COPDCOGH' 'COPDFLEM' 'COPDBRTH' 'COPDBTST'
 'COPDSMOK' 'CNCRDIFF' 'CNCRAGE' 'CNCRTYP2' 'CSRVTRT3' 'CSRVDOC1'
 'CSRVSUM' 'CSRVRTRN' 'CSRVINST' 'CSRVINSR' 'CSRVDEIN' 'CSRVCLIN'
 'CSRVPAIN' 'CSRVCTL2' 'PSATEST1' 'PSATIME1' 'PCPSARS2' 'PSASUGST'
 'PCSTALK1' 'CIMEMLOS' 'CDHOUSE' 'CDASSIST' 'CDHELP' 'CDSOCIAL' 'CDDISCUS'
 'CAREGIV1' 'CRGVREL4' 'CRGVLNG1' 'CRGVHRS1' 'CRGVPRB3' 'CRGVALZD'
 'CRGVPER1' 'CRGVHOU1' 'CRGVEXPT' 'ACEDEPRS' 'ACEDRINK' 'ACEDRUGS'
 'ACEPRISN' 'ACEDIVRC' 'ACEPUNCH' 'ACEHURT1' 'ACESWEAR' 'ACETOUCH'
 'ACETTHEM' 'ACEHVSEX' 'ACEADSAF' 'ACEADNED' 'MARIJAN1' 'MARJSMOK'
 'MARJEAT' 'MARJVAPE' 'MARJDAB' 'MARJOTHR' 'USEMRJN4' 'LASTSMK2'
 'STOPSMK2' 'MENTCIGS' 'MENTECIG' 'HEATTBCO' 'ASBIALCH' 'ASBIDRNK'
 'ASBIBING' 'ASBIADVC' 'ASBIRDUC' 'FIREARM5' 'GUNLOAD' 'LOADULK2'
 'RCSXBRTH' 'CASTHNO2' 'BIRTHSEX' 'SOMALE' 'SOFEMALE' 'TRNSGNDR' 'HADSEX'
 'PFPPRVN4' 'TYPCNTR9' 'BRTHCNT4' 'WHEREGET' 'NOBCUSE8' 'BCPREFER'
 'RRCLASS3' 'RRCOGNT2' 'RRTREAT' 'RRATWRK2' 'RRHCARE4' 'RRPHYSM2' 'CAGEG']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-27 21:35:41,075:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'SAFETIME' 'CTELNUM1' 'CELLFON5' 'CADULT1'
 'CELLSEX1' 'PVTRESD3' 'CCLGHOUS' 'CSTATE1' 'LANDLINE' 'HHADULT'
 'LASTDEN4' 'RMVTETH4' 'BLDSTFIT' 'SDNATES1' 'PDIABTS1' 'PREDIAB2'
 'DIABTYPE' 'INSULIN1' 'CHKHEMO3' 'EYEEXAM1' 'DIABEYE1' 'DIABEDU1'
 'FEETSORE' 'TOLDCFS' 'HAVECFS' 'WORKCFS' 'IMFVPLA3' 'HPVADVC4' 'HPVADSHT'
 'SHINGLE2' 'COVIDVA1' 'COVACGET' 'COVIDNU1' 'COVIDINT' 'COVIDFS1'
 'COVIDSE1' 'COPDCOGH' 'COPDFLEM' 'COPDBRTH' 'COPDBTST' 'COPDSMOK'
 'CNCRDIFF' 'CNCRAGE' 'CNCRTYP2' 'CSRVTRT3' 'CSRVDOC1' 'CSRVSUM'
 'CSRVRTRN' 'CSRVINST' 'CSRVINSR' 'CSRVDEIN' 'CSRVCLIN' 'CSRVPAIN'
 'CSRVCTL2' 'PSATEST1' 'PSATIME1' 'PCPSARS2' 'PSASUGST' 'PCSTALK1'
 'CIMEMLOS' 'CDHOUSE' 'CDASSIST' 'CDHELP' 'CDSOCIAL' 'CDDISCUS' 'CAREGIV1'
 'CRGVREL4' 'CRGVLNG1' 'CRGVHRS1' 'CRGVPRB3' 'CRGVALZD' 'CRGVPER1'
 'CRGVHOU1' 'CRGVEXPT' 'ACEDEPRS' 'ACEDRINK' 'ACEDRUGS' 'ACEPRISN'
 'ACEDIVRC' 'ACEPUNCH' 'ACEHURT1' 'ACESWEAR' 'ACETOUCH' 'ACETTHEM'
 'ACEHVSEX' 'ACEADSAF' 'ACEADNED' 'MARIJAN1' 'MARJSMOK' 'MARJEAT'
 'MARJVAPE' 'MARJDAB' 'MARJOTHR' 'USEMRJN4' 'LASTSMK2' 'STOPSMK2'
 'MENTCIGS' 'MENTECIG' 'HEATTBCO' 'ASBIALCH' 'ASBIDRNK' 'ASBIBING'
 'ASBIADVC' 'ASBIRDUC' 'FIREARM5' 'GUNLOAD' 'LOADULK2' 'RCSXBRTH'
 'CASTHNO2' 'BIRTHSEX' 'SOMALE' 'SOFEMALE' 'TRNSGNDR' 'HADSEX' 'PFPPRVN4'
 'TYPCNTR9' 'BRTHCNT4' 'WHEREGET' 'NOBCUSE8' 'BCPREFER' 'RRCLASS3'
 'RRCOGNT2' 'RRTREAT' 'RRATWRK2' 'RRHCARE4' 'RRPHYSM2' 'CAGEG']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-27 21:35:41,123:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'SAFETIME' 'CTELNUM1' 'CELLFON5' 'CADULT1'
 'CELLSEX1' 'PVTRESD3' 'CCLGHOUS' 'CSTATE1' 'LANDLINE' 'HHADULT'
 'LASTDEN4' 'RMVTETH4' 'BLDSTFIT' 'SDNATES1' 'COVIDPRM' 'PDIABTS1'
 'PREDIAB2' 'DIABTYPE' 'INSULIN1' 'CHKHEMO3' 'EYEEXAM1' 'DIABEYE1'
 'DIABEDU1' 'FEETSORE' 'TOLDCFS' 'HAVECFS' 'WORKCFS' 'IMFVPLA3' 'HPVADVC4'
 'HPVADSHT' 'SHINGLE2' 'COVIDVA1' 'COVACGET' 'COVIDNU1' 'COVIDINT'
 'COVIDFS1' 'COVIDSE1' 'COPDCOGH' 'COPDFLEM' 'COPDBRTH' 'COPDBTST'
 'COPDSMOK' 'CNCRDIFF' 'CNCRAGE' 'CNCRTYP2' 'CSRVTRT3' 'CSRVDOC1'
 'CSRVSUM' 'CSRVRTRN' 'CSRVINST' 'CSRVINSR' 'CSRVDEIN' 'CSRVCLIN'
 'CSRVPAIN' 'CSRVCTL2' 'PSATEST1' 'PSATIME1' 'PCPSARS2' 'PSASUGST'
 'PCSTALK1' 'CIMEMLOS' 'CDHOUSE' 'CDASSIST' 'CDHELP' 'CDSOCIAL' 'CDDISCUS'
 'CAREGIV1' 'CRGVREL4' 'CRGVLNG1' 'CRGVHRS1' 'CRGVPRB3' 'CRGVALZD'
 'CRGVPER1' 'CRGVHOU1' 'CRGVEXPT' 'ACEDEPRS' 'ACEDRINK' 'ACEDRUGS'
 'ACEPRISN' 'ACEDIVRC' 'ACEPUNCH' 'ACEHURT1' 'ACESWEAR' 'ACETOUCH'
 'ACETTHEM' 'ACEHVSEX' 'ACEADSAF' 'ACEADNED' 'MARIJAN1' 'MARJSMOK'
 'MARJEAT' 'MARJVAPE' 'MARJDAB' 'MARJOTHR' 'USEMRJN4' 'LASTSMK2'
 'STOPSMK2' 'MENTCIGS' 'MENTECIG' 'HEATTBCO' 'ASBIALCH' 'ASBIDRNK'
 'ASBIBING' 'ASBIADVC' 'ASBIRDUC' 'FIREARM5' 'GUNLOAD' 'LOADULK2'
 'RCSXBRTH' 'CASTHNO2' 'BIRTHSEX' 'SOMALE' 'SOFEMALE' 'TRNSGNDR' 'HADSEX'
 'PFPPRVN4' 'TYPCNTR9' 'BRTHCNT4' 'WHEREGET' 'NOBCUSE8' 'BCPREFER'
 'RRCLASS3' 'RRCOGNT2' 'RRTREAT' 'RRATWRK2' 'RRHCARE4' 'RRPHYSM2' 'CAGEG']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-27 21:35:41,125:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'SAFETIME' 'CTELNUM1' 'CELLFON5' 'CADULT1'
 'CELLSEX1' 'PVTRESD3' 'CCLGHOUS' 'CSTATE1' 'LANDLINE' 'HHADULT'
 'LASTDEN4' 'RMVTETH4' 'BLDSTFIT' 'SDNATES1' 'PDIABTS1' 'PREDIAB2'
 'DIABTYPE' 'INSULIN1' 'CHKHEMO3' 'EYEEXAM1' 'DIABEYE1' 'DIABEDU1'
 'FEETSORE' 'TOLDCFS' 'HAVECFS' 'WORKCFS' 'IMFVPLA3' 'HPVADVC4' 'HPVADSHT'
 'SHINGLE2' 'COVIDVA1' 'COVACGET' 'COVIDNU1' 'COVIDINT' 'COVIDFS1'
 'COVIDSE1' 'COPDCOGH' 'COPDFLEM' 'COPDBRTH' 'COPDBTST' 'COPDSMOK'
 'CNCRDIFF' 'CNCRAGE' 'CNCRTYP2' 'CSRVTRT3' 'CSRVDOC1' 'CSRVSUM'
 'CSRVRTRN' 'CSRVINST' 'CSRVINSR' 'CSRVDEIN' 'CSRVCLIN' 'CSRVPAIN'
 'CSRVCTL2' 'PSATEST1' 'PSATIME1' 'PCPSARS2' 'PSASUGST' 'PCSTALK1'
 'CIMEMLOS' 'CDHOUSE' 'CDASSIST' 'CDHELP' 'CDSOCIAL' 'CDDISCUS' 'CAREGIV1'
 'CRGVREL4' 'CRGVLNG1' 'CRGVHRS1' 'CRGVPRB3' 'CRGVALZD' 'CRGVPER1'
 'CRGVHOU1' 'CRGVEXPT' 'ACEDEPRS' 'ACEDRINK' 'ACEDRUGS' 'ACEPRISN'
 'ACEDIVRC' 'ACEPUNCH' 'ACEHURT1' 'ACESWEAR' 'ACETOUCH' 'ACETTHEM'
 'ACEHVSEX' 'ACEADSAF' 'ACEADNED' 'MARIJAN1' 'MARJSMOK' 'MARJEAT'
 'MARJVAPE' 'MARJDAB' 'MARJOTHR' 'USEMRJN4' 'LASTSMK2' 'STOPSMK2'
 'MENTCIGS' 'MENTECIG' 'HEATTBCO' 'ASBIALCH' 'ASBIDRNK' 'ASBIBING'
 'ASBIADVC' 'ASBIRDUC' 'FIREARM5' 'GUNLOAD' 'LOADULK2' 'RCSXBRTH'
 'CASTHNO2' 'BIRTHSEX' 'SOMALE' 'SOFEMALE' 'TRNSGNDR' 'HADSEX' 'PFPPRVN4'
 'TYPCNTR9' 'BRTHCNT4' 'WHEREGET' 'NOBCUSE8' 'BCPREFER' 'RRCLASS3'
 'RRCOGNT2' 'RRTREAT' 'RRATWRK2' 'RRHCARE4' 'RRPHYSM2' 'CAGEG']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-27 21:35:41,175:INFO:Calculating mean and std
2025-11-27 21:35:41,175:INFO:Creating metrics dataframe
2025-11-27 21:35:41,177:INFO:Uploading results into container
2025-11-27 21:35:41,177:INFO:Uploading model into container now
2025-11-27 21:35:41,177:INFO:_master_model_container: 2
2025-11-27 21:35:41,177:INFO:_display_container: 2
2025-11-27 21:35:41,177:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best')
2025-11-27 21:35:41,177:INFO:create_model() successfully completed......................................
2025-11-27 21:35:41,278:INFO:SubProcess create_model() end ==================================
2025-11-27 21:35:41,278:INFO:Creating metrics dataframe
2025-11-27 21:35:41,285:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  master_display_.apply(

2025-11-27 21:35:41,285:INFO:Initializing create_model()
2025-11-27 21:35:41,285:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024612C71C30>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-27 21:35:41,285:INFO:Checking exceptions
2025-11-27 21:35:41,285:INFO:Importing libraries
2025-11-27 21:35:41,285:INFO:Copying training dataset
2025-11-27 21:35:41,308:INFO:Defining folds
2025-11-27 21:35:41,309:INFO:Declaring metric variables
2025-11-27 21:35:41,309:INFO:Importing untrained model
2025-11-27 21:35:41,309:INFO:Declaring custom model
2025-11-27 21:35:41,309:INFO:Decision Tree Classifier Imported successfully
2025-11-27 21:35:41,310:INFO:Cross validation set to False
2025-11-27 21:35:41,310:INFO:Fitting Model
2025-11-27 21:35:41,322:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'SAFETIME' 'CTELNUM1' 'CELLFON5' 'CADULT1'
 'CELLSEX1' 'PVTRESD3' 'CCLGHOUS' 'CSTATE1' 'LANDLINE' 'HHADULT'
 'LASTDEN4' 'RMVTETH4' 'BLDSTFIT' 'SDNATES1' 'PDIABTS1' 'PREDIAB2'
 'DIABTYPE' 'INSULIN1' 'CHKHEMO3' 'EYEEXAM1' 'DIABEYE1' 'DIABEDU1'
 'FEETSORE' 'TOLDCFS' 'HAVECFS' 'WORKCFS' 'IMFVPLA3' 'HPVADVC4' 'HPVADSHT'
 'SHINGLE2' 'COVIDVA1' 'COVACGET' 'COVIDNU1' 'COVIDINT' 'COVIDFS1'
 'COVIDSE1' 'COPDCOGH' 'COPDFLEM' 'COPDBRTH' 'COPDBTST' 'COPDSMOK'
 'CNCRDIFF' 'CNCRAGE' 'CNCRTYP2' 'CSRVTRT3' 'CSRVDOC1' 'CSRVSUM'
 'CSRVRTRN' 'CSRVINST' 'CSRVINSR' 'CSRVDEIN' 'CSRVCLIN' 'CSRVPAIN'
 'CSRVCTL2' 'PSATEST1' 'PSATIME1' 'PCPSARS2' 'PSASUGST' 'PCSTALK1'
 'CIMEMLOS' 'CDHOUSE' 'CDASSIST' 'CDHELP' 'CDSOCIAL' 'CDDISCUS' 'CAREGIV1'
 'CRGVREL4' 'CRGVLNG1' 'CRGVHRS1' 'CRGVPRB3' 'CRGVALZD' 'CRGVPER1'
 'CRGVHOU1' 'CRGVEXPT' 'ACEDEPRS' 'ACEDRINK' 'ACEDRUGS' 'ACEPRISN'
 'ACEDIVRC' 'ACEPUNCH' 'ACEHURT1' 'ACESWEAR' 'ACETOUCH' 'ACETTHEM'
 'ACEHVSEX' 'ACEADSAF' 'ACEADNED' 'MARIJAN1' 'MARJSMOK' 'MARJEAT'
 'MARJVAPE' 'MARJDAB' 'MARJOTHR' 'USEMRJN4' 'LASTSMK2' 'STOPSMK2'
 'MENTCIGS' 'MENTECIG' 'HEATTBCO' 'ASBIALCH' 'ASBIDRNK' 'ASBIBING'
 'ASBIADVC' 'ASBIRDUC' 'FIREARM5' 'GUNLOAD' 'LOADULK2' 'RCSXBRTH'
 'CASTHNO2' 'BIRTHSEX' 'SOMALE' 'SOFEMALE' 'TRNSGNDR' 'HADSEX' 'PFPPRVN4'
 'TYPCNTR9' 'BRTHCNT4' 'WHEREGET' 'NOBCUSE8' 'BCPREFER' 'RRCLASS3'
 'RRCOGNT2' 'RRTREAT' 'RRATWRK2' 'RRHCARE4' 'RRPHYSM2' 'CAGEG']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-27 21:35:41,364:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best')
2025-11-27 21:35:41,364:INFO:create_model() successfully completed......................................
2025-11-27 21:35:41,472:INFO:_master_model_container: 2
2025-11-27 21:35:41,472:INFO:_display_container: 2
2025-11-27 21:35:41,472:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best')
2025-11-27 21:35:41,472:INFO:compare_models() successfully completed......................................
2025-11-27 21:41:07,306:INFO:Initializing predict_model()
2025-11-27 21:41:07,306:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024612C71C30>, estimator=<__main__.MockModel object at 0x00000246A05C0CD0>, probability_threshold=None, encoded_labels=False, raw_score=True, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002467E654B80>)
2025-11-27 21:41:07,306:INFO:Checking exceptions
2025-11-27 21:41:07,306:INFO:Preloading libraries
2025-11-27 21:41:07,306:INFO:Set up data.
2025-11-27 21:41:07,308:INFO:Set up index.
2025-11-27 21:41:07,308:INFO:Initializing predict_model()
2025-11-27 21:41:07,310:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024612C71C30>, estimator=<__main__.MockModel object at 0x00000246A05C0CD0>, probability_threshold=None, encoded_labels=False, raw_score=True, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002467E654B80>)
2025-11-27 21:41:07,310:INFO:Checking exceptions
2025-11-27 21:41:07,310:INFO:Preloading libraries
2025-11-27 21:41:07,310:INFO:Set up data.
2025-11-27 21:41:07,312:INFO:Set up index.
2025-11-28 15:00:09,716:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-11-28 15:00:09,716:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-11-28 15:00:09,716:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-11-28 15:00:09,716:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-11-28 15:12:30,382:INFO:PyCaret ClassificationExperiment
2025-11-28 15:12:30,384:INFO:Logging name: clf-default-name
2025-11-28 15:12:30,384:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-11-28 15:12:30,384:INFO:version 3.3.2
2025-11-28 15:12:30,384:INFO:Initializing setup()
2025-11-28 15:12:30,384:INFO:self.USI: efbb
2025-11-28 15:12:30,384:INFO:self._variable_keys: {'USI', 'memory', '_ml_usecase', 'data', 'logging_param', 'target_param', 'y_test', 'gpu_param', 'fix_imbalance', 'exp_id', 'gpu_n_jobs_param', 'seed', 'fold_shuffle_param', 'log_plots_param', 'X', 'is_multiclass', 'pipeline', 'y', 'fold_groups_param', 'X_test', 'n_jobs_param', 'idx', 'X_train', '_available_plots', 'exp_name_log', 'y_train', 'fold_generator', 'html_param'}
2025-11-28 15:12:30,384:INFO:Checking environment
2025-11-28 15:12:30,384:INFO:python_version: 3.10.19
2025-11-28 15:12:30,384:INFO:python_build: ('main', 'Oct 22 2025 22:23:22')
2025-11-28 15:12:30,384:INFO:machine: AMD64
2025-11-28 15:12:30,384:INFO:platform: Windows-10-10.0.26200-SP0
2025-11-28 15:12:30,384:INFO:Memory: svmem(total=16282144768, available=1869496320, percent=88.5, used=14412648448, free=1869496320)
2025-11-28 15:12:30,384:INFO:Physical Core: 6
2025-11-28 15:12:30,384:INFO:Logical Core: 12
2025-11-28 15:12:30,384:INFO:Checking libraries
2025-11-28 15:12:30,384:INFO:System:
2025-11-28 15:12:30,384:INFO:    python: 3.10.19 | packaged by conda-forge | (main, Oct 22 2025, 22:23:22) [MSC v.1944 64 bit (AMD64)]
2025-11-28 15:12:30,384:INFO:executable: c:\Users\OMAR\miniconda3\envs\xgb_env\python.exe
2025-11-28 15:12:30,384:INFO:   machine: Windows-10-10.0.26200-SP0
2025-11-28 15:12:30,384:INFO:PyCaret required dependencies:
2025-11-28 15:12:30,386:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-28 15:12:30,448:INFO:                 pip: 25.3
2025-11-28 15:12:30,448:INFO:          setuptools: 80.9.0
2025-11-28 15:12:30,448:INFO:             pycaret: 3.3.2
2025-11-28 15:12:30,448:INFO:             IPython: 8.37.0
2025-11-28 15:12:30,448:INFO:          ipywidgets: 8.1.8
2025-11-28 15:12:30,448:INFO:                tqdm: 4.67.1
2025-11-28 15:12:30,448:INFO:               numpy: 1.26.4
2025-11-28 15:12:30,449:INFO:              pandas: 2.1.4
2025-11-28 15:12:30,449:INFO:              jinja2: 3.1.6
2025-11-28 15:12:30,449:INFO:               scipy: 1.11.4
2025-11-28 15:12:30,449:INFO:              joblib: 1.3.2
2025-11-28 15:12:30,449:INFO:             sklearn: 1.4.2
2025-11-28 15:12:30,449:INFO:                pyod: 2.0.5
2025-11-28 15:12:30,449:INFO:            imblearn: 0.14.0
2025-11-28 15:12:30,449:INFO:   category_encoders: 2.7.0
2025-11-28 15:12:30,449:INFO:            lightgbm: 4.6.0
2025-11-28 15:12:30,449:INFO:               numba: 0.62.1
2025-11-28 15:12:30,449:INFO:            requests: 2.32.5
2025-11-28 15:12:30,449:INFO:          matplotlib: 3.7.5
2025-11-28 15:12:30,449:INFO:          scikitplot: 0.3.7
2025-11-28 15:12:30,449:INFO:         yellowbrick: 1.5
2025-11-28 15:12:30,449:INFO:              plotly: 6.5.0
2025-11-28 15:12:30,449:INFO:    plotly-resampler: Not installed
2025-11-28 15:12:30,449:INFO:             kaleido: 1.2.0
2025-11-28 15:12:30,449:INFO:           schemdraw: 0.15
2025-11-28 15:12:30,449:INFO:         statsmodels: 0.14.5
2025-11-28 15:12:30,449:INFO:              sktime: 0.26.0
2025-11-28 15:12:30,449:INFO:               tbats: 1.1.3
2025-11-28 15:12:30,449:INFO:            pmdarima: 2.0.4
2025-11-28 15:12:30,449:INFO:              psutil: 7.1.3
2025-11-28 15:12:30,449:INFO:          markupsafe: 3.0.3
2025-11-28 15:12:30,449:INFO:             pickle5: Not installed
2025-11-28 15:12:30,449:INFO:         cloudpickle: 3.1.2
2025-11-28 15:12:30,449:INFO:         deprecation: 2.1.0
2025-11-28 15:12:30,449:INFO:              xxhash: 3.6.0
2025-11-28 15:12:30,449:INFO:           wurlitzer: Not installed
2025-11-28 15:12:30,449:INFO:PyCaret optional dependencies:
2025-11-28 15:12:30,497:INFO:                shap: 0.48.0
2025-11-28 15:12:30,497:INFO:           interpret: Not installed
2025-11-28 15:12:30,497:INFO:                umap: Not installed
2025-11-28 15:12:30,497:INFO:     ydata_profiling: Not installed
2025-11-28 15:12:30,497:INFO:  explainerdashboard: Not installed
2025-11-28 15:12:30,497:INFO:             autoviz: Not installed
2025-11-28 15:12:30,497:INFO:           fairlearn: 0.12.0.dev0
2025-11-28 15:12:30,497:INFO:          deepchecks: Not installed
2025-11-28 15:12:30,497:INFO:             xgboost: 3.1.2
2025-11-28 15:12:30,497:INFO:            catboost: Not installed
2025-11-28 15:12:30,497:INFO:              kmodes: Not installed
2025-11-28 15:12:30,497:INFO:             mlxtend: Not installed
2025-11-28 15:12:30,497:INFO:       statsforecast: Not installed
2025-11-28 15:12:30,497:INFO:        tune_sklearn: Not installed
2025-11-28 15:12:30,497:INFO:                 ray: Not installed
2025-11-28 15:12:30,498:INFO:            hyperopt: Not installed
2025-11-28 15:12:30,498:INFO:              optuna: Not installed
2025-11-28 15:12:30,498:INFO:               skopt: Not installed
2025-11-28 15:12:30,498:INFO:              mlflow: Not installed
2025-11-28 15:12:30,498:INFO:              gradio: Not installed
2025-11-28 15:12:30,498:INFO:             fastapi: Not installed
2025-11-28 15:12:30,498:INFO:             uvicorn: Not installed
2025-11-28 15:12:30,498:INFO:              m2cgen: Not installed
2025-11-28 15:12:30,498:INFO:           evidently: Not installed
2025-11-28 15:12:30,498:INFO:               fugue: Not installed
2025-11-28 15:12:30,498:INFO:           streamlit: 1.51.0
2025-11-28 15:12:30,498:INFO:             prophet: Not installed
2025-11-28 15:12:30,498:INFO:None
2025-11-28 15:12:30,498:INFO:Set up data.
2025-11-28 15:43:51,874:INFO:PyCaret ClassificationExperiment
2025-11-28 15:43:51,874:INFO:Logging name: clf-default-name
2025-11-28 15:43:51,874:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-11-28 15:43:51,874:INFO:version 3.3.2
2025-11-28 15:43:51,874:INFO:Initializing setup()
2025-11-28 15:43:51,874:INFO:self.USI: 3f34
2025-11-28 15:43:51,874:INFO:self._variable_keys: {'USI', 'memory', '_ml_usecase', 'data', 'logging_param', 'target_param', 'y_test', 'gpu_param', 'fix_imbalance', 'exp_id', 'gpu_n_jobs_param', 'seed', 'fold_shuffle_param', 'log_plots_param', 'X', 'is_multiclass', 'pipeline', 'y', 'fold_groups_param', 'X_test', 'n_jobs_param', 'idx', 'X_train', '_available_plots', 'exp_name_log', 'y_train', 'fold_generator', 'html_param'}
2025-11-28 15:43:51,874:INFO:Checking environment
2025-11-28 15:43:51,874:INFO:python_version: 3.10.19
2025-11-28 15:43:51,874:INFO:python_build: ('main', 'Oct 22 2025 22:23:22')
2025-11-28 15:43:51,874:INFO:machine: AMD64
2025-11-28 15:43:51,874:INFO:platform: Windows-10-10.0.26200-SP0
2025-11-28 15:43:51,874:INFO:Memory: svmem(total=16282144768, available=2224078848, percent=86.3, used=14058065920, free=2224078848)
2025-11-28 15:43:51,874:INFO:Physical Core: 6
2025-11-28 15:43:51,874:INFO:Logical Core: 12
2025-11-28 15:43:51,874:INFO:Checking libraries
2025-11-28 15:43:51,874:INFO:System:
2025-11-28 15:43:51,874:INFO:    python: 3.10.19 | packaged by conda-forge | (main, Oct 22 2025, 22:23:22) [MSC v.1944 64 bit (AMD64)]
2025-11-28 15:43:51,874:INFO:executable: c:\Users\OMAR\miniconda3\envs\xgb_env\python.exe
2025-11-28 15:43:51,874:INFO:   machine: Windows-10-10.0.26200-SP0
2025-11-28 15:43:51,874:INFO:PyCaret required dependencies:
2025-11-28 15:43:51,874:INFO:                 pip: 25.3
2025-11-28 15:43:51,874:INFO:          setuptools: 80.9.0
2025-11-28 15:43:51,874:INFO:             pycaret: 3.3.2
2025-11-28 15:43:51,874:INFO:             IPython: 8.37.0
2025-11-28 15:43:51,874:INFO:          ipywidgets: 8.1.8
2025-11-28 15:43:51,874:INFO:                tqdm: 4.67.1
2025-11-28 15:43:51,874:INFO:               numpy: 1.26.4
2025-11-28 15:43:51,874:INFO:              pandas: 2.1.4
2025-11-28 15:43:51,874:INFO:              jinja2: 3.1.6
2025-11-28 15:43:51,874:INFO:               scipy: 1.11.4
2025-11-28 15:43:51,874:INFO:              joblib: 1.3.2
2025-11-28 15:43:51,874:INFO:             sklearn: 1.4.2
2025-11-28 15:43:51,874:INFO:                pyod: 2.0.5
2025-11-28 15:43:51,874:INFO:            imblearn: 0.14.0
2025-11-28 15:43:51,874:INFO:   category_encoders: 2.7.0
2025-11-28 15:43:51,874:INFO:            lightgbm: 4.6.0
2025-11-28 15:43:51,874:INFO:               numba: 0.62.1
2025-11-28 15:43:51,874:INFO:            requests: 2.32.5
2025-11-28 15:43:51,874:INFO:          matplotlib: 3.7.5
2025-11-28 15:43:51,874:INFO:          scikitplot: 0.3.7
2025-11-28 15:43:51,874:INFO:         yellowbrick: 1.5
2025-11-28 15:43:51,874:INFO:              plotly: 6.5.0
2025-11-28 15:43:51,874:INFO:    plotly-resampler: Not installed
2025-11-28 15:43:51,874:INFO:             kaleido: 1.2.0
2025-11-28 15:43:51,874:INFO:           schemdraw: 0.15
2025-11-28 15:43:51,874:INFO:         statsmodels: 0.14.5
2025-11-28 15:43:51,874:INFO:              sktime: 0.26.0
2025-11-28 15:43:51,874:INFO:               tbats: 1.1.3
2025-11-28 15:43:51,874:INFO:            pmdarima: 2.0.4
2025-11-28 15:43:51,874:INFO:              psutil: 7.1.3
2025-11-28 15:43:51,874:INFO:          markupsafe: 3.0.3
2025-11-28 15:43:51,874:INFO:             pickle5: Not installed
2025-11-28 15:43:51,878:INFO:         cloudpickle: 3.1.2
2025-11-28 15:43:51,878:INFO:         deprecation: 2.1.0
2025-11-28 15:43:51,878:INFO:              xxhash: 3.6.0
2025-11-28 15:43:51,878:INFO:           wurlitzer: Not installed
2025-11-28 15:43:51,878:INFO:PyCaret optional dependencies:
2025-11-28 15:43:51,878:INFO:                shap: 0.48.0
2025-11-28 15:43:51,878:INFO:           interpret: Not installed
2025-11-28 15:43:51,878:INFO:                umap: Not installed
2025-11-28 15:43:51,878:INFO:     ydata_profiling: Not installed
2025-11-28 15:43:51,878:INFO:  explainerdashboard: Not installed
2025-11-28 15:43:51,879:INFO:             autoviz: Not installed
2025-11-28 15:43:51,879:INFO:           fairlearn: 0.12.0.dev0
2025-11-28 15:43:51,879:INFO:          deepchecks: Not installed
2025-11-28 15:43:51,879:INFO:             xgboost: 3.1.2
2025-11-28 15:43:51,879:INFO:            catboost: Not installed
2025-11-28 15:43:51,879:INFO:              kmodes: Not installed
2025-11-28 15:43:51,879:INFO:             mlxtend: Not installed
2025-11-28 15:43:51,879:INFO:       statsforecast: Not installed
2025-11-28 15:43:51,879:INFO:        tune_sklearn: Not installed
2025-11-28 15:43:51,879:INFO:                 ray: Not installed
2025-11-28 15:43:51,879:INFO:            hyperopt: Not installed
2025-11-28 15:43:51,879:INFO:              optuna: Not installed
2025-11-28 15:43:51,879:INFO:               skopt: Not installed
2025-11-28 15:43:51,879:INFO:              mlflow: Not installed
2025-11-28 15:43:51,879:INFO:              gradio: Not installed
2025-11-28 15:43:51,879:INFO:             fastapi: Not installed
2025-11-28 15:43:51,879:INFO:             uvicorn: Not installed
2025-11-28 15:43:51,879:INFO:              m2cgen: Not installed
2025-11-28 15:43:51,879:INFO:           evidently: Not installed
2025-11-28 15:43:51,879:INFO:               fugue: Not installed
2025-11-28 15:43:51,879:INFO:           streamlit: 1.51.0
2025-11-28 15:43:51,879:INFO:             prophet: Not installed
2025-11-28 15:43:51,879:INFO:None
2025-11-28 15:43:51,879:INFO:Set up data.
2025-11-28 15:43:55,003:INFO:Set up folding strategy.
2025-11-28 15:43:55,004:INFO:Set up train/test split.
2025-11-28 15:43:57,481:INFO:Set up index.
2025-11-28 15:43:57,553:INFO:Assigning column types.
2025-11-28 15:43:59,879:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-11-28 15:43:59,909:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-11-28 15:43:59,914:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-11-28 15:43:59,941:INFO:Soft dependency imported: xgboost: 3.1.2
2025-11-28 15:43:59,944:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-28 15:43:59,967:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-11-28 15:43:59,967:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-11-28 15:43:59,986:INFO:Soft dependency imported: xgboost: 3.1.2
2025-11-28 15:43:59,986:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-28 15:43:59,986:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-11-28 15:44:00,017:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-11-28 15:44:00,029:INFO:Soft dependency imported: xgboost: 3.1.2
2025-11-28 15:44:00,035:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-28 15:44:00,062:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-11-28 15:44:00,079:INFO:Soft dependency imported: xgboost: 3.1.2
2025-11-28 15:44:00,081:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-28 15:44:00,081:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-11-28 15:44:00,124:INFO:Soft dependency imported: xgboost: 3.1.2
2025-11-28 15:44:00,126:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-28 15:44:00,167:INFO:Soft dependency imported: xgboost: 3.1.2
2025-11-28 15:44:00,171:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-28 15:44:00,174:INFO:Preparing preprocessing pipeline...
2025-11-28 15:44:00,495:INFO:Set up simple imputation.
2025-11-28 15:44:01,277:INFO:Set up encoding of ordinal features.
2025-11-28 15:44:01,890:INFO:Set up encoding of categorical features.
2025-11-28 15:44:01,909:INFO:Set up imbalanced handling.
2025-11-28 15:44:06,298:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 15:44:18,641:INFO:Finished creating preprocessing pipeline.
2025-11-28 15:44:18,665:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\OMAR\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['STATE', 'FMONTH', 'DISPCODE',
                                             'PSU', 'CTELENM1', 'PVTRESD1',
                                             'COLGHOUS', 'STATERE1', 'CELPHON1',
                                             'LADULT1', 'COLGSEX1', 'NUMADULT',
                                             'LANDSEX1', 'NUMMEN', 'NUMWOMEN',
                                             'RESPSLCT', 'SAFETIME', 'CTELNUM1',
                                             'CELLFON5', 'CADULT1...
                                    transformer=TargetEncoder(cols=['IDATE',
                                                                    'IDAY'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              random_state=42,
                                                                              sampling_strategy='auto'))))],
         verbose=False)
2025-11-28 15:44:18,665:INFO:Creating final display dataframe.
2025-11-28 15:44:27,298:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\joblib\externals\loky\backend\context.py:136: UserWarning: Could not find the number of physical cores for the following reason:
[WinError 2] El sistema no puede encontrar el archivo especificado
Returning the number of logical cores instead. You can silence this warning by setting LOKY_MAX_CPU_COUNT to the number of cores you want to use.
  warnings.warn(

2025-11-28 15:44:38,246:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 15:45:00,340:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target          CVDINFR4
2                   Target type            Binary
3           Original data shape     (442067, 327)
4        Transformed data shape     (716361, 335)
5   Transformed train set shape     (583740, 335)
6    Transformed test set shape     (132621, 335)
7              Numeric features               322
8          Categorical features                 4
9      Rows with missing values            100.0%
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16                Fix imbalance              True
17         Fix imbalance method             SMOTE
18               Fold Generator   StratifiedKFold
19                  Fold Number                10
20                     CPU Jobs                -1
21                      Use GPU             False
22               Log Experiment             False
23              Experiment Name  clf-default-name
24                          USI              3f34
2025-11-28 15:45:00,390:INFO:Soft dependency imported: xgboost: 3.1.2
2025-11-28 15:45:00,393:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-28 15:45:00,437:INFO:Soft dependency imported: xgboost: 3.1.2
2025-11-28 15:45:00,440:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-28 15:45:00,441:INFO:setup() successfully completed in 68.57s...............
2025-11-28 15:45:00,448:INFO:Initializing get_config()
2025-11-28 15:45:00,448:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000205440814E0>, variable=X_train)
2025-11-28 15:45:00,448:INFO:Variable: 'X_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_train_transformed' instead.
2025-11-28 15:45:00,452:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'X_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_train_transformed' instead.
  warnings.warn(msg)  # print on screen

2025-11-28 15:45:01,658:INFO:Variable:  returned as         STATE  FMONTH     IDATE IMONTH IDAY IYEAR  DISPCODE           PSU  \
72923    12.0    10.0  12082022     12   08  2022    1200.0  2.022010e+09   
240937   33.0     3.0  03242022     03   24  2022    1100.0  2.022004e+09   
359568   49.0     1.0  03092022     03   09  2022    1100.0  2.022002e+09   
26678     6.0     1.0  02242022     02   24  2022    1200.0  2.022000e+09   
392399   53.0    12.0  12172022     12   17  2022    1200.0  2.022001e+09   
...       ...     ...       ...    ...  ...   ...       ...           ...   
340098   47.0     2.0  03152022     03   15  2022    1100.0  2.022002e+09   
212124   29.0     1.0  02062022     02   06  2022    1100.0  2.022001e+09   
78203    13.0    10.0  10212022     10   21  2022    1100.0  2.022002e+09   
167309   24.0     5.0  05092022     05   09  2022    1100.0  2.022013e+09   
313531   42.0     3.0  07272022     07   27  2022    1100.0  2.022003e+09   

        CTELENM1  PVTRESD1  COLGHOUS  STATERE1  CELPHON1  LADULT1  COLGSEX1  \
72923        NaN       NaN       NaN       NaN       NaN      NaN       NaN   
240937       NaN       NaN       NaN       NaN       NaN      NaN       NaN   
359568       NaN       NaN       NaN       NaN       NaN      NaN       NaN   
26678        NaN       NaN       NaN       NaN       NaN      NaN       NaN   
392399       NaN       NaN       NaN       NaN       NaN      NaN       NaN   
...          ...       ...       ...       ...       ...      ...       ...   
340098       NaN       NaN       NaN       NaN       NaN      NaN       NaN   
212124       1.0       1.0       NaN       1.0       2.0      1.0       NaN   
78203        1.0       1.0       NaN       1.0       2.0      1.0       NaN   
167309       NaN       NaN       NaN       NaN       NaN      NaN       NaN   
313531       NaN       NaN       NaN       NaN       NaN      NaN       NaN   

        NUMADULT  LANDSEX1  NUMMEN  NUMWOMEN  RESPSLCT  SAFETIME  CTELNUM1  \
72923        NaN       NaN     NaN       NaN       NaN       1.0       1.0   
240937       NaN       NaN     NaN       NaN       NaN       1.0       1.0   
359568       NaN       NaN     NaN       NaN       NaN       1.0       1.0   
26678        NaN       NaN     NaN       NaN       NaN       1.0       1.0   
392399       NaN       NaN     NaN       NaN       NaN       1.0       1.0   
...          ...       ...     ...       ...       ...       ...       ...   
340098       NaN       NaN     NaN       NaN       NaN       1.0       1.0   
212124       1.0       2.0     NaN       NaN       NaN       NaN       NaN   
78203        1.0       2.0     NaN       NaN       NaN       NaN       NaN   
167309       NaN       NaN     NaN       NaN       NaN       1.0       1.0   
313531       NaN       NaN     NaN       NaN       NaN       1.0       1.0   

        CELLFON5  CADULT1  CELLSEX1  PVTRESD3  CCLGHOUS  CSTATE1  LANDLINE  \
72923        1.0      1.0       2.0       1.0       NaN      1.0       1.0   
240937       1.0      1.0       1.0       1.0       NaN      1.0       1.0   
359568       1.0      1.0       2.0       1.0       NaN      1.0       2.0   
26678        1.0      1.0       1.0       1.0       NaN      2.0       2.0   
392399       1.0      1.0       1.0       1.0       NaN      2.0       2.0   
...          ...      ...       ...       ...       ...      ...       ...   
340098       1.0      1.0       1.0       1.0       NaN      1.0       2.0   
212124       NaN      NaN       NaN       NaN       NaN      NaN       NaN   
78203        NaN      NaN       NaN       NaN       NaN      NaN       NaN   
167309       1.0      1.0       1.0       1.0       NaN      1.0       2.0   
313531       1.0      1.0       1.0       1.0       NaN      1.0       2.0   

        HHADULT  SEXVAR  GENHLTH  PHYSHLTH  MENTHLTH  POORHLTH  PRIMINSR  \
72923       4.0     2.0      1.0      88.0      88.0       NaN      99.0   
240937      1.0     1.0      5.0      30.0       1.0      30.0       5.0   
359568      3.0     2.0      3.0      20.0       5.0      88.0       3.0   
26678       4.0     1.0      3.0       2.0      25.0      88.0       1.0   
392399      4.0     1.0      3.0       3.0      88.0      88.0       1.0   
...         ...     ...      ...       ...       ...       ...       ...   
340098      3.0     1.0      1.0      88.0      88.0       NaN       1.0   
212124      NaN     2.0      2.0      88.0      88.0       NaN       9.0   
78203       NaN     2.0      4.0      20.0      88.0      88.0       2.0   
167309      3.0     1.0      2.0       1.0      88.0      88.0       1.0   
313531      1.0     1.0      2.0       2.0      25.0       6.0       1.0   

        PERSDOC3  MEDCOST1  CHECKUP1  EXERANY2  SLEPTIM1  LASTDEN4  RMVTETH4  \
72923        2.0       2.0       1.0       1.0       7.0       2.0       8.0   
240937       3.0       1.0       1.0       1.0       9.0       2.0       2.0   
359568       1.0       2.0       1.0       1.0       5.0       2.0       1.0   
26678        3.0       2.0       2.0       1.0       7.0       1.0       8.0   
392399       2.0       2.0       1.0       1.0       5.0       1.0       2.0   
...          ...       ...       ...       ...       ...       ...       ...   
340098       3.0       2.0       4.0       1.0       6.0       2.0       1.0   
212124       1.0       2.0       1.0       1.0       8.0       3.0       2.0   
78203        2.0       2.0       1.0       2.0       6.0       1.0       2.0   
167309       2.0       2.0       1.0       1.0       7.0       1.0       1.0   
313531       3.0       2.0       3.0       1.0       9.0       2.0       8.0   

        CVDCRHD4  CVDSTRK3  ASTHMA3  ASTHNOW  CHCSCNC1  CHCOCNC1  CHCCOPD3  \
72923        2.0       2.0      2.0      NaN       2.0       2.0       2.0   
240937       2.0       2.0      2.0      NaN       2.0       2.0       2.0   
359568       2.0       2.0      2.0      NaN       2.0       2.0       2.0   
26678        2.0       2.0      1.0      1.0       2.0       2.0       2.0   
392399       2.0       2.0      2.0      NaN       2.0       2.0       2.0   
...          ...       ...      ...      ...       ...       ...       ...   
340098       2.0       2.0      2.0      NaN       2.0       2.0       2.0   
212124       2.0       2.0      2.0      NaN       1.0       1.0       2.0   
78203        2.0       1.0      2.0      NaN       2.0       2.0       2.0   
167309       2.0       2.0      2.0      NaN       2.0       2.0       2.0   
313531       2.0       2.0      2.0      NaN       2.0       2.0       2.0   

        ADDEPEV3  CHCKDNY2  HAVARTH4  DIABETE4  DIABAGE4  MARITAL  EDUCA  \
72923        2.0       2.0       2.0       3.0       NaN      9.0    9.0   
240937       2.0       2.0       2.0       1.0      60.0      5.0    5.0   
359568       2.0       2.0       1.0       3.0       NaN      1.0    5.0   
26678        2.0       2.0       2.0       3.0       NaN      6.0    4.0   
392399       2.0       2.0       2.0       1.0      55.0      2.0    6.0   
...          ...       ...       ...       ...       ...      ...    ...   
340098       2.0       2.0       2.0       3.0       NaN      1.0    3.0   
212124       2.0       2.0       1.0       3.0       NaN      3.0    4.0   
78203        2.0       2.0       1.0       3.0       NaN      3.0    4.0   
167309       2.0       2.0       1.0       3.0       NaN      1.0    6.0   
313531       2.0       2.0       2.0       3.0       NaN      5.0    5.0   

        RENTHOM1  NUMHHOL4  NUMPHON4  CPDEMO1C  VETERAN3  EMPLOY1  CHILDREN  \
72923        9.0       NaN       NaN       9.0       2.0      1.0      88.0   
240937       1.0       NaN       NaN       1.0       2.0      8.0      88.0   
359568       1.0       NaN       NaN       1.0       2.0      7.0      88.0   
26678        2.0       NaN       NaN       9.0       1.0      1.0      99.0   
392399       2.0       NaN       NaN       1.0       2.0      1.0      88.0   
...          ...       ...       ...       ...       ...      ...       ...   
340098       1.0       NaN       NaN       1.0       2.0      1.0       1.0   
212124       1.0       2.0       NaN       1.0       2.0      7.0      88.0   
78203        2.0       2.0       NaN       1.0       2.0      7.0      88.0   
167309       1.0       NaN       NaN       1.0       2.0      1.0      88.0   
313531       2.0       NaN       NaN       1.0       2.0      1.0      88.0   

        INCOME3  PREGNANT  WEIGHT2  HEIGHT3  DEAF  BLIND  DECIDE  DIFFWALK  \
72923      99.0       NaN   9999.0   9999.0   2.0    2.0     2.0       2.0   
240937      2.0       NaN    130.0    507.0   2.0    2.0     2.0       2.0   
359568      7.0       NaN    198.0    505.0   2.0    2.0     1.0       2.0   
26678      99.0       NaN    140.0    508.0   2.0    2.0     9.0       2.0   
392399      9.0       NaN    220.0    601.0   2.0    2.0     2.0       2.0   
...         ...       ...      ...      ...   ...    ...     ...       ...   
340098      8.0       NaN    140.0    509.0   2.0    2.0     2.0       2.0   
212124      4.0       NaN    148.0    504.0   2.0    2.0     2.0       2.0   
78203      99.0       NaN   9999.0   9999.0   9.0    9.0     2.0       2.0   
167309     11.0       NaN    192.0    600.0   2.0    2.0     2.0       2.0   
313531     11.0       NaN    155.0    601.0   2.0    2.0     2.0       2.0   

        DIFFDRES  DIFFALON  HADMAM  HOWLONG  CERVSCRN  CRVCLCNC  CRVCLPAP  \
72923        2.0       NaN     NaN      NaN       NaN       NaN       NaN   
240937       1.0       1.0     NaN      NaN       NaN       NaN       NaN   
359568       2.0       1.0     1.0      7.0       1.0       5.0       1.0   
26678        2.0       2.0     NaN      NaN       NaN       NaN       NaN   
392399       2.0       2.0     NaN      NaN       NaN       NaN       NaN   
...          ...       ...     ...      ...       ...       ...       ...   
340098       2.0       2.0     NaN      NaN       NaN       NaN       NaN   
212124       2.0       2.0     1.0      1.0       1.0       5.0       1.0   
78203        2.0       2.0     1.0      1.0       1.0       2.0       7.0   
167309       2.0       2.0     NaN      NaN       NaN       NaN       NaN   
313531       2.0       2.0     NaN      NaN       NaN       NaN       NaN   

        CRVCLHPV  HADHYST2  HADSIGM4  COLNSIGM  COLNTES1  SIGMTES1  LASTSIG4  \
72923        NaN       NaN       NaN       NaN       NaN       NaN       NaN   
240937       NaN       NaN       1.0       1.0       2.0       NaN       NaN   
359568       2.0       1.0       1.0       1.0       4.0       NaN       NaN   
26678        NaN       NaN       NaN       NaN       NaN       NaN       NaN   
392399       NaN       NaN       2.0       NaN       NaN       NaN       NaN   
...          ...       ...       ...       ...       ...       ...       ...   
340098       NaN       NaN       2.0       NaN       NaN       NaN       NaN   
212124       7.0       1.0       1.0       1.0       4.0       NaN       NaN   
78203        2.0       1.0       1.0       3.0       2.0       1.0       NaN   
167309       NaN       NaN       2.0       NaN       NaN       NaN       NaN   
313531       NaN       NaN       NaN       NaN       NaN       NaN       NaN   

        COLNCNCR  VIRCOLO1  VCLNTES2  SMALSTOL  STOLTEST  STOOLDN2  BLDSTFIT  \
72923        NaN       NaN       NaN       NaN       NaN       NaN       NaN   
240937       1.0       2.0       NaN       2.0       NaN       2.0       NaN   
359568       1.0       1.0       4.0       1.0       4.0       2.0       NaN   
26678        NaN       NaN       NaN       NaN       NaN       NaN       NaN   
392399       2.0       NaN       NaN       NaN       NaN       NaN       NaN   
...          ...       ...       ...       ...       ...       ...       ...   
340098       2.0       NaN       NaN       NaN       NaN       NaN       NaN   
212124       2.0       NaN       NaN       NaN       NaN       NaN       NaN   
78203        2.0       NaN       NaN       NaN       NaN       NaN       NaN   
167309       1.0       2.0       NaN       1.0       1.0       1.0       2.0   
313531       NaN       NaN       NaN       NaN       NaN       NaN       NaN   

        SDNATES1  SMOKE100  SMOKDAY2  USENOW3  ECIGNOW2  LCSFIRST  LCSLAST  \
72923        NaN       NaN       NaN      NaN       NaN       NaN      NaN   
240937       NaN       1.0       1.0      3.0       4.0      45.0      NaN   
359568       NaN       2.0       NaN      3.0       1.0       NaN      NaN   
26678        NaN       2.0       NaN      3.0       1.0       NaN      NaN   
392399       NaN       2.0       NaN      3.0       4.0       NaN      NaN   
...          ...       ...       ...      ...       ...       ...      ...   
340098       NaN       1.0       3.0      3.0       2.0      12.0     40.0   
212124       NaN       1.0       3.0      3.0       1.0      16.0     27.0   
78203        NaN       1.0       3.0      3.0       1.0      40.0     60.0   
167309       1.0       2.0       NaN      3.0       1.0       NaN      NaN   
313531       NaN       2.0       NaN      3.0       1.0       NaN      NaN   

        LCSNUMCG  LCSCTSC1  LCSSCNCR  LCSCTWHN  ALCDAY4  AVEDRNK3  DRNK3GE5  \
72923        NaN       NaN       NaN       NaN      NaN       NaN       NaN   
240937      10.0       1.0       2.0       NaN    203.0       1.0      88.0   
359568       NaN       2.0       NaN       NaN    888.0       NaN       NaN   
26678        NaN       2.0       NaN       NaN    888.0       NaN       NaN   
392399       NaN       2.0       NaN       NaN    888.0       NaN       NaN   
...          ...       ...       ...       ...      ...       ...       ...   
340098      40.0       1.0       2.0       NaN    888.0       NaN       NaN   
212124      15.0       1.0       2.0       NaN    888.0       NaN       NaN   
78203        2.0       1.0       2.0       NaN    888.0       NaN       NaN   
167309       NaN       1.0       2.0       NaN    103.0       3.0       2.0   
313531       NaN       1.0       2.0       NaN    103.0       3.0       4.0   

        MAXDRNKS  FLUSHOT7  FLSHTMY3  PNEUVAC4  TETANUS1  HIVTST7  HIVTSTD3  \
72923        NaN       NaN       NaN       NaN       NaN      NaN       NaN   
240937       2.0       2.0       NaN       2.0       3.0      1.0   31999.0   
359568       NaN       1.0   92021.0       2.0       2.0      2.0       NaN   
26678        NaN       1.0  999999.0       2.0       3.0      1.0  777777.0   
392399       NaN       2.0       NaN       2.0       4.0      2.0       NaN   
...          ...       ...       ...       ...       ...      ...       ...   
340098       NaN       2.0       NaN       2.0       3.0      2.0       NaN   
212124       NaN       1.0  102021.0       1.0       4.0      2.0       NaN   
78203        NaN       1.0  777777.0       1.0       4.0      2.0       NaN   
167309       6.0       1.0  112021.0       2.0       4.0      1.0  772015.0   
313531      12.0       1.0  102021.0       7.0       3.0      2.0       NaN   

        HIVRISK5  COVIDPOS  COVIDSMP  COVIDPRM  PDIABTS1  PREDIAB2  DIABTYPE  \
72923        NaN       NaN       NaN       NaN       NaN       NaN       NaN   
240937       2.0       2.0       NaN       NaN       NaN       NaN       NaN   
359568       2.0       1.0       2.0       NaN       NaN       NaN       NaN   
26678        2.0       2.0       NaN       NaN       NaN       NaN       NaN   
392399       2.0       2.0       NaN       NaN       NaN       NaN       NaN   
...          ...       ...       ...       ...       ...       ...       ...   
340098       2.0       2.0       NaN       NaN       NaN       NaN       NaN   
212124       2.0       2.0       NaN       NaN       1.0       3.0       NaN   
78203        2.0       2.0       NaN       NaN       1.0       3.0       NaN   
167309       2.0       1.0       2.0       NaN       NaN       NaN       NaN   
313531       1.0       2.0       NaN       NaN       3.0       3.0       NaN   

        INSULIN1  CHKHEMO3  EYEEXAM1  DIABEYE1  DIABEDU1  FEETSORE  TOLDCFS  \
72923        NaN       NaN       NaN       NaN       NaN       NaN      NaN   
240937       NaN       NaN       NaN       NaN       NaN       NaN      NaN   
359568       NaN       NaN       NaN       NaN       NaN       NaN      NaN   
26678        NaN       NaN       NaN       NaN       NaN       NaN      NaN   
392399       NaN       NaN       NaN       NaN       NaN       NaN      NaN   
...          ...       ...       ...       ...       ...       ...      ...   
340098       NaN       NaN       NaN       NaN       NaN       NaN      NaN   
212124       NaN       NaN       NaN       NaN       NaN       NaN      NaN   
78203        NaN       NaN       NaN       NaN       NaN       NaN      NaN   
167309       NaN       NaN       NaN       NaN       NaN       NaN      NaN   
313531       NaN       NaN       NaN       NaN       NaN       NaN      NaN   

        HAVECFS  WORKCFS  IMFVPLA3  HPVADVC4  HPVADSHT  SHINGLE2  COVIDVA1  \
72923       NaN      NaN       NaN       NaN       NaN       NaN       NaN   
240937      NaN      NaN       NaN       NaN       NaN       NaN       2.0   
359568      NaN      NaN       NaN       NaN       NaN       NaN       NaN   
26678       NaN      NaN       NaN       NaN       NaN       NaN       NaN   
392399      NaN      NaN       NaN       NaN       NaN       NaN       NaN   
...         ...      ...       ...       ...       ...       ...       ...   
340098      NaN      NaN       NaN       NaN       NaN       NaN       2.0   
212124      NaN      NaN       NaN       NaN       NaN       NaN       NaN   
78203       NaN      NaN       1.0       NaN       NaN       2.0       1.0   
167309      NaN      NaN       NaN       NaN       NaN       NaN       NaN   
313531      NaN      NaN       NaN       NaN       NaN       NaN       NaN   

        COVACGET  COVIDNU1  COVIDINT  COVIDFS1  COVIDSE1  COPDCOGH  COPDFLEM  \
72923        NaN       NaN       NaN       NaN       NaN       NaN       NaN   
240937       3.0       NaN       NaN       NaN       NaN       NaN       NaN   
359568       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
26678        NaN       NaN       NaN       NaN       NaN       NaN       NaN   
392399       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
...          ...       ...       ...       ...       ...       ...       ...   
340098       4.0       NaN       NaN       NaN       NaN       NaN       NaN   
212124       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
78203        NaN       4.0       NaN   22021.0   52021.0       2.0       2.0   
167309       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
313531       NaN       NaN       NaN       NaN       NaN       NaN       NaN   

        COPDBRTH  COPDBTST  COPDSMOK  CNCRDIFF  CNCRAGE  CNCRTYP2  CSRVTRT3  \
72923        NaN       NaN       NaN       NaN      NaN       NaN       NaN   
240937       NaN       NaN       NaN       NaN      NaN       NaN       NaN   
359568       NaN       NaN       NaN       NaN      NaN       NaN       NaN   
26678        NaN       NaN       NaN       NaN      NaN       NaN       NaN   
392399       NaN       NaN       NaN       NaN      NaN       NaN       NaN   
...          ...       ...       ...       ...      ...       ...       ...   
340098       NaN       NaN       NaN       NaN      NaN       NaN       NaN   
212124       NaN       NaN       NaN       2.0     72.0       5.0       2.0   
78203        1.0       2.0      10.0       NaN      NaN       NaN       NaN   
167309       NaN       NaN       NaN       NaN      NaN       NaN       NaN   
313531       NaN       NaN       NaN       NaN      NaN       NaN       NaN   

        CSRVDOC1  CSRVSUM  CSRVRTRN  CSRVINST  CSRVINSR  CSRVDEIN  CSRVCLIN  \
72923        NaN      NaN       NaN       NaN       NaN       NaN       NaN   
240937       NaN      NaN       NaN       NaN       NaN       NaN       NaN   
359568       NaN      NaN       NaN       NaN       NaN       NaN       NaN   
26678        NaN      NaN       NaN       NaN       NaN       NaN       NaN   
392399       NaN      NaN       NaN       NaN       NaN       NaN       NaN   
...          ...      ...       ...       ...       ...       ...       ...   
340098       NaN      NaN       NaN       NaN       NaN       NaN       NaN   
212124       2.0      2.0       2.0       NaN       1.0       2.0       2.0   
78203        NaN      NaN       NaN       NaN       NaN       NaN       NaN   
167309       NaN      NaN       NaN       NaN       NaN       NaN       NaN   
313531       NaN      NaN       NaN       NaN       NaN       NaN       NaN   

        CSRVPAIN  CSRVCTL2  PSATEST1  PSATIME1  PCPSARS2  PSASUGST  PCSTALK1  \
72923        NaN       NaN       NaN       NaN       NaN       NaN       NaN   
240937       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
359568       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
26678        NaN       NaN       NaN       NaN       NaN       NaN       NaN   
392399       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
...          ...       ...       ...       ...       ...       ...       ...   
340098       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
212124       2.0       NaN       NaN       NaN       NaN       NaN       NaN   
78203        NaN       NaN       NaN       NaN       NaN       NaN       NaN   
167309       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
313531       NaN       NaN       NaN       NaN       NaN       NaN       NaN   

        CIMEMLOS  CDHOUSE  CDASSIST  CDHELP  CDSOCIAL  CDDISCUS  CAREGIV1  \
72923        NaN      NaN       NaN     NaN       NaN       NaN       NaN   
240937       NaN      NaN       NaN     NaN       NaN       NaN       2.0   
359568       2.0      NaN       NaN     NaN       NaN       NaN       1.0   
26678        NaN      NaN       NaN     NaN       NaN       NaN       NaN   
392399       NaN      NaN       NaN     NaN       NaN       NaN       NaN   
...          ...      ...       ...     ...       ...       ...       ...   
340098       NaN      NaN       NaN     NaN       NaN       NaN       NaN   
212124       NaN      NaN       NaN     NaN       NaN       NaN       NaN   
78203        NaN      NaN       NaN     NaN       NaN       NaN       2.0   
167309       NaN      NaN       NaN     NaN       NaN       NaN       NaN   
313531       NaN      NaN       NaN     NaN       NaN       NaN       2.0   

        CRGVREL4  CRGVLNG1  CRGVHRS1  CRGVPRB3  CRGVALZD  CRGVPER1  CRGVHOU1  \
72923        NaN       NaN       NaN       NaN       NaN       NaN       NaN   
240937       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
359568       5.0       5.0       2.0      13.0       2.0       1.0       1.0   
26678        NaN       NaN       NaN       NaN       NaN       NaN       NaN   
392399       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
...          ...       ...       ...       ...       ...       ...       ...   
340098       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
212124       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
78203        NaN       NaN       NaN       NaN       NaN       NaN       NaN   
167309       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
313531       NaN       NaN       NaN       NaN       NaN       NaN       NaN   

        CRGVEXPT  ACEDEPRS  ACEDRINK  ACEDRUGS  ACEPRISN  ACEDIVRC  ACEPUNCH  \
72923        NaN       NaN       NaN       NaN       NaN       NaN       NaN   
240937       1.0       NaN       NaN       NaN       NaN       NaN       NaN   
359568       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
26678        NaN       NaN       NaN       NaN       NaN       NaN       NaN   
392399       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
...          ...       ...       ...       ...       ...       ...       ...   
340098       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
212124       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
78203        2.0       NaN       NaN       NaN       NaN       NaN       NaN   
167309       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
313531       2.0       NaN       NaN       NaN       NaN       NaN       NaN   

        ACEHURT1  ACESWEAR  ACETOUCH  ACETTHEM  ACEHVSEX  ACEADSAF  ACEADNED  \
72923        NaN       NaN       NaN       NaN       NaN       NaN       NaN   
240937       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
359568       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
26678        NaN       NaN       NaN       NaN       NaN       NaN       NaN   
392399       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
...          ...       ...       ...       ...       ...       ...       ...   
340098       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
212124       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
78203        NaN       NaN       NaN       NaN       NaN       NaN       NaN   
167309       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
313531       NaN       NaN       NaN       NaN       NaN       NaN       NaN   

        LSATISFY  EMTSUPRT  SDHISOLT  SDHEMPLY  FOODSTMP  SDHFOOD1  SDHBILLS  \
72923        NaN       NaN       NaN       NaN       NaN       NaN       NaN   
240937       2.0       1.0       5.0       2.0       1.0       2.0       2.0   
359568       1.0       1.0       5.0       2.0       2.0       5.0       2.0   
26678        NaN       NaN       NaN       NaN       NaN       NaN       NaN   
392399       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
...          ...       ...       ...       ...       ...       ...       ...   
340098       1.0       3.0       4.0       2.0       2.0       5.0       2.0   
212124       1.0       1.0       5.0       2.0       2.0       5.0       2.0   
78203        2.0       1.0       3.0       2.0       2.0       5.0       2.0   
167309       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
313531       NaN       NaN       NaN       NaN       NaN       NaN       NaN   

        SDHUTILS  SDHTRNSP  SDHSTRE1  MARIJAN1  MARJSMOK  MARJEAT  MARJVAPE  \
72923        NaN       NaN       NaN       NaN       NaN      NaN       NaN   
240937       2.0       1.0       4.0       NaN       NaN      NaN       NaN   
359568       2.0       2.0       2.0       NaN       NaN      NaN       NaN   
26678        NaN       NaN       NaN       NaN       NaN      NaN       NaN   
392399       NaN       NaN       NaN       NaN       NaN      NaN       NaN   
...          ...       ...       ...       ...       ...      ...       ...   
340098       2.0       2.0       3.0       NaN       NaN      NaN       NaN   
212124       2.0       2.0       5.0       NaN       NaN      NaN       NaN   
78203        2.0       2.0       3.0       NaN       NaN      NaN       NaN   
167309       NaN       NaN       NaN       NaN       NaN      NaN       NaN   
313531       NaN       NaN       NaN       NaN       NaN      NaN       NaN   

        MARJDAB  MARJOTHR  USEMRJN4  LASTSMK2  STOPSMK2  MENTCIGS  MENTECIG  \
72923       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
240937      NaN       NaN       NaN       NaN       NaN       NaN       NaN   
359568      NaN       NaN       NaN       NaN       NaN       NaN       NaN   
26678       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
392399      NaN       NaN       NaN       NaN       NaN       NaN       NaN   
...         ...       ...       ...       ...       ...       ...       ...   
340098      NaN       NaN       NaN       NaN       NaN       NaN       NaN   
212124      NaN       NaN       NaN       NaN       NaN       NaN       NaN   
78203       NaN       NaN       NaN       7.0       NaN       NaN       NaN   
167309      NaN       NaN       NaN       NaN       NaN       NaN       NaN   
313531      NaN       NaN       NaN       NaN       NaN       NaN       NaN   

        HEATTBCO  ASBIALCH  ASBIDRNK  ASBIBING  ASBIADVC  ASBIRDUC  FIREARM5  \
72923        NaN       NaN       NaN       NaN       NaN       NaN       NaN   
240937       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
359568       NaN       1.0       2.0       2.0       2.0       2.0       NaN   
26678        NaN       NaN       NaN       NaN       NaN       NaN       NaN   
392399       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
...          ...       ...       ...       ...       ...       ...       ...   
340098       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
212124       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
78203        NaN       NaN       NaN       NaN       NaN       NaN       NaN   
167309       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
313531       NaN       NaN       NaN       NaN       NaN       NaN       NaN   

        GUNLOAD  LOADULK2  RCSGEND1  RCSXBRTH  RCSRLTN2  CASTHDX2  CASTHNO2  \
72923       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
240937      NaN       NaN       NaN       NaN       NaN       NaN       NaN   
359568      NaN       NaN       NaN       NaN       NaN       NaN       NaN   
26678       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
392399      NaN       NaN       NaN       NaN       NaN       NaN       NaN   
...         ...       ...       ...       ...       ...       ...       ...   
340098      NaN       NaN       NaN       NaN       NaN       NaN       NaN   
212124      NaN       NaN       NaN       NaN       NaN       NaN       NaN   
78203       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
167309      NaN       NaN       NaN       NaN       NaN       NaN       NaN   
313531      NaN       NaN       NaN       NaN       NaN       NaN       NaN   

        BIRTHSEX  SOMALE  SOFEMALE  TRNSGNDR  HADSEX  PFPPRVN4  TYPCNTR9  \
72923        NaN     NaN       NaN       NaN     NaN       NaN       NaN   
240937       NaN     NaN       NaN       NaN     NaN       NaN       NaN   
359568       2.0     NaN       2.0       4.0     NaN       NaN       NaN   
26678        NaN     NaN       NaN       NaN     NaN       NaN       NaN   
392399       NaN     NaN       NaN       NaN     NaN       NaN       NaN   
...          ...     ...       ...       ...     ...       ...       ...   
340098       NaN     NaN       NaN       NaN     NaN       NaN       NaN   
212124       NaN     NaN       2.0       4.0     NaN       NaN       NaN   
78203        NaN     NaN       2.0       4.0     NaN       NaN       NaN   
167309       NaN     2.0       NaN       4.0     NaN       NaN       NaN   
313531       NaN     1.0       NaN       4.0     NaN       NaN       NaN   

        BRTHCNT4  WHEREGET  NOBCUSE8  BCPREFER  RRCLASS3  RRCOGNT2  RRTREAT  \
72923        NaN       NaN       NaN       NaN       NaN       NaN      NaN   
240937       NaN       NaN       NaN       NaN       NaN       NaN      NaN   
359568       NaN       NaN       NaN       NaN       NaN       NaN      NaN   
26678        NaN       NaN       NaN       NaN       NaN       NaN      NaN   
392399       NaN       NaN       NaN       NaN       NaN       NaN      NaN   
...          ...       ...       ...       ...       ...       ...      ...   
340098       NaN       NaN       NaN       NaN       1.0       5.0      2.0   
212124       NaN       NaN       NaN       NaN       NaN       NaN      NaN   
78203        NaN       NaN       NaN       NaN      77.0       1.0      2.0   
167309       NaN       NaN       NaN       NaN       1.0       3.0      3.0   
313531       NaN       NaN       NaN       NaN       NaN       NaN      NaN   

        RRATWRK2  RRHCARE4  RRPHYSM2  QSTVER  QSTLANG  METSTAT  URBSTAT  \
72923        NaN       NaN       NaN    20.0      1.0      1.0      1.0   
240937       NaN       NaN       NaN    20.0      1.0      1.0      1.0   
359568       NaN       NaN       NaN    21.0      1.0      2.0      1.0   
26678        NaN       NaN       NaN    20.0      1.0      1.0      1.0   
392399       NaN       NaN       NaN    20.0      1.0      1.0      1.0   
...          ...       ...       ...     ...      ...      ...      ...   
340098       2.0       2.0       2.0    20.0      1.0      1.0      1.0   
212124       NaN       NaN       NaN    10.0      1.0      2.0      2.0   
78203        NaN       2.0       1.0    10.0      1.0      2.0      1.0   
167309       2.0       2.0       2.0    23.0      1.0      1.0      1.0   
313531       NaN       NaN       NaN    20.0      1.0      1.0      1.0   

        MSCODE     STSTR       STRWT  RAWRAKE     WT2RAKE  IMPRACE  CHISPNC  \
72923      NaN  122322.0  248.452301      1.0  248.452301      1.0      9.0   
240937     NaN  332082.0   19.826805      1.0   19.826805      1.0      9.0   
359568     NaN  492091.0   12.845830      1.0   12.845830      1.0      9.0   
26678      NaN   62061.0   79.020515      1.0   79.020515      1.0      9.0   
392399     NaN  532042.0   27.861792      1.0   27.861792      1.0      9.0   
...        ...       ...         ...      ...         ...      ...      ...   
340098     NaN  472102.0   74.083954      1.0   74.083954      1.0      NaN   
212124     5.0  291061.0   39.401371      1.0   39.401371      1.0      9.0   
78203      5.0  131091.0   22.524734      1.0   22.524734      1.0      9.0   
167309     NaN  242021.0   11.215499      1.0   11.215499      1.0      9.0   
313531     NaN  422071.0  182.986099      1.0  182.986099      1.0      9.0   

        CRACE2  CPRACE2  CAGEG  CLLCPWT  DUALUSE   DUALCOR      LLCPWT2  \
72923      NaN      NaN    NaN      NaN      2.0  0.487943  6447.701660   
240937     NaN      NaN    NaN      NaN      2.0  0.378823   171.189651   
359568     NaN      NaN    NaN      NaN      9.0       NaN    97.794701   
26678      NaN      NaN    NaN      NaN      9.0       NaN  2596.461426   
392399     NaN      NaN    NaN      NaN      9.0       NaN   276.487793   
...        ...      ...    ...      ...      ...       ...          ...   
340098     NaN      NaN    NaN      NaN      9.0       NaN  1601.732788   
212124     NaN      NaN    NaN      NaN      1.0  0.484466   318.347107   
78203      NaN      NaN    NaN      NaN      1.0  0.608557   648.050659   
167309     NaN      NaN    NaN      NaN      9.0       NaN   149.325851   
313531     NaN      NaN    NaN      NaN      9.0       NaN  1313.389648   

              LLCPWT  RFHLTH  PHYS14D  MENT14D  HLTHPLN  HCVU652  TOTINDA  \
72923   11676.675781     1.0      1.0      1.0      9.0      9.0      1.0   
240937    344.872498     2.0      3.0      2.0      1.0      1.0      1.0   
359568     47.741280     1.0      3.0      2.0      1.0      9.0      1.0   
26678    1610.860840     1.0      2.0      3.0      1.0      1.0      1.0   
392399     95.158501     1.0      2.0      1.0      1.0      1.0      1.0   
...              ...     ...      ...      ...      ...      ...      ...   
340098   3215.943604     1.0      1.0      1.0      1.0      1.0      1.0   
212124    303.684662     1.0      1.0      1.0      1.0      9.0      1.0   
78203     268.017426     2.0      3.0      1.0      1.0      9.0      2.0   
167309     88.821060     1.0      2.0      1.0      1.0      1.0      1.0   
313531   1464.617065     1.0      2.0      3.0      1.0      1.0      1.0   

        EXTETH3  ALTETH3  DENVST3  MICHD  LTASTH1  CASTHM1  ASTHMS1  DRDXAR2  \
72923       1.0      9.0      2.0    2.0      1.0      1.0      3.0      2.0   
240937      2.0      NaN      2.0    2.0      1.0      1.0      3.0      2.0   
359568      2.0      1.0      2.0    2.0      1.0      1.0      3.0      1.0   
26678       1.0      NaN      1.0    2.0      2.0      2.0      1.0      2.0   
392399      2.0      NaN      1.0    2.0      1.0      1.0      3.0      2.0   
...         ...      ...      ...    ...      ...      ...      ...      ...   
340098      2.0      NaN      2.0    2.0      1.0      1.0      3.0      2.0   
212124      2.0      1.0      2.0    2.0      1.0      1.0      3.0      1.0   
78203       2.0      1.0      1.0    2.0      1.0      1.0      3.0      1.0   
167309      2.0      NaN      1.0    2.0      1.0      1.0      3.0      1.0   
313531      1.0      NaN      2.0    2.0      1.0      1.0      3.0      2.0   

        PRACE2  MRACE2  HISPANC  RACE1  RACEG22  RACEGR4  RACEPR1  SEX  \
72923      1.0     1.0      2.0    1.0      1.0      1.0      1.0  2.0   
240937     1.0     1.0      2.0    1.0      1.0      1.0      1.0  1.0   
359568     1.0     1.0      2.0    1.0      1.0      1.0      1.0  2.0   
26678     99.0    99.0      9.0    9.0      9.0      9.0      1.0  1.0   
392399     1.0     1.0      2.0    1.0      1.0      1.0      1.0  1.0   
...        ...     ...      ...    ...      ...      ...      ...  ...   
340098     1.0     1.0      2.0    1.0      1.0      1.0      1.0  1.0   
212124     1.0     1.0      2.0    1.0      1.0      1.0      1.0  2.0   
78203      1.0     1.0      2.0    1.0      1.0      1.0      1.0  2.0   
167309     1.0     1.0      2.0    1.0      1.0      1.0      1.0  1.0   
313531     1.0     1.0      2.0    1.0      1.0      1.0      1.0  1.0   

        AGEG5YR  AGE65YR  AGE80  AGE_G  HTIN4   HTM4   WTKG3    BMI5  BMI5CAT  \
72923      14.0      3.0   52.0    4.0    NaN    NaN     NaN     NaN      NaN   
240937      9.0      1.0   62.0    5.0   67.0  170.0  5897.0  2036.0      2.0   
359568     11.0      2.0   73.0    6.0   65.0  165.0  8981.0  3295.0      4.0   
26678       1.0      1.0   24.0    1.0   68.0  173.0  6350.0  2129.0      2.0   
392399      9.0      1.0   60.0    5.0   73.0  185.0  9979.0  2903.0      3.0   
...         ...      ...    ...    ...    ...    ...     ...     ...      ...   
340098      6.0      1.0   48.0    4.0   69.0  175.0  6350.0  2067.0      2.0   
212124     13.0      2.0   80.0    6.0   64.0  163.0  6713.0  2540.0      3.0   
78203      13.0      2.0   80.0    6.0    NaN    NaN     NaN     NaN      NaN   
167309      7.0      1.0   50.0    4.0   72.0  183.0  8709.0  2604.0      3.0   
313531      3.0      1.0   30.0    2.0   73.0  185.0  7031.0  2045.0      2.0   

        RFBMI5  CHLDCNT  EDUCAG  INCOMG1  RFMAM22  MAM5023  HADCOLN  CLNSCP1  \
72923      9.0      1.0     9.0      9.0      NaN      NaN      NaN      NaN   
240937     1.0      1.0     3.0      1.0      NaN      NaN      1.0      1.0   
359568     2.0      1.0     3.0      5.0      9.0      NaN      1.0      1.0   
26678      1.0      9.0     2.0      9.0      NaN      NaN      NaN      NaN   
392399     2.0      1.0     4.0      6.0      NaN      NaN      2.0      3.0   
...        ...      ...     ...      ...      ...      ...      ...      ...   
340098     1.0      2.0     1.0      5.0      NaN      NaN      2.0      3.0   
212124     2.0      1.0     2.0      2.0      1.0      NaN      1.0      NaN   
78203      9.0      1.0     2.0      9.0      1.0      NaN      1.0      NaN   
167309     2.0      1.0     4.0      7.0      NaN      NaN      2.0      3.0   
313531     1.0      1.0     3.0      7.0      NaN      NaN      NaN      NaN   

        HADSIGM  SGMSCP1  SGMS101  RFBLDS5  STOLDN1  VIRCOL1  SBONTI1  \
72923       NaN      NaN      NaN      NaN      NaN      NaN      NaN   
240937      2.0      3.0      3.0      3.0      3.0      3.0      3.0   
359568      2.0      3.0      3.0      2.0      3.0      2.0      2.0   
26678       NaN      NaN      NaN      NaN      NaN      NaN      NaN   
392399      2.0      3.0      3.0      3.0      3.0      3.0      3.0   
...         ...      ...      ...      ...      ...      ...      ...   
340098      2.0      3.0      3.0      3.0      3.0      3.0      3.0   
212124      2.0      NaN      NaN      NaN      NaN      NaN      NaN   
78203       1.0      NaN      NaN      NaN      NaN      NaN      NaN   
167309      2.0      3.0      3.0      1.0      1.0      3.0      2.0   
313531      NaN      NaN      NaN      NaN      NaN      NaN      NaN   

        CRCREC2  SMOKER3  RFSMOK3  CURECI2  YRSSMOK  PACKDAY  PACKYRS  \
72923       NaN      9.0      9.0      9.0      NaN      NaN      NaN   
240937      1.0      1.0      2.0      1.0     17.0     0.50      9.0   
359568      1.0      4.0      1.0      1.0      NaN      NaN      NaN   
26678       NaN      4.0      1.0      1.0      NaN      NaN      NaN   
392399      3.0      4.0      1.0      1.0      NaN      NaN      NaN   
...         ...      ...      ...      ...      ...      ...      ...   
340098      3.0      3.0      1.0      2.0     28.0     2.00     56.0   
212124      NaN      3.0      1.0      1.0     11.0     0.75      8.0   
78203       NaN      3.0      1.0      1.0     20.0     0.10      2.0   
167309      1.0      4.0      1.0      1.0      NaN      NaN      NaN   
313531      NaN      4.0      1.0      1.0      NaN      NaN      NaN   

        YRSQUIT  SMOKGRP  LCSREC  DRNKANY6  DROCDY4_  RFBING6  DRNKWK2  \
72923       NaN      NaN     NaN       9.0     900.0      9.0  99900.0   
240937      NaN      3.0     2.0       1.0      10.0      1.0     70.0   
359568      NaN      4.0     NaN       2.0       0.0      1.0      0.0   
26678       NaN      4.0     NaN       2.0       0.0      1.0      0.0   
392399      NaN      4.0     NaN       2.0       0.0      1.0      0.0   
...         ...      ...     ...       ...       ...      ...      ...   
340098      8.0      2.0     NaN       2.0       0.0      1.0      0.0   
212124     54.0      3.0     NaN       2.0       0.0      1.0      0.0   
78203      25.0      3.0     NaN       2.0       0.0      1.0      0.0   
167309      NaN      4.0     NaN       1.0      43.0      2.0    900.0   
313531      NaN      4.0     NaN       1.0      43.0      2.0    900.0   

        RFDRHV8  FLSHOT7  PNEUMO3  AIDTST4  
72923       9.0      9.0      9.0      NaN  
240937      1.0      NaN      NaN      1.0  
359568      1.0      1.0      2.0      2.0  
26678       1.0      NaN      NaN      1.0  
392399      1.0      NaN      NaN      2.0  
...         ...      ...      ...      ...  
340098      1.0      NaN      NaN      2.0  
212124      1.0      1.0      1.0      2.0  
78203       1.0      1.0      1.0      2.0  
167309      1.0      NaN      NaN      1.0  
313531      1.0      NaN      NaN      2.0  

[309446 rows x 326 columns]
2025-11-28 15:45:01,663:INFO:get_config() successfully completed......................................
2025-11-28 15:45:01,680:INFO:Initializing get_config()
2025-11-28 15:45:01,680:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000205440814E0>, variable=X_test)
2025-11-28 15:45:01,680:INFO:Variable: 'X_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_test_transformed' instead.
2025-11-28 15:45:01,680:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'X_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_test_transformed' instead.
  warnings.warn(msg)  # print on screen

2025-11-28 15:45:02,318:INFO:Variable:  returned as         STATE  FMONTH     IDATE IMONTH IDAY IYEAR  DISPCODE           PSU  \
410792   53.0    12.0  12202022     12   20  2022    1100.0  2.022024e+09   
75448    12.0     7.0  07152022     07   15  2022    1200.0  2.022013e+09   
439484   72.0     9.0  11202022     11   20  2022    1100.0  2.022004e+09   
179447   25.0     6.0  06212022     06   21  2022    1200.0  2.022009e+09   
390924   53.0    11.0  12022022     12   02  2022    1100.0  2.022005e+09   
...       ...     ...       ...    ...  ...   ...       ...           ...   
321216   45.0     3.0  03102022     03   10  2022    1100.0  2.022001e+09   
420811   55.0     8.0  08262022     08   26  2022    1200.0  2.022000e+09   
189121   26.0     4.0  04202022     04   20  2022    1100.0  2.022008e+09   
238196   33.0     6.0  06102022     06   10  2022    1100.0  2.022001e+09   
181731   26.0    11.0  11152022     11   15  2022    1100.0  2.022001e+09   

        CTELENM1  PVTRESD1  COLGHOUS  STATERE1  CELPHON1  LADULT1  COLGSEX1  \
410792       NaN       NaN       NaN       NaN       NaN      NaN       NaN   
75448        NaN       NaN       NaN       NaN       NaN      NaN       NaN   
439484       NaN       NaN       NaN       NaN       NaN      NaN       NaN   
179447       NaN       NaN       NaN       NaN       NaN      NaN       NaN   
390924       1.0       1.0       NaN       1.0       2.0      1.0       NaN   
...          ...       ...       ...       ...       ...      ...       ...   
321216       1.0       1.0       NaN       1.0       2.0      1.0       NaN   
420811       NaN       NaN       NaN       NaN       NaN      NaN       NaN   
189121       NaN       NaN       NaN       NaN       NaN      NaN       NaN   
238196       1.0       1.0       NaN       1.0       2.0      1.0       NaN   
181731       1.0       1.0       NaN       1.0       2.0      1.0       NaN   

        NUMADULT  LANDSEX1  NUMMEN  NUMWOMEN  RESPSLCT  SAFETIME  CTELNUM1  \
410792       NaN       NaN     NaN       NaN       NaN       1.0       1.0   
75448        NaN       NaN     NaN       NaN       NaN       1.0       1.0   
439484       NaN       NaN     NaN       NaN       NaN       1.0       1.0   
179447       NaN       NaN     NaN       NaN       NaN       1.0       1.0   
390924       2.0       NaN     1.0       1.0       2.0       NaN       NaN   
...          ...       ...     ...       ...       ...       ...       ...   
321216       1.0       2.0     NaN       NaN       NaN       NaN       NaN   
420811       NaN       NaN     NaN       NaN       NaN       1.0       1.0   
189121       NaN       NaN     NaN       NaN       NaN       1.0       1.0   
238196       3.0       NaN     1.0       2.0       1.0       NaN       NaN   
181731       2.0       NaN     1.0       1.0       2.0       NaN       NaN   

        CELLFON5  CADULT1  CELLSEX1  PVTRESD3  CCLGHOUS  CSTATE1  LANDLINE  \
410792       1.0      1.0       2.0       1.0       NaN      1.0       1.0   
75448        1.0      1.0       1.0       1.0       NaN      2.0       2.0   
439484       1.0      1.0       2.0       1.0       NaN      1.0       2.0   
179447       1.0      1.0       2.0       1.0       NaN      1.0       2.0   
390924       NaN      NaN       NaN       NaN       NaN      NaN       NaN   
...          ...      ...       ...       ...       ...      ...       ...   
321216       NaN      NaN       NaN       NaN       NaN      NaN       NaN   
420811       1.0      1.0       2.0       1.0       NaN      2.0       2.0   
189121       1.0      1.0       2.0       1.0       NaN      1.0       2.0   
238196       NaN      NaN       NaN       NaN       NaN      NaN       NaN   
181731       NaN      NaN       NaN       NaN       NaN      NaN       NaN   

        HHADULT  SEXVAR  GENHLTH  PHYSHLTH  MENTHLTH  POORHLTH  PRIMINSR  \
410792      2.0     2.0      4.0      15.0      30.0      30.0       3.0   
75448       2.0     1.0      1.0       1.0      88.0      88.0       1.0   
439484      2.0     2.0      4.0      88.0      88.0       NaN       3.0   
179447      2.0     2.0      4.0       7.0      30.0      88.0       5.0   
390924      NaN     2.0      2.0      88.0      88.0       NaN       1.0   
...         ...     ...      ...       ...       ...       ...       ...   
321216      NaN     2.0      5.0      30.0      30.0      30.0       3.0   
420811      1.0     2.0      3.0       8.0      88.0      88.0       3.0   
189121      2.0     2.0      2.0      88.0       2.0      88.0       1.0   
238196      NaN     1.0      2.0      88.0      88.0       NaN       3.0   
181731      NaN     2.0      3.0       2.0       7.0      88.0       3.0   

        PERSDOC3  MEDCOST1  CHECKUP1  EXERANY2  SLEPTIM1  LASTDEN4  RMVTETH4  \
410792       1.0       2.0       1.0       2.0       9.0       3.0       8.0   
75448        1.0       2.0       1.0       1.0       7.0       2.0       8.0   
439484       1.0       2.0       1.0       2.0       8.0       1.0       2.0   
179447       1.0       2.0       1.0       1.0       4.0       1.0       1.0   
390924       2.0       2.0       1.0       1.0       8.0       1.0       2.0   
...          ...       ...       ...       ...       ...       ...       ...   
321216       2.0       2.0       1.0       2.0      12.0       1.0       8.0   
420811       1.0       2.0       2.0       1.0       6.0       1.0       8.0   
189121       1.0       2.0       1.0       1.0       7.0       1.0       8.0   
238196       2.0       2.0       1.0       1.0       9.0       1.0       8.0   
181731       1.0       2.0       1.0       1.0       8.0       1.0       2.0   

        CVDCRHD4  CVDSTRK3  ASTHMA3  ASTHNOW  CHCSCNC1  CHCOCNC1  CHCCOPD3  \
410792       2.0       2.0      2.0      NaN       2.0       2.0       2.0   
75448        2.0       2.0      2.0      NaN       1.0       2.0       2.0   
439484       2.0       2.0      2.0      NaN       2.0       2.0       2.0   
179447       2.0       2.0      2.0      NaN       2.0       2.0       2.0   
390924       2.0       2.0      1.0      7.0       2.0       1.0       2.0   
...          ...       ...      ...      ...       ...       ...       ...   
321216       2.0       2.0      2.0      NaN       1.0       1.0       2.0   
420811       2.0       2.0      1.0      1.0       2.0       2.0       2.0   
189121       2.0       2.0      2.0      NaN       2.0       2.0       2.0   
238196       1.0       2.0      2.0      NaN       2.0       1.0       2.0   
181731       2.0       2.0      2.0      NaN       1.0       2.0       2.0   

        ADDEPEV3  CHCKDNY2  HAVARTH4  DIABETE4  DIABAGE4  MARITAL  EDUCA  \
410792       7.0       2.0       1.0       3.0       NaN      5.0    6.0   
75448        2.0       2.0       2.0       3.0       NaN      1.0    5.0   
439484       2.0       2.0       2.0       1.0      25.0      1.0    5.0   
179447       1.0       2.0       2.0       3.0       NaN      5.0    4.0   
390924       1.0       2.0       1.0       4.0       NaN      1.0    6.0   
...          ...       ...       ...       ...       ...      ...    ...   
321216       1.0       2.0       1.0       3.0       NaN      3.0    6.0   
420811       1.0       2.0       1.0       1.0      40.0      2.0    5.0   
189121       2.0       2.0       1.0       3.0       NaN      1.0    6.0   
238196       2.0       2.0       2.0       3.0       NaN      1.0    6.0   
181731       1.0       2.0       1.0       3.0       NaN      1.0    4.0   

        RENTHOM1  NUMHHOL4  NUMPHON4  CPDEMO1C  VETERAN3  EMPLOY1  CHILDREN  \
410792       2.0       NaN       NaN       1.0       2.0      7.0      88.0   
75448        1.0       NaN       NaN       1.0       1.0      7.0      88.0   
439484       1.0       NaN       NaN       1.0       2.0      5.0      88.0   
179447       2.0       NaN       NaN       1.0       2.0      4.0       3.0   
390924       1.0       2.0       NaN       1.0       2.0      7.0      88.0   
...          ...       ...       ...       ...       ...      ...       ...   
321216       1.0       2.0       NaN       8.0       2.0      7.0      88.0   
420811       1.0       NaN       NaN       1.0       2.0      8.0      88.0   
189121       1.0       NaN       NaN       1.0       1.0      1.0      88.0   
238196       1.0       2.0       NaN       1.0       1.0      7.0      88.0   
181731       1.0       2.0       NaN       1.0       2.0      5.0      88.0   

        INCOME3  PREGNANT  WEIGHT2  HEIGHT3  DEAF  BLIND  DECIDE  DIFFWALK  \
410792      5.0       NaN    200.0    510.0   2.0    2.0     2.0       1.0   
75448       9.0       NaN    150.0    506.0   2.0    2.0     2.0       2.0   
439484      3.0       NaN    200.0    504.0   2.0    2.0     2.0       1.0   
179447      NaN       NaN      NaN      NaN   NaN    NaN     NaN       NaN   
390924      9.0       NaN    121.0    501.0   2.0    2.0     2.0       2.0   
...         ...       ...      ...      ...   ...    ...     ...       ...   
321216      6.0       NaN    167.0    506.0   2.0    2.0     1.0       1.0   
420811      2.0       NaN    248.0    507.0   1.0    1.0     1.0       1.0   
189121      9.0       NaN    180.0    505.0   2.0    2.0     2.0       2.0   
238196      9.0       NaN    165.0    504.0   2.0    2.0     2.0       2.0   
181731     77.0       NaN    155.0    503.0   2.0    2.0     1.0       2.0   

        DIFFDRES  DIFFALON  HADMAM  HOWLONG  CERVSCRN  CRVCLCNC  CRVCLPAP  \
410792       1.0       2.0     1.0      1.0       1.0       5.0       2.0   
75448        2.0       2.0     NaN      NaN       NaN       NaN       NaN   
439484       2.0       2.0     1.0      3.0       1.0       5.0       1.0   
179447       NaN       NaN     NaN      NaN       NaN       NaN       NaN   
390924       2.0       2.0     1.0      5.0       1.0       5.0       1.0   
...          ...       ...     ...      ...       ...       ...       ...   
321216       1.0       1.0     1.0      5.0       1.0       5.0       1.0   
420811       2.0       2.0     1.0      4.0       1.0       5.0       1.0   
189121       2.0       2.0     2.0      NaN       2.0       NaN       NaN   
238196       2.0       2.0     NaN      NaN       NaN       NaN       NaN   
181731       2.0       2.0     1.0      4.0       1.0       5.0       1.0   

        CRVCLHPV  HADHYST2  HADSIGM4  COLNSIGM  COLNTES1  SIGMTES1  LASTSIG4  \
410792       2.0       2.0       1.0       1.0       5.0       NaN       NaN   
75448        NaN       NaN       1.0       1.0       2.0       NaN       NaN   
439484       1.0       2.0       2.0       NaN       NaN       NaN       NaN   
179447       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
390924       2.0       1.0       1.0       1.0       2.0       NaN       NaN   
...          ...       ...       ...       ...       ...       ...       ...   
321216       2.0       2.0       1.0       1.0       5.0       NaN       NaN   
420811       7.0       1.0       1.0       1.0       3.0       NaN       NaN   
189121       NaN       2.0       1.0       1.0       3.0       NaN       NaN   
238196       NaN       NaN       1.0       3.0       3.0       5.0       NaN   
181731       7.0       1.0       1.0       3.0       3.0       7.0       NaN   

        COLNCNCR  VIRCOLO1  VCLNTES2  SMALSTOL  STOLTEST  STOOLDN2  BLDSTFIT  \
410792       1.0       2.0       NaN       1.0       2.0       2.0       NaN   
75448        7.0       NaN       NaN       NaN       NaN       NaN       NaN   
439484       1.0       2.0       NaN       1.0       1.0       2.0       NaN   
179447       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
390924       2.0       NaN       NaN       NaN       NaN       NaN       NaN   
...          ...       ...       ...       ...       ...       ...       ...   
321216       1.0       2.0       NaN       1.0       2.0       2.0       NaN   
420811       2.0       NaN       NaN       NaN       NaN       NaN       NaN   
189121       1.0       2.0       NaN       2.0       NaN       2.0       NaN   
238196       1.0       2.0       NaN       1.0       7.0       2.0       NaN   
181731       1.0       2.0       NaN       1.0       4.0       2.0       NaN   

        SDNATES1  SMOKE100  SMOKDAY2  USENOW3  ECIGNOW2  LCSFIRST  LCSLAST  \
410792       NaN       2.0       NaN      3.0       1.0       NaN      NaN   
75448        NaN       2.0       NaN      3.0       1.0       NaN      NaN   
439484       NaN       2.0       NaN      3.0       1.0       NaN      NaN   
179447       NaN       NaN       NaN      NaN       NaN       NaN      NaN   
390924       NaN       1.0       3.0      3.0       4.0      16.0     29.0   
...          ...       ...       ...      ...       ...       ...      ...   
321216       NaN       2.0       NaN      3.0       1.0       NaN      NaN   
420811       NaN       2.0       NaN      3.0       1.0       NaN      NaN   
189121       NaN       1.0       3.0      3.0       1.0      22.0     41.0   
238196       NaN       1.0       3.0      3.0       4.0      16.0     21.0   
181731       NaN       1.0       3.0      3.0       1.0      20.0     60.0   

        LCSNUMCG  LCSCTSC1  LCSSCNCR  LCSCTWHN  ALCDAY4  AVEDRNK3  DRNK3GE5  \
410792       NaN       2.0       NaN       NaN    105.0       6.0      20.0   
75448        NaN       1.0       2.0       NaN    203.0       1.0      88.0   
439484       NaN       1.0       2.0       NaN    888.0       NaN       NaN   
179447       NaN       NaN       NaN       NaN      NaN       NaN       NaN   
390924      10.0       7.0       NaN       NaN    888.0       NaN       NaN   
...          ...       ...       ...       ...      ...       ...       ...   
321216       NaN       1.0       7.0       NaN    888.0       NaN       NaN   
420811       NaN       7.0       NaN       NaN    777.0       NaN       NaN   
189121      10.0       2.0       NaN       NaN    201.0       2.0       2.0   
238196       5.0       2.0       NaN       NaN    102.0       2.0      88.0   
181731       3.0       1.0       7.0       NaN    101.0       1.0      88.0   

        MAXDRNKS  FLUSHOT7  FLSHTMY3  PNEUVAC4  TETANUS1  HIVTST7  HIVTSTD3  \
410792       5.0       1.0  112022.0       2.0       4.0      1.0  777777.0   
75448        2.0       2.0       NaN       2.0       3.0      1.0  772018.0   
439484       NaN       2.0       NaN       2.0       3.0      2.0       NaN   
179447       NaN       NaN       NaN       NaN       NaN      NaN       NaN   
390924       NaN       1.0  102022.0       1.0       1.0      1.0   81991.0   
...          ...       ...       ...       ...       ...      ...       ...   
321216       NaN       1.0   22022.0       1.0       3.0      7.0       NaN   
420811       NaN       2.0       NaN       2.0       1.0      1.0  777777.0   
189121       6.0       1.0   92021.0       2.0       1.0      1.0  777777.0   
238196       2.0       7.0       NaN       1.0       4.0      2.0       NaN   
181731       2.0       1.0  777777.0       1.0       1.0      2.0       NaN   

        HIVRISK5  COVIDPOS  COVIDSMP  COVIDPRM  PDIABTS1  PREDIAB2  DIABTYPE  \
410792       2.0       2.0       NaN       NaN       NaN       NaN       NaN   
75448        2.0       1.0       2.0       NaN       NaN       NaN       NaN   
439484       2.0       2.0       NaN       NaN       NaN       NaN       NaN   
179447       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
390924       2.0       2.0       NaN       NaN       NaN       NaN       NaN   
...          ...       ...       ...       ...       ...       ...       ...   
321216       2.0       2.0       NaN       NaN       1.0       1.0       NaN   
420811       1.0       2.0       NaN       NaN       NaN       NaN       NaN   
189121       2.0       1.0       2.0       NaN       1.0       3.0       NaN   
238196       2.0       2.0       NaN       NaN       1.0       3.0       NaN   
181731       2.0       3.0       2.0       NaN       1.0       3.0       NaN   

        INSULIN1  CHKHEMO3  EYEEXAM1  DIABEYE1  DIABEDU1  FEETSORE  TOLDCFS  \
410792       NaN       NaN       NaN       NaN       NaN       NaN      NaN   
75448        NaN       NaN       NaN       NaN       NaN       NaN      NaN   
439484       NaN       NaN       NaN       NaN       NaN       NaN      NaN   
179447       NaN       NaN       NaN       NaN       NaN       NaN      NaN   
390924       NaN       NaN       NaN       NaN       NaN       NaN      NaN   
...          ...       ...       ...       ...       ...       ...      ...   
321216       NaN       NaN       NaN       NaN       NaN       NaN      NaN   
420811       NaN       NaN       NaN       NaN       NaN       NaN      NaN   
189121       NaN       NaN       NaN       NaN       NaN       NaN      NaN   
238196       NaN       NaN       NaN       NaN       NaN       NaN      NaN   
181731       NaN       NaN       NaN       NaN       NaN       NaN      NaN   

        HAVECFS  WORKCFS  IMFVPLA3  HPVADVC4  HPVADSHT  SHINGLE2  COVIDVA1  \
410792      NaN      NaN       NaN       NaN       NaN       NaN       NaN   
75448       NaN      NaN       NaN       NaN       NaN       NaN       NaN   
439484      NaN      NaN       NaN       NaN       NaN       NaN       1.0   
179447      NaN      NaN       NaN       NaN       NaN       NaN       NaN   
390924      NaN      NaN       NaN       NaN       NaN       NaN       NaN   
...         ...      ...       ...       ...       ...       ...       ...   
321216      NaN      NaN       NaN       NaN       NaN       NaN       1.0   
420811      NaN      NaN       NaN       NaN       NaN       NaN       NaN   
189121      NaN      NaN       NaN       NaN       NaN       NaN       NaN   
238196      NaN      NaN       NaN       NaN       NaN       NaN       1.0   
181731      NaN      NaN       NaN       NaN       NaN       NaN       NaN   

        COVACGET  COVIDNU1  COVIDINT  COVIDFS1  COVIDSE1  COPDCOGH  COPDFLEM  \
410792       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
75448        NaN       NaN       NaN       NaN       NaN       NaN       NaN   
439484       NaN       4.0       NaN  777777.0  777777.0       NaN       NaN   
179447       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
390924       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
...          ...       ...       ...       ...       ...       ...       ...   
321216       NaN       1.0       7.0   42021.0       NaN       NaN       NaN   
420811       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
189121       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
238196       NaN       3.0       NaN   32020.0   42020.0       NaN       NaN   
181731       NaN       NaN       NaN       NaN       NaN       NaN       NaN   

        COPDBRTH  COPDBTST  COPDSMOK  CNCRDIFF  CNCRAGE  CNCRTYP2  CSRVTRT3  \
410792       NaN       NaN       NaN       NaN      NaN       NaN       NaN   
75448        NaN       NaN       NaN       NaN      NaN       NaN       NaN   
439484       NaN       NaN       NaN       NaN      NaN       NaN       NaN   
179447       NaN       NaN       NaN       NaN      NaN       NaN       NaN   
390924       NaN       NaN       NaN       NaN      NaN       NaN       NaN   
...          ...       ...       ...       ...      ...       ...       ...   
321216       NaN       NaN       NaN       NaN      NaN       NaN       NaN   
420811       NaN       NaN       NaN       NaN      NaN       NaN       NaN   
189121       NaN       NaN       NaN       NaN      NaN       NaN       NaN   
238196       NaN       NaN       NaN       NaN      NaN       NaN       NaN   
181731       NaN       NaN       NaN       1.0     98.0      77.0       NaN   

        CSRVDOC1  CSRVSUM  CSRVRTRN  CSRVINST  CSRVINSR  CSRVDEIN  CSRVCLIN  \
410792       NaN      NaN       NaN       NaN       NaN       NaN       NaN   
75448        NaN      NaN       NaN       NaN       NaN       NaN       NaN   
439484       NaN      NaN       NaN       NaN       NaN       NaN       NaN   
179447       NaN      NaN       NaN       NaN       NaN       NaN       NaN   
390924       NaN      NaN       NaN       NaN       NaN       NaN       NaN   
...          ...      ...       ...       ...       ...       ...       ...   
321216       NaN      NaN       NaN       NaN       NaN       NaN       NaN   
420811       NaN      NaN       NaN       NaN       NaN       NaN       NaN   
189121       NaN      NaN       NaN       NaN       NaN       NaN       NaN   
238196       NaN      NaN       NaN       NaN       NaN       NaN       NaN   
181731       NaN      NaN       NaN       NaN       NaN       NaN       NaN   

        CSRVPAIN  CSRVCTL2  PSATEST1  PSATIME1  PCPSARS2  PSASUGST  PCSTALK1  \
410792       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
75448        NaN       NaN       NaN       NaN       NaN       NaN       NaN   
439484       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
179447       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
390924       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
...          ...       ...       ...       ...       ...       ...       ...   
321216       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
420811       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
189121       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
238196       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
181731       2.0       NaN       NaN       NaN       NaN       NaN       NaN   

        CIMEMLOS  CDHOUSE  CDASSIST  CDHELP  CDSOCIAL  CDDISCUS  CAREGIV1  \
410792       NaN      NaN       NaN     NaN       NaN       NaN       1.0   
75448        NaN      NaN       NaN     NaN       NaN       NaN       NaN   
439484       NaN      NaN       NaN     NaN       NaN       NaN       1.0   
179447       NaN      NaN       NaN     NaN       NaN       NaN       NaN   
390924       NaN      NaN       NaN     NaN       NaN       NaN       1.0   
...          ...      ...       ...     ...       ...       ...       ...   
321216       2.0      NaN       NaN     NaN       NaN       NaN       NaN   
420811       NaN      NaN       NaN     NaN       NaN       NaN       NaN   
189121       NaN      NaN       NaN     NaN       NaN       NaN       NaN   
238196       NaN      NaN       NaN     NaN       NaN       NaN       2.0   
181731       NaN      NaN       NaN     NaN       NaN       NaN       NaN   

        CRGVREL4  CRGVLNG1  CRGVHRS1  CRGVPRB3  CRGVALZD  CRGVPER1  CRGVHOU1  \
410792      15.0       4.0       1.0      15.0       1.0       2.0       1.0   
75448        NaN       NaN       NaN       NaN       NaN       NaN       NaN   
439484      10.0       5.0       4.0       6.0       2.0       2.0       1.0   
179447       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
390924       3.0       5.0       2.0      14.0       7.0       2.0       1.0   
...          ...       ...       ...       ...       ...       ...       ...   
321216       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
420811       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
189121       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
238196       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
181731       NaN       NaN       NaN       NaN       NaN       NaN       NaN   

        CRGVEXPT  ACEDEPRS  ACEDRINK  ACEDRUGS  ACEPRISN  ACEDIVRC  ACEPUNCH  \
410792       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
75448        NaN       NaN       NaN       NaN       NaN       NaN       NaN   
439484       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
179447       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
390924       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
...          ...       ...       ...       ...       ...       ...       ...   
321216       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
420811       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
189121       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
238196       2.0       NaN       NaN       NaN       NaN       NaN       NaN   
181731       NaN       NaN       NaN       NaN       NaN       NaN       NaN   

        ACEHURT1  ACESWEAR  ACETOUCH  ACETTHEM  ACEHVSEX  ACEADSAF  ACEADNED  \
410792       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
75448        NaN       NaN       NaN       NaN       NaN       NaN       NaN   
439484       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
179447       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
390924       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
...          ...       ...       ...       ...       ...       ...       ...   
321216       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
420811       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
189121       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
238196       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
181731       NaN       NaN       NaN       NaN       NaN       NaN       NaN   

        LSATISFY  EMTSUPRT  SDHISOLT  SDHEMPLY  FOODSTMP  SDHFOOD1  SDHBILLS  \
410792       3.0       4.0       3.0       2.0       2.0       5.0       2.0   
75448        NaN       NaN       NaN       NaN       NaN       NaN       NaN   
439484       1.0       1.0       5.0       2.0       2.0       3.0       1.0   
179447       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
390924       1.0       1.0       5.0       2.0       2.0       5.0       2.0   
...          ...       ...       ...       ...       ...       ...       ...   
321216       4.0       3.0       2.0       2.0       2.0       5.0       2.0   
420811       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
189121       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
238196       1.0       1.0       5.0       2.0       2.0       5.0       2.0   
181731       NaN       NaN       NaN       NaN       NaN       NaN       NaN   

        SDHUTILS  SDHTRNSP  SDHSTRE1  MARIJAN1  MARJSMOK  MARJEAT  MARJVAPE  \
410792       2.0       2.0       4.0       NaN       NaN      NaN       NaN   
75448        NaN       NaN       NaN       NaN       NaN      NaN       NaN   
439484       2.0       2.0       5.0       NaN       NaN      NaN       NaN   
179447       NaN       NaN       NaN       NaN       NaN      NaN       NaN   
390924       2.0       2.0       5.0       NaN       NaN      NaN       NaN   
...          ...       ...       ...       ...       ...      ...       ...   
321216       2.0       1.0       3.0       NaN       NaN      NaN       NaN   
420811       NaN       NaN       NaN       NaN       NaN      NaN       NaN   
189121       NaN       NaN       NaN       NaN       NaN      NaN       NaN   
238196       2.0       2.0       5.0       NaN       NaN      NaN       NaN   
181731       NaN       NaN       NaN       NaN       NaN      NaN       NaN   

        MARJDAB  MARJOTHR  USEMRJN4  LASTSMK2  STOPSMK2  MENTCIGS  MENTECIG  \
410792      NaN       NaN       NaN       NaN       NaN       NaN       NaN   
75448       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
439484      NaN       NaN       NaN       NaN       NaN       NaN       NaN   
179447      NaN       NaN       NaN       NaN       NaN       NaN       NaN   
390924      NaN       NaN       NaN       6.0       NaN       NaN       NaN   
...         ...       ...       ...       ...       ...       ...       ...   
321216      NaN       NaN       NaN       NaN       NaN       NaN       NaN   
420811      NaN       NaN       NaN       NaN       NaN       NaN       NaN   
189121      NaN       NaN       NaN       NaN       NaN       NaN       NaN   
238196      NaN       NaN       NaN       NaN       NaN       NaN       NaN   
181731      NaN       NaN       NaN       NaN       NaN       NaN       NaN   

        HEATTBCO  ASBIALCH  ASBIDRNK  ASBIBING  ASBIADVC  ASBIRDUC  FIREARM5  \
410792       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
75448        NaN       NaN       NaN       NaN       NaN       NaN       NaN   
439484       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
179447       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
390924       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
...          ...       ...       ...       ...       ...       ...       ...   
321216       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
420811       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
189121       NaN       1.0       1.0       7.0       7.0       2.0       NaN   
238196       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
181731       NaN       2.0       2.0       2.0       2.0       NaN       NaN   

        GUNLOAD  LOADULK2  RCSGEND1  RCSXBRTH  RCSRLTN2  CASTHDX2  CASTHNO2  \
410792      NaN       NaN       NaN       NaN       NaN       NaN       NaN   
75448       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
439484      NaN       NaN       NaN       NaN       NaN       NaN       NaN   
179447      NaN       NaN       NaN       NaN       NaN       NaN       NaN   
390924      NaN       NaN       NaN       NaN       NaN       NaN       NaN   
...         ...       ...       ...       ...       ...       ...       ...   
321216      NaN       NaN       NaN       NaN       NaN       NaN       NaN   
420811      NaN       NaN       NaN       NaN       NaN       NaN       NaN   
189121      NaN       NaN       NaN       NaN       NaN       NaN       NaN   
238196      NaN       NaN       NaN       NaN       NaN       NaN       NaN   
181731      NaN       NaN       NaN       NaN       NaN       NaN       NaN   

        BIRTHSEX  SOMALE  SOFEMALE  TRNSGNDR  HADSEX  PFPPRVN4  TYPCNTR9  \
410792       NaN     NaN       1.0       4.0     NaN       NaN       NaN   
75448        NaN     NaN       NaN       NaN     NaN       NaN       NaN   
439484       NaN     NaN       NaN       NaN     NaN       NaN       NaN   
179447       NaN     NaN       3.0       4.0     NaN       NaN       NaN   
390924       NaN     NaN       2.0       4.0     NaN       NaN       NaN   
...          ...     ...       ...       ...     ...       ...       ...   
321216       NaN     NaN       NaN       NaN     NaN       NaN       NaN   
420811       NaN     NaN       NaN       NaN     NaN       NaN       NaN   
189121       NaN     NaN       2.0       4.0     NaN       NaN       NaN   
238196       NaN     NaN       NaN       NaN     NaN       NaN       NaN   
181731       NaN     NaN       2.0       4.0     NaN       NaN       NaN   

        BRTHCNT4  WHEREGET  NOBCUSE8  BCPREFER  RRCLASS3  RRCOGNT2  RRTREAT  \
410792       NaN       NaN       NaN       NaN       NaN       NaN      NaN   
75448        NaN       NaN       NaN       NaN       NaN       NaN      NaN   
439484       NaN       NaN       NaN       NaN       NaN       NaN      NaN   
179447       NaN       NaN       NaN       NaN       NaN       NaN      NaN   
390924       NaN       NaN       NaN       NaN       NaN       NaN      NaN   
...          ...       ...       ...       ...       ...       ...      ...   
321216       NaN       NaN       NaN       NaN       1.0       7.0      2.0   
420811       NaN       NaN       NaN       NaN       NaN       NaN      NaN   
189121       NaN       NaN       NaN       NaN       NaN       NaN      NaN   
238196       NaN       NaN       NaN       NaN       NaN       NaN      NaN   
181731       NaN       NaN       NaN       NaN       NaN       NaN      NaN   

        RRATWRK2  RRHCARE4  RRPHYSM2  QSTVER  QSTLANG  METSTAT  URBSTAT  \
410792       NaN       NaN       NaN    20.0      1.0      1.0      1.0   
75448        NaN       NaN       NaN    20.0      1.0      1.0      1.0   
439484       NaN       NaN       NaN    20.0      2.0      NaN      NaN   
179447       NaN       NaN       NaN    23.0      1.0      1.0      1.0   
390924       NaN       NaN       NaN    10.0      1.0      1.0      1.0   
...          ...       ...       ...     ...      ...      ...      ...   
321216       NaN       2.0       2.0    10.0      1.0      1.0      1.0   
420811       NaN       NaN       NaN    20.0      1.0      2.0      2.0   
189121       NaN       NaN       NaN    23.0      1.0      1.0      1.0   
238196       NaN       NaN       NaN    10.0      1.0      1.0      1.0   
181731       NaN       NaN       NaN    11.0      1.0      1.0      1.0   

        MSCODE     STSTR       STRWT  RAWRAKE     WT2RAKE  IMPRACE  CHISPNC  \
410792     NaN  532011.0   34.399036      1.0   34.399036      1.0      9.0   
75448      NaN  122141.0  172.734833      1.0  172.734833      1.0      9.0   
439484     NaN  722011.0  140.162384      1.0  140.162384      5.0      9.0   
179447     NaN  252092.0   28.653528      1.0   28.653528      5.0      9.0   
390924     1.0  531161.0   12.983629      2.0   25.967258      3.0      9.0   
...        ...       ...         ...      ...         ...      ...      ...   
321216     3.0  451061.0    3.292533      1.0    3.292533      1.0      NaN   
420811     NaN  552062.0   12.734881      1.0   12.734881      1.0      9.0   
189121     NaN  262041.0   75.429985      1.0   75.429985      1.0      9.0   
238196     3.0  331081.0    7.434364      3.0   22.303093      1.0      9.0   
181731     1.0  261091.0   17.746788      2.0   35.493576      1.0      9.0   

        CRACE2  CPRACE2  CAGEG  CLLCPWT  DUALUSE   DUALCOR      LLCPWT2  \
410792     NaN      NaN    NaN      NaN      2.0  0.656351   388.521027   
75448      NaN      NaN    NaN      NaN      9.0       NaN  2796.276611   
439484     NaN      NaN    NaN      NaN      9.0       NaN   551.805725   
179447     NaN      NaN    NaN      NaN      9.0       NaN   430.192139   
390924     NaN      NaN    NaN      NaN      1.0  0.343649   153.558273   
...        ...      ...    ...      ...      ...       ...          ...   
321216     NaN      NaN    NaN      NaN      9.0       NaN   100.302292   
420811     NaN      NaN    NaN      NaN      9.0       NaN   382.623993   
189121     NaN      NaN    NaN      NaN      9.0       NaN   967.920349   
238196     NaN      NaN    NaN      NaN      1.0  0.621177   315.768005   
181731     NaN      NaN    NaN      NaN      1.0  0.490989   420.190948   

             LLCPWT  RFHLTH  PHYS14D  MENT14D  HLTHPLN  HCVU652  TOTINDA  \
410792   152.656052     2.0      3.0      3.0      1.0      1.0      2.0   
75448   1881.282349     1.0      2.0      1.0      1.0      1.0      1.0   
439484   188.245804     2.0      1.0      1.0      1.0      9.0      2.0   
179447   632.091187     2.0      2.0      3.0      1.0      1.0      1.0   
390924   541.812378     1.0      1.0      1.0      1.0      1.0      1.0   
...             ...     ...      ...      ...      ...      ...      ...   
321216    40.995720     2.0      3.0      3.0      1.0      9.0      2.0   
420811   322.629639     1.0      2.0      1.0      1.0      1.0      1.0   
189121   527.158508     1.0      1.0      2.0      1.0      1.0      1.0   
238196   112.328415     1.0      1.0      1.0      1.0      9.0      1.0   
181731   285.703003     1.0      2.0      2.0      1.0      9.0      1.0   

        EXTETH3  ALTETH3  DENVST3  MICHD  LTASTH1  CASTHM1  ASTHMS1  DRDXAR2  \
410792      1.0      NaN      2.0    2.0      1.0      1.0      3.0      1.0   
75448       1.0      NaN      2.0    2.0      1.0      1.0      3.0      2.0   
439484      2.0      1.0      1.0    2.0      1.0      1.0      3.0      2.0   
179447      2.0      NaN      1.0    2.0      1.0      1.0      3.0      2.0   
390924      2.0      NaN      1.0    2.0      2.0      9.0      9.0      1.0   
...         ...      ...      ...    ...      ...      ...      ...      ...   
321216      1.0      1.0      1.0    2.0      1.0      1.0      3.0      1.0   
420811      1.0      NaN      1.0    2.0      2.0      2.0      1.0      1.0   
189121      1.0      NaN      1.0    2.0      1.0      1.0      3.0      1.0   
238196      1.0      1.0      1.0    1.0      1.0      1.0      3.0      2.0   
181731      2.0      1.0      1.0    2.0      1.0      1.0      3.0      1.0   

        PRACE2  MRACE2  HISPANC  RACE1  RACEG22  RACEGR4  RACEPR1  SEX  \
410792     1.0     1.0      2.0    1.0      1.0      1.0      1.0  2.0   
75448     99.0    99.0      2.0    9.0      9.0      9.0      1.0  1.0   
439484     2.0     2.0      1.0    8.0      2.0      5.0      7.0  2.0   
179447     1.0     1.0      1.0    8.0      2.0      5.0      7.0  2.0   
390924     4.0     4.0      2.0    4.0      2.0      3.0      4.0  2.0   
...        ...     ...      ...    ...      ...      ...      ...  ...   
321216     1.0     1.0      2.0    1.0      1.0      1.0      1.0  2.0   
420811     1.0     1.0      2.0    1.0      1.0      1.0      1.0  2.0   
189121     1.0     1.0      2.0    1.0      1.0      1.0      1.0  2.0   
238196     1.0     1.0      2.0    1.0      1.0      1.0      1.0  1.0   
181731     1.0     1.0      2.0    1.0      1.0      1.0      1.0  2.0   

        AGEG5YR  AGE65YR  AGE80  AGE_G  HTIN4   HTM4    WTKG3    BMI5  \
410792      9.0      1.0   64.0    5.0   70.0  178.0   9072.0  2870.0   
75448       8.0      1.0   55.0    5.0   66.0  168.0   6804.0  2421.0   
439484     11.0      2.0   70.0    6.0   64.0  163.0   9072.0  3433.0   
179447      3.0      1.0   33.0    2.0    NaN    NaN      NaN     NaN   
390924      9.0      1.0   61.0    5.0   61.0  155.0   5488.0  2286.0   
...         ...      ...    ...    ...    ...    ...      ...     ...   
321216     12.0      2.0   76.0    6.0   66.0  168.0   7575.0  2695.0   
420811      7.0      1.0   52.0    4.0   67.0  170.0  11249.0  3884.0   
189121      7.0      1.0   54.0    4.0   65.0  165.0   8165.0  2995.0   
238196     12.0      2.0   79.0    6.0   64.0  163.0   7484.0  2832.0   
181731     13.0      2.0   80.0    6.0   63.0  160.0   7031.0  2746.0   

        BMI5CAT  RFBMI5  CHLDCNT  EDUCAG  INCOMG1  RFMAM22  MAM5023  HADCOLN  \
410792      3.0     2.0      1.0     4.0      3.0      1.0      1.0      1.0   
75448       2.0     1.0      1.0     3.0      6.0      NaN      NaN      1.0   
439484      4.0     2.0      1.0     3.0      2.0      2.0      2.0      2.0   
179447      NaN     9.0      4.0     2.0      9.0      NaN      NaN      NaN   
390924      2.0     1.0      1.0     4.0      6.0      2.0      2.0      1.0   
...         ...     ...      ...     ...      ...      ...      ...      ...   
321216      3.0     2.0      1.0     4.0      4.0      2.0      NaN      1.0   
420811      4.0     2.0      1.0     3.0      1.0      2.0      2.0      1.0   
189121      3.0     2.0      1.0     4.0      6.0      2.0      2.0      1.0   
238196      3.0     2.0      1.0     4.0      6.0      NaN      NaN      1.0   
181731      3.0     2.0      1.0     2.0      9.0      2.0      NaN      1.0   

        CLNSCP1  HADSIGM  SGMSCP1  SGMS101  RFBLDS5  STOLDN1  VIRCOL1  \
410792      2.0      2.0      3.0      3.0      2.0      3.0      3.0   
75448       1.0      2.0      3.0      3.0      NaN      NaN      NaN   
439484      3.0      2.0      3.0      3.0      1.0      3.0      3.0   
179447      NaN      NaN      NaN      NaN      NaN      NaN      NaN   
390924      1.0      2.0      3.0      3.0      3.0      3.0      3.0   
...         ...      ...      ...      ...      ...      ...      ...   
321216      NaN      2.0      NaN      NaN      NaN      NaN      NaN   
420811      1.0      2.0      3.0      3.0      3.0      3.0      3.0   
189121      1.0      2.0      3.0      3.0      3.0      3.0      3.0   
238196      NaN      1.0      NaN      NaN      NaN      NaN      NaN   
181731      NaN      1.0      NaN      NaN      NaN      NaN      NaN   

        SBONTI1  CRCREC2  SMOKER3  RFSMOK3  CURECI2  YRSSMOK  PACKDAY  \
410792      2.0      2.0      4.0      1.0      1.0      NaN      NaN   
75448       NaN      1.0      4.0      1.0      1.0      NaN      NaN   
439484      2.0      1.0      4.0      1.0      1.0      NaN      NaN   
179447      NaN      NaN      9.0      9.0      9.0      NaN      NaN   
390924      3.0      1.0      3.0      1.0      1.0     13.0     0.50   
...         ...      ...      ...      ...      ...      ...      ...   
321216      NaN      NaN      4.0      1.0      1.0      NaN      NaN   
420811      3.0      1.0      4.0      1.0      1.0      NaN      NaN   
189121      3.0      1.0      3.0      1.0      1.0     19.0     0.50   
238196      NaN      NaN      3.0      1.0      1.0      5.0     0.25   
181731      NaN      NaN      3.0      1.0      1.0     40.0     0.15   

        PACKYRS  YRSQUIT  SMOKGRP  LCSREC  DRNKANY6  DROCDY4_  RFBING6  \
410792      NaN      NaN      4.0     NaN       1.0      71.0      2.0   
75448       NaN      NaN      4.0     NaN       1.0      10.0      1.0   
439484      NaN      NaN      4.0     NaN       2.0       0.0      1.0   
179447      NaN      NaN      NaN     NaN       9.0     900.0      9.0   
390924      7.0     32.0      3.0     NaN       2.0       0.0      1.0   
...         ...      ...      ...     ...       ...       ...      ...   
321216      NaN      NaN      4.0     NaN       2.0       0.0      1.0   
420811      NaN      NaN      4.0     NaN       7.0     900.0      9.0   
189121     10.0     13.0      3.0     NaN       1.0       3.0      2.0   
238196      1.0     58.0      3.0     NaN       1.0      29.0      1.0   
181731      6.0     21.0      3.0     NaN       1.0      14.0      1.0   

        DRNKWK2  RFDRHV8  FLSHOT7  PNEUMO3  AIDTST4  
410792   3000.0      2.0      NaN      NaN      1.0  
75448      70.0      1.0      NaN      NaN      1.0  
439484      0.0      1.0      2.0      2.0      2.0  
179447  99900.0      9.0      NaN      NaN      NaN  
390924      0.0      1.0      NaN      NaN      1.0  
...         ...      ...      ...      ...      ...  
321216      0.0      1.0      1.0      1.0      9.0  
420811  99900.0      9.0      NaN      NaN      1.0  
189121     47.0      1.0      NaN      NaN      1.0  
238196    400.0      1.0      9.0      1.0      2.0  
181731    100.0      1.0      1.0      1.0      2.0  

[132621 rows x 326 columns]
2025-11-28 15:45:02,318:INFO:get_config() successfully completed......................................
2025-11-28 15:51:56,417:INFO:PyCaret ClassificationExperiment
2025-11-28 15:51:56,417:INFO:Logging name: clf-default-name
2025-11-28 15:51:56,417:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-11-28 15:51:56,417:INFO:version 3.3.2
2025-11-28 15:51:56,417:INFO:Initializing setup()
2025-11-28 15:51:56,417:INFO:self.USI: 97a8
2025-11-28 15:51:56,417:INFO:self._variable_keys: {'USI', 'memory', '_ml_usecase', 'data', 'logging_param', 'target_param', 'y_test', 'gpu_param', 'fix_imbalance', 'exp_id', 'gpu_n_jobs_param', 'seed', 'fold_shuffle_param', 'log_plots_param', 'X', 'is_multiclass', 'pipeline', 'y', 'fold_groups_param', 'X_test', 'n_jobs_param', 'idx', 'X_train', '_available_plots', 'exp_name_log', 'y_train', 'fold_generator', 'html_param'}
2025-11-28 15:51:56,417:INFO:Checking environment
2025-11-28 15:51:56,417:INFO:python_version: 3.10.19
2025-11-28 15:51:56,417:INFO:python_build: ('main', 'Oct 22 2025 22:23:22')
2025-11-28 15:51:56,417:INFO:machine: AMD64
2025-11-28 15:51:56,417:INFO:platform: Windows-10-10.0.26200-SP0
2025-11-28 15:51:56,417:INFO:Memory: svmem(total=16282144768, available=3864506368, percent=76.3, used=12417638400, free=3864506368)
2025-11-28 15:51:56,417:INFO:Physical Core: 6
2025-11-28 15:51:56,417:INFO:Logical Core: 12
2025-11-28 15:51:56,417:INFO:Checking libraries
2025-11-28 15:51:56,417:INFO:System:
2025-11-28 15:51:56,417:INFO:    python: 3.10.19 | packaged by conda-forge | (main, Oct 22 2025, 22:23:22) [MSC v.1944 64 bit (AMD64)]
2025-11-28 15:51:56,417:INFO:executable: c:\Users\OMAR\miniconda3\envs\xgb_env\python.exe
2025-11-28 15:51:56,417:INFO:   machine: Windows-10-10.0.26200-SP0
2025-11-28 15:51:56,417:INFO:PyCaret required dependencies:
2025-11-28 15:51:56,417:INFO:                 pip: 25.3
2025-11-28 15:51:56,417:INFO:          setuptools: 80.9.0
2025-11-28 15:51:56,417:INFO:             pycaret: 3.3.2
2025-11-28 15:51:56,417:INFO:             IPython: 8.37.0
2025-11-28 15:51:56,417:INFO:          ipywidgets: 8.1.8
2025-11-28 15:51:56,417:INFO:                tqdm: 4.67.1
2025-11-28 15:51:56,417:INFO:               numpy: 1.26.4
2025-11-28 15:51:56,417:INFO:              pandas: 2.1.4
2025-11-28 15:51:56,417:INFO:              jinja2: 3.1.6
2025-11-28 15:51:56,417:INFO:               scipy: 1.11.4
2025-11-28 15:51:56,417:INFO:              joblib: 1.3.2
2025-11-28 15:51:56,417:INFO:             sklearn: 1.4.2
2025-11-28 15:51:56,417:INFO:                pyod: 2.0.5
2025-11-28 15:51:56,417:INFO:            imblearn: 0.14.0
2025-11-28 15:51:56,417:INFO:   category_encoders: 2.7.0
2025-11-28 15:51:56,417:INFO:            lightgbm: 4.6.0
2025-11-28 15:51:56,417:INFO:               numba: 0.62.1
2025-11-28 15:51:56,417:INFO:            requests: 2.32.5
2025-11-28 15:51:56,417:INFO:          matplotlib: 3.7.5
2025-11-28 15:51:56,417:INFO:          scikitplot: 0.3.7
2025-11-28 15:51:56,417:INFO:         yellowbrick: 1.5
2025-11-28 15:51:56,417:INFO:              plotly: 6.5.0
2025-11-28 15:51:56,417:INFO:    plotly-resampler: Not installed
2025-11-28 15:51:56,417:INFO:             kaleido: 1.2.0
2025-11-28 15:51:56,417:INFO:           schemdraw: 0.15
2025-11-28 15:51:56,417:INFO:         statsmodels: 0.14.5
2025-11-28 15:51:56,417:INFO:              sktime: 0.26.0
2025-11-28 15:51:56,417:INFO:               tbats: 1.1.3
2025-11-28 15:51:56,417:INFO:            pmdarima: 2.0.4
2025-11-28 15:51:56,417:INFO:              psutil: 7.1.3
2025-11-28 15:51:56,417:INFO:          markupsafe: 3.0.3
2025-11-28 15:51:56,417:INFO:             pickle5: Not installed
2025-11-28 15:51:56,417:INFO:         cloudpickle: 3.1.2
2025-11-28 15:51:56,417:INFO:         deprecation: 2.1.0
2025-11-28 15:51:56,417:INFO:              xxhash: 3.6.0
2025-11-28 15:51:56,417:INFO:           wurlitzer: Not installed
2025-11-28 15:51:56,417:INFO:PyCaret optional dependencies:
2025-11-28 15:51:56,417:INFO:                shap: 0.48.0
2025-11-28 15:51:56,417:INFO:           interpret: Not installed
2025-11-28 15:51:56,417:INFO:                umap: Not installed
2025-11-28 15:51:56,417:INFO:     ydata_profiling: Not installed
2025-11-28 15:51:56,417:INFO:  explainerdashboard: Not installed
2025-11-28 15:51:56,417:INFO:             autoviz: Not installed
2025-11-28 15:51:56,417:INFO:           fairlearn: 0.12.0.dev0
2025-11-28 15:51:56,417:INFO:          deepchecks: Not installed
2025-11-28 15:51:56,417:INFO:             xgboost: 3.1.2
2025-11-28 15:51:56,417:INFO:            catboost: Not installed
2025-11-28 15:51:56,417:INFO:              kmodes: Not installed
2025-11-28 15:51:56,417:INFO:             mlxtend: Not installed
2025-11-28 15:51:56,417:INFO:       statsforecast: Not installed
2025-11-28 15:51:56,417:INFO:        tune_sklearn: Not installed
2025-11-28 15:51:56,417:INFO:                 ray: Not installed
2025-11-28 15:51:56,417:INFO:            hyperopt: Not installed
2025-11-28 15:51:56,417:INFO:              optuna: Not installed
2025-11-28 15:51:56,417:INFO:               skopt: Not installed
2025-11-28 15:51:56,417:INFO:              mlflow: Not installed
2025-11-28 15:51:56,417:INFO:              gradio: Not installed
2025-11-28 15:51:56,417:INFO:             fastapi: Not installed
2025-11-28 15:51:56,417:INFO:             uvicorn: Not installed
2025-11-28 15:51:56,417:INFO:              m2cgen: Not installed
2025-11-28 15:51:56,417:INFO:           evidently: Not installed
2025-11-28 15:51:56,417:INFO:               fugue: Not installed
2025-11-28 15:51:56,417:INFO:           streamlit: 1.51.0
2025-11-28 15:51:56,417:INFO:             prophet: Not installed
2025-11-28 15:51:56,417:INFO:None
2025-11-28 15:51:56,417:INFO:Set up data.
2025-11-28 15:51:56,509:INFO:Set up folding strategy.
2025-11-28 15:51:56,509:INFO:Set up train/test split.
2025-11-28 15:51:56,607:INFO:Set up index.
2025-11-28 15:51:56,611:INFO:Assigning column types.
2025-11-28 15:51:56,731:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-11-28 15:51:56,756:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-11-28 15:51:56,756:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-11-28 15:51:56,774:INFO:Soft dependency imported: xgboost: 3.1.2
2025-11-28 15:51:56,775:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-28 15:51:56,802:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-11-28 15:51:56,802:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-11-28 15:51:56,819:INFO:Soft dependency imported: xgboost: 3.1.2
2025-11-28 15:51:56,820:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-28 15:51:56,820:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-11-28 15:51:56,848:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-11-28 15:51:56,865:INFO:Soft dependency imported: xgboost: 3.1.2
2025-11-28 15:51:56,866:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-28 15:51:56,894:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-11-28 15:51:56,910:INFO:Soft dependency imported: xgboost: 3.1.2
2025-11-28 15:51:56,912:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-28 15:51:56,912:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-11-28 15:51:56,952:INFO:Soft dependency imported: xgboost: 3.1.2
2025-11-28 15:51:56,957:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-28 15:51:56,998:INFO:Soft dependency imported: xgboost: 3.1.2
2025-11-28 15:51:56,998:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-28 15:51:57,002:INFO:Preparing preprocessing pipeline...
2025-11-28 15:51:57,020:INFO:Set up simple imputation.
2025-11-28 15:51:57,062:INFO:Set up encoding of ordinal features.
2025-11-28 15:51:57,091:INFO:Set up encoding of categorical features.
2025-11-28 15:51:57,096:INFO:Set up imbalanced handling.
2025-11-28 15:51:57,335:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 15:51:57,630:INFO:Finished creating preprocessing pipeline.
2025-11-28 15:51:57,640:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\OMAR\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['STATE', 'FMONTH', 'DISPCODE',
                                             'PSU', 'CTELENM1', 'PVTRESD1',
                                             'COLGHOUS', 'STATERE1', 'CELPHON1',
                                             'LADULT1', 'COLGSEX1', 'NUMADULT',
                                             'LANDSEX1', 'NUMMEN', 'NUMWOMEN',
                                             'RESPSLCT', 'SAFETIME', 'CTELNUM1',
                                             'CELLFON5', 'CADULT1...
                                    transformer=TargetEncoder(cols=['IDATE',
                                                                    'IDAY'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              random_state=42,
                                                                              sampling_strategy='auto'))))],
         verbose=False)
2025-11-28 15:51:57,640:INFO:Creating final display dataframe.
2025-11-28 15:51:57,843:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 15:51:58,914:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 15:52:00,353:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target          CVDINFR4
2                   Target type            Binary
3           Original data shape      (13262, 327)
4        Transformed data shape      (21507, 333)
5   Transformed train set shape      (17528, 333)
6    Transformed test set shape       (3979, 333)
7              Numeric features               322
8          Categorical features                 4
9      Rows with missing values            100.0%
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16                Fix imbalance              True
17         Fix imbalance method             SMOTE
18               Fold Generator   StratifiedKFold
19                  Fold Number                10
20                     CPU Jobs                -1
21                      Use GPU             False
22               Log Experiment             False
23              Experiment Name  clf-default-name
24                          USI              97a8
2025-11-28 15:52:00,399:INFO:Soft dependency imported: xgboost: 3.1.2
2025-11-28 15:52:00,399:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-28 15:52:00,441:INFO:Soft dependency imported: xgboost: 3.1.2
2025-11-28 15:52:00,445:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-28 15:52:00,445:INFO:setup() successfully completed in 4.04s...............
2025-11-28 15:52:00,502:INFO:Initializing get_config()
2025-11-28 15:52:00,502:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020508BC6920>, variable=X_train)
2025-11-28 15:52:00,502:INFO:Variable: 'X_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_train_transformed' instead.
2025-11-28 15:52:00,502:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'X_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_train_transformed' instead.
  warnings.warn(msg)  # print on screen

2025-11-28 15:52:00,625:INFO:Variable:  returned as        STATE  FMONTH     IDATE IMONTH IDAY IYEAR  DISPCODE           PSU  \
720     54.0     1.0  01192022     01   19  2022    1100.0  2.022002e+09   
3896    20.0     8.0  09042022     09   04  2022    1200.0  2.022005e+09   
12399    9.0     1.0  02282022     02   28  2022    1200.0  2.022006e+09   
1720    22.0     1.0  03212022     03   21  2022    1100.0  2.022002e+09   
4419    51.0     7.0  07082022     07   08  2022    1100.0  2.022007e+09   
...      ...     ...       ...    ...  ...   ...       ...           ...   
868     51.0     7.0  07072022     07   07  2022    1100.0  2.022007e+09   
11800    8.0     1.0  01252022     01   25  2022    1100.0  2.022001e+09   
10049   53.0    10.0  11102022     11   10  2022    1200.0  2.022021e+09   
4993    50.0     7.0  08022022     08   02  2022    1100.0  2.022005e+09   
9992    53.0     4.0  04212022     04   21  2022    1100.0  2.022010e+09   

       CTELENM1  PVTRESD1  COLGHOUS  STATERE1  CELPHON1  LADULT1  COLGSEX1  \
720         NaN       NaN       NaN       NaN       NaN      NaN       NaN   
3896        NaN       NaN       NaN       NaN       NaN      NaN       NaN   
12399       NaN       NaN       NaN       NaN       NaN      NaN       NaN   
1720        NaN       NaN       NaN       NaN       NaN      NaN       NaN   
4419        NaN       NaN       NaN       NaN       NaN      NaN       NaN   
...         ...       ...       ...       ...       ...      ...       ...   
868         NaN       NaN       NaN       NaN       NaN      NaN       NaN   
11800       NaN       NaN       NaN       NaN       NaN      NaN       NaN   
10049       NaN       NaN       NaN       NaN       NaN      NaN       NaN   
4993        NaN       NaN       NaN       NaN       NaN      NaN       NaN   
9992        NaN       NaN       NaN       NaN       NaN      NaN       NaN   

       NUMADULT  LANDSEX1  NUMMEN  NUMWOMEN  RESPSLCT  SAFETIME  CTELNUM1  \
720         NaN       NaN     NaN       NaN       NaN       1.0       1.0   
3896        NaN       NaN     NaN       NaN       NaN       1.0       1.0   
12399       NaN       NaN     NaN       NaN       NaN       1.0       1.0   
1720        NaN       NaN     NaN       NaN       NaN       1.0       1.0   
4419        NaN       NaN     NaN       NaN       NaN       1.0       1.0   
...         ...       ...     ...       ...       ...       ...       ...   
868         NaN       NaN     NaN       NaN       NaN       1.0       1.0   
11800       NaN       NaN     NaN       NaN       NaN       1.0       1.0   
10049       NaN       NaN     NaN       NaN       NaN       1.0       1.0   
4993        NaN       NaN     NaN       NaN       NaN       1.0       1.0   
9992        NaN       NaN     NaN       NaN       NaN       1.0       1.0   

       CELLFON5  CADULT1  CELLSEX1  PVTRESD3  CCLGHOUS  CSTATE1  LANDLINE  \
720         1.0      1.0       1.0       1.0       NaN      1.0       1.0   
3896        1.0      1.0       2.0       1.0       NaN      1.0       1.0   
12399       1.0      1.0       2.0       1.0       NaN      1.0       2.0   
1720        1.0      1.0       2.0       1.0       NaN      1.0       2.0   
4419        1.0      1.0       1.0       1.0       NaN      1.0       1.0   
...         ...      ...       ...       ...       ...      ...       ...   
868         1.0      1.0       1.0       1.0       NaN      1.0       2.0   
11800       1.0      1.0       2.0       1.0       NaN      1.0       2.0   
10049       1.0      1.0       2.0       1.0       NaN      1.0       2.0   
4993        1.0      1.0       2.0       1.0       NaN      1.0       2.0   
9992        1.0      1.0       1.0       1.0       NaN      1.0       2.0   

       HHADULT  SEXVAR  GENHLTH  PHYSHLTH  MENTHLTH  POORHLTH  PRIMINSR  \
720        1.0     1.0      3.0      88.0       3.0      88.0       1.0   
3896       2.0     2.0      1.0      88.0      88.0       NaN       1.0   
12399      4.0     2.0      2.0      88.0      30.0      88.0       1.0   
1720       2.0     2.0      3.0      88.0      88.0       NaN       3.0   
4419       2.0     1.0      2.0      88.0      88.0       NaN       5.0   
...        ...     ...      ...       ...       ...       ...       ...   
868        2.0     1.0      2.0      88.0      88.0       NaN       2.0   
11800      2.0     2.0      4.0      20.0      15.0      20.0       3.0   
10049      2.0     2.0      1.0       5.0      88.0      88.0       1.0   
4993       2.0     2.0      3.0      88.0       5.0      88.0       1.0   
9992       2.0     1.0      3.0      88.0      88.0       NaN      10.0   

       PERSDOC3  MEDCOST1  CHECKUP1  EXERANY2  SLEPTIM1  LASTDEN4  RMVTETH4  \
720         2.0       2.0       1.0       1.0       5.0       1.0       1.0   
3896        1.0       2.0       1.0       1.0       7.0       1.0       8.0   
12399       1.0       1.0       1.0       2.0       7.0       1.0       8.0   
1720        1.0       2.0       1.0       1.0       7.0       1.0       1.0   
4419        3.0       2.0       4.0       1.0       8.0       1.0       8.0   
...         ...       ...       ...       ...       ...       ...       ...   
868         1.0       2.0       1.0       1.0       7.0       1.0       1.0   
11800       2.0       1.0       1.0       2.0      10.0       1.0       8.0   
10049       1.0       2.0       1.0       1.0       6.0       1.0       1.0   
4993        2.0       2.0       1.0       1.0       7.0       1.0       1.0   
9992        2.0       2.0       1.0       1.0       8.0       1.0       1.0   

       CVDCRHD4  CVDSTRK3  ASTHMA3  ASTHNOW  CHCSCNC1  CHCOCNC1  CHCCOPD3  \
720         2.0       2.0      2.0      NaN       1.0       2.0       2.0   
3896        2.0       2.0      2.0      NaN       2.0       2.0       2.0   
12399       2.0       2.0      1.0      1.0       2.0       2.0       2.0   
1720        2.0       2.0      2.0      NaN       2.0       2.0       2.0   
4419        2.0       2.0      2.0      NaN       2.0       2.0       2.0   
...         ...       ...      ...      ...       ...       ...       ...   
868         2.0       2.0      2.0      NaN       2.0       2.0       2.0   
11800       2.0       2.0      1.0      1.0       2.0       2.0       1.0   
10049       2.0       2.0      2.0      NaN       2.0       2.0       2.0   
4993        2.0       2.0      2.0      NaN       2.0       2.0       2.0   
9992        1.0       2.0      2.0      NaN       2.0       2.0       2.0   

       ADDEPEV3  CHCKDNY2  HAVARTH4  DIABETE4  DIABAGE4  MARITAL  EDUCA  \
720         2.0       2.0       2.0       1.0      46.0      1.0    5.0   
3896        2.0       2.0       2.0       3.0       NaN      1.0    6.0   
12399       1.0       2.0       2.0       3.0       NaN      1.0    6.0   
1720        2.0       2.0       2.0       3.0       NaN      1.0    4.0   
4419        2.0       2.0       2.0       3.0       NaN      5.0    4.0   
...         ...       ...       ...       ...       ...      ...    ...   
868         2.0       2.0       2.0       3.0       NaN      1.0    6.0   
11800       1.0       2.0       1.0       3.0       NaN      1.0    6.0   
10049       2.0       2.0       2.0       3.0       NaN      2.0    6.0   
4993        2.0       2.0       2.0       2.0       NaN      1.0    6.0   
9992        2.0       2.0       2.0       3.0       NaN      1.0    4.0   

       RENTHOM1  NUMHHOL4  NUMPHON4  CPDEMO1C  VETERAN3  EMPLOY1  CHILDREN  \
720         1.0       NaN       NaN       1.0       2.0      2.0      88.0   
3896        1.0       NaN       NaN       1.0       2.0      1.0      99.0   
12399       1.0       NaN       NaN       1.0       2.0      1.0       2.0   
1720        1.0       NaN       NaN       1.0       2.0      7.0      88.0   
4419        3.0       NaN       NaN       2.0       2.0      3.0      88.0   
...         ...       ...       ...       ...       ...      ...       ...   
868         1.0       NaN       NaN       1.0       2.0      2.0       1.0   
11800       1.0       NaN       NaN       1.0       2.0      8.0      88.0   
10049       1.0       NaN       NaN       1.0       2.0      1.0      88.0   
4993        1.0       NaN       NaN       1.0       2.0      1.0       3.0   
9992        1.0       NaN       NaN       1.0       2.0      7.0      88.0   

       INCOME3  PREGNANT  WEIGHT2  HEIGHT3  DEAF  BLIND  DECIDE  DIFFWALK  \
720        9.0       NaN    171.0    507.0   2.0    1.0     2.0       2.0   
3896      10.0       2.0   9999.0   9999.0   2.0    2.0     2.0       2.0   
12399     10.0       2.0      NaN      NaN   NaN    NaN     NaN       NaN   
1720       6.0       NaN    125.0    411.0   2.0    2.0     2.0       2.0   
4419      77.0       NaN    230.0    509.0   2.0    2.0     2.0       2.0   
...        ...       ...      ...      ...   ...    ...     ...       ...   
868       99.0       NaN    212.0    601.0   2.0    2.0     2.0       2.0   
11800      6.0       NaN    150.0    509.0   2.0    2.0     2.0       1.0   
10049      9.0       NaN      NaN      NaN   NaN    NaN     NaN       NaN   
4993      10.0       NaN    198.0    504.0   2.0    2.0     2.0       2.0   
9992       9.0       NaN    228.0    600.0   2.0    2.0     2.0       2.0   

       DIFFDRES  DIFFALON  HADMAM  HOWLONG  CERVSCRN  CRVCLCNC  CRVCLPAP  \
720         1.0       2.0     NaN      NaN       NaN       NaN       NaN   
3896        2.0       2.0     1.0      1.0       1.0       2.0       1.0   
12399       NaN       NaN     NaN      NaN       NaN       NaN       NaN   
1720        2.0       2.0     1.0      1.0       1.0       2.0       1.0   
4419        2.0       2.0     NaN      NaN       NaN       NaN       NaN   
...         ...       ...     ...      ...       ...       ...       ...   
868         2.0       2.0     NaN      NaN       NaN       NaN       NaN   
11800       2.0       1.0     1.0      3.0       1.0       3.0       1.0   
10049       NaN       NaN     NaN      NaN       NaN       NaN       NaN   
4993        2.0       2.0     1.0      2.0       1.0       1.0       1.0   
9992        2.0       2.0     NaN      NaN       NaN       NaN       NaN   

       CRVCLHPV  HADHYST2  HADSIGM4  COLNSIGM  COLNTES1  SIGMTES1  LASTSIG4  \
720         NaN       NaN       1.0       1.0       3.0       NaN       NaN   
3896        7.0       2.0       1.0       1.0       1.0       NaN       NaN   
12399       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
1720        2.0       1.0       1.0       1.0       3.0       NaN       NaN   
4419        NaN       NaN       NaN       NaN       NaN       NaN       NaN   
...         ...       ...       ...       ...       ...       ...       ...   
868         NaN       NaN       1.0       1.0       1.0       NaN       NaN   
11800       1.0       2.0       2.0       NaN       NaN       NaN       NaN   
10049       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
4993        1.0       2.0       2.0       NaN       NaN       NaN       NaN   
9992        NaN       NaN       1.0       1.0       5.0       NaN       NaN   

       COLNCNCR  VIRCOLO1  VCLNTES2  SMALSTOL  STOLTEST  STOOLDN2  BLDSTFIT  \
720         2.0       NaN       NaN       NaN       NaN       NaN       NaN   
3896        2.0       NaN       NaN       NaN       NaN       NaN       NaN   
12399       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
1720        2.0       NaN       NaN       NaN       NaN       NaN       NaN   
4419        NaN       NaN       NaN       NaN       NaN       NaN       NaN   
...         ...       ...       ...       ...       ...       ...       ...   
868         2.0       NaN       NaN       NaN       NaN       NaN       NaN   
11800       1.0       2.0       NaN       2.0       NaN       2.0       NaN   
10049       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
4993        2.0       NaN       NaN       NaN       NaN       NaN       NaN   
9992        2.0       NaN       NaN       NaN       NaN       NaN       NaN   

       SDNATES1  SMOKE100  SMOKDAY2  USENOW3  ECIGNOW2  LCSFIRST  LCSLAST  \
720         NaN       1.0       3.0      3.0       4.0      17.0     18.0   
3896        NaN       1.0       1.0      3.0       1.0       NaN      NaN   
12399       NaN       NaN       NaN      NaN       NaN       NaN      NaN   
1720        NaN       2.0       NaN      3.0       1.0       NaN      NaN   
4419        NaN       1.0       1.0      3.0       4.0      20.0      NaN   
...         ...       ...       ...      ...       ...       ...      ...   
868         NaN       2.0       NaN      3.0       1.0       NaN      NaN   
11800       NaN       2.0       NaN      3.0       1.0       NaN      NaN   
10049       NaN       NaN       NaN      NaN       NaN       NaN      NaN   
4993        NaN       2.0       NaN      3.0       1.0       NaN      NaN   
9992        NaN       1.0       3.0      3.0       1.0      16.0     58.0   

       LCSNUMCG  LCSCTSC1  LCSSCNCR  LCSCTWHN  ALCDAY4  AVEDRNK3  DRNK3GE5  \
720         3.0       1.0       2.0       NaN    215.0       1.0      88.0   
3896        NaN       NaN       NaN       NaN      NaN       NaN       NaN   
12399       NaN       NaN       NaN       NaN      NaN       NaN       NaN   
1720        NaN       2.0       NaN       NaN    102.0       1.0      88.0   
4419       20.0       2.0       NaN       NaN    202.0       4.0      88.0   
...         ...       ...       ...       ...      ...       ...       ...   
868         NaN       2.0       NaN       NaN    888.0       NaN       NaN   
11800       NaN       1.0       2.0       NaN    888.0       NaN       NaN   
10049       NaN       NaN       NaN       NaN      NaN       NaN       NaN   
4993        NaN       2.0       NaN       NaN    101.0       1.0      88.0   
9992       20.0       2.0       NaN       NaN    101.0       2.0      88.0   

       MAXDRNKS  FLUSHOT7  FLSHTMY3  PNEUVAC4  TETANUS1  HIVTST7  HIVTSTD3  \
720         2.0       1.0  112021.0       1.0       1.0      1.0   62017.0   
3896        NaN       NaN       NaN       NaN       NaN      NaN       NaN   
12399       NaN       NaN       NaN       NaN       NaN      NaN       NaN   
1720        2.0       1.0  102021.0       1.0       3.0      2.0       NaN   
4419        2.0       2.0       NaN       2.0       4.0      2.0       NaN   
...         ...       ...       ...       ...       ...      ...       ...   
868         NaN       1.0   92021.0       2.0       1.0      1.0  771990.0   
11800       NaN       2.0       NaN       2.0       4.0      2.0       NaN   
10049       NaN       NaN       NaN       NaN       NaN      NaN       NaN   
4993        1.0       2.0       NaN       1.0       1.0      2.0       NaN   
9992        2.0       2.0       NaN       2.0       7.0      2.0       NaN   

       HIVRISK5  COVIDPOS  COVIDSMP  COVIDPRM  PDIABTS1  PREDIAB2  DIABTYPE  \
720         2.0       2.0       NaN       NaN       NaN       NaN       NaN   
3896        NaN       NaN       NaN       NaN       NaN       NaN       NaN   
12399       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
1720        2.0       2.0       NaN       NaN       NaN       NaN       NaN   
4419        2.0       2.0       NaN       NaN       NaN       NaN       NaN   
...         ...       ...       ...       ...       ...       ...       ...   
868         2.0       2.0       NaN       NaN       NaN       NaN       NaN   
11800       2.0       1.0       1.0       2.0       NaN       NaN       NaN   
10049       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
4993        2.0       2.0       NaN       NaN       NaN       NaN       NaN   
9992        2.0       2.0       NaN       NaN       NaN       NaN       NaN   

       INSULIN1  CHKHEMO3  EYEEXAM1  DIABEYE1  DIABEDU1  FEETSORE  TOLDCFS  \
720         NaN       NaN       NaN       NaN       NaN       NaN      NaN   
3896        NaN       NaN       NaN       NaN       NaN       NaN      NaN   
12399       NaN       NaN       NaN       NaN       NaN       NaN      NaN   
1720        NaN       NaN       NaN       NaN       NaN       NaN      NaN   
4419        NaN       NaN       NaN       NaN       NaN       NaN      NaN   
...         ...       ...       ...       ...       ...       ...      ...   
868         NaN       NaN       NaN       NaN       NaN       NaN      NaN   
11800       NaN       NaN       NaN       NaN       NaN       NaN      NaN   
10049       NaN       NaN       NaN       NaN       NaN       NaN      NaN   
4993        NaN       NaN       NaN       NaN       NaN       NaN      NaN   
9992        NaN       NaN       NaN       NaN       NaN       NaN      NaN   

       HAVECFS  WORKCFS  IMFVPLA3  HPVADVC4  HPVADSHT  SHINGLE2  COVIDVA1  \
720        NaN      NaN       NaN       NaN       NaN       NaN       1.0   
3896       NaN      NaN       NaN       NaN       NaN       NaN       NaN   
12399      NaN      NaN       NaN       NaN       NaN       NaN       NaN   
1720       NaN      NaN       NaN       NaN       NaN       NaN       1.0   
4419       NaN      NaN       NaN       NaN       NaN       NaN       NaN   
...        ...      ...       ...       ...       ...       ...       ...   
868        NaN      NaN       NaN       NaN       NaN       1.0       NaN   
11800      NaN      NaN       NaN       NaN       NaN       NaN       NaN   
10049      NaN      NaN       NaN       NaN       NaN       NaN       NaN   
4993       NaN      NaN       NaN       NaN       NaN       NaN       NaN   
9992       NaN      NaN       NaN       NaN       NaN       NaN       NaN   

       COVACGET  COVIDNU1  COVIDINT  COVIDFS1  COVIDSE1  COPDCOGH  COPDFLEM  \
720         NaN       3.0       NaN   42020.0   52020.0       NaN       NaN   
3896        NaN       NaN       NaN       NaN       NaN       NaN       NaN   
12399       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
1720        NaN       3.0       NaN   12022.0   22022.0       NaN       NaN   
4419        NaN       NaN       NaN       NaN       NaN       NaN       NaN   
...         ...       ...       ...       ...       ...       ...       ...   
868         NaN       NaN       NaN       NaN       NaN       NaN       NaN   
11800       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
10049       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
4993        NaN       NaN       NaN       NaN       NaN       NaN       NaN   
9992        NaN       NaN       NaN       NaN       NaN       NaN       NaN   

       COPDBRTH  COPDBTST  COPDSMOK  CNCRDIFF  CNCRAGE  CNCRTYP2  CSRVTRT3  \
720         NaN       NaN       NaN       NaN      NaN       NaN       NaN   
3896        NaN       NaN       NaN       NaN      NaN       NaN       NaN   
12399       NaN       NaN       NaN       NaN      NaN       NaN       NaN   
1720        NaN       NaN       NaN       NaN      NaN       NaN       NaN   
4419        NaN       NaN       NaN       NaN      NaN       NaN       NaN   
...         ...       ...       ...       ...      ...       ...       ...   
868         NaN       NaN       NaN       NaN      NaN       NaN       NaN   
11800       NaN       NaN       NaN       NaN      NaN       NaN       NaN   
10049       NaN       NaN       NaN       NaN      NaN       NaN       NaN   
4993        NaN       NaN       NaN       NaN      NaN       NaN       NaN   
9992        NaN       NaN       NaN       NaN      NaN       NaN       NaN   

       CSRVDOC1  CSRVSUM  CSRVRTRN  CSRVINST  CSRVINSR  CSRVDEIN  CSRVCLIN  \
720         NaN      NaN       NaN       NaN       NaN       NaN       NaN   
3896        NaN      NaN       NaN       NaN       NaN       NaN       NaN   
12399       NaN      NaN       NaN       NaN       NaN       NaN       NaN   
1720        NaN      NaN       NaN       NaN       NaN       NaN       NaN   
4419        NaN      NaN       NaN       NaN       NaN       NaN       NaN   
...         ...      ...       ...       ...       ...       ...       ...   
868         NaN      NaN       NaN       NaN       NaN       NaN       NaN   
11800       NaN      NaN       NaN       NaN       NaN       NaN       NaN   
10049       NaN      NaN       NaN       NaN       NaN       NaN       NaN   
4993        NaN      NaN       NaN       NaN       NaN       NaN       NaN   
9992        NaN      NaN       NaN       NaN       NaN       NaN       NaN   

       CSRVPAIN  CSRVCTL2  PSATEST1  PSATIME1  PCPSARS2  PSASUGST  PCSTALK1  \
720         NaN       NaN       NaN       NaN       NaN       NaN       NaN   
3896        NaN       NaN       NaN       NaN       NaN       NaN       NaN   
12399       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
1720        NaN       NaN       NaN       NaN       NaN       NaN       NaN   
4419        NaN       NaN       NaN       NaN       NaN       NaN       NaN   
...         ...       ...       ...       ...       ...       ...       ...   
868         NaN       NaN       NaN       NaN       NaN       NaN       NaN   
11800       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
10049       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
4993        NaN       NaN       NaN       NaN       NaN       NaN       NaN   
9992        NaN       NaN       NaN       NaN       NaN       NaN       NaN   

       CIMEMLOS  CDHOUSE  CDASSIST  CDHELP  CDSOCIAL  CDDISCUS  CAREGIV1  \
720         NaN      NaN       NaN     NaN       NaN       NaN       NaN   
3896        NaN      NaN       NaN     NaN       NaN       NaN       NaN   
12399       NaN      NaN       NaN     NaN       NaN       NaN       NaN   
1720        NaN      NaN       NaN     NaN       NaN       NaN       2.0   
4419        NaN      NaN       NaN     NaN       NaN       NaN       2.0   
...         ...      ...       ...     ...       ...       ...       ...   
868         2.0      NaN       NaN     NaN       NaN       NaN       2.0   
11800       NaN      NaN       NaN     NaN       NaN       NaN       NaN   
10049       NaN      NaN       NaN     NaN       NaN       NaN       NaN   
4993        2.0      NaN       NaN     NaN       NaN       NaN       NaN   
9992        NaN      NaN       NaN     NaN       NaN       NaN       2.0   

       CRGVREL4  CRGVLNG1  CRGVHRS1  CRGVPRB3  CRGVALZD  CRGVPER1  CRGVHOU1  \
720         NaN       NaN       NaN       NaN       NaN       NaN       NaN   
3896        NaN       NaN       NaN       NaN       NaN       NaN       NaN   
12399       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
1720        NaN       NaN       NaN       NaN       NaN       NaN       NaN   
4419        NaN       NaN       NaN       NaN       NaN       NaN       NaN   
...         ...       ...       ...       ...       ...       ...       ...   
868         NaN       NaN       NaN       NaN       NaN       NaN       NaN   
11800       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
10049       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
4993        NaN       NaN       NaN       NaN       NaN       NaN       NaN   
9992        NaN       NaN       NaN       NaN       NaN       NaN       NaN   

       CRGVEXPT  ACEDEPRS  ACEDRINK  ACEDRUGS  ACEPRISN  ACEDIVRC  ACEPUNCH  \
720         NaN       NaN       NaN       NaN       NaN       NaN       NaN   
3896        NaN       NaN       NaN       NaN       NaN       NaN       NaN   
12399       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
1720        1.0       NaN       NaN       NaN       NaN       NaN       NaN   
4419        1.0       2.0       2.0       2.0       2.0       1.0       1.0   
...         ...       ...       ...       ...       ...       ...       ...   
868         1.0       1.0       2.0       2.0       2.0       2.0       3.0   
11800       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
10049       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
4993        NaN       NaN       NaN       NaN       NaN       NaN       NaN   
9992        2.0       NaN       NaN       NaN       NaN       NaN       NaN   

       ACEHURT1  ACESWEAR  ACETOUCH  ACETTHEM  ACEHVSEX  ACEADSAF  ACEADNED  \
720         NaN       NaN       NaN       NaN       NaN       NaN       NaN   
3896        NaN       NaN       NaN       NaN       NaN       NaN       NaN   
12399       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
1720        NaN       NaN       NaN       NaN       NaN       NaN       NaN   
4419        1.0       1.0       1.0       1.0       1.0       5.0       5.0   
...         ...       ...       ...       ...       ...       ...       ...   
868         1.0       1.0       1.0       1.0       1.0       5.0       5.0   
11800       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
10049       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
4993        NaN       NaN       NaN       NaN       NaN       NaN       NaN   
9992        NaN       NaN       NaN       NaN       NaN       NaN       NaN   

       LSATISFY  EMTSUPRT  SDHISOLT  SDHEMPLY  FOODSTMP  SDHFOOD1  SDHBILLS  \
720         3.0       7.0       7.0       2.0       2.0       5.0       2.0   
3896        NaN       NaN       NaN       NaN       NaN       NaN       NaN   
12399       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
1720        NaN       NaN       NaN       NaN       NaN       NaN       NaN   
4419        NaN       NaN       NaN       NaN       NaN       NaN       NaN   
...         ...       ...       ...       ...       ...       ...       ...   
868         NaN       NaN       NaN       NaN       NaN       NaN       NaN   
11800       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
10049       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
4993        2.0       2.0       3.0       2.0       1.0       5.0       2.0   
9992        1.0       1.0       4.0       2.0       2.0       5.0       2.0   

       SDHUTILS  SDHTRNSP  SDHSTRE1  MARIJAN1  MARJSMOK  MARJEAT  MARJVAPE  \
720         2.0       2.0       2.0       NaN       NaN      NaN       NaN   
3896        NaN       NaN       NaN       NaN       NaN      NaN       NaN   
12399       NaN       NaN       NaN       NaN       NaN      NaN       NaN   
1720        NaN       NaN       NaN       NaN       NaN      NaN       NaN   
4419        NaN       NaN       NaN      88.0       NaN      NaN       NaN   
...         ...       ...       ...       ...       ...      ...       ...   
868         NaN       NaN       NaN      88.0       NaN      NaN       NaN   
11800       NaN       NaN       NaN       NaN       NaN      NaN       NaN   
10049       NaN       NaN       NaN       NaN       NaN      NaN       NaN   
4993        2.0       2.0       4.0       NaN       NaN      NaN       NaN   
9992        2.0       2.0       4.0       NaN       NaN      NaN       NaN   

       MARJDAB  MARJOTHR  USEMRJN4  LASTSMK2  STOPSMK2  MENTCIGS  MENTECIG  \
720        NaN       NaN       NaN       NaN       NaN       NaN       NaN   
3896       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
12399      NaN       NaN       NaN       NaN       NaN       NaN       NaN   
1720       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
4419       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
...        ...       ...       ...       ...       ...       ...       ...   
868        NaN       NaN       NaN       NaN       NaN       NaN       NaN   
11800      NaN       NaN       NaN       NaN       NaN       NaN       NaN   
10049      NaN       NaN       NaN       NaN       NaN       NaN       NaN   
4993       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
9992       NaN       NaN       NaN       5.0       NaN       NaN       NaN   

       HEATTBCO  ASBIALCH  ASBIDRNK  ASBIBING  ASBIADVC  ASBIRDUC  FIREARM5  \
720         NaN       1.0       1.0       1.0       1.0       2.0       NaN   
3896        NaN       NaN       NaN       NaN       NaN       NaN       NaN   
12399       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
1720        NaN       NaN       NaN       NaN       NaN       NaN       NaN   
4419        NaN       NaN       NaN       NaN       NaN       NaN       NaN   
...         ...       ...       ...       ...       ...       ...       ...   
868         NaN       NaN       NaN       NaN       NaN       NaN       NaN   
11800       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
10049       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
4993        NaN       NaN       NaN       NaN       NaN       NaN       NaN   
9992        NaN       NaN       NaN       NaN       NaN       NaN       NaN   

       GUNLOAD  LOADULK2  RCSGEND1  RCSXBRTH  RCSRLTN2  CASTHDX2  CASTHNO2  \
720        NaN       NaN       NaN       NaN       NaN       NaN       NaN   
3896       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
12399      NaN       NaN       NaN       NaN       NaN       NaN       NaN   
1720       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
4419       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
...        ...       ...       ...       ...       ...       ...       ...   
868        NaN       NaN       NaN       NaN       NaN       NaN       NaN   
11800      NaN       NaN       NaN       NaN       NaN       NaN       NaN   
10049      NaN       NaN       NaN       NaN       NaN       NaN       NaN   
4993       NaN       NaN       2.0       NaN       1.0       2.0       NaN   
9992       NaN       NaN       NaN       NaN       NaN       NaN       NaN   

       BIRTHSEX  SOMALE  SOFEMALE  TRNSGNDR  HADSEX  PFPPRVN4  TYPCNTR9  \
720         1.0     2.0       NaN       4.0     NaN       NaN       NaN   
3896        NaN     NaN       2.0       4.0     NaN       NaN       NaN   
12399       NaN     NaN       2.0       4.0     NaN       NaN       NaN   
1720        2.0     NaN       2.0       4.0     NaN       NaN       NaN   
4419        NaN     2.0       NaN       4.0     NaN       NaN       NaN   
...         ...     ...       ...       ...     ...       ...       ...   
868         NaN     2.0       NaN       4.0     NaN       NaN       NaN   
11800       NaN     NaN       2.0       4.0     NaN       NaN       NaN   
10049       NaN     NaN       2.0       4.0     NaN       NaN       NaN   
4993        2.0     NaN       2.0       4.0     NaN       NaN       NaN   
9992        NaN     2.0       NaN       4.0     NaN       NaN       NaN   

       BRTHCNT4  WHEREGET  NOBCUSE8  BCPREFER  RRCLASS3  RRCOGNT2  RRTREAT  \
720         NaN       NaN       NaN       NaN       1.0       4.0      7.0   
3896        NaN       NaN       NaN       NaN       NaN       NaN      NaN   
12399       NaN       NaN       NaN       NaN       NaN       NaN      NaN   
1720        NaN       NaN       NaN       NaN       1.0       1.0      2.0   
4419        NaN       NaN       NaN       NaN       2.0       1.0      2.0   
...         ...       ...       ...       ...       ...       ...      ...   
868         NaN       NaN       NaN       NaN       1.0       5.0      3.0   
11800       NaN       NaN       NaN       NaN       NaN       NaN      NaN   
10049       NaN       NaN       NaN       NaN       NaN       NaN      NaN   
4993        NaN       NaN       NaN       NaN       3.0       8.0      2.0   
9992        NaN       NaN       NaN       NaN       NaN       NaN      NaN   

       RRATWRK2  RRHCARE4  RRPHYSM2  QSTVER  QSTLANG  METSTAT  URBSTAT  \
720         2.0       2.0       2.0    20.0      1.0      1.0      1.0   
3896        NaN       NaN       NaN    21.0      1.0      1.0      1.0   
12399       NaN       NaN       NaN    22.0      1.0      1.0      1.0   
1720        NaN       2.0       2.0    20.0      1.0      1.0      1.0   
4419        NaN       2.0       2.0    20.0      1.0      1.0      1.0   
...         ...       ...       ...     ...      ...      ...      ...   
868         2.0       3.0       2.0    20.0      1.0      1.0      1.0   
11800       NaN       NaN       NaN    21.0      1.0      2.0      1.0   
10049       NaN       NaN       NaN    20.0      1.0      1.0      1.0   
4993        2.0       2.0       2.0    20.0      1.0      1.0      1.0   
9992        NaN       NaN       NaN    20.0      1.0      1.0      1.0   

       MSCODE     STSTR      STRWT  RAWRAKE    WT2RAKE  IMPRACE  CHISPNC  \
720       NaN  542011.0  31.419962      1.0  31.419962      1.0      NaN   
3896      NaN  202031.0  25.224237      1.0  25.224237      1.0      9.0   
12399     NaN   92082.0   8.240453      1.0   8.240453      1.0      9.0   
1720      NaN  222101.0  30.394903      1.0  30.394903      1.0      NaN   
4419      NaN  512101.0  26.973183      1.0  26.973183      2.0      NaN   
...       ...       ...        ...      ...        ...      ...      ...   
868       NaN  512131.0  27.471043      1.0  27.471043      1.0      NaN   
11800     NaN   82011.0  32.891766      1.0  32.891766      1.0      NaN   
10049     NaN  532031.0  29.512003      1.0  29.512003      1.0      9.0   
4993      NaN  502041.0   4.915876      1.0   4.915876      5.0      1.0   
9992      NaN  532111.0  24.901403      1.0  24.901403      1.0      9.0   

       CRACE2  CPRACE2  CAGEG     CLLCPWT  DUALUSE   DUALCOR     LLCPWT2  \
720       NaN      NaN    NaN         NaN      2.0  0.549764  227.480301   
3896      NaN      NaN    NaN         NaN      2.0  0.464215  205.222443   
12399     NaN      NaN    NaN         NaN      9.0       NaN  119.102203   
1720      NaN      NaN    NaN         NaN      9.0       NaN  562.665955   
4419      NaN      NaN    NaN         NaN      2.0  0.427727  817.554260   
...       ...      ...    ...         ...      ...       ...         ...   
868       NaN      NaN    NaN         NaN      9.0       NaN  595.094177   
11800     NaN      NaN    NaN         NaN      9.0       NaN  389.329376   
10049     NaN      NaN    NaN         NaN      9.0       NaN  263.843597   
4993     88.0      NaN    3.0  219.474854      9.0       NaN   68.351936   
9992      NaN      NaN    NaN         NaN      9.0       NaN  245.326355   

            LLCPWT  RFHLTH  PHYS14D  MENT14D  HLTHPLN  HCVU652  TOTINDA  \
720     221.263245     1.0      1.0      2.0      1.0      1.0      1.0   
3896    172.647430     1.0      1.0      1.0      1.0      9.0      1.0   
12399   103.267838     1.0      1.0      3.0      1.0      1.0      2.0   
1720    268.984131     1.0      1.0      1.0      1.0      9.0      1.0   
4419   2100.551270     1.0      1.0      1.0      1.0      1.0      1.0   
...            ...     ...      ...      ...      ...      ...      ...   
868     321.381378     1.0      1.0      1.0      1.0      1.0      1.0   
11800   177.848862     2.0      3.0      3.0      1.0      1.0      2.0   
10049   166.740921     1.0      2.0      1.0      1.0      1.0      1.0   
4993     33.581871     1.0      1.0      2.0      1.0      1.0      1.0   
9992    176.818588     1.0      1.0      1.0      1.0      1.0      1.0   

       EXTETH3  ALTETH3  DENVST3  MICHD  LTASTH1  CASTHM1  ASTHMS1  DRDXAR2  \
720        2.0      NaN      1.0    2.0      1.0      1.0      3.0      2.0   
3896       1.0      9.0      1.0    2.0      1.0      1.0      3.0      2.0   
12399      1.0      NaN      1.0    2.0      2.0      2.0      1.0      2.0   
1720       2.0      1.0      1.0    2.0      1.0      1.0      3.0      2.0   
4419       1.0      NaN      1.0    2.0      1.0      1.0      3.0      2.0   
...        ...      ...      ...    ...      ...      ...      ...      ...   
868        2.0      NaN      1.0    2.0      1.0      1.0      3.0      2.0   
11800      1.0      NaN      1.0    2.0      2.0      2.0      1.0      1.0   
10049      2.0      NaN      1.0    2.0      1.0      1.0      3.0      2.0   
4993       2.0      NaN      1.0    2.0      1.0      1.0      3.0      2.0   
9992       2.0      NaN      1.0    1.0      1.0      1.0      3.0      2.0   

       PRACE2  MRACE2  HISPANC  RACE1  RACEG22  RACEGR4  RACEPR1  SEX  \
720      88.0    88.0      2.0    9.0      9.0      9.0      1.0  1.0   
3896      1.0     1.0      2.0    1.0      1.0      1.0      1.0  2.0   
12399     1.0     1.0      2.0    1.0      1.0      1.0      1.0  2.0   
1720      1.0     1.0      2.0    1.0      1.0      1.0      1.0  2.0   
4419      2.0     2.0      2.0    2.0      2.0      2.0      2.0  1.0   
...       ...     ...      ...    ...      ...      ...      ...  ...   
868       1.0     1.0      2.0    1.0      1.0      1.0      1.0  1.0   
11800     1.0     1.0      2.0    1.0      1.0      1.0      1.0  2.0   
10049     1.0     1.0      2.0    1.0      1.0      1.0      1.0  2.0   
4993     88.0    88.0      1.0    8.0      2.0      5.0      7.0  2.0   
9992      1.0     1.0      2.0    1.0      1.0      1.0      1.0  1.0   

       AGEG5YR  AGE65YR  AGE80  AGE_G  HTIN4   HTM4    WTKG3    BMI5  BMI5CAT  \
720        9.0      1.0   63.0    5.0   67.0  170.0   7756.0  2678.0      3.0   
3896      14.0      3.0   52.0    4.0    NaN    NaN      NaN     NaN      NaN   
12399      5.0      1.0   40.0    3.0    NaN    NaN      NaN     NaN      NaN   
1720      12.0      2.0   75.0    6.0   59.0  150.0   5670.0  2525.0      3.0   
4419       2.0      1.0   25.0    2.0   69.0  175.0  10433.0  3396.0      4.0   
...        ...      ...    ...    ...    ...    ...      ...     ...      ...   
868        7.0      1.0   52.0    4.0   73.0  185.0   9616.0  2797.0      3.0   
11800      8.0      1.0   55.0    5.0   69.0  175.0   6804.0  2215.0      2.0   
10049      7.0      1.0   52.0    4.0    NaN    NaN      NaN     NaN      NaN   
4993       7.0      1.0   50.0    4.0   64.0  163.0   8981.0  3399.0      4.0   
9992       9.0      1.0   62.0    5.0   72.0  183.0  10342.0  3092.0      4.0   

       RFBMI5  CHLDCNT  EDUCAG  INCOMG1  RFMAM22  MAM5023  HADCOLN  CLNSCP1  \
720       2.0      1.0     3.0      6.0      NaN      NaN      1.0      1.0   
3896      9.0      9.0     4.0      6.0      NaN      NaN      1.0      NaN   
12399     9.0      3.0     4.0      6.0      9.0      NaN      NaN      NaN   
1720      2.0      1.0     2.0      4.0      1.0      NaN      1.0      1.0   
4419      2.0      1.0     2.0      9.0      NaN      NaN      NaN      NaN   
...       ...      ...     ...      ...      ...      ...      ...      ...   
868       2.0      2.0     4.0      9.0      NaN      NaN      1.0      1.0   
11800     1.0      1.0     4.0      4.0      2.0      2.0      2.0      3.0   
10049     9.0      1.0     4.0      6.0      9.0      NaN      NaN      NaN   
4993      2.0      4.0     4.0      6.0      1.0      1.0      2.0      3.0   
9992      2.0      1.0     2.0      6.0      NaN      NaN      1.0      2.0   

       HADSIGM  SGMSCP1  SGMS101  RFBLDS5  STOLDN1  VIRCOL1  SBONTI1  CRCREC2  \
720        2.0      3.0      3.0      3.0      3.0      3.0      3.0      1.0   
3896       2.0      NaN      NaN      NaN      NaN      NaN      NaN      NaN   
12399      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN   
1720       2.0      3.0      3.0      3.0      3.0      3.0      3.0      1.0   
4419       NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN   
...        ...      ...      ...      ...      ...      ...      ...      ...   
868        2.0      3.0      3.0      3.0      3.0      3.0      3.0      1.0   
11800      2.0      3.0      3.0      3.0      3.0      3.0      3.0      3.0   
10049      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN   
4993       2.0      3.0      3.0      3.0      3.0      3.0      3.0      3.0   
9992       2.0      3.0      3.0      3.0      3.0      3.0      3.0      2.0   

       SMOKER3  RFSMOK3  CURECI2  YRSSMOK  PACKDAY  PACKYRS  YRSQUIT  SMOKGRP  \
720        3.0      1.0      1.0      1.0     0.15      0.0     45.0      3.0   
3896       1.0      2.0      1.0      NaN      NaN      NaN      NaN      3.0   
12399      9.0      9.0      9.0      NaN      NaN      NaN      NaN      NaN   
1720       4.0      1.0      1.0      NaN      NaN      NaN      NaN      4.0   
4419       1.0      2.0      1.0      5.0     1.00      5.0      NaN      3.0   
...        ...      ...      ...      ...      ...      ...      ...      ...   
868        4.0      1.0      1.0      NaN      NaN      NaN      NaN      4.0   
11800      4.0      1.0      1.0      NaN      NaN      NaN      NaN      4.0   
10049      9.0      9.0      9.0      NaN      NaN      NaN      NaN      NaN   
4993       4.0      1.0      1.0      NaN      NaN      NaN      NaN      4.0   
9992       3.0      1.0      1.0     42.0     1.00     42.0      4.0      2.0   

       LCSREC  DRNKANY6  DROCDY4_  RFBING6  DRNKWK2  RFDRHV8  FLSHOT7  \
720       2.0       1.0      50.0      1.0    350.0      1.0      NaN   
3896      NaN       9.0     900.0      9.0  99900.0      9.0      9.0   
12399     NaN       9.0     900.0      9.0  99900.0      9.0      NaN   
1720      NaN       1.0      29.0      1.0    200.0      1.0      1.0   
4419      NaN       1.0       7.0      1.0    187.0      1.0      NaN   
...       ...       ...       ...      ...      ...      ...      ...   
868       NaN       2.0       0.0      1.0      0.0      1.0      NaN   
11800     NaN       2.0       0.0      1.0      0.0      1.0      NaN   
10049     NaN       9.0     900.0      9.0  99900.0      9.0      NaN   
4993      NaN       1.0      14.0      1.0    100.0      1.0      NaN   
9992      NaN       1.0      14.0      1.0    200.0      1.0      NaN   

       PNEUMO3  AIDTST4  
720        NaN      1.0  
3896       9.0      NaN  
12399      NaN      NaN  
1720       1.0      2.0  
4419       NaN      2.0  
...        ...      ...  
868        NaN      1.0  
11800      NaN      2.0  
10049      NaN      NaN  
4993       NaN      2.0  
9992       NaN      2.0  

[9283 rows x 326 columns]
2025-11-28 15:52:00,625:INFO:get_config() successfully completed......................................
2025-11-28 15:52:00,629:INFO:Initializing get_config()
2025-11-28 15:52:00,629:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020508BC6920>, variable=X_test)
2025-11-28 15:52:00,629:INFO:Variable: 'X_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_test_transformed' instead.
2025-11-28 15:52:00,629:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'X_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_test_transformed' instead.
  warnings.warn(msg)  # print on screen

2025-11-28 15:52:00,746:INFO:Variable:  returned as       STATE  FMONTH     IDATE IMONTH IDAY IYEAR  DISPCODE           PSU  \
3064   28.0     1.0  04202022     04   20  2022    1200.0  2.022001e+09   
7094   49.0     7.0  08022022     08   02  2022    1100.0  2.022001e+09   
2690   55.0    11.0  11192022     11   19  2022    1200.0  2.022009e+09   
5406   33.0     1.0  01302022     01   30  2022    1100.0  2.022001e+09   
4078   19.0     5.0  05242022     05   24  2022    1100.0  2.022007e+09   
...     ...     ...       ...    ...  ...   ...       ...           ...   
3848   12.0     5.0  05102022     05   10  2022    1100.0  2.022007e+09   
9966   45.0     8.0  09022022     09   02  2022    1100.0  2.022007e+09   
7841   29.0     9.0  09192022     09   19  2022    1100.0  2.022006e+09   
7411   15.0    10.0  10292022     10   29  2022    1100.0  2.022006e+09   
7035   27.0     7.0  08042022     08   04  2022    1100.0  2.022008e+09   

      CTELENM1  PVTRESD1  COLGHOUS  STATERE1  CELPHON1  LADULT1  COLGSEX1  \
3064       NaN       NaN       NaN       NaN       NaN      NaN       NaN   
7094       1.0       1.0       NaN       1.0       2.0      1.0       NaN   
2690       NaN       NaN       NaN       NaN       NaN      NaN       NaN   
5406       1.0       1.0       NaN       1.0       2.0      1.0       NaN   
4078       NaN       NaN       NaN       NaN       NaN      NaN       NaN   
...        ...       ...       ...       ...       ...      ...       ...   
3848       NaN       NaN       NaN       NaN       NaN      NaN       NaN   
9966       NaN       NaN       NaN       NaN       NaN      NaN       NaN   
7841       NaN       NaN       NaN       NaN       NaN      NaN       NaN   
7411       NaN       NaN       NaN       NaN       NaN      NaN       NaN   
7035       NaN       NaN       NaN       NaN       NaN      NaN       NaN   

      NUMADULT  LANDSEX1  NUMMEN  NUMWOMEN  RESPSLCT  SAFETIME  CTELNUM1  \
3064       NaN       NaN     NaN       NaN       NaN       1.0       1.0   
7094       2.0       NaN     1.0       1.0       2.0       NaN       NaN   
2690       NaN       NaN     NaN       NaN       NaN       1.0       1.0   
5406       1.0       2.0     NaN       NaN       NaN       NaN       NaN   
4078       NaN       NaN     NaN       NaN       NaN       1.0       1.0   
...        ...       ...     ...       ...       ...       ...       ...   
3848       NaN       NaN     NaN       NaN       NaN       1.0       1.0   
9966       NaN       NaN     NaN       NaN       NaN       1.0       1.0   
7841       NaN       NaN     NaN       NaN       NaN       1.0       1.0   
7411       NaN       NaN     NaN       NaN       NaN       1.0       1.0   
7035       NaN       NaN     NaN       NaN       NaN       1.0       1.0   

      CELLFON5  CADULT1  CELLSEX1  PVTRESD3  CCLGHOUS  CSTATE1  LANDLINE  \
3064       1.0      1.0       2.0       1.0       NaN      1.0       2.0   
7094       NaN      NaN       NaN       NaN       NaN      NaN       NaN   
2690       1.0      1.0       1.0       1.0       NaN      1.0       2.0   
5406       NaN      NaN       NaN       NaN       NaN      NaN       NaN   
4078       1.0      1.0       1.0       1.0       NaN      1.0       2.0   
...        ...      ...       ...       ...       ...      ...       ...   
3848       1.0      1.0       2.0       1.0       NaN      1.0       2.0   
9966       1.0      1.0       2.0       1.0       NaN      1.0       2.0   
7841       1.0      1.0       2.0       1.0       NaN      1.0       2.0   
7411       1.0      1.0       1.0       1.0       NaN      1.0       2.0   
7035       1.0      1.0       2.0       1.0       NaN      1.0       2.0   

      HHADULT  SEXVAR  GENHLTH  PHYSHLTH  MENTHLTH  POORHLTH  PRIMINSR  \
3064      3.0     2.0      3.0       2.0       1.0       1.0       1.0   
7094      NaN     2.0      4.0      88.0      15.0      88.0       3.0   
2690      2.0     1.0      1.0      88.0      88.0       NaN       1.0   
5406      NaN     2.0      4.0      30.0      10.0      88.0       3.0   
4078      2.0     1.0      1.0      88.0      88.0       NaN       1.0   
...       ...     ...      ...       ...       ...       ...       ...   
3848      2.0     2.0      1.0      88.0       2.0      88.0       1.0   
9966      2.0     2.0      1.0      88.0      88.0       NaN       1.0   
7841      2.0     2.0      2.0      88.0      88.0       NaN       3.0   
7411      4.0     1.0      3.0      88.0      88.0       NaN       1.0   
7035      5.0     2.0      3.0      88.0      88.0       NaN       1.0   

      PERSDOC3  MEDCOST1  CHECKUP1  EXERANY2  SLEPTIM1  LASTDEN4  RMVTETH4  \
3064       1.0       2.0       1.0       2.0       6.0       1.0       1.0   
7094       1.0       2.0       1.0       1.0       8.0       1.0       8.0   
2690       1.0       2.0       1.0       1.0       6.0       1.0       8.0   
5406       2.0       2.0       1.0       2.0       6.0       4.0       3.0   
4078       1.0       2.0       1.0       1.0       8.0       1.0       2.0   
...        ...       ...       ...       ...       ...       ...       ...   
3848       2.0       2.0       1.0       1.0       7.0       1.0       8.0   
9966       3.0       2.0       1.0       1.0       6.0       1.0       8.0   
7841       3.0       2.0       1.0       2.0       5.0       1.0       2.0   
7411       1.0       2.0       2.0       2.0       5.0       4.0       8.0   
7035       3.0       2.0       1.0       1.0       8.0       1.0       1.0   

      CVDCRHD4  CVDSTRK3  ASTHMA3  ASTHNOW  CHCSCNC1  CHCOCNC1  CHCCOPD3  \
3064       2.0       2.0      2.0      NaN       1.0       2.0       2.0   
7094       2.0       2.0      1.0      2.0       2.0       2.0       2.0   
2690       2.0       2.0      2.0      NaN       2.0       2.0       2.0   
5406       1.0       1.0      1.0      1.0       2.0       2.0       1.0   
4078       2.0       2.0      2.0      NaN       2.0       2.0       2.0   
...        ...       ...      ...      ...       ...       ...       ...   
3848       2.0       2.0      2.0      NaN       2.0       2.0       2.0   
9966       2.0       2.0      2.0      NaN       2.0       2.0       2.0   
7841       2.0       2.0      2.0      NaN       2.0       2.0       2.0   
7411       2.0       2.0      2.0      NaN       2.0       2.0       2.0   
7035       2.0       2.0      2.0      NaN       2.0       2.0       2.0   

      ADDEPEV3  CHCKDNY2  HAVARTH4  DIABETE4  DIABAGE4  MARITAL  EDUCA  \
3064       2.0       2.0       2.0       3.0       NaN      1.0    5.0   
7094       1.0       2.0       1.0       3.0       NaN      1.0    5.0   
2690       2.0       2.0       2.0       3.0       NaN      1.0    5.0   
5406       2.0       2.0       1.0       1.0      65.0      9.0    6.0   
4078       2.0       2.0       2.0       3.0       NaN      1.0    4.0   
...        ...       ...       ...       ...       ...      ...    ...   
3848       7.0       2.0       2.0       3.0       NaN      1.0    6.0   
9966       2.0       2.0       2.0       3.0       NaN      5.0    6.0   
7841       1.0       2.0       7.0       3.0       NaN      1.0    4.0   
7411       2.0       2.0       2.0       3.0       NaN      2.0    5.0   
7035       2.0       2.0       1.0       3.0       NaN      1.0    6.0   

      RENTHOM1  NUMHHOL4  NUMPHON4  CPDEMO1C  VETERAN3  EMPLOY1  CHILDREN  \
3064       1.0       NaN       NaN       1.0       2.0      1.0       1.0   
7094       1.0       1.0       1.0       1.0       2.0      7.0      88.0   
2690       1.0       NaN       NaN       1.0       2.0      1.0      88.0   
5406       1.0       2.0       NaN       8.0       2.0      7.0      88.0   
4078       1.0       NaN       NaN       1.0       2.0      1.0      88.0   
...        ...       ...       ...       ...       ...      ...       ...   
3848       1.0       NaN       NaN       2.0       2.0      1.0       3.0   
9966       2.0       NaN       NaN       1.0       2.0      1.0      88.0   
7841       1.0       NaN       NaN       1.0       2.0      1.0      88.0   
7411       2.0       NaN       NaN       1.0       2.0      1.0       1.0   
7035       1.0       NaN       NaN       1.0       2.0      1.0      88.0   

      INCOME3  PREGNANT  WEIGHT2  HEIGHT3  DEAF  BLIND  DECIDE  DIFFWALK  \
3064     99.0       2.0   9999.0   9999.0   NaN    NaN     NaN       NaN   
7094     77.0       NaN    140.0    503.0   2.0    2.0     2.0       2.0   
2690      6.0       NaN    176.0    600.0   2.0    2.0     2.0       2.0   
5406     99.0       NaN    240.0    406.0   2.0    2.0     2.0       1.0   
4078      9.0       NaN    200.0    600.0   2.0    2.0     2.0       2.0   
...       ...       ...      ...      ...   ...    ...     ...       ...   
3848     11.0       2.0    120.0    504.0   2.0    2.0     2.0       2.0   
9966     11.0       2.0    115.0    502.0   2.0    2.0     2.0       2.0   
7841      4.0       NaN    170.0    507.0   2.0    2.0     2.0       2.0   
7411      9.0       NaN    180.0    507.0   2.0    2.0     2.0       2.0   
7035      9.0       NaN    170.0    506.0   2.0    2.0     2.0       2.0   

      DIFFDRES  DIFFALON  HADMAM  HOWLONG  CERVSCRN  CRVCLCNC  CRVCLPAP  \
3064       NaN       NaN     NaN      NaN       NaN       NaN       NaN   
7094       2.0       2.0     1.0      1.0       1.0       7.0       2.0   
2690       2.0       2.0     NaN      NaN       NaN       NaN       NaN   
5406       2.0       2.0     1.0      2.0       1.0       2.0       2.0   
4078       2.0       2.0     NaN      NaN       NaN       NaN       NaN   
...        ...       ...     ...      ...       ...       ...       ...   
3848       2.0       2.0     2.0      NaN       7.0       NaN       NaN   
9966       2.0       2.0     2.0      NaN       1.0       1.0       1.0   
7841       2.0       2.0     1.0      1.0       1.0       2.0       1.0   
7411       2.0       2.0     NaN      NaN       NaN       NaN       NaN   
7035       2.0       2.0     1.0      1.0       1.0       4.0       1.0   

      CRVCLHPV  HADHYST2  HADSIGM4  COLNSIGM  COLNTES1  SIGMTES1  LASTSIG4  \
3064       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
7094       7.0       1.0       1.0       1.0       1.0       NaN       NaN   
2690       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
5406       2.0       2.0       1.0       1.0       1.0       NaN       NaN   
4078       NaN       NaN       1.0       1.0       4.0       NaN       NaN   
...        ...       ...       ...       ...       ...       ...       ...   
3848       NaN       2.0       NaN       NaN       NaN       NaN       NaN   
9966       1.0       2.0       NaN       NaN       NaN       NaN       NaN   
7841       7.0       2.0       1.0       1.0       5.0       NaN       NaN   
7411       NaN       NaN       2.0       NaN       NaN       NaN       NaN   
7035       7.0       2.0       1.0       1.0       2.0       NaN       NaN   

      COLNCNCR  VIRCOLO1  VCLNTES2  SMALSTOL  STOLTEST  STOOLDN2  BLDSTFIT  \
3064       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
7094       2.0       NaN       NaN       NaN       NaN       NaN       NaN   
2690       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
5406       2.0       NaN       NaN       NaN       NaN       NaN       NaN   
4078       2.0       NaN       NaN       NaN       NaN       NaN       NaN   
...        ...       ...       ...       ...       ...       ...       ...   
3848       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
9966       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
7841       1.0       2.0       NaN       1.0       1.0       2.0       NaN   
7411       2.0       NaN       NaN       NaN       NaN       NaN       NaN   
7035       2.0       NaN       NaN       NaN       NaN       NaN       NaN   

      SDNATES1  SMOKE100  SMOKDAY2  USENOW3  ECIGNOW2  LCSFIRST  LCSLAST  \
3064       NaN       NaN       NaN      NaN       NaN       NaN      NaN   
7094       NaN       2.0       NaN      3.0       1.0       NaN      NaN   
2690       NaN       2.0       NaN      3.0       1.0       NaN      NaN   
5406       NaN       1.0       3.0      3.0       1.0      16.0     65.0   
4078       NaN       1.0       3.0      2.0       1.0      23.0     40.0   
...        ...       ...       ...      ...       ...       ...      ...   
3848       NaN       2.0       NaN      3.0       1.0       NaN      NaN   
9966       NaN       2.0       NaN      3.0       1.0       NaN      NaN   
7841       NaN       2.0       NaN      3.0       1.0       NaN      NaN   
7411       NaN       2.0       NaN      3.0       1.0       NaN      NaN   
7035       NaN       2.0       NaN      3.0       1.0       NaN      NaN   

      LCSNUMCG  LCSCTSC1  LCSSCNCR  LCSCTWHN  ALCDAY4  AVEDRNK3  DRNK3GE5  \
3064       NaN       NaN       NaN       NaN      NaN       NaN       NaN   
7094       NaN       2.0       NaN       NaN    888.0       NaN       NaN   
2690       NaN       2.0       NaN       NaN    201.0       2.0      88.0   
5406      30.0       1.0       1.0       1.0    888.0       NaN       NaN   
4078      20.0       2.0       NaN       NaN    101.0       2.0       1.0   
...        ...       ...       ...       ...      ...       ...       ...   
3848       NaN       2.0       NaN       NaN    205.0       4.0       1.0   
9966       NaN       2.0       NaN       NaN    888.0       NaN       NaN   
7841       NaN       2.0       NaN       NaN    204.0       1.0      88.0   
7411       NaN       2.0       NaN       NaN    888.0       NaN       NaN   
7035       NaN       1.0       2.0       NaN    103.0       2.0      88.0   

      MAXDRNKS  FLUSHOT7  FLSHTMY3  PNEUVAC4  TETANUS1  HIVTST7  HIVTSTD3  \
3064       NaN       NaN       NaN       NaN       NaN      NaN       NaN   
7094       NaN       2.0       NaN       1.0       1.0      2.0       NaN   
2690       2.0       2.0       NaN       1.0       1.0      1.0       NaN   
5406       NaN       1.0  112021.0       1.0       1.0      2.0       NaN   
4078       5.0       2.0       NaN       2.0       3.0      1.0  777777.0   
...        ...       ...       ...       ...       ...      ...       ...   
3848       6.0       2.0       NaN       1.0       3.0      1.0   22021.0   
9966       NaN       1.0  102021.0       2.0       4.0      1.0  777777.0   
7841       1.0       2.0       NaN       2.0       4.0      2.0       NaN   
7411       NaN       2.0       NaN       2.0       4.0      2.0       NaN   
7035       3.0       1.0   42022.0       2.0       3.0      2.0       NaN   

      HIVRISK5  COVIDPOS  COVIDSMP  COVIDPRM  PDIABTS1  PREDIAB2  DIABTYPE  \
3064       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
7094       2.0       2.0       NaN       NaN       NaN       NaN       NaN   
2690       NaN       NaN       NaN       NaN       1.0       3.0       NaN   
5406       2.0       2.0       NaN       NaN       NaN       NaN       NaN   
4078       2.0       1.0       2.0       NaN       1.0       3.0       NaN   
...        ...       ...       ...       ...       ...       ...       ...   
3848       2.0       2.0       NaN       NaN       NaN       NaN       NaN   
9966       2.0       1.0       2.0       NaN       8.0       3.0       NaN   
7841       2.0       1.0       2.0       NaN       7.0       3.0       NaN   
7411       2.0       2.0       NaN       NaN       3.0       3.0       NaN   
7035       2.0       2.0       NaN       NaN       7.0       3.0       NaN   

      INSULIN1  CHKHEMO3  EYEEXAM1  DIABEYE1  DIABEDU1  FEETSORE  TOLDCFS  \
3064       NaN       NaN       NaN       NaN       NaN       NaN      NaN   
7094       NaN       NaN       NaN       NaN       NaN       NaN      NaN   
2690       NaN       NaN       NaN       NaN       NaN       NaN      NaN   
5406       NaN       NaN       NaN       NaN       NaN       NaN      NaN   
4078       NaN       NaN       NaN       NaN       NaN       NaN      NaN   
...        ...       ...       ...       ...       ...       ...      ...   
3848       NaN       NaN       NaN       NaN       NaN       NaN      NaN   
9966       NaN       NaN       NaN       NaN       NaN       NaN      NaN   
7841       NaN       NaN       NaN       NaN       NaN       NaN      NaN   
7411       NaN       NaN       NaN       NaN       NaN       NaN      NaN   
7035       NaN       NaN       NaN       NaN       NaN       NaN      NaN   

      HAVECFS  WORKCFS  IMFVPLA3  HPVADVC4  HPVADSHT  SHINGLE2  COVIDVA1  \
3064      NaN      NaN       NaN       NaN       NaN       NaN       NaN   
7094      NaN      NaN       NaN       NaN       NaN       NaN       NaN   
2690      NaN      NaN       NaN       NaN       NaN       NaN       NaN   
5406      NaN      NaN       NaN       NaN       NaN       NaN       1.0   
4078      NaN      NaN       NaN       NaN       NaN       NaN       2.0   
...       ...      ...       ...       ...       ...       ...       ...   
3848      NaN      NaN       NaN       NaN       NaN       NaN       NaN   
9966      NaN      NaN       NaN       NaN       NaN       NaN       1.0   
7841      NaN      NaN       NaN       NaN       NaN       NaN       NaN   
7411      NaN      NaN       NaN       2.0       NaN       NaN       1.0   
7035      NaN      NaN       NaN       NaN       NaN       NaN       NaN   

      COVACGET  COVIDNU1  COVIDINT  COVIDFS1  COVIDSE1  COPDCOGH  COPDFLEM  \
3064       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
7094       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
2690       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
5406       NaN       3.0       NaN   12021.0   22021.0       NaN       NaN   
4078       4.0       NaN       NaN       NaN       NaN       NaN       NaN   
...        ...       ...       ...       ...       ...       ...       ...   
3848       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
9966       NaN       3.0       NaN  122020.0   62021.0       NaN       NaN   
7841       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
7411       NaN       4.0       NaN   32020.0   72020.0       NaN       NaN   
7035       NaN       NaN       NaN       NaN       NaN       NaN       NaN   

      COPDBRTH  COPDBTST  COPDSMOK  CNCRDIFF  CNCRAGE  CNCRTYP2  CSRVTRT3  \
3064       NaN       NaN       NaN       NaN      NaN       NaN       NaN   
7094       NaN       NaN       NaN       NaN      NaN       NaN       NaN   
2690       NaN       NaN       NaN       NaN      NaN       NaN       NaN   
5406       NaN       NaN       NaN       NaN      NaN       NaN       NaN   
4078       NaN       NaN       NaN       NaN      NaN       NaN       NaN   
...        ...       ...       ...       ...      ...       ...       ...   
3848       NaN       NaN       NaN       NaN      NaN       NaN       NaN   
9966       NaN       NaN       NaN       NaN      NaN       NaN       NaN   
7841       NaN       NaN       NaN       NaN      NaN       NaN       NaN   
7411       NaN       NaN       NaN       NaN      NaN       NaN       NaN   
7035       NaN       NaN       NaN       NaN      NaN       NaN       NaN   

      CSRVDOC1  CSRVSUM  CSRVRTRN  CSRVINST  CSRVINSR  CSRVDEIN  CSRVCLIN  \
3064       NaN      NaN       NaN       NaN       NaN       NaN       NaN   
7094       NaN      NaN       NaN       NaN       NaN       NaN       NaN   
2690       NaN      NaN       NaN       NaN       NaN       NaN       NaN   
5406       NaN      NaN       NaN       NaN       NaN       NaN       NaN   
4078       NaN      NaN       NaN       NaN       NaN       NaN       NaN   
...        ...      ...       ...       ...       ...       ...       ...   
3848       NaN      NaN       NaN       NaN       NaN       NaN       NaN   
9966       NaN      NaN       NaN       NaN       NaN       NaN       NaN   
7841       NaN      NaN       NaN       NaN       NaN       NaN       NaN   
7411       NaN      NaN       NaN       NaN       NaN       NaN       NaN   
7035       NaN      NaN       NaN       NaN       NaN       NaN       NaN   

      CSRVPAIN  CSRVCTL2  PSATEST1  PSATIME1  PCPSARS2  PSASUGST  PCSTALK1  \
3064       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
7094       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
2690       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
5406       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
4078       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
...        ...       ...       ...       ...       ...       ...       ...   
3848       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
9966       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
7841       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
7411       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
7035       NaN       NaN       NaN       NaN       NaN       NaN       NaN   

      CIMEMLOS  CDHOUSE  CDASSIST  CDHELP  CDSOCIAL  CDDISCUS  CAREGIV1  \
3064       NaN      NaN       NaN     NaN       NaN       NaN       NaN   
7094       2.0      NaN       NaN     NaN       NaN       NaN       1.0   
2690       NaN      NaN       NaN     NaN       NaN       NaN       NaN   
5406       NaN      NaN       NaN     NaN       NaN       NaN       2.0   
4078       NaN      NaN       NaN     NaN       NaN       NaN       NaN   
...        ...      ...       ...     ...       ...       ...       ...   
3848       NaN      NaN       NaN     NaN       NaN       NaN       NaN   
9966       NaN      NaN       NaN     NaN       NaN       NaN       NaN   
7841       NaN      NaN       NaN     NaN       NaN       NaN       NaN   
7411       NaN      NaN       NaN     NaN       NaN       NaN       NaN   
7035       NaN      NaN       NaN     NaN       NaN       NaN       NaN   

      CRGVREL4  CRGVLNG1  CRGVHRS1  CRGVPRB3  CRGVALZD  CRGVPER1  CRGVHOU1  \
3064       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
7094       6.0       4.0       4.0      13.0       1.0       1.0       1.0   
2690       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
5406       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
4078       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
...        ...       ...       ...       ...       ...       ...       ...   
3848       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
9966       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
7841       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
7411       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
7035       NaN       NaN       NaN       NaN       NaN       NaN       NaN   

      CRGVEXPT  ACEDEPRS  ACEDRINK  ACEDRUGS  ACEPRISN  ACEDIVRC  ACEPUNCH  \
3064       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
7094       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
2690       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
5406       2.0       NaN       NaN       NaN       NaN       NaN       NaN   
4078       NaN       2.0       2.0       2.0       2.0       2.0       1.0   
...        ...       ...       ...       ...       ...       ...       ...   
3848       NaN       2.0       1.0       2.0       2.0       2.0       1.0   
9966       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
7841       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
7411       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
7035       NaN       NaN       NaN       NaN       NaN       NaN       NaN   

      ACEHURT1  ACESWEAR  ACETOUCH  ACETTHEM  ACEHVSEX  ACEADSAF  ACEADNED  \
3064       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
7094       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
2690       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
5406       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
4078       1.0       1.0       1.0       1.0       1.0       5.0       5.0   
...        ...       ...       ...       ...       ...       ...       ...   
3848       1.0       1.0       1.0       1.0       1.0       5.0       5.0   
9966       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
7841       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
7411       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
7035       NaN       NaN       NaN       NaN       NaN       NaN       NaN   

      LSATISFY  EMTSUPRT  SDHISOLT  SDHEMPLY  FOODSTMP  SDHFOOD1  SDHBILLS  \
3064       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
7094       2.0       2.0       4.0       2.0       2.0       5.0       2.0   
2690       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
5406       3.0       5.0       3.0       2.0       1.0       5.0       2.0   
4078       1.0       1.0       5.0       2.0       2.0       5.0       2.0   
...        ...       ...       ...       ...       ...       ...       ...   
3848       1.0       2.0       4.0       2.0       2.0       5.0       2.0   
9966       2.0       1.0       4.0       2.0       2.0       5.0       2.0   
7841       2.0       3.0       3.0       2.0       2.0       5.0       2.0   
7411       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
7035       1.0       2.0       4.0       2.0       2.0       5.0       2.0   

      SDHUTILS  SDHTRNSP  SDHSTRE1  MARIJAN1  MARJSMOK  MARJEAT  MARJVAPE  \
3064       NaN       NaN       NaN       NaN       NaN      NaN       NaN   
7094       2.0       2.0       5.0       NaN       NaN      NaN       NaN   
2690       NaN       NaN       NaN       NaN       NaN      NaN       NaN   
5406       2.0       2.0       3.0       NaN       NaN      NaN       NaN   
4078       2.0       2.0       4.0       NaN       NaN      NaN       NaN   
...        ...       ...       ...       ...       ...      ...       ...   
3848       2.0       2.0       5.0       NaN       NaN      NaN       NaN   
9966       2.0       2.0       3.0       NaN       NaN      NaN       NaN   
7841       2.0       2.0       1.0       NaN       NaN      NaN       NaN   
7411       NaN       NaN       NaN      88.0       NaN      NaN       NaN   
7035       2.0       2.0       4.0       NaN       NaN      NaN       NaN   

      MARJDAB  MARJOTHR  USEMRJN4  LASTSMK2  STOPSMK2  MENTCIGS  MENTECIG  \
3064      NaN       NaN       NaN       NaN       NaN       NaN       NaN   
7094      NaN       NaN       NaN       NaN       NaN       NaN       NaN   
2690      NaN       NaN       NaN       NaN       NaN       NaN       NaN   
5406      NaN       NaN       NaN       NaN       NaN       NaN       NaN   
4078      NaN       NaN       NaN       NaN       NaN       NaN       NaN   
...       ...       ...       ...       ...       ...       ...       ...   
3848      NaN       NaN       NaN       NaN       NaN       NaN       NaN   
9966      NaN       NaN       NaN       NaN       NaN       NaN       NaN   
7841      NaN       NaN       NaN       NaN       NaN       NaN       NaN   
7411      NaN       NaN       NaN       NaN       NaN       NaN       NaN   
7035      NaN       NaN       NaN       NaN       NaN       NaN       NaN   

      HEATTBCO  ASBIALCH  ASBIDRNK  ASBIBING  ASBIADVC  ASBIRDUC  FIREARM5  \
3064       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
7094       NaN       1.0       1.0       7.0       2.0       2.0       NaN   
2690       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
5406       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
4078       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
...        ...       ...       ...       ...       ...       ...       ...   
3848       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
9966       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
7841       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
7411       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
7035       NaN       1.0       7.0       1.0       7.0       2.0       1.0   

      GUNLOAD  LOADULK2  RCSGEND1  RCSXBRTH  RCSRLTN2  CASTHDX2  CASTHNO2  \
3064      NaN       NaN       NaN       NaN       NaN       NaN       NaN   
7094      NaN       NaN       NaN       NaN       NaN       NaN       NaN   
2690      NaN       NaN       NaN       NaN       NaN       NaN       NaN   
5406      NaN       NaN       NaN       NaN       NaN       NaN       NaN   
4078      NaN       NaN       NaN       NaN       NaN       NaN       NaN   
...       ...       ...       ...       ...       ...       ...       ...   
3848      NaN       NaN       2.0       NaN       1.0       2.0       NaN   
9966      NaN       NaN       NaN       NaN       NaN       NaN       NaN   
7841      NaN       NaN       NaN       NaN       NaN       NaN       NaN   
7411      NaN       NaN       2.0       NaN       1.0       2.0       NaN   
7035      2.0       NaN       NaN       NaN       NaN       NaN       NaN   

      BIRTHSEX  SOMALE  SOFEMALE  TRNSGNDR  HADSEX  PFPPRVN4  TYPCNTR9  \
3064       NaN     NaN       NaN       NaN     NaN       NaN       NaN   
7094       2.0     NaN       2.0       4.0     NaN       NaN       NaN   
2690       NaN     NaN       NaN       NaN     NaN       NaN       NaN   
5406       NaN     NaN       NaN       NaN     NaN       NaN       NaN   
4078       1.0     2.0       NaN       4.0     NaN       NaN       NaN   
...        ...     ...       ...       ...     ...       ...       ...   
3848       NaN     NaN       NaN       NaN     NaN       NaN       NaN   
9966       NaN     NaN       NaN       NaN     1.0       1.0       6.0   
7841       NaN     NaN       2.0       4.0     NaN       NaN       NaN   
7411       1.0     2.0       NaN       4.0     NaN       NaN       NaN   
7035       NaN     NaN       2.0       4.0     NaN       NaN       NaN   

      BRTHCNT4  WHEREGET  NOBCUSE8  BCPREFER  RRCLASS3  RRCOGNT2  RRTREAT  \
3064       NaN       NaN       NaN       NaN       NaN       NaN      NaN   
7094       NaN       NaN       NaN       NaN       NaN       NaN      NaN   
2690       NaN       NaN       NaN       NaN       NaN       NaN      NaN   
5406       NaN       NaN       NaN       NaN       NaN       NaN      NaN   
4078       NaN       NaN       NaN       NaN       NaN       NaN      NaN   
...        ...       ...       ...       ...       ...       ...      ...   
3848       NaN       NaN       NaN       NaN       NaN       NaN      NaN   
9966       0.0       1.0       NaN       6.0       1.0       3.0      3.0   
7841       NaN       NaN       NaN       NaN       NaN       NaN      NaN   
7411       NaN       NaN       NaN       NaN       NaN       NaN      NaN   
7035       NaN       NaN       NaN       NaN       1.0       4.0      3.0   

      RRATWRK2  RRHCARE4  RRPHYSM2  QSTVER  QSTLANG  METSTAT  URBSTAT  MSCODE  \
3064       NaN       NaN       NaN    20.0      1.0      2.0      1.0     NaN   
7094       NaN       NaN       NaN    11.0      1.0      1.0      1.0     2.0   
2690       NaN       NaN       NaN    20.0      1.0      1.0      1.0     NaN   
5406       NaN       NaN       NaN    10.0      1.0      2.0      1.0     5.0   
4078       NaN       NaN       NaN    22.0      1.0      1.0      1.0     NaN   
...        ...       ...       ...     ...      ...      ...      ...     ...   
3848       NaN       NaN       NaN    20.0      1.0      1.0      1.0     NaN   
9966       3.0       3.0       2.0    20.0      1.0      1.0      1.0     NaN   
7841       NaN       NaN       NaN    20.0      1.0      2.0      2.0     NaN   
7411       NaN       NaN       NaN    20.0      1.0      1.0      1.0     NaN   
7035       2.0       2.0       2.0    20.0      1.0      2.0      1.0     NaN   

         STSTR       STRWT  RAWRAKE     WT2RAKE  IMPRACE  CHISPNC  CRACE2  \
3064  282081.0   28.492376      1.0   28.492376      1.0      9.0     NaN   
7094  491031.0   10.145546      2.0   20.291092      1.0      9.0     NaN   
2690  552021.0   27.905266      1.0   27.905266      1.0      9.0     NaN   
5406  331071.0    5.338731      1.0    5.338731      1.0      9.0     NaN   
4078  192011.0   62.956829      1.0   62.956829      1.0      NaN     NaN   
...        ...         ...      ...         ...      ...      ...     ...   
3848  122361.0  278.095062      1.0  278.095062      1.0      2.0     1.0   
9966  452041.0   40.883793      1.0   40.883793      1.0      NaN     NaN   
7841  292092.0   49.860222      1.0   49.860222      1.0      9.0     NaN   
7411  152011.0   33.954716      1.0   33.954716      3.0      2.0     4.0   
7035  272051.0   10.358928      1.0   10.358928      1.0      9.0     NaN   

      CPRACE2  CAGEG      CLLCPWT  DUALUSE   DUALCOR      LLCPWT2  \
3064      NaN    NaN          NaN      9.0       NaN   444.960327   
7094      NaN    NaN          NaN      1.0  0.329513   100.684883   
2690      NaN    NaN          NaN      9.0       NaN   796.997192   
5406      NaN    NaN          NaN      9.0       NaN    77.780647   
4078      NaN    NaN          NaN      9.0       NaN   459.487732   
...       ...    ...          ...      ...       ...          ...   
3848      1.0    1.0  7634.865723      9.0       NaN  3486.888428   
9966      NaN    NaN          NaN      9.0       NaN   598.121826   
7841      NaN    NaN          NaN      9.0       NaN   374.905426   
7411      4.0    3.0    64.473625      9.0       NaN   177.631119   
7035      NaN    NaN          NaN      9.0       NaN   294.094330   

           LLCPWT  RFHLTH  PHYS14D  MENT14D  HLTHPLN  HCVU652  TOTINDA  \
3064   432.689270     1.0      2.0      2.0      1.0      1.0      2.0   
7094    67.612061     2.0      1.0      3.0      1.0      9.0      1.0   
2690  2129.954102     1.0      1.0      1.0      1.0      1.0      1.0   
5406    51.311665     2.0      3.0      2.0      1.0      9.0      2.0   
4078   364.324219     1.0      1.0      1.0      1.0      1.0      1.0   
...           ...     ...      ...      ...      ...      ...      ...   
3848  3365.920410     1.0      1.0      2.0      1.0      1.0      1.0   
9966   443.944580     1.0      1.0      1.0      1.0      1.0      1.0   
7841   229.813339     1.0      1.0      1.0      1.0      9.0      2.0   
7411   138.597214     1.0      1.0      1.0      1.0      1.0      2.0   
7035   117.460205     1.0      1.0      1.0      1.0      1.0      1.0   

      EXTETH3  ALTETH3  DENVST3  MICHD  LTASTH1  CASTHM1  ASTHMS1  DRDXAR2  \
3064      2.0      NaN      1.0    2.0      1.0      1.0      3.0      2.0   
7094      1.0      1.0      1.0    2.0      2.0      1.0      2.0      1.0   
2690      1.0      NaN      1.0    2.0      1.0      1.0      3.0      2.0   
5406      2.0      2.0      2.0    1.0      2.0      2.0      1.0      1.0   
4078      2.0      NaN      1.0    2.0      1.0      1.0      3.0      2.0   
...       ...      ...      ...    ...      ...      ...      ...      ...   
3848      1.0      NaN      1.0    2.0      1.0      1.0      3.0      2.0   
9966      1.0      NaN      1.0    2.0      1.0      1.0      3.0      2.0   
7841      2.0      1.0      1.0    2.0      1.0      1.0      3.0      NaN   
7411      1.0      NaN      2.0    2.0      1.0      1.0      3.0      2.0   
7035      2.0      NaN      1.0    2.0      1.0      1.0      3.0      1.0   

      PRACE2  MRACE2  HISPANC  RACE1  RACEG22  RACEGR4  RACEPR1  SEX  AGEG5YR  \
3064     1.0     1.0      2.0    1.0      1.0      1.0      1.0  2.0      6.0   
7094     1.0     1.0      2.0    1.0      1.0      1.0      1.0  2.0     12.0   
2690     1.0     1.0      2.0    1.0      1.0      1.0      1.0  1.0      3.0   
5406     1.0     1.0      2.0    1.0      1.0      1.0      1.0  2.0     11.0   
4078     1.0     1.0      2.0    1.0      1.0      1.0      1.0  1.0      8.0   
...      ...     ...      ...    ...      ...      ...      ...  ...      ...   
3848     1.0     1.0      2.0    1.0      1.0      1.0      1.0  2.0      4.0   
9966     1.0     1.0      2.0    1.0      1.0      1.0      1.0  2.0      3.0   
7841     1.0     1.0      2.0    1.0      1.0      1.0      1.0  2.0     10.0   
7411     4.0     4.0      2.0    4.0      2.0      3.0      4.0  1.0      6.0   
7035     1.0     1.0      2.0    1.0      1.0      1.0      1.0  2.0      9.0   

      AGE65YR  AGE80  AGE_G  HTIN4   HTM4    WTKG3    BMI5  BMI5CAT  RFBMI5  \
3064      1.0   48.0    4.0    NaN    NaN      NaN     NaN      NaN     9.0   
7094      2.0   79.0    6.0   63.0  160.0   6350.0  2480.0      2.0     1.0   
2690      1.0   34.0    2.0   72.0  183.0   7983.0  2387.0      2.0     1.0   
5406      2.0   72.0    6.0   54.0  137.0  10886.0  5787.0      4.0     2.0   
4078      1.0   58.0    5.0   72.0  183.0   9072.0  2712.0      3.0     2.0   
...       ...    ...    ...    ...    ...      ...     ...      ...     ...   
3848      1.0   36.0    3.0   64.0  163.0   5443.0  2060.0      2.0     1.0   
9966      1.0   31.0    2.0   62.0  157.0   5216.0  2103.0      2.0     1.0   
7841      2.0   65.0    6.0   67.0  170.0   7711.0  2663.0      3.0     2.0   
7411      1.0   49.0    4.0   67.0  170.0   8165.0  2819.0      3.0     2.0   
7035      1.0   62.0    5.0   66.0  168.0   7711.0  2744.0      3.0     2.0   

      CHLDCNT  EDUCAG  INCOMG1  RFMAM22  MAM5023  HADCOLN  CLNSCP1  HADSIGM  \
3064      2.0     3.0      9.0      9.0      NaN      NaN      NaN      NaN   
7094      1.0     3.0      9.0      1.0      NaN      1.0      NaN      2.0   
2690      1.0     3.0      4.0      NaN      NaN      NaN      NaN      NaN   
5406      1.0     4.0      9.0      1.0      1.0      1.0      1.0      2.0   
4078      1.0     2.0      6.0      NaN      NaN      1.0      1.0      2.0   
...       ...     ...      ...      ...      ...      ...      ...      ...   
3848      4.0     4.0      7.0      NaN      NaN      NaN      NaN      NaN   
9966      1.0     4.0      7.0      NaN      NaN      NaN      NaN      NaN   
7841      1.0     2.0      2.0      1.0      1.0      1.0      2.0      2.0   
7411      2.0     3.0      6.0      NaN      NaN      2.0      3.0      2.0   
7035      1.0     4.0      6.0      1.0      1.0      1.0      1.0      2.0   

      SGMSCP1  SGMS101  RFBLDS5  STOLDN1  VIRCOL1  SBONTI1  CRCREC2  SMOKER3  \
3064      NaN      NaN      NaN      NaN      NaN      NaN      NaN      9.0   
7094      NaN      NaN      NaN      NaN      NaN      NaN      NaN      4.0   
2690      NaN      NaN      NaN      NaN      NaN      NaN      NaN      4.0   
5406      3.0      3.0      3.0      3.0      3.0      3.0      1.0      3.0   
4078      3.0      3.0      3.0      3.0      3.0      3.0      1.0      3.0   
...       ...      ...      ...      ...      ...      ...      ...      ...   
3848      NaN      NaN      NaN      NaN      NaN      NaN      NaN      4.0   
9966      NaN      NaN      NaN      NaN      NaN      NaN      NaN      4.0   
7841      3.0      3.0      1.0      3.0      3.0      2.0      1.0      4.0   
7411      3.0      3.0      3.0      3.0      3.0      3.0      3.0      4.0   
7035      3.0      3.0      3.0      3.0      3.0      3.0      1.0      4.0   

      RFSMOK3  CURECI2  YRSSMOK  PACKDAY  PACKYRS  YRSQUIT  SMOKGRP  LCSREC  \
3064      9.0      9.0      NaN      NaN      NaN      NaN      NaN     NaN   
7094      1.0      1.0      NaN      NaN      NaN      NaN      4.0     NaN   
2690      1.0      1.0      NaN      NaN      NaN      NaN      4.0     NaN   
5406      1.0      1.0     49.0      1.5     74.0      7.0      2.0     1.0   
4078      1.0      1.0     17.0      1.0     17.0     18.0      3.0     NaN   
...       ...      ...      ...      ...      ...      ...      ...     ...   
3848      1.0      1.0      NaN      NaN      NaN      NaN      4.0     NaN   
9966      1.0      1.0      NaN      NaN      NaN      NaN      4.0     NaN   
7841      1.0      1.0      NaN      NaN      NaN      NaN      4.0     NaN   
7411      1.0      1.0      NaN      NaN      NaN      NaN      4.0     NaN   
7035      1.0      1.0      NaN      NaN      NaN      NaN      4.0     NaN   

      DRNKANY6  DROCDY4_  RFBING6  DRNKWK2  RFDRHV8  FLSHOT7  PNEUMO3  AIDTST4  
3064       9.0     900.0      9.0  99900.0      9.0      NaN      NaN      NaN  
7094       2.0       0.0      1.0      0.0      1.0      2.0      1.0      2.0  
2690       1.0       3.0      1.0     47.0      1.0      NaN      NaN      1.0  
5406       2.0       0.0      1.0      0.0      1.0      1.0      1.0      2.0  
4078       1.0      14.0      2.0    200.0      1.0      NaN      NaN      1.0  
...        ...       ...      ...      ...      ...      ...      ...      ...  
3848       1.0      17.0      2.0    467.0      1.0      NaN      NaN      1.0  
9966       2.0       0.0      1.0      0.0      1.0      NaN      NaN      1.0  
7841       1.0      13.0      1.0     93.0      1.0      2.0      2.0      2.0  
7411       2.0       0.0      1.0      0.0      1.0      NaN      NaN      2.0  
7035       1.0      43.0      1.0    600.0      1.0      NaN      NaN      2.0  

[3979 rows x 326 columns]
2025-11-28 15:52:00,749:INFO:get_config() successfully completed......................................
2025-11-28 15:52:59,135:INFO:Initializing compare_models()
2025-11-28 15:52:59,135:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020508BC6920>, include=['xgboost', 'lightgbm', 'rf', 'gbc'], fold=None, round=4, cross_validation=True, sort=Recall, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000020508BC6920>, 'include': ['xgboost', 'lightgbm', 'rf', 'gbc'], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Recall', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2025-11-28 15:52:59,135:INFO:Checking exceptions
2025-11-28 15:52:59,215:INFO:Preparing display monitor
2025-11-28 15:52:59,241:INFO:Initializing Extreme Gradient Boosting
2025-11-28 15:52:59,242:INFO:Total runtime is 1.6681353251139323e-05 minutes
2025-11-28 15:52:59,245:INFO:SubProcess create_model() called ==================================
2025-11-28 15:52:59,245:INFO:Initializing create_model()
2025-11-28 15:52:59,246:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020508BC6920>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002051006BC40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-28 15:52:59,246:INFO:Checking exceptions
2025-11-28 15:52:59,246:INFO:Importing libraries
2025-11-28 15:52:59,246:INFO:Copying training dataset
2025-11-28 15:52:59,367:INFO:Defining folds
2025-11-28 15:52:59,367:INFO:Declaring metric variables
2025-11-28 15:52:59,370:INFO:Importing untrained model
2025-11-28 15:52:59,373:INFO:Extreme Gradient Boosting Imported successfully
2025-11-28 15:52:59,376:INFO:Starting cross validation
2025-11-28 15:52:59,379:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-28 15:53:04,359:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-28 15:53:04,359:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-28 15:53:04,359:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-28 15:53:04,359:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-28 15:53:04,359:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-28 15:53:04,359:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-28 15:53:04,359:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-28 15:53:04,359:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-28 15:53:04,359:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-28 15:53:04,947:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 15:53:04,958:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 15:53:04,960:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 15:53:04,972:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 15:53:04,976:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 15:53:04,995:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 15:53:05,002:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 15:53:05,002:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 15:53:05,005:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 15:53:05,012:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 15:53:09,417:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 15:53:09,444:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 15:53:09,447:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 15:53:09,457:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 15:53:09,474:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 15:53:09,475:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 15:53:09,477:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 15:53:09,501:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 15:53:09,510:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 15:53:09,526:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 15:53:09,705:INFO:Calculating mean and std
2025-11-28 15:53:09,705:INFO:Creating metrics dataframe
2025-11-28 15:53:09,709:INFO:Uploading results into container
2025-11-28 15:53:09,709:INFO:Uploading model into container now
2025-11-28 15:53:09,709:INFO:_master_model_container: 1
2025-11-28 15:53:09,709:INFO:_display_container: 2
2025-11-28 15:53:09,711:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              feature_weights=None, gamma=None, grow_policy=None,
              importance_type=None, interaction_constraints=None,
              learning_rate=None, max_bin=None, max_cat_threshold=None,
              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,
              max_leaves=None, min_child_weight=None, missing=nan,
              monotone_constraints=None, multi_strategy=None, n_estimators=None,
              n_jobs=-1, num_parallel_tree=None, ...)
2025-11-28 15:53:09,711:INFO:create_model() successfully completed......................................
2025-11-28 15:53:09,880:INFO:SubProcess create_model() end ==================================
2025-11-28 15:53:09,880:INFO:Creating metrics dataframe
2025-11-28 15:53:09,885:INFO:Initializing Light Gradient Boosting Machine
2025-11-28 15:53:09,885:INFO:Total runtime is 0.1773943305015564 minutes
2025-11-28 15:53:09,885:INFO:SubProcess create_model() called ==================================
2025-11-28 15:53:09,889:INFO:Initializing create_model()
2025-11-28 15:53:09,889:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020508BC6920>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002051006BC40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-28 15:53:09,889:INFO:Checking exceptions
2025-11-28 15:53:09,889:INFO:Importing libraries
2025-11-28 15:53:09,889:INFO:Copying training dataset
2025-11-28 15:53:10,003:INFO:Defining folds
2025-11-28 15:53:10,003:INFO:Declaring metric variables
2025-11-28 15:53:10,005:INFO:Importing untrained model
2025-11-28 15:53:10,010:INFO:Light Gradient Boosting Machine Imported successfully
2025-11-28 15:53:10,010:INFO:Starting cross validation
2025-11-28 15:53:10,017:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-28 15:53:10,287:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 15:53:10,382:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 15:53:10,444:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 15:53:10,547:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 15:53:10,602:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 15:53:10,719:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 15:53:10,809:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 15:53:10,905:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 15:53:16,887:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-28 15:53:17,119:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 15:53:17,185:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-28 15:53:17,457:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 15:53:22,995:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 15:53:23,012:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 15:53:23,098:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 15:53:23,971:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 15:53:23,979:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 15:53:24,004:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 15:53:24,018:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 15:53:24,165:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 15:53:24,825:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 15:53:24,837:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 15:53:24,989:INFO:Calculating mean and std
2025-11-28 15:53:24,991:INFO:Creating metrics dataframe
2025-11-28 15:53:24,994:INFO:Uploading results into container
2025-11-28 15:53:24,994:INFO:Uploading model into container now
2025-11-28 15:53:24,995:INFO:_master_model_container: 2
2025-11-28 15:53:24,995:INFO:_display_container: 2
2025-11-28 15:53:24,995:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-11-28 15:53:24,996:INFO:create_model() successfully completed......................................
2025-11-28 15:53:25,209:INFO:SubProcess create_model() end ==================================
2025-11-28 15:53:25,209:INFO:Creating metrics dataframe
2025-11-28 15:53:25,216:INFO:Initializing Random Forest Classifier
2025-11-28 15:53:25,216:INFO:Total runtime is 0.43291822671890257 minutes
2025-11-28 15:53:25,220:INFO:SubProcess create_model() called ==================================
2025-11-28 15:53:25,220:INFO:Initializing create_model()
2025-11-28 15:53:25,220:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020508BC6920>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002051006BC40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-28 15:53:25,220:INFO:Checking exceptions
2025-11-28 15:53:25,220:INFO:Importing libraries
2025-11-28 15:53:25,220:INFO:Copying training dataset
2025-11-28 15:53:25,341:INFO:Defining folds
2025-11-28 15:53:25,341:INFO:Declaring metric variables
2025-11-28 15:53:25,349:INFO:Importing untrained model
2025-11-28 15:53:25,353:INFO:Random Forest Classifier Imported successfully
2025-11-28 15:53:25,357:INFO:Starting cross validation
2025-11-28 15:53:25,359:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-28 15:53:25,581:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 15:53:25,642:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 15:53:25,714:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 15:53:25,759:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 15:53:25,847:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 15:53:25,976:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 15:53:26,095:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 15:53:26,176:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 15:53:26,311:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 15:53:26,441:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 15:53:29,629:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 15:53:29,631:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 15:53:29,712:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 15:53:30,266:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 15:53:32,680:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 15:53:32,798:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 15:53:32,799:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 15:53:32,912:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 15:53:33,349:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 15:53:33,403:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 15:53:33,547:INFO:Calculating mean and std
2025-11-28 15:53:33,548:INFO:Creating metrics dataframe
2025-11-28 15:53:33,548:INFO:Uploading results into container
2025-11-28 15:53:33,548:INFO:Uploading model into container now
2025-11-28 15:53:33,548:INFO:_master_model_container: 3
2025-11-28 15:53:33,548:INFO:_display_container: 2
2025-11-28 15:53:33,548:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2025-11-28 15:53:33,551:INFO:create_model() successfully completed......................................
2025-11-28 15:53:33,679:INFO:SubProcess create_model() end ==================================
2025-11-28 15:53:33,679:INFO:Creating metrics dataframe
2025-11-28 15:53:33,685:INFO:Initializing Gradient Boosting Classifier
2025-11-28 15:53:33,685:INFO:Total runtime is 0.5740575075149537 minutes
2025-11-28 15:53:33,685:INFO:SubProcess create_model() called ==================================
2025-11-28 15:53:33,685:INFO:Initializing create_model()
2025-11-28 15:53:33,685:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020508BC6920>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002051006BC40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-28 15:53:33,685:INFO:Checking exceptions
2025-11-28 15:53:33,685:INFO:Importing libraries
2025-11-28 15:53:33,685:INFO:Copying training dataset
2025-11-28 15:53:33,794:INFO:Defining folds
2025-11-28 15:53:33,794:INFO:Declaring metric variables
2025-11-28 15:53:33,800:INFO:Importing untrained model
2025-11-28 15:53:33,803:INFO:Gradient Boosting Classifier Imported successfully
2025-11-28 15:53:33,804:INFO:Starting cross validation
2025-11-28 15:53:33,809:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-28 15:53:34,017:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 15:53:34,071:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 15:53:34,120:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 15:53:34,218:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 15:53:34,340:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 15:53:34,403:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 15:53:34,517:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 15:53:34,669:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 15:53:34,764:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 15:53:34,898:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 15:54:10,392:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 15:54:10,492:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 15:54:10,530:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 15:54:10,595:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 15:54:10,670:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 15:54:10,713:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 15:54:10,916:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 15:54:10,923:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 15:54:10,961:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 15:54:11,337:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 15:54:11,418:INFO:Calculating mean and std
2025-11-28 15:54:11,419:INFO:Creating metrics dataframe
2025-11-28 15:54:11,420:INFO:Uploading results into container
2025-11-28 15:54:11,421:INFO:Uploading model into container now
2025-11-28 15:54:11,421:INFO:_master_model_container: 4
2025-11-28 15:54:11,421:INFO:_display_container: 2
2025-11-28 15:54:11,421:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-11-28 15:54:11,423:INFO:create_model() successfully completed......................................
2025-11-28 15:54:11,555:INFO:SubProcess create_model() end ==================================
2025-11-28 15:54:11,555:INFO:Creating metrics dataframe
2025-11-28 15:54:11,563:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  master_display_.apply(

2025-11-28 15:54:11,566:INFO:Initializing create_model()
2025-11-28 15:54:11,566:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020508BC6920>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-28 15:54:11,566:INFO:Checking exceptions
2025-11-28 15:54:11,570:INFO:Importing libraries
2025-11-28 15:54:11,570:INFO:Copying training dataset
2025-11-28 15:54:11,674:INFO:Defining folds
2025-11-28 15:54:11,674:INFO:Declaring metric variables
2025-11-28 15:54:11,674:INFO:Importing untrained model
2025-11-28 15:54:11,674:INFO:Declaring custom model
2025-11-28 15:54:11,674:INFO:Gradient Boosting Classifier Imported successfully
2025-11-28 15:54:11,675:INFO:Cross validation set to False
2025-11-28 15:54:11,675:INFO:Fitting Model
2025-11-28 15:54:11,751:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 15:54:43,151:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-11-28 15:54:43,151:INFO:create_model() successfully completed......................................
2025-11-28 15:54:43,309:INFO:_master_model_container: 4
2025-11-28 15:54:43,309:INFO:_display_container: 2
2025-11-28 15:54:43,309:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-11-28 15:54:43,309:INFO:compare_models() successfully completed......................................
2025-11-28 16:20:33,299:INFO:Initializing tune_model()
2025-11-28 16:20:33,299:INFO:tune_model(estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=None, round=4, n_iter=20, custom_grid=None, optimize=Recall, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020508BC6920>)
2025-11-28 16:20:33,299:INFO:Checking exceptions
2025-11-28 16:20:33,361:INFO:Copying training dataset
2025-11-28 16:20:33,444:INFO:Checking base model
2025-11-28 16:20:33,444:INFO:Base model : Gradient Boosting Classifier
2025-11-28 16:20:33,448:INFO:Declaring metric variables
2025-11-28 16:20:33,450:INFO:Defining Hyperparameters
2025-11-28 16:20:33,583:INFO:Tuning with n_jobs=-1
2025-11-28 16:20:33,583:INFO:Initializing RandomizedSearchCV
2025-11-28 16:20:37,285:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-28 16:20:37,325:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-28 16:20:37,364:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-28 16:20:37,399:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-28 16:20:37,488:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-28 16:20:37,607:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-28 16:20:37,638:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-28 16:20:37,689:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:20:37,711:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-28 16:20:37,723:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-28 16:20:37,738:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:20:37,775:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:20:37,841:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:20:37,853:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-28 16:20:37,972:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-28 16:20:38,018:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:20:38,343:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:20:38,423:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-28 16:20:38,581:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:20:38,694:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:20:38,748:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:20:38,760:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:20:39,011:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:20:39,515:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:20:41,359:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:20:41,653:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:20:41,709:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:20:42,082:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:20:43,534:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:20:43,805:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:20:44,463:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:20:44,749:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:20:45,594:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:20:45,885:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:20:46,578:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:20:46,872:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:20:47,755:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:20:48,037:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:20:48,721:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:20:49,003:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:20:49,946:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:20:50,240:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:20:50,899:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:20:51,193:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:20:51,788:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:20:52,068:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:20:52,554:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:20:52,844:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:20:53,446:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:20:53,763:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:20:54,176:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:20:54,460:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:20:55,128:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:20:55,478:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:20:55,776:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:20:56,164:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:20:56,859:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:20:57,121:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:20:57,441:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:20:57,755:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:20:58,474:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:20:58,756:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:20:59,050:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:20:59,341:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:21:01,808:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:21:02,072:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:21:02,086:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:21:02,381:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:21:05,059:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:21:05,332:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:21:05,349:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:21:05,635:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:21:08,308:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:21:08,453:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:21:08,564:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:21:08,741:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:21:11,672:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:21:11,682:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:21:11,955:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:21:12,036:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:21:15,036:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:21:15,379:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:21:15,404:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:21:15,796:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:21:17,341:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:21:17,584:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:21:17,737:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:21:18,053:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:21:19,517:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:21:19,779:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:21:19,932:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:21:20,220:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:21:21,771:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:21:22,050:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:21:22,140:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:21:22,421:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:21:24,152:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:21:24,402:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:21:24,416:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:21:24,663:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:21:26,453:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:21:26,604:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:21:26,743:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:21:26,874:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:21:30,463:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:21:30,575:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:21:30,771:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:21:30,997:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:21:34,672:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:21:34,977:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:21:34,999:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:21:35,394:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:21:38,695:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:21:38,944:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:21:39,143:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:21:39,446:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:21:42,626:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:21:42,879:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:21:43,200:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:21:43,488:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:21:46,552:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:21:46,818:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:21:47,068:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:21:47,388:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:21:52,863:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:21:53,141:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:21:53,391:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:21:53,682:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:21:58,448:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:21:58,827:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:21:59,031:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:21:59,353:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:21:59,414:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:21:59,583:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:21:59,711:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:00,061:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:00,310:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:00,573:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:00,740:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:00,755:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:00,867:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:01,055:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:01,063:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:01,204:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:01,362:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:01,464:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:01,729:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:01,899:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:01,987:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:02,693:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:04,527:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:04,907:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:04,911:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:04,994:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:05,125:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:05,208:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:05,325:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:05,398:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:05,436:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:05,713:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:05,794:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:05,949:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:05,990:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:06,268:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:06,476:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:06,823:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:06,999:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:07,059:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:07,460:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:07,539:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:08,000:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:08,391:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:08,764:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:08,815:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:09,151:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:09,227:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:09,294:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:09,346:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:09,713:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:09,815:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:09,909:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:10,014:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:10,392:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:10,499:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:12,782:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:12,892:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:13,094:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:13,260:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:15,473:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:15,507:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:15,676:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:15,763:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:15,796:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:15,909:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:16,102:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:16,190:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:16,227:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:16,893:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:16,921:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:16,993:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:17,372:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:17,555:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:17,703:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:18,119:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:18,515:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:18,628:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:18,694:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:18,722:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:18,836:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:18,896:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:18,991:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:19,087:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:19,233:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:19,277:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:19,357:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:19,425:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:19,534:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:19,659:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:19,796:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:20,087:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:20,325:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:20,387:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:20,489:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:20,545:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:20,996:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:21,093:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:21,418:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:21,839:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:22,155:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:22,406:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:22,440:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:22,494:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:22,816:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:22,881:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:23,019:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:23,057:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:23,063:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:23,188:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:23,580:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:23,634:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:23,719:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:23,813:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:23,981:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:24,187:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:24,191:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:24,224:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:24,271:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:24,774:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:24,952:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:25,065:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:25,178:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:25,709:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:25,981:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:26,319:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:26,392:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:26,627:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:26,740:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:26,769:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:26,905:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:27,021:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:27,203:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:27,293:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:27,322:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:27,669:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:32,432:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:32,650:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:32,734:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:32,991:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:37,813:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:38,063:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:38,105:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:38,380:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:43,099:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:43,383:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:43,387:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:43,702:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:48,208:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:48,478:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:48,692:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:49,041:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:53,790:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:54,074:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:54,192:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:54,501:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:55,817:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:56,103:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:56,117:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:56,417:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:57,708:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:57,971:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:57,974:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:58,263:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:59,626:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:59,818:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:59,906:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:23:00,128:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:23:01,652:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:23:01,772:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:23:02,035:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:23:02,145:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:26:47,792:INFO:Initializing compare_models()
2025-11-28 16:26:47,792:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020508BC6920>, include=['xgboost', 'lightgbm'], fold=None, round=4, cross_validation=True, sort=Recall, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000020508BC6920>, 'include': ['xgboost', 'lightgbm'], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Recall', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2025-11-28 16:26:47,792:INFO:Checking exceptions
2025-11-28 16:26:47,830:INFO:Preparing display monitor
2025-11-28 16:26:47,849:INFO:Initializing Extreme Gradient Boosting
2025-11-28 16:26:47,849:INFO:Total runtime is 0.0 minutes
2025-11-28 16:26:47,851:INFO:SubProcess create_model() called ==================================
2025-11-28 16:26:47,851:INFO:Initializing create_model()
2025-11-28 16:26:47,851:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020508BC6920>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020502D29360>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-28 16:26:47,851:INFO:Checking exceptions
2025-11-28 16:26:47,851:INFO:Importing libraries
2025-11-28 16:26:47,851:INFO:Copying training dataset
2025-11-28 16:26:47,968:INFO:Defining folds
2025-11-28 16:26:47,968:INFO:Declaring metric variables
2025-11-28 16:26:47,971:INFO:Importing untrained model
2025-11-28 16:26:47,974:INFO:Extreme Gradient Boosting Imported successfully
2025-11-28 16:26:47,979:INFO:Starting cross validation
2025-11-28 16:26:47,979:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-28 16:26:51,327:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-28 16:26:51,327:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-28 16:26:51,327:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-28 16:26:51,353:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-28 16:26:51,392:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-28 16:26:51,440:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-28 16:26:51,440:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-28 16:26:51,496:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-28 16:26:51,537:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-28 16:26:51,612:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-28 16:26:51,693:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:26:51,704:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:26:51,707:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:26:51,735:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:26:51,821:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:26:51,950:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:26:51,960:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:26:52,223:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:26:52,392:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:26:52,630:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:26:55,956:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:26:56,022:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:26:56,032:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:26:56,071:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:26:56,224:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:26:56,227:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:26:56,247:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:26:56,327:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:26:56,356:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:26:56,403:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:26:56,516:INFO:Calculating mean and std
2025-11-28 16:26:56,517:INFO:Creating metrics dataframe
2025-11-28 16:26:56,518:INFO:Uploading results into container
2025-11-28 16:26:56,519:INFO:Uploading model into container now
2025-11-28 16:26:56,519:INFO:_master_model_container: 5
2025-11-28 16:26:56,519:INFO:_display_container: 3
2025-11-28 16:26:56,519:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              feature_weights=None, gamma=None, grow_policy=None,
              importance_type=None, interaction_constraints=None,
              learning_rate=None, max_bin=None, max_cat_threshold=None,
              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,
              max_leaves=None, min_child_weight=None, missing=nan,
              monotone_constraints=None, multi_strategy=None, n_estimators=None,
              n_jobs=-1, num_parallel_tree=None, ...)
2025-11-28 16:26:56,519:INFO:create_model() successfully completed......................................
2025-11-28 16:26:56,855:INFO:SubProcess create_model() end ==================================
2025-11-28 16:26:56,855:INFO:Creating metrics dataframe
2025-11-28 16:26:56,860:INFO:Initializing Light Gradient Boosting Machine
2025-11-28 16:26:56,860:INFO:Total runtime is 0.15018306573232015 minutes
2025-11-28 16:26:56,860:INFO:SubProcess create_model() called ==================================
2025-11-28 16:26:56,860:INFO:Initializing create_model()
2025-11-28 16:26:56,860:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020508BC6920>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020502D29360>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-28 16:26:56,860:INFO:Checking exceptions
2025-11-28 16:26:56,860:INFO:Importing libraries
2025-11-28 16:26:56,860:INFO:Copying training dataset
2025-11-28 16:26:56,968:INFO:Defining folds
2025-11-28 16:26:56,969:INFO:Declaring metric variables
2025-11-28 16:26:56,971:INFO:Importing untrained model
2025-11-28 16:26:56,973:INFO:Light Gradient Boosting Machine Imported successfully
2025-11-28 16:26:56,973:INFO:Starting cross validation
2025-11-28 16:26:56,983:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-28 16:26:57,275:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:26:57,369:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:26:57,429:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:26:57,506:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:26:57,604:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:26:57,727:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:26:57,841:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:26:57,958:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:27:04,137:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-28 16:27:04,174:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-28 16:27:04,398:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:27:04,438:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:27:09,872:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:27:09,891:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:27:09,908:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:27:10,073:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:27:10,754:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:27:10,759:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:27:10,775:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:27:10,831:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:27:11,542:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:27:11,550:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:27:11,665:INFO:Calculating mean and std
2025-11-28 16:27:11,665:INFO:Creating metrics dataframe
2025-11-28 16:27:11,669:INFO:Uploading results into container
2025-11-28 16:27:11,669:INFO:Uploading model into container now
2025-11-28 16:27:11,669:INFO:_master_model_container: 6
2025-11-28 16:27:11,669:INFO:_display_container: 3
2025-11-28 16:27:11,670:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-11-28 16:27:11,670:INFO:create_model() successfully completed......................................
2025-11-28 16:27:11,903:INFO:SubProcess create_model() end ==================================
2025-11-28 16:27:11,903:INFO:Creating metrics dataframe
2025-11-28 16:27:11,909:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  master_display_.apply(

2025-11-28 16:27:11,917:INFO:Initializing create_model()
2025-11-28 16:27:11,917:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020508BC6920>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-28 16:27:11,917:INFO:Checking exceptions
2025-11-28 16:27:11,917:INFO:Importing libraries
2025-11-28 16:27:11,917:INFO:Copying training dataset
2025-11-28 16:27:12,032:INFO:Defining folds
2025-11-28 16:27:12,032:INFO:Declaring metric variables
2025-11-28 16:27:12,032:INFO:Importing untrained model
2025-11-28 16:27:12,032:INFO:Declaring custom model
2025-11-28 16:27:12,033:INFO:Light Gradient Boosting Machine Imported successfully
2025-11-28 16:27:12,035:INFO:Cross validation set to False
2025-11-28 16:27:12,035:INFO:Fitting Model
2025-11-28 16:27:12,109:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:27:12,737:INFO:[LightGBM] [Info] Number of positive: 8764, number of negative: 8764
2025-11-28 16:27:12,765:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021939 seconds.
2025-11-28 16:27:12,766:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-11-28 16:27:12,766:INFO:[LightGBM] [Info] Total Bins 76025
2025-11-28 16:27:12,770:INFO:[LightGBM] [Info] Number of data points in the train set: 17528, number of used features: 323
2025-11-28 16:27:12,770:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-11-28 16:27:13,494:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-11-28 16:27:13,494:INFO:create_model() successfully completed......................................
2025-11-28 16:27:13,673:INFO:_master_model_container: 6
2025-11-28 16:27:13,673:INFO:_display_container: 3
2025-11-28 16:27:13,673:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-11-28 16:27:13,673:INFO:compare_models() successfully completed......................................
2025-11-28 16:30:43,431:INFO:Initializing tune_model()
2025-11-28 16:30:43,431:INFO:tune_model(estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=4, custom_grid=None, optimize=Recall, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020508BC6920>)
2025-11-28 16:30:43,431:INFO:Checking exceptions
2025-11-28 16:30:43,480:INFO:Copying training dataset
2025-11-28 16:30:43,551:INFO:Checking base model
2025-11-28 16:30:43,551:INFO:Base model : Light Gradient Boosting Machine
2025-11-28 16:30:43,553:INFO:Declaring metric variables
2025-11-28 16:30:43,555:INFO:Defining Hyperparameters
2025-11-28 16:30:43,709:INFO:Tuning with n_jobs=-1
2025-11-28 16:30:43,709:INFO:Initializing RandomizedSearchCV
2025-11-28 16:30:43,929:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:30:43,998:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:30:44,058:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:30:44,165:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:30:44,248:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:30:44,378:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:30:44,468:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:30:44,559:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:30:44,698:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:30:44,977:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:30:45,090:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:30:45,376:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:30:49,948:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:30:50,437:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:30:50,440:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:30:50,945:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:30:53,274:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:30:53,355:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:30:53,675:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:30:53,710:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:30:53,714:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:30:53,741:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:30:54,111:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:30:54,133:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:30:54,555:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:30:59,700:INFO:Initializing tune_model()
2025-11-28 16:30:59,700:INFO:tune_model(estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=1, custom_grid=None, optimize=Recall, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020508BC6920>)
2025-11-28 16:30:59,700:INFO:Checking exceptions
2025-11-28 16:30:59,750:INFO:Copying training dataset
2025-11-28 16:30:59,822:INFO:Checking base model
2025-11-28 16:30:59,823:INFO:Base model : Light Gradient Boosting Machine
2025-11-28 16:30:59,827:INFO:Declaring metric variables
2025-11-28 16:30:59,830:INFO:Defining Hyperparameters
2025-11-28 16:30:59,991:INFO:Tuning with n_jobs=-1
2025-11-28 16:30:59,991:INFO:Initializing RandomizedSearchCV
2025-11-28 16:31:03,398:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-28 16:31:03,426:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-28 16:31:03,439:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-28 16:31:03,479:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-28 16:31:03,485:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-28 16:31:03,559:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-28 16:31:03,571:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:31:03,628:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-28 16:31:03,631:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:31:03,650:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:31:03,667:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-28 16:31:03,709:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-28 16:31:03,735:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:31:03,747:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:31:03,895:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:31:03,981:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-28 16:31:03,990:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:31:04,035:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:31:04,106:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:31:04,449:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:31:09,846:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:31:10,409:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:31:10,453:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:31:10,453:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:31:10,678:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:31:10,689:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:31:10,750:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:31:10,938:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:31:10,950:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:31:10,956:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:31:11,069:INFO:best_params: {'actual_estimator__reg_lambda': 0.05, 'actual_estimator__reg_alpha': 0.1, 'actual_estimator__num_leaves': 10, 'actual_estimator__n_estimators': 190, 'actual_estimator__min_split_gain': 0.3, 'actual_estimator__min_child_samples': 100, 'actual_estimator__learning_rate': 0.5, 'actual_estimator__feature_fraction': 1.0, 'actual_estimator__bagging_freq': 3, 'actual_estimator__bagging_fraction': 0.8}
2025-11-28 16:31:11,069:INFO:Hyperparameter search completed
2025-11-28 16:31:11,069:INFO:SubProcess create_model() called ==================================
2025-11-28 16:31:11,071:INFO:Initializing create_model()
2025-11-28 16:31:11,071:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020508BC6920>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020502D71750>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'reg_lambda': 0.05, 'reg_alpha': 0.1, 'num_leaves': 10, 'n_estimators': 190, 'min_split_gain': 0.3, 'min_child_samples': 100, 'learning_rate': 0.5, 'feature_fraction': 1.0, 'bagging_freq': 3, 'bagging_fraction': 0.8})
2025-11-28 16:31:11,071:INFO:Checking exceptions
2025-11-28 16:31:11,071:INFO:Importing libraries
2025-11-28 16:31:11,071:INFO:Copying training dataset
2025-11-28 16:31:11,211:INFO:Defining folds
2025-11-28 16:31:11,211:INFO:Declaring metric variables
2025-11-28 16:31:11,216:INFO:Importing untrained model
2025-11-28 16:31:11,216:INFO:Declaring custom model
2025-11-28 16:31:11,221:INFO:Light Gradient Boosting Machine Imported successfully
2025-11-28 16:31:11,223:INFO:Starting cross validation
2025-11-28 16:31:11,228:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-28 16:31:11,544:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:31:11,618:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:31:11,713:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:31:11,789:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:31:11,839:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:31:11,923:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:31:12,036:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:31:12,126:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:31:17,689:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:31:17,735:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:31:18,381:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:31:18,402:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:31:18,445:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:31:18,463:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:31:18,613:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:31:18,668:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:31:18,712:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-28 16:31:18,759:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-28 16:31:18,868:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:31:18,941:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:31:20,609:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:31:20,617:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:31:20,734:INFO:Calculating mean and std
2025-11-28 16:31:20,736:INFO:Creating metrics dataframe
2025-11-28 16:31:20,740:INFO:Finalizing model
2025-11-28 16:31:20,839:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:31:21,283:INFO:[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0
2025-11-28 16:31:21,285:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
2025-11-28 16:31:21,285:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-11-28 16:31:21,512:INFO:[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0
2025-11-28 16:31:21,513:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
2025-11-28 16:31:21,513:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-11-28 16:31:21,513:INFO:[LightGBM] [Info] Number of positive: 8764, number of negative: 8764
2025-11-28 16:31:21,537:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021056 seconds.
2025-11-28 16:31:21,537:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-11-28 16:31:21,540:INFO:[LightGBM] [Info] Total Bins 75973
2025-11-28 16:31:21,541:INFO:[LightGBM] [Info] Number of data points in the train set: 17528, number of used features: 319
2025-11-28 16:31:21,543:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-11-28 16:31:21,680:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,682:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,685:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,687:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,687:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,689:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,691:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,693:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,693:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,696:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,697:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,698:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,698:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,700:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,700:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,700:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,700:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,702:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,702:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,702:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,702:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,702:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,702:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,705:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,705:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,705:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,705:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,707:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,707:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,707:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,707:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,709:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,709:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,710:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,710:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,710:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,710:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,712:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,712:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,713:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,713:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,713:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,713:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,715:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,715:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,717:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,717:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,718:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,718:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,718:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,718:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,720:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,720:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,720:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,720:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,720:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,720:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,723:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,723:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,723:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,723:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,725:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,725:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,725:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,725:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,727:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,727:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,728:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,729:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,731:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,731:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,732:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,732:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,734:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,735:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,735:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,736:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,736:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,736:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,736:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,736:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,738:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,738:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,738:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,738:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,739:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,739:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,739:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,739:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,740:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,740:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,740:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,740:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,740:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,740:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,742:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,742:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,742:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,742:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,742:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,742:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,742:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,742:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,745:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,745:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,747:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,747:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,747:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,747:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,749:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,749:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,749:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,749:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,749:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,749:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,751:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,751:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,751:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,751:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,751:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,751:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,753:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,753:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,753:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,753:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,753:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,753:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,755:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,755:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,755:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,755:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,755:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,755:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,757:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,757:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,757:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,757:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,757:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,757:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,757:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,759:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,759:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,759:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,759:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,759:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,759:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,759:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,761:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,761:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,762:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,762:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,765:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,765:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,765:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,765:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,766:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,766:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,766:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,766:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,768:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,768:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,769:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,769:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,771:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,771:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,772:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,772:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,773:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,773:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,773:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,773:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,775:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,775:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,775:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,775:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,775:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,777:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,777:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,777:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,779:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,779:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,780:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,780:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,782:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,782:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,784:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,784:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,786:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,786:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,787:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,787:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,789:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,789:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,789:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,789:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,789:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,789:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,791:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,791:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,792:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,792:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,792:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,792:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,792:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,792:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,794:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,794:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,794:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,794:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,794:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,794:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,796:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,796:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,796:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,796:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,798:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,798:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,799:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,799:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,799:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,799:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,799:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,799:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,801:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,801:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,801:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,801:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,801:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,801:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,803:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,803:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,803:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,803:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,803:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,803:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,805:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,805:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,805:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,805:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,805:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,805:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,805:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,807:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,807:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,807:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,807:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,807:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,807:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,807:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,810:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,810:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,810:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,810:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,810:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,810:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,812:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,812:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,813:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,813:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,815:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,815:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,815:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,815:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,817:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,817:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,817:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,817:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,817:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,817:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,819:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,819:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,819:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,819:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,821:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,821:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,821:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,821:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,822:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,822:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,822:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,822:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,823:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,823:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,823:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,823:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,823:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,823:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,825:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,825:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,825:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,825:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,825:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,825:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,825:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,827:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,827:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,827:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,840:INFO:Uploading results into container
2025-11-28 16:31:21,840:INFO:Uploading model into container now
2025-11-28 16:31:21,840:INFO:_master_model_container: 7
2025-11-28 16:31:21,840:INFO:_display_container: 4
2025-11-28 16:31:21,840:INFO:LGBMClassifier(bagging_fraction=0.8, bagging_freq=3, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=1.0,
               importance_type='split', learning_rate=0.5, max_depth=-1,
               min_child_samples=100, min_child_weight=0.001,
               min_split_gain=0.3, n_estimators=190, n_jobs=-1, num_leaves=10,
               objective=None, random_state=42, reg_alpha=0.1, reg_lambda=0.05,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2025-11-28 16:31:21,842:INFO:create_model() successfully completed......................................
2025-11-28 16:31:22,009:INFO:SubProcess create_model() end ==================================
2025-11-28 16:31:22,009:INFO:choose_better activated
2025-11-28 16:31:22,013:INFO:SubProcess create_model() called ==================================
2025-11-28 16:31:22,013:INFO:Initializing create_model()
2025-11-28 16:31:22,013:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020508BC6920>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-28 16:31:22,013:INFO:Checking exceptions
2025-11-28 16:31:22,013:INFO:Importing libraries
2025-11-28 16:31:22,013:INFO:Copying training dataset
2025-11-28 16:31:22,113:INFO:Defining folds
2025-11-28 16:31:22,113:INFO:Declaring metric variables
2025-11-28 16:31:22,114:INFO:Importing untrained model
2025-11-28 16:31:22,114:INFO:Declaring custom model
2025-11-28 16:31:22,114:INFO:Light Gradient Boosting Machine Imported successfully
2025-11-28 16:31:22,114:INFO:Starting cross validation
2025-11-28 16:31:22,117:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-28 16:31:22,386:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:31:22,446:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:31:22,458:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:31:22,539:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:31:22,649:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:31:22,750:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:31:22,822:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:31:22,927:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:31:23,047:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:31:23,134:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:31:33,184:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:31:33,600:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:31:34,229:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:31:34,402:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:31:34,627:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:31:34,645:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:31:34,661:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:31:34,692:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:31:34,737:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:31:34,820:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:31:34,941:INFO:Calculating mean and std
2025-11-28 16:31:34,941:INFO:Creating metrics dataframe
2025-11-28 16:31:34,942:INFO:Finalizing model
2025-11-28 16:31:35,060:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:31:35,711:INFO:[LightGBM] [Info] Number of positive: 8764, number of negative: 8764
2025-11-28 16:31:35,735:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.018627 seconds.
2025-11-28 16:31:35,735:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-11-28 16:31:35,736:INFO:[LightGBM] [Info] Total Bins 76025
2025-11-28 16:31:35,740:INFO:[LightGBM] [Info] Number of data points in the train set: 17528, number of used features: 323
2025-11-28 16:31:35,741:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-11-28 16:31:36,368:INFO:Uploading results into container
2025-11-28 16:31:36,370:INFO:Uploading model into container now
2025-11-28 16:31:36,370:INFO:_master_model_container: 8
2025-11-28 16:31:36,370:INFO:_display_container: 5
2025-11-28 16:31:36,371:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-11-28 16:31:36,371:INFO:create_model() successfully completed......................................
2025-11-28 16:31:36,545:INFO:SubProcess create_model() end ==================================
2025-11-28 16:31:36,545:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for Recall is 0.7515
2025-11-28 16:31:36,546:INFO:LGBMClassifier(bagging_fraction=0.8, bagging_freq=3, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=1.0,
               importance_type='split', learning_rate=0.5, max_depth=-1,
               min_child_samples=100, min_child_weight=0.001,
               min_split_gain=0.3, n_estimators=190, n_jobs=-1, num_leaves=10,
               objective=None, random_state=42, reg_alpha=0.1, reg_lambda=0.05,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0) result for Recall is 0.7418
2025-11-28 16:31:36,546:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) is best model
2025-11-28 16:31:36,546:INFO:choose_better completed
2025-11-28 16:31:36,546:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2025-11-28 16:31:36,554:INFO:_master_model_container: 8
2025-11-28 16:31:36,554:INFO:_display_container: 4
2025-11-28 16:31:36,554:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-11-28 16:31:36,554:INFO:tune_model() successfully completed......................................
2025-11-28 16:34:37,651:INFO:Initializing predict_model()
2025-11-28 16:34:37,651:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020508BC6920>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=True, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000020507C8A830>)
2025-11-28 16:34:37,653:INFO:Checking exceptions
2025-11-28 16:34:37,653:INFO:Preloading libraries
2025-11-28 16:39:43,417:INFO:Initializing finalize_model()
2025-11-28 16:39:43,417:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020508BC6920>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2025-11-28 16:39:43,418:INFO:Finalizing LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-11-28 16:39:43,491:INFO:Initializing create_model()
2025-11-28 16:39:43,491:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020508BC6920>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2025-11-28 16:39:43,491:INFO:Checking exceptions
2025-11-28 16:39:43,492:INFO:Importing libraries
2025-11-28 16:39:43,492:INFO:Copying training dataset
2025-11-28 16:39:43,505:INFO:Defining folds
2025-11-28 16:39:43,505:INFO:Declaring metric variables
2025-11-28 16:39:43,505:INFO:Importing untrained model
2025-11-28 16:39:43,505:INFO:Declaring custom model
2025-11-28 16:39:43,506:INFO:Light Gradient Boosting Machine Imported successfully
2025-11-28 16:39:43,509:INFO:Cross validation set to False
2025-11-28 16:39:43,510:INFO:Fitting Model
2025-11-28 16:39:43,579:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:39:44,381:INFO:[LightGBM] [Info] Number of positive: 12520, number of negative: 12520
2025-11-28 16:39:44,410:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.025714 seconds.
2025-11-28 16:39:44,410:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-11-28 16:39:44,412:INFO:[LightGBM] [Info] Total Bins 76811
2025-11-28 16:39:44,416:INFO:[LightGBM] [Info] Number of data points in the train set: 25040, number of used features: 323
2025-11-28 16:39:44,417:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-11-28 16:39:45,187:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['STATE', 'FMONTH', 'DISPCODE',
                                             'PSU', 'CTELENM1', 'PVTRESD1',
                                             'COLGHOUS', 'STATERE1', 'CELPHON1',
                                             'LADULT1', 'COLGSEX1', 'NUMADULT',
                                             'LANDSEX1', 'NUMMEN', 'NUMWOMEN',
                                             'RESPSLCT', 'SAFETIME', 'CTELNUM1',
                                             'CELLFON5', 'CADULT1', 'CELLSEX1',
                                             'PVTRESD3', 'CCLGHOUS', 'CST...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=42,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2025-11-28 16:39:45,187:INFO:create_model() successfully completed......................................
2025-11-28 16:39:45,348:INFO:_master_model_container: 8
2025-11-28 16:39:45,348:INFO:_display_container: 5
2025-11-28 16:39:45,360:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['STATE', 'FMONTH', 'DISPCODE',
                                             'PSU', 'CTELENM1', 'PVTRESD1',
                                             'COLGHOUS', 'STATERE1', 'CELPHON1',
                                             'LADULT1', 'COLGSEX1', 'NUMADULT',
                                             'LANDSEX1', 'NUMMEN', 'NUMWOMEN',
                                             'RESPSLCT', 'SAFETIME', 'CTELNUM1',
                                             'CELLFON5', 'CADULT1', 'CELLSEX1',
                                             'PVTRESD3', 'CCLGHOUS', 'CST...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=42,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2025-11-28 16:39:45,360:INFO:finalize_model() successfully completed......................................
2025-11-28 16:39:45,535:INFO:Initializing save_model()
2025-11-28 16:39:45,535:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['STATE', 'FMONTH', 'DISPCODE',
                                             'PSU', 'CTELENM1', 'PVTRESD1',
                                             'COLGHOUS', 'STATERE1', 'CELPHON1',
                                             'LADULT1', 'COLGSEX1', 'NUMADULT',
                                             'LANDSEX1', 'NUMMEN', 'NUMWOMEN',
                                             'RESPSLCT', 'SAFETIME', 'CTELNUM1',
                                             'CELLFON5', 'CADULT1', 'CELLSEX1',
                                             'PVTRESD3', 'CCLGHOUS', 'CST...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=42,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), model_name=../models\final_pipeline_v1, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\OMAR\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['STATE', 'FMONTH', 'DISPCODE',
                                             'PSU', 'CTELENM1', 'PVTRESD1',
                                             'COLGHOUS', 'STATERE1', 'CELPHON1',
                                             'LADULT1', 'COLGSEX1', 'NUMADULT',
                                             'LANDSEX1', 'NUMMEN', 'NUMWOMEN',
                                             'RESPSLCT', 'SAFETIME', 'CTELNUM1',
                                             'CELLFON5', 'CADULT1...
                                    transformer=TargetEncoder(cols=['IDATE',
                                                                    'IDAY'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              random_state=42,
                                                                              sampling_strategy='auto'))))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2025-11-28 16:39:45,535:INFO:Adding model into prep_pipe
2025-11-28 16:39:45,535:WARNING:Only Model saved as it was a pipeline.
2025-11-28 16:39:45,554:INFO:../models\final_pipeline_v1.pkl saved in current working directory
2025-11-28 16:39:45,574:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['STATE', 'FMONTH', 'DISPCODE',
                                             'PSU', 'CTELENM1', 'PVTRESD1',
                                             'COLGHOUS', 'STATERE1', 'CELPHON1',
                                             'LADULT1', 'COLGSEX1', 'NUMADULT',
                                             'LANDSEX1', 'NUMMEN', 'NUMWOMEN',
                                             'RESPSLCT', 'SAFETIME', 'CTELNUM1',
                                             'CELLFON5', 'CADULT1', 'CELLSEX1',
                                             'PVTRESD3', 'CCLGHOUS', 'CST...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=42,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2025-11-28 16:39:45,574:INFO:save_model() successfully completed......................................
2025-11-28 16:41:05,175:INFO:Initializing finalize_model()
2025-11-28 16:41:05,175:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020508BC6920>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2025-11-28 16:41:05,176:INFO:Finalizing LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-11-28 16:41:05,248:INFO:Initializing create_model()
2025-11-28 16:41:05,248:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020508BC6920>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2025-11-28 16:41:05,248:INFO:Checking exceptions
2025-11-28 16:41:05,248:INFO:Importing libraries
2025-11-28 16:41:05,248:INFO:Copying training dataset
2025-11-28 16:41:05,260:INFO:Defining folds
2025-11-28 16:41:05,260:INFO:Declaring metric variables
2025-11-28 16:41:05,261:INFO:Importing untrained model
2025-11-28 16:41:05,261:INFO:Declaring custom model
2025-11-28 16:41:05,261:INFO:Light Gradient Boosting Machine Imported successfully
2025-11-28 16:41:05,264:INFO:Cross validation set to False
2025-11-28 16:41:05,264:INFO:Fitting Model
2025-11-28 16:41:05,330:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:41:06,109:INFO:[LightGBM] [Info] Number of positive: 12520, number of negative: 12520
2025-11-28 16:41:06,139:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.024391 seconds.
2025-11-28 16:41:06,139:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-11-28 16:41:06,140:INFO:[LightGBM] [Info] Total Bins 76811
2025-11-28 16:41:06,145:INFO:[LightGBM] [Info] Number of data points in the train set: 25040, number of used features: 323
2025-11-28 16:41:06,145:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-11-28 16:41:06,912:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['STATE', 'FMONTH', 'DISPCODE',
                                             'PSU', 'CTELENM1', 'PVTRESD1',
                                             'COLGHOUS', 'STATERE1', 'CELPHON1',
                                             'LADULT1', 'COLGSEX1', 'NUMADULT',
                                             'LANDSEX1', 'NUMMEN', 'NUMWOMEN',
                                             'RESPSLCT', 'SAFETIME', 'CTELNUM1',
                                             'CELLFON5', 'CADULT1', 'CELLSEX1',
                                             'PVTRESD3', 'CCLGHOUS', 'CST...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=42,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2025-11-28 16:41:06,912:INFO:create_model() successfully completed......................................
2025-11-28 16:41:07,074:INFO:_master_model_container: 8
2025-11-28 16:41:07,074:INFO:_display_container: 5
2025-11-28 16:41:07,085:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['STATE', 'FMONTH', 'DISPCODE',
                                             'PSU', 'CTELENM1', 'PVTRESD1',
                                             'COLGHOUS', 'STATERE1', 'CELPHON1',
                                             'LADULT1', 'COLGSEX1', 'NUMADULT',
                                             'LANDSEX1', 'NUMMEN', 'NUMWOMEN',
                                             'RESPSLCT', 'SAFETIME', 'CTELNUM1',
                                             'CELLFON5', 'CADULT1', 'CELLSEX1',
                                             'PVTRESD3', 'CCLGHOUS', 'CST...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=42,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2025-11-28 16:41:07,085:INFO:finalize_model() successfully completed......................................
2025-11-28 16:41:07,255:INFO:Initializing save_model()
2025-11-28 16:41:07,255:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['STATE', 'FMONTH', 'DISPCODE',
                                             'PSU', 'CTELENM1', 'PVTRESD1',
                                             'COLGHOUS', 'STATERE1', 'CELPHON1',
                                             'LADULT1', 'COLGSEX1', 'NUMADULT',
                                             'LANDSEX1', 'NUMMEN', 'NUMWOMEN',
                                             'RESPSLCT', 'SAFETIME', 'CTELNUM1',
                                             'CELLFON5', 'CADULT1', 'CELLSEX1',
                                             'PVTRESD3', 'CCLGHOUS', 'CST...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=42,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), model_name=../models\final_pipeline_v1, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\OMAR\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['STATE', 'FMONTH', 'DISPCODE',
                                             'PSU', 'CTELENM1', 'PVTRESD1',
                                             'COLGHOUS', 'STATERE1', 'CELPHON1',
                                             'LADULT1', 'COLGSEX1', 'NUMADULT',
                                             'LANDSEX1', 'NUMMEN', 'NUMWOMEN',
                                             'RESPSLCT', 'SAFETIME', 'CTELNUM1',
                                             'CELLFON5', 'CADULT1...
                                    transformer=TargetEncoder(cols=['IDATE',
                                                                    'IDAY'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              random_state=42,
                                                                              sampling_strategy='auto'))))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2025-11-28 16:41:07,255:INFO:Adding model into prep_pipe
2025-11-28 16:41:07,255:WARNING:Only Model saved as it was a pipeline.
2025-11-28 16:41:07,273:INFO:../models\final_pipeline_v1.pkl saved in current working directory
2025-11-28 16:41:07,290:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['STATE', 'FMONTH', 'DISPCODE',
                                             'PSU', 'CTELENM1', 'PVTRESD1',
                                             'COLGHOUS', 'STATERE1', 'CELPHON1',
                                             'LADULT1', 'COLGSEX1', 'NUMADULT',
                                             'LANDSEX1', 'NUMMEN', 'NUMWOMEN',
                                             'RESPSLCT', 'SAFETIME', 'CTELNUM1',
                                             'CELLFON5', 'CADULT1', 'CELLSEX1',
                                             'PVTRESD3', 'CCLGHOUS', 'CST...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=42,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2025-11-28 16:41:07,290:INFO:save_model() successfully completed......................................
2025-11-28 16:41:07,452:INFO:Initializing get_config()
2025-11-28 16:41:07,452:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020508BC6920>, variable=X_train)
2025-11-28 16:41:07,452:INFO:Variable: 'X_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_train_transformed' instead.
2025-11-28 16:41:07,452:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'X_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_train_transformed' instead.
  warnings.warn(msg)  # print on screen

2025-11-28 16:41:07,490:INFO:Variable:  returned as        STATE  FMONTH     IDATE IMONTH IDAY IYEAR  DISPCODE           PSU  \
720     54.0     1.0  01192022     01   19  2022    1100.0  2.022002e+09   
3896    20.0     8.0  09042022     09   04  2022    1200.0  2.022005e+09   
12399    9.0     1.0  02282022     02   28  2022    1200.0  2.022006e+09   
1720    22.0     1.0  03212022     03   21  2022    1100.0  2.022002e+09   
4419    51.0     7.0  07082022     07   08  2022    1100.0  2.022007e+09   
...      ...     ...       ...    ...  ...   ...       ...           ...   
868     51.0     7.0  07072022     07   07  2022    1100.0  2.022007e+09   
11800    8.0     1.0  01252022     01   25  2022    1100.0  2.022001e+09   
10049   53.0    10.0  11102022     11   10  2022    1200.0  2.022021e+09   
4993    50.0     7.0  08022022     08   02  2022    1100.0  2.022005e+09   
9992    53.0     4.0  04212022     04   21  2022    1100.0  2.022010e+09   

       CTELENM1  PVTRESD1  ...  SMOKGRP  LCSREC  DRNKANY6  DROCDY4_  RFBING6  \
720         NaN       NaN  ...      3.0     2.0       1.0      50.0      1.0   
3896        NaN       NaN  ...      3.0     NaN       9.0     900.0      9.0   
12399       NaN       NaN  ...      NaN     NaN       9.0     900.0      9.0   
1720        NaN       NaN  ...      4.0     NaN       1.0      29.0      1.0   
4419        NaN       NaN  ...      3.0     NaN       1.0       7.0      1.0   
...         ...       ...  ...      ...     ...       ...       ...      ...   
868         NaN       NaN  ...      4.0     NaN       2.0       0.0      1.0   
11800       NaN       NaN  ...      4.0     NaN       2.0       0.0      1.0   
10049       NaN       NaN  ...      NaN     NaN       9.0     900.0      9.0   
4993        NaN       NaN  ...      4.0     NaN       1.0      14.0      1.0   
9992        NaN       NaN  ...      2.0     NaN       1.0      14.0      1.0   

       DRNKWK2  RFDRHV8  FLSHOT7  PNEUMO3  AIDTST4  
720      350.0      1.0      NaN      NaN      1.0  
3896   99900.0      9.0      9.0      9.0      NaN  
12399  99900.0      9.0      NaN      NaN      NaN  
1720     200.0      1.0      1.0      1.0      2.0  
4419     187.0      1.0      NaN      NaN      2.0  
...        ...      ...      ...      ...      ...  
868        0.0      1.0      NaN      NaN      1.0  
11800      0.0      1.0      NaN      NaN      2.0  
10049  99900.0      9.0      NaN      NaN      NaN  
4993     100.0      1.0      NaN      NaN      2.0  
9992     200.0      1.0      NaN      NaN      2.0  

[9283 rows x 326 columns]
2025-11-28 16:41:07,490:INFO:get_config() successfully completed......................................
2025-11-28 16:41:23,356:INFO:Initializing finalize_model()
2025-11-28 16:41:23,356:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020508BC6920>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2025-11-28 16:41:23,356:INFO:Finalizing LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-11-28 16:41:23,417:INFO:Initializing create_model()
2025-11-28 16:41:23,417:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020508BC6920>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2025-11-28 16:41:23,417:INFO:Checking exceptions
2025-11-28 16:41:23,418:INFO:Importing libraries
2025-11-28 16:41:23,418:INFO:Copying training dataset
2025-11-28 16:41:23,430:INFO:Defining folds
2025-11-28 16:41:23,430:INFO:Declaring metric variables
2025-11-28 16:41:23,430:INFO:Importing untrained model
2025-11-28 16:41:23,430:INFO:Declaring custom model
2025-11-28 16:41:23,431:INFO:Light Gradient Boosting Machine Imported successfully
2025-11-28 16:41:23,435:INFO:Cross validation set to False
2025-11-28 16:41:23,435:INFO:Fitting Model
2025-11-28 16:41:23,509:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:41:24,310:INFO:[LightGBM] [Info] Number of positive: 12520, number of negative: 12520
2025-11-28 16:41:24,343:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026326 seconds.
2025-11-28 16:41:24,343:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-11-28 16:41:24,345:INFO:[LightGBM] [Info] Total Bins 76811
2025-11-28 16:41:24,349:INFO:[LightGBM] [Info] Number of data points in the train set: 25040, number of used features: 323
2025-11-28 16:41:24,350:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-11-28 16:41:25,190:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['STATE', 'FMONTH', 'DISPCODE',
                                             'PSU', 'CTELENM1', 'PVTRESD1',
                                             'COLGHOUS', 'STATERE1', 'CELPHON1',
                                             'LADULT1', 'COLGSEX1', 'NUMADULT',
                                             'LANDSEX1', 'NUMMEN', 'NUMWOMEN',
                                             'RESPSLCT', 'SAFETIME', 'CTELNUM1',
                                             'CELLFON5', 'CADULT1', 'CELLSEX1',
                                             'PVTRESD3', 'CCLGHOUS', 'CST...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=42,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2025-11-28 16:41:25,190:INFO:create_model() successfully completed......................................
2025-11-28 16:41:25,361:INFO:_master_model_container: 8
2025-11-28 16:41:25,361:INFO:_display_container: 5
2025-11-28 16:41:25,374:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['STATE', 'FMONTH', 'DISPCODE',
                                             'PSU', 'CTELENM1', 'PVTRESD1',
                                             'COLGHOUS', 'STATERE1', 'CELPHON1',
                                             'LADULT1', 'COLGSEX1', 'NUMADULT',
                                             'LANDSEX1', 'NUMMEN', 'NUMWOMEN',
                                             'RESPSLCT', 'SAFETIME', 'CTELNUM1',
                                             'CELLFON5', 'CADULT1', 'CELLSEX1',
                                             'PVTRESD3', 'CCLGHOUS', 'CST...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=42,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2025-11-28 16:41:25,374:INFO:finalize_model() successfully completed......................................
2025-11-28 16:41:25,550:INFO:Initializing save_model()
2025-11-28 16:41:25,550:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['STATE', 'FMONTH', 'DISPCODE',
                                             'PSU', 'CTELENM1', 'PVTRESD1',
                                             'COLGHOUS', 'STATERE1', 'CELPHON1',
                                             'LADULT1', 'COLGSEX1', 'NUMADULT',
                                             'LANDSEX1', 'NUMMEN', 'NUMWOMEN',
                                             'RESPSLCT', 'SAFETIME', 'CTELNUM1',
                                             'CELLFON5', 'CADULT1', 'CELLSEX1',
                                             'PVTRESD3', 'CCLGHOUS', 'CST...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=42,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), model_name=../models\final_pipeline_v1, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\OMAR\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['STATE', 'FMONTH', 'DISPCODE',
                                             'PSU', 'CTELENM1', 'PVTRESD1',
                                             'COLGHOUS', 'STATERE1', 'CELPHON1',
                                             'LADULT1', 'COLGSEX1', 'NUMADULT',
                                             'LANDSEX1', 'NUMMEN', 'NUMWOMEN',
                                             'RESPSLCT', 'SAFETIME', 'CTELNUM1',
                                             'CELLFON5', 'CADULT1...
                                    transformer=TargetEncoder(cols=['IDATE',
                                                                    'IDAY'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              random_state=42,
                                                                              sampling_strategy='auto'))))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2025-11-28 16:41:25,550:INFO:Adding model into prep_pipe
2025-11-28 16:41:25,550:WARNING:Only Model saved as it was a pipeline.
2025-11-28 16:41:25,569:INFO:../models\final_pipeline_v1.pkl saved in current working directory
2025-11-28 16:41:25,587:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['STATE', 'FMONTH', 'DISPCODE',
                                             'PSU', 'CTELENM1', 'PVTRESD1',
                                             'COLGHOUS', 'STATERE1', 'CELPHON1',
                                             'LADULT1', 'COLGSEX1', 'NUMADULT',
                                             'LANDSEX1', 'NUMMEN', 'NUMWOMEN',
                                             'RESPSLCT', 'SAFETIME', 'CTELNUM1',
                                             'CELLFON5', 'CADULT1', 'CELLSEX1',
                                             'PVTRESD3', 'CCLGHOUS', 'CST...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=42,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2025-11-28 16:41:25,587:INFO:save_model() successfully completed......................................
2025-11-28 16:41:33,335:INFO:Initializing get_config()
2025-11-28 16:41:33,335:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020508BC6920>, variable=X_train)
2025-11-28 16:41:33,335:INFO:Variable: 'X_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_train_transformed' instead.
2025-11-28 16:41:33,335:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'X_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_train_transformed' instead.
  warnings.warn(msg)  # print on screen

2025-11-28 16:41:33,382:INFO:Variable:  returned as        STATE  FMONTH     IDATE IMONTH IDAY IYEAR  DISPCODE           PSU  \
720     54.0     1.0  01192022     01   19  2022    1100.0  2.022002e+09   
3896    20.0     8.0  09042022     09   04  2022    1200.0  2.022005e+09   
12399    9.0     1.0  02282022     02   28  2022    1200.0  2.022006e+09   
1720    22.0     1.0  03212022     03   21  2022    1100.0  2.022002e+09   
4419    51.0     7.0  07082022     07   08  2022    1100.0  2.022007e+09   
...      ...     ...       ...    ...  ...   ...       ...           ...   
868     51.0     7.0  07072022     07   07  2022    1100.0  2.022007e+09   
11800    8.0     1.0  01252022     01   25  2022    1100.0  2.022001e+09   
10049   53.0    10.0  11102022     11   10  2022    1200.0  2.022021e+09   
4993    50.0     7.0  08022022     08   02  2022    1100.0  2.022005e+09   
9992    53.0     4.0  04212022     04   21  2022    1100.0  2.022010e+09   

       CTELENM1  PVTRESD1  ...  SMOKGRP  LCSREC  DRNKANY6  DROCDY4_  RFBING6  \
720         NaN       NaN  ...      3.0     2.0       1.0      50.0      1.0   
3896        NaN       NaN  ...      3.0     NaN       9.0     900.0      9.0   
12399       NaN       NaN  ...      NaN     NaN       9.0     900.0      9.0   
1720        NaN       NaN  ...      4.0     NaN       1.0      29.0      1.0   
4419        NaN       NaN  ...      3.0     NaN       1.0       7.0      1.0   
...         ...       ...  ...      ...     ...       ...       ...      ...   
868         NaN       NaN  ...      4.0     NaN       2.0       0.0      1.0   
11800       NaN       NaN  ...      4.0     NaN       2.0       0.0      1.0   
10049       NaN       NaN  ...      NaN     NaN       9.0     900.0      9.0   
4993        NaN       NaN  ...      4.0     NaN       1.0      14.0      1.0   
9992        NaN       NaN  ...      2.0     NaN       1.0      14.0      1.0   

       DRNKWK2  RFDRHV8  FLSHOT7  PNEUMO3  AIDTST4  
720      350.0      1.0      NaN      NaN      1.0  
3896   99900.0      9.0      9.0      9.0      NaN  
12399  99900.0      9.0      NaN      NaN      NaN  
1720     200.0      1.0      1.0      1.0      2.0  
4419     187.0      1.0      NaN      NaN      2.0  
...        ...      ...      ...      ...      ...  
868        0.0      1.0      NaN      NaN      1.0  
11800      0.0      1.0      NaN      NaN      2.0  
10049  99900.0      9.0      NaN      NaN      NaN  
4993     100.0      1.0      NaN      NaN      2.0  
9992     200.0      1.0      NaN      NaN      2.0  

[9283 rows x 326 columns]
2025-11-28 16:41:33,382:INFO:get_config() successfully completed......................................
2025-11-28 16:50:07,909:INFO:Initializing load_model()
2025-11-28 16:50:07,913:INFO:load_model(model_name=../models\final_pipeline_v1, platform=None, authentication=None, verbose=True)
2025-11-28 16:50:07,976:INFO:Initializing predict_model()
2025-11-28 16:50:07,976:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020508BC6920>, estimator=Pipeline(memory=FastMemory(location=C:\Users\OMAR\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['STATE', 'FMONTH', 'DISPCODE',
                                             'PSU', 'CTELENM1', 'PVTRESD1',
                                             'COLGHOUS', 'STATERE1', 'CELPHON1',
                                             'LADULT1', 'COLGSEX1', 'NUMADULT',
                                             'LANDSEX1', 'NUMMEN', 'NUMWOMEN',
                                             'RESPSLCT', 'SAFETIME', 'CTELNUM1',
                                             'CELLFON5', 'CADULT1...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=42,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=True, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000020507DE05E0>)
2025-11-28 16:50:07,976:INFO:Checking exceptions
2025-11-28 16:50:07,976:INFO:Preloading libraries
2025-11-28 16:50:07,979:INFO:Set up data.
2025-11-28 16:50:08,029:INFO:Set up index.
2025-11-28 16:50:08,042:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:50:08,096:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\utils\generic.py:585: UserWarning: Traceback (most recent call last):
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\utils\generic.py", line 580, in _calculate_metric
    calculated_metric = score_func(y_test, target, sample_weight=weights, **kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\utils\generic.py", line 583, in _calculate_metric
    calculated_metric = score_func(y_test, target, **kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(traceback.format_exc())

2025-11-28 16:50:08,102:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-11-28 16:50:08,105:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-11-28 16:50:08,106:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-11-28 16:50:08,108:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-28 16:50:08,108:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-28 16:50:08,109:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-29 10:00:05,094:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-11-29 10:00:05,094:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-11-29 10:00:05,094:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-11-29 10:00:05,094:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-11-29 10:32:00,396:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-11-29 10:32:00,396:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-11-29 10:32:00,396:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-11-29 10:32:00,396:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-11-29 10:45:58,415:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-11-29 10:45:58,415:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-11-29 10:45:58,415:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-11-29 10:45:58,415:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-11-29 10:46:45,867:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-11-29 10:46:45,867:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-11-29 10:46:45,867:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-11-29 10:46:45,867:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-11-29 10:47:53,850:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-11-29 10:47:53,850:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-11-29 10:47:53,850:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-11-29 10:47:53,850:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-11-29 10:52:13,250:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-11-29 10:52:13,250:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-11-29 10:52:13,250:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-11-29 10:52:13,250:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-11-29 11:22:47,280:INFO:PyCaret ClassificationExperiment
2025-11-29 11:22:47,280:INFO:Logging name: clf-default-name
2025-11-29 11:22:47,280:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-11-29 11:22:47,280:INFO:version 3.3.2
2025-11-29 11:22:47,280:INFO:Initializing setup()
2025-11-29 11:22:47,280:INFO:self.USI: 7743
2025-11-29 11:22:47,280:INFO:self._variable_keys: {'y_train', 'idx', 'logging_param', 'data', 'y', 'fix_imbalance', 'pipeline', 'log_plots_param', 'html_param', 'X_train', 'fold_groups_param', '_ml_usecase', 'n_jobs_param', 'memory', 'gpu_param', 'X', 'X_test', 'exp_id', 'fold_shuffle_param', 'y_test', 'exp_name_log', 'USI', 'is_multiclass', 'gpu_n_jobs_param', 'fold_generator', 'target_param', '_available_plots', 'seed'}
2025-11-29 11:22:47,280:INFO:Checking environment
2025-11-29 11:22:47,280:INFO:python_version: 3.10.19
2025-11-29 11:22:47,280:INFO:python_build: ('main', 'Oct 22 2025 22:23:22')
2025-11-29 11:22:47,280:INFO:machine: AMD64
2025-11-29 11:22:47,280:INFO:platform: Windows-10-10.0.26100-SP0
2025-11-29 11:22:47,280:INFO:Memory: svmem(total=16282144768, available=3520397312, percent=78.4, used=12761747456, free=3520397312)
2025-11-29 11:22:47,281:INFO:Physical Core: 6
2025-11-29 11:22:47,281:INFO:Logical Core: 12
2025-11-29 11:22:47,281:INFO:Checking libraries
2025-11-29 11:22:47,281:INFO:System:
2025-11-29 11:22:47,281:INFO:    python: 3.10.19 | packaged by conda-forge | (main, Oct 22 2025, 22:23:22) [MSC v.1944 64 bit (AMD64)]
2025-11-29 11:22:47,281:INFO:executable: c:\Users\OMAR\miniconda3\envs\xgb_env\python.exe
2025-11-29 11:22:47,281:INFO:   machine: Windows-10-10.0.26100-SP0
2025-11-29 11:22:47,281:INFO:PyCaret required dependencies:
2025-11-29 11:22:47,285:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-29 11:22:47,363:INFO:                 pip: 25.3
2025-11-29 11:22:47,363:INFO:          setuptools: 80.9.0
2025-11-29 11:22:47,363:INFO:             pycaret: 3.3.2
2025-11-29 11:22:47,363:INFO:             IPython: 8.37.0
2025-11-29 11:22:47,363:INFO:          ipywidgets: 8.1.8
2025-11-29 11:22:47,363:INFO:                tqdm: 4.67.1
2025-11-29 11:22:47,363:INFO:               numpy: 1.26.4
2025-11-29 11:22:47,363:INFO:              pandas: 2.1.4
2025-11-29 11:22:47,363:INFO:              jinja2: 3.1.6
2025-11-29 11:22:47,363:INFO:               scipy: 1.11.4
2025-11-29 11:22:47,363:INFO:              joblib: 1.3.2
2025-11-29 11:22:47,363:INFO:             sklearn: 1.4.2
2025-11-29 11:22:47,363:INFO:                pyod: 2.0.5
2025-11-29 11:22:47,364:INFO:            imblearn: 0.14.0
2025-11-29 11:22:47,364:INFO:   category_encoders: 2.7.0
2025-11-29 11:22:47,364:INFO:            lightgbm: 4.6.0
2025-11-29 11:22:47,364:INFO:               numba: 0.62.1
2025-11-29 11:22:47,364:INFO:            requests: 2.32.5
2025-11-29 11:22:47,364:INFO:          matplotlib: 3.7.5
2025-11-29 11:22:47,364:INFO:          scikitplot: 0.3.7
2025-11-29 11:22:47,364:INFO:         yellowbrick: 1.5
2025-11-29 11:22:47,364:INFO:              plotly: 6.5.0
2025-11-29 11:22:47,364:INFO:    plotly-resampler: Not installed
2025-11-29 11:22:47,364:INFO:             kaleido: 1.2.0
2025-11-29 11:22:47,364:INFO:           schemdraw: 0.15
2025-11-29 11:22:47,364:INFO:         statsmodels: 0.14.5
2025-11-29 11:22:47,364:INFO:              sktime: 0.26.0
2025-11-29 11:22:47,364:INFO:               tbats: 1.1.3
2025-11-29 11:22:47,364:INFO:            pmdarima: 2.0.4
2025-11-29 11:22:47,364:INFO:              psutil: 7.1.3
2025-11-29 11:22:47,364:INFO:          markupsafe: 3.0.3
2025-11-29 11:22:47,364:INFO:             pickle5: Not installed
2025-11-29 11:22:47,364:INFO:         cloudpickle: 3.1.2
2025-11-29 11:22:47,364:INFO:         deprecation: 2.1.0
2025-11-29 11:22:47,364:INFO:              xxhash: 3.6.0
2025-11-29 11:22:47,364:INFO:           wurlitzer: Not installed
2025-11-29 11:22:47,364:INFO:PyCaret optional dependencies:
2025-11-29 11:22:47,413:INFO:                shap: 0.48.0
2025-11-29 11:22:47,414:INFO:           interpret: Not installed
2025-11-29 11:22:47,414:INFO:                umap: Not installed
2025-11-29 11:22:47,414:INFO:     ydata_profiling: Not installed
2025-11-29 11:22:47,414:INFO:  explainerdashboard: Not installed
2025-11-29 11:22:47,414:INFO:             autoviz: Not installed
2025-11-29 11:22:47,414:INFO:           fairlearn: 0.12.0.dev0
2025-11-29 11:22:47,414:INFO:          deepchecks: Not installed
2025-11-29 11:22:47,414:INFO:             xgboost: 3.1.2
2025-11-29 11:22:47,414:INFO:            catboost: Not installed
2025-11-29 11:22:47,414:INFO:              kmodes: Not installed
2025-11-29 11:22:47,414:INFO:             mlxtend: Not installed
2025-11-29 11:22:47,414:INFO:       statsforecast: Not installed
2025-11-29 11:22:47,414:INFO:        tune_sklearn: Not installed
2025-11-29 11:22:47,414:INFO:                 ray: Not installed
2025-11-29 11:22:47,414:INFO:            hyperopt: Not installed
2025-11-29 11:22:47,414:INFO:              optuna: Not installed
2025-11-29 11:22:47,414:INFO:               skopt: Not installed
2025-11-29 11:22:47,414:INFO:              mlflow: Not installed
2025-11-29 11:22:47,414:INFO:              gradio: Not installed
2025-11-29 11:22:47,414:INFO:             fastapi: Not installed
2025-11-29 11:22:47,414:INFO:             uvicorn: Not installed
2025-11-29 11:22:47,414:INFO:              m2cgen: Not installed
2025-11-29 11:22:47,414:INFO:           evidently: Not installed
2025-11-29 11:22:47,414:INFO:               fugue: Not installed
2025-11-29 11:22:47,414:INFO:           streamlit: 1.51.0
2025-11-29 11:22:47,414:INFO:             prophet: Not installed
2025-11-29 11:22:47,414:INFO:None
2025-11-29 11:22:47,414:INFO:Set up data.
2025-11-29 11:22:47,420:INFO:Set up folding strategy.
2025-11-29 11:22:47,420:INFO:Set up train/test split.
2025-11-29 11:22:47,424:INFO:Set up index.
2025-11-29 11:22:47,425:INFO:Assigning column types.
2025-11-29 11:22:47,428:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-11-29 11:22:47,455:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-11-29 11:22:47,458:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-11-29 11:22:47,480:INFO:Soft dependency imported: xgboost: 3.1.2
2025-11-29 11:22:47,482:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-29 11:22:47,507:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-11-29 11:22:47,508:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-11-29 11:22:47,525:INFO:Soft dependency imported: xgboost: 3.1.2
2025-11-29 11:22:47,527:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-29 11:22:47,527:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-11-29 11:22:47,553:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-11-29 11:22:47,568:INFO:Soft dependency imported: xgboost: 3.1.2
2025-11-29 11:22:47,569:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-29 11:22:47,596:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-11-29 11:22:47,612:INFO:Soft dependency imported: xgboost: 3.1.2
2025-11-29 11:22:47,613:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-29 11:22:47,613:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-11-29 11:22:47,667:INFO:Soft dependency imported: xgboost: 3.1.2
2025-11-29 11:22:47,670:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-29 11:22:47,713:INFO:Soft dependency imported: xgboost: 3.1.2
2025-11-29 11:22:47,714:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-29 11:22:47,720:INFO:Preparing preprocessing pipeline...
2025-11-29 11:22:47,721:INFO:Set up simple imputation.
2025-11-29 11:22:47,725:INFO:Set up encoding of ordinal features.
2025-11-29 11:22:47,730:INFO:Set up encoding of categorical features.
2025-11-29 11:22:47,730:INFO:Set up removing outliers.
2025-11-29 11:22:47,730:INFO:Set up imbalanced handling.
2025-11-29 11:22:47,730:INFO:Set up feature normalization.
2025-11-29 11:22:47,945:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\joblib\externals\loky\backend\context.py:136: UserWarning: Could not find the number of physical cores for the following reason:
[WinError 2] El sistema no puede encontrar el archivo especificado
Returning the number of logical cores instead. You can silence this warning by setting LOKY_MAX_CPU_COUNT to the number of cores you want to use.
  warnings.warn(

2025-11-29 11:22:47,967:INFO:Finished creating preprocessing pipeline.
2025-11-29 11:22:48,015:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\OMAR\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'SystolicBP',
                                             'TotalCholesterol', 'LDL',
                                             'Triglycerides', 'HbA1c',
                                             'Glucose', 'UricAcid',
                                             'Creatinine', 'BMI',
                                             'WaistCircumference', 'Height',
                                             'IncomeRatio', 'ALT_Enzyme',
                                             'AST_Enzyme', 'GGT_Enzyme',
                                             'Albumin', 'Po...
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              random_state=123,
                                                                              sampling_strategy='auto')))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=RobustScaler(copy=True,
                                                             quantile_range=(25.0,
                                                                             75.0),
                                                             unit_variance=False,
                                                             with_centering=True,
                                                             with_scaling=True)))],
         verbose=False)
2025-11-29 11:22:48,015:INFO:Creating final display dataframe.
2025-11-29 11:22:48,575:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target      HeartDisease
2                   Target type            Binary
3           Original data shape        (2185, 27)
4        Transformed data shape        (3484, 36)
5   Transformed train set shape        (2828, 36)
6    Transformed test set shape         (656, 36)
7              Numeric features                19
8          Categorical features                 7
9      Rows with missing values             87.6%
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16              Remove outliers              True
17           Outliers threshold              0.05
18                Fix imbalance              True
19         Fix imbalance method             SMOTE
20                    Normalize              True
21             Normalize method            robust
22               Fold Generator   StratifiedKFold
23                  Fold Number                10
24                     CPU Jobs                -1
25                      Use GPU             False
26               Log Experiment             False
27              Experiment Name  clf-default-name
28                          USI              7743
2025-11-29 11:22:48,626:INFO:Soft dependency imported: xgboost: 3.1.2
2025-11-29 11:22:48,627:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-29 11:22:48,671:INFO:Soft dependency imported: xgboost: 3.1.2
2025-11-29 11:22:48,673:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-29 11:22:48,675:INFO:setup() successfully completed in 1.41s...............
2025-11-29 11:30:52,503:INFO:Initializing compare_models()
2025-11-29 11:30:52,503:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025EE79BDC00>, include=['xgboost', 'lightgbm'], fold=None, round=4, cross_validation=True, sort=Recall, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000025EE79BDC00>, 'include': ['xgboost', 'lightgbm'], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Recall', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2025-11-29 11:30:52,503:INFO:Checking exceptions
2025-11-29 11:30:52,509:INFO:Preparing display monitor
2025-11-29 11:30:52,530:INFO:Initializing Extreme Gradient Boosting
2025-11-29 11:30:52,530:INFO:Total runtime is 0.0 minutes
2025-11-29 11:30:52,532:INFO:SubProcess create_model() called ==================================
2025-11-29 11:30:52,532:INFO:Initializing create_model()
2025-11-29 11:30:52,532:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025EE79BDC00>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025EE4FEEBF0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-29 11:30:52,532:INFO:Checking exceptions
2025-11-29 11:30:52,532:INFO:Importing libraries
2025-11-29 11:30:52,532:INFO:Copying training dataset
2025-11-29 11:30:52,537:INFO:Defining folds
2025-11-29 11:30:52,537:INFO:Declaring metric variables
2025-11-29 11:30:52,540:INFO:Importing untrained model
2025-11-29 11:30:52,544:INFO:Extreme Gradient Boosting Imported successfully
2025-11-29 11:30:52,550:INFO:Starting cross validation
2025-11-29 11:30:52,558:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-29 11:30:56,153:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-29 11:30:56,161:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-29 11:30:56,165:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-29 11:30:56,167:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-29 11:30:56,169:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-29 11:30:56,169:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-29 11:30:56,176:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-29 11:30:56,176:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-29 11:30:56,180:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-29 11:30:56,187:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-29 11:30:56,803:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-11-29 11:30:56,806:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-11-29 11:30:56,817:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-11-29 11:30:56,844:INFO:Calculating mean and std
2025-11-29 11:30:56,846:INFO:Creating metrics dataframe
2025-11-29 11:30:56,848:INFO:Uploading results into container
2025-11-29 11:30:56,850:INFO:Uploading model into container now
2025-11-29 11:30:56,850:INFO:_master_model_container: 1
2025-11-29 11:30:56,850:INFO:_display_container: 2
2025-11-29 11:30:56,853:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              feature_weights=None, gamma=None, grow_policy=None,
              importance_type=None, interaction_constraints=None,
              learning_rate=None, max_bin=None, max_cat_threshold=None,
              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,
              max_leaves=None, min_child_weight=None, missing=nan,
              monotone_constraints=None, multi_strategy=None, n_estimators=None,
              n_jobs=-1, num_parallel_tree=None, ...)
2025-11-29 11:30:56,853:INFO:create_model() successfully completed......................................
2025-11-29 11:30:57,026:INFO:SubProcess create_model() end ==================================
2025-11-29 11:30:57,026:INFO:Creating metrics dataframe
2025-11-29 11:30:57,032:INFO:Initializing Light Gradient Boosting Machine
2025-11-29 11:30:57,032:INFO:Total runtime is 0.0750348687171936 minutes
2025-11-29 11:30:57,037:INFO:SubProcess create_model() called ==================================
2025-11-29 11:30:57,037:INFO:Initializing create_model()
2025-11-29 11:30:57,037:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025EE79BDC00>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025EE4FEEBF0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-29 11:30:57,037:INFO:Checking exceptions
2025-11-29 11:30:57,037:INFO:Importing libraries
2025-11-29 11:30:57,037:INFO:Copying training dataset
2025-11-29 11:30:57,044:INFO:Defining folds
2025-11-29 11:30:57,044:INFO:Declaring metric variables
2025-11-29 11:30:57,049:INFO:Importing untrained model
2025-11-29 11:30:57,049:INFO:Light Gradient Boosting Machine Imported successfully
2025-11-29 11:30:57,056:INFO:Starting cross validation
2025-11-29 11:30:57,064:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-29 11:30:58,553:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-11-29 11:30:58,616:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-11-29 11:30:58,780:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-11-29 11:30:58,840:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-11-29 11:30:59,726:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-29 11:30:59,740:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-29 11:31:00,090:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-11-29 11:31:00,099:INFO:Calculating mean and std
2025-11-29 11:31:00,100:INFO:Creating metrics dataframe
2025-11-29 11:31:00,103:INFO:Uploading results into container
2025-11-29 11:31:00,103:INFO:Uploading model into container now
2025-11-29 11:31:00,104:INFO:_master_model_container: 2
2025-11-29 11:31:00,104:INFO:_display_container: 2
2025-11-29 11:31:00,105:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-11-29 11:31:00,105:INFO:create_model() successfully completed......................................
2025-11-29 11:31:00,246:INFO:SubProcess create_model() end ==================================
2025-11-29 11:31:00,246:INFO:Creating metrics dataframe
2025-11-29 11:31:00,259:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  master_display_.apply(

2025-11-29 11:31:00,266:INFO:Initializing create_model()
2025-11-29 11:31:00,266:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025EE79BDC00>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              feature_weights=None, gamma=None, grow_policy=None,
              importance_type=None, interaction_constraints=None,
              learning_rate=None, max_bin=None, max_cat_threshold=None,
              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,
              max_leaves=None, min_child_weight=None, missing=nan,
              monotone_constraints=None, multi_strategy=None, n_estimators=None,
              n_jobs=-1, num_parallel_tree=None, ...), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-29 11:31:00,266:INFO:Checking exceptions
2025-11-29 11:31:00,267:INFO:Importing libraries
2025-11-29 11:31:00,267:INFO:Copying training dataset
2025-11-29 11:31:00,267:INFO:Defining folds
2025-11-29 11:31:00,267:INFO:Declaring metric variables
2025-11-29 11:31:00,267:INFO:Importing untrained model
2025-11-29 11:31:00,267:INFO:Declaring custom model
2025-11-29 11:31:00,267:INFO:Extreme Gradient Boosting Imported successfully
2025-11-29 11:31:00,280:INFO:Cross validation set to False
2025-11-29 11:31:00,280:INFO:Fitting Model
2025-11-29 11:31:00,492:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              feature_weights=None, gamma=None, grow_policy=None,
              importance_type=None, interaction_constraints=None,
              learning_rate=None, max_bin=None, max_cat_threshold=None,
              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,
              max_leaves=None, min_child_weight=None, missing=nan,
              monotone_constraints=None, multi_strategy=None, n_estimators=None,
              n_jobs=-1, num_parallel_tree=None, ...)
2025-11-29 11:31:00,492:INFO:create_model() successfully completed......................................
2025-11-29 11:31:00,630:INFO:_master_model_container: 2
2025-11-29 11:31:00,630:INFO:_display_container: 2
2025-11-29 11:31:00,631:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              feature_weights=None, gamma=None, grow_policy=None,
              importance_type=None, interaction_constraints=None,
              learning_rate=None, max_bin=None, max_cat_threshold=None,
              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,
              max_leaves=None, min_child_weight=None, missing=nan,
              monotone_constraints=None, multi_strategy=None, n_estimators=None,
              n_jobs=-1, num_parallel_tree=None, ...)
2025-11-29 11:31:00,631:INFO:compare_models() successfully completed......................................
2025-11-29 11:31:22,717:INFO:Initializing tune_model()
2025-11-29 11:31:22,717:INFO:tune_model(estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              feature_weights=None, gamma=None, grow_policy=None,
              importance_type=None, interaction_constraints=None,
              learning_rate=None, max_bin=None, max_cat_threshold=None,
              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,
              max_leaves=None, min_child_weight=None, missing=nan,
              monotone_constraints=None, multi_strategy=None, n_estimators=None,
              n_jobs=-1, num_parallel_tree=None, ...), fold=None, round=4, n_iter=5, custom_grid=None, optimize=Recall, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=False, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025EE79BDC00>)
2025-11-29 11:31:22,717:INFO:Checking exceptions
2025-11-29 11:31:22,723:INFO:Copying training dataset
2025-11-29 11:31:22,728:INFO:Checking base model
2025-11-29 11:31:22,728:INFO:Base model : Extreme Gradient Boosting
2025-11-29 11:31:22,729:INFO:Declaring metric variables
2025-11-29 11:31:22,729:INFO:Defining Hyperparameters
2025-11-29 11:31:22,861:INFO:Tuning with n_jobs=-1
2025-11-29 11:31:22,861:INFO:Initializing RandomizedSearchCV
2025-11-29 11:31:26,292:INFO:best_params: {'actual_estimator__subsample': 0.5, 'actual_estimator__scale_pos_weight': 2.1, 'actual_estimator__reg_lambda': 5, 'actual_estimator__reg_alpha': 0.05, 'actual_estimator__n_estimators': 300, 'actual_estimator__min_child_weight': 1, 'actual_estimator__max_depth': 10, 'actual_estimator__learning_rate': 0.0005, 'actual_estimator__colsample_bytree': 1}
2025-11-29 11:31:26,292:INFO:Hyperparameter search completed
2025-11-29 11:31:26,292:INFO:SubProcess create_model() called ==================================
2025-11-29 11:31:26,293:INFO:Initializing create_model()
2025-11-29 11:31:26,293:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025EE79BDC00>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              feature_weights=None, gamma=None, grow_policy=None,
              importance_type=None, interaction_constraints=None,
              learning_rate=None, max_bin=None, max_cat_threshold=None,
              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,
              max_leaves=None, min_child_weight=None, missing=nan,
              monotone_constraints=None, multi_strategy=None, n_estimators=None,
              n_jobs=-1, num_parallel_tree=None, ...), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025EE4E877F0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'subsample': 0.5, 'scale_pos_weight': 2.1, 'reg_lambda': 5, 'reg_alpha': 0.05, 'n_estimators': 300, 'min_child_weight': 1, 'max_depth': 10, 'learning_rate': 0.0005, 'colsample_bytree': 1})
2025-11-29 11:31:26,293:INFO:Checking exceptions
2025-11-29 11:31:26,293:INFO:Importing libraries
2025-11-29 11:31:26,293:INFO:Copying training dataset
2025-11-29 11:31:26,296:INFO:Defining folds
2025-11-29 11:31:26,296:INFO:Declaring metric variables
2025-11-29 11:31:26,296:INFO:Importing untrained model
2025-11-29 11:31:26,296:INFO:Declaring custom model
2025-11-29 11:31:26,296:INFO:Extreme Gradient Boosting Imported successfully
2025-11-29 11:31:26,296:INFO:Starting cross validation
2025-11-29 11:31:26,303:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-29 11:31:28,026:INFO:Calculating mean and std
2025-11-29 11:31:28,026:INFO:Creating metrics dataframe
2025-11-29 11:31:28,026:INFO:Finalizing model
2025-11-29 11:31:28,477:INFO:Uploading results into container
2025-11-29 11:31:28,477:INFO:Uploading model into container now
2025-11-29 11:31:28,477:INFO:_master_model_container: 3
2025-11-29 11:31:28,477:INFO:_display_container: 3
2025-11-29 11:31:28,479:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None, colsample_bytree=1,
              device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              feature_weights=None, gamma=None, grow_policy=None,
              importance_type=None, interaction_constraints=None,
              learning_rate=0.0005, max_bin=None, max_cat_threshold=None,
              max_cat_to_onehot=None, max_delta_step=None, max_depth=10,
              max_leaves=None, min_child_weight=1, missing=nan,
              monotone_constraints=None, multi_strategy=None, n_estimators=300,
              n_jobs=-1, num_parallel_tree=None, ...)
2025-11-29 11:31:28,479:INFO:create_model() successfully completed......................................
2025-11-29 11:31:28,602:INFO:SubProcess create_model() end ==================================
2025-11-29 11:31:28,602:INFO:choose_better activated
2025-11-29 11:31:28,603:INFO:SubProcess create_model() called ==================================
2025-11-29 11:31:28,603:INFO:Initializing create_model()
2025-11-29 11:31:28,603:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025EE79BDC00>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              feature_weights=None, gamma=None, grow_policy=None,
              importance_type=None, interaction_constraints=None,
              learning_rate=None, max_bin=None, max_cat_threshold=None,
              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,
              max_leaves=None, min_child_weight=None, missing=nan,
              monotone_constraints=None, multi_strategy=None, n_estimators=None,
              n_jobs=-1, num_parallel_tree=None, ...), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-29 11:31:28,603:INFO:Checking exceptions
2025-11-29 11:31:28,603:INFO:Importing libraries
2025-11-29 11:31:28,603:INFO:Copying training dataset
2025-11-29 11:31:28,606:INFO:Defining folds
2025-11-29 11:31:28,606:INFO:Declaring metric variables
2025-11-29 11:31:28,606:INFO:Importing untrained model
2025-11-29 11:31:28,606:INFO:Declaring custom model
2025-11-29 11:31:28,609:INFO:Extreme Gradient Boosting Imported successfully
2025-11-29 11:31:28,609:INFO:Starting cross validation
2025-11-29 11:31:28,613:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-29 11:31:29,053:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-11-29 11:31:29,060:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-11-29 11:31:29,067:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-11-29 11:31:29,076:INFO:Calculating mean and std
2025-11-29 11:31:29,076:INFO:Creating metrics dataframe
2025-11-29 11:31:29,078:INFO:Finalizing model
2025-11-29 11:31:29,277:INFO:Uploading results into container
2025-11-29 11:31:29,277:INFO:Uploading model into container now
2025-11-29 11:31:29,277:INFO:_master_model_container: 4
2025-11-29 11:31:29,277:INFO:_display_container: 4
2025-11-29 11:31:29,280:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              feature_weights=None, gamma=None, grow_policy=None,
              importance_type=None, interaction_constraints=None,
              learning_rate=None, max_bin=None, max_cat_threshold=None,
              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,
              max_leaves=None, min_child_weight=None, missing=nan,
              monotone_constraints=None, multi_strategy=None, n_estimators=None,
              n_jobs=-1, num_parallel_tree=None, ...)
2025-11-29 11:31:29,280:INFO:create_model() successfully completed......................................
2025-11-29 11:31:29,404:INFO:SubProcess create_model() end ==================================
2025-11-29 11:31:29,404:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              feature_weights=None, gamma=None, grow_policy=None,
              importance_type=None, interaction_constraints=None,
              learning_rate=None, max_bin=None, max_cat_threshold=None,
              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,
              max_leaves=None, min_child_weight=None, missing=nan,
              monotone_constraints=None, multi_strategy=None, n_estimators=None,
              n_jobs=-1, num_parallel_tree=None, ...) result for Recall is 0.065
2025-11-29 11:31:29,404:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None, colsample_bytree=1,
              device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              feature_weights=None, gamma=None, grow_policy=None,
              importance_type=None, interaction_constraints=None,
              learning_rate=0.0005, max_bin=None, max_cat_threshold=None,
              max_cat_to_onehot=None, max_delta_step=None, max_depth=10,
              max_leaves=None, min_child_weight=1, missing=nan,
              monotone_constraints=None, multi_strategy=None, n_estimators=300,
              n_jobs=-1, num_parallel_tree=None, ...) result for Recall is 1.0
2025-11-29 11:31:29,404:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None, colsample_bytree=1,
              device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              feature_weights=None, gamma=None, grow_policy=None,
              importance_type=None, interaction_constraints=None,
              learning_rate=0.0005, max_bin=None, max_cat_threshold=None,
              max_cat_to_onehot=None, max_delta_step=None, max_depth=10,
              max_leaves=None, min_child_weight=1, missing=nan,
              monotone_constraints=None, multi_strategy=None, n_estimators=300,
              n_jobs=-1, num_parallel_tree=None, ...) is best model
2025-11-29 11:31:29,404:INFO:choose_better completed
2025-11-29 11:31:29,406:INFO:_master_model_container: 4
2025-11-29 11:31:29,406:INFO:_display_container: 3
2025-11-29 11:31:29,406:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None, colsample_bytree=1,
              device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              feature_weights=None, gamma=None, grow_policy=None,
              importance_type=None, interaction_constraints=None,
              learning_rate=0.0005, max_bin=None, max_cat_threshold=None,
              max_cat_to_onehot=None, max_delta_step=None, max_depth=10,
              max_leaves=None, min_child_weight=1, missing=nan,
              monotone_constraints=None, multi_strategy=None, n_estimators=300,
              n_jobs=-1, num_parallel_tree=None, ...)
2025-11-29 11:31:29,406:INFO:tune_model() successfully completed......................................
2025-11-29 11:32:35,163:INFO:Initializing finalize_model()
2025-11-29 11:32:35,163:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025EE79BDC00>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None, colsample_bytree=1,
              device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              feature_weights=None, gamma=None, grow_policy=None,
              importance_type=None, interaction_constraints=None,
              learning_rate=0.0005, max_bin=None, max_cat_threshold=None,
              max_cat_to_onehot=None, max_delta_step=None, max_depth=10,
              max_leaves=None, min_child_weight=1, missing=nan,
              monotone_constraints=None, multi_strategy=None, n_estimators=300,
              n_jobs=-1, num_parallel_tree=None, ...), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2025-11-29 11:32:35,164:INFO:Finalizing XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None, colsample_bytree=1,
              device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              feature_weights=None, gamma=None, grow_policy=None,
              importance_type=None, interaction_constraints=None,
              learning_rate=0.0005, max_bin=None, max_cat_threshold=None,
              max_cat_to_onehot=None, max_delta_step=None, max_depth=10,
              max_leaves=None, min_child_weight=1, missing=nan,
              monotone_constraints=None, multi_strategy=None, n_estimators=300,
              n_jobs=-1, num_parallel_tree=None, ...)
2025-11-29 11:32:35,167:INFO:Initializing create_model()
2025-11-29 11:32:35,167:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025EE79BDC00>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None, colsample_bytree=1,
              device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              feature_weights=None, gamma=None, grow_policy=None,
              importance_type=None, interaction_constraints=None,
              learning_rate=0.0005, max_bin=None, max_cat_threshold=None,
              max_cat_to_onehot=None, max_delta_step=None, max_depth=10,
              max_leaves=None, min_child_weight=1, missing=nan,
              monotone_constraints=None, multi_strategy=None, n_estimators=300,
              n_jobs=-1, num_parallel_tree=None, ...), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2025-11-29 11:32:35,167:INFO:Checking exceptions
2025-11-29 11:32:35,169:INFO:Importing libraries
2025-11-29 11:32:35,169:INFO:Copying training dataset
2025-11-29 11:32:35,169:INFO:Defining folds
2025-11-29 11:32:35,169:INFO:Declaring metric variables
2025-11-29 11:32:35,169:INFO:Importing untrained model
2025-11-29 11:32:35,169:INFO:Declaring custom model
2025-11-29 11:32:35,171:INFO:Extreme Gradient Boosting Imported successfully
2025-11-29 11:32:35,176:INFO:Cross validation set to False
2025-11-29 11:32:35,176:INFO:Fitting Model
2025-11-29 11:32:35,797:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'SystolicBP',
                                             'TotalCholesterol', 'LDL',
                                             'Triglycerides', 'HbA1c',
                                             'Glucose', 'UricAcid',
                                             'Creatinine', 'BMI',
                                             'WaistCircumference', 'Height',
                                             'IncomeRatio', 'ALT_Enzyme',
                                             'AST_Enzyme', 'GGT_Enzyme',
                                             'Albumin', 'Potassium', 'Sodium'],
                                    transformer=SimpleIm...
                               gamma=None, grow_policy=None,
                               importance_type=None,
                               interaction_constraints=None,
                               learning_rate=0.0005, max_bin=None,
                               max_cat_threshold=None, max_cat_to_onehot=None,
                               max_delta_step=None, max_depth=10,
                               max_leaves=None, min_child_weight=1, missing=nan,
                               monotone_constraints=None, multi_strategy=None,
                               n_estimators=300, n_jobs=-1,
                               num_parallel_tree=None, ...))],
         verbose=False)
2025-11-29 11:32:35,797:INFO:create_model() successfully completed......................................
2025-11-29 11:32:35,910:INFO:_master_model_container: 4
2025-11-29 11:32:35,910:INFO:_display_container: 3
2025-11-29 11:32:35,959:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'SystolicBP',
                                             'TotalCholesterol', 'LDL',
                                             'Triglycerides', 'HbA1c',
                                             'Glucose', 'UricAcid',
                                             'Creatinine', 'BMI',
                                             'WaistCircumference', 'Height',
                                             'IncomeRatio', 'ALT_Enzyme',
                                             'AST_Enzyme', 'GGT_Enzyme',
                                             'Albumin', 'Potassium', 'Sodium'],
                                    transformer=SimpleIm...
                               gamma=None, grow_policy=None,
                               importance_type=None,
                               interaction_constraints=None,
                               learning_rate=0.0005, max_bin=None,
                               max_cat_threshold=None, max_cat_to_onehot=None,
                               max_delta_step=None, max_depth=10,
                               max_leaves=None, min_child_weight=1, missing=nan,
                               monotone_constraints=None, multi_strategy=None,
                               n_estimators=300, n_jobs=-1,
                               num_parallel_tree=None, ...))],
         verbose=False)
2025-11-29 11:32:35,959:INFO:finalize_model() successfully completed......................................
2025-11-29 11:32:36,167:INFO:Initializing save_model()
2025-11-29 11:32:36,167:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'SystolicBP',
                                             'TotalCholesterol', 'LDL',
                                             'Triglycerides', 'HbA1c',
                                             'Glucose', 'UricAcid',
                                             'Creatinine', 'BMI',
                                             'WaistCircumference', 'Height',
                                             'IncomeRatio', 'ALT_Enzyme',
                                             'AST_Enzyme', 'GGT_Enzyme',
                                             'Albumin', 'Potassium', 'Sodium'],
                                    transformer=SimpleIm...
                               gamma=None, grow_policy=None,
                               importance_type=None,
                               interaction_constraints=None,
                               learning_rate=0.0005, max_bin=None,
                               max_cat_threshold=None, max_cat_to_onehot=None,
                               max_delta_step=None, max_depth=10,
                               max_leaves=None, min_child_weight=1, missing=nan,
                               monotone_constraints=None, multi_strategy=None,
                               n_estimators=300, n_jobs=-1,
                               num_parallel_tree=None, ...))],
         verbose=False), model_name=../models\best_pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\OMAR\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'SystolicBP',
                                             'TotalCholesterol', 'LDL',
                                             'Triglycerides', 'HbA1c',
                                             'Glucose', 'UricAcid',
                                             'Creatinine', 'BMI',
                                             'WaistCircumference', 'Height',
                                             'IncomeRatio', 'ALT_Enzyme',
                                             'AST_Enzyme', 'GGT_Enzyme',
                                             'Albumin', 'Po...
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              random_state=123,
                                                                              sampling_strategy='auto')))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=RobustScaler(copy=True,
                                                             quantile_range=(25.0,
                                                                             75.0),
                                                             unit_variance=False,
                                                             with_centering=True,
                                                             with_scaling=True)))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2025-11-29 11:32:36,167:INFO:Adding model into prep_pipe
2025-11-29 11:32:36,167:WARNING:Only Model saved as it was a pipeline.
2025-11-29 11:32:36,207:INFO:../models\best_pipeline.pkl saved in current working directory
2025-11-29 11:32:36,273:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'SystolicBP',
                                             'TotalCholesterol', 'LDL',
                                             'Triglycerides', 'HbA1c',
                                             'Glucose', 'UricAcid',
                                             'Creatinine', 'BMI',
                                             'WaistCircumference', 'Height',
                                             'IncomeRatio', 'ALT_Enzyme',
                                             'AST_Enzyme', 'GGT_Enzyme',
                                             'Albumin', 'Potassium', 'Sodium'],
                                    transformer=SimpleIm...
                               gamma=None, grow_policy=None,
                               importance_type=None,
                               interaction_constraints=None,
                               learning_rate=0.0005, max_bin=None,
                               max_cat_threshold=None, max_cat_to_onehot=None,
                               max_delta_step=None, max_depth=10,
                               max_leaves=None, min_child_weight=1, missing=nan,
                               monotone_constraints=None, multi_strategy=None,
                               n_estimators=300, n_jobs=-1,
                               num_parallel_tree=None, ...))],
         verbose=False)
2025-11-29 11:32:36,273:INFO:save_model() successfully completed......................................
2025-11-29 11:32:56,840:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-11-29 11:32:56,840:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-11-29 11:32:56,840:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-11-29 11:32:56,840:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-11-29 11:33:01,238:INFO:Initializing load_model()
2025-11-29 11:33:01,238:INFO:load_model(model_name=../models/best_pipeline, platform=None, authentication=None, verbose=True)
2025-11-29 11:33:01,297:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-29 11:33:11,410:INFO:Initializing predict_model()
2025-11-29 11:33:11,410:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021219F935B0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Age', 'SystolicBP',
                                             'TotalCholesterol', 'LDL',
                                             'Triglycerides', 'HbA1c',
                                             'Glucose', 'UricAcid',
                                             'Creatinine', 'BMI',
                                             'WaistCircumference', 'Height',
                                             'IncomeRatio', 'ALT_Enzyme',
                                             'AST_Enzyme', 'GGT_Enzyme',
                                             'Albumin', 'Potassium', 'Sodium'],
                                    transformer=SimpleImputer())),
                ('c...
                               feature_types=None, feature_weights=None,
                               gamma=None, grow_policy=None,
                               importance_type=None,
                               interaction_constraints=None,
                               learning_rate=0.0005, max_bin=None,
                               max_cat_threshold=None, max_cat_to_onehot=None,
                               max_delta_step=None, max_depth=10,
                               max_leaves=None, min_child_weight=1, missing=nan,
                               monotone_constraints=None, multi_strategy=None,
                               n_estimators=300, n_jobs=-1,
                               num_parallel_tree=None, ...))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000021219DFA170>)
2025-11-29 11:33:11,410:INFO:Checking exceptions
2025-11-29 11:33:11,410:INFO:Preloading libraries
2025-11-29 11:33:11,410:INFO:Set up data.
2025-11-29 11:33:11,421:INFO:Set up index.
2025-11-29 11:33:27,570:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-11-29 11:33:27,574:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-11-29 11:33:27,574:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-11-29 11:48:23,953:INFO:Initializing load_model()
2025-11-29 11:48:23,954:INFO:load_model(model_name=../models/best_pipeline, platform=None, authentication=None, verbose=True)
2025-11-29 11:48:33,828:INFO:Initializing predict_model()
2025-11-29 11:48:33,828:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002124DF96EC0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Age', 'SystolicBP',
                                             'TotalCholesterol', 'LDL',
                                             'Triglycerides', 'HbA1c',
                                             'Glucose', 'UricAcid',
                                             'Creatinine', 'BMI',
                                             'WaistCircumference', 'Height',
                                             'IncomeRatio', 'ALT_Enzyme',
                                             'AST_Enzyme', 'GGT_Enzyme',
                                             'Albumin', 'Potassium', 'Sodium'],
                                    transformer=SimpleImputer())),
                ('c...
                               feature_types=None, feature_weights=None,
                               gamma=None, grow_policy=None,
                               importance_type=None,
                               interaction_constraints=None,
                               learning_rate=0.0005, max_bin=None,
                               max_cat_threshold=None, max_cat_to_onehot=None,
                               max_delta_step=None, max_depth=10,
                               max_leaves=None, min_child_weight=1, missing=nan,
                               monotone_constraints=None, multi_strategy=None,
                               n_estimators=300, n_jobs=-1,
                               num_parallel_tree=None, ...))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000021232187880>)
2025-11-29 11:48:33,828:INFO:Checking exceptions
2025-11-29 11:48:33,828:INFO:Preloading libraries
2025-11-29 11:48:33,828:INFO:Set up data.
2025-11-29 11:48:33,837:INFO:Set up index.
2025-11-29 11:48:39,864:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-11-29 11:48:39,867:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-11-29 11:48:39,869:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-11-29 11:53:13,069:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-11-29 11:53:13,069:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-11-29 11:53:13,069:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-11-29 11:53:13,069:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-11-29 11:53:22,473:INFO:Initializing load_model()
2025-11-29 11:53:22,473:INFO:load_model(model_name=../models/best_pipeline, platform=None, authentication=None, verbose=True)
2025-11-29 11:53:22,530:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-29 12:00:24,813:INFO:Initializing load_model()
2025-11-29 12:00:24,813:INFO:load_model(model_name=../models/best_pipeline, platform=None, authentication=None, verbose=True)
2025-11-29 12:00:50,055:INFO:Initializing predict_model()
2025-11-29 12:00:50,055:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017F198DB070>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Age', 'SystolicBP',
                                             'TotalCholesterol', 'LDL',
                                             'Triglycerides', 'HbA1c',
                                             'Glucose', 'UricAcid',
                                             'Creatinine', 'BMI',
                                             'WaistCircumference', 'Height',
                                             'IncomeRatio', 'ALT_Enzyme',
                                             'AST_Enzyme', 'GGT_Enzyme',
                                             'Albumin', 'Potassium', 'Sodium'],
                                    transformer=SimpleImputer())),
                ('c...
                               feature_types=None, feature_weights=None,
                               gamma=None, grow_policy=None,
                               importance_type=None,
                               interaction_constraints=None,
                               learning_rate=0.0005, max_bin=None,
                               max_cat_threshold=None, max_cat_to_onehot=None,
                               max_delta_step=None, max_depth=10,
                               max_leaves=None, min_child_weight=1, missing=nan,
                               monotone_constraints=None, multi_strategy=None,
                               n_estimators=300, n_jobs=-1,
                               num_parallel_tree=None, ...))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000017F1AC72B00>)
2025-11-29 12:00:50,055:INFO:Checking exceptions
2025-11-29 12:00:50,055:INFO:Preloading libraries
2025-11-29 12:00:50,055:INFO:Set up data.
2025-11-29 12:00:50,058:INFO:Set up index.
2025-11-29 12:04:17,178:INFO:Initializing predict_model()
2025-11-29 12:04:17,179:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017F198DB1F0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Age', 'SystolicBP',
                                             'TotalCholesterol', 'LDL',
                                             'Triglycerides', 'HbA1c',
                                             'Glucose', 'UricAcid',
                                             'Creatinine', 'BMI',
                                             'WaistCircumference', 'Height',
                                             'IncomeRatio', 'ALT_Enzyme',
                                             'AST_Enzyme', 'GGT_Enzyme',
                                             'Albumin', 'Potassium', 'Sodium'],
                                    transformer=SimpleImputer())),
                ('c...
                               feature_types=None, feature_weights=None,
                               gamma=None, grow_policy=None,
                               importance_type=None,
                               interaction_constraints=None,
                               learning_rate=0.0005, max_bin=None,
                               max_cat_threshold=None, max_cat_to_onehot=None,
                               max_delta_step=None, max_depth=10,
                               max_leaves=None, min_child_weight=1, missing=nan,
                               monotone_constraints=None, multi_strategy=None,
                               n_estimators=300, n_jobs=-1,
                               num_parallel_tree=None, ...))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000017F1D1B6560>)
2025-11-29 12:04:17,179:INFO:Checking exceptions
2025-11-29 12:04:17,179:INFO:Preloading libraries
2025-11-29 12:04:17,179:INFO:Set up data.
2025-11-29 12:04:17,183:INFO:Set up index.
2025-11-29 12:04:44,535:INFO:Initializing predict_model()
2025-11-29 12:04:44,535:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017F1991A7A0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Age', 'SystolicBP',
                                             'TotalCholesterol', 'LDL',
                                             'Triglycerides', 'HbA1c',
                                             'Glucose', 'UricAcid',
                                             'Creatinine', 'BMI',
                                             'WaistCircumference', 'Height',
                                             'IncomeRatio', 'ALT_Enzyme',
                                             'AST_Enzyme', 'GGT_Enzyme',
                                             'Albumin', 'Potassium', 'Sodium'],
                                    transformer=SimpleImputer())),
                ('c...
                               feature_types=None, feature_weights=None,
                               gamma=None, grow_policy=None,
                               importance_type=None,
                               interaction_constraints=None,
                               learning_rate=0.0005, max_bin=None,
                               max_cat_threshold=None, max_cat_to_onehot=None,
                               max_delta_step=None, max_depth=10,
                               max_leaves=None, min_child_weight=1, missing=nan,
                               monotone_constraints=None, multi_strategy=None,
                               n_estimators=300, n_jobs=-1,
                               num_parallel_tree=None, ...))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000017F1B370A60>)
2025-11-29 12:04:44,535:INFO:Checking exceptions
2025-11-29 12:04:44,535:INFO:Preloading libraries
2025-11-29 12:04:44,535:INFO:Set up data.
2025-11-29 12:04:44,538:INFO:Set up index.
2025-11-29 12:31:07,015:INFO:Initializing load_model()
2025-11-29 12:31:07,020:INFO:load_model(model_name=../models/best_pipeline, platform=None, authentication=None, verbose=True)
2025-11-29 12:31:12,746:INFO:Initializing predict_model()
2025-11-29 12:31:12,746:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017F199197B0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Age', 'SystolicBP',
                                             'TotalCholesterol', 'LDL',
                                             'Triglycerides', 'HbA1c',
                                             'Glucose', 'UricAcid',
                                             'Creatinine', 'BMI',
                                             'WaistCircumference', 'Height',
                                             'IncomeRatio', 'ALT_Enzyme',
                                             'AST_Enzyme', 'GGT_Enzyme',
                                             'Albumin', 'Potassium', 'Sodium'],
                                    transformer=SimpleImputer())),
                ('c...
                               feature_types=None, feature_weights=None,
                               gamma=None, grow_policy=None,
                               importance_type=None,
                               interaction_constraints=None,
                               learning_rate=0.0005, max_bin=None,
                               max_cat_threshold=None, max_cat_to_onehot=None,
                               max_delta_step=None, max_depth=10,
                               max_leaves=None, min_child_weight=1, missing=nan,
                               monotone_constraints=None, multi_strategy=None,
                               n_estimators=300, n_jobs=-1,
                               num_parallel_tree=None, ...))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000017F1B370E50>)
2025-11-29 12:31:12,746:INFO:Checking exceptions
2025-11-29 12:31:12,746:INFO:Preloading libraries
2025-11-29 12:31:12,748:INFO:Set up data.
2025-11-29 12:31:12,757:INFO:Set up index.
2025-11-29 12:31:43,603:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-11-29 12:31:43,603:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-11-29 12:31:43,603:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-11-29 12:31:43,603:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-11-29 12:31:47,347:INFO:Initializing load_model()
2025-11-29 12:31:47,347:INFO:load_model(model_name=../models/best_pipeline, platform=None, authentication=None, verbose=True)
2025-11-29 12:31:47,433:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-29 12:31:54,176:INFO:Initializing predict_model()
2025-11-29 12:31:54,177:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000015B4E3BB370>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Age', 'SystolicBP',
                                             'TotalCholesterol', 'LDL',
                                             'Triglycerides', 'HbA1c',
                                             'Glucose', 'UricAcid',
                                             'Creatinine', 'BMI',
                                             'WaistCircumference', 'Height',
                                             'IncomeRatio', 'ALT_Enzyme',
                                             'AST_Enzyme', 'GGT_Enzyme',
                                             'Albumin', 'Potassium', 'Sodium'],
                                    transformer=SimpleImputer())),
                ('c...
                               feature_types=None, feature_weights=None,
                               gamma=None, grow_policy=None,
                               importance_type=None,
                               interaction_constraints=None,
                               learning_rate=0.0005, max_bin=None,
                               max_cat_threshold=None, max_cat_to_onehot=None,
                               max_delta_step=None, max_depth=10,
                               max_leaves=None, min_child_weight=1, missing=nan,
                               monotone_constraints=None, multi_strategy=None,
                               n_estimators=300, n_jobs=-1,
                               num_parallel_tree=None, ...))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000015B4F759900>)
2025-11-29 12:31:54,177:INFO:Checking exceptions
2025-11-29 12:31:54,177:INFO:Preloading libraries
2025-11-29 12:31:54,177:INFO:Set up data.
2025-11-29 12:31:54,181:INFO:Set up index.
2025-11-29 12:38:30,568:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-11-29 12:38:30,569:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-11-29 12:38:30,569:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-11-29 12:38:30,569:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-11-29 13:55:29,461:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-11-29 13:55:29,461:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-11-29 13:55:29,461:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-11-29 13:55:29,461:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-11-29 13:55:32,238:INFO:Initializing load_model()
2025-11-29 13:55:32,239:INFO:load_model(model_name=../models/best_pipeline, platform=None, authentication=None, verbose=True)
2025-11-29 13:55:32,321:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-29 13:55:36,208:INFO:Initializing predict_model()
2025-11-29 13:55:36,208:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A8E62365C0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Age', 'SystolicBP',
                                             'TotalCholesterol', 'LDL',
                                             'Triglycerides', 'HbA1c',
                                             'Glucose', 'UricAcid',
                                             'Creatinine', 'BMI',
                                             'WaistCircumference', 'Height',
                                             'IncomeRatio', 'ALT_Enzyme',
                                             'AST_Enzyme', 'GGT_Enzyme',
                                             'Albumin', 'Potassium', 'Sodium'],
                                    transformer=SimpleImputer())),
                ('c...
                               feature_types=None, feature_weights=None,
                               gamma=None, grow_policy=None,
                               importance_type=None,
                               interaction_constraints=None,
                               learning_rate=0.0005, max_bin=None,
                               max_cat_threshold=None, max_cat_to_onehot=None,
                               max_delta_step=None, max_depth=10,
                               max_leaves=None, min_child_weight=1, missing=nan,
                               monotone_constraints=None, multi_strategy=None,
                               n_estimators=300, n_jobs=-1,
                               num_parallel_tree=None, ...))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002A8E609A560>)
2025-11-29 13:55:36,208:INFO:Checking exceptions
2025-11-29 13:55:36,208:INFO:Preloading libraries
2025-11-29 13:55:36,208:INFO:Set up data.
2025-11-29 13:55:36,222:INFO:Set up index.
2025-11-29 13:55:45,988:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-11-29 13:55:45,991:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-11-29 13:55:45,992:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-11-30 01:49:46,864:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-11-30 01:49:46,865:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-11-30 01:49:46,865:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-11-30 01:49:46,865:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-11-30 01:49:47,369:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2025-11-30 01:51:01,117:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-11-30 01:51:01,118:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-11-30 01:51:01,118:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-11-30 01:51:01,118:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-11-30 01:51:01,991:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2025-11-30 01:51:02,569:INFO:PyCaret ClassificationExperiment
2025-11-30 01:51:02,570:INFO:Logging name: clf-default-name
2025-11-30 01:51:02,570:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-11-30 01:51:02,570:INFO:version 3.0.3
2025-11-30 01:51:02,570:INFO:Initializing setup()
2025-11-30 01:51:02,570:INFO:self.USI: d751
2025-11-30 01:51:02,570:INFO:self._variable_keys: {'target_param', 'X_train', 'y', 'seed', 'X_test', 'pipeline', '_ml_usecase', 'gpu_param', 'y_train', 'exp_id', 'logging_param', 'USI', 'exp_name_log', '_available_plots', 'n_jobs_param', 'data', 'y_test', 'fold_shuffle_param', 'X', 'is_multiclass', 'html_param', 'memory', 'fold_generator', 'fold_groups_param', 'idx', 'fix_imbalance', 'gpu_n_jobs_param', 'log_plots_param'}
2025-11-30 01:51:02,570:INFO:Checking environment
2025-11-30 01:51:02,570:INFO:python_version: 3.10.19
2025-11-30 01:51:02,570:INFO:python_build: ('main', 'Nov  7 2025 00:05:37')
2025-11-30 01:51:02,570:INFO:machine: x86_64
2025-11-30 01:51:02,570:INFO:platform: Linux-6.8.0-x86_64-with-glibc2.39
2025-11-30 01:51:02,571:INFO:Memory: svmem(total=8345706496, available=7554994176, percent=9.5, used=790712320, free=3790553088, active=281694208, inactive=3908857856, buffers=71065600, cached=4005851136, shared=557056, slab=293490688)
2025-11-30 01:51:02,573:INFO:Physical Core: 4
2025-11-30 01:51:02,573:INFO:Logical Core: 4
2025-11-30 01:51:02,573:INFO:Checking libraries
2025-11-30 01:51:02,573:INFO:System:
2025-11-30 01:51:02,573:INFO:    python: 3.10.19 (main, Nov  7 2025, 00:05:37) [GCC 13.3.0]
2025-11-30 01:51:02,573:INFO:executable: /home/jules/.pyenv/versions/3.10.19/bin/python
2025-11-30 01:51:02,574:INFO:   machine: Linux-6.8.0-x86_64-with-glibc2.39
2025-11-30 01:51:02,574:INFO:PyCaret required dependencies:
2025-11-30 01:51:02,581:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-30 01:51:02,691:INFO:                 pip: 25.3
2025-11-30 01:51:02,691:INFO:          setuptools: 79.0.1
2025-11-30 01:51:02,692:INFO:             pycaret: 3.0.3
2025-11-30 01:51:02,692:INFO:             IPython: 8.37.0
2025-11-30 01:51:02,692:INFO:          ipywidgets: 8.1.8
2025-11-30 01:51:02,692:INFO:                tqdm: 4.67.1
2025-11-30 01:51:02,692:INFO:               numpy: 1.23.5
2025-11-30 01:51:02,692:INFO:              pandas: 1.5.3
2025-11-30 01:51:02,692:INFO:              jinja2: 3.1.6
2025-11-30 01:51:02,692:INFO:               scipy: 1.10.1
2025-11-30 01:51:02,692:INFO:              joblib: 1.2.0
2025-11-30 01:51:02,692:INFO:             sklearn: 1.3.2
2025-11-30 01:51:02,692:INFO:                pyod: 2.0.5
2025-11-30 01:51:02,692:INFO:            imblearn: 0.12.4
2025-11-30 01:51:02,692:INFO:   category_encoders: 2.7.0
2025-11-30 01:51:02,692:INFO:            lightgbm: 4.6.0
2025-11-30 01:51:02,692:INFO:               numba: 0.59.0
2025-11-30 01:51:02,692:INFO:            requests: 2.32.5
2025-11-30 01:51:02,692:INFO:          matplotlib: 3.10.7
2025-11-30 01:51:02,692:INFO:          scikitplot: 0.3.7
2025-11-30 01:51:02,692:INFO:         yellowbrick: 1.5
2025-11-30 01:51:02,692:INFO:              plotly: 6.5.0
2025-11-30 01:51:02,692:INFO:    plotly-resampler: Not installed
2025-11-30 01:51:02,692:INFO:             kaleido: 1.2.0
2025-11-30 01:51:02,692:INFO:           schemdraw: 0.15
2025-11-30 01:51:02,692:INFO:         statsmodels: 0.14.5
2025-11-30 01:51:02,692:INFO:              sktime: 0.40.1
2025-11-30 01:51:02,692:INFO:               tbats: 1.1.3
2025-11-30 01:51:02,693:INFO:            pmdarima: 2.1.1
2025-11-30 01:51:02,693:INFO:              psutil: 7.1.3
2025-11-30 01:51:02,693:INFO:          markupsafe: 3.0.3
2025-11-30 01:51:02,693:INFO:             pickle5: Not installed
2025-11-30 01:51:02,693:INFO:         cloudpickle: 3.1.2
2025-11-30 01:51:02,693:INFO:         deprecation: 2.1.0
2025-11-30 01:51:02,693:INFO:              xxhash: 3.6.0
2025-11-30 01:51:02,693:INFO:           wurlitzer: 3.1.1
2025-11-30 01:51:02,693:INFO:PyCaret optional dependencies:
2025-11-30 01:51:03,576:INFO:                shap: 0.48.0
2025-11-30 01:51:03,576:INFO:           interpret: Not installed
2025-11-30 01:51:03,576:INFO:                umap: Not installed
2025-11-30 01:51:03,576:INFO:    pandas_profiling: Not installed
2025-11-30 01:51:03,576:INFO:  explainerdashboard: Not installed
2025-11-30 01:51:03,576:INFO:             autoviz: Not installed
2025-11-30 01:51:03,576:INFO:           fairlearn: 0.9.0
2025-11-30 01:51:03,576:INFO:          deepchecks: Not installed
2025-11-30 01:51:03,577:INFO:             xgboost: 3.1.2
2025-11-30 01:51:03,577:INFO:            catboost: Not installed
2025-11-30 01:51:03,577:INFO:              kmodes: Not installed
2025-11-30 01:51:03,577:INFO:             mlxtend: Not installed
2025-11-30 01:51:03,577:INFO:       statsforecast: Not installed
2025-11-30 01:51:03,577:INFO:        tune_sklearn: Not installed
2025-11-30 01:51:03,577:INFO:                 ray: Not installed
2025-11-30 01:51:03,577:INFO:            hyperopt: Not installed
2025-11-30 01:51:03,577:INFO:              optuna: Not installed
2025-11-30 01:51:03,577:INFO:               skopt: Not installed
2025-11-30 01:51:03,577:INFO:              mlflow: Not installed
2025-11-30 01:51:03,577:INFO:              gradio: Not installed
2025-11-30 01:51:03,577:INFO:             fastapi: 0.122.0
2025-11-30 01:51:03,577:INFO:             uvicorn: 0.38.0
2025-11-30 01:51:03,577:INFO:              m2cgen: Not installed
2025-11-30 01:51:03,577:INFO:           evidently: Not installed
2025-11-30 01:51:03,577:INFO:               fugue: Not installed
2025-11-30 01:51:03,577:INFO:           streamlit: 1.50.0
2025-11-30 01:51:03,577:INFO:             prophet: Not installed
2025-11-30 01:51:03,577:INFO:None
2025-11-30 01:51:03,577:INFO:Set up data.
2025-11-30 01:51:03,597:INFO:Set up train/test split.
2025-11-30 01:51:03,604:INFO:Set up index.
2025-11-30 01:51:03,604:INFO:Set up folding strategy.
2025-11-30 01:51:03,604:INFO:Assigning column types.
2025-11-30 01:51:03,608:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-11-30 01:51:03,683:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-11-30 01:51:03,688:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-11-30 01:51:03,738:INFO:Soft dependency imported: xgboost: 3.1.2
2025-11-30 01:51:03,743:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-30 01:51:03,814:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-11-30 01:51:03,815:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-11-30 01:51:03,854:INFO:Soft dependency imported: xgboost: 3.1.2
2025-11-30 01:51:03,858:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-30 01:51:03,859:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-11-30 01:51:03,931:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-11-30 01:51:03,970:INFO:Soft dependency imported: xgboost: 3.1.2
2025-11-30 01:51:03,974:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-30 01:51:04,045:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-11-30 01:51:04,084:INFO:Soft dependency imported: xgboost: 3.1.2
2025-11-30 01:51:04,088:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-30 01:51:04,088:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-11-30 01:51:04,199:INFO:Soft dependency imported: xgboost: 3.1.2
2025-11-30 01:51:04,202:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-30 01:51:04,313:INFO:Soft dependency imported: xgboost: 3.1.2
2025-11-30 01:51:04,317:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-30 01:51:04,320:INFO:Preparing preprocessing pipeline...
2025-11-30 01:51:04,321:INFO:Set up simple imputation.
2025-11-30 01:51:04,327:INFO:Set up encoding of ordinal features.
2025-11-30 01:51:04,336:INFO:Set up encoding of categorical features.
2025-11-30 01:51:04,336:INFO:Set up removing outliers.
2025-11-30 01:51:04,336:INFO:Set up imbalanced handling.
2025-11-30 01:51:04,336:INFO:Set up feature normalization.
2025-11-30 01:51:04,950:INFO:Finished creating preprocessing pipeline.
2025-11-30 01:51:05,085:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'SystolicBP',
                                             'TotalCholesterol', 'LDL',
                                             'Triglycerides', 'HbA1c',
                                             'Glucose', 'UricAcid',
                                             'Creatinine', 'BMI',
                                             'WaistCircumference', 'Height',
                                             'IncomeRatio', 'ALT_Enzyme',
                                             'AST_Enzyme', 'GGT_Enzyme',
                                             'Albumin', 'Potassium', 'Sodium'],
                                    transform...
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              n_jobs=None,
                                                                              random_state=None,
                                                                              sampling_strategy='auto')))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=RobustScaler(copy=True,
                                                             quantile_range=(25.0,
                                                                             75.0),
                                                             unit_variance=False,
                                                             with_centering=True,
                                                             with_scaling=True)))],
         verbose=False)
2025-11-30 01:51:05,085:INFO:Creating final display dataframe.
2025-11-30 01:51:06,384:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target      HeartDisease
2                   Target type            Binary
3           Original data shape         (437, 27)
4        Transformed data shape         (696, 35)
5   Transformed train set shape         (564, 35)
6    Transformed test set shape         (132, 35)
7              Ordinal features                 5
8              Numeric features                19
9          Categorical features                 7
10     Rows with missing values             88.6%
11                   Preprocess              True
12              Imputation type            simple
13           Numeric imputation              mean
14       Categorical imputation              mode
15     Maximum one-hot encoding                25
16              Encoding method              None
17              Remove outliers              True
18           Outliers threshold              0.05
19                Fix imbalance              True
20         Fix imbalance method             SMOTE
21                    Normalize              True
22             Normalize method            robust
23               Fold Generator   StratifiedKFold
24                  Fold Number                10
25                     CPU Jobs                -1
26                      Use GPU             False
27               Log Experiment             False
28              Experiment Name  clf-default-name
29                          USI              d751
2025-11-30 01:51:06,504:INFO:Soft dependency imported: xgboost: 3.1.2
2025-11-30 01:51:06,508:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-30 01:51:06,614:INFO:Soft dependency imported: xgboost: 3.1.2
2025-11-30 01:51:06,618:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-30 01:51:06,620:INFO:setup() successfully completed in 4.05s...............
2025-11-30 01:51:06,654:INFO:Initializing compare_models()
2025-11-30 01:51:06,654:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fc53b4f3580>, include=['xgboost', 'lightgbm'], fold=None, round=4, cross_validation=True, sort=Recall, n_select=3, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=False, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x7fc53b4f3580>, 'include': ['xgboost', 'lightgbm'], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Recall', 'n_select': 3, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': False, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2025-11-30 01:51:06,654:INFO:Checking exceptions
2025-11-30 01:51:06,661:INFO:Preparing display monitor
2025-11-30 01:51:06,666:INFO:Initializing Extreme Gradient Boosting
2025-11-30 01:51:06,666:INFO:Total runtime is 2.658367156982422e-06 minutes
2025-11-30 01:51:06,666:INFO:SubProcess create_model() called ==================================
2025-11-30 01:51:06,667:INFO:Initializing create_model()
2025-11-30 01:51:06,667:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fc53b4f3580>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc53b1fb2e0>, model_only=True, return_train_score=False, kwargs={})
2025-11-30 01:51:06,667:INFO:Checking exceptions
2025-11-30 01:51:06,667:INFO:Importing libraries
2025-11-30 01:51:06,667:INFO:Copying training dataset
2025-11-30 01:51:06,673:INFO:Defining folds
2025-11-30 01:51:06,673:INFO:Declaring metric variables
2025-11-30 01:51:06,673:INFO:Importing untrained model
2025-11-30 01:51:06,674:INFO:Extreme Gradient Boosting Imported successfully
2025-11-30 01:51:06,675:INFO:Starting cross validation
2025-11-30 01:51:06,705:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-30 01:51:06,750:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 7 members, which is less than n_splits=10.
  warnings.warn(

2025-11-30 01:51:11,019:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-30 01:51:11,039:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-30 01:51:11,059:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-30 01:51:11,397:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-30 01:51:12,752:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-11-30 01:51:13,792:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 401, in _score
    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 214, in wrapper
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 627, in roc_auc_score
    return _average_binary_score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-11-30 01:51:13,795:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-11-30 01:51:13,798:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-11-30 01:51:13,801:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1760: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2025-11-30 01:51:13,803:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:697: RuntimeWarning: invalid value encountered in double_scalars
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-30 01:51:13,837:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 401, in _score
    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 214, in wrapper
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 627, in roc_auc_score
    return _average_binary_score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-11-30 01:51:13,843:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-11-30 01:51:13,901:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 401, in _score
    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 214, in wrapper
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 627, in roc_auc_score
    return _average_binary_score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-11-30 01:51:13,907:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-11-30 01:51:14,115:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-11-30 01:51:14,299:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:425: FitFailedWarning:
3 fits failed out of a total of 10.
The score on these train-test partitions for these parameters will be set to 0.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
3 fits failed with the following error:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/model_selection/_validation.py", line 729, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 255, in fit
    X, y, _ = self._fit(X, y, **fit_params_steps)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 238, in _fit
    X, y = self._memory_transform(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/joblib/memory.py", line 594, in __call__
    return self._cached_call(args, kwargs)[0]
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/memory.py", line 398, in _cached_call
    out, metadata = self.call(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/memory.py", line 309, in call
    output = self.func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 77, in _transform_one
    output = transformer.transform(*args)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 157, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 259, in transform
    output = self.transformer.transform(*args)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 157, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 546, in transform
    X, y = self.estimator.fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/base.py", line 208, in fit_resample
    return super().fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/base.py", line 112, in fit_resample
    output = self._fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/over_sampling/_smote/base.py", line 389, in _fit_resample
    nns = self.nn_k_.kneighbors(X_class, return_distance=False)[:, 1:]
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/neighbors/_base.py", line 808, in kneighbors
    raise ValueError(
ValueError: Expected n_neighbors <= n_samples,  but n_samples = 5, n_neighbors = 6

  warnings.warn(some_fits_failed_message, FitFailedWarning)

2025-11-30 01:51:14,301:INFO:Calculating mean and std
2025-11-30 01:51:14,302:INFO:Creating metrics dataframe
2025-11-30 01:51:14,313:INFO:Uploading results into container
2025-11-30 01:51:14,315:INFO:Uploading model into container now
2025-11-30 01:51:14,315:INFO:_master_model_container: 1
2025-11-30 01:51:14,315:INFO:_display_container: 2
2025-11-30 01:51:14,317:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              feature_weights=None, gamma=None, grow_policy=None,
              importance_type=None, interaction_constraints=None,
              learning_rate=None, max_bin=None, max_cat_threshold=None,
              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,
              max_leaves=None, min_child_weight=None, missing=nan,
              monotone_constraints=None, multi_strategy=None, n_estimators=None,
              n_jobs=-1, num_parallel_tree=None, ...)
2025-11-30 01:51:14,317:INFO:create_model() successfully completed......................................
2025-11-30 01:51:14,504:INFO:SubProcess create_model() end ==================================
2025-11-30 01:51:14,505:INFO:Creating metrics dataframe
2025-11-30 01:51:14,512:INFO:Initializing Light Gradient Boosting Machine
2025-11-30 01:51:14,513:INFO:Total runtime is 0.13078117767969769 minutes
2025-11-30 01:51:14,513:INFO:SubProcess create_model() called ==================================
2025-11-30 01:51:14,513:INFO:Initializing create_model()
2025-11-30 01:51:14,513:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fc53b4f3580>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc53b1fb2e0>, model_only=True, return_train_score=False, kwargs={})
2025-11-30 01:51:14,514:INFO:Checking exceptions
2025-11-30 01:51:14,514:INFO:Importing libraries
2025-11-30 01:51:14,514:INFO:Copying training dataset
2025-11-30 01:51:14,519:INFO:Defining folds
2025-11-30 01:51:14,519:INFO:Declaring metric variables
2025-11-30 01:51:14,520:INFO:Importing untrained model
2025-11-30 01:51:14,520:INFO:Light Gradient Boosting Machine Imported successfully
2025-11-30 01:51:14,521:INFO:Starting cross validation
2025-11-30 01:51:14,545:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-30 01:51:14,550:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 7 members, which is less than n_splits=10.
  warnings.warn(

2025-11-30 01:52:08,921:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.70s to run.
If this happens often in your code, it can cause performance problems
(results will be correct in all cases).
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2025-11-30 01:53:00,189:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.71s to run.
If this happens often in your code, it can cause performance problems
(results will be correct in all cases).
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2025-11-30 01:53:00,351:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 401, in _score
    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 214, in wrapper
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 627, in roc_auc_score
    return _average_binary_score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-11-30 01:53:00,354:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-11-30 01:53:00,374:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-11-30 01:53:00,377:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1760: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2025-11-30 01:53:00,387:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:697: RuntimeWarning: invalid value encountered in double_scalars
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-30 01:53:12,301:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.74s to run.
If this happens often in your code, it can cause performance problems
(results will be correct in all cases).
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2025-11-30 01:54:22,153:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.80s to run.
If this happens often in your code, it can cause performance problems
(results will be correct in all cases).
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2025-11-30 01:54:28,976:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 401, in _score
    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 214, in wrapper
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 627, in roc_auc_score
    return _average_binary_score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-11-30 01:54:28,982:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-11-30 01:54:28,985:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-11-30 01:54:28,988:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1760: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2025-11-30 01:54:28,990:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:697: RuntimeWarning: invalid value encountered in double_scalars
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-30 01:55:18,956:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 401, in _score
    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 214, in wrapper
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 627, in roc_auc_score
    return _average_binary_score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-11-30 01:55:18,959:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-11-30 01:55:18,962:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-11-30 01:55:18,965:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1760: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2025-11-30 01:55:18,967:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:697: RuntimeWarning: invalid value encountered in double_scalars
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-30 01:55:18,997:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-11-30 01:55:19,005:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:425: FitFailedWarning:
3 fits failed out of a total of 10.
The score on these train-test partitions for these parameters will be set to 0.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
3 fits failed with the following error:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/model_selection/_validation.py", line 729, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 255, in fit
    X, y, _ = self._fit(X, y, **fit_params_steps)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 238, in _fit
    X, y = self._memory_transform(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/joblib/memory.py", line 594, in __call__
    return self._cached_call(args, kwargs)[0]
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/memory.py", line 398, in _cached_call
    out, metadata = self.call(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/memory.py", line 309, in call
    output = self.func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 77, in _transform_one
    output = transformer.transform(*args)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 157, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 259, in transform
    output = self.transformer.transform(*args)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 157, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 546, in transform
    X, y = self.estimator.fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/base.py", line 208, in fit_resample
    return super().fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/base.py", line 112, in fit_resample
    output = self._fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/over_sampling/_smote/base.py", line 389, in _fit_resample
    nns = self.nn_k_.kneighbors(X_class, return_distance=False)[:, 1:]
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/neighbors/_base.py", line 808, in kneighbors
    raise ValueError(
ValueError: Expected n_neighbors <= n_samples,  but n_samples = 5, n_neighbors = 6

  warnings.warn(some_fits_failed_message, FitFailedWarning)

2025-11-30 01:55:19,007:INFO:Calculating mean and std
2025-11-30 01:55:19,007:INFO:Creating metrics dataframe
2025-11-30 01:55:19,020:INFO:Uploading results into container
2025-11-30 01:55:19,021:INFO:Uploading model into container now
2025-11-30 01:55:19,021:INFO:_master_model_container: 2
2025-11-30 01:55:19,021:INFO:_display_container: 2
2025-11-30 01:55:19,022:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-11-30 01:55:19,022:INFO:create_model() successfully completed......................................
2025-11-30 01:55:19,168:INFO:SubProcess create_model() end ==================================
2025-11-30 01:55:19,168:INFO:Creating metrics dataframe
2025-11-30 01:55:19,179:INFO:Initializing create_model()
2025-11-30 01:55:19,179:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fc53b4f3580>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              feature_weights=None, gamma=None, grow_policy=None,
              importance_type=None, interaction_constraints=None,
              learning_rate=None, max_bin=None, max_cat_threshold=None,
              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,
              max_leaves=None, min_child_weight=None, missing=nan,
              monotone_constraints=None, multi_strategy=None, n_estimators=None,
              n_jobs=-1, num_parallel_tree=None, ...), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2025-11-30 01:55:19,179:INFO:Checking exceptions
2025-11-30 01:55:19,182:INFO:Importing libraries
2025-11-30 01:55:19,182:INFO:Copying training dataset
2025-11-30 01:55:19,186:INFO:Defining folds
2025-11-30 01:55:19,187:INFO:Declaring metric variables
2025-11-30 01:55:19,187:INFO:Importing untrained model
2025-11-30 01:55:19,187:INFO:Declaring custom model
2025-11-30 01:55:19,189:INFO:Extreme Gradient Boosting Imported successfully
2025-11-30 01:55:19,202:INFO:Cross validation set to False
2025-11-30 01:55:19,202:INFO:Fitting Model
2025-11-30 01:55:19,587:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              feature_weights=None, gamma=None, grow_policy=None,
              importance_type=None, interaction_constraints=None,
              learning_rate=None, max_bin=None, max_cat_threshold=None,
              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,
              max_leaves=None, min_child_weight=None, missing=nan,
              monotone_constraints=None, multi_strategy=None, n_estimators=None,
              n_jobs=-1, num_parallel_tree=None, ...)
2025-11-30 01:55:19,587:INFO:create_model() successfully completed......................................
2025-11-30 01:55:19,723:INFO:Initializing create_model()
2025-11-30 01:55:19,723:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fc53b4f3580>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2025-11-30 01:55:19,723:INFO:Checking exceptions
2025-11-30 01:55:19,726:INFO:Importing libraries
2025-11-30 01:55:19,726:INFO:Copying training dataset
2025-11-30 01:55:19,730:INFO:Defining folds
2025-11-30 01:55:19,730:INFO:Declaring metric variables
2025-11-30 01:55:19,730:INFO:Importing untrained model
2025-11-30 01:55:19,730:INFO:Declaring custom model
2025-11-30 01:55:19,732:INFO:Light Gradient Boosting Machine Imported successfully
2025-11-30 01:55:19,745:INFO:Cross validation set to False
2025-11-30 01:55:19,745:INFO:Fitting Model
2025-11-30 01:55:19,953:INFO:[LightGBM] [Info] Number of positive: 282, number of negative: 282
2025-11-30 01:55:19,954:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000364 seconds.
2025-11-30 01:55:19,954:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-11-30 01:55:19,956:INFO:[LightGBM] [Info] Total Bins 3055
2025-11-30 01:55:19,960:INFO:[LightGBM] [Info] Number of data points in the train set: 564, number of used features: 33
2025-11-30 01:55:19,961:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-11-30 01:55:19,961:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-30 01:55:19,962:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-30 01:55:19,962:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-30 01:55:19,963:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-30 01:55:19,964:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-30 01:55:19,965:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-30 01:55:19,966:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-30 01:55:19,966:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-30 01:55:19,967:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-30 01:55:19,968:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-30 01:55:19,969:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-30 01:55:19,969:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-30 01:55:19,970:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-30 01:55:19,971:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-30 01:55:19,972:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-30 01:55:19,973:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-30 01:55:19,974:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-30 01:55:19,974:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-30 01:55:19,975:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-30 01:55:19,976:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-30 01:55:19,977:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-30 01:55:19,978:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-30 01:55:19,979:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-30 01:55:19,979:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-30 01:55:19,980:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-30 01:55:19,981:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-30 01:55:19,982:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-30 01:55:19,983:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-30 01:55:19,984:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-30 01:55:19,984:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-30 01:55:19,985:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-30 01:55:19,986:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-30 01:55:19,987:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-30 01:55:19,988:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-30 01:55:19,989:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-30 01:55:19,990:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-30 01:55:19,991:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-30 01:55:19,991:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-30 01:55:19,992:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-30 01:55:19,993:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-30 01:55:19,994:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-30 01:55:19,995:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-30 01:55:19,996:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-30 01:55:19,997:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-30 01:55:19,998:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-30 01:55:19,999:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-30 01:55:20,000:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-30 01:55:20,001:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-30 01:55:20,001:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-30 01:55:20,002:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-30 01:55:20,003:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-30 01:55:20,004:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-30 01:55:20,005:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-30 01:55:20,006:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-30 01:55:20,007:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-30 01:55:20,008:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-30 01:55:20,009:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-30 01:55:20,010:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-30 01:55:20,011:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-30 01:55:20,012:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-30 01:55:20,013:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-30 01:55:20,013:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-30 01:55:20,014:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-30 01:55:20,015:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-30 01:55:20,016:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-30 01:55:20,017:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-30 01:55:20,018:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-30 01:55:20,019:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-30 01:55:20,020:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-30 01:55:20,021:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-30 01:55:20,023:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-30 01:55:20,024:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-30 01:55:20,025:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-30 01:55:20,026:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-30 01:55:20,027:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-30 01:55:20,028:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-30 01:55:20,030:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-30 01:55:20,031:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-30 01:55:20,032:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-30 01:55:20,033:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-30 01:55:20,034:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-30 01:55:20,035:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-30 01:55:20,036:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-30 01:55:20,037:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-30 01:55:20,038:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-30 01:55:20,039:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-30 01:55:20,040:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-30 01:55:20,041:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-30 01:55:20,042:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-30 01:55:20,043:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-30 01:55:20,044:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-30 01:55:20,045:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-30 01:55:20,046:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-30 01:55:20,047:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-30 01:55:20,047:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-30 01:55:20,048:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-30 01:55:20,049:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-30 01:55:20,096:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-11-30 01:55:20,096:INFO:create_model() successfully completed......................................
2025-11-30 01:55:20,231:INFO:_master_model_container: 2
2025-11-30 01:55:20,231:INFO:_display_container: 2
2025-11-30 01:55:20,233:INFO:[XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              feature_weights=None, gamma=None, grow_policy=None,
              importance_type=None, interaction_constraints=None,
              learning_rate=None, max_bin=None, max_cat_threshold=None,
              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,
              max_leaves=None, min_child_weight=None, missing=nan,
              monotone_constraints=None, multi_strategy=None, n_estimators=None,
              n_jobs=-1, num_parallel_tree=None, ...), LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)]
2025-11-30 01:55:20,233:INFO:compare_models() successfully completed......................................
2025-11-30 01:55:20,275:INFO:Initializing tune_model()
2025-11-30 01:55:20,276:INFO:tune_model(estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              feature_weights=None, gamma=None, grow_policy=None,
              importance_type=None, interaction_constraints=None,
              learning_rate=None, max_bin=None, max_cat_threshold=None,
              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,
              max_leaves=None, min_child_weight=None, missing=nan,
              monotone_constraints=None, multi_strategy=None, n_estimators=None,
              n_jobs=-1, num_parallel_tree=None, ...), fold=None, round=4, n_iter=2, custom_grid=None, optimize=Recall, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=False, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fc53b4f3580>)
2025-11-30 01:55:20,276:INFO:Checking exceptions
2025-11-30 01:55:20,281:INFO:Copying training dataset
2025-11-30 01:55:20,285:INFO:Checking base model
2025-11-30 01:55:20,285:INFO:Base model : Extreme Gradient Boosting
2025-11-30 01:55:20,286:INFO:Declaring metric variables
2025-11-30 01:55:20,286:INFO:Defining Hyperparameters
2025-11-30 01:55:20,438:INFO:Tuning with n_jobs=-1
2025-11-30 01:55:20,438:INFO:Initializing RandomizedSearchCV
2025-11-30 01:55:20,448:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 7 members, which is less than n_splits=10.
  warnings.warn(

2025-11-30 01:55:21,169:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-11-30 01:55:21,180:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-11-30 01:55:21,204:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-11-30 01:55:21,730:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-11-30 01:55:21,739:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-11-30 01:55:22,065:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-11-30 01:55:22,084:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:425: FitFailedWarning:
6 fits failed out of a total of 20.
The score on these train-test partitions for these parameters will be set to nan.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
6 fits failed with the following error:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/model_selection/_validation.py", line 729, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 255, in fit
    X, y, _ = self._fit(X, y, **fit_params_steps)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 238, in _fit
    X, y = self._memory_transform(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/joblib/memory.py", line 594, in __call__
    return self._cached_call(args, kwargs)[0]
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/memory.py", line 398, in _cached_call
    out, metadata = self.call(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/memory.py", line 309, in call
    output = self.func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 77, in _transform_one
    output = transformer.transform(*args)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 157, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 259, in transform
    output = self.transformer.transform(*args)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 157, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 546, in transform
    X, y = self.estimator.fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/base.py", line 208, in fit_resample
    return super().fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/base.py", line 112, in fit_resample
    output = self._fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/over_sampling/_smote/base.py", line 389, in _fit_resample
    nns = self.nn_k_.kneighbors(X_class, return_distance=False)[:, 1:]
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/neighbors/_base.py", line 808, in kneighbors
    raise ValueError(
ValueError: Expected n_neighbors <= n_samples,  but n_samples = 5, n_neighbors = 6

  warnings.warn(some_fits_failed_message, FitFailedWarning)

2025-11-30 01:55:22,086:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/model_selection/_search.py:979: UserWarning: One or more of the test scores are non-finite: [nan nan]
  warnings.warn(

2025-11-30 01:55:22,097:INFO:best_params: {'actual_estimator__subsample': 1, 'actual_estimator__scale_pos_weight': 8.5, 'actual_estimator__reg_lambda': 0.0005, 'actual_estimator__reg_alpha': 0.001, 'actual_estimator__n_estimators': 10, 'actual_estimator__min_child_weight': 3, 'actual_estimator__max_depth': 8, 'actual_estimator__learning_rate': 0.0001, 'actual_estimator__colsample_bytree': 0.7}
2025-11-30 01:55:22,097:INFO:Hyperparameter search completed
2025-11-30 01:55:22,097:INFO:SubProcess create_model() called ==================================
2025-11-30 01:55:22,099:INFO:Initializing create_model()
2025-11-30 01:55:22,099:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fc53b4f3580>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              feature_weights=None, gamma=None, grow_policy=None,
              importance_type=None, interaction_constraints=None,
              learning_rate=None, max_bin=None, max_cat_threshold=None,
              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,
              max_leaves=None, min_child_weight=None, missing=nan,
              monotone_constraints=None, multi_strategy=None, n_estimators=None,
              n_jobs=-1, num_parallel_tree=None, ...), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc4f2406290>, model_only=True, return_train_score=False, kwargs={'subsample': 1, 'scale_pos_weight': 8.5, 'reg_lambda': 0.0005, 'reg_alpha': 0.001, 'n_estimators': 10, 'min_child_weight': 3, 'max_depth': 8, 'learning_rate': 0.0001, 'colsample_bytree': 0.7})
2025-11-30 01:55:22,099:INFO:Checking exceptions
2025-11-30 01:55:22,099:INFO:Importing libraries
2025-11-30 01:55:22,099:INFO:Copying training dataset
2025-11-30 01:55:22,105:INFO:Defining folds
2025-11-30 01:55:22,105:INFO:Declaring metric variables
2025-11-30 01:55:22,105:INFO:Importing untrained model
2025-11-30 01:55:22,106:INFO:Declaring custom model
2025-11-30 01:55:22,108:INFO:Extreme Gradient Boosting Imported successfully
2025-11-30 01:55:22,108:INFO:Starting cross validation
2025-11-30 01:55:22,128:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-30 01:55:22,133:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 7 members, which is less than n_splits=10.
  warnings.warn(

2025-11-30 01:55:22,954:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 401, in _score
    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 214, in wrapper
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 627, in roc_auc_score
    return _average_binary_score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-11-30 01:55:22,957:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-11-30 01:55:23,050:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 401, in _score
    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 214, in wrapper
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 627, in roc_auc_score
    return _average_binary_score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-11-30 01:55:23,053:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-11-30 01:55:23,055:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 401, in _score
    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 214, in wrapper
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 627, in roc_auc_score
    return _average_binary_score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-11-30 01:55:23,058:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-11-30 01:55:23,135:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:425: FitFailedWarning:
3 fits failed out of a total of 10.
The score on these train-test partitions for these parameters will be set to 0.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
3 fits failed with the following error:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/model_selection/_validation.py", line 729, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 255, in fit
    X, y, _ = self._fit(X, y, **fit_params_steps)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 238, in _fit
    X, y = self._memory_transform(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/joblib/memory.py", line 594, in __call__
    return self._cached_call(args, kwargs)[0]
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/memory.py", line 398, in _cached_call
    out, metadata = self.call(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/memory.py", line 309, in call
    output = self.func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 77, in _transform_one
    output = transformer.transform(*args)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 157, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 259, in transform
    output = self.transformer.transform(*args)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 157, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 546, in transform
    X, y = self.estimator.fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/base.py", line 208, in fit_resample
    return super().fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/base.py", line 112, in fit_resample
    output = self._fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/over_sampling/_smote/base.py", line 389, in _fit_resample
    nns = self.nn_k_.kneighbors(X_class, return_distance=False)[:, 1:]
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/neighbors/_base.py", line 808, in kneighbors
    raise ValueError(
ValueError: Expected n_neighbors <= n_samples,  but n_samples = 5, n_neighbors = 6

  warnings.warn(some_fits_failed_message, FitFailedWarning)

2025-11-30 01:55:23,138:INFO:Calculating mean and std
2025-11-30 01:55:23,139:INFO:Creating metrics dataframe
2025-11-30 01:55:23,142:INFO:Finalizing model
2025-11-30 01:55:23,388:INFO:Uploading results into container
2025-11-30 01:55:23,389:INFO:Uploading model into container now
2025-11-30 01:55:23,390:INFO:_master_model_container: 3
2025-11-30 01:55:23,390:INFO:_display_container: 3
2025-11-30 01:55:23,391:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=0.7, device=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              feature_weights=None, gamma=None, grow_policy=None,
              importance_type=None, interaction_constraints=None,
              learning_rate=0.0001, max_bin=None, max_cat_threshold=None,
              max_cat_to_onehot=None, max_delta_step=None, max_depth=8,
              max_leaves=None, min_child_weight=3, missing=nan,
              monotone_constraints=None, multi_strategy=None, n_estimators=10,
              n_jobs=-1, num_parallel_tree=None, ...)
2025-11-30 01:55:23,391:INFO:create_model() successfully completed......................................
2025-11-30 01:55:23,529:INFO:SubProcess create_model() end ==================================
2025-11-30 01:55:23,529:INFO:choose_better activated
2025-11-30 01:55:23,529:INFO:SubProcess create_model() called ==================================
2025-11-30 01:55:23,531:INFO:Initializing create_model()
2025-11-30 01:55:23,531:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fc53b4f3580>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              feature_weights=None, gamma=None, grow_policy=None,
              importance_type=None, interaction_constraints=None,
              learning_rate=None, max_bin=None, max_cat_threshold=None,
              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,
              max_leaves=None, min_child_weight=None, missing=nan,
              monotone_constraints=None, multi_strategy=None, n_estimators=None,
              n_jobs=-1, num_parallel_tree=None, ...), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2025-11-30 01:55:23,531:INFO:Checking exceptions
2025-11-30 01:55:23,534:INFO:Importing libraries
2025-11-30 01:55:23,534:INFO:Copying training dataset
2025-11-30 01:55:23,539:INFO:Defining folds
2025-11-30 01:55:23,539:INFO:Declaring metric variables
2025-11-30 01:55:23,539:INFO:Importing untrained model
2025-11-30 01:55:23,539:INFO:Declaring custom model
2025-11-30 01:55:23,541:INFO:Extreme Gradient Boosting Imported successfully
2025-11-30 01:55:23,541:INFO:Starting cross validation
2025-11-30 01:55:23,555:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-30 01:55:23,559:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 7 members, which is less than n_splits=10.
  warnings.warn(

2025-11-30 01:55:24,065:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-11-30 01:55:24,420:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 401, in _score
    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 214, in wrapper
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 627, in roc_auc_score
    return _average_binary_score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-11-30 01:55:24,423:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-11-30 01:55:24,426:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-11-30 01:55:24,429:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1760: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2025-11-30 01:55:24,430:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:697: RuntimeWarning: invalid value encountered in double_scalars
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-30 01:55:24,548:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 401, in _score
    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 214, in wrapper
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 627, in roc_auc_score
    return _average_binary_score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-11-30 01:55:24,551:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-11-30 01:55:24,563:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 401, in _score
    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 214, in wrapper
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 627, in roc_auc_score
    return _average_binary_score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-11-30 01:55:24,567:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-11-30 01:55:24,569:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-11-30 01:55:24,572:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1760: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2025-11-30 01:55:24,574:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:697: RuntimeWarning: invalid value encountered in double_scalars
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-30 01:55:24,772:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-11-30 01:55:24,781:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:425: FitFailedWarning:
3 fits failed out of a total of 10.
The score on these train-test partitions for these parameters will be set to 0.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
3 fits failed with the following error:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/model_selection/_validation.py", line 729, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 255, in fit
    X, y, _ = self._fit(X, y, **fit_params_steps)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 238, in _fit
    X, y = self._memory_transform(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/joblib/memory.py", line 594, in __call__
    return self._cached_call(args, kwargs)[0]
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/memory.py", line 398, in _cached_call
    out, metadata = self.call(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/memory.py", line 309, in call
    output = self.func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 77, in _transform_one
    output = transformer.transform(*args)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 157, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 259, in transform
    output = self.transformer.transform(*args)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 157, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 546, in transform
    X, y = self.estimator.fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/base.py", line 208, in fit_resample
    return super().fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/base.py", line 112, in fit_resample
    output = self._fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/over_sampling/_smote/base.py", line 389, in _fit_resample
    nns = self.nn_k_.kneighbors(X_class, return_distance=False)[:, 1:]
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/neighbors/_base.py", line 808, in kneighbors
    raise ValueError(
ValueError: Expected n_neighbors <= n_samples,  but n_samples = 5, n_neighbors = 6

  warnings.warn(some_fits_failed_message, FitFailedWarning)

2025-11-30 01:55:24,783:INFO:Calculating mean and std
2025-11-30 01:55:24,783:INFO:Creating metrics dataframe
2025-11-30 01:55:24,787:INFO:Finalizing model
2025-11-30 01:55:25,043:INFO:Uploading results into container
2025-11-30 01:55:25,043:INFO:Uploading model into container now
2025-11-30 01:55:25,044:INFO:_master_model_container: 4
2025-11-30 01:55:25,044:INFO:_display_container: 4
2025-11-30 01:55:25,045:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              feature_weights=None, gamma=None, grow_policy=None,
              importance_type=None, interaction_constraints=None,
              learning_rate=None, max_bin=None, max_cat_threshold=None,
              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,
              max_leaves=None, min_child_weight=None, missing=nan,
              monotone_constraints=None, multi_strategy=None, n_estimators=None,
              n_jobs=-1, num_parallel_tree=None, ...)
2025-11-30 01:55:25,045:INFO:create_model() successfully completed......................................
2025-11-30 01:55:25,179:INFO:SubProcess create_model() end ==================================
2025-11-30 01:55:25,181:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              feature_weights=None, gamma=None, grow_policy=None,
              importance_type=None, interaction_constraints=None,
              learning_rate=None, max_bin=None, max_cat_threshold=None,
              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,
              max_leaves=None, min_child_weight=None, missing=nan,
              monotone_constraints=None, multi_strategy=None, n_estimators=None,
              n_jobs=-1, num_parallel_tree=None, ...) result for Recall is 0.0
2025-11-30 01:55:25,182:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=0.7, device=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              feature_weights=None, gamma=None, grow_policy=None,
              importance_type=None, interaction_constraints=None,
              learning_rate=0.0001, max_bin=None, max_cat_threshold=None,
              max_cat_to_onehot=None, max_delta_step=None, max_depth=8,
              max_leaves=None, min_child_weight=3, missing=nan,
              monotone_constraints=None, multi_strategy=None, n_estimators=10,
              n_jobs=-1, num_parallel_tree=None, ...) result for Recall is 0.4
2025-11-30 01:55:25,183:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=0.7, device=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              feature_weights=None, gamma=None, grow_policy=None,
              importance_type=None, interaction_constraints=None,
              learning_rate=0.0001, max_bin=None, max_cat_threshold=None,
              max_cat_to_onehot=None, max_delta_step=None, max_depth=8,
              max_leaves=None, min_child_weight=3, missing=nan,
              monotone_constraints=None, multi_strategy=None, n_estimators=10,
              n_jobs=-1, num_parallel_tree=None, ...) is best model
2025-11-30 01:55:25,183:INFO:choose_better completed
2025-11-30 01:55:25,184:INFO:_master_model_container: 4
2025-11-30 01:55:25,184:INFO:_display_container: 3
2025-11-30 01:55:25,185:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=0.7, device=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              feature_weights=None, gamma=None, grow_policy=None,
              importance_type=None, interaction_constraints=None,
              learning_rate=0.0001, max_bin=None, max_cat_threshold=None,
              max_cat_to_onehot=None, max_delta_step=None, max_depth=8,
              max_leaves=None, min_child_weight=3, missing=nan,
              monotone_constraints=None, multi_strategy=None, n_estimators=10,
              n_jobs=-1, num_parallel_tree=None, ...)
2025-11-30 01:55:25,185:INFO:tune_model() successfully completed......................................
2025-11-30 01:55:25,365:INFO:Initializing predict_model()
2025-11-30 01:55:25,365:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fc53b4f3580>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=0.7, device=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              feature_weights=None, gamma=None, grow_policy=None,
              importance_type=None, interaction_constraints=None,
              learning_rate=0.0001, max_bin=None, max_cat_threshold=None,
              max_cat_to_onehot=None, max_delta_step=None, max_depth=8,
              max_leaves=None, min_child_weight=3, missing=nan,
              monotone_constraints=None, multi_strategy=None, n_estimators=10,
              n_jobs=-1, num_parallel_tree=None, ...), probability_threshold=None, encoded_labels=False, raw_score=True, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7fc541dcea70>)
2025-11-30 01:55:25,365:INFO:Checking exceptions
2025-11-30 01:55:25,365:INFO:Preloading libraries
2025-11-30 01:55:25,963:INFO:Initializing get_config()
2025-11-30 01:55:25,963:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fc53b4f3580>, variable=target_param)
2025-11-30 01:55:25,963:INFO:Variable:  returned as HeartDisease
2025-11-30 01:55:25,963:INFO:get_config() successfully completed......................................
2025-11-30 01:55:27,052:INFO:Initializing interpret_model()
2025-11-30 01:55:27,052:INFO:interpret_model(estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=0.7, device=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              feature_weights=None, gamma=None, grow_policy=None,
              importance_type=None, interaction_constraints=None,
              learning_rate=0.0001, max_bin=None, max_cat_threshold=None,
              max_cat_to_onehot=None, max_delta_step=None, max_depth=8,
              max_leaves=None, min_child_weight=3, missing=nan,
              monotone_constraints=None, multi_strategy=None, n_estimators=10,
              n_jobs=-1, num_parallel_tree=None, ...), use_train_data=False, X_new_sample=None, y_new_sample=None, feature=None, kwargs={}, observation=None, plot=summary, save=False, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fc53b4f3580>)
2025-11-30 01:55:27,052:INFO:Checking exceptions
2025-11-30 01:55:27,052:INFO:Soft dependency imported: shap: 0.48.0
2025-11-30 01:55:27,812:INFO:plot type: summary
2025-11-30 01:55:27,812:INFO:Creating TreeExplainer
2025-11-30 01:55:27,851:INFO:Initializing finalize_model()
2025-11-30 01:55:27,851:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fc53b4f3580>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=0.7, device=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              feature_weights=None, gamma=None, grow_policy=None,
              importance_type=None, interaction_constraints=None,
              learning_rate=0.0001, max_bin=None, max_cat_threshold=None,
              max_cat_to_onehot=None, max_delta_step=None, max_depth=8,
              max_leaves=None, min_child_weight=3, missing=nan,
              monotone_constraints=None, multi_strategy=None, n_estimators=10,
              n_jobs=-1, num_parallel_tree=None, ...), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2025-11-30 01:55:27,852:INFO:Finalizing XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=0.7, device=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              feature_weights=None, gamma=None, grow_policy=None,
              importance_type=None, interaction_constraints=None,
              learning_rate=0.0001, max_bin=None, max_cat_threshold=None,
              max_cat_to_onehot=None, max_delta_step=None, max_depth=8,
              max_leaves=None, min_child_weight=3, missing=nan,
              monotone_constraints=None, multi_strategy=None, n_estimators=10,
              n_jobs=-1, num_parallel_tree=None, ...)
2025-11-30 01:55:27,858:INFO:Initializing create_model()
2025-11-30 01:55:27,858:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fc53b4f3580>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=0.7, device=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              feature_weights=None, gamma=None, grow_policy=None,
              importance_type=None, interaction_constraints=None,
              learning_rate=0.0001, max_bin=None, max_cat_threshold=None,
              max_cat_to_onehot=None, max_delta_step=None, max_depth=8,
              max_leaves=None, min_child_weight=3, missing=nan,
              monotone_constraints=None, multi_strategy=None, n_estimators=10,
              n_jobs=-1, num_parallel_tree=None, ...), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2025-11-30 01:55:27,859:INFO:Checking exceptions
2025-11-30 01:55:27,861:INFO:Importing libraries
2025-11-30 01:55:27,861:INFO:Copying training dataset
2025-11-30 01:55:27,861:INFO:Defining folds
2025-11-30 01:55:27,861:INFO:Declaring metric variables
2025-11-30 01:55:27,862:INFO:Importing untrained model
2025-11-30 01:55:27,862:INFO:Declaring custom model
2025-11-30 01:55:27,864:INFO:Extreme Gradient Boosting Imported successfully
2025-11-30 01:55:27,896:INFO:Cross validation set to False
2025-11-30 01:55:27,897:INFO:Fitting Model
2025-11-30 01:55:28,597:INFO:Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'SystolicBP',
                                             'TotalCholesterol', 'LDL',
                                             'Triglycerides', 'HbA1c',
                                             'Glucose', 'UricAcid',
                                             'Creatinine', 'BMI',
                                             'WaistCircumference', 'Height',
                                             'IncomeRatio', 'ALT_Enzyme',
                                             'AST_Enzyme', 'GGT_Enzyme',
                                             'Albumin', 'Potassium', 'Sodium'],
                                    transform...
                               gamma=None, grow_policy=None,
                               importance_type=None,
                               interaction_constraints=None,
                               learning_rate=0.0001, max_bin=None,
                               max_cat_threshold=None, max_cat_to_onehot=None,
                               max_delta_step=None, max_depth=8,
                               max_leaves=None, min_child_weight=3, missing=nan,
                               monotone_constraints=None, multi_strategy=None,
                               n_estimators=10, n_jobs=-1,
                               num_parallel_tree=None, ...))],
         verbose=False)
2025-11-30 01:55:28,597:INFO:create_model() successfully completed......................................
2025-11-30 01:55:28,765:INFO:_master_model_container: 4
2025-11-30 01:55:28,765:INFO:_display_container: 4
2025-11-30 01:55:28,903:INFO:Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'SystolicBP',
                                             'TotalCholesterol', 'LDL',
                                             'Triglycerides', 'HbA1c',
                                             'Glucose', 'UricAcid',
                                             'Creatinine', 'BMI',
                                             'WaistCircumference', 'Height',
                                             'IncomeRatio', 'ALT_Enzyme',
                                             'AST_Enzyme', 'GGT_Enzyme',
                                             'Albumin', 'Potassium', 'Sodium'],
                                    transform...
                               gamma=None, grow_policy=None,
                               importance_type=None,
                               interaction_constraints=None,
                               learning_rate=0.0001, max_bin=None,
                               max_cat_threshold=None, max_cat_to_onehot=None,
                               max_delta_step=None, max_depth=8,
                               max_leaves=None, min_child_weight=3, missing=nan,
                               monotone_constraints=None, multi_strategy=None,
                               n_estimators=10, n_jobs=-1,
                               num_parallel_tree=None, ...))],
         verbose=False)
2025-11-30 01:55:28,903:INFO:finalize_model() successfully completed......................................
2025-11-30 01:55:29,323:INFO:Initializing save_model()
2025-11-30 01:55:29,323:INFO:save_model(model=Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'SystolicBP',
                                             'TotalCholesterol', 'LDL',
                                             'Triglycerides', 'HbA1c',
                                             'Glucose', 'UricAcid',
                                             'Creatinine', 'BMI',
                                             'WaistCircumference', 'Height',
                                             'IncomeRatio', 'ALT_Enzyme',
                                             'AST_Enzyme', 'GGT_Enzyme',
                                             'Albumin', 'Potassium', 'Sodium'],
                                    transform...
                               gamma=None, grow_policy=None,
                               importance_type=None,
                               interaction_constraints=None,
                               learning_rate=0.0001, max_bin=None,
                               max_cat_threshold=None, max_cat_to_onehot=None,
                               max_delta_step=None, max_depth=8,
                               max_leaves=None, min_child_weight=3, missing=nan,
                               monotone_constraints=None, multi_strategy=None,
                               n_estimators=10, n_jobs=-1,
                               num_parallel_tree=None, ...))],
         verbose=False), model_name=../models/best_pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'SystolicBP',
                                             'TotalCholesterol', 'LDL',
                                             'Triglycerides', 'HbA1c',
                                             'Glucose', 'UricAcid',
                                             'Creatinine', 'BMI',
                                             'WaistCircumference', 'Height',
                                             'IncomeRatio', 'ALT_Enzyme',
                                             'AST_Enzyme', 'GGT_Enzyme',
                                             'Albumin', 'Potassium', 'Sodium'],
                                    transform...
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              n_jobs=None,
                                                                              random_state=None,
                                                                              sampling_strategy='auto')))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=RobustScaler(copy=True,
                                                             quantile_range=(25.0,
                                                                             75.0),
                                                             unit_variance=False,
                                                             with_centering=True,
                                                             with_scaling=True)))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2025-11-30 01:55:29,323:INFO:Adding model into prep_pipe
2025-11-30 01:55:29,323:WARNING:Only Model saved as it was a pipeline.
2025-11-30 01:55:29,433:INFO:../models/best_pipeline.pkl saved in current working directory
2025-11-30 01:55:29,571:INFO:Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'SystolicBP',
                                             'TotalCholesterol', 'LDL',
                                             'Triglycerides', 'HbA1c',
                                             'Glucose', 'UricAcid',
                                             'Creatinine', 'BMI',
                                             'WaistCircumference', 'Height',
                                             'IncomeRatio', 'ALT_Enzyme',
                                             'AST_Enzyme', 'GGT_Enzyme',
                                             'Albumin', 'Potassium', 'Sodium'],
                                    transform...
                               gamma=None, grow_policy=None,
                               importance_type=None,
                               interaction_constraints=None,
                               learning_rate=0.0001, max_bin=None,
                               max_cat_threshold=None, max_cat_to_onehot=None,
                               max_delta_step=None, max_depth=8,
                               max_leaves=None, min_child_weight=3, missing=nan,
                               monotone_constraints=None, multi_strategy=None,
                               n_estimators=10, n_jobs=-1,
                               num_parallel_tree=None, ...))],
         verbose=False)
2025-11-30 01:55:29,571:INFO:save_model() successfully completed......................................
2025-12-01 14:29:58,226:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-12-01 14:29:58,227:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-12-01 14:29:58,227:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-12-01 14:29:58,227:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-12-01 14:29:58,726:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2025-12-01 14:32:12,693:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-12-01 14:32:12,693:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-12-01 14:32:12,693:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-12-01 14:32:12,693:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-12-01 14:32:13,187:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2025-12-01 14:33:31,808:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-12-01 14:33:31,809:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-12-01 14:33:31,809:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-12-01 14:33:31,809:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-12-01 14:33:32,350:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2025-12-01 14:33:32,762:INFO:PyCaret ClassificationExperiment
2025-12-01 14:33:32,762:INFO:Logging name: clf-default-name
2025-12-01 14:33:32,762:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-12-01 14:33:32,762:INFO:version 3.0.3
2025-12-01 14:33:32,762:INFO:Initializing setup()
2025-12-01 14:33:32,762:INFO:self.USI: 9964
2025-12-01 14:33:32,762:INFO:self._variable_keys: {'gpu_n_jobs_param', 'exp_id', '_available_plots', 'logging_param', 'is_multiclass', 'USI', 'X', 'memory', 'pipeline', 'log_plots_param', 'target_param', 'X_test', 'y_train', 'gpu_param', 'fix_imbalance', 'data', 'fold_generator', 'n_jobs_param', 'exp_name_log', 'X_train', 'html_param', 'y', 'y_test', 'idx', 'fold_groups_param', 'seed', 'fold_shuffle_param', '_ml_usecase'}
2025-12-01 14:33:32,762:INFO:Checking environment
2025-12-01 14:33:32,762:INFO:python_version: 3.10.19
2025-12-01 14:33:32,762:INFO:python_build: ('main', 'Nov  7 2025 00:05:37')
2025-12-01 14:33:32,762:INFO:machine: x86_64
2025-12-01 14:33:32,763:INFO:platform: Linux-6.8.0-x86_64-with-glibc2.39
2025-12-01 14:33:32,763:INFO:Memory: svmem(total=8345706496, available=7589097472, percent=9.1, used=756609024, free=4428079104, active=340205568, inactive=3270496256, buffers=75214848, cached=3398266880, shared=548864, slab=245153792)
2025-12-01 14:33:32,764:INFO:Physical Core: 4
2025-12-01 14:33:32,765:INFO:Logical Core: 4
2025-12-01 14:33:32,765:INFO:Checking libraries
2025-12-01 14:33:32,765:INFO:System:
2025-12-01 14:33:32,765:INFO:    python: 3.10.19 (main, Nov  7 2025, 00:05:37) [GCC 13.3.0]
2025-12-01 14:33:32,765:INFO:executable: /home/jules/.pyenv/versions/3.10.19/bin/python3.10
2025-12-01 14:33:32,765:INFO:   machine: Linux-6.8.0-x86_64-with-glibc2.39
2025-12-01 14:33:32,765:INFO:PyCaret required dependencies:
2025-12-01 14:33:32,770:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-01 14:33:32,808:INFO:                 pip: 25.3
2025-12-01 14:33:32,808:INFO:          setuptools: 79.0.1
2025-12-01 14:33:32,808:INFO:             pycaret: 3.0.3
2025-12-01 14:33:32,808:INFO:             IPython: 8.37.0
2025-12-01 14:33:32,808:INFO:          ipywidgets: 8.1.8
2025-12-01 14:33:32,808:INFO:                tqdm: 4.67.1
2025-12-01 14:33:32,808:INFO:               numpy: 1.23.5
2025-12-01 14:33:32,808:INFO:              pandas: 1.5.3
2025-12-01 14:33:32,808:INFO:              jinja2: 3.1.6
2025-12-01 14:33:32,808:INFO:               scipy: 1.10.1
2025-12-01 14:33:32,808:INFO:              joblib: 1.2.0
2025-12-01 14:33:32,808:INFO:             sklearn: 1.3.2
2025-12-01 14:33:32,809:INFO:                pyod: 2.0.5
2025-12-01 14:33:32,809:INFO:            imblearn: 0.12.4
2025-12-01 14:33:32,809:INFO:   category_encoders: 2.7.0
2025-12-01 14:33:32,809:INFO:            lightgbm: 4.6.0
2025-12-01 14:33:32,809:INFO:               numba: 0.62.1
2025-12-01 14:33:32,809:INFO:            requests: 2.32.5
2025-12-01 14:33:32,809:INFO:          matplotlib: 3.10.7
2025-12-01 14:33:32,809:INFO:          scikitplot: 0.3.7
2025-12-01 14:33:32,809:INFO:         yellowbrick: 1.5
2025-12-01 14:33:32,809:INFO:              plotly: 6.5.0
2025-12-01 14:33:32,809:INFO:    plotly-resampler: Not installed
2025-12-01 14:33:32,809:INFO:             kaleido: 1.2.0
2025-12-01 14:33:32,809:INFO:           schemdraw: 0.15
2025-12-01 14:33:32,809:INFO:         statsmodels: 0.14.5
2025-12-01 14:33:32,809:INFO:              sktime: 0.40.1
2025-12-01 14:33:32,809:INFO:               tbats: 1.1.3
2025-12-01 14:33:32,809:INFO:            pmdarima: 2.1.1
2025-12-01 14:33:32,809:INFO:              psutil: 7.1.3
2025-12-01 14:33:32,809:INFO:          markupsafe: 3.0.3
2025-12-01 14:33:32,809:INFO:             pickle5: Not installed
2025-12-01 14:33:32,809:INFO:         cloudpickle: 3.1.2
2025-12-01 14:33:32,809:INFO:         deprecation: 2.1.0
2025-12-01 14:33:32,809:INFO:              xxhash: 3.6.0
2025-12-01 14:33:32,809:INFO:           wurlitzer: 3.1.1
2025-12-01 14:33:32,810:INFO:PyCaret optional dependencies:
2025-12-01 14:33:32,879:INFO:                shap: 0.49.1
2025-12-01 14:33:32,879:INFO:           interpret: Not installed
2025-12-01 14:33:32,879:INFO:                umap: Not installed
2025-12-01 14:33:32,879:INFO:    pandas_profiling: Not installed
2025-12-01 14:33:32,879:INFO:  explainerdashboard: Not installed
2025-12-01 14:33:32,879:INFO:             autoviz: Not installed
2025-12-01 14:33:32,879:INFO:           fairlearn: Not installed
2025-12-01 14:33:32,879:INFO:          deepchecks: Not installed
2025-12-01 14:33:32,879:INFO:             xgboost: 3.1.2
2025-12-01 14:33:32,879:INFO:            catboost: Not installed
2025-12-01 14:33:32,879:INFO:              kmodes: Not installed
2025-12-01 14:33:32,879:INFO:             mlxtend: Not installed
2025-12-01 14:33:32,879:INFO:       statsforecast: Not installed
2025-12-01 14:33:32,879:INFO:        tune_sklearn: Not installed
2025-12-01 14:33:32,879:INFO:                 ray: Not installed
2025-12-01 14:33:32,879:INFO:            hyperopt: Not installed
2025-12-01 14:33:32,879:INFO:              optuna: Not installed
2025-12-01 14:33:32,879:INFO:               skopt: Not installed
2025-12-01 14:33:32,879:INFO:              mlflow: Not installed
2025-12-01 14:33:32,880:INFO:              gradio: Not installed
2025-12-01 14:33:32,880:INFO:             fastapi: Not installed
2025-12-01 14:33:32,880:INFO:             uvicorn: Not installed
2025-12-01 14:33:32,880:INFO:              m2cgen: Not installed
2025-12-01 14:33:32,880:INFO:           evidently: Not installed
2025-12-01 14:33:32,880:INFO:               fugue: Not installed
2025-12-01 14:33:32,880:INFO:           streamlit: Not installed
2025-12-01 14:33:32,880:INFO:             prophet: Not installed
2025-12-01 14:33:32,880:INFO:None
2025-12-01 14:33:32,880:INFO:Set up data.
2025-12-01 14:33:32,899:INFO:Set up train/test split.
2025-12-01 14:33:32,906:INFO:Set up index.
2025-12-01 14:33:32,907:INFO:Set up folding strategy.
2025-12-01 14:33:32,907:INFO:Assigning column types.
2025-12-01 14:33:32,911:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-12-01 14:33:32,976:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-12-01 14:33:32,981:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-01 14:33:33,027:INFO:Soft dependency imported: xgboost: 3.1.2
2025-12-01 14:33:33,031:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-01 14:33:33,097:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-12-01 14:33:33,098:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-01 14:33:33,140:INFO:Soft dependency imported: xgboost: 3.1.2
2025-12-01 14:33:33,144:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-01 14:33:33,144:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-12-01 14:33:33,215:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-01 14:33:33,268:INFO:Soft dependency imported: xgboost: 3.1.2
2025-12-01 14:33:33,272:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-01 14:33:33,346:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-01 14:33:33,385:INFO:Soft dependency imported: xgboost: 3.1.2
2025-12-01 14:33:33,389:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-01 14:33:33,390:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-12-01 14:33:33,504:INFO:Soft dependency imported: xgboost: 3.1.2
2025-12-01 14:33:33,508:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-01 14:33:33,614:INFO:Soft dependency imported: xgboost: 3.1.2
2025-12-01 14:33:33,617:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-01 14:33:33,620:INFO:Preparing preprocessing pipeline...
2025-12-01 14:33:33,622:INFO:Set up simple imputation.
2025-12-01 14:33:33,626:INFO:Set up encoding of ordinal features.
2025-12-01 14:33:33,629:INFO:Set up encoding of categorical features.
2025-12-01 14:33:33,629:INFO:Set up removing outliers.
2025-12-01 14:33:33,630:INFO:Set up imbalanced handling.
2025-12-01 14:33:33,630:INFO:Set up feature normalization.
2025-12-01 14:33:34,214:INFO:Finished creating preprocessing pipeline.
2025-12-01 14:33:34,290:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'SystolicBP',
                                             'TotalCholesterol', 'LDL',
                                             'Triglycerides', 'HbA1c',
                                             'Glucose', 'UricAcid',
                                             'Creatinine', 'BMI',
                                             'WaistCircumference', 'Height',
                                             'IncomeRatio', 'ALT_Enzyme',
                                             'AST_Enzyme', 'GGT_Enzyme',
                                             'Albumin', 'Potassium', 'Sodium'],
                                    transform...
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              n_jobs=None,
                                                                              random_state=None,
                                                                              sampling_strategy='auto')))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=RobustScaler(copy=True,
                                                             quantile_range=(25.0,
                                                                             75.0),
                                                             unit_variance=False,
                                                             with_centering=True,
                                                             with_scaling=True)))],
         verbose=False)
2025-12-01 14:33:34,290:INFO:Creating final display dataframe.
2025-12-01 14:33:35,475:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target      HeartDisease
2                   Target type            Binary
3           Original data shape         (437, 27)
4        Transformed data shape         (698, 31)
5   Transformed train set shape         (566, 31)
6    Transformed test set shape         (132, 31)
7              Ordinal features                 2
8              Numeric features                19
9          Categorical features                 7
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16              Remove outliers              True
17           Outliers threshold              0.05
18                Fix imbalance              True
19         Fix imbalance method             SMOTE
20                    Normalize              True
21             Normalize method            robust
22               Fold Generator   StratifiedKFold
23                  Fold Number                10
24                     CPU Jobs                -1
25                      Use GPU             False
26               Log Experiment             False
27              Experiment Name  clf-default-name
28                          USI              9964
2025-12-01 14:33:35,715:INFO:Soft dependency imported: xgboost: 3.1.2
2025-12-01 14:33:35,723:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-01 14:33:35,828:INFO:Soft dependency imported: xgboost: 3.1.2
2025-12-01 14:33:35,832:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-01 14:33:35,834:INFO:setup() successfully completed in 3.07s...............
2025-12-01 14:33:35,869:INFO:Initializing compare_models()
2025-12-01 14:33:35,870:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f4c1d91fa30>, include=['xgboost', 'lightgbm'], fold=None, round=4, cross_validation=True, sort=Recall, n_select=3, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=False, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x7f4c1d91fa30>, 'include': ['xgboost', 'lightgbm'], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Recall', 'n_select': 3, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': False, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2025-12-01 14:33:35,870:INFO:Checking exceptions
2025-12-01 14:33:35,877:INFO:Preparing display monitor
2025-12-01 14:33:35,885:INFO:Initializing Extreme Gradient Boosting
2025-12-01 14:33:35,885:INFO:Total runtime is 3.353754679361979e-06 minutes
2025-12-01 14:33:35,886:INFO:SubProcess create_model() called ==================================
2025-12-01 14:33:35,886:INFO:Initializing create_model()
2025-12-01 14:33:35,886:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f4c1d91fa30>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f4bc74f79d0>, model_only=True, return_train_score=False, kwargs={})
2025-12-01 14:33:35,886:INFO:Checking exceptions
2025-12-01 14:33:35,887:INFO:Importing libraries
2025-12-01 14:33:35,887:INFO:Copying training dataset
2025-12-01 14:33:35,895:INFO:Defining folds
2025-12-01 14:33:35,895:INFO:Declaring metric variables
2025-12-01 14:33:35,896:INFO:Importing untrained model
2025-12-01 14:33:35,898:INFO:Extreme Gradient Boosting Imported successfully
2025-12-01 14:33:35,898:INFO:Starting cross validation
2025-12-01 14:33:35,928:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-01 14:33:35,959:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 7 members, which is less than n_splits=10.
  warnings.warn(

2025-12-01 14:33:38,774:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-01 14:33:38,843:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-01 14:33:38,844:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-01 14:33:38,904:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-01 14:33:40,818:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 401, in _score
    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 214, in wrapper
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 627, in roc_auc_score
    return _average_binary_score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-12-01 14:33:40,824:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 14:33:40,827:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 14:33:40,831:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1760: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2025-12-01 14:33:40,833:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:697: RuntimeWarning: invalid value encountered in double_scalars
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-12-01 14:33:40,934:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 401, in _score
    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 214, in wrapper
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 627, in roc_auc_score
    return _average_binary_score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-12-01 14:33:40,939:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 14:33:40,943:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 14:33:40,946:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1760: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2025-12-01 14:33:40,948:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:697: RuntimeWarning: invalid value encountered in double_scalars
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-12-01 14:33:41,251:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 401, in _score
    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 214, in wrapper
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 627, in roc_auc_score
    return _average_binary_score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-12-01 14:33:41,256:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 14:33:41,260:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 14:33:41,263:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1760: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2025-12-01 14:33:41,265:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:697: RuntimeWarning: invalid value encountered in double_scalars
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-12-01 14:33:41,299:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:425: FitFailedWarning:
5 fits failed out of a total of 10.
The score on these train-test partitions for these parameters will be set to 0.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
4 fits failed with the following error:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/model_selection/_validation.py", line 729, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 255, in fit
    X, y, _ = self._fit(X, y, **fit_params_steps)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 238, in _fit
    X, y = self._memory_transform(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/joblib/memory.py", line 594, in __call__
    return self._cached_call(args, kwargs)[0]
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/memory.py", line 398, in _cached_call
    out, metadata = self.call(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/memory.py", line 309, in call
    output = self.func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 77, in _transform_one
    output = transformer.transform(*args)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 157, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 259, in transform
    output = self.transformer.transform(*args)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 157, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 546, in transform
    X, y = self.estimator.fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/base.py", line 208, in fit_resample
    return super().fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/base.py", line 112, in fit_resample
    output = self._fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/over_sampling/_smote/base.py", line 389, in _fit_resample
    nns = self.nn_k_.kneighbors(X_class, return_distance=False)[:, 1:]
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/neighbors/_base.py", line 808, in kneighbors
    raise ValueError(
ValueError: Expected n_neighbors <= n_samples,  but n_samples = 5, n_neighbors = 6

--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/model_selection/_validation.py", line 729, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 255, in fit
    X, y, _ = self._fit(X, y, **fit_params_steps)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 238, in _fit
    X, y = self._memory_transform(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/joblib/memory.py", line 594, in __call__
    return self._cached_call(args, kwargs)[0]
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/memory.py", line 398, in _cached_call
    out, metadata = self.call(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/memory.py", line 309, in call
    output = self.func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 77, in _transform_one
    output = transformer.transform(*args)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 157, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 259, in transform
    output = self.transformer.transform(*args)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 157, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 546, in transform
    X, y = self.estimator.fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/base.py", line 208, in fit_resample
    return super().fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/base.py", line 112, in fit_resample
    output = self._fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/over_sampling/_smote/base.py", line 389, in _fit_resample
    nns = self.nn_k_.kneighbors(X_class, return_distance=False)[:, 1:]
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/neighbors/_base.py", line 808, in kneighbors
    raise ValueError(
ValueError: Expected n_neighbors <= n_samples,  but n_samples = 4, n_neighbors = 6

  warnings.warn(some_fits_failed_message, FitFailedWarning)

2025-12-01 14:33:41,301:INFO:Calculating mean and std
2025-12-01 14:33:41,301:INFO:Creating metrics dataframe
2025-12-01 14:33:41,318:INFO:Uploading results into container
2025-12-01 14:33:41,319:INFO:Uploading model into container now
2025-12-01 14:33:41,320:INFO:_master_model_container: 1
2025-12-01 14:33:41,320:INFO:_display_container: 2
2025-12-01 14:33:41,321:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              feature_weights=None, gamma=None, grow_policy=None,
              importance_type=None, interaction_constraints=None,
              learning_rate=None, max_bin=None, max_cat_threshold=None,
              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,
              max_leaves=None, min_child_weight=None, missing=nan,
              monotone_constraints=None, multi_strategy=None, n_estimators=None,
              n_jobs=-1, num_parallel_tree=None, ...)
2025-12-01 14:33:41,322:INFO:create_model() successfully completed......................................
2025-12-01 14:33:41,479:WARNING:create_model() for XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              feature_weights=None, gamma=None, grow_policy=None,
              importance_type=None, interaction_constraints=None,
              learning_rate=None, max_bin=None, max_cat_threshold=None,
              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,
              max_leaves=None, min_child_weight=None, missing=nan,
              monotone_constraints=None, multi_strategy=None, n_estimators=None,
              n_jobs=-1, num_parallel_tree=None, ...) raised an exception or returned all 0.0, trying without fit_kwargs:
2025-12-01 14:33:41,482:WARNING:Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 795, in compare_models
    np.sum(
AssertionError

2025-12-01 14:33:41,482:INFO:Initializing create_model()
2025-12-01 14:33:41,483:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f4c1d91fa30>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f4bc74f79d0>, model_only=True, return_train_score=False, kwargs={})
2025-12-01 14:33:41,483:INFO:Checking exceptions
2025-12-01 14:33:41,483:INFO:Importing libraries
2025-12-01 14:33:41,483:INFO:Copying training dataset
2025-12-01 14:33:41,488:INFO:Defining folds
2025-12-01 14:33:41,489:INFO:Declaring metric variables
2025-12-01 14:33:41,489:INFO:Importing untrained model
2025-12-01 14:33:41,490:INFO:Extreme Gradient Boosting Imported successfully
2025-12-01 14:33:41,490:INFO:Starting cross validation
2025-12-01 14:33:41,508:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-01 14:33:41,513:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 7 members, which is less than n_splits=10.
  warnings.warn(

2025-12-01 14:33:42,176:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 401, in _score
    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 214, in wrapper
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 627, in roc_auc_score
    return _average_binary_score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-12-01 14:33:42,179:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 14:33:42,182:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 14:33:42,189:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1760: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2025-12-01 14:33:42,191:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 401, in _score
    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 214, in wrapper
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 627, in roc_auc_score
    return _average_binary_score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-12-01 14:33:42,191:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:697: RuntimeWarning: invalid value encountered in double_scalars
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-12-01 14:33:42,194:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 14:33:42,320:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 401, in _score
    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 214, in wrapper
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 627, in roc_auc_score
    return _average_binary_score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-12-01 14:33:42,324:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 14:33:42,327:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 14:33:42,331:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1760: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2025-12-01 14:33:42,333:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:697: RuntimeWarning: invalid value encountered in double_scalars
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-12-01 14:33:42,499:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:425: FitFailedWarning:
5 fits failed out of a total of 10.
The score on these train-test partitions for these parameters will be set to 0.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
4 fits failed with the following error:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/model_selection/_validation.py", line 729, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 255, in fit
    X, y, _ = self._fit(X, y, **fit_params_steps)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 238, in _fit
    X, y = self._memory_transform(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/joblib/memory.py", line 594, in __call__
    return self._cached_call(args, kwargs)[0]
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/memory.py", line 398, in _cached_call
    out, metadata = self.call(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/memory.py", line 309, in call
    output = self.func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 77, in _transform_one
    output = transformer.transform(*args)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 157, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 259, in transform
    output = self.transformer.transform(*args)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 157, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 546, in transform
    X, y = self.estimator.fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/base.py", line 208, in fit_resample
    return super().fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/base.py", line 112, in fit_resample
    output = self._fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/over_sampling/_smote/base.py", line 389, in _fit_resample
    nns = self.nn_k_.kneighbors(X_class, return_distance=False)[:, 1:]
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/neighbors/_base.py", line 808, in kneighbors
    raise ValueError(
ValueError: Expected n_neighbors <= n_samples,  but n_samples = 5, n_neighbors = 6

--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/model_selection/_validation.py", line 729, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 255, in fit
    X, y, _ = self._fit(X, y, **fit_params_steps)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 238, in _fit
    X, y = self._memory_transform(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/joblib/memory.py", line 594, in __call__
    return self._cached_call(args, kwargs)[0]
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/memory.py", line 398, in _cached_call
    out, metadata = self.call(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/memory.py", line 309, in call
    output = self.func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 77, in _transform_one
    output = transformer.transform(*args)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 157, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 259, in transform
    output = self.transformer.transform(*args)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 157, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 546, in transform
    X, y = self.estimator.fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/base.py", line 208, in fit_resample
    return super().fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/base.py", line 112, in fit_resample
    output = self._fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/over_sampling/_smote/base.py", line 389, in _fit_resample
    nns = self.nn_k_.kneighbors(X_class, return_distance=False)[:, 1:]
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/neighbors/_base.py", line 808, in kneighbors
    raise ValueError(
ValueError: Expected n_neighbors <= n_samples,  but n_samples = 4, n_neighbors = 6

  warnings.warn(some_fits_failed_message, FitFailedWarning)

2025-12-01 14:33:42,500:INFO:Calculating mean and std
2025-12-01 14:33:42,501:INFO:Creating metrics dataframe
2025-12-01 14:33:42,515:INFO:Uploading results into container
2025-12-01 14:33:42,516:INFO:Uploading model into container now
2025-12-01 14:33:42,517:INFO:_master_model_container: 2
2025-12-01 14:33:42,517:INFO:_display_container: 2
2025-12-01 14:33:42,518:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              feature_weights=None, gamma=None, grow_policy=None,
              importance_type=None, interaction_constraints=None,
              learning_rate=None, max_bin=None, max_cat_threshold=None,
              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,
              max_leaves=None, min_child_weight=None, missing=nan,
              monotone_constraints=None, multi_strategy=None, n_estimators=None,
              n_jobs=-1, num_parallel_tree=None, ...)
2025-12-01 14:33:42,519:INFO:create_model() successfully completed......................................
2025-12-01 14:33:42,645:ERROR:create_model() for XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              feature_weights=None, gamma=None, grow_policy=None,
              importance_type=None, interaction_constraints=None,
              learning_rate=None, max_bin=None, max_cat_threshold=None,
              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,
              max_leaves=None, min_child_weight=None, missing=nan,
              monotone_constraints=None, multi_strategy=None, n_estimators=None,
              n_jobs=-1, num_parallel_tree=None, ...) raised an exception or returned all 0.0:
2025-12-01 14:33:42,645:ERROR:Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 795, in compare_models
    np.sum(
AssertionError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 811, in compare_models
    np.sum(
AssertionError

2025-12-01 14:33:42,645:INFO:Initializing Light Gradient Boosting Machine
2025-12-01 14:33:42,645:INFO:Total runtime is 0.11267447074254354 minutes
2025-12-01 14:33:42,646:INFO:SubProcess create_model() called ==================================
2025-12-01 14:33:42,646:INFO:Initializing create_model()
2025-12-01 14:33:42,646:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f4c1d91fa30>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f4bc74f79d0>, model_only=True, return_train_score=False, kwargs={})
2025-12-01 14:33:42,646:INFO:Checking exceptions
2025-12-01 14:33:42,646:INFO:Importing libraries
2025-12-01 14:33:42,646:INFO:Copying training dataset
2025-12-01 14:33:42,651:INFO:Defining folds
2025-12-01 14:33:42,651:INFO:Declaring metric variables
2025-12-01 14:33:42,651:INFO:Importing untrained model
2025-12-01 14:33:42,652:INFO:Light Gradient Boosting Machine Imported successfully
2025-12-01 14:33:42,652:INFO:Starting cross validation
2025-12-01 14:33:42,665:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-01 14:33:42,670:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 7 members, which is less than n_splits=10.
  warnings.warn(

2025-12-01 14:33:56,893:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 401, in _score
    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 214, in wrapper
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 627, in roc_auc_score
    return _average_binary_score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-12-01 14:33:56,908:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 14:33:56,923:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 14:33:56,926:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1760: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2025-12-01 14:33:56,940:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:697: RuntimeWarning: invalid value encountered in double_scalars
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-12-01 14:36:35,210:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 401, in _score
    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 214, in wrapper
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 627, in roc_auc_score
    return _average_binary_score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-12-01 14:36:35,227:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 14:36:35,231:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 14:36:35,242:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1760: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2025-12-01 14:36:35,252:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:697: RuntimeWarning: invalid value encountered in double_scalars
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-12-01 14:36:42,153:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 401, in _score
    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 214, in wrapper
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 627, in roc_auc_score
    return _average_binary_score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-12-01 14:36:42,160:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 14:36:42,167:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 14:36:42,170:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1760: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2025-12-01 14:36:42,176:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:697: RuntimeWarning: invalid value encountered in double_scalars
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-12-01 14:36:42,605:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:425: FitFailedWarning:
5 fits failed out of a total of 10.
The score on these train-test partitions for these parameters will be set to 0.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
4 fits failed with the following error:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/model_selection/_validation.py", line 729, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 255, in fit
    X, y, _ = self._fit(X, y, **fit_params_steps)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 238, in _fit
    X, y = self._memory_transform(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/joblib/memory.py", line 594, in __call__
    return self._cached_call(args, kwargs)[0]
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/memory.py", line 398, in _cached_call
    out, metadata = self.call(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/memory.py", line 309, in call
    output = self.func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 77, in _transform_one
    output = transformer.transform(*args)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 157, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 259, in transform
    output = self.transformer.transform(*args)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 157, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 546, in transform
    X, y = self.estimator.fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/base.py", line 208, in fit_resample
    return super().fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/base.py", line 112, in fit_resample
    output = self._fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/over_sampling/_smote/base.py", line 389, in _fit_resample
    nns = self.nn_k_.kneighbors(X_class, return_distance=False)[:, 1:]
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/neighbors/_base.py", line 808, in kneighbors
    raise ValueError(
ValueError: Expected n_neighbors <= n_samples,  but n_samples = 5, n_neighbors = 6

--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/model_selection/_validation.py", line 729, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 255, in fit
    X, y, _ = self._fit(X, y, **fit_params_steps)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 238, in _fit
    X, y = self._memory_transform(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/joblib/memory.py", line 594, in __call__
    return self._cached_call(args, kwargs)[0]
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/memory.py", line 398, in _cached_call
    out, metadata = self.call(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/memory.py", line 309, in call
    output = self.func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 77, in _transform_one
    output = transformer.transform(*args)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 157, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 259, in transform
    output = self.transformer.transform(*args)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 157, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 546, in transform
    X, y = self.estimator.fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/base.py", line 208, in fit_resample
    return super().fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/base.py", line 112, in fit_resample
    output = self._fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/over_sampling/_smote/base.py", line 389, in _fit_resample
    nns = self.nn_k_.kneighbors(X_class, return_distance=False)[:, 1:]
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/neighbors/_base.py", line 808, in kneighbors
    raise ValueError(
ValueError: Expected n_neighbors <= n_samples,  but n_samples = 4, n_neighbors = 6

  warnings.warn(some_fits_failed_message, FitFailedWarning)

2025-12-01 14:36:42,606:INFO:Calculating mean and std
2025-12-01 14:36:42,607:INFO:Creating metrics dataframe
2025-12-01 14:36:42,627:INFO:Uploading results into container
2025-12-01 14:36:42,628:INFO:Uploading model into container now
2025-12-01 14:36:42,628:INFO:_master_model_container: 3
2025-12-01 14:36:42,628:INFO:_display_container: 2
2025-12-01 14:36:42,629:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-12-01 14:36:42,629:INFO:create_model() successfully completed......................................
2025-12-01 14:36:42,749:WARNING:create_model() for LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) raised an exception or returned all 0.0, trying without fit_kwargs:
2025-12-01 14:36:42,750:WARNING:Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 795, in compare_models
    np.sum(
AssertionError

2025-12-01 14:36:42,750:INFO:Initializing create_model()
2025-12-01 14:36:42,750:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f4c1d91fa30>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f4bc74f79d0>, model_only=True, return_train_score=False, kwargs={})
2025-12-01 14:36:42,750:INFO:Checking exceptions
2025-12-01 14:36:42,750:INFO:Importing libraries
2025-12-01 14:36:42,750:INFO:Copying training dataset
2025-12-01 14:36:42,754:INFO:Defining folds
2025-12-01 14:36:42,755:INFO:Declaring metric variables
2025-12-01 14:36:42,755:INFO:Importing untrained model
2025-12-01 14:36:42,756:INFO:Light Gradient Boosting Machine Imported successfully
2025-12-01 14:36:42,756:INFO:Starting cross validation
2025-12-01 14:36:42,769:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-01 14:36:42,773:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 7 members, which is less than n_splits=10.
  warnings.warn(

2025-12-01 14:37:42,837:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 401, in _score
    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 214, in wrapper
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 627, in roc_auc_score
    return _average_binary_score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-12-01 14:37:42,852:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 14:37:42,868:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 14:37:42,880:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1760: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2025-12-01 14:37:42,882:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:697: RuntimeWarning: invalid value encountered in double_scalars
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-12-01 14:38:15,321:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 401, in _score
    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 214, in wrapper
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 627, in roc_auc_score
    return _average_binary_score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-12-01 14:38:15,332:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 14:38:42,657:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 401, in _score
    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 214, in wrapper
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 627, in roc_auc_score
    return _average_binary_score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-12-01 14:38:42,668:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 14:38:42,674:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 14:38:42,677:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1760: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2025-12-01 14:38:42,679:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:697: RuntimeWarning: invalid value encountered in double_scalars
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-12-01 14:38:42,956:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:425: FitFailedWarning:
5 fits failed out of a total of 10.
The score on these train-test partitions for these parameters will be set to 0.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
4 fits failed with the following error:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/model_selection/_validation.py", line 729, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 255, in fit
    X, y, _ = self._fit(X, y, **fit_params_steps)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 238, in _fit
    X, y = self._memory_transform(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/joblib/memory.py", line 594, in __call__
    return self._cached_call(args, kwargs)[0]
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/memory.py", line 398, in _cached_call
    out, metadata = self.call(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/memory.py", line 309, in call
    output = self.func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 77, in _transform_one
    output = transformer.transform(*args)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 157, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 259, in transform
    output = self.transformer.transform(*args)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 157, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 546, in transform
    X, y = self.estimator.fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/base.py", line 208, in fit_resample
    return super().fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/base.py", line 112, in fit_resample
    output = self._fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/over_sampling/_smote/base.py", line 389, in _fit_resample
    nns = self.nn_k_.kneighbors(X_class, return_distance=False)[:, 1:]
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/neighbors/_base.py", line 808, in kneighbors
    raise ValueError(
ValueError: Expected n_neighbors <= n_samples,  but n_samples = 5, n_neighbors = 6

--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/model_selection/_validation.py", line 729, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 255, in fit
    X, y, _ = self._fit(X, y, **fit_params_steps)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 238, in _fit
    X, y = self._memory_transform(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/joblib/memory.py", line 594, in __call__
    return self._cached_call(args, kwargs)[0]
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/memory.py", line 398, in _cached_call
    out, metadata = self.call(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/memory.py", line 309, in call
    output = self.func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 77, in _transform_one
    output = transformer.transform(*args)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 157, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 259, in transform
    output = self.transformer.transform(*args)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 157, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 546, in transform
    X, y = self.estimator.fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/base.py", line 208, in fit_resample
    return super().fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/base.py", line 112, in fit_resample
    output = self._fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/over_sampling/_smote/base.py", line 389, in _fit_resample
    nns = self.nn_k_.kneighbors(X_class, return_distance=False)[:, 1:]
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/neighbors/_base.py", line 808, in kneighbors
    raise ValueError(
ValueError: Expected n_neighbors <= n_samples,  but n_samples = 4, n_neighbors = 6

  warnings.warn(some_fits_failed_message, FitFailedWarning)

2025-12-01 14:38:42,957:INFO:Calculating mean and std
2025-12-01 14:38:42,958:INFO:Creating metrics dataframe
2025-12-01 14:38:42,983:INFO:Uploading results into container
2025-12-01 14:38:42,983:INFO:Uploading model into container now
2025-12-01 14:38:42,984:INFO:_master_model_container: 4
2025-12-01 14:38:42,984:INFO:_display_container: 2
2025-12-01 14:38:42,985:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-12-01 14:38:42,985:INFO:create_model() successfully completed......................................
2025-12-01 14:38:43,111:ERROR:create_model() for LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) raised an exception or returned all 0.0:
2025-12-01 14:38:43,111:ERROR:Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 795, in compare_models
    np.sum(
AssertionError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 811, in compare_models
    np.sum(
AssertionError

2025-12-01 14:38:43,112:INFO:_master_model_container: 4
2025-12-01 14:38:43,112:INFO:_display_container: 2
2025-12-01 14:38:43,112:INFO:[]
2025-12-01 14:38:43,112:INFO:compare_models() successfully completed......................................
2025-12-01 14:41:02,881:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-12-01 14:41:02,881:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-12-01 14:41:02,881:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-12-01 14:41:02,881:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-12-01 14:41:03,442:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2025-12-01 14:41:03,832:INFO:PyCaret ClassificationExperiment
2025-12-01 14:41:03,832:INFO:Logging name: clf-default-name
2025-12-01 14:41:03,832:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-12-01 14:41:03,832:INFO:version 3.0.3
2025-12-01 14:41:03,832:INFO:Initializing setup()
2025-12-01 14:41:03,832:INFO:self.USI: 93f9
2025-12-01 14:41:03,832:INFO:self._variable_keys: {'X', 'fold_shuffle_param', 'data', 'logging_param', 'fold_groups_param', 'X_train', 'is_multiclass', 'USI', 'gpu_param', 'y', 'fold_generator', 'fix_imbalance', 'gpu_n_jobs_param', 'memory', 'n_jobs_param', 'y_train', '_available_plots', 'log_plots_param', 'pipeline', 'X_test', 'exp_name_log', 'target_param', 'html_param', '_ml_usecase', 'exp_id', 'y_test', 'idx', 'seed'}
2025-12-01 14:41:03,832:INFO:Checking environment
2025-12-01 14:41:03,832:INFO:python_version: 3.10.19
2025-12-01 14:41:03,832:INFO:python_build: ('main', 'Nov  7 2025 00:05:37')
2025-12-01 14:41:03,832:INFO:machine: x86_64
2025-12-01 14:41:03,832:INFO:platform: Linux-6.8.0-x86_64-with-glibc2.39
2025-12-01 14:41:03,833:INFO:Memory: svmem(total=8345706496, available=7601012736, percent=8.9, used=744693760, free=4221861888, active=377139200, inactive=3444461568, buffers=75583488, cached=3616030720, shared=548864, slab=253394944)
2025-12-01 14:41:03,833:INFO:Physical Core: 4
2025-12-01 14:41:03,834:INFO:Logical Core: 4
2025-12-01 14:41:03,834:INFO:Checking libraries
2025-12-01 14:41:03,834:INFO:System:
2025-12-01 14:41:03,834:INFO:    python: 3.10.19 (main, Nov  7 2025, 00:05:37) [GCC 13.3.0]
2025-12-01 14:41:03,834:INFO:executable: /home/jules/.pyenv/versions/3.10.19/bin/python3.10
2025-12-01 14:41:03,834:INFO:   machine: Linux-6.8.0-x86_64-with-glibc2.39
2025-12-01 14:41:03,834:INFO:PyCaret required dependencies:
2025-12-01 14:41:03,836:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-01 14:41:03,872:INFO:                 pip: 25.3
2025-12-01 14:41:03,872:INFO:          setuptools: 79.0.1
2025-12-01 14:41:03,872:INFO:             pycaret: 3.0.3
2025-12-01 14:41:03,872:INFO:             IPython: 8.37.0
2025-12-01 14:41:03,872:INFO:          ipywidgets: 8.1.8
2025-12-01 14:41:03,872:INFO:                tqdm: 4.67.1
2025-12-01 14:41:03,872:INFO:               numpy: 1.23.5
2025-12-01 14:41:03,872:INFO:              pandas: 1.5.3
2025-12-01 14:41:03,872:INFO:              jinja2: 3.1.6
2025-12-01 14:41:03,872:INFO:               scipy: 1.10.1
2025-12-01 14:41:03,872:INFO:              joblib: 1.2.0
2025-12-01 14:41:03,872:INFO:             sklearn: 1.3.2
2025-12-01 14:41:03,872:INFO:                pyod: 2.0.5
2025-12-01 14:41:03,872:INFO:            imblearn: 0.12.4
2025-12-01 14:41:03,872:INFO:   category_encoders: 2.7.0
2025-12-01 14:41:03,872:INFO:            lightgbm: 4.6.0
2025-12-01 14:41:03,872:INFO:               numba: 0.62.1
2025-12-01 14:41:03,873:INFO:            requests: 2.32.5
2025-12-01 14:41:03,873:INFO:          matplotlib: 3.10.7
2025-12-01 14:41:03,873:INFO:          scikitplot: 0.3.7
2025-12-01 14:41:03,873:INFO:         yellowbrick: 1.5
2025-12-01 14:41:03,873:INFO:              plotly: 6.5.0
2025-12-01 14:41:03,873:INFO:    plotly-resampler: Not installed
2025-12-01 14:41:03,873:INFO:             kaleido: 1.2.0
2025-12-01 14:41:03,873:INFO:           schemdraw: 0.15
2025-12-01 14:41:03,873:INFO:         statsmodels: 0.14.5
2025-12-01 14:41:03,873:INFO:              sktime: 0.40.1
2025-12-01 14:41:03,873:INFO:               tbats: 1.1.3
2025-12-01 14:41:03,873:INFO:            pmdarima: 2.1.1
2025-12-01 14:41:03,873:INFO:              psutil: 7.1.3
2025-12-01 14:41:03,873:INFO:          markupsafe: 3.0.3
2025-12-01 14:41:03,873:INFO:             pickle5: Not installed
2025-12-01 14:41:03,873:INFO:         cloudpickle: 3.1.2
2025-12-01 14:41:03,873:INFO:         deprecation: 2.1.0
2025-12-01 14:41:03,873:INFO:              xxhash: 3.6.0
2025-12-01 14:41:03,873:INFO:           wurlitzer: 3.1.1
2025-12-01 14:41:03,873:INFO:PyCaret optional dependencies:
2025-12-01 14:41:03,942:INFO:                shap: 0.49.1
2025-12-01 14:41:03,942:INFO:           interpret: Not installed
2025-12-01 14:41:03,942:INFO:                umap: Not installed
2025-12-01 14:41:03,942:INFO:    pandas_profiling: Not installed
2025-12-01 14:41:03,942:INFO:  explainerdashboard: Not installed
2025-12-01 14:41:03,942:INFO:             autoviz: Not installed
2025-12-01 14:41:03,942:INFO:           fairlearn: Not installed
2025-12-01 14:41:03,942:INFO:          deepchecks: Not installed
2025-12-01 14:41:03,942:INFO:             xgboost: 2.1.3
2025-12-01 14:41:03,942:INFO:            catboost: Not installed
2025-12-01 14:41:03,942:INFO:              kmodes: Not installed
2025-12-01 14:41:03,942:INFO:             mlxtend: Not installed
2025-12-01 14:41:03,942:INFO:       statsforecast: Not installed
2025-12-01 14:41:03,942:INFO:        tune_sklearn: Not installed
2025-12-01 14:41:03,942:INFO:                 ray: Not installed
2025-12-01 14:41:03,942:INFO:            hyperopt: Not installed
2025-12-01 14:41:03,942:INFO:              optuna: Not installed
2025-12-01 14:41:03,942:INFO:               skopt: Not installed
2025-12-01 14:41:03,943:INFO:              mlflow: Not installed
2025-12-01 14:41:03,943:INFO:              gradio: Not installed
2025-12-01 14:41:03,943:INFO:             fastapi: Not installed
2025-12-01 14:41:03,943:INFO:             uvicorn: Not installed
2025-12-01 14:41:03,943:INFO:              m2cgen: Not installed
2025-12-01 14:41:03,943:INFO:           evidently: Not installed
2025-12-01 14:41:03,943:INFO:               fugue: Not installed
2025-12-01 14:41:03,943:INFO:           streamlit: Not installed
2025-12-01 14:41:03,943:INFO:             prophet: Not installed
2025-12-01 14:41:03,943:INFO:None
2025-12-01 14:41:03,943:INFO:Set up data.
2025-12-01 14:41:03,961:INFO:Set up train/test split.
2025-12-01 14:41:03,966:INFO:Set up index.
2025-12-01 14:41:03,967:INFO:Set up folding strategy.
2025-12-01 14:41:03,967:INFO:Assigning column types.
2025-12-01 14:41:03,971:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-12-01 14:41:04,035:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-12-01 14:41:04,039:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-01 14:41:04,086:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-01 14:41:04,091:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-01 14:41:04,159:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-12-01 14:41:04,160:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-01 14:41:04,202:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-01 14:41:04,206:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-01 14:41:04,206:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-12-01 14:41:04,280:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-01 14:41:04,323:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-01 14:41:04,327:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-01 14:41:04,398:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-01 14:41:04,441:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-01 14:41:04,445:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-01 14:41:04,446:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-12-01 14:41:04,567:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-01 14:41:04,572:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-01 14:41:04,694:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-01 14:41:04,698:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-01 14:41:04,700:INFO:Preparing preprocessing pipeline...
2025-12-01 14:41:04,702:INFO:Set up simple imputation.
2025-12-01 14:41:04,706:INFO:Set up encoding of ordinal features.
2025-12-01 14:41:04,710:INFO:Set up encoding of categorical features.
2025-12-01 14:41:04,711:INFO:Set up removing outliers.
2025-12-01 14:41:04,711:INFO:Set up imbalanced handling.
2025-12-01 14:41:04,711:INFO:Set up feature normalization.
2025-12-01 14:41:04,953:INFO:Finished creating preprocessing pipeline.
2025-12-01 14:41:05,034:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'SystolicBP',
                                             'TotalCholesterol', 'LDL',
                                             'Triglycerides', 'HbA1c',
                                             'Glucose', 'UricAcid',
                                             'Creatinine', 'BMI',
                                             'WaistCircumference', 'Height',
                                             'IncomeRatio', 'ALT_Enzyme',
                                             'AST_Enzyme', 'GGT_Enzyme',
                                             'Albumin', 'Potassium', 'Sodium'],
                                    transform...
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              n_jobs=None,
                                                                              random_state=None,
                                                                              sampling_strategy='auto')))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=RobustScaler(copy=True,
                                                             quantile_range=(25.0,
                                                                             75.0),
                                                             unit_variance=False,
                                                             with_centering=True,
                                                             with_scaling=True)))],
         verbose=False)
2025-12-01 14:41:05,034:INFO:Creating final display dataframe.
2025-12-01 14:41:05,527:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target      HeartDisease
2                   Target type            Binary
3           Original data shape         (437, 27)
4        Transformed data shape         (698, 31)
5   Transformed train set shape         (566, 31)
6    Transformed test set shape         (132, 31)
7              Ordinal features                 2
8              Numeric features                19
9          Categorical features                 7
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16              Remove outliers              True
17           Outliers threshold              0.05
18                Fix imbalance              True
19         Fix imbalance method             SMOTE
20                    Normalize              True
21             Normalize method            robust
22               Fold Generator   StratifiedKFold
23                  Fold Number                10
24                     CPU Jobs                -1
25                      Use GPU             False
26               Log Experiment             False
27              Experiment Name  clf-default-name
28                          USI              93f9
2025-12-01 14:41:05,663:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-01 14:41:05,668:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-01 14:41:05,787:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-01 14:41:05,791:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-01 14:41:05,793:INFO:setup() successfully completed in 1.97s...............
2025-12-01 14:41:05,831:INFO:Initializing compare_models()
2025-12-01 14:41:05,831:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f09a152e3b0>, include=['xgboost', 'lightgbm'], fold=None, round=4, cross_validation=True, sort=Recall, n_select=3, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=False, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x7f09a152e3b0>, 'include': ['xgboost', 'lightgbm'], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Recall', 'n_select': 3, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': False, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2025-12-01 14:41:05,831:INFO:Checking exceptions
2025-12-01 14:41:05,836:INFO:Preparing display monitor
2025-12-01 14:41:05,841:INFO:Initializing Extreme Gradient Boosting
2025-12-01 14:41:05,841:INFO:Total runtime is 2.26895014444987e-06 minutes
2025-12-01 14:41:05,841:INFO:SubProcess create_model() called ==================================
2025-12-01 14:41:05,842:INFO:Initializing create_model()
2025-12-01 14:41:05,842:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f09a152e3b0>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f094af576a0>, model_only=True, return_train_score=False, kwargs={})
2025-12-01 14:41:05,842:INFO:Checking exceptions
2025-12-01 14:41:05,842:INFO:Importing libraries
2025-12-01 14:41:05,842:INFO:Copying training dataset
2025-12-01 14:41:05,848:INFO:Defining folds
2025-12-01 14:41:05,848:INFO:Declaring metric variables
2025-12-01 14:41:05,848:INFO:Importing untrained model
2025-12-01 14:41:05,849:INFO:Extreme Gradient Boosting Imported successfully
2025-12-01 14:41:05,850:INFO:Starting cross validation
2025-12-01 14:41:05,853:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-01 14:41:05,875:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 7 members, which is less than n_splits=10.
  warnings.warn(

2025-12-01 14:41:08,471:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-01 14:41:08,519:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-01 14:41:08,607:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-01 14:41:08,632:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-01 14:41:09,759:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 401, in _score
    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 214, in wrapper
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 627, in roc_auc_score
    return _average_binary_score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-12-01 14:41:09,765:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 14:41:09,768:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 14:41:09,772:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1760: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2025-12-01 14:41:09,773:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:697: RuntimeWarning: invalid value encountered in double_scalars
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-12-01 14:41:09,880:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 401, in _score
    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 214, in wrapper
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 627, in roc_auc_score
    return _average_binary_score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-12-01 14:41:09,882:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 401, in _score
    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 214, in wrapper
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 627, in roc_auc_score
    return _average_binary_score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-12-01 14:41:09,886:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 14:41:09,887:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 14:41:09,891:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 14:41:09,894:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1760: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2025-12-01 14:41:09,896:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:697: RuntimeWarning: invalid value encountered in double_scalars
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-12-01 14:41:10,174:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:425: FitFailedWarning:
5 fits failed out of a total of 10.
The score on these train-test partitions for these parameters will be set to 0.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
4 fits failed with the following error:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/model_selection/_validation.py", line 729, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 255, in fit
    X, y, _ = self._fit(X, y, **fit_params_steps)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 238, in _fit
    X, y = self._memory_transform(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/joblib/memory.py", line 594, in __call__
    return self._cached_call(args, kwargs)[0]
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/memory.py", line 398, in _cached_call
    out, metadata = self.call(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/memory.py", line 309, in call
    output = self.func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 77, in _transform_one
    output = transformer.transform(*args)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 157, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 259, in transform
    output = self.transformer.transform(*args)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 157, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 546, in transform
    X, y = self.estimator.fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/base.py", line 208, in fit_resample
    return super().fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/base.py", line 112, in fit_resample
    output = self._fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/over_sampling/_smote/base.py", line 389, in _fit_resample
    nns = self.nn_k_.kneighbors(X_class, return_distance=False)[:, 1:]
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/neighbors/_base.py", line 808, in kneighbors
    raise ValueError(
ValueError: Expected n_neighbors <= n_samples,  but n_samples = 5, n_neighbors = 6

--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/model_selection/_validation.py", line 729, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 255, in fit
    X, y, _ = self._fit(X, y, **fit_params_steps)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 238, in _fit
    X, y = self._memory_transform(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/joblib/memory.py", line 594, in __call__
    return self._cached_call(args, kwargs)[0]
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/memory.py", line 398, in _cached_call
    out, metadata = self.call(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/memory.py", line 309, in call
    output = self.func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 77, in _transform_one
    output = transformer.transform(*args)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 157, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 259, in transform
    output = self.transformer.transform(*args)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 157, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 546, in transform
    X, y = self.estimator.fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/base.py", line 208, in fit_resample
    return super().fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/base.py", line 112, in fit_resample
    output = self._fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/over_sampling/_smote/base.py", line 389, in _fit_resample
    nns = self.nn_k_.kneighbors(X_class, return_distance=False)[:, 1:]
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/neighbors/_base.py", line 808, in kneighbors
    raise ValueError(
ValueError: Expected n_neighbors <= n_samples,  but n_samples = 4, n_neighbors = 6

  warnings.warn(some_fits_failed_message, FitFailedWarning)

2025-12-01 14:41:10,176:INFO:Calculating mean and std
2025-12-01 14:41:10,177:INFO:Creating metrics dataframe
2025-12-01 14:41:10,198:INFO:Uploading results into container
2025-12-01 14:41:10,199:INFO:Uploading model into container now
2025-12-01 14:41:10,200:INFO:_master_model_container: 1
2025-12-01 14:41:10,200:INFO:_display_container: 2
2025-12-01 14:41:10,201:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2025-12-01 14:41:10,201:INFO:create_model() successfully completed......................................
2025-12-01 14:41:10,358:WARNING:create_model() for XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...) raised an exception or returned all 0.0, trying without fit_kwargs:
2025-12-01 14:41:10,360:WARNING:Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 795, in compare_models
    np.sum(
AssertionError

2025-12-01 14:41:10,360:INFO:Initializing create_model()
2025-12-01 14:41:10,360:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f09a152e3b0>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f094af576a0>, model_only=True, return_train_score=False, kwargs={})
2025-12-01 14:41:10,360:INFO:Checking exceptions
2025-12-01 14:41:10,360:INFO:Importing libraries
2025-12-01 14:41:10,360:INFO:Copying training dataset
2025-12-01 14:41:10,365:INFO:Defining folds
2025-12-01 14:41:10,365:INFO:Declaring metric variables
2025-12-01 14:41:10,366:INFO:Importing untrained model
2025-12-01 14:41:10,367:INFO:Extreme Gradient Boosting Imported successfully
2025-12-01 14:41:10,367:INFO:Starting cross validation
2025-12-01 14:41:10,369:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-01 14:41:10,374:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 7 members, which is less than n_splits=10.
  warnings.warn(

2025-12-01 14:41:11,058:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 401, in _score
    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 214, in wrapper
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 627, in roc_auc_score
    return _average_binary_score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-12-01 14:41:11,061:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 14:41:11,083:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 401, in _score
    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 214, in wrapper
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 627, in roc_auc_score
    return _average_binary_score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-12-01 14:41:11,089:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 14:41:11,212:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 401, in _score
    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 214, in wrapper
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 627, in roc_auc_score
    return _average_binary_score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-12-01 14:41:11,215:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 14:41:11,218:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 14:41:11,221:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1760: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2025-12-01 14:41:11,223:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:697: RuntimeWarning: invalid value encountered in double_scalars
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-12-01 14:41:11,373:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:425: FitFailedWarning:
5 fits failed out of a total of 10.
The score on these train-test partitions for these parameters will be set to 0.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
4 fits failed with the following error:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/model_selection/_validation.py", line 729, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 255, in fit
    X, y, _ = self._fit(X, y, **fit_params_steps)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 238, in _fit
    X, y = self._memory_transform(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/joblib/memory.py", line 594, in __call__
    return self._cached_call(args, kwargs)[0]
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/memory.py", line 398, in _cached_call
    out, metadata = self.call(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/memory.py", line 309, in call
    output = self.func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 77, in _transform_one
    output = transformer.transform(*args)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 157, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 259, in transform
    output = self.transformer.transform(*args)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 157, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 546, in transform
    X, y = self.estimator.fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/base.py", line 208, in fit_resample
    return super().fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/base.py", line 112, in fit_resample
    output = self._fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/over_sampling/_smote/base.py", line 389, in _fit_resample
    nns = self.nn_k_.kneighbors(X_class, return_distance=False)[:, 1:]
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/neighbors/_base.py", line 808, in kneighbors
    raise ValueError(
ValueError: Expected n_neighbors <= n_samples,  but n_samples = 5, n_neighbors = 6

--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/model_selection/_validation.py", line 729, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 255, in fit
    X, y, _ = self._fit(X, y, **fit_params_steps)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 238, in _fit
    X, y = self._memory_transform(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/joblib/memory.py", line 594, in __call__
    return self._cached_call(args, kwargs)[0]
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/memory.py", line 398, in _cached_call
    out, metadata = self.call(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/memory.py", line 309, in call
    output = self.func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 77, in _transform_one
    output = transformer.transform(*args)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 157, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 259, in transform
    output = self.transformer.transform(*args)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 157, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 546, in transform
    X, y = self.estimator.fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/base.py", line 208, in fit_resample
    return super().fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/base.py", line 112, in fit_resample
    output = self._fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/over_sampling/_smote/base.py", line 389, in _fit_resample
    nns = self.nn_k_.kneighbors(X_class, return_distance=False)[:, 1:]
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/neighbors/_base.py", line 808, in kneighbors
    raise ValueError(
ValueError: Expected n_neighbors <= n_samples,  but n_samples = 4, n_neighbors = 6

  warnings.warn(some_fits_failed_message, FitFailedWarning)

2025-12-01 14:41:11,374:INFO:Calculating mean and std
2025-12-01 14:41:11,375:INFO:Creating metrics dataframe
2025-12-01 14:41:11,393:INFO:Uploading results into container
2025-12-01 14:41:11,393:INFO:Uploading model into container now
2025-12-01 14:41:11,394:INFO:_master_model_container: 2
2025-12-01 14:41:11,394:INFO:_display_container: 2
2025-12-01 14:41:11,395:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2025-12-01 14:41:11,395:INFO:create_model() successfully completed......................................
2025-12-01 14:41:11,514:ERROR:create_model() for XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...) raised an exception or returned all 0.0:
2025-12-01 14:41:11,514:ERROR:Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 795, in compare_models
    np.sum(
AssertionError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 811, in compare_models
    np.sum(
AssertionError

2025-12-01 14:41:11,514:INFO:Initializing Light Gradient Boosting Machine
2025-12-01 14:41:11,514:INFO:Total runtime is 0.09455025990804036 minutes
2025-12-01 14:41:11,514:INFO:SubProcess create_model() called ==================================
2025-12-01 14:41:11,515:INFO:Initializing create_model()
2025-12-01 14:41:11,515:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f09a152e3b0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f094af576a0>, model_only=True, return_train_score=False, kwargs={})
2025-12-01 14:41:11,515:INFO:Checking exceptions
2025-12-01 14:41:11,515:INFO:Importing libraries
2025-12-01 14:41:11,515:INFO:Copying training dataset
2025-12-01 14:41:11,519:INFO:Defining folds
2025-12-01 14:41:11,519:INFO:Declaring metric variables
2025-12-01 14:41:11,520:INFO:Importing untrained model
2025-12-01 14:41:11,520:INFO:Light Gradient Boosting Machine Imported successfully
2025-12-01 14:41:11,521:INFO:Starting cross validation
2025-12-01 14:41:11,523:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-01 14:41:11,527:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 7 members, which is less than n_splits=10.
  warnings.warn(

2025-12-01 14:41:38,661:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 401, in _score
    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 214, in wrapper
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 627, in roc_auc_score
    return _average_binary_score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-12-01 14:41:38,674:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 14:43:41,497:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 401, in _score
    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 214, in wrapper
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 627, in roc_auc_score
    return _average_binary_score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-12-01 14:43:41,508:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 14:43:41,520:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 14:43:41,531:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1760: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2025-12-01 14:43:41,533:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:697: RuntimeWarning: invalid value encountered in double_scalars
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-12-01 14:44:08,699:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.61s to run.
If this happens often in your code, it can cause performance problems
(results will be correct in all cases).
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2025-12-01 14:44:08,789:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 401, in _score
    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 214, in wrapper
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 627, in roc_auc_score
    return _average_binary_score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-12-01 14:44:08,801:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 14:44:08,810:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 14:44:08,817:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1760: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2025-12-01 14:44:08,823:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:697: RuntimeWarning: invalid value encountered in double_scalars
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-12-01 14:44:15,922:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:425: FitFailedWarning:
5 fits failed out of a total of 10.
The score on these train-test partitions for these parameters will be set to 0.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
4 fits failed with the following error:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/model_selection/_validation.py", line 729, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 255, in fit
    X, y, _ = self._fit(X, y, **fit_params_steps)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 238, in _fit
    X, y = self._memory_transform(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/joblib/memory.py", line 594, in __call__
    return self._cached_call(args, kwargs)[0]
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/memory.py", line 398, in _cached_call
    out, metadata = self.call(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/memory.py", line 309, in call
    output = self.func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 77, in _transform_one
    output = transformer.transform(*args)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 157, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 259, in transform
    output = self.transformer.transform(*args)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 157, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 546, in transform
    X, y = self.estimator.fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/base.py", line 208, in fit_resample
    return super().fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/base.py", line 112, in fit_resample
    output = self._fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/over_sampling/_smote/base.py", line 389, in _fit_resample
    nns = self.nn_k_.kneighbors(X_class, return_distance=False)[:, 1:]
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/neighbors/_base.py", line 808, in kneighbors
    raise ValueError(
ValueError: Expected n_neighbors <= n_samples,  but n_samples = 5, n_neighbors = 6

--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/model_selection/_validation.py", line 729, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 255, in fit
    X, y, _ = self._fit(X, y, **fit_params_steps)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 238, in _fit
    X, y = self._memory_transform(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/joblib/memory.py", line 594, in __call__
    return self._cached_call(args, kwargs)[0]
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/memory.py", line 398, in _cached_call
    out, metadata = self.call(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/memory.py", line 309, in call
    output = self.func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 77, in _transform_one
    output = transformer.transform(*args)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 157, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 259, in transform
    output = self.transformer.transform(*args)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 157, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 546, in transform
    X, y = self.estimator.fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/base.py", line 208, in fit_resample
    return super().fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/base.py", line 112, in fit_resample
    output = self._fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/over_sampling/_smote/base.py", line 389, in _fit_resample
    nns = self.nn_k_.kneighbors(X_class, return_distance=False)[:, 1:]
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/neighbors/_base.py", line 808, in kneighbors
    raise ValueError(
ValueError: Expected n_neighbors <= n_samples,  but n_samples = 4, n_neighbors = 6

  warnings.warn(some_fits_failed_message, FitFailedWarning)

2025-12-01 14:44:15,924:INFO:Calculating mean and std
2025-12-01 14:44:15,924:INFO:Creating metrics dataframe
2025-12-01 14:44:15,951:INFO:Uploading results into container
2025-12-01 14:44:15,952:INFO:Uploading model into container now
2025-12-01 14:44:15,952:INFO:_master_model_container: 3
2025-12-01 14:44:15,953:INFO:_display_container: 2
2025-12-01 14:44:15,954:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-12-01 14:44:15,954:INFO:create_model() successfully completed......................................
2025-12-01 14:44:16,095:WARNING:create_model() for LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) raised an exception or returned all 0.0, trying without fit_kwargs:
2025-12-01 14:44:16,095:WARNING:Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 795, in compare_models
    np.sum(
AssertionError

2025-12-01 14:44:16,096:INFO:Initializing create_model()
2025-12-01 14:44:16,096:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f09a152e3b0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f094af576a0>, model_only=True, return_train_score=False, kwargs={})
2025-12-01 14:44:16,096:INFO:Checking exceptions
2025-12-01 14:44:16,096:INFO:Importing libraries
2025-12-01 14:44:16,096:INFO:Copying training dataset
2025-12-01 14:44:16,101:INFO:Defining folds
2025-12-01 14:44:16,101:INFO:Declaring metric variables
2025-12-01 14:44:16,101:INFO:Importing untrained model
2025-12-01 14:44:16,102:INFO:Light Gradient Boosting Machine Imported successfully
2025-12-01 14:44:16,103:INFO:Starting cross validation
2025-12-01 14:44:16,105:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-01 14:44:16,111:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 7 members, which is less than n_splits=10.
  warnings.warn(

2025-12-01 14:44:50,089:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 401, in _score
    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 214, in wrapper
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 627, in roc_auc_score
    return _average_binary_score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-12-01 14:44:50,101:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 14:44:50,113:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 14:44:50,124:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1760: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2025-12-01 14:44:50,126:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:697: RuntimeWarning: invalid value encountered in double_scalars
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-12-01 14:46:31,557:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 401, in _score
    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 214, in wrapper
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 627, in roc_auc_score
    return _average_binary_score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-12-01 14:46:31,570:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 14:46:54,560:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 401, in _score
    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 214, in wrapper
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 627, in roc_auc_score
    return _average_binary_score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-12-01 14:46:54,563:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 14:46:54,566:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 14:46:54,569:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1760: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2025-12-01 14:46:54,571:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:697: RuntimeWarning: invalid value encountered in double_scalars
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-12-01 14:46:54,574:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:425: FitFailedWarning:
5 fits failed out of a total of 10.
The score on these train-test partitions for these parameters will be set to 0.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
4 fits failed with the following error:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/model_selection/_validation.py", line 729, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 255, in fit
    X, y, _ = self._fit(X, y, **fit_params_steps)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 238, in _fit
    X, y = self._memory_transform(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/joblib/memory.py", line 594, in __call__
    return self._cached_call(args, kwargs)[0]
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/memory.py", line 398, in _cached_call
    out, metadata = self.call(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/memory.py", line 309, in call
    output = self.func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 77, in _transform_one
    output = transformer.transform(*args)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 157, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 259, in transform
    output = self.transformer.transform(*args)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 157, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 546, in transform
    X, y = self.estimator.fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/base.py", line 208, in fit_resample
    return super().fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/base.py", line 112, in fit_resample
    output = self._fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/over_sampling/_smote/base.py", line 389, in _fit_resample
    nns = self.nn_k_.kneighbors(X_class, return_distance=False)[:, 1:]
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/neighbors/_base.py", line 808, in kneighbors
    raise ValueError(
ValueError: Expected n_neighbors <= n_samples,  but n_samples = 5, n_neighbors = 6

--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/model_selection/_validation.py", line 729, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 255, in fit
    X, y, _ = self._fit(X, y, **fit_params_steps)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 238, in _fit
    X, y = self._memory_transform(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/joblib/memory.py", line 594, in __call__
    return self._cached_call(args, kwargs)[0]
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/memory.py", line 398, in _cached_call
    out, metadata = self.call(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/memory.py", line 309, in call
    output = self.func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 77, in _transform_one
    output = transformer.transform(*args)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 157, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 259, in transform
    output = self.transformer.transform(*args)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 157, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 546, in transform
    X, y = self.estimator.fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/base.py", line 208, in fit_resample
    return super().fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/base.py", line 112, in fit_resample
    output = self._fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/over_sampling/_smote/base.py", line 389, in _fit_resample
    nns = self.nn_k_.kneighbors(X_class, return_distance=False)[:, 1:]
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/neighbors/_base.py", line 808, in kneighbors
    raise ValueError(
ValueError: Expected n_neighbors <= n_samples,  but n_samples = 4, n_neighbors = 6

  warnings.warn(some_fits_failed_message, FitFailedWarning)

2025-12-01 14:46:54,576:INFO:Calculating mean and std
2025-12-01 14:46:54,576:INFO:Creating metrics dataframe
2025-12-01 14:46:54,603:INFO:Uploading results into container
2025-12-01 14:46:54,604:INFO:Uploading model into container now
2025-12-01 14:46:54,605:INFO:_master_model_container: 4
2025-12-01 14:46:54,605:INFO:_display_container: 2
2025-12-01 14:46:54,606:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-12-01 14:46:54,606:INFO:create_model() successfully completed......................................
2025-12-01 14:46:54,721:ERROR:create_model() for LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) raised an exception or returned all 0.0:
2025-12-01 14:46:54,721:ERROR:Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 795, in compare_models
    np.sum(
AssertionError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 811, in compare_models
    np.sum(
AssertionError

2025-12-01 14:46:54,722:INFO:_master_model_container: 4
2025-12-01 14:46:54,722:INFO:_display_container: 2
2025-12-01 14:46:54,722:INFO:[]
2025-12-01 14:46:54,722:INFO:compare_models() successfully completed......................................
2025-12-01 14:57:17,776:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-12-01 14:57:17,777:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-12-01 14:57:17,777:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-12-01 14:57:17,777:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-12-01 14:57:18,291:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2025-12-01 14:57:18,664:INFO:PyCaret ClassificationExperiment
2025-12-01 14:57:18,664:INFO:Logging name: clf-default-name
2025-12-01 14:57:18,664:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-12-01 14:57:18,664:INFO:version 3.0.3
2025-12-01 14:57:18,664:INFO:Initializing setup()
2025-12-01 14:57:18,664:INFO:self.USI: e55e
2025-12-01 14:57:18,664:INFO:self._variable_keys: {'y', 'X', 'USI', 'logging_param', 'is_multiclass', 'log_plots_param', 'X_train', 'gpu_param', 'pipeline', 'idx', 'fold_generator', 'fix_imbalance', 'fold_groups_param', 'fold_shuffle_param', 'X_test', 'memory', 'data', 'exp_name_log', 'n_jobs_param', '_available_plots', 'seed', '_ml_usecase', 'gpu_n_jobs_param', 'target_param', 'y_test', 'exp_id', 'html_param', 'y_train'}
2025-12-01 14:57:18,665:INFO:Checking environment
2025-12-01 14:57:18,665:INFO:python_version: 3.10.19
2025-12-01 14:57:18,665:INFO:python_build: ('main', 'Nov  7 2025 00:05:37')
2025-12-01 14:57:18,665:INFO:machine: x86_64
2025-12-01 14:57:18,665:INFO:platform: Linux-6.8.0-x86_64-with-glibc2.39
2025-12-01 14:57:18,665:INFO:Memory: svmem(total=8345706496, available=7591936000, percent=9.0, used=753770496, free=4167172096, active=404787200, inactive=3462168576, buffers=76161024, cached=3661107200, shared=589824, slab=253845504)
2025-12-01 14:57:18,666:INFO:Physical Core: 4
2025-12-01 14:57:18,666:INFO:Logical Core: 4
2025-12-01 14:57:18,666:INFO:Checking libraries
2025-12-01 14:57:18,666:INFO:System:
2025-12-01 14:57:18,666:INFO:    python: 3.10.19 (main, Nov  7 2025, 00:05:37) [GCC 13.3.0]
2025-12-01 14:57:18,666:INFO:executable: /home/jules/.pyenv/versions/3.10.19/bin/python3.10
2025-12-01 14:57:18,666:INFO:   machine: Linux-6.8.0-x86_64-with-glibc2.39
2025-12-01 14:57:18,666:INFO:PyCaret required dependencies:
2025-12-01 14:57:18,668:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-01 14:57:18,703:INFO:                 pip: 25.3
2025-12-01 14:57:18,703:INFO:          setuptools: 79.0.1
2025-12-01 14:57:18,704:INFO:             pycaret: 3.0.3
2025-12-01 14:57:18,704:INFO:             IPython: 8.37.0
2025-12-01 14:57:18,704:INFO:          ipywidgets: 8.1.8
2025-12-01 14:57:18,704:INFO:                tqdm: 4.67.1
2025-12-01 14:57:18,704:INFO:               numpy: 1.23.5
2025-12-01 14:57:18,704:INFO:              pandas: 1.5.3
2025-12-01 14:57:18,704:INFO:              jinja2: 3.1.6
2025-12-01 14:57:18,704:INFO:               scipy: 1.10.1
2025-12-01 14:57:18,704:INFO:              joblib: 1.2.0
2025-12-01 14:57:18,704:INFO:             sklearn: 1.3.2
2025-12-01 14:57:18,704:INFO:                pyod: 2.0.5
2025-12-01 14:57:18,704:INFO:            imblearn: 0.12.4
2025-12-01 14:57:18,704:INFO:   category_encoders: 2.7.0
2025-12-01 14:57:18,704:INFO:            lightgbm: 4.6.0
2025-12-01 14:57:18,704:INFO:               numba: 0.62.1
2025-12-01 14:57:18,704:INFO:            requests: 2.32.5
2025-12-01 14:57:18,704:INFO:          matplotlib: 3.10.7
2025-12-01 14:57:18,704:INFO:          scikitplot: 0.3.7
2025-12-01 14:57:18,704:INFO:         yellowbrick: 1.5
2025-12-01 14:57:18,704:INFO:              plotly: 6.5.0
2025-12-01 14:57:18,704:INFO:    plotly-resampler: Not installed
2025-12-01 14:57:18,704:INFO:             kaleido: 1.2.0
2025-12-01 14:57:18,704:INFO:           schemdraw: 0.15
2025-12-01 14:57:18,704:INFO:         statsmodels: 0.14.5
2025-12-01 14:57:18,704:INFO:              sktime: 0.40.1
2025-12-01 14:57:18,705:INFO:               tbats: 1.1.3
2025-12-01 14:57:18,705:INFO:            pmdarima: 2.1.1
2025-12-01 14:57:18,705:INFO:              psutil: 7.1.3
2025-12-01 14:57:18,705:INFO:          markupsafe: 3.0.3
2025-12-01 14:57:18,705:INFO:             pickle5: Not installed
2025-12-01 14:57:18,705:INFO:         cloudpickle: 3.1.2
2025-12-01 14:57:18,705:INFO:         deprecation: 2.1.0
2025-12-01 14:57:18,705:INFO:              xxhash: 3.6.0
2025-12-01 14:57:18,705:INFO:           wurlitzer: 3.1.1
2025-12-01 14:57:18,705:INFO:PyCaret optional dependencies:
2025-12-01 14:57:18,764:INFO:                shap: 0.49.1
2025-12-01 14:57:18,765:INFO:           interpret: Not installed
2025-12-01 14:57:18,765:INFO:                umap: Not installed
2025-12-01 14:57:18,765:INFO:    pandas_profiling: Not installed
2025-12-01 14:57:18,765:INFO:  explainerdashboard: Not installed
2025-12-01 14:57:18,765:INFO:             autoviz: Not installed
2025-12-01 14:57:18,765:INFO:           fairlearn: Not installed
2025-12-01 14:57:18,765:INFO:          deepchecks: Not installed
2025-12-01 14:57:18,765:INFO:             xgboost: 2.1.3
2025-12-01 14:57:18,765:INFO:            catboost: Not installed
2025-12-01 14:57:18,765:INFO:              kmodes: Not installed
2025-12-01 14:57:18,765:INFO:             mlxtend: Not installed
2025-12-01 14:57:18,765:INFO:       statsforecast: Not installed
2025-12-01 14:57:18,765:INFO:        tune_sklearn: Not installed
2025-12-01 14:57:18,765:INFO:                 ray: Not installed
2025-12-01 14:57:18,765:INFO:            hyperopt: Not installed
2025-12-01 14:57:18,765:INFO:              optuna: Not installed
2025-12-01 14:57:18,765:INFO:               skopt: Not installed
2025-12-01 14:57:18,765:INFO:              mlflow: Not installed
2025-12-01 14:57:18,765:INFO:              gradio: Not installed
2025-12-01 14:57:18,765:INFO:             fastapi: Not installed
2025-12-01 14:57:18,765:INFO:             uvicorn: Not installed
2025-12-01 14:57:18,765:INFO:              m2cgen: Not installed
2025-12-01 14:57:18,765:INFO:           evidently: Not installed
2025-12-01 14:57:18,765:INFO:               fugue: Not installed
2025-12-01 14:57:18,766:INFO:           streamlit: Not installed
2025-12-01 14:57:18,766:INFO:             prophet: Not installed
2025-12-01 14:57:18,766:INFO:None
2025-12-01 14:57:18,766:INFO:Set up data.
2025-12-01 14:57:18,780:INFO:Set up train/test split.
2025-12-01 14:57:18,785:INFO:Set up index.
2025-12-01 14:57:18,786:INFO:Set up folding strategy.
2025-12-01 14:57:18,786:INFO:Assigning column types.
2025-12-01 14:57:18,789:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-12-01 14:57:18,850:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-12-01 14:57:18,854:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-01 14:57:18,898:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-01 14:57:18,902:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-01 14:57:18,962:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-12-01 14:57:18,964:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-01 14:57:19,002:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-01 14:57:19,005:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-01 14:57:19,006:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-12-01 14:57:19,068:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-01 14:57:19,106:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-01 14:57:19,109:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-01 14:57:19,172:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-01 14:57:19,209:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-01 14:57:19,213:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-01 14:57:19,213:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-12-01 14:57:19,313:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-01 14:57:19,316:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-01 14:57:19,416:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-01 14:57:19,419:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-01 14:57:19,422:INFO:Preparing preprocessing pipeline...
2025-12-01 14:57:19,423:INFO:Set up simple imputation.
2025-12-01 14:57:19,427:INFO:Set up encoding of ordinal features.
2025-12-01 14:57:19,431:INFO:Set up encoding of categorical features.
2025-12-01 14:57:19,431:INFO:Set up removing outliers.
2025-12-01 14:57:19,431:INFO:Set up imbalanced handling.
2025-12-01 14:57:19,431:INFO:Set up feature normalization.
2025-12-01 14:57:19,652:INFO:Finished creating preprocessing pipeline.
2025-12-01 14:57:19,724:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'SystolicBP',
                                             'TotalCholesterol', 'LDL',
                                             'Triglycerides', 'HbA1c',
                                             'Glucose', 'UricAcid',
                                             'Creatinine', 'BMI',
                                             'WaistCircumference', 'Height',
                                             'IncomeRatio', 'ALT_Enzyme',
                                             'AST_Enzyme', 'GGT_Enzyme',
                                             'Albumin', 'Potassium', 'Sodium'],
                                    transform...
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              n_jobs=None,
                                                                              random_state=None,
                                                                              sampling_strategy='auto')))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=RobustScaler(copy=True,
                                                             quantile_range=(25.0,
                                                                             75.0),
                                                             unit_variance=False,
                                                             with_centering=True,
                                                             with_scaling=True)))],
         verbose=False)
2025-12-01 14:57:19,724:INFO:Creating final display dataframe.
2025-12-01 14:57:19,955:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target      HeartDisease
2                   Target type            Binary
3           Original data shape         (437, 27)
4        Transformed data shape         (698, 31)
5   Transformed train set shape         (566, 31)
6    Transformed test set shape         (132, 31)
7              Ordinal features                 2
8              Numeric features                19
9          Categorical features                 7
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16              Remove outliers              True
17           Outliers threshold              0.05
18                Fix imbalance              True
19         Fix imbalance method             SMOTE
20                    Normalize              True
21             Normalize method            robust
22               Fold Generator   StratifiedKFold
23                  Fold Number                10
24                     CPU Jobs                 1
25                      Use GPU             False
26               Log Experiment             False
27              Experiment Name  clf-default-name
28                          USI              e55e
2025-12-01 14:57:20,071:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-01 14:57:20,074:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-01 14:57:20,175:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-01 14:57:20,179:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-01 14:57:20,181:INFO:setup() successfully completed in 1.52s...............
2025-12-01 14:57:20,217:INFO:Initializing compare_models()
2025-12-01 14:57:20,217:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f125b6effa0>, include=['xgboost', 'lightgbm'], fold=None, round=4, cross_validation=True, sort=Recall, n_select=3, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=False, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x7f125b6effa0>, 'include': ['xgboost', 'lightgbm'], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Recall', 'n_select': 3, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': False, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2025-12-01 14:57:20,217:INFO:Checking exceptions
2025-12-01 14:57:20,222:INFO:Preparing display monitor
2025-12-01 14:57:20,227:INFO:Initializing Extreme Gradient Boosting
2025-12-01 14:57:20,227:INFO:Total runtime is 2.2252400716145835e-06 minutes
2025-12-01 14:57:20,227:INFO:SubProcess create_model() called ==================================
2025-12-01 14:57:20,228:INFO:Initializing create_model()
2025-12-01 14:57:20,228:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f125b6effa0>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f125b6efa00>, model_only=True, return_train_score=False, kwargs={})
2025-12-01 14:57:20,228:INFO:Checking exceptions
2025-12-01 14:57:20,228:INFO:Importing libraries
2025-12-01 14:57:20,228:INFO:Copying training dataset
2025-12-01 14:57:20,233:INFO:Defining folds
2025-12-01 14:57:20,233:INFO:Declaring metric variables
2025-12-01 14:57:20,233:INFO:Importing untrained model
2025-12-01 14:57:20,238:INFO:Extreme Gradient Boosting Imported successfully
2025-12-01 14:57:20,238:INFO:Starting cross validation
2025-12-01 14:57:20,241:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-12-01 14:57:20,246:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 7 members, which is less than n_splits=10.
  warnings.warn(

2025-12-01 14:57:21,770:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 401, in _score
    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 214, in wrapper
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 627, in roc_auc_score
    return _average_binary_score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-12-01 14:57:21,773:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 14:57:22,251:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 401, in _score
    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 214, in wrapper
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 627, in roc_auc_score
    return _average_binary_score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-12-01 14:57:22,255:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 14:57:22,718:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 401, in _score
    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 214, in wrapper
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 627, in roc_auc_score
    return _average_binary_score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-12-01 14:57:22,722:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 14:57:22,725:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 14:57:22,728:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1760: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2025-12-01 14:57:22,730:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:697: RuntimeWarning: invalid value encountered in double_scalars
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-12-01 14:57:23,328:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:425: FitFailedWarning:
5 fits failed out of a total of 10.
The score on these train-test partitions for these parameters will be set to 0.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
4 fits failed with the following error:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/model_selection/_validation.py", line 729, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 255, in fit
    X, y, _ = self._fit(X, y, **fit_params_steps)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 238, in _fit
    X, y = self._memory_transform(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/joblib/memory.py", line 594, in __call__
    return self._cached_call(args, kwargs)[0]
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/memory.py", line 398, in _cached_call
    out, metadata = self.call(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/memory.py", line 309, in call
    output = self.func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 77, in _transform_one
    output = transformer.transform(*args)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 157, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 259, in transform
    output = self.transformer.transform(*args)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 157, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 546, in transform
    X, y = self.estimator.fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/base.py", line 208, in fit_resample
    return super().fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/base.py", line 112, in fit_resample
    output = self._fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/over_sampling/_smote/base.py", line 389, in _fit_resample
    nns = self.nn_k_.kneighbors(X_class, return_distance=False)[:, 1:]
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/neighbors/_base.py", line 808, in kneighbors
    raise ValueError(
ValueError: Expected n_neighbors <= n_samples,  but n_samples = 5, n_neighbors = 6

--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/model_selection/_validation.py", line 729, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 255, in fit
    X, y, _ = self._fit(X, y, **fit_params_steps)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 238, in _fit
    X, y = self._memory_transform(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/joblib/memory.py", line 594, in __call__
    return self._cached_call(args, kwargs)[0]
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/memory.py", line 398, in _cached_call
    out, metadata = self.call(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/memory.py", line 309, in call
    output = self.func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 77, in _transform_one
    output = transformer.transform(*args)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 157, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 259, in transform
    output = self.transformer.transform(*args)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 157, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 546, in transform
    X, y = self.estimator.fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/base.py", line 208, in fit_resample
    return super().fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/base.py", line 112, in fit_resample
    output = self._fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/over_sampling/_smote/base.py", line 389, in _fit_resample
    nns = self.nn_k_.kneighbors(X_class, return_distance=False)[:, 1:]
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/neighbors/_base.py", line 808, in kneighbors
    raise ValueError(
ValueError: Expected n_neighbors <= n_samples,  but n_samples = 4, n_neighbors = 6

  warnings.warn(some_fits_failed_message, FitFailedWarning)

2025-12-01 14:57:23,329:INFO:Calculating mean and std
2025-12-01 14:57:23,329:INFO:Creating metrics dataframe
2025-12-01 14:57:23,340:INFO:Uploading results into container
2025-12-01 14:57:23,340:INFO:Uploading model into container now
2025-12-01 14:57:23,341:INFO:_master_model_container: 1
2025-12-01 14:57:23,341:INFO:_display_container: 2
2025-12-01 14:57:23,342:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2025-12-01 14:57:23,342:INFO:create_model() successfully completed......................................
2025-12-01 14:57:23,462:WARNING:create_model() for XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...) raised an exception or returned all 0.0, trying without fit_kwargs:
2025-12-01 14:57:23,464:WARNING:Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 795, in compare_models
    np.sum(
AssertionError

2025-12-01 14:57:23,464:INFO:Initializing create_model()
2025-12-01 14:57:23,464:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f125b6effa0>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f125b6efa00>, model_only=True, return_train_score=False, kwargs={})
2025-12-01 14:57:23,464:INFO:Checking exceptions
2025-12-01 14:57:23,464:INFO:Importing libraries
2025-12-01 14:57:23,464:INFO:Copying training dataset
2025-12-01 14:57:23,468:INFO:Defining folds
2025-12-01 14:57:23,469:INFO:Declaring metric variables
2025-12-01 14:57:23,469:INFO:Importing untrained model
2025-12-01 14:57:23,470:INFO:Extreme Gradient Boosting Imported successfully
2025-12-01 14:57:23,470:INFO:Starting cross validation
2025-12-01 14:57:23,472:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-12-01 14:57:23,476:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 7 members, which is less than n_splits=10.
  warnings.warn(

2025-12-01 14:57:24,934:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 795, in compare_models
    np.sum(
AssertionError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 401, in _score
    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 214, in wrapper
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 627, in roc_auc_score
    return _average_binary_score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-12-01 14:57:24,937:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 14:57:25,389:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 795, in compare_models
    np.sum(
AssertionError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 401, in _score
    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 214, in wrapper
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 627, in roc_auc_score
    return _average_binary_score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-12-01 14:57:25,392:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 14:57:25,849:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 795, in compare_models
    np.sum(
AssertionError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 401, in _score
    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 214, in wrapper
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 627, in roc_auc_score
    return _average_binary_score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-12-01 14:57:25,852:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 14:57:25,856:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 14:57:25,859:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1760: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2025-12-01 14:57:25,861:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:697: RuntimeWarning: invalid value encountered in double_scalars
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-12-01 14:57:26,464:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:425: FitFailedWarning:
5 fits failed out of a total of 10.
The score on these train-test partitions for these parameters will be set to 0.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
4 fits failed with the following error:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 795, in compare_models
    np.sum(
AssertionError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/model_selection/_validation.py", line 729, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 255, in fit
    X, y, _ = self._fit(X, y, **fit_params_steps)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 238, in _fit
    X, y = self._memory_transform(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/joblib/memory.py", line 594, in __call__
    return self._cached_call(args, kwargs)[0]
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/memory.py", line 398, in _cached_call
    out, metadata = self.call(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/memory.py", line 309, in call
    output = self.func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 77, in _transform_one
    output = transformer.transform(*args)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 157, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 259, in transform
    output = self.transformer.transform(*args)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 157, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 546, in transform
    X, y = self.estimator.fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/base.py", line 208, in fit_resample
    return super().fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/base.py", line 112, in fit_resample
    output = self._fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/over_sampling/_smote/base.py", line 389, in _fit_resample
    nns = self.nn_k_.kneighbors(X_class, return_distance=False)[:, 1:]
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/neighbors/_base.py", line 808, in kneighbors
    raise ValueError(
ValueError: Expected n_neighbors <= n_samples,  but n_samples = 5, n_neighbors = 6

--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 795, in compare_models
    np.sum(
AssertionError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/model_selection/_validation.py", line 729, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 255, in fit
    X, y, _ = self._fit(X, y, **fit_params_steps)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 238, in _fit
    X, y = self._memory_transform(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/joblib/memory.py", line 594, in __call__
    return self._cached_call(args, kwargs)[0]
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/memory.py", line 398, in _cached_call
    out, metadata = self.call(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/memory.py", line 309, in call
    output = self.func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 77, in _transform_one
    output = transformer.transform(*args)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 157, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 259, in transform
    output = self.transformer.transform(*args)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 157, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 546, in transform
    X, y = self.estimator.fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/base.py", line 208, in fit_resample
    return super().fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/base.py", line 112, in fit_resample
    output = self._fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/over_sampling/_smote/base.py", line 389, in _fit_resample
    nns = self.nn_k_.kneighbors(X_class, return_distance=False)[:, 1:]
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/neighbors/_base.py", line 808, in kneighbors
    raise ValueError(
ValueError: Expected n_neighbors <= n_samples,  but n_samples = 4, n_neighbors = 6

  warnings.warn(some_fits_failed_message, FitFailedWarning)

2025-12-01 14:57:26,466:INFO:Calculating mean and std
2025-12-01 14:57:26,466:INFO:Creating metrics dataframe
2025-12-01 14:57:26,476:INFO:Uploading results into container
2025-12-01 14:57:26,477:INFO:Uploading model into container now
2025-12-01 14:57:26,477:INFO:_master_model_container: 2
2025-12-01 14:57:26,477:INFO:_display_container: 2
2025-12-01 14:57:26,478:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2025-12-01 14:57:26,478:INFO:create_model() successfully completed......................................
2025-12-01 14:57:26,595:ERROR:create_model() for XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...) raised an exception or returned all 0.0:
2025-12-01 14:57:26,595:ERROR:Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 795, in compare_models
    np.sum(
AssertionError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 811, in compare_models
    np.sum(
AssertionError

2025-12-01 14:57:26,595:INFO:Initializing Light Gradient Boosting Machine
2025-12-01 14:57:26,596:INFO:Total runtime is 0.10614464282989501 minutes
2025-12-01 14:57:26,596:INFO:SubProcess create_model() called ==================================
2025-12-01 14:57:26,596:INFO:Initializing create_model()
2025-12-01 14:57:26,596:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f125b6effa0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f125b6efa00>, model_only=True, return_train_score=False, kwargs={})
2025-12-01 14:57:26,596:INFO:Checking exceptions
2025-12-01 14:57:26,596:INFO:Importing libraries
2025-12-01 14:57:26,596:INFO:Copying training dataset
2025-12-01 14:57:26,601:INFO:Defining folds
2025-12-01 14:57:26,601:INFO:Declaring metric variables
2025-12-01 14:57:26,601:INFO:Importing untrained model
2025-12-01 14:57:26,602:INFO:Light Gradient Boosting Machine Imported successfully
2025-12-01 14:57:26,602:INFO:Starting cross validation
2025-12-01 14:57:26,604:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-12-01 14:57:26,608:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 7 members, which is less than n_splits=10.
  warnings.warn(

2025-12-01 14:57:27,075:INFO:[LightGBM] [Info] Number of positive: 254, number of negative: 254
2025-12-01 14:57:27,075:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000113 seconds.
2025-12-01 14:57:27,075:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-01 14:57:27,075:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-01 14:57:27,077:INFO:[LightGBM] [Info] Total Bins 3657
2025-12-01 14:57:27,077:INFO:[LightGBM] [Info] Number of data points in the train set: 508, number of used features: 30
2025-12-01 14:57:27,078:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-01 14:57:27,078:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:27,079:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:27,080:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:27,081:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:27,082:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:27,083:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:27,084:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:27,085:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:27,086:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:27,087:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:27,088:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:27,090:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:27,091:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:27,092:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:27,093:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:27,095:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:27,096:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:27,097:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:27,098:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:27,100:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:27,101:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:27,102:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:27,104:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:27,105:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:27,106:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:27,107:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:27,109:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:27,110:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:27,111:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:27,113:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:27,114:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:27,115:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:27,117:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:27,118:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:27,120:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:27,121:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:27,122:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:27,124:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:27,125:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:27,127:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:27,128:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:27,130:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:27,131:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:27,132:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:27,133:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:27,135:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:27,136:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:27,137:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:27,139:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:27,140:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:27,141:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:27,143:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:27,144:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:27,146:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:27,147:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:27,149:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:27,150:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:27,151:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:27,153:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:27,154:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:27,156:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:27,157:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:27,159:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:27,160:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:27,162:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:27,163:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:27,164:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:27,166:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:27,167:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:27,169:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:27,170:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:27,171:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:27,173:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:27,174:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:27,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:27,178:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:27,179:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:27,181:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:27,182:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:27,183:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:27,185:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:27,186:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:27,188:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:27,189:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:27,191:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:27,192:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:27,194:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:27,195:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:27,197:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:27,198:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:27,200:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:27,201:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:27,203:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:27,204:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:27,206:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:27,207:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:27,208:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:27,210:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:27,211:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:27,212:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:27,924:INFO:[LightGBM] [Info] Number of positive: 255, number of negative: 255
2025-12-01 14:57:27,924:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000185 seconds.
2025-12-01 14:57:27,924:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-01 14:57:27,926:INFO:[LightGBM] [Info] Total Bins 3717
2025-12-01 14:57:27,926:INFO:[LightGBM] [Info] Number of data points in the train set: 510, number of used features: 30
2025-12-01 14:57:27,926:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-01 14:57:27,927:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:27,928:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:27,929:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:27,930:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:27,931:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:27,932:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:27,933:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:27,935:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:27,936:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:27,937:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:27,939:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:27,940:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:27,941:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:27,943:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:27,944:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:27,946:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:27,947:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:27,948:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:27,950:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:27,951:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:27,952:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:27,954:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:27,955:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:27,957:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:27,958:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:27,960:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:27,961:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:27,963:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:27,964:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:27,966:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:27,967:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:27,968:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:27,970:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:27,971:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:27,973:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:27,974:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:27,976:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:27,977:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:27,978:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:27,980:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:27,982:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:27,983:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:27,984:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:27,986:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:27,987:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:27,989:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:27,990:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:27,992:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:27,993:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:27,995:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:27,996:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:27,998:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:27,999:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:28,001:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:28,002:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:28,004:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:28,005:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:28,007:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:28,008:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:28,010:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:28,012:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:28,013:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:28,015:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:28,016:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:28,018:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:28,019:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:28,021:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:28,022:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:28,024:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:28,025:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:28,027:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:28,028:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:28,030:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:28,031:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:28,033:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:28,034:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:28,036:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:28,037:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:28,039:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:28,040:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:28,042:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:28,044:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:28,045:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:28,047:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:28,048:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:28,050:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:28,051:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:28,057:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:28,058:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:28,060:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:28,061:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:28,063:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:28,064:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:28,066:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:28,067:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:28,069:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:28,070:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:28,072:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:28,294:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 401, in _score
    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 214, in wrapper
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 627, in roc_auc_score
    return _average_binary_score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-12-01 14:57:28,297:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 14:57:28,301:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 14:57:28,304:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1760: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2025-12-01 14:57:28,306:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:697: RuntimeWarning: invalid value encountered in double_scalars
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-12-01 14:57:28,494:INFO:[LightGBM] [Info] Number of positive: 254, number of negative: 254
2025-12-01 14:57:28,495:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000105 seconds.
2025-12-01 14:57:28,495:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-01 14:57:28,495:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-01 14:57:28,497:INFO:[LightGBM] [Info] Total Bins 3641
2025-12-01 14:57:28,497:INFO:[LightGBM] [Info] Number of data points in the train set: 508, number of used features: 30
2025-12-01 14:57:28,498:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-01 14:57:28,498:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:28,499:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:28,500:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:28,501:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:28,502:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:28,503:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:28,504:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:28,505:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:28,507:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:28,508:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:28,509:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:28,510:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:28,511:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:28,512:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:28,514:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:28,515:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:28,516:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:28,517:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:28,519:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:28,520:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:28,521:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:28,523:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:28,524:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:28,525:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:28,527:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:28,528:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:28,529:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:28,530:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:28,532:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:28,533:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:28,534:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:28,535:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:28,537:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:28,538:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:28,539:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:28,541:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:28,542:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:28,543:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:28,544:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:28,546:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:28,547:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:28,548:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:28,549:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:28,551:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:28,552:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:28,553:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:28,555:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:28,556:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:28,558:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:28,559:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:28,560:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:28,562:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:28,564:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:28,565:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:28,566:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:28,568:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:28,569:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:28,570:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:28,572:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:28,573:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:28,574:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:28,576:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:28,577:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:28,579:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:28,580:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:28,582:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:28,583:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:28,584:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:28,586:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:28,588:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:28,589:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:28,590:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:28,592:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:28,593:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:28,595:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:28,596:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:28,598:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:28,599:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:28,601:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:28,602:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:28,604:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:28,605:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:28,606:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:28,608:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:28,609:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:28,611:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:28,612:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:28,614:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:28,615:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:28,616:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:28,618:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:28,619:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:28,621:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:28,622:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:28,623:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:28,625:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:28,626:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:28,627:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:28,628:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:28,630:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:28,844:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 401, in _score
    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 214, in wrapper
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 627, in roc_auc_score
    return _average_binary_score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-12-01 14:57:28,847:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 14:57:28,851:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 14:57:28,854:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1760: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2025-12-01 14:57:28,856:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:697: RuntimeWarning: invalid value encountered in double_scalars
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-12-01 14:57:29,043:INFO:[LightGBM] [Info] Number of positive: 254, number of negative: 254
2025-12-01 14:57:29,043:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000102 seconds.
2025-12-01 14:57:29,043:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-01 14:57:29,043:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-01 14:57:29,045:INFO:[LightGBM] [Info] Total Bins 3637
2025-12-01 14:57:29,045:INFO:[LightGBM] [Info] Number of data points in the train set: 508, number of used features: 30
2025-12-01 14:57:29,046:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-01 14:57:29,046:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:29,047:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:29,048:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:29,049:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:29,050:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:29,051:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:29,053:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:29,054:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:29,055:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:29,056:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:29,057:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:29,059:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:29,060:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:29,061:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:29,062:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:29,064:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:29,065:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:29,066:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:29,068:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:29,069:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:29,070:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:29,071:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:29,073:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:29,074:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:29,075:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:29,077:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:29,078:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:29,079:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:29,081:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:29,082:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:29,083:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:29,085:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:29,086:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:29,087:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:29,089:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:29,090:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:29,092:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:29,093:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:29,094:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:29,096:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:29,097:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:29,099:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:29,100:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:29,101:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:29,103:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:29,104:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:29,106:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:29,108:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:29,109:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:29,110:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:29,112:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:29,113:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:29,115:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:29,116:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:29,118:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:29,119:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:29,121:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:29,122:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:29,124:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:29,125:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:29,127:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:29,128:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:29,130:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:29,131:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:29,133:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:29,134:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:29,136:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:29,137:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:29,138:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:29,140:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:29,141:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:29,143:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:29,144:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:29,146:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:29,147:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:29,149:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:29,150:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:29,152:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:29,153:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:29,154:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:29,156:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:29,157:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:29,159:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:29,160:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:29,162:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:29,163:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:29,165:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:29,166:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:29,167:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:29,169:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:29,170:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:29,172:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:29,173:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:29,175:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:29,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:29,178:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:29,179:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:29,181:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:29,182:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:29,183:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:29,399:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 401, in _score
    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 214, in wrapper
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 627, in roc_auc_score
    return _average_binary_score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-12-01 14:57:29,402:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 14:57:29,593:INFO:[LightGBM] [Info] Number of positive: 255, number of negative: 255
2025-12-01 14:57:29,593:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000069 seconds.
2025-12-01 14:57:29,594:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-01 14:57:29,594:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-01 14:57:29,595:INFO:[LightGBM] [Info] Total Bins 3655
2025-12-01 14:57:29,596:INFO:[LightGBM] [Info] Number of data points in the train set: 510, number of used features: 30
2025-12-01 14:57:29,596:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-01 14:57:29,596:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:29,597:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:29,598:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:29,599:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:29,600:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:29,601:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:29,602:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:29,603:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:29,604:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:29,605:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:29,606:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:29,607:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:29,608:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:29,609:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:29,610:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:29,611:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:29,612:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:29,613:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:29,614:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:29,615:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:29,616:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:29,617:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:29,618:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:29,620:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:29,621:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:29,622:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:29,623:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:29,625:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:29,626:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:29,627:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:29,628:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:29,630:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:29,631:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:29,632:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:29,634:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:29,635:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:29,636:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:29,638:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:29,639:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:29,640:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:29,642:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:29,643:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:29,644:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:29,645:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:29,647:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:29,648:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:29,649:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:29,651:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:29,652:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:29,653:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:29,655:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:29,656:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:29,657:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:29,658:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:29,660:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:29,661:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:29,663:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:29,664:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:29,665:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:29,667:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:29,668:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:29,669:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:29,671:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:29,672:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:29,674:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:29,675:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:29,677:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:29,678:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:29,680:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:29,681:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:29,683:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:29,684:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:29,686:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:29,687:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:29,689:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:29,690:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:29,691:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:29,693:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:29,694:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:29,696:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:29,697:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:29,698:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:29,700:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:29,701:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:29,702:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:29,704:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:29,705:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:29,707:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:29,708:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:29,710:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:29,711:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:29,712:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:29,714:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:29,715:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:29,717:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:29,718:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:29,719:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:29,721:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:29,722:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:29,723:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 14:57:30,092:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:425: FitFailedWarning:
5 fits failed out of a total of 10.
The score on these train-test partitions for these parameters will be set to 0.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
4 fits failed with the following error:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/model_selection/_validation.py", line 729, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 255, in fit
    X, y, _ = self._fit(X, y, **fit_params_steps)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 238, in _fit
    X, y = self._memory_transform(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/joblib/memory.py", line 594, in __call__
    return self._cached_call(args, kwargs)[0]
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/memory.py", line 398, in _cached_call
    out, metadata = self.call(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/memory.py", line 309, in call
    output = self.func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 77, in _transform_one
    output = transformer.transform(*args)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 157, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 259, in transform
    output = self.transformer.transform(*args)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 157, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 546, in transform
    X, y = self.estimator.fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/base.py", line 208, in fit_resample
    return super().fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/base.py", line 112, in fit_resample
    output = self._fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/over_sampling/_smote/base.py", line 389, in _fit_resample
    nns = self.nn_k_.kneighbors(X_class, return_distance=False)[:, 1:]
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/neighbors/_base.py", line 808, in kneighbors
    raise ValueError(
ValueError: Expected n_neighbors <= n_samples,  but n_samples = 5, n_neighbors = 6

--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/model_selection/_validation.py", line 729, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 255, in fit
    X, y, _ = self._fit(X, y, **fit_params_steps)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 238, in _fit
    X, y = self._memory_transform(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/joblib/memory.py", line 594, in __call__
    return self._cached_call(args, kwargs)[0]
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/memory.py", line 398, in _cached_call
    out, metadata = self.call(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/memory.py", line 309, in call
    output = self.func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 77, in _transform_one
    output = transformer.transform(*args)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 157, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 259, in transform
    output = self.transformer.transform(*args)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 157, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 546, in transform
    X, y = self.estimator.fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/base.py", line 208, in fit_resample
    return super().fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/base.py", line 112, in fit_resample
    output = self._fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/over_sampling/_smote/base.py", line 389, in _fit_resample
    nns = self.nn_k_.kneighbors(X_class, return_distance=False)[:, 1:]
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/neighbors/_base.py", line 808, in kneighbors
    raise ValueError(
ValueError: Expected n_neighbors <= n_samples,  but n_samples = 4, n_neighbors = 6

  warnings.warn(some_fits_failed_message, FitFailedWarning)

2025-12-01 14:57:30,092:INFO:Calculating mean and std
2025-12-01 14:57:30,093:INFO:Creating metrics dataframe
2025-12-01 14:57:30,103:INFO:Uploading results into container
2025-12-01 14:57:30,104:INFO:Uploading model into container now
2025-12-01 14:57:30,104:INFO:_master_model_container: 3
2025-12-01 14:57:30,104:INFO:_display_container: 2
2025-12-01 14:57:30,105:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-12-01 14:57:30,105:INFO:create_model() successfully completed......................................
2025-12-01 14:57:30,222:WARNING:create_model() for LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) raised an exception or returned all 0.0, trying without fit_kwargs:
2025-12-01 14:57:30,222:WARNING:Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 795, in compare_models
    np.sum(
AssertionError

2025-12-01 14:57:30,222:INFO:Initializing create_model()
2025-12-01 14:57:30,222:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f125b6effa0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f125b6efa00>, model_only=True, return_train_score=False, kwargs={})
2025-12-01 14:57:30,222:INFO:Checking exceptions
2025-12-01 14:57:30,222:INFO:Importing libraries
2025-12-01 14:57:30,222:INFO:Copying training dataset
2025-12-01 14:57:30,226:INFO:Defining folds
2025-12-01 14:57:30,227:INFO:Declaring metric variables
2025-12-01 14:57:30,227:INFO:Importing untrained model
2025-12-01 14:57:30,228:INFO:Light Gradient Boosting Machine Imported successfully
2025-12-01 14:57:30,228:INFO:Starting cross validation
2025-12-01 14:57:30,230:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-12-01 14:57:30,234:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 7 members, which is less than n_splits=10.
  warnings.warn(

2025-12-01 14:57:31,534:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 795, in compare_models
    np.sum(
AssertionError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 401, in _score
    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 214, in wrapper
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 627, in roc_auc_score
    return _average_binary_score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-12-01 14:57:31,537:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 14:57:31,541:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 14:57:31,544:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1760: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2025-12-01 14:57:31,546:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:697: RuntimeWarning: invalid value encountered in double_scalars
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-12-01 14:57:31,911:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 795, in compare_models
    np.sum(
AssertionError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 401, in _score
    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 214, in wrapper
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 627, in roc_auc_score
    return _average_binary_score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-12-01 14:57:31,914:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 14:57:31,917:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 14:57:31,921:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1760: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2025-12-01 14:57:31,923:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:697: RuntimeWarning: invalid value encountered in double_scalars
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-12-01 14:57:32,299:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 795, in compare_models
    np.sum(
AssertionError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 401, in _score
    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 214, in wrapper
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 627, in roc_auc_score
    return _average_binary_score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-12-01 14:57:32,302:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 14:57:32,845:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:425: FitFailedWarning:
5 fits failed out of a total of 10.
The score on these train-test partitions for these parameters will be set to 0.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
4 fits failed with the following error:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 795, in compare_models
    np.sum(
AssertionError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/model_selection/_validation.py", line 729, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 255, in fit
    X, y, _ = self._fit(X, y, **fit_params_steps)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 238, in _fit
    X, y = self._memory_transform(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/joblib/memory.py", line 594, in __call__
    return self._cached_call(args, kwargs)[0]
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/memory.py", line 398, in _cached_call
    out, metadata = self.call(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/memory.py", line 309, in call
    output = self.func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 77, in _transform_one
    output = transformer.transform(*args)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 157, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 259, in transform
    output = self.transformer.transform(*args)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 157, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 546, in transform
    X, y = self.estimator.fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/base.py", line 208, in fit_resample
    return super().fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/base.py", line 112, in fit_resample
    output = self._fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/over_sampling/_smote/base.py", line 389, in _fit_resample
    nns = self.nn_k_.kneighbors(X_class, return_distance=False)[:, 1:]
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/neighbors/_base.py", line 808, in kneighbors
    raise ValueError(
ValueError: Expected n_neighbors <= n_samples,  but n_samples = 5, n_neighbors = 6

--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 795, in compare_models
    np.sum(
AssertionError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/model_selection/_validation.py", line 729, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 255, in fit
    X, y, _ = self._fit(X, y, **fit_params_steps)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 238, in _fit
    X, y = self._memory_transform(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/joblib/memory.py", line 594, in __call__
    return self._cached_call(args, kwargs)[0]
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/memory.py", line 398, in _cached_call
    out, metadata = self.call(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/memory.py", line 309, in call
    output = self.func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 77, in _transform_one
    output = transformer.transform(*args)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 157, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 259, in transform
    output = self.transformer.transform(*args)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 157, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 546, in transform
    X, y = self.estimator.fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/base.py", line 208, in fit_resample
    return super().fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/base.py", line 112, in fit_resample
    output = self._fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/over_sampling/_smote/base.py", line 389, in _fit_resample
    nns = self.nn_k_.kneighbors(X_class, return_distance=False)[:, 1:]
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/neighbors/_base.py", line 808, in kneighbors
    raise ValueError(
ValueError: Expected n_neighbors <= n_samples,  but n_samples = 4, n_neighbors = 6

  warnings.warn(some_fits_failed_message, FitFailedWarning)

2025-12-01 14:57:32,846:INFO:Calculating mean and std
2025-12-01 14:57:32,847:INFO:Creating metrics dataframe
2025-12-01 14:57:32,858:INFO:Uploading results into container
2025-12-01 14:57:32,858:INFO:Uploading model into container now
2025-12-01 14:57:32,859:INFO:_master_model_container: 4
2025-12-01 14:57:32,859:INFO:_display_container: 2
2025-12-01 14:57:32,860:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-12-01 14:57:32,860:INFO:create_model() successfully completed......................................
2025-12-01 14:57:32,986:ERROR:create_model() for LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) raised an exception or returned all 0.0:
2025-12-01 14:57:32,986:ERROR:Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 795, in compare_models
    np.sum(
AssertionError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 811, in compare_models
    np.sum(
AssertionError

2025-12-01 14:57:32,987:INFO:_master_model_container: 4
2025-12-01 14:57:32,987:INFO:_display_container: 2
2025-12-01 14:57:32,987:INFO:[]
2025-12-01 14:57:32,987:INFO:compare_models() successfully completed......................................
2025-12-01 14:59:47,996:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-12-01 14:59:47,996:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-12-01 14:59:47,996:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-12-01 14:59:47,997:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-12-01 14:59:48,489:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2025-12-01 14:59:48,836:INFO:PyCaret ClassificationExperiment
2025-12-01 14:59:48,836:INFO:Logging name: clf-default-name
2025-12-01 14:59:48,836:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-12-01 14:59:48,836:INFO:version 3.0.3
2025-12-01 14:59:48,836:INFO:Initializing setup()
2025-12-01 14:59:48,836:INFO:self.USI: b62b
2025-12-01 14:59:48,836:INFO:self._variable_keys: {'log_plots_param', 'fold_shuffle_param', 'fold_generator', 'fix_imbalance', 'n_jobs_param', 'fold_groups_param', 'html_param', 'X', 'data', 'gpu_param', 'pipeline', 'exp_id', 'target_param', 'X_test', 'y_train', 'is_multiclass', 'y', '_ml_usecase', 'USI', 'y_test', 'logging_param', 'gpu_n_jobs_param', 'seed', 'memory', '_available_plots', 'X_train', 'idx', 'exp_name_log'}
2025-12-01 14:59:48,836:INFO:Checking environment
2025-12-01 14:59:48,836:INFO:python_version: 3.10.19
2025-12-01 14:59:48,836:INFO:python_build: ('main', 'Nov  7 2025 00:05:37')
2025-12-01 14:59:48,836:INFO:machine: x86_64
2025-12-01 14:59:48,837:INFO:platform: Linux-6.8.0-x86_64-with-glibc2.39
2025-12-01 14:59:48,837:INFO:Memory: svmem(total=8345706496, available=7590821888, percent=9.0, used=754884608, free=4137259008, active=407068672, inactive=3490070528, buffers=76316672, cached=3689750528, shared=589824, slab=254078976)
2025-12-01 14:59:48,837:INFO:Physical Core: 4
2025-12-01 14:59:48,837:INFO:Logical Core: 4
2025-12-01 14:59:48,838:INFO:Checking libraries
2025-12-01 14:59:48,838:INFO:System:
2025-12-01 14:59:48,838:INFO:    python: 3.10.19 (main, Nov  7 2025, 00:05:37) [GCC 13.3.0]
2025-12-01 14:59:48,838:INFO:executable: /home/jules/.pyenv/versions/3.10.19/bin/python3.10
2025-12-01 14:59:48,838:INFO:   machine: Linux-6.8.0-x86_64-with-glibc2.39
2025-12-01 14:59:48,838:INFO:PyCaret required dependencies:
2025-12-01 14:59:48,839:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-01 14:59:48,871:INFO:                 pip: 25.3
2025-12-01 14:59:48,871:INFO:          setuptools: 79.0.1
2025-12-01 14:59:48,871:INFO:             pycaret: 3.0.3
2025-12-01 14:59:48,871:INFO:             IPython: 8.37.0
2025-12-01 14:59:48,871:INFO:          ipywidgets: 8.1.8
2025-12-01 14:59:48,871:INFO:                tqdm: 4.67.1
2025-12-01 14:59:48,871:INFO:               numpy: 1.23.5
2025-12-01 14:59:48,871:INFO:              pandas: 1.5.3
2025-12-01 14:59:48,871:INFO:              jinja2: 3.1.6
2025-12-01 14:59:48,871:INFO:               scipy: 1.10.1
2025-12-01 14:59:48,871:INFO:              joblib: 1.2.0
2025-12-01 14:59:48,871:INFO:             sklearn: 1.3.2
2025-12-01 14:59:48,871:INFO:                pyod: 2.0.5
2025-12-01 14:59:48,871:INFO:            imblearn: 0.12.4
2025-12-01 14:59:48,871:INFO:   category_encoders: 2.7.0
2025-12-01 14:59:48,871:INFO:            lightgbm: 4.6.0
2025-12-01 14:59:48,871:INFO:               numba: 0.62.1
2025-12-01 14:59:48,872:INFO:            requests: 2.32.5
2025-12-01 14:59:48,872:INFO:          matplotlib: 3.10.7
2025-12-01 14:59:48,872:INFO:          scikitplot: 0.3.7
2025-12-01 14:59:48,872:INFO:         yellowbrick: 1.5
2025-12-01 14:59:48,872:INFO:              plotly: 6.5.0
2025-12-01 14:59:48,872:INFO:    plotly-resampler: Not installed
2025-12-01 14:59:48,872:INFO:             kaleido: 1.2.0
2025-12-01 14:59:48,872:INFO:           schemdraw: 0.15
2025-12-01 14:59:48,872:INFO:         statsmodels: 0.14.5
2025-12-01 14:59:48,872:INFO:              sktime: 0.40.1
2025-12-01 14:59:48,872:INFO:               tbats: 1.1.3
2025-12-01 14:59:48,872:INFO:            pmdarima: 2.1.1
2025-12-01 14:59:48,872:INFO:              psutil: 7.1.3
2025-12-01 14:59:48,872:INFO:          markupsafe: 3.0.3
2025-12-01 14:59:48,872:INFO:             pickle5: Not installed
2025-12-01 14:59:48,872:INFO:         cloudpickle: 3.1.2
2025-12-01 14:59:48,872:INFO:         deprecation: 2.1.0
2025-12-01 14:59:48,872:INFO:              xxhash: 3.6.0
2025-12-01 14:59:48,872:INFO:           wurlitzer: 3.1.1
2025-12-01 14:59:48,872:INFO:PyCaret optional dependencies:
2025-12-01 14:59:48,932:INFO:                shap: 0.49.1
2025-12-01 14:59:48,932:INFO:           interpret: Not installed
2025-12-01 14:59:48,932:INFO:                umap: Not installed
2025-12-01 14:59:48,932:INFO:    pandas_profiling: Not installed
2025-12-01 14:59:48,932:INFO:  explainerdashboard: Not installed
2025-12-01 14:59:48,932:INFO:             autoviz: Not installed
2025-12-01 14:59:48,932:INFO:           fairlearn: Not installed
2025-12-01 14:59:48,932:INFO:          deepchecks: Not installed
2025-12-01 14:59:48,932:INFO:             xgboost: 2.1.3
2025-12-01 14:59:48,932:INFO:            catboost: Not installed
2025-12-01 14:59:48,932:INFO:              kmodes: Not installed
2025-12-01 14:59:48,932:INFO:             mlxtend: Not installed
2025-12-01 14:59:48,932:INFO:       statsforecast: Not installed
2025-12-01 14:59:48,932:INFO:        tune_sklearn: Not installed
2025-12-01 14:59:48,932:INFO:                 ray: Not installed
2025-12-01 14:59:48,932:INFO:            hyperopt: Not installed
2025-12-01 14:59:48,932:INFO:              optuna: Not installed
2025-12-01 14:59:48,932:INFO:               skopt: Not installed
2025-12-01 14:59:48,933:INFO:              mlflow: Not installed
2025-12-01 14:59:48,933:INFO:              gradio: Not installed
2025-12-01 14:59:48,933:INFO:             fastapi: Not installed
2025-12-01 14:59:48,933:INFO:             uvicorn: Not installed
2025-12-01 14:59:48,933:INFO:              m2cgen: Not installed
2025-12-01 14:59:48,933:INFO:           evidently: Not installed
2025-12-01 14:59:48,933:INFO:               fugue: Not installed
2025-12-01 14:59:48,933:INFO:           streamlit: Not installed
2025-12-01 14:59:48,933:INFO:             prophet: Not installed
2025-12-01 14:59:48,933:INFO:None
2025-12-01 14:59:48,933:INFO:Set up data.
2025-12-01 14:59:48,947:INFO:Set up train/test split.
2025-12-01 14:59:48,952:INFO:Set up index.
2025-12-01 14:59:48,952:INFO:Set up folding strategy.
2025-12-01 14:59:48,952:INFO:Assigning column types.
2025-12-01 14:59:48,956:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-12-01 14:59:49,017:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-12-01 14:59:49,021:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-01 14:59:49,065:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-01 14:59:49,069:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-01 14:59:49,130:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-12-01 14:59:49,131:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-01 14:59:49,168:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-01 14:59:49,172:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-01 14:59:49,172:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-12-01 14:59:49,234:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-01 14:59:49,272:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-01 14:59:49,275:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-01 14:59:49,338:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-01 14:59:49,375:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-01 14:59:49,379:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-01 14:59:49,379:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-12-01 14:59:49,480:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-01 14:59:49,484:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-01 14:59:49,584:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-01 14:59:49,588:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-01 14:59:49,590:INFO:Preparing preprocessing pipeline...
2025-12-01 14:59:49,591:INFO:Set up simple imputation.
2025-12-01 14:59:49,595:INFO:Set up encoding of ordinal features.
2025-12-01 14:59:49,598:INFO:Set up encoding of categorical features.
2025-12-01 14:59:49,599:INFO:Set up removing outliers.
2025-12-01 14:59:49,599:INFO:Set up imbalanced handling.
2025-12-01 14:59:49,599:INFO:Set up feature normalization.
2025-12-01 14:59:49,804:INFO:Finished creating preprocessing pipeline.
2025-12-01 14:59:49,874:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'SystolicBP',
                                             'TotalCholesterol', 'LDL',
                                             'Triglycerides', 'HbA1c',
                                             'Glucose', 'UricAcid',
                                             'Creatinine', 'BMI',
                                             'WaistCircumference', 'Height',
                                             'IncomeRatio', 'ALT_Enzyme',
                                             'AST_Enzyme', 'GGT_Enzyme',
                                             'Albumin', 'Potassium', 'Sodium'],
                                    transform...
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              n_jobs=None,
                                                                              random_state=None,
                                                                              sampling_strategy='auto')))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=RobustScaler(copy=True,
                                                             quantile_range=(25.0,
                                                                             75.0),
                                                             unit_variance=False,
                                                             with_centering=True,
                                                             with_scaling=True)))],
         verbose=False)
2025-12-01 14:59:49,874:INFO:Creating final display dataframe.
2025-12-01 14:59:50,095:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target      HeartDisease
2                   Target type            Binary
3           Original data shape         (437, 27)
4        Transformed data shape         (698, 31)
5   Transformed train set shape         (566, 31)
6    Transformed test set shape         (132, 31)
7              Ordinal features                 2
8              Numeric features                19
9          Categorical features                 7
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16              Remove outliers              True
17           Outliers threshold              0.05
18                Fix imbalance              True
19         Fix imbalance method             SMOTE
20                    Normalize              True
21             Normalize method            robust
22               Fold Generator   StratifiedKFold
23                  Fold Number                10
24                     CPU Jobs                 1
25                      Use GPU             False
26               Log Experiment             False
27              Experiment Name  clf-default-name
28                          USI              b62b
2025-12-01 14:59:50,210:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-01 14:59:50,214:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-01 14:59:50,317:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-01 14:59:50,321:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-01 14:59:50,323:INFO:setup() successfully completed in 1.49s...............
2025-12-01 14:59:50,355:INFO:Initializing compare_models()
2025-12-01 14:59:50,355:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fc81338a4d0>, include=['xgboost', 'lightgbm'], fold=None, round=4, cross_validation=True, sort=Recall, n_select=3, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x7fc81338a4d0>, 'include': ['xgboost', 'lightgbm'], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Recall', 'n_select': 3, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2025-12-01 14:59:50,355:INFO:Checking exceptions
2025-12-01 14:59:50,360:INFO:Preparing display monitor
2025-12-01 14:59:50,400:INFO:Initializing Extreme Gradient Boosting
2025-12-01 14:59:50,400:INFO:Total runtime is 3.0199686686197915e-06 minutes
2025-12-01 14:59:50,406:INFO:SubProcess create_model() called ==================================
2025-12-01 14:59:50,406:INFO:Initializing create_model()
2025-12-01 14:59:50,406:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fc81338a4d0>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc81338a470>, model_only=True, return_train_score=False, kwargs={})
2025-12-01 14:59:50,406:INFO:Checking exceptions
2025-12-01 14:59:50,406:INFO:Importing libraries
2025-12-01 14:59:50,406:INFO:Copying training dataset
2025-12-01 14:59:50,411:INFO:Defining folds
2025-12-01 14:59:50,412:INFO:Declaring metric variables
2025-12-01 14:59:50,416:INFO:Importing untrained model
2025-12-01 14:59:50,422:INFO:Extreme Gradient Boosting Imported successfully
2025-12-01 14:59:50,432:INFO:Starting cross validation
2025-12-01 14:59:50,435:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-12-01 14:59:50,440:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 7 members, which is less than n_splits=10.
  warnings.warn(

2025-12-01 14:59:51,944:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 401, in _score
    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 214, in wrapper
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 627, in roc_auc_score
    return _average_binary_score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-12-01 14:59:51,948:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 14:59:52,400:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 401, in _score
    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 214, in wrapper
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 627, in roc_auc_score
    return _average_binary_score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-12-01 14:59:52,404:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 14:59:52,857:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 401, in _score
    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 214, in wrapper
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 627, in roc_auc_score
    return _average_binary_score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-12-01 14:59:52,860:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 14:59:52,863:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 14:59:52,866:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1760: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2025-12-01 14:59:52,868:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:697: RuntimeWarning: invalid value encountered in double_scalars
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-12-01 14:59:53,465:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:425: FitFailedWarning:
5 fits failed out of a total of 10.
The score on these train-test partitions for these parameters will be set to 0.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
4 fits failed with the following error:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/model_selection/_validation.py", line 729, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 255, in fit
    X, y, _ = self._fit(X, y, **fit_params_steps)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 238, in _fit
    X, y = self._memory_transform(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/joblib/memory.py", line 594, in __call__
    return self._cached_call(args, kwargs)[0]
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/memory.py", line 398, in _cached_call
    out, metadata = self.call(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/memory.py", line 309, in call
    output = self.func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 77, in _transform_one
    output = transformer.transform(*args)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 157, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 259, in transform
    output = self.transformer.transform(*args)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 157, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 546, in transform
    X, y = self.estimator.fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/base.py", line 208, in fit_resample
    return super().fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/base.py", line 112, in fit_resample
    output = self._fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/over_sampling/_smote/base.py", line 389, in _fit_resample
    nns = self.nn_k_.kneighbors(X_class, return_distance=False)[:, 1:]
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/neighbors/_base.py", line 808, in kneighbors
    raise ValueError(
ValueError: Expected n_neighbors <= n_samples,  but n_samples = 5, n_neighbors = 6

--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/model_selection/_validation.py", line 729, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 255, in fit
    X, y, _ = self._fit(X, y, **fit_params_steps)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 238, in _fit
    X, y = self._memory_transform(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/joblib/memory.py", line 594, in __call__
    return self._cached_call(args, kwargs)[0]
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/memory.py", line 398, in _cached_call
    out, metadata = self.call(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/memory.py", line 309, in call
    output = self.func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 77, in _transform_one
    output = transformer.transform(*args)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 157, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 259, in transform
    output = self.transformer.transform(*args)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 157, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 546, in transform
    X, y = self.estimator.fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/base.py", line 208, in fit_resample
    return super().fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/base.py", line 112, in fit_resample
    output = self._fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/over_sampling/_smote/base.py", line 389, in _fit_resample
    nns = self.nn_k_.kneighbors(X_class, return_distance=False)[:, 1:]
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/neighbors/_base.py", line 808, in kneighbors
    raise ValueError(
ValueError: Expected n_neighbors <= n_samples,  but n_samples = 4, n_neighbors = 6

  warnings.warn(some_fits_failed_message, FitFailedWarning)

2025-12-01 14:59:53,466:INFO:Calculating mean and std
2025-12-01 14:59:53,468:INFO:Creating metrics dataframe
2025-12-01 14:59:53,481:INFO:Uploading results into container
2025-12-01 14:59:53,482:INFO:Uploading model into container now
2025-12-01 14:59:53,482:INFO:_master_model_container: 1
2025-12-01 14:59:53,482:INFO:_display_container: 2
2025-12-01 14:59:53,484:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2025-12-01 14:59:53,484:INFO:create_model() successfully completed......................................
2025-12-01 14:59:53,599:WARNING:create_model() for XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...) raised an exception or returned all 0.0, trying without fit_kwargs:
2025-12-01 14:59:53,601:WARNING:Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 795, in compare_models
    np.sum(
AssertionError

2025-12-01 14:59:53,601:INFO:Initializing create_model()
2025-12-01 14:59:53,601:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fc81338a4d0>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc81338a470>, model_only=True, return_train_score=False, kwargs={})
2025-12-01 14:59:53,601:INFO:Checking exceptions
2025-12-01 14:59:53,601:INFO:Importing libraries
2025-12-01 14:59:53,601:INFO:Copying training dataset
2025-12-01 14:59:53,606:INFO:Defining folds
2025-12-01 14:59:53,607:INFO:Declaring metric variables
2025-12-01 14:59:53,613:INFO:Importing untrained model
2025-12-01 14:59:53,618:INFO:Extreme Gradient Boosting Imported successfully
2025-12-01 14:59:53,628:INFO:Starting cross validation
2025-12-01 14:59:53,631:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-12-01 14:59:53,634:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 7 members, which is less than n_splits=10.
  warnings.warn(

2025-12-01 14:59:55,093:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 795, in compare_models
    np.sum(
AssertionError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 401, in _score
    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 214, in wrapper
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 627, in roc_auc_score
    return _average_binary_score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-12-01 14:59:55,096:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 14:59:55,550:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 795, in compare_models
    np.sum(
AssertionError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 401, in _score
    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 214, in wrapper
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 627, in roc_auc_score
    return _average_binary_score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-12-01 14:59:55,553:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 14:59:56,002:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 795, in compare_models
    np.sum(
AssertionError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 401, in _score
    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 214, in wrapper
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 627, in roc_auc_score
    return _average_binary_score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-12-01 14:59:56,006:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 14:59:56,009:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 14:59:56,012:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1760: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2025-12-01 14:59:56,014:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:697: RuntimeWarning: invalid value encountered in double_scalars
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-12-01 14:59:56,615:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:425: FitFailedWarning:
5 fits failed out of a total of 10.
The score on these train-test partitions for these parameters will be set to 0.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
4 fits failed with the following error:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 795, in compare_models
    np.sum(
AssertionError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/model_selection/_validation.py", line 729, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 255, in fit
    X, y, _ = self._fit(X, y, **fit_params_steps)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 238, in _fit
    X, y = self._memory_transform(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/joblib/memory.py", line 594, in __call__
    return self._cached_call(args, kwargs)[0]
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/memory.py", line 398, in _cached_call
    out, metadata = self.call(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/memory.py", line 309, in call
    output = self.func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 77, in _transform_one
    output = transformer.transform(*args)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 157, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 259, in transform
    output = self.transformer.transform(*args)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 157, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 546, in transform
    X, y = self.estimator.fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/base.py", line 208, in fit_resample
    return super().fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/base.py", line 112, in fit_resample
    output = self._fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/over_sampling/_smote/base.py", line 389, in _fit_resample
    nns = self.nn_k_.kneighbors(X_class, return_distance=False)[:, 1:]
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/neighbors/_base.py", line 808, in kneighbors
    raise ValueError(
ValueError: Expected n_neighbors <= n_samples,  but n_samples = 5, n_neighbors = 6

--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 795, in compare_models
    np.sum(
AssertionError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/model_selection/_validation.py", line 729, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 255, in fit
    X, y, _ = self._fit(X, y, **fit_params_steps)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 238, in _fit
    X, y = self._memory_transform(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/joblib/memory.py", line 594, in __call__
    return self._cached_call(args, kwargs)[0]
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/memory.py", line 398, in _cached_call
    out, metadata = self.call(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/memory.py", line 309, in call
    output = self.func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 77, in _transform_one
    output = transformer.transform(*args)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 157, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 259, in transform
    output = self.transformer.transform(*args)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 157, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 546, in transform
    X, y = self.estimator.fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/base.py", line 208, in fit_resample
    return super().fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/base.py", line 112, in fit_resample
    output = self._fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/over_sampling/_smote/base.py", line 389, in _fit_resample
    nns = self.nn_k_.kneighbors(X_class, return_distance=False)[:, 1:]
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/neighbors/_base.py", line 808, in kneighbors
    raise ValueError(
ValueError: Expected n_neighbors <= n_samples,  but n_samples = 4, n_neighbors = 6

  warnings.warn(some_fits_failed_message, FitFailedWarning)

2025-12-01 14:59:56,616:INFO:Calculating mean and std
2025-12-01 14:59:56,618:INFO:Creating metrics dataframe
2025-12-01 14:59:56,629:INFO:Uploading results into container
2025-12-01 14:59:56,630:INFO:Uploading model into container now
2025-12-01 14:59:56,630:INFO:_master_model_container: 2
2025-12-01 14:59:56,630:INFO:_display_container: 2
2025-12-01 14:59:56,631:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2025-12-01 14:59:56,632:INFO:create_model() successfully completed......................................
2025-12-01 14:59:56,742:ERROR:create_model() for XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...) raised an exception or returned all 0.0:
2025-12-01 14:59:56,742:ERROR:Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 795, in compare_models
    np.sum(
AssertionError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 811, in compare_models
    np.sum(
AssertionError

2025-12-01 14:59:56,742:INFO:Initializing Light Gradient Boosting Machine
2025-12-01 14:59:56,742:INFO:Total runtime is 0.10570334593454997 minutes
2025-12-01 14:59:56,748:INFO:SubProcess create_model() called ==================================
2025-12-01 14:59:56,748:INFO:Initializing create_model()
2025-12-01 14:59:56,748:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fc81338a4d0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc81338a470>, model_only=True, return_train_score=False, kwargs={})
2025-12-01 14:59:56,748:INFO:Checking exceptions
2025-12-01 14:59:56,748:INFO:Importing libraries
2025-12-01 14:59:56,749:INFO:Copying training dataset
2025-12-01 14:59:56,754:INFO:Defining folds
2025-12-01 14:59:56,754:INFO:Declaring metric variables
2025-12-01 14:59:56,760:INFO:Importing untrained model
2025-12-01 14:59:56,766:INFO:Light Gradient Boosting Machine Imported successfully
2025-12-01 14:59:56,776:INFO:Starting cross validation
2025-12-01 14:59:56,778:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-12-01 14:59:56,783:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 7 members, which is less than n_splits=10.
  warnings.warn(

2025-12-01 14:59:58,049:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 401, in _score
    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 214, in wrapper
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 627, in roc_auc_score
    return _average_binary_score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-12-01 14:59:58,052:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 14:59:58,056:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 14:59:58,059:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1760: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2025-12-01 14:59:58,061:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:697: RuntimeWarning: invalid value encountered in double_scalars
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-12-01 14:59:58,424:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 401, in _score
    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 214, in wrapper
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 627, in roc_auc_score
    return _average_binary_score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-12-01 14:59:58,428:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 14:59:58,431:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 14:59:58,434:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1760: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2025-12-01 14:59:58,436:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:697: RuntimeWarning: invalid value encountered in double_scalars
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-12-01 14:59:58,796:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 401, in _score
    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 214, in wrapper
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 627, in roc_auc_score
    return _average_binary_score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-12-01 14:59:58,799:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 14:59:59,328:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:425: FitFailedWarning:
5 fits failed out of a total of 10.
The score on these train-test partitions for these parameters will be set to 0.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
4 fits failed with the following error:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/model_selection/_validation.py", line 729, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 255, in fit
    X, y, _ = self._fit(X, y, **fit_params_steps)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 238, in _fit
    X, y = self._memory_transform(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/joblib/memory.py", line 594, in __call__
    return self._cached_call(args, kwargs)[0]
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/memory.py", line 398, in _cached_call
    out, metadata = self.call(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/memory.py", line 309, in call
    output = self.func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 77, in _transform_one
    output = transformer.transform(*args)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 157, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 259, in transform
    output = self.transformer.transform(*args)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 157, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 546, in transform
    X, y = self.estimator.fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/base.py", line 208, in fit_resample
    return super().fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/base.py", line 112, in fit_resample
    output = self._fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/over_sampling/_smote/base.py", line 389, in _fit_resample
    nns = self.nn_k_.kneighbors(X_class, return_distance=False)[:, 1:]
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/neighbors/_base.py", line 808, in kneighbors
    raise ValueError(
ValueError: Expected n_neighbors <= n_samples,  but n_samples = 5, n_neighbors = 6

--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/model_selection/_validation.py", line 729, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 255, in fit
    X, y, _ = self._fit(X, y, **fit_params_steps)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 238, in _fit
    X, y = self._memory_transform(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/joblib/memory.py", line 594, in __call__
    return self._cached_call(args, kwargs)[0]
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/memory.py", line 398, in _cached_call
    out, metadata = self.call(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/memory.py", line 309, in call
    output = self.func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 77, in _transform_one
    output = transformer.transform(*args)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 157, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 259, in transform
    output = self.transformer.transform(*args)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 157, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 546, in transform
    X, y = self.estimator.fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/base.py", line 208, in fit_resample
    return super().fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/base.py", line 112, in fit_resample
    output = self._fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/over_sampling/_smote/base.py", line 389, in _fit_resample
    nns = self.nn_k_.kneighbors(X_class, return_distance=False)[:, 1:]
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/neighbors/_base.py", line 808, in kneighbors
    raise ValueError(
ValueError: Expected n_neighbors <= n_samples,  but n_samples = 4, n_neighbors = 6

  warnings.warn(some_fits_failed_message, FitFailedWarning)

2025-12-01 14:59:59,328:INFO:Calculating mean and std
2025-12-01 14:59:59,330:INFO:Creating metrics dataframe
2025-12-01 14:59:59,347:INFO:Uploading results into container
2025-12-01 14:59:59,348:INFO:Uploading model into container now
2025-12-01 14:59:59,348:INFO:_master_model_container: 3
2025-12-01 14:59:59,349:INFO:_display_container: 2
2025-12-01 14:59:59,350:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-12-01 14:59:59,350:INFO:create_model() successfully completed......................................
2025-12-01 14:59:59,463:WARNING:create_model() for LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) raised an exception or returned all 0.0, trying without fit_kwargs:
2025-12-01 14:59:59,463:WARNING:Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 795, in compare_models
    np.sum(
AssertionError

2025-12-01 14:59:59,463:INFO:Initializing create_model()
2025-12-01 14:59:59,464:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fc81338a4d0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc81338a470>, model_only=True, return_train_score=False, kwargs={})
2025-12-01 14:59:59,464:INFO:Checking exceptions
2025-12-01 14:59:59,464:INFO:Importing libraries
2025-12-01 14:59:59,464:INFO:Copying training dataset
2025-12-01 14:59:59,468:INFO:Defining folds
2025-12-01 14:59:59,468:INFO:Declaring metric variables
2025-12-01 14:59:59,473:INFO:Importing untrained model
2025-12-01 14:59:59,479:INFO:Light Gradient Boosting Machine Imported successfully
2025-12-01 14:59:59,488:INFO:Starting cross validation
2025-12-01 14:59:59,491:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-12-01 14:59:59,495:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 7 members, which is less than n_splits=10.
  warnings.warn(

2025-12-01 15:00:00,761:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 795, in compare_models
    np.sum(
AssertionError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 401, in _score
    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 214, in wrapper
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 627, in roc_auc_score
    return _average_binary_score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-12-01 15:00:00,764:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 15:00:00,767:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 15:00:00,770:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1760: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2025-12-01 15:00:00,772:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:697: RuntimeWarning: invalid value encountered in double_scalars
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-12-01 15:00:01,122:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 795, in compare_models
    np.sum(
AssertionError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 401, in _score
    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 214, in wrapper
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 627, in roc_auc_score
    return _average_binary_score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-12-01 15:00:01,125:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 15:00:01,128:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 15:00:01,132:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1760: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2025-12-01 15:00:01,134:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:697: RuntimeWarning: invalid value encountered in double_scalars
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-12-01 15:00:01,485:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 795, in compare_models
    np.sum(
AssertionError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 401, in _score
    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 214, in wrapper
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 627, in roc_auc_score
    return _average_binary_score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-12-01 15:00:01,489:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 15:00:02,007:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:425: FitFailedWarning:
5 fits failed out of a total of 10.
The score on these train-test partitions for these parameters will be set to 0.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
4 fits failed with the following error:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 795, in compare_models
    np.sum(
AssertionError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/model_selection/_validation.py", line 729, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 255, in fit
    X, y, _ = self._fit(X, y, **fit_params_steps)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 238, in _fit
    X, y = self._memory_transform(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/joblib/memory.py", line 594, in __call__
    return self._cached_call(args, kwargs)[0]
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/memory.py", line 398, in _cached_call
    out, metadata = self.call(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/memory.py", line 309, in call
    output = self.func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 77, in _transform_one
    output = transformer.transform(*args)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 157, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 259, in transform
    output = self.transformer.transform(*args)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 157, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 546, in transform
    X, y = self.estimator.fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/base.py", line 208, in fit_resample
    return super().fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/base.py", line 112, in fit_resample
    output = self._fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/over_sampling/_smote/base.py", line 389, in _fit_resample
    nns = self.nn_k_.kneighbors(X_class, return_distance=False)[:, 1:]
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/neighbors/_base.py", line 808, in kneighbors
    raise ValueError(
ValueError: Expected n_neighbors <= n_samples,  but n_samples = 5, n_neighbors = 6

--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 795, in compare_models
    np.sum(
AssertionError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/model_selection/_validation.py", line 729, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 255, in fit
    X, y, _ = self._fit(X, y, **fit_params_steps)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 238, in _fit
    X, y = self._memory_transform(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/joblib/memory.py", line 594, in __call__
    return self._cached_call(args, kwargs)[0]
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/memory.py", line 398, in _cached_call
    out, metadata = self.call(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/memory.py", line 309, in call
    output = self.func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 77, in _transform_one
    output = transformer.transform(*args)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 157, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 259, in transform
    output = self.transformer.transform(*args)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 157, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 546, in transform
    X, y = self.estimator.fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/base.py", line 208, in fit_resample
    return super().fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/base.py", line 112, in fit_resample
    output = self._fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/over_sampling/_smote/base.py", line 389, in _fit_resample
    nns = self.nn_k_.kneighbors(X_class, return_distance=False)[:, 1:]
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/neighbors/_base.py", line 808, in kneighbors
    raise ValueError(
ValueError: Expected n_neighbors <= n_samples,  but n_samples = 4, n_neighbors = 6

  warnings.warn(some_fits_failed_message, FitFailedWarning)

2025-12-01 15:00:02,008:INFO:Calculating mean and std
2025-12-01 15:00:02,009:INFO:Creating metrics dataframe
2025-12-01 15:00:02,019:INFO:Uploading results into container
2025-12-01 15:00:02,020:INFO:Uploading model into container now
2025-12-01 15:00:02,021:INFO:_master_model_container: 4
2025-12-01 15:00:02,021:INFO:_display_container: 2
2025-12-01 15:00:02,022:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-12-01 15:00:02,022:INFO:create_model() successfully completed......................................
2025-12-01 15:00:02,141:ERROR:create_model() for LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) raised an exception or returned all 0.0:
2025-12-01 15:00:02,141:ERROR:Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 795, in compare_models
    np.sum(
AssertionError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 811, in compare_models
    np.sum(
AssertionError

2025-12-01 15:00:02,153:INFO:_master_model_container: 4
2025-12-01 15:00:02,153:INFO:_display_container: 2
2025-12-01 15:00:02,153:INFO:[]
2025-12-01 15:00:02,153:INFO:compare_models() successfully completed......................................
2025-12-01 15:03:28,469:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-12-01 15:03:28,469:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-12-01 15:03:28,469:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-12-01 15:03:28,469:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-12-01 15:03:28,975:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2025-12-01 15:03:29,327:INFO:PyCaret ClassificationExperiment
2025-12-01 15:03:29,327:INFO:Logging name: clf-default-name
2025-12-01 15:03:29,327:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-12-01 15:03:29,327:INFO:version 3.0.3
2025-12-01 15:03:29,327:INFO:Initializing setup()
2025-12-01 15:03:29,327:INFO:self.USI: cede
2025-12-01 15:03:29,327:INFO:self._variable_keys: {'log_plots_param', 'seed', 'USI', 'X', 'gpu_param', 'fold_groups_param', 'fold_shuffle_param', 'target_param', 'fix_imbalance', 'y_train', 'pipeline', 'exp_name_log', '_ml_usecase', 'gpu_n_jobs_param', 'memory', 'data', 'idx', 'y', 'is_multiclass', 'html_param', 'exp_id', '_available_plots', 'logging_param', 'y_test', 'X_train', 'n_jobs_param', 'X_test', 'fold_generator'}
2025-12-01 15:03:29,328:INFO:Checking environment
2025-12-01 15:03:29,328:INFO:python_version: 3.10.19
2025-12-01 15:03:29,328:INFO:python_build: ('main', 'Nov  7 2025 00:05:37')
2025-12-01 15:03:29,328:INFO:machine: x86_64
2025-12-01 15:03:29,328:INFO:platform: Linux-6.8.0-x86_64-with-glibc2.39
2025-12-01 15:03:29,328:INFO:Memory: svmem(total=8345706496, available=7596453888, percent=9.0, used=749252608, free=4100382720, active=411000832, inactive=3527036928, buffers=76619776, cached=3731955712, shared=589824, slab=254697472)
2025-12-01 15:03:29,329:INFO:Physical Core: 4
2025-12-01 15:03:29,329:INFO:Logical Core: 4
2025-12-01 15:03:29,329:INFO:Checking libraries
2025-12-01 15:03:29,329:INFO:System:
2025-12-01 15:03:29,329:INFO:    python: 3.10.19 (main, Nov  7 2025, 00:05:37) [GCC 13.3.0]
2025-12-01 15:03:29,329:INFO:executable: /home/jules/.pyenv/versions/3.10.19/bin/python3.10
2025-12-01 15:03:29,329:INFO:   machine: Linux-6.8.0-x86_64-with-glibc2.39
2025-12-01 15:03:29,329:INFO:PyCaret required dependencies:
2025-12-01 15:03:29,331:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-01 15:03:29,363:INFO:                 pip: 25.3
2025-12-01 15:03:29,363:INFO:          setuptools: 79.0.1
2025-12-01 15:03:29,363:INFO:             pycaret: 3.0.3
2025-12-01 15:03:29,363:INFO:             IPython: 8.37.0
2025-12-01 15:03:29,363:INFO:          ipywidgets: 8.1.8
2025-12-01 15:03:29,363:INFO:                tqdm: 4.67.1
2025-12-01 15:03:29,363:INFO:               numpy: 1.23.5
2025-12-01 15:03:29,363:INFO:              pandas: 1.5.3
2025-12-01 15:03:29,363:INFO:              jinja2: 3.1.6
2025-12-01 15:03:29,363:INFO:               scipy: 1.10.1
2025-12-01 15:03:29,363:INFO:              joblib: 1.2.0
2025-12-01 15:03:29,363:INFO:             sklearn: 1.3.2
2025-12-01 15:03:29,363:INFO:                pyod: 2.0.5
2025-12-01 15:03:29,363:INFO:            imblearn: 0.12.4
2025-12-01 15:03:29,363:INFO:   category_encoders: 2.7.0
2025-12-01 15:03:29,363:INFO:            lightgbm: 4.6.0
2025-12-01 15:03:29,364:INFO:               numba: 0.62.1
2025-12-01 15:03:29,364:INFO:            requests: 2.32.5
2025-12-01 15:03:29,364:INFO:          matplotlib: 3.10.7
2025-12-01 15:03:29,364:INFO:          scikitplot: 0.3.7
2025-12-01 15:03:29,364:INFO:         yellowbrick: 1.5
2025-12-01 15:03:29,364:INFO:              plotly: 6.5.0
2025-12-01 15:03:29,364:INFO:    plotly-resampler: Not installed
2025-12-01 15:03:29,364:INFO:             kaleido: 1.2.0
2025-12-01 15:03:29,364:INFO:           schemdraw: 0.15
2025-12-01 15:03:29,364:INFO:         statsmodels: 0.14.5
2025-12-01 15:03:29,364:INFO:              sktime: 0.40.1
2025-12-01 15:03:29,364:INFO:               tbats: 1.1.3
2025-12-01 15:03:29,364:INFO:            pmdarima: 2.1.1
2025-12-01 15:03:29,364:INFO:              psutil: 7.1.3
2025-12-01 15:03:29,364:INFO:          markupsafe: 3.0.3
2025-12-01 15:03:29,364:INFO:             pickle5: Not installed
2025-12-01 15:03:29,364:INFO:         cloudpickle: 3.1.2
2025-12-01 15:03:29,364:INFO:         deprecation: 2.1.0
2025-12-01 15:03:29,364:INFO:              xxhash: 3.6.0
2025-12-01 15:03:29,364:INFO:           wurlitzer: 3.1.1
2025-12-01 15:03:29,364:INFO:PyCaret optional dependencies:
2025-12-01 15:03:29,424:INFO:                shap: 0.49.1
2025-12-01 15:03:29,424:INFO:           interpret: Not installed
2025-12-01 15:03:29,424:INFO:                umap: Not installed
2025-12-01 15:03:29,424:INFO:    pandas_profiling: Not installed
2025-12-01 15:03:29,424:INFO:  explainerdashboard: Not installed
2025-12-01 15:03:29,424:INFO:             autoviz: Not installed
2025-12-01 15:03:29,424:INFO:           fairlearn: Not installed
2025-12-01 15:03:29,425:INFO:          deepchecks: Not installed
2025-12-01 15:03:29,425:INFO:             xgboost: 2.1.3
2025-12-01 15:03:29,425:INFO:            catboost: Not installed
2025-12-01 15:03:29,425:INFO:              kmodes: Not installed
2025-12-01 15:03:29,425:INFO:             mlxtend: Not installed
2025-12-01 15:03:29,425:INFO:       statsforecast: Not installed
2025-12-01 15:03:29,425:INFO:        tune_sklearn: Not installed
2025-12-01 15:03:29,425:INFO:                 ray: Not installed
2025-12-01 15:03:29,425:INFO:            hyperopt: Not installed
2025-12-01 15:03:29,425:INFO:              optuna: Not installed
2025-12-01 15:03:29,425:INFO:               skopt: Not installed
2025-12-01 15:03:29,425:INFO:              mlflow: Not installed
2025-12-01 15:03:29,425:INFO:              gradio: Not installed
2025-12-01 15:03:29,425:INFO:             fastapi: Not installed
2025-12-01 15:03:29,425:INFO:             uvicorn: Not installed
2025-12-01 15:03:29,425:INFO:              m2cgen: Not installed
2025-12-01 15:03:29,425:INFO:           evidently: Not installed
2025-12-01 15:03:29,425:INFO:               fugue: Not installed
2025-12-01 15:03:29,425:INFO:           streamlit: Not installed
2025-12-01 15:03:29,425:INFO:             prophet: Not installed
2025-12-01 15:03:29,425:INFO:None
2025-12-01 15:03:29,425:INFO:Set up data.
2025-12-01 15:03:29,440:INFO:Set up train/test split.
2025-12-01 15:03:29,445:INFO:Set up index.
2025-12-01 15:03:29,445:INFO:Set up folding strategy.
2025-12-01 15:03:29,445:INFO:Assigning column types.
2025-12-01 15:03:29,449:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-12-01 15:03:29,507:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-12-01 15:03:29,511:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-01 15:03:29,554:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-01 15:03:29,557:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-01 15:03:29,616:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-12-01 15:03:29,617:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-01 15:03:29,653:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-01 15:03:29,656:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-01 15:03:29,657:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-12-01 15:03:29,716:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-01 15:03:29,752:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-01 15:03:29,756:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-01 15:03:29,819:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-01 15:03:29,856:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-01 15:03:29,860:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-01 15:03:29,860:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-12-01 15:03:29,964:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-01 15:03:29,968:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-01 15:03:30,069:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-01 15:03:30,072:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-01 15:03:30,075:INFO:Preparing preprocessing pipeline...
2025-12-01 15:03:30,076:INFO:Set up simple imputation.
2025-12-01 15:03:30,080:INFO:Set up encoding of ordinal features.
2025-12-01 15:03:30,084:INFO:Set up encoding of categorical features.
2025-12-01 15:03:30,084:INFO:Set up removing outliers.
2025-12-01 15:03:30,084:INFO:Set up imbalanced handling.
2025-12-01 15:03:30,084:INFO:Set up feature normalization.
2025-12-01 15:03:30,308:INFO:Finished creating preprocessing pipeline.
2025-12-01 15:03:30,381:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'SystolicBP',
                                             'TotalCholesterol', 'LDL',
                                             'Triglycerides', 'HbA1c',
                                             'Glucose', 'UricAcid',
                                             'Creatinine', 'BMI',
                                             'WaistCircumference', 'Height',
                                             'IncomeRatio', 'ALT_Enzyme',
                                             'AST_Enzyme', 'GGT_Enzyme',
                                             'Albumin', 'Potassium', 'Sodium'],
                                    transform...
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              n_jobs=None,
                                                                              random_state=None,
                                                                              sampling_strategy='auto')))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=RobustScaler(copy=True,
                                                             quantile_range=(25.0,
                                                                             75.0),
                                                             unit_variance=False,
                                                             with_centering=True,
                                                             with_scaling=True)))],
         verbose=False)
2025-12-01 15:03:30,381:INFO:Creating final display dataframe.
2025-12-01 15:03:30,626:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target      HeartDisease
2                   Target type            Binary
3           Original data shape         (437, 27)
4        Transformed data shape         (698, 31)
5   Transformed train set shape         (566, 31)
6    Transformed test set shape         (132, 31)
7              Ordinal features                 2
8              Numeric features                19
9          Categorical features                 7
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16              Remove outliers              True
17           Outliers threshold              0.05
18                Fix imbalance              True
19         Fix imbalance method             SMOTE
20                    Normalize              True
21             Normalize method            robust
22               Fold Generator   StratifiedKFold
23                  Fold Number                10
24                     CPU Jobs                 1
25                      Use GPU             False
26               Log Experiment             False
27              Experiment Name  clf-default-name
28                          USI              cede
2025-12-01 15:03:30,743:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-01 15:03:30,747:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-01 15:03:30,850:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-01 15:03:30,854:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-01 15:03:30,856:INFO:setup() successfully completed in 1.54s...............
2025-12-01 15:03:30,890:INFO:Initializing compare_models()
2025-12-01 15:03:30,890:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f56dc1329b0>, include=None, fold=None, round=4, cross_validation=True, sort=Recall, n_select=3, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x7f56dc1329b0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Recall', 'n_select': 3, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2025-12-01 15:03:30,890:INFO:Checking exceptions
2025-12-01 15:03:30,895:INFO:Preparing display monitor
2025-12-01 15:03:30,936:INFO:Initializing Logistic Regression
2025-12-01 15:03:30,936:INFO:Total runtime is 3.3775965372721353e-06 minutes
2025-12-01 15:03:30,941:INFO:SubProcess create_model() called ==================================
2025-12-01 15:03:30,942:INFO:Initializing create_model()
2025-12-01 15:03:30,942:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f56dc1329b0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f56dc132ec0>, model_only=True, return_train_score=False, kwargs={})
2025-12-01 15:03:30,942:INFO:Checking exceptions
2025-12-01 15:03:30,942:INFO:Importing libraries
2025-12-01 15:03:30,942:INFO:Copying training dataset
2025-12-01 15:03:30,948:INFO:Defining folds
2025-12-01 15:03:30,948:INFO:Declaring metric variables
2025-12-01 15:03:30,953:INFO:Importing untrained model
2025-12-01 15:03:30,958:INFO:Logistic Regression Imported successfully
2025-12-01 15:03:30,968:INFO:Starting cross validation
2025-12-01 15:03:30,971:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-12-01 15:03:30,977:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 7 members, which is less than n_splits=10.
  warnings.warn(

2025-12-01 15:03:32,351:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 401, in _score
    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 214, in wrapper
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 627, in roc_auc_score
    return _average_binary_score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-12-01 15:03:32,354:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 15:03:32,714:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 401, in _score
    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 214, in wrapper
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 627, in roc_auc_score
    return _average_binary_score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-12-01 15:03:32,717:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 15:03:33,075:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 401, in _score
    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 214, in wrapper
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 627, in roc_auc_score
    return _average_binary_score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-12-01 15:03:33,078:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 15:03:33,590:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:425: FitFailedWarning:
5 fits failed out of a total of 10.
The score on these train-test partitions for these parameters will be set to 0.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
4 fits failed with the following error:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/model_selection/_validation.py", line 729, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 255, in fit
    X, y, _ = self._fit(X, y, **fit_params_steps)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 238, in _fit
    X, y = self._memory_transform(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/joblib/memory.py", line 594, in __call__
    return self._cached_call(args, kwargs)[0]
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/memory.py", line 398, in _cached_call
    out, metadata = self.call(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/memory.py", line 309, in call
    output = self.func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 77, in _transform_one
    output = transformer.transform(*args)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 157, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 259, in transform
    output = self.transformer.transform(*args)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 157, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 546, in transform
    X, y = self.estimator.fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/base.py", line 208, in fit_resample
    return super().fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/base.py", line 112, in fit_resample
    output = self._fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/over_sampling/_smote/base.py", line 389, in _fit_resample
    nns = self.nn_k_.kneighbors(X_class, return_distance=False)[:, 1:]
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/neighbors/_base.py", line 808, in kneighbors
    raise ValueError(
ValueError: Expected n_neighbors <= n_samples,  but n_samples = 5, n_neighbors = 6

--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/model_selection/_validation.py", line 729, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 255, in fit
    X, y, _ = self._fit(X, y, **fit_params_steps)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 238, in _fit
    X, y = self._memory_transform(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/joblib/memory.py", line 594, in __call__
    return self._cached_call(args, kwargs)[0]
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/memory.py", line 398, in _cached_call
    out, metadata = self.call(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/memory.py", line 309, in call
    output = self.func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 77, in _transform_one
    output = transformer.transform(*args)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 157, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 259, in transform
    output = self.transformer.transform(*args)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 157, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 546, in transform
    X, y = self.estimator.fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/base.py", line 208, in fit_resample
    return super().fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/base.py", line 112, in fit_resample
    output = self._fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/over_sampling/_smote/base.py", line 389, in _fit_resample
    nns = self.nn_k_.kneighbors(X_class, return_distance=False)[:, 1:]
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/neighbors/_base.py", line 808, in kneighbors
    raise ValueError(
ValueError: Expected n_neighbors <= n_samples,  but n_samples = 4, n_neighbors = 6

  warnings.warn(some_fits_failed_message, FitFailedWarning)

2025-12-01 15:03:33,591:INFO:Calculating mean and std
2025-12-01 15:03:33,593:INFO:Creating metrics dataframe
2025-12-01 15:03:33,605:INFO:Uploading results into container
2025-12-01 15:03:33,605:INFO:Uploading model into container now
2025-12-01 15:03:33,606:INFO:_master_model_container: 1
2025-12-01 15:03:33,606:INFO:_display_container: 2
2025-12-01 15:03:33,606:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-12-01 15:03:33,606:INFO:create_model() successfully completed......................................
2025-12-01 15:03:33,728:WARNING:create_model() for LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) raised an exception or returned all 0.0, trying without fit_kwargs:
2025-12-01 15:03:33,729:WARNING:Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 795, in compare_models
    np.sum(
AssertionError

2025-12-01 15:03:33,729:INFO:Initializing create_model()
2025-12-01 15:03:33,729:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f56dc1329b0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f56dc132ec0>, model_only=True, return_train_score=False, kwargs={})
2025-12-01 15:03:33,729:INFO:Checking exceptions
2025-12-01 15:03:33,729:INFO:Importing libraries
2025-12-01 15:03:33,729:INFO:Copying training dataset
2025-12-01 15:03:33,735:INFO:Defining folds
2025-12-01 15:03:33,735:INFO:Declaring metric variables
2025-12-01 15:03:33,741:INFO:Importing untrained model
2025-12-01 15:03:33,746:INFO:Logistic Regression Imported successfully
2025-12-01 15:03:33,756:INFO:Starting cross validation
2025-12-01 15:03:33,758:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-12-01 15:03:33,762:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 7 members, which is less than n_splits=10.
  warnings.warn(

2025-12-01 15:03:35,026:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 795, in compare_models
    np.sum(
AssertionError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 401, in _score
    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 214, in wrapper
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 627, in roc_auc_score
    return _average_binary_score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-12-01 15:03:35,029:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 15:03:35,379:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 795, in compare_models
    np.sum(
AssertionError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 401, in _score
    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 214, in wrapper
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 627, in roc_auc_score
    return _average_binary_score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-12-01 15:03:35,382:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 15:03:35,730:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 795, in compare_models
    np.sum(
AssertionError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 401, in _score
    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 214, in wrapper
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 627, in roc_auc_score
    return _average_binary_score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-12-01 15:03:35,733:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 15:03:36,337:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:425: FitFailedWarning:
5 fits failed out of a total of 10.
The score on these train-test partitions for these parameters will be set to 0.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
4 fits failed with the following error:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 795, in compare_models
    np.sum(
AssertionError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/model_selection/_validation.py", line 729, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 255, in fit
    X, y, _ = self._fit(X, y, **fit_params_steps)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 238, in _fit
    X, y = self._memory_transform(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/joblib/memory.py", line 594, in __call__
    return self._cached_call(args, kwargs)[0]
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/memory.py", line 398, in _cached_call
    out, metadata = self.call(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/memory.py", line 309, in call
    output = self.func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 77, in _transform_one
    output = transformer.transform(*args)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 157, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 259, in transform
    output = self.transformer.transform(*args)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 157, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 546, in transform
    X, y = self.estimator.fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/base.py", line 208, in fit_resample
    return super().fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/base.py", line 112, in fit_resample
    output = self._fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/over_sampling/_smote/base.py", line 389, in _fit_resample
    nns = self.nn_k_.kneighbors(X_class, return_distance=False)[:, 1:]
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/neighbors/_base.py", line 808, in kneighbors
    raise ValueError(
ValueError: Expected n_neighbors <= n_samples,  but n_samples = 5, n_neighbors = 6

--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 795, in compare_models
    np.sum(
AssertionError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/model_selection/_validation.py", line 729, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 255, in fit
    X, y, _ = self._fit(X, y, **fit_params_steps)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 238, in _fit
    X, y = self._memory_transform(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/joblib/memory.py", line 594, in __call__
    return self._cached_call(args, kwargs)[0]
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/memory.py", line 398, in _cached_call
    out, metadata = self.call(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/memory.py", line 309, in call
    output = self.func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 77, in _transform_one
    output = transformer.transform(*args)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 157, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 259, in transform
    output = self.transformer.transform(*args)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 157, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 546, in transform
    X, y = self.estimator.fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/base.py", line 208, in fit_resample
    return super().fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/base.py", line 112, in fit_resample
    output = self._fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/over_sampling/_smote/base.py", line 389, in _fit_resample
    nns = self.nn_k_.kneighbors(X_class, return_distance=False)[:, 1:]
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/neighbors/_base.py", line 808, in kneighbors
    raise ValueError(
ValueError: Expected n_neighbors <= n_samples,  but n_samples = 4, n_neighbors = 6

  warnings.warn(some_fits_failed_message, FitFailedWarning)

2025-12-01 15:03:36,339:INFO:Calculating mean and std
2025-12-01 15:03:36,342:INFO:Creating metrics dataframe
2025-12-01 15:03:36,364:INFO:Uploading results into container
2025-12-01 15:03:36,366:INFO:Uploading model into container now
2025-12-01 15:03:36,367:INFO:_master_model_container: 2
2025-12-01 15:03:36,367:INFO:_display_container: 2
2025-12-01 15:03:36,368:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-12-01 15:03:36,368:INFO:create_model() successfully completed......................................
2025-12-01 15:03:36,514:ERROR:create_model() for LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) raised an exception or returned all 0.0:
2025-12-01 15:03:36,514:ERROR:Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 795, in compare_models
    np.sum(
AssertionError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 811, in compare_models
    np.sum(
AssertionError

2025-12-01 15:03:36,514:INFO:Initializing K Neighbors Classifier
2025-12-01 15:03:36,514:INFO:Total runtime is 0.09296875397364299 minutes
2025-12-01 15:03:36,522:INFO:SubProcess create_model() called ==================================
2025-12-01 15:03:36,522:INFO:Initializing create_model()
2025-12-01 15:03:36,523:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f56dc1329b0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f56dc132ec0>, model_only=True, return_train_score=False, kwargs={})
2025-12-01 15:03:36,523:INFO:Checking exceptions
2025-12-01 15:03:36,523:INFO:Importing libraries
2025-12-01 15:03:36,523:INFO:Copying training dataset
2025-12-01 15:03:36,531:INFO:Defining folds
2025-12-01 15:03:36,531:INFO:Declaring metric variables
2025-12-01 15:03:36,538:INFO:Importing untrained model
2025-12-01 15:03:36,545:INFO:K Neighbors Classifier Imported successfully
2025-12-01 15:03:36,557:INFO:Starting cross validation
2025-12-01 15:03:36,561:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-12-01 15:03:36,567:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 7 members, which is less than n_splits=10.
  warnings.warn(

2025-12-01 15:03:38,397:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 401, in _score
    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 214, in wrapper
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 627, in roc_auc_score
    return _average_binary_score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-12-01 15:03:38,400:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 15:03:38,740:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 401, in _score
    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 214, in wrapper
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 627, in roc_auc_score
    return _average_binary_score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-12-01 15:03:38,743:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 15:03:39,090:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 401, in _score
    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 214, in wrapper
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 627, in roc_auc_score
    return _average_binary_score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-12-01 15:03:39,093:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 15:03:39,589:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:425: FitFailedWarning:
5 fits failed out of a total of 10.
The score on these train-test partitions for these parameters will be set to 0.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
4 fits failed with the following error:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/model_selection/_validation.py", line 729, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 255, in fit
    X, y, _ = self._fit(X, y, **fit_params_steps)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 238, in _fit
    X, y = self._memory_transform(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/joblib/memory.py", line 594, in __call__
    return self._cached_call(args, kwargs)[0]
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/memory.py", line 398, in _cached_call
    out, metadata = self.call(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/memory.py", line 309, in call
    output = self.func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 77, in _transform_one
    output = transformer.transform(*args)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 157, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 259, in transform
    output = self.transformer.transform(*args)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 157, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 546, in transform
    X, y = self.estimator.fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/base.py", line 208, in fit_resample
    return super().fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/base.py", line 112, in fit_resample
    output = self._fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/over_sampling/_smote/base.py", line 389, in _fit_resample
    nns = self.nn_k_.kneighbors(X_class, return_distance=False)[:, 1:]
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/neighbors/_base.py", line 808, in kneighbors
    raise ValueError(
ValueError: Expected n_neighbors <= n_samples,  but n_samples = 5, n_neighbors = 6

--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/model_selection/_validation.py", line 729, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 255, in fit
    X, y, _ = self._fit(X, y, **fit_params_steps)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 238, in _fit
    X, y = self._memory_transform(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/joblib/memory.py", line 594, in __call__
    return self._cached_call(args, kwargs)[0]
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/memory.py", line 398, in _cached_call
    out, metadata = self.call(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/memory.py", line 309, in call
    output = self.func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 77, in _transform_one
    output = transformer.transform(*args)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 157, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 259, in transform
    output = self.transformer.transform(*args)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 157, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 546, in transform
    X, y = self.estimator.fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/base.py", line 208, in fit_resample
    return super().fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/base.py", line 112, in fit_resample
    output = self._fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/over_sampling/_smote/base.py", line 389, in _fit_resample
    nns = self.nn_k_.kneighbors(X_class, return_distance=False)[:, 1:]
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/neighbors/_base.py", line 808, in kneighbors
    raise ValueError(
ValueError: Expected n_neighbors <= n_samples,  but n_samples = 4, n_neighbors = 6

  warnings.warn(some_fits_failed_message, FitFailedWarning)

2025-12-01 15:03:39,589:INFO:Calculating mean and std
2025-12-01 15:03:39,591:INFO:Creating metrics dataframe
2025-12-01 15:03:39,603:INFO:Uploading results into container
2025-12-01 15:03:39,604:INFO:Uploading model into container now
2025-12-01 15:03:39,604:INFO:_master_model_container: 3
2025-12-01 15:03:39,604:INFO:_display_container: 2
2025-12-01 15:03:39,604:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=1, n_neighbors=5, p=2,
                     weights='uniform')
2025-12-01 15:03:39,604:INFO:create_model() successfully completed......................................
2025-12-01 15:03:39,713:WARNING:create_model() for KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=1, n_neighbors=5, p=2,
                     weights='uniform') raised an exception or returned all 0.0, trying without fit_kwargs:
2025-12-01 15:03:39,714:WARNING:Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 795, in compare_models
    np.sum(
AssertionError

2025-12-01 15:03:39,714:INFO:Initializing create_model()
2025-12-01 15:03:39,714:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f56dc1329b0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f56dc132ec0>, model_only=True, return_train_score=False, kwargs={})
2025-12-01 15:03:39,714:INFO:Checking exceptions
2025-12-01 15:03:39,714:INFO:Importing libraries
2025-12-01 15:03:39,714:INFO:Copying training dataset
2025-12-01 15:03:39,719:INFO:Defining folds
2025-12-01 15:03:39,720:INFO:Declaring metric variables
2025-12-01 15:03:39,725:INFO:Importing untrained model
2025-12-01 15:03:39,730:INFO:K Neighbors Classifier Imported successfully
2025-12-01 15:03:39,740:INFO:Starting cross validation
2025-12-01 15:03:39,742:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-12-01 15:03:39,747:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 7 members, which is less than n_splits=10.
  warnings.warn(

2025-12-01 15:03:40,963:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 795, in compare_models
    np.sum(
AssertionError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 401, in _score
    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 214, in wrapper
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 627, in roc_auc_score
    return _average_binary_score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-12-01 15:03:40,966:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 15:03:41,307:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 795, in compare_models
    np.sum(
AssertionError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 401, in _score
    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 214, in wrapper
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 627, in roc_auc_score
    return _average_binary_score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-12-01 15:03:41,310:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 15:03:41,650:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 795, in compare_models
    np.sum(
AssertionError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 401, in _score
    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 214, in wrapper
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 627, in roc_auc_score
    return _average_binary_score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-12-01 15:03:41,653:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 15:03:42,150:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:425: FitFailedWarning:
5 fits failed out of a total of 10.
The score on these train-test partitions for these parameters will be set to 0.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
4 fits failed with the following error:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 795, in compare_models
    np.sum(
AssertionError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/model_selection/_validation.py", line 729, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 255, in fit
    X, y, _ = self._fit(X, y, **fit_params_steps)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 238, in _fit
    X, y = self._memory_transform(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/joblib/memory.py", line 594, in __call__
    return self._cached_call(args, kwargs)[0]
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/memory.py", line 398, in _cached_call
    out, metadata = self.call(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/memory.py", line 309, in call
    output = self.func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 77, in _transform_one
    output = transformer.transform(*args)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 157, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 259, in transform
    output = self.transformer.transform(*args)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 157, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 546, in transform
    X, y = self.estimator.fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/base.py", line 208, in fit_resample
    return super().fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/base.py", line 112, in fit_resample
    output = self._fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/over_sampling/_smote/base.py", line 389, in _fit_resample
    nns = self.nn_k_.kneighbors(X_class, return_distance=False)[:, 1:]
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/neighbors/_base.py", line 808, in kneighbors
    raise ValueError(
ValueError: Expected n_neighbors <= n_samples,  but n_samples = 5, n_neighbors = 6

--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 795, in compare_models
    np.sum(
AssertionError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/model_selection/_validation.py", line 729, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 255, in fit
    X, y, _ = self._fit(X, y, **fit_params_steps)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 238, in _fit
    X, y = self._memory_transform(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/joblib/memory.py", line 594, in __call__
    return self._cached_call(args, kwargs)[0]
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/memory.py", line 398, in _cached_call
    out, metadata = self.call(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/memory.py", line 309, in call
    output = self.func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 77, in _transform_one
    output = transformer.transform(*args)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 157, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 259, in transform
    output = self.transformer.transform(*args)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 157, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 546, in transform
    X, y = self.estimator.fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/base.py", line 208, in fit_resample
    return super().fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/base.py", line 112, in fit_resample
    output = self._fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/over_sampling/_smote/base.py", line 389, in _fit_resample
    nns = self.nn_k_.kneighbors(X_class, return_distance=False)[:, 1:]
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/neighbors/_base.py", line 808, in kneighbors
    raise ValueError(
ValueError: Expected n_neighbors <= n_samples,  but n_samples = 4, n_neighbors = 6

  warnings.warn(some_fits_failed_message, FitFailedWarning)

2025-12-01 15:03:42,151:INFO:Calculating mean and std
2025-12-01 15:03:42,153:INFO:Creating metrics dataframe
2025-12-01 15:03:42,165:INFO:Uploading results into container
2025-12-01 15:03:42,165:INFO:Uploading model into container now
2025-12-01 15:03:42,166:INFO:_master_model_container: 4
2025-12-01 15:03:42,166:INFO:_display_container: 2
2025-12-01 15:03:42,166:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=1, n_neighbors=5, p=2,
                     weights='uniform')
2025-12-01 15:03:42,166:INFO:create_model() successfully completed......................................
2025-12-01 15:03:42,281:ERROR:create_model() for KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=1, n_neighbors=5, p=2,
                     weights='uniform') raised an exception or returned all 0.0:
2025-12-01 15:03:42,281:ERROR:Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 795, in compare_models
    np.sum(
AssertionError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 811, in compare_models
    np.sum(
AssertionError

2025-12-01 15:03:42,281:INFO:Initializing Naive Bayes
2025-12-01 15:03:42,281:INFO:Total runtime is 0.1890844980875651 minutes
2025-12-01 15:03:42,287:INFO:SubProcess create_model() called ==================================
2025-12-01 15:03:42,287:INFO:Initializing create_model()
2025-12-01 15:03:42,287:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f56dc1329b0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f56dc132ec0>, model_only=True, return_train_score=False, kwargs={})
2025-12-01 15:03:42,287:INFO:Checking exceptions
2025-12-01 15:03:42,287:INFO:Importing libraries
2025-12-01 15:03:42,287:INFO:Copying training dataset
2025-12-01 15:03:42,293:INFO:Defining folds
2025-12-01 15:03:42,294:INFO:Declaring metric variables
2025-12-01 15:03:42,299:INFO:Importing untrained model
2025-12-01 15:03:42,304:INFO:Naive Bayes Imported successfully
2025-12-01 15:03:42,314:INFO:Starting cross validation
2025-12-01 15:03:42,316:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-12-01 15:03:42,320:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 7 members, which is less than n_splits=10.
  warnings.warn(

2025-12-01 15:03:43,529:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 401, in _score
    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 214, in wrapper
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 627, in roc_auc_score
    return _average_binary_score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-12-01 15:03:43,532:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 15:03:43,870:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 401, in _score
    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 214, in wrapper
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 627, in roc_auc_score
    return _average_binary_score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-12-01 15:03:43,873:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 15:03:44,218:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 401, in _score
    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 214, in wrapper
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 627, in roc_auc_score
    return _average_binary_score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-12-01 15:03:44,221:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 15:03:44,708:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:425: FitFailedWarning:
5 fits failed out of a total of 10.
The score on these train-test partitions for these parameters will be set to 0.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
4 fits failed with the following error:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/model_selection/_validation.py", line 729, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 255, in fit
    X, y, _ = self._fit(X, y, **fit_params_steps)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 238, in _fit
    X, y = self._memory_transform(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/joblib/memory.py", line 594, in __call__
    return self._cached_call(args, kwargs)[0]
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/memory.py", line 398, in _cached_call
    out, metadata = self.call(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/memory.py", line 309, in call
    output = self.func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 77, in _transform_one
    output = transformer.transform(*args)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 157, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 259, in transform
    output = self.transformer.transform(*args)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 157, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 546, in transform
    X, y = self.estimator.fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/base.py", line 208, in fit_resample
    return super().fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/base.py", line 112, in fit_resample
    output = self._fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/over_sampling/_smote/base.py", line 389, in _fit_resample
    nns = self.nn_k_.kneighbors(X_class, return_distance=False)[:, 1:]
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/neighbors/_base.py", line 808, in kneighbors
    raise ValueError(
ValueError: Expected n_neighbors <= n_samples,  but n_samples = 5, n_neighbors = 6

--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/model_selection/_validation.py", line 729, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 255, in fit
    X, y, _ = self._fit(X, y, **fit_params_steps)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 238, in _fit
    X, y = self._memory_transform(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/joblib/memory.py", line 594, in __call__
    return self._cached_call(args, kwargs)[0]
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/memory.py", line 398, in _cached_call
    out, metadata = self.call(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/memory.py", line 309, in call
    output = self.func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 77, in _transform_one
    output = transformer.transform(*args)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 157, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 259, in transform
    output = self.transformer.transform(*args)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 157, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 546, in transform
    X, y = self.estimator.fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/base.py", line 208, in fit_resample
    return super().fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/base.py", line 112, in fit_resample
    output = self._fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/over_sampling/_smote/base.py", line 389, in _fit_resample
    nns = self.nn_k_.kneighbors(X_class, return_distance=False)[:, 1:]
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/neighbors/_base.py", line 808, in kneighbors
    raise ValueError(
ValueError: Expected n_neighbors <= n_samples,  but n_samples = 4, n_neighbors = 6

  warnings.warn(some_fits_failed_message, FitFailedWarning)

2025-12-01 15:03:44,709:INFO:Calculating mean and std
2025-12-01 15:03:44,710:INFO:Creating metrics dataframe
2025-12-01 15:03:44,722:INFO:Uploading results into container
2025-12-01 15:03:44,723:INFO:Uploading model into container now
2025-12-01 15:03:44,723:INFO:_master_model_container: 5
2025-12-01 15:03:44,723:INFO:_display_container: 2
2025-12-01 15:03:44,723:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-12-01 15:03:44,724:INFO:create_model() successfully completed......................................
2025-12-01 15:03:44,833:WARNING:create_model() for GaussianNB(priors=None, var_smoothing=1e-09) raised an exception or returned all 0.0, trying without fit_kwargs:
2025-12-01 15:03:44,834:WARNING:Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 795, in compare_models
    np.sum(
AssertionError

2025-12-01 15:03:44,834:INFO:Initializing create_model()
2025-12-01 15:03:44,834:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f56dc1329b0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f56dc132ec0>, model_only=True, return_train_score=False, kwargs={})
2025-12-01 15:03:44,834:INFO:Checking exceptions
2025-12-01 15:03:44,834:INFO:Importing libraries
2025-12-01 15:03:44,834:INFO:Copying training dataset
2025-12-01 15:03:44,839:INFO:Defining folds
2025-12-01 15:03:44,840:INFO:Declaring metric variables
2025-12-01 15:03:44,846:INFO:Importing untrained model
2025-12-01 15:03:44,852:INFO:Naive Bayes Imported successfully
2025-12-01 15:03:44,862:INFO:Starting cross validation
2025-12-01 15:03:44,866:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-12-01 15:03:44,871:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 7 members, which is less than n_splits=10.
  warnings.warn(

2025-12-01 15:03:46,107:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 795, in compare_models
    np.sum(
AssertionError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 401, in _score
    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 214, in wrapper
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 627, in roc_auc_score
    return _average_binary_score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-12-01 15:03:46,110:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 15:03:46,452:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 795, in compare_models
    np.sum(
AssertionError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 401, in _score
    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 214, in wrapper
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 627, in roc_auc_score
    return _average_binary_score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-12-01 15:03:46,454:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 15:03:46,793:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 795, in compare_models
    np.sum(
AssertionError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 401, in _score
    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 214, in wrapper
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 627, in roc_auc_score
    return _average_binary_score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-12-01 15:03:46,796:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 15:03:47,305:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:425: FitFailedWarning:
5 fits failed out of a total of 10.
The score on these train-test partitions for these parameters will be set to 0.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
4 fits failed with the following error:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 795, in compare_models
    np.sum(
AssertionError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/model_selection/_validation.py", line 729, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 255, in fit
    X, y, _ = self._fit(X, y, **fit_params_steps)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 238, in _fit
    X, y = self._memory_transform(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/joblib/memory.py", line 594, in __call__
    return self._cached_call(args, kwargs)[0]
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/memory.py", line 398, in _cached_call
    out, metadata = self.call(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/memory.py", line 309, in call
    output = self.func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 77, in _transform_one
    output = transformer.transform(*args)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 157, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 259, in transform
    output = self.transformer.transform(*args)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 157, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 546, in transform
    X, y = self.estimator.fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/base.py", line 208, in fit_resample
    return super().fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/base.py", line 112, in fit_resample
    output = self._fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/over_sampling/_smote/base.py", line 389, in _fit_resample
    nns = self.nn_k_.kneighbors(X_class, return_distance=False)[:, 1:]
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/neighbors/_base.py", line 808, in kneighbors
    raise ValueError(
ValueError: Expected n_neighbors <= n_samples,  but n_samples = 5, n_neighbors = 6

--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 795, in compare_models
    np.sum(
AssertionError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/model_selection/_validation.py", line 729, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 255, in fit
    X, y, _ = self._fit(X, y, **fit_params_steps)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 238, in _fit
    X, y = self._memory_transform(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/joblib/memory.py", line 594, in __call__
    return self._cached_call(args, kwargs)[0]
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/memory.py", line 398, in _cached_call
    out, metadata = self.call(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/memory.py", line 309, in call
    output = self.func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 77, in _transform_one
    output = transformer.transform(*args)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 157, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 259, in transform
    output = self.transformer.transform(*args)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 157, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 546, in transform
    X, y = self.estimator.fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/base.py", line 208, in fit_resample
    return super().fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/base.py", line 112, in fit_resample
    output = self._fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/over_sampling/_smote/base.py", line 389, in _fit_resample
    nns = self.nn_k_.kneighbors(X_class, return_distance=False)[:, 1:]
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/neighbors/_base.py", line 808, in kneighbors
    raise ValueError(
ValueError: Expected n_neighbors <= n_samples,  but n_samples = 4, n_neighbors = 6

  warnings.warn(some_fits_failed_message, FitFailedWarning)

2025-12-01 15:03:47,306:INFO:Calculating mean and std
2025-12-01 15:03:47,307:INFO:Creating metrics dataframe
2025-12-01 15:03:47,319:INFO:Uploading results into container
2025-12-01 15:03:47,320:INFO:Uploading model into container now
2025-12-01 15:03:47,321:INFO:_master_model_container: 6
2025-12-01 15:03:47,321:INFO:_display_container: 2
2025-12-01 15:03:47,321:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-12-01 15:03:47,321:INFO:create_model() successfully completed......................................
2025-12-01 15:03:47,436:ERROR:create_model() for GaussianNB(priors=None, var_smoothing=1e-09) raised an exception or returned all 0.0:
2025-12-01 15:03:47,437:ERROR:Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 795, in compare_models
    np.sum(
AssertionError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 811, in compare_models
    np.sum(
AssertionError

2025-12-01 15:03:47,437:INFO:Initializing Decision Tree Classifier
2025-12-01 15:03:47,437:INFO:Total runtime is 0.2750118613243103 minutes
2025-12-01 15:03:47,442:INFO:SubProcess create_model() called ==================================
2025-12-01 15:03:47,443:INFO:Initializing create_model()
2025-12-01 15:03:47,443:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f56dc1329b0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f56dc132ec0>, model_only=True, return_train_score=False, kwargs={})
2025-12-01 15:03:47,443:INFO:Checking exceptions
2025-12-01 15:03:47,443:INFO:Importing libraries
2025-12-01 15:03:47,443:INFO:Copying training dataset
2025-12-01 15:03:47,449:INFO:Defining folds
2025-12-01 15:03:47,449:INFO:Declaring metric variables
2025-12-01 15:03:47,455:INFO:Importing untrained model
2025-12-01 15:03:47,460:INFO:Decision Tree Classifier Imported successfully
2025-12-01 15:03:47,470:INFO:Starting cross validation
2025-12-01 15:03:47,472:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-12-01 15:03:47,476:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 7 members, which is less than n_splits=10.
  warnings.warn(

2025-12-01 15:03:48,701:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 401, in _score
    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 214, in wrapper
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 627, in roc_auc_score
    return _average_binary_score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-12-01 15:03:48,704:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 15:03:48,707:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 15:03:48,710:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1760: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2025-12-01 15:03:48,712:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:697: RuntimeWarning: invalid value encountered in double_scalars
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-12-01 15:03:49,048:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 401, in _score
    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 214, in wrapper
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 627, in roc_auc_score
    return _average_binary_score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-12-01 15:03:49,051:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 15:03:49,402:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 401, in _score
    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 214, in wrapper
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 627, in roc_auc_score
    return _average_binary_score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-12-01 15:03:49,405:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 15:03:49,408:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 15:03:49,411:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1760: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2025-12-01 15:03:49,413:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:697: RuntimeWarning: invalid value encountered in double_scalars
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-12-01 15:03:49,899:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:425: FitFailedWarning:
5 fits failed out of a total of 10.
The score on these train-test partitions for these parameters will be set to 0.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
4 fits failed with the following error:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/model_selection/_validation.py", line 729, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 255, in fit
    X, y, _ = self._fit(X, y, **fit_params_steps)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 238, in _fit
    X, y = self._memory_transform(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/joblib/memory.py", line 594, in __call__
    return self._cached_call(args, kwargs)[0]
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/memory.py", line 398, in _cached_call
    out, metadata = self.call(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/memory.py", line 309, in call
    output = self.func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 77, in _transform_one
    output = transformer.transform(*args)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 157, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 259, in transform
    output = self.transformer.transform(*args)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 157, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 546, in transform
    X, y = self.estimator.fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/base.py", line 208, in fit_resample
    return super().fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/base.py", line 112, in fit_resample
    output = self._fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/over_sampling/_smote/base.py", line 389, in _fit_resample
    nns = self.nn_k_.kneighbors(X_class, return_distance=False)[:, 1:]
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/neighbors/_base.py", line 808, in kneighbors
    raise ValueError(
ValueError: Expected n_neighbors <= n_samples,  but n_samples = 5, n_neighbors = 6

--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/model_selection/_validation.py", line 729, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 255, in fit
    X, y, _ = self._fit(X, y, **fit_params_steps)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 238, in _fit
    X, y = self._memory_transform(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/joblib/memory.py", line 594, in __call__
    return self._cached_call(args, kwargs)[0]
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/memory.py", line 398, in _cached_call
    out, metadata = self.call(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/memory.py", line 309, in call
    output = self.func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 77, in _transform_one
    output = transformer.transform(*args)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 157, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 259, in transform
    output = self.transformer.transform(*args)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 157, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 546, in transform
    X, y = self.estimator.fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/base.py", line 208, in fit_resample
    return super().fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/base.py", line 112, in fit_resample
    output = self._fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/over_sampling/_smote/base.py", line 389, in _fit_resample
    nns = self.nn_k_.kneighbors(X_class, return_distance=False)[:, 1:]
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/neighbors/_base.py", line 808, in kneighbors
    raise ValueError(
ValueError: Expected n_neighbors <= n_samples,  but n_samples = 4, n_neighbors = 6

  warnings.warn(some_fits_failed_message, FitFailedWarning)

2025-12-01 15:03:49,900:INFO:Calculating mean and std
2025-12-01 15:03:49,901:INFO:Creating metrics dataframe
2025-12-01 15:03:49,913:INFO:Uploading results into container
2025-12-01 15:03:49,914:INFO:Uploading model into container now
2025-12-01 15:03:49,914:INFO:_master_model_container: 7
2025-12-01 15:03:49,914:INFO:_display_container: 2
2025-12-01 15:03:49,915:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=42, splitter='best')
2025-12-01 15:03:49,915:INFO:create_model() successfully completed......................................
2025-12-01 15:03:50,028:WARNING:create_model() for DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=42, splitter='best') raised an exception or returned all 0.0, trying without fit_kwargs:
2025-12-01 15:03:50,028:WARNING:Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 795, in compare_models
    np.sum(
AssertionError

2025-12-01 15:03:50,028:INFO:Initializing create_model()
2025-12-01 15:03:50,029:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f56dc1329b0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f56dc132ec0>, model_only=True, return_train_score=False, kwargs={})
2025-12-01 15:03:50,029:INFO:Checking exceptions
2025-12-01 15:03:50,029:INFO:Importing libraries
2025-12-01 15:03:50,029:INFO:Copying training dataset
2025-12-01 15:03:50,034:INFO:Defining folds
2025-12-01 15:03:50,034:INFO:Declaring metric variables
2025-12-01 15:03:50,040:INFO:Importing untrained model
2025-12-01 15:03:50,045:INFO:Decision Tree Classifier Imported successfully
2025-12-01 15:03:50,056:INFO:Starting cross validation
2025-12-01 15:03:50,059:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-12-01 15:03:50,063:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 7 members, which is less than n_splits=10.
  warnings.warn(

2025-12-01 15:03:51,297:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 795, in compare_models
    np.sum(
AssertionError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 401, in _score
    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 214, in wrapper
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 627, in roc_auc_score
    return _average_binary_score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-12-01 15:03:51,300:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 15:03:51,303:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 15:03:51,306:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1760: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2025-12-01 15:03:51,308:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:697: RuntimeWarning: invalid value encountered in double_scalars
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-12-01 15:03:51,649:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 795, in compare_models
    np.sum(
AssertionError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 401, in _score
    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 214, in wrapper
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 627, in roc_auc_score
    return _average_binary_score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-12-01 15:03:51,652:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 15:03:52,005:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 795, in compare_models
    np.sum(
AssertionError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 401, in _score
    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 214, in wrapper
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 627, in roc_auc_score
    return _average_binary_score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-12-01 15:03:52,008:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 15:03:52,012:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 15:03:52,015:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1760: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2025-12-01 15:03:52,016:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:697: RuntimeWarning: invalid value encountered in double_scalars
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-12-01 15:03:52,510:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:425: FitFailedWarning:
5 fits failed out of a total of 10.
The score on these train-test partitions for these parameters will be set to 0.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
4 fits failed with the following error:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 795, in compare_models
    np.sum(
AssertionError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/model_selection/_validation.py", line 729, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 255, in fit
    X, y, _ = self._fit(X, y, **fit_params_steps)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 238, in _fit
    X, y = self._memory_transform(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/joblib/memory.py", line 594, in __call__
    return self._cached_call(args, kwargs)[0]
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/memory.py", line 398, in _cached_call
    out, metadata = self.call(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/memory.py", line 309, in call
    output = self.func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 77, in _transform_one
    output = transformer.transform(*args)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 157, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 259, in transform
    output = self.transformer.transform(*args)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 157, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 546, in transform
    X, y = self.estimator.fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/base.py", line 208, in fit_resample
    return super().fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/base.py", line 112, in fit_resample
    output = self._fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/over_sampling/_smote/base.py", line 389, in _fit_resample
    nns = self.nn_k_.kneighbors(X_class, return_distance=False)[:, 1:]
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/neighbors/_base.py", line 808, in kneighbors
    raise ValueError(
ValueError: Expected n_neighbors <= n_samples,  but n_samples = 5, n_neighbors = 6

--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 795, in compare_models
    np.sum(
AssertionError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/model_selection/_validation.py", line 729, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 255, in fit
    X, y, _ = self._fit(X, y, **fit_params_steps)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 238, in _fit
    X, y = self._memory_transform(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/joblib/memory.py", line 594, in __call__
    return self._cached_call(args, kwargs)[0]
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/memory.py", line 398, in _cached_call
    out, metadata = self.call(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/memory.py", line 309, in call
    output = self.func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 77, in _transform_one
    output = transformer.transform(*args)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 157, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 259, in transform
    output = self.transformer.transform(*args)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 157, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 546, in transform
    X, y = self.estimator.fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/base.py", line 208, in fit_resample
    return super().fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/base.py", line 112, in fit_resample
    output = self._fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/over_sampling/_smote/base.py", line 389, in _fit_resample
    nns = self.nn_k_.kneighbors(X_class, return_distance=False)[:, 1:]
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/neighbors/_base.py", line 808, in kneighbors
    raise ValueError(
ValueError: Expected n_neighbors <= n_samples,  but n_samples = 4, n_neighbors = 6

  warnings.warn(some_fits_failed_message, FitFailedWarning)

2025-12-01 15:03:52,511:INFO:Calculating mean and std
2025-12-01 15:03:52,513:INFO:Creating metrics dataframe
2025-12-01 15:03:52,524:INFO:Uploading results into container
2025-12-01 15:03:52,525:INFO:Uploading model into container now
2025-12-01 15:03:52,526:INFO:_master_model_container: 8
2025-12-01 15:03:52,526:INFO:_display_container: 2
2025-12-01 15:03:52,526:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=42, splitter='best')
2025-12-01 15:03:52,526:INFO:create_model() successfully completed......................................
2025-12-01 15:03:52,647:ERROR:create_model() for DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=42, splitter='best') raised an exception or returned all 0.0:
2025-12-01 15:03:52,647:ERROR:Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 795, in compare_models
    np.sum(
AssertionError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 811, in compare_models
    np.sum(
AssertionError

2025-12-01 15:03:52,648:INFO:Initializing SVM - Linear Kernel
2025-12-01 15:03:52,648:INFO:Total runtime is 0.36185552279154465 minutes
2025-12-01 15:03:52,653:INFO:SubProcess create_model() called ==================================
2025-12-01 15:03:52,654:INFO:Initializing create_model()
2025-12-01 15:03:52,654:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f56dc1329b0>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f56dc132ec0>, model_only=True, return_train_score=False, kwargs={})
2025-12-01 15:03:52,654:INFO:Checking exceptions
2025-12-01 15:03:52,654:INFO:Importing libraries
2025-12-01 15:03:52,654:INFO:Copying training dataset
2025-12-01 15:03:52,660:INFO:Defining folds
2025-12-01 15:03:52,660:INFO:Declaring metric variables
2025-12-01 15:03:52,666:INFO:Importing untrained model
2025-12-01 15:03:52,671:INFO:SVM - Linear Kernel Imported successfully
2025-12-01 15:03:52,681:INFO:Starting cross validation
2025-12-01 15:03:52,684:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-12-01 15:03:52,688:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 7 members, which is less than n_splits=10.
  warnings.warn(

2025-12-01 15:03:53,216:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_response.py", line 181, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1939, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2025-12-01 15:03:53,773:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_response.py", line 181, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1939, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2025-12-01 15:03:53,776:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 15:03:53,779:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 15:03:53,783:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1760: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2025-12-01 15:03:53,784:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:697: RuntimeWarning: invalid value encountered in double_scalars
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-12-01 15:03:54,045:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_response.py", line 181, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1939, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2025-12-01 15:03:54,048:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 15:03:54,322:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_response.py", line 181, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1939, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2025-12-01 15:03:54,326:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 15:03:54,593:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_response.py", line 181, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1939, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2025-12-01 15:03:54,745:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:425: FitFailedWarning:
5 fits failed out of a total of 10.
The score on these train-test partitions for these parameters will be set to 0.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
4 fits failed with the following error:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/model_selection/_validation.py", line 729, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 255, in fit
    X, y, _ = self._fit(X, y, **fit_params_steps)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 238, in _fit
    X, y = self._memory_transform(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/joblib/memory.py", line 594, in __call__
    return self._cached_call(args, kwargs)[0]
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/memory.py", line 398, in _cached_call
    out, metadata = self.call(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/memory.py", line 309, in call
    output = self.func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 77, in _transform_one
    output = transformer.transform(*args)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 157, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 259, in transform
    output = self.transformer.transform(*args)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 157, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 546, in transform
    X, y = self.estimator.fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/base.py", line 208, in fit_resample
    return super().fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/base.py", line 112, in fit_resample
    output = self._fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/over_sampling/_smote/base.py", line 389, in _fit_resample
    nns = self.nn_k_.kneighbors(X_class, return_distance=False)[:, 1:]
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/neighbors/_base.py", line 808, in kneighbors
    raise ValueError(
ValueError: Expected n_neighbors <= n_samples,  but n_samples = 5, n_neighbors = 6

--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/model_selection/_validation.py", line 729, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 255, in fit
    X, y, _ = self._fit(X, y, **fit_params_steps)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 238, in _fit
    X, y = self._memory_transform(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/joblib/memory.py", line 594, in __call__
    return self._cached_call(args, kwargs)[0]
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/memory.py", line 398, in _cached_call
    out, metadata = self.call(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/memory.py", line 309, in call
    output = self.func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 77, in _transform_one
    output = transformer.transform(*args)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 157, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 259, in transform
    output = self.transformer.transform(*args)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 157, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 546, in transform
    X, y = self.estimator.fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/base.py", line 208, in fit_resample
    return super().fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/base.py", line 112, in fit_resample
    output = self._fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/over_sampling/_smote/base.py", line 389, in _fit_resample
    nns = self.nn_k_.kneighbors(X_class, return_distance=False)[:, 1:]
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/neighbors/_base.py", line 808, in kneighbors
    raise ValueError(
ValueError: Expected n_neighbors <= n_samples,  but n_samples = 4, n_neighbors = 6

  warnings.warn(some_fits_failed_message, FitFailedWarning)

2025-12-01 15:03:54,746:INFO:Calculating mean and std
2025-12-01 15:03:54,748:INFO:Creating metrics dataframe
2025-12-01 15:03:54,759:INFO:Uploading results into container
2025-12-01 15:03:54,760:INFO:Uploading model into container now
2025-12-01 15:03:54,760:INFO:_master_model_container: 9
2025-12-01 15:03:54,760:INFO:_display_container: 2
2025-12-01 15:03:54,761:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=1, penalty='l2',
              power_t=0.5, random_state=42, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-12-01 15:03:54,761:INFO:create_model() successfully completed......................................
2025-12-01 15:03:54,873:WARNING:create_model() for SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=1, penalty='l2',
              power_t=0.5, random_state=42, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False) raised an exception or returned all 0.0, trying without fit_kwargs:
2025-12-01 15:03:54,874:WARNING:Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 795, in compare_models
    np.sum(
AssertionError

2025-12-01 15:03:54,874:INFO:Initializing create_model()
2025-12-01 15:03:54,874:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f56dc1329b0>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f56dc132ec0>, model_only=True, return_train_score=False, kwargs={})
2025-12-01 15:03:54,874:INFO:Checking exceptions
2025-12-01 15:03:54,874:INFO:Importing libraries
2025-12-01 15:03:54,874:INFO:Copying training dataset
2025-12-01 15:03:54,879:INFO:Defining folds
2025-12-01 15:03:54,879:INFO:Declaring metric variables
2025-12-01 15:03:54,885:INFO:Importing untrained model
2025-12-01 15:03:54,890:INFO:SVM - Linear Kernel Imported successfully
2025-12-01 15:03:54,899:INFO:Starting cross validation
2025-12-01 15:03:54,902:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-12-01 15:03:54,906:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 7 members, which is less than n_splits=10.
  warnings.warn(

2025-12-01 15:03:55,421:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 795, in compare_models
    np.sum(
AssertionError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_response.py", line 181, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1939, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2025-12-01 15:03:56,125:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 795, in compare_models
    np.sum(
AssertionError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_response.py", line 181, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1939, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2025-12-01 15:03:56,128:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 15:03:56,132:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 15:03:56,135:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1760: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2025-12-01 15:03:56,137:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:697: RuntimeWarning: invalid value encountered in double_scalars
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-12-01 15:03:56,399:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 795, in compare_models
    np.sum(
AssertionError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_response.py", line 181, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1939, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2025-12-01 15:03:56,402:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 15:03:56,668:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 795, in compare_models
    np.sum(
AssertionError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_response.py", line 181, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1939, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2025-12-01 15:03:56,671:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 15:03:56,934:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 795, in compare_models
    np.sum(
AssertionError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_response.py", line 181, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1939, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2025-12-01 15:03:57,090:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:425: FitFailedWarning:
5 fits failed out of a total of 10.
The score on these train-test partitions for these parameters will be set to 0.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
4 fits failed with the following error:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 795, in compare_models
    np.sum(
AssertionError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/model_selection/_validation.py", line 729, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 255, in fit
    X, y, _ = self._fit(X, y, **fit_params_steps)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 238, in _fit
    X, y = self._memory_transform(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/joblib/memory.py", line 594, in __call__
    return self._cached_call(args, kwargs)[0]
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/memory.py", line 398, in _cached_call
    out, metadata = self.call(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/memory.py", line 309, in call
    output = self.func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 77, in _transform_one
    output = transformer.transform(*args)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 157, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 259, in transform
    output = self.transformer.transform(*args)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 157, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 546, in transform
    X, y = self.estimator.fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/base.py", line 208, in fit_resample
    return super().fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/base.py", line 112, in fit_resample
    output = self._fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/over_sampling/_smote/base.py", line 389, in _fit_resample
    nns = self.nn_k_.kneighbors(X_class, return_distance=False)[:, 1:]
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/neighbors/_base.py", line 808, in kneighbors
    raise ValueError(
ValueError: Expected n_neighbors <= n_samples,  but n_samples = 5, n_neighbors = 6

--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 795, in compare_models
    np.sum(
AssertionError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/model_selection/_validation.py", line 729, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 255, in fit
    X, y, _ = self._fit(X, y, **fit_params_steps)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 238, in _fit
    X, y = self._memory_transform(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/joblib/memory.py", line 594, in __call__
    return self._cached_call(args, kwargs)[0]
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/memory.py", line 398, in _cached_call
    out, metadata = self.call(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/memory.py", line 309, in call
    output = self.func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 77, in _transform_one
    output = transformer.transform(*args)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 157, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 259, in transform
    output = self.transformer.transform(*args)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 157, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 546, in transform
    X, y = self.estimator.fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/base.py", line 208, in fit_resample
    return super().fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/base.py", line 112, in fit_resample
    output = self._fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/over_sampling/_smote/base.py", line 389, in _fit_resample
    nns = self.nn_k_.kneighbors(X_class, return_distance=False)[:, 1:]
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/neighbors/_base.py", line 808, in kneighbors
    raise ValueError(
ValueError: Expected n_neighbors <= n_samples,  but n_samples = 4, n_neighbors = 6

  warnings.warn(some_fits_failed_message, FitFailedWarning)

2025-12-01 15:03:57,091:INFO:Calculating mean and std
2025-12-01 15:03:57,093:INFO:Creating metrics dataframe
2025-12-01 15:03:57,105:INFO:Uploading results into container
2025-12-01 15:03:57,106:INFO:Uploading model into container now
2025-12-01 15:03:57,106:INFO:_master_model_container: 10
2025-12-01 15:03:57,106:INFO:_display_container: 2
2025-12-01 15:03:57,107:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=1, penalty='l2',
              power_t=0.5, random_state=42, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-12-01 15:03:57,107:INFO:create_model() successfully completed......................................
2025-12-01 15:03:57,221:ERROR:create_model() for SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=1, penalty='l2',
              power_t=0.5, random_state=42, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False) raised an exception or returned all 0.0:
2025-12-01 15:03:57,222:ERROR:Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 795, in compare_models
    np.sum(
AssertionError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 811, in compare_models
    np.sum(
AssertionError

2025-12-01 15:03:57,222:INFO:Initializing Ridge Classifier
2025-12-01 15:03:57,222:INFO:Total runtime is 0.43809098800023405 minutes
2025-12-01 15:03:57,227:INFO:SubProcess create_model() called ==================================
2025-12-01 15:03:57,227:INFO:Initializing create_model()
2025-12-01 15:03:57,227:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f56dc1329b0>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f56dc132ec0>, model_only=True, return_train_score=False, kwargs={})
2025-12-01 15:03:57,228:INFO:Checking exceptions
2025-12-01 15:03:57,228:INFO:Importing libraries
2025-12-01 15:03:57,228:INFO:Copying training dataset
2025-12-01 15:03:57,234:INFO:Defining folds
2025-12-01 15:03:57,234:INFO:Declaring metric variables
2025-12-01 15:03:57,239:INFO:Importing untrained model
2025-12-01 15:03:57,247:INFO:Ridge Classifier Imported successfully
2025-12-01 15:03:57,260:INFO:Starting cross validation
2025-12-01 15:03:57,264:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-12-01 15:03:57,270:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 7 members, which is less than n_splits=10.
  warnings.warn(

2025-12-01 15:03:57,790:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_response.py", line 181, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1939, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2025-12-01 15:03:58,343:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_response.py", line 181, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1939, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2025-12-01 15:03:58,346:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 15:03:58,610:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_response.py", line 181, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1939, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2025-12-01 15:03:58,613:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 15:03:58,878:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_response.py", line 181, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1939, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2025-12-01 15:03:58,881:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 15:03:59,156:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_response.py", line 181, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1939, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2025-12-01 15:03:59,314:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:425: FitFailedWarning:
5 fits failed out of a total of 10.
The score on these train-test partitions for these parameters will be set to 0.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
4 fits failed with the following error:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/model_selection/_validation.py", line 729, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 255, in fit
    X, y, _ = self._fit(X, y, **fit_params_steps)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 238, in _fit
    X, y = self._memory_transform(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/joblib/memory.py", line 594, in __call__
    return self._cached_call(args, kwargs)[0]
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/memory.py", line 398, in _cached_call
    out, metadata = self.call(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/memory.py", line 309, in call
    output = self.func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 77, in _transform_one
    output = transformer.transform(*args)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 157, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 259, in transform
    output = self.transformer.transform(*args)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 157, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 546, in transform
    X, y = self.estimator.fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/base.py", line 208, in fit_resample
    return super().fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/base.py", line 112, in fit_resample
    output = self._fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/over_sampling/_smote/base.py", line 389, in _fit_resample
    nns = self.nn_k_.kneighbors(X_class, return_distance=False)[:, 1:]
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/neighbors/_base.py", line 808, in kneighbors
    raise ValueError(
ValueError: Expected n_neighbors <= n_samples,  but n_samples = 5, n_neighbors = 6

--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/model_selection/_validation.py", line 729, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 255, in fit
    X, y, _ = self._fit(X, y, **fit_params_steps)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 238, in _fit
    X, y = self._memory_transform(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/joblib/memory.py", line 594, in __call__
    return self._cached_call(args, kwargs)[0]
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/memory.py", line 398, in _cached_call
    out, metadata = self.call(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/memory.py", line 309, in call
    output = self.func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 77, in _transform_one
    output = transformer.transform(*args)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 157, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 259, in transform
    output = self.transformer.transform(*args)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 157, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 546, in transform
    X, y = self.estimator.fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/base.py", line 208, in fit_resample
    return super().fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/base.py", line 112, in fit_resample
    output = self._fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/over_sampling/_smote/base.py", line 389, in _fit_resample
    nns = self.nn_k_.kneighbors(X_class, return_distance=False)[:, 1:]
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/neighbors/_base.py", line 808, in kneighbors
    raise ValueError(
ValueError: Expected n_neighbors <= n_samples,  but n_samples = 4, n_neighbors = 6

  warnings.warn(some_fits_failed_message, FitFailedWarning)

2025-12-01 15:03:59,315:INFO:Calculating mean and std
2025-12-01 15:03:59,316:INFO:Creating metrics dataframe
2025-12-01 15:03:59,329:INFO:Uploading results into container
2025-12-01 15:03:59,329:INFO:Uploading model into container now
2025-12-01 15:03:59,330:INFO:_master_model_container: 11
2025-12-01 15:03:59,330:INFO:_display_container: 2
2025-12-01 15:03:59,330:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001)
2025-12-01 15:03:59,330:INFO:create_model() successfully completed......................................
2025-12-01 15:03:59,453:WARNING:create_model() for RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001) raised an exception or returned all 0.0, trying without fit_kwargs:
2025-12-01 15:03:59,454:WARNING:Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 795, in compare_models
    np.sum(
AssertionError

2025-12-01 15:03:59,454:INFO:Initializing create_model()
2025-12-01 15:03:59,454:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f56dc1329b0>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f56dc132ec0>, model_only=True, return_train_score=False, kwargs={})
2025-12-01 15:03:59,454:INFO:Checking exceptions
2025-12-01 15:03:59,454:INFO:Importing libraries
2025-12-01 15:03:59,454:INFO:Copying training dataset
2025-12-01 15:03:59,460:INFO:Defining folds
2025-12-01 15:03:59,460:INFO:Declaring metric variables
2025-12-01 15:03:59,466:INFO:Importing untrained model
2025-12-01 15:03:59,471:INFO:Ridge Classifier Imported successfully
2025-12-01 15:03:59,480:INFO:Starting cross validation
2025-12-01 15:03:59,483:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-12-01 15:03:59,487:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 7 members, which is less than n_splits=10.
  warnings.warn(

2025-12-01 15:04:00,013:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 795, in compare_models
    np.sum(
AssertionError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_response.py", line 181, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1939, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2025-12-01 15:04:00,575:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 795, in compare_models
    np.sum(
AssertionError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_response.py", line 181, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1939, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2025-12-01 15:04:00,578:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 15:04:00,850:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 795, in compare_models
    np.sum(
AssertionError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_response.py", line 181, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1939, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2025-12-01 15:04:00,853:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 15:04:01,129:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 795, in compare_models
    np.sum(
AssertionError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_response.py", line 181, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1939, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2025-12-01 15:04:01,132:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 15:04:01,407:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 795, in compare_models
    np.sum(
AssertionError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_response.py", line 181, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1939, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2025-12-01 15:04:01,567:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:425: FitFailedWarning:
5 fits failed out of a total of 10.
The score on these train-test partitions for these parameters will be set to 0.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
4 fits failed with the following error:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 795, in compare_models
    np.sum(
AssertionError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/model_selection/_validation.py", line 729, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 255, in fit
    X, y, _ = self._fit(X, y, **fit_params_steps)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 238, in _fit
    X, y = self._memory_transform(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/joblib/memory.py", line 594, in __call__
    return self._cached_call(args, kwargs)[0]
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/memory.py", line 398, in _cached_call
    out, metadata = self.call(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/memory.py", line 309, in call
    output = self.func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 77, in _transform_one
    output = transformer.transform(*args)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 157, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 259, in transform
    output = self.transformer.transform(*args)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 157, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 546, in transform
    X, y = self.estimator.fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/base.py", line 208, in fit_resample
    return super().fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/base.py", line 112, in fit_resample
    output = self._fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/over_sampling/_smote/base.py", line 389, in _fit_resample
    nns = self.nn_k_.kneighbors(X_class, return_distance=False)[:, 1:]
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/neighbors/_base.py", line 808, in kneighbors
    raise ValueError(
ValueError: Expected n_neighbors <= n_samples,  but n_samples = 5, n_neighbors = 6

--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 795, in compare_models
    np.sum(
AssertionError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/model_selection/_validation.py", line 729, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 255, in fit
    X, y, _ = self._fit(X, y, **fit_params_steps)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 238, in _fit
    X, y = self._memory_transform(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/joblib/memory.py", line 594, in __call__
    return self._cached_call(args, kwargs)[0]
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/memory.py", line 398, in _cached_call
    out, metadata = self.call(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/memory.py", line 309, in call
    output = self.func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 77, in _transform_one
    output = transformer.transform(*args)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 157, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 259, in transform
    output = self.transformer.transform(*args)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 157, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 546, in transform
    X, y = self.estimator.fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/base.py", line 208, in fit_resample
    return super().fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/base.py", line 112, in fit_resample
    output = self._fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/over_sampling/_smote/base.py", line 389, in _fit_resample
    nns = self.nn_k_.kneighbors(X_class, return_distance=False)[:, 1:]
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/neighbors/_base.py", line 808, in kneighbors
    raise ValueError(
ValueError: Expected n_neighbors <= n_samples,  but n_samples = 4, n_neighbors = 6

  warnings.warn(some_fits_failed_message, FitFailedWarning)

2025-12-01 15:04:01,568:INFO:Calculating mean and std
2025-12-01 15:04:01,570:INFO:Creating metrics dataframe
2025-12-01 15:04:01,582:INFO:Uploading results into container
2025-12-01 15:04:01,583:INFO:Uploading model into container now
2025-12-01 15:04:01,583:INFO:_master_model_container: 12
2025-12-01 15:04:01,583:INFO:_display_container: 2
2025-12-01 15:04:01,584:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001)
2025-12-01 15:04:01,584:INFO:create_model() successfully completed......................................
2025-12-01 15:04:01,707:ERROR:create_model() for RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001) raised an exception or returned all 0.0:
2025-12-01 15:04:01,707:ERROR:Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 795, in compare_models
    np.sum(
AssertionError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 811, in compare_models
    np.sum(
AssertionError

2025-12-01 15:04:01,707:INFO:Initializing Random Forest Classifier
2025-12-01 15:04:01,707:INFO:Total runtime is 0.5128514091173808 minutes
2025-12-01 15:04:01,713:INFO:SubProcess create_model() called ==================================
2025-12-01 15:04:01,713:INFO:Initializing create_model()
2025-12-01 15:04:01,713:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f56dc1329b0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f56dc132ec0>, model_only=True, return_train_score=False, kwargs={})
2025-12-01 15:04:01,713:INFO:Checking exceptions
2025-12-01 15:04:01,713:INFO:Importing libraries
2025-12-01 15:04:01,713:INFO:Copying training dataset
2025-12-01 15:04:01,720:INFO:Defining folds
2025-12-01 15:04:01,720:INFO:Declaring metric variables
2025-12-01 15:04:01,725:INFO:Importing untrained model
2025-12-01 15:04:01,731:INFO:Random Forest Classifier Imported successfully
2025-12-01 15:04:01,740:INFO:Starting cross validation
2025-12-01 15:04:01,743:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-12-01 15:04:01,748:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 7 members, which is less than n_splits=10.
  warnings.warn(

2025-12-01 15:04:02,947:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 15:04:04,150:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 401, in _score
    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 214, in wrapper
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 627, in roc_auc_score
    return _average_binary_score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-12-01 15:04:04,153:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 15:04:04,156:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 15:04:04,159:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1760: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2025-12-01 15:04:04,161:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:697: RuntimeWarning: invalid value encountered in double_scalars
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-12-01 15:04:05,077:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 401, in _score
    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 214, in wrapper
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 627, in roc_auc_score
    return _average_binary_score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-12-01 15:04:05,080:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 15:04:05,084:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 15:04:05,087:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1760: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2025-12-01 15:04:05,088:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:697: RuntimeWarning: invalid value encountered in double_scalars
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-12-01 15:04:06,248:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 401, in _score
    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 214, in wrapper
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 627, in roc_auc_score
    return _average_binary_score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-12-01 15:04:06,251:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 15:04:06,255:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 15:04:06,259:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1760: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2025-12-01 15:04:06,261:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:697: RuntimeWarning: invalid value encountered in double_scalars
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-12-01 15:04:07,342:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:425: FitFailedWarning:
5 fits failed out of a total of 10.
The score on these train-test partitions for these parameters will be set to 0.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
4 fits failed with the following error:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/model_selection/_validation.py", line 729, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 255, in fit
    X, y, _ = self._fit(X, y, **fit_params_steps)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 238, in _fit
    X, y = self._memory_transform(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/joblib/memory.py", line 594, in __call__
    return self._cached_call(args, kwargs)[0]
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/memory.py", line 398, in _cached_call
    out, metadata = self.call(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/memory.py", line 309, in call
    output = self.func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 77, in _transform_one
    output = transformer.transform(*args)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 157, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 259, in transform
    output = self.transformer.transform(*args)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 157, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 546, in transform
    X, y = self.estimator.fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/base.py", line 208, in fit_resample
    return super().fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/base.py", line 112, in fit_resample
    output = self._fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/over_sampling/_smote/base.py", line 389, in _fit_resample
    nns = self.nn_k_.kneighbors(X_class, return_distance=False)[:, 1:]
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/neighbors/_base.py", line 808, in kneighbors
    raise ValueError(
ValueError: Expected n_neighbors <= n_samples,  but n_samples = 5, n_neighbors = 6

--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/model_selection/_validation.py", line 729, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 255, in fit
    X, y, _ = self._fit(X, y, **fit_params_steps)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 238, in _fit
    X, y = self._memory_transform(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/joblib/memory.py", line 594, in __call__
    return self._cached_call(args, kwargs)[0]
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/memory.py", line 398, in _cached_call
    out, metadata = self.call(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/memory.py", line 309, in call
    output = self.func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 77, in _transform_one
    output = transformer.transform(*args)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 157, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 259, in transform
    output = self.transformer.transform(*args)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 157, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 546, in transform
    X, y = self.estimator.fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/base.py", line 208, in fit_resample
    return super().fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/base.py", line 112, in fit_resample
    output = self._fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/over_sampling/_smote/base.py", line 389, in _fit_resample
    nns = self.nn_k_.kneighbors(X_class, return_distance=False)[:, 1:]
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/neighbors/_base.py", line 808, in kneighbors
    raise ValueError(
ValueError: Expected n_neighbors <= n_samples,  but n_samples = 4, n_neighbors = 6

  warnings.warn(some_fits_failed_message, FitFailedWarning)

2025-12-01 15:04:07,343:INFO:Calculating mean and std
2025-12-01 15:04:07,345:INFO:Creating metrics dataframe
2025-12-01 15:04:07,357:INFO:Uploading results into container
2025-12-01 15:04:07,357:INFO:Uploading model into container now
2025-12-01 15:04:07,358:INFO:_master_model_container: 13
2025-12-01 15:04:07,358:INFO:_display_container: 2
2025-12-01 15:04:07,358:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=1, oob_score=False,
                       random_state=42, verbose=0, warm_start=False)
2025-12-01 15:04:07,359:INFO:create_model() successfully completed......................................
2025-12-01 15:04:07,472:WARNING:create_model() for RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=1, oob_score=False,
                       random_state=42, verbose=0, warm_start=False) raised an exception or returned all 0.0, trying without fit_kwargs:
2025-12-01 15:04:07,472:WARNING:Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 795, in compare_models
    np.sum(
AssertionError

2025-12-01 15:04:07,473:INFO:Initializing create_model()
2025-12-01 15:04:07,473:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f56dc1329b0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f56dc132ec0>, model_only=True, return_train_score=False, kwargs={})
2025-12-01 15:04:07,473:INFO:Checking exceptions
2025-12-01 15:04:07,473:INFO:Importing libraries
2025-12-01 15:04:07,473:INFO:Copying training dataset
2025-12-01 15:04:07,478:INFO:Defining folds
2025-12-01 15:04:07,478:INFO:Declaring metric variables
2025-12-01 15:04:07,484:INFO:Importing untrained model
2025-12-01 15:04:07,489:INFO:Random Forest Classifier Imported successfully
2025-12-01 15:04:07,499:INFO:Starting cross validation
2025-12-01 15:04:07,502:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-12-01 15:04:07,505:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 7 members, which is less than n_splits=10.
  warnings.warn(

2025-12-01 15:04:08,316:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 15:04:09,154:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 795, in compare_models
    np.sum(
AssertionError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 401, in _score
    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 214, in wrapper
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 627, in roc_auc_score
    return _average_binary_score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-12-01 15:04:09,158:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 15:04:09,162:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 15:04:09,169:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1760: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2025-12-01 15:04:09,172:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:697: RuntimeWarning: invalid value encountered in double_scalars
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-12-01 15:04:09,720:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 795, in compare_models
    np.sum(
AssertionError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 401, in _score
    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 214, in wrapper
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 627, in roc_auc_score
    return _average_binary_score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-12-01 15:04:09,723:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 15:04:09,726:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 15:04:09,729:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1760: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2025-12-01 15:04:09,731:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:697: RuntimeWarning: invalid value encountered in double_scalars
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-12-01 15:04:10,301:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 795, in compare_models
    np.sum(
AssertionError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 401, in _score
    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 214, in wrapper
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 627, in roc_auc_score
    return _average_binary_score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-12-01 15:04:10,304:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 15:04:10,308:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 15:04:10,311:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1760: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2025-12-01 15:04:10,313:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:697: RuntimeWarning: invalid value encountered in double_scalars
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-12-01 15:04:11,014:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:425: FitFailedWarning:
5 fits failed out of a total of 10.
The score on these train-test partitions for these parameters will be set to 0.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
4 fits failed with the following error:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 795, in compare_models
    np.sum(
AssertionError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/model_selection/_validation.py", line 729, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 255, in fit
    X, y, _ = self._fit(X, y, **fit_params_steps)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 238, in _fit
    X, y = self._memory_transform(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/joblib/memory.py", line 594, in __call__
    return self._cached_call(args, kwargs)[0]
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/memory.py", line 398, in _cached_call
    out, metadata = self.call(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/memory.py", line 309, in call
    output = self.func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 77, in _transform_one
    output = transformer.transform(*args)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 157, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 259, in transform
    output = self.transformer.transform(*args)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 157, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 546, in transform
    X, y = self.estimator.fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/base.py", line 208, in fit_resample
    return super().fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/base.py", line 112, in fit_resample
    output = self._fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/over_sampling/_smote/base.py", line 389, in _fit_resample
    nns = self.nn_k_.kneighbors(X_class, return_distance=False)[:, 1:]
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/neighbors/_base.py", line 808, in kneighbors
    raise ValueError(
ValueError: Expected n_neighbors <= n_samples,  but n_samples = 5, n_neighbors = 6

--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 795, in compare_models
    np.sum(
AssertionError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/model_selection/_validation.py", line 729, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 255, in fit
    X, y, _ = self._fit(X, y, **fit_params_steps)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 238, in _fit
    X, y = self._memory_transform(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/joblib/memory.py", line 594, in __call__
    return self._cached_call(args, kwargs)[0]
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/memory.py", line 398, in _cached_call
    out, metadata = self.call(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/memory.py", line 309, in call
    output = self.func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 77, in _transform_one
    output = transformer.transform(*args)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 157, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 259, in transform
    output = self.transformer.transform(*args)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 157, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 546, in transform
    X, y = self.estimator.fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/base.py", line 208, in fit_resample
    return super().fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/base.py", line 112, in fit_resample
    output = self._fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/over_sampling/_smote/base.py", line 389, in _fit_resample
    nns = self.nn_k_.kneighbors(X_class, return_distance=False)[:, 1:]
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/neighbors/_base.py", line 808, in kneighbors
    raise ValueError(
ValueError: Expected n_neighbors <= n_samples,  but n_samples = 4, n_neighbors = 6

  warnings.warn(some_fits_failed_message, FitFailedWarning)

2025-12-01 15:04:11,015:INFO:Calculating mean and std
2025-12-01 15:04:11,017:INFO:Creating metrics dataframe
2025-12-01 15:04:11,030:INFO:Uploading results into container
2025-12-01 15:04:11,031:INFO:Uploading model into container now
2025-12-01 15:04:11,031:INFO:_master_model_container: 14
2025-12-01 15:04:11,031:INFO:_display_container: 2
2025-12-01 15:04:11,032:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=1, oob_score=False,
                       random_state=42, verbose=0, warm_start=False)
2025-12-01 15:04:11,032:INFO:create_model() successfully completed......................................
2025-12-01 15:04:11,140:ERROR:create_model() for RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=1, oob_score=False,
                       random_state=42, verbose=0, warm_start=False) raised an exception or returned all 0.0:
2025-12-01 15:04:11,140:ERROR:Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 795, in compare_models
    np.sum(
AssertionError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 811, in compare_models
    np.sum(
AssertionError

2025-12-01 15:04:11,140:INFO:Initializing Quadratic Discriminant Analysis
2025-12-01 15:04:11,140:INFO:Total runtime is 0.6700653990109762 minutes
2025-12-01 15:04:11,145:INFO:SubProcess create_model() called ==================================
2025-12-01 15:04:11,146:INFO:Initializing create_model()
2025-12-01 15:04:11,146:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f56dc1329b0>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f56dc132ec0>, model_only=True, return_train_score=False, kwargs={})
2025-12-01 15:04:11,146:INFO:Checking exceptions
2025-12-01 15:04:11,146:INFO:Importing libraries
2025-12-01 15:04:11,146:INFO:Copying training dataset
2025-12-01 15:04:11,152:INFO:Defining folds
2025-12-01 15:04:11,153:INFO:Declaring metric variables
2025-12-01 15:04:11,158:INFO:Importing untrained model
2025-12-01 15:04:11,163:INFO:Quadratic Discriminant Analysis Imported successfully
2025-12-01 15:04:11,173:INFO:Starting cross validation
2025-12-01 15:04:11,175:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-12-01 15:04:11,179:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 7 members, which is less than n_splits=10.
  warnings.warn(

2025-12-01 15:04:11,603:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-12-01 15:04:11,764:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 15:04:12,216:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-12-01 15:04:12,371:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 401, in _score
    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 214, in wrapper
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 627, in roc_auc_score
    return _average_binary_score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-12-01 15:04:12,374:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 15:04:12,377:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 15:04:12,380:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1760: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2025-12-01 15:04:12,382:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:697: RuntimeWarning: invalid value encountered in double_scalars
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-12-01 15:04:12,555:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-12-01 15:04:12,711:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 401, in _score
    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 214, in wrapper
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 627, in roc_auc_score
    return _average_binary_score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-12-01 15:04:12,714:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 15:04:12,717:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 15:04:12,721:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1760: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2025-12-01 15:04:12,722:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:697: RuntimeWarning: invalid value encountered in double_scalars
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-12-01 15:04:12,897:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-12-01 15:04:13,055:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 401, in _score
    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 214, in wrapper
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 627, in roc_auc_score
    return _average_binary_score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-12-01 15:04:13,058:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 15:04:13,061:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 15:04:13,064:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1760: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2025-12-01 15:04:13,066:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:697: RuntimeWarning: invalid value encountered in double_scalars
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-12-01 15:04:13,241:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-12-01 15:04:13,401:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 15:04:13,547:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:425: FitFailedWarning:
5 fits failed out of a total of 10.
The score on these train-test partitions for these parameters will be set to 0.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
4 fits failed with the following error:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/model_selection/_validation.py", line 729, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 255, in fit
    X, y, _ = self._fit(X, y, **fit_params_steps)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 238, in _fit
    X, y = self._memory_transform(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/joblib/memory.py", line 594, in __call__
    return self._cached_call(args, kwargs)[0]
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/memory.py", line 398, in _cached_call
    out, metadata = self.call(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/memory.py", line 309, in call
    output = self.func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 77, in _transform_one
    output = transformer.transform(*args)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 157, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 259, in transform
    output = self.transformer.transform(*args)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 157, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 546, in transform
    X, y = self.estimator.fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/base.py", line 208, in fit_resample
    return super().fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/base.py", line 112, in fit_resample
    output = self._fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/over_sampling/_smote/base.py", line 389, in _fit_resample
    nns = self.nn_k_.kneighbors(X_class, return_distance=False)[:, 1:]
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/neighbors/_base.py", line 808, in kneighbors
    raise ValueError(
ValueError: Expected n_neighbors <= n_samples,  but n_samples = 5, n_neighbors = 6

--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/model_selection/_validation.py", line 729, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 255, in fit
    X, y, _ = self._fit(X, y, **fit_params_steps)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 238, in _fit
    X, y = self._memory_transform(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/joblib/memory.py", line 594, in __call__
    return self._cached_call(args, kwargs)[0]
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/memory.py", line 398, in _cached_call
    out, metadata = self.call(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/memory.py", line 309, in call
    output = self.func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 77, in _transform_one
    output = transformer.transform(*args)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 157, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 259, in transform
    output = self.transformer.transform(*args)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 157, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 546, in transform
    X, y = self.estimator.fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/base.py", line 208, in fit_resample
    return super().fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/base.py", line 112, in fit_resample
    output = self._fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/over_sampling/_smote/base.py", line 389, in _fit_resample
    nns = self.nn_k_.kneighbors(X_class, return_distance=False)[:, 1:]
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/neighbors/_base.py", line 808, in kneighbors
    raise ValueError(
ValueError: Expected n_neighbors <= n_samples,  but n_samples = 4, n_neighbors = 6

  warnings.warn(some_fits_failed_message, FitFailedWarning)

2025-12-01 15:04:13,548:INFO:Calculating mean and std
2025-12-01 15:04:13,549:INFO:Creating metrics dataframe
2025-12-01 15:04:13,562:INFO:Uploading results into container
2025-12-01 15:04:13,562:INFO:Uploading model into container now
2025-12-01 15:04:13,563:INFO:_master_model_container: 15
2025-12-01 15:04:13,563:INFO:_display_container: 2
2025-12-01 15:04:13,563:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-12-01 15:04:13,563:INFO:create_model() successfully completed......................................
2025-12-01 15:04:13,669:WARNING:create_model() for QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001) raised an exception or returned all 0.0, trying without fit_kwargs:
2025-12-01 15:04:13,669:WARNING:Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 795, in compare_models
    np.sum(
AssertionError

2025-12-01 15:04:13,670:INFO:Initializing create_model()
2025-12-01 15:04:13,670:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f56dc1329b0>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f56dc132ec0>, model_only=True, return_train_score=False, kwargs={})
2025-12-01 15:04:13,670:INFO:Checking exceptions
2025-12-01 15:04:13,670:INFO:Importing libraries
2025-12-01 15:04:13,670:INFO:Copying training dataset
2025-12-01 15:04:13,675:INFO:Defining folds
2025-12-01 15:04:13,675:INFO:Declaring metric variables
2025-12-01 15:04:13,681:INFO:Importing untrained model
2025-12-01 15:04:13,686:INFO:Quadratic Discriminant Analysis Imported successfully
2025-12-01 15:04:13,695:INFO:Starting cross validation
2025-12-01 15:04:13,698:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-12-01 15:04:13,702:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 7 members, which is less than n_splits=10.
  warnings.warn(

2025-12-01 15:04:14,126:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-12-01 15:04:14,286:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 15:04:14,739:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-12-01 15:04:14,892:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 795, in compare_models
    np.sum(
AssertionError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 401, in _score
    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 214, in wrapper
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 627, in roc_auc_score
    return _average_binary_score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-12-01 15:04:14,895:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 15:04:14,898:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 15:04:14,901:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1760: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2025-12-01 15:04:14,903:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:697: RuntimeWarning: invalid value encountered in double_scalars
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-12-01 15:04:15,078:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-12-01 15:04:15,236:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 795, in compare_models
    np.sum(
AssertionError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 401, in _score
    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 214, in wrapper
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 627, in roc_auc_score
    return _average_binary_score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-12-01 15:04:15,239:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 15:04:15,242:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 15:04:15,246:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1760: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2025-12-01 15:04:15,247:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:697: RuntimeWarning: invalid value encountered in double_scalars
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-12-01 15:04:15,425:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-12-01 15:04:15,579:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 795, in compare_models
    np.sum(
AssertionError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 401, in _score
    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 214, in wrapper
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 627, in roc_auc_score
    return _average_binary_score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-12-01 15:04:15,582:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 15:04:15,585:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 15:04:15,588:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1760: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2025-12-01 15:04:15,590:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:697: RuntimeWarning: invalid value encountered in double_scalars
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-12-01 15:04:15,764:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-12-01 15:04:15,924:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 15:04:16,070:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:425: FitFailedWarning:
5 fits failed out of a total of 10.
The score on these train-test partitions for these parameters will be set to 0.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
4 fits failed with the following error:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 795, in compare_models
    np.sum(
AssertionError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/model_selection/_validation.py", line 729, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 255, in fit
    X, y, _ = self._fit(X, y, **fit_params_steps)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 238, in _fit
    X, y = self._memory_transform(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/joblib/memory.py", line 594, in __call__
    return self._cached_call(args, kwargs)[0]
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/memory.py", line 398, in _cached_call
    out, metadata = self.call(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/memory.py", line 309, in call
    output = self.func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 77, in _transform_one
    output = transformer.transform(*args)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 157, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 259, in transform
    output = self.transformer.transform(*args)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 157, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 546, in transform
    X, y = self.estimator.fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/base.py", line 208, in fit_resample
    return super().fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/base.py", line 112, in fit_resample
    output = self._fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/over_sampling/_smote/base.py", line 389, in _fit_resample
    nns = self.nn_k_.kneighbors(X_class, return_distance=False)[:, 1:]
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/neighbors/_base.py", line 808, in kneighbors
    raise ValueError(
ValueError: Expected n_neighbors <= n_samples,  but n_samples = 5, n_neighbors = 6

--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 795, in compare_models
    np.sum(
AssertionError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/model_selection/_validation.py", line 729, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 255, in fit
    X, y, _ = self._fit(X, y, **fit_params_steps)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 238, in _fit
    X, y = self._memory_transform(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/joblib/memory.py", line 594, in __call__
    return self._cached_call(args, kwargs)[0]
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/memory.py", line 398, in _cached_call
    out, metadata = self.call(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/memory.py", line 309, in call
    output = self.func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 77, in _transform_one
    output = transformer.transform(*args)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 157, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 259, in transform
    output = self.transformer.transform(*args)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 157, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 546, in transform
    X, y = self.estimator.fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/base.py", line 208, in fit_resample
    return super().fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/base.py", line 112, in fit_resample
    output = self._fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/over_sampling/_smote/base.py", line 389, in _fit_resample
    nns = self.nn_k_.kneighbors(X_class, return_distance=False)[:, 1:]
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/neighbors/_base.py", line 808, in kneighbors
    raise ValueError(
ValueError: Expected n_neighbors <= n_samples,  but n_samples = 4, n_neighbors = 6

  warnings.warn(some_fits_failed_message, FitFailedWarning)

2025-12-01 15:04:16,071:INFO:Calculating mean and std
2025-12-01 15:04:16,073:INFO:Creating metrics dataframe
2025-12-01 15:04:16,085:INFO:Uploading results into container
2025-12-01 15:04:16,085:INFO:Uploading model into container now
2025-12-01 15:04:16,086:INFO:_master_model_container: 16
2025-12-01 15:04:16,086:INFO:_display_container: 2
2025-12-01 15:04:16,086:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-12-01 15:04:16,086:INFO:create_model() successfully completed......................................
2025-12-01 15:04:16,199:ERROR:create_model() for QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001) raised an exception or returned all 0.0:
2025-12-01 15:04:16,199:ERROR:Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 795, in compare_models
    np.sum(
AssertionError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 811, in compare_models
    np.sum(
AssertionError

2025-12-01 15:04:16,200:INFO:Initializing Ada Boost Classifier
2025-12-01 15:04:16,200:INFO:Total runtime is 0.754388956228892 minutes
2025-12-01 15:04:16,205:INFO:SubProcess create_model() called ==================================
2025-12-01 15:04:16,205:INFO:Initializing create_model()
2025-12-01 15:04:16,205:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f56dc1329b0>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f56dc132ec0>, model_only=True, return_train_score=False, kwargs={})
2025-12-01 15:04:16,205:INFO:Checking exceptions
2025-12-01 15:04:16,205:INFO:Importing libraries
2025-12-01 15:04:16,206:INFO:Copying training dataset
2025-12-01 15:04:16,217:INFO:Defining folds
2025-12-01 15:04:16,217:INFO:Declaring metric variables
2025-12-01 15:04:16,222:INFO:Importing untrained model
2025-12-01 15:04:16,227:INFO:Ada Boost Classifier Imported successfully
2025-12-01 15:04:16,236:INFO:Starting cross validation
2025-12-01 15:04:16,239:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-12-01 15:04:16,243:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 7 members, which is less than n_splits=10.
  warnings.warn(

2025-12-01 15:04:18,206:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 401, in _score
    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 214, in wrapper
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 627, in roc_auc_score
    return _average_binary_score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-12-01 15:04:18,209:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 15:04:18,213:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 15:04:18,216:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1760: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2025-12-01 15:04:18,218:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:697: RuntimeWarning: invalid value encountered in double_scalars
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-12-01 15:04:18,929:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 401, in _score
    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 214, in wrapper
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 627, in roc_auc_score
    return _average_binary_score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-12-01 15:04:18,932:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 15:04:19,652:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 401, in _score
    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 214, in wrapper
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 627, in roc_auc_score
    return _average_binary_score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-12-01 15:04:19,655:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 15:04:19,658:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 15:04:19,661:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1760: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2025-12-01 15:04:19,663:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:697: RuntimeWarning: invalid value encountered in double_scalars
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-12-01 15:04:20,379:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 15:04:20,527:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:425: FitFailedWarning:
5 fits failed out of a total of 10.
The score on these train-test partitions for these parameters will be set to 0.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
4 fits failed with the following error:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/model_selection/_validation.py", line 729, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 255, in fit
    X, y, _ = self._fit(X, y, **fit_params_steps)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 238, in _fit
    X, y = self._memory_transform(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/joblib/memory.py", line 594, in __call__
    return self._cached_call(args, kwargs)[0]
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/memory.py", line 398, in _cached_call
    out, metadata = self.call(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/memory.py", line 309, in call
    output = self.func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 77, in _transform_one
    output = transformer.transform(*args)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 157, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 259, in transform
    output = self.transformer.transform(*args)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 157, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 546, in transform
    X, y = self.estimator.fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/base.py", line 208, in fit_resample
    return super().fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/base.py", line 112, in fit_resample
    output = self._fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/over_sampling/_smote/base.py", line 389, in _fit_resample
    nns = self.nn_k_.kneighbors(X_class, return_distance=False)[:, 1:]
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/neighbors/_base.py", line 808, in kneighbors
    raise ValueError(
ValueError: Expected n_neighbors <= n_samples,  but n_samples = 5, n_neighbors = 6

--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/model_selection/_validation.py", line 729, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 255, in fit
    X, y, _ = self._fit(X, y, **fit_params_steps)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 238, in _fit
    X, y = self._memory_transform(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/joblib/memory.py", line 594, in __call__
    return self._cached_call(args, kwargs)[0]
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/memory.py", line 398, in _cached_call
    out, metadata = self.call(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/memory.py", line 309, in call
    output = self.func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 77, in _transform_one
    output = transformer.transform(*args)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 157, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 259, in transform
    output = self.transformer.transform(*args)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 157, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 546, in transform
    X, y = self.estimator.fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/base.py", line 208, in fit_resample
    return super().fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/base.py", line 112, in fit_resample
    output = self._fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/over_sampling/_smote/base.py", line 389, in _fit_resample
    nns = self.nn_k_.kneighbors(X_class, return_distance=False)[:, 1:]
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/neighbors/_base.py", line 808, in kneighbors
    raise ValueError(
ValueError: Expected n_neighbors <= n_samples,  but n_samples = 4, n_neighbors = 6

  warnings.warn(some_fits_failed_message, FitFailedWarning)

2025-12-01 15:04:20,528:INFO:Calculating mean and std
2025-12-01 15:04:20,529:INFO:Creating metrics dataframe
2025-12-01 15:04:20,540:INFO:Uploading results into container
2025-12-01 15:04:20,541:INFO:Uploading model into container now
2025-12-01 15:04:20,541:INFO:_master_model_container: 17
2025-12-01 15:04:20,541:INFO:_display_container: 2
2025-12-01 15:04:20,541:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=42)
2025-12-01 15:04:20,541:INFO:create_model() successfully completed......................................
2025-12-01 15:04:20,651:WARNING:create_model() for AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=42) raised an exception or returned all 0.0, trying without fit_kwargs:
2025-12-01 15:04:20,652:WARNING:Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 795, in compare_models
    np.sum(
AssertionError

2025-12-01 15:04:20,652:INFO:Initializing create_model()
2025-12-01 15:04:20,652:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f56dc1329b0>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f56dc132ec0>, model_only=True, return_train_score=False, kwargs={})
2025-12-01 15:04:20,652:INFO:Checking exceptions
2025-12-01 15:04:20,652:INFO:Importing libraries
2025-12-01 15:04:20,652:INFO:Copying training dataset
2025-12-01 15:04:20,656:INFO:Defining folds
2025-12-01 15:04:20,656:INFO:Declaring metric variables
2025-12-01 15:04:20,662:INFO:Importing untrained model
2025-12-01 15:04:20,667:INFO:Ada Boost Classifier Imported successfully
2025-12-01 15:04:20,676:INFO:Starting cross validation
2025-12-01 15:04:20,679:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-12-01 15:04:20,683:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 7 members, which is less than n_splits=10.
  warnings.warn(

2025-12-01 15:04:22,113:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 795, in compare_models
    np.sum(
AssertionError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 401, in _score
    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 214, in wrapper
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 627, in roc_auc_score
    return _average_binary_score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-12-01 15:04:22,116:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 15:04:22,119:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 15:04:22,122:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1760: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2025-12-01 15:04:22,124:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:697: RuntimeWarning: invalid value encountered in double_scalars
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-12-01 15:04:22,566:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 795, in compare_models
    np.sum(
AssertionError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 401, in _score
    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 214, in wrapper
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 627, in roc_auc_score
    return _average_binary_score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-12-01 15:04:22,569:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 15:04:23,018:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 795, in compare_models
    np.sum(
AssertionError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 401, in _score
    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 214, in wrapper
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 627, in roc_auc_score
    return _average_binary_score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-12-01 15:04:23,021:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 15:04:23,024:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 15:04:23,027:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1760: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2025-12-01 15:04:23,029:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:697: RuntimeWarning: invalid value encountered in double_scalars
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-12-01 15:04:23,488:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 15:04:23,639:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:425: FitFailedWarning:
5 fits failed out of a total of 10.
The score on these train-test partitions for these parameters will be set to 0.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
4 fits failed with the following error:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 795, in compare_models
    np.sum(
AssertionError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/model_selection/_validation.py", line 729, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 255, in fit
    X, y, _ = self._fit(X, y, **fit_params_steps)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 238, in _fit
    X, y = self._memory_transform(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/joblib/memory.py", line 594, in __call__
    return self._cached_call(args, kwargs)[0]
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/memory.py", line 398, in _cached_call
    out, metadata = self.call(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/memory.py", line 309, in call
    output = self.func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 77, in _transform_one
    output = transformer.transform(*args)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 157, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 259, in transform
    output = self.transformer.transform(*args)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 157, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 546, in transform
    X, y = self.estimator.fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/base.py", line 208, in fit_resample
    return super().fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/base.py", line 112, in fit_resample
    output = self._fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/over_sampling/_smote/base.py", line 389, in _fit_resample
    nns = self.nn_k_.kneighbors(X_class, return_distance=False)[:, 1:]
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/neighbors/_base.py", line 808, in kneighbors
    raise ValueError(
ValueError: Expected n_neighbors <= n_samples,  but n_samples = 5, n_neighbors = 6

--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 795, in compare_models
    np.sum(
AssertionError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/model_selection/_validation.py", line 729, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 255, in fit
    X, y, _ = self._fit(X, y, **fit_params_steps)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 238, in _fit
    X, y = self._memory_transform(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/joblib/memory.py", line 594, in __call__
    return self._cached_call(args, kwargs)[0]
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/memory.py", line 398, in _cached_call
    out, metadata = self.call(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/memory.py", line 309, in call
    output = self.func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 77, in _transform_one
    output = transformer.transform(*args)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 157, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 259, in transform
    output = self.transformer.transform(*args)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 157, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 546, in transform
    X, y = self.estimator.fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/base.py", line 208, in fit_resample
    return super().fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/base.py", line 112, in fit_resample
    output = self._fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/over_sampling/_smote/base.py", line 389, in _fit_resample
    nns = self.nn_k_.kneighbors(X_class, return_distance=False)[:, 1:]
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/neighbors/_base.py", line 808, in kneighbors
    raise ValueError(
ValueError: Expected n_neighbors <= n_samples,  but n_samples = 4, n_neighbors = 6

  warnings.warn(some_fits_failed_message, FitFailedWarning)

2025-12-01 15:04:23,640:INFO:Calculating mean and std
2025-12-01 15:04:23,641:INFO:Creating metrics dataframe
2025-12-01 15:04:23,652:INFO:Uploading results into container
2025-12-01 15:04:23,652:INFO:Uploading model into container now
2025-12-01 15:04:23,653:INFO:_master_model_container: 18
2025-12-01 15:04:23,653:INFO:_display_container: 2
2025-12-01 15:04:23,653:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=42)
2025-12-01 15:04:23,653:INFO:create_model() successfully completed......................................
2025-12-01 15:04:23,761:ERROR:create_model() for AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=42) raised an exception or returned all 0.0:
2025-12-01 15:04:23,762:ERROR:Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 795, in compare_models
    np.sum(
AssertionError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 811, in compare_models
    np.sum(
AssertionError

2025-12-01 15:04:23,762:INFO:Initializing Gradient Boosting Classifier
2025-12-01 15:04:23,762:INFO:Total runtime is 0.8804280042648316 minutes
2025-12-01 15:04:23,767:INFO:SubProcess create_model() called ==================================
2025-12-01 15:04:23,768:INFO:Initializing create_model()
2025-12-01 15:04:23,768:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f56dc1329b0>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f56dc132ec0>, model_only=True, return_train_score=False, kwargs={})
2025-12-01 15:04:23,768:INFO:Checking exceptions
2025-12-01 15:04:23,768:INFO:Importing libraries
2025-12-01 15:04:23,768:INFO:Copying training dataset
2025-12-01 15:04:23,773:INFO:Defining folds
2025-12-01 15:04:23,773:INFO:Declaring metric variables
2025-12-01 15:04:23,778:INFO:Importing untrained model
2025-12-01 15:04:23,783:INFO:Gradient Boosting Classifier Imported successfully
2025-12-01 15:04:23,792:INFO:Starting cross validation
2025-12-01 15:04:23,795:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-12-01 15:04:23,798:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 7 members, which is less than n_splits=10.
  warnings.warn(

2025-12-01 15:04:26,408:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 401, in _score
    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 214, in wrapper
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 627, in roc_auc_score
    return _average_binary_score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-12-01 15:04:26,411:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 15:04:26,414:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 15:04:26,417:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1760: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2025-12-01 15:04:26,419:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:697: RuntimeWarning: invalid value encountered in double_scalars
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-12-01 15:04:27,442:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 401, in _score
    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 214, in wrapper
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 627, in roc_auc_score
    return _average_binary_score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-12-01 15:04:27,445:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 15:04:28,517:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 401, in _score
    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 214, in wrapper
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 627, in roc_auc_score
    return _average_binary_score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-12-01 15:04:28,520:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 15:04:29,733:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:425: FitFailedWarning:
5 fits failed out of a total of 10.
The score on these train-test partitions for these parameters will be set to 0.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
4 fits failed with the following error:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/model_selection/_validation.py", line 729, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 255, in fit
    X, y, _ = self._fit(X, y, **fit_params_steps)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 238, in _fit
    X, y = self._memory_transform(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/joblib/memory.py", line 594, in __call__
    return self._cached_call(args, kwargs)[0]
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/memory.py", line 398, in _cached_call
    out, metadata = self.call(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/memory.py", line 309, in call
    output = self.func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 77, in _transform_one
    output = transformer.transform(*args)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 157, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 259, in transform
    output = self.transformer.transform(*args)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 157, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 546, in transform
    X, y = self.estimator.fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/base.py", line 208, in fit_resample
    return super().fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/base.py", line 112, in fit_resample
    output = self._fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/over_sampling/_smote/base.py", line 389, in _fit_resample
    nns = self.nn_k_.kneighbors(X_class, return_distance=False)[:, 1:]
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/neighbors/_base.py", line 808, in kneighbors
    raise ValueError(
ValueError: Expected n_neighbors <= n_samples,  but n_samples = 5, n_neighbors = 6

--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/model_selection/_validation.py", line 729, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 255, in fit
    X, y, _ = self._fit(X, y, **fit_params_steps)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 238, in _fit
    X, y = self._memory_transform(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/joblib/memory.py", line 594, in __call__
    return self._cached_call(args, kwargs)[0]
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/memory.py", line 398, in _cached_call
    out, metadata = self.call(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/memory.py", line 309, in call
    output = self.func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 77, in _transform_one
    output = transformer.transform(*args)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 157, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 259, in transform
    output = self.transformer.transform(*args)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 157, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 546, in transform
    X, y = self.estimator.fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/base.py", line 208, in fit_resample
    return super().fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/base.py", line 112, in fit_resample
    output = self._fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/over_sampling/_smote/base.py", line 389, in _fit_resample
    nns = self.nn_k_.kneighbors(X_class, return_distance=False)[:, 1:]
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/neighbors/_base.py", line 808, in kneighbors
    raise ValueError(
ValueError: Expected n_neighbors <= n_samples,  but n_samples = 4, n_neighbors = 6

  warnings.warn(some_fits_failed_message, FitFailedWarning)

2025-12-01 15:04:29,735:INFO:Calculating mean and std
2025-12-01 15:04:29,735:INFO:Creating metrics dataframe
2025-12-01 15:04:29,746:INFO:Uploading results into container
2025-12-01 15:04:29,747:INFO:Uploading model into container now
2025-12-01 15:04:29,748:INFO:_master_model_container: 19
2025-12-01 15:04:29,748:INFO:_display_container: 2
2025-12-01 15:04:29,748:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-12-01 15:04:29,748:INFO:create_model() successfully completed......................................
2025-12-01 15:04:29,864:WARNING:create_model() for GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) raised an exception or returned all 0.0, trying without fit_kwargs:
2025-12-01 15:04:29,864:WARNING:Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 795, in compare_models
    np.sum(
AssertionError

2025-12-01 15:04:29,864:INFO:Initializing create_model()
2025-12-01 15:04:29,864:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f56dc1329b0>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f56dc132ec0>, model_only=True, return_train_score=False, kwargs={})
2025-12-01 15:04:29,865:INFO:Checking exceptions
2025-12-01 15:04:29,865:INFO:Importing libraries
2025-12-01 15:04:29,865:INFO:Copying training dataset
2025-12-01 15:04:29,869:INFO:Defining folds
2025-12-01 15:04:29,869:INFO:Declaring metric variables
2025-12-01 15:04:29,874:INFO:Importing untrained model
2025-12-01 15:04:29,879:INFO:Gradient Boosting Classifier Imported successfully
2025-12-01 15:04:29,889:INFO:Starting cross validation
2025-12-01 15:04:29,891:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-12-01 15:04:29,895:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 7 members, which is less than n_splits=10.
  warnings.warn(

2025-12-01 15:04:31,350:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 795, in compare_models
    np.sum(
AssertionError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 401, in _score
    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 214, in wrapper
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 627, in roc_auc_score
    return _average_binary_score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-12-01 15:04:31,353:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 15:04:31,356:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 15:04:31,359:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1760: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2025-12-01 15:04:31,360:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:697: RuntimeWarning: invalid value encountered in double_scalars
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-12-01 15:04:31,804:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 795, in compare_models
    np.sum(
AssertionError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 401, in _score
    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 214, in wrapper
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 627, in roc_auc_score
    return _average_binary_score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-12-01 15:04:31,807:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 15:04:32,259:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 795, in compare_models
    np.sum(
AssertionError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 401, in _score
    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 214, in wrapper
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 627, in roc_auc_score
    return _average_binary_score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-12-01 15:04:32,262:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 15:04:32,867:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:425: FitFailedWarning:
5 fits failed out of a total of 10.
The score on these train-test partitions for these parameters will be set to 0.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
4 fits failed with the following error:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 795, in compare_models
    np.sum(
AssertionError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/model_selection/_validation.py", line 729, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 255, in fit
    X, y, _ = self._fit(X, y, **fit_params_steps)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 238, in _fit
    X, y = self._memory_transform(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/joblib/memory.py", line 594, in __call__
    return self._cached_call(args, kwargs)[0]
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/memory.py", line 398, in _cached_call
    out, metadata = self.call(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/memory.py", line 309, in call
    output = self.func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 77, in _transform_one
    output = transformer.transform(*args)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 157, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 259, in transform
    output = self.transformer.transform(*args)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 157, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 546, in transform
    X, y = self.estimator.fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/base.py", line 208, in fit_resample
    return super().fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/base.py", line 112, in fit_resample
    output = self._fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/over_sampling/_smote/base.py", line 389, in _fit_resample
    nns = self.nn_k_.kneighbors(X_class, return_distance=False)[:, 1:]
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/neighbors/_base.py", line 808, in kneighbors
    raise ValueError(
ValueError: Expected n_neighbors <= n_samples,  but n_samples = 5, n_neighbors = 6

--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 795, in compare_models
    np.sum(
AssertionError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/model_selection/_validation.py", line 729, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 255, in fit
    X, y, _ = self._fit(X, y, **fit_params_steps)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 238, in _fit
    X, y = self._memory_transform(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/joblib/memory.py", line 594, in __call__
    return self._cached_call(args, kwargs)[0]
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/memory.py", line 398, in _cached_call
    out, metadata = self.call(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/memory.py", line 309, in call
    output = self.func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 77, in _transform_one
    output = transformer.transform(*args)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 157, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 259, in transform
    output = self.transformer.transform(*args)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 157, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 546, in transform
    X, y = self.estimator.fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/base.py", line 208, in fit_resample
    return super().fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/base.py", line 112, in fit_resample
    output = self._fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/over_sampling/_smote/base.py", line 389, in _fit_resample
    nns = self.nn_k_.kneighbors(X_class, return_distance=False)[:, 1:]
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/neighbors/_base.py", line 808, in kneighbors
    raise ValueError(
ValueError: Expected n_neighbors <= n_samples,  but n_samples = 4, n_neighbors = 6

  warnings.warn(some_fits_failed_message, FitFailedWarning)

2025-12-01 15:04:32,868:INFO:Calculating mean and std
2025-12-01 15:04:32,869:INFO:Creating metrics dataframe
2025-12-01 15:04:32,880:INFO:Uploading results into container
2025-12-01 15:04:32,881:INFO:Uploading model into container now
2025-12-01 15:04:32,881:INFO:_master_model_container: 20
2025-12-01 15:04:32,881:INFO:_display_container: 2
2025-12-01 15:04:32,882:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-12-01 15:04:32,882:INFO:create_model() successfully completed......................................
2025-12-01 15:04:32,997:ERROR:create_model() for GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) raised an exception or returned all 0.0:
2025-12-01 15:04:32,997:ERROR:Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 795, in compare_models
    np.sum(
AssertionError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 811, in compare_models
    np.sum(
AssertionError

2025-12-01 15:04:32,997:INFO:Initializing Linear Discriminant Analysis
2025-12-01 15:04:32,997:INFO:Total runtime is 1.0343527356783548 minutes
2025-12-01 15:04:33,003:INFO:SubProcess create_model() called ==================================
2025-12-01 15:04:33,003:INFO:Initializing create_model()
2025-12-01 15:04:33,003:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f56dc1329b0>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f56dc132ec0>, model_only=True, return_train_score=False, kwargs={})
2025-12-01 15:04:33,003:INFO:Checking exceptions
2025-12-01 15:04:33,003:INFO:Importing libraries
2025-12-01 15:04:33,003:INFO:Copying training dataset
2025-12-01 15:04:33,008:INFO:Defining folds
2025-12-01 15:04:33,008:INFO:Declaring metric variables
2025-12-01 15:04:33,013:INFO:Importing untrained model
2025-12-01 15:04:33,018:INFO:Linear Discriminant Analysis Imported successfully
2025-12-01 15:04:33,030:INFO:Starting cross validation
2025-12-01 15:04:33,035:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-12-01 15:04:33,041:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 7 members, which is less than n_splits=10.
  warnings.warn(

2025-12-01 15:04:34,294:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 401, in _score
    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 214, in wrapper
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 627, in roc_auc_score
    return _average_binary_score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-12-01 15:04:34,297:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 15:04:34,644:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 401, in _score
    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 214, in wrapper
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 627, in roc_auc_score
    return _average_binary_score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-12-01 15:04:34,647:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 15:04:34,995:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 401, in _score
    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 214, in wrapper
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 627, in roc_auc_score
    return _average_binary_score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-12-01 15:04:34,998:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 15:04:35,500:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:425: FitFailedWarning:
5 fits failed out of a total of 10.
The score on these train-test partitions for these parameters will be set to 0.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
4 fits failed with the following error:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/model_selection/_validation.py", line 729, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 255, in fit
    X, y, _ = self._fit(X, y, **fit_params_steps)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 238, in _fit
    X, y = self._memory_transform(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/joblib/memory.py", line 594, in __call__
    return self._cached_call(args, kwargs)[0]
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/memory.py", line 398, in _cached_call
    out, metadata = self.call(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/memory.py", line 309, in call
    output = self.func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 77, in _transform_one
    output = transformer.transform(*args)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 157, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 259, in transform
    output = self.transformer.transform(*args)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 157, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 546, in transform
    X, y = self.estimator.fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/base.py", line 208, in fit_resample
    return super().fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/base.py", line 112, in fit_resample
    output = self._fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/over_sampling/_smote/base.py", line 389, in _fit_resample
    nns = self.nn_k_.kneighbors(X_class, return_distance=False)[:, 1:]
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/neighbors/_base.py", line 808, in kneighbors
    raise ValueError(
ValueError: Expected n_neighbors <= n_samples,  but n_samples = 5, n_neighbors = 6

--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/model_selection/_validation.py", line 729, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 255, in fit
    X, y, _ = self._fit(X, y, **fit_params_steps)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 238, in _fit
    X, y = self._memory_transform(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/joblib/memory.py", line 594, in __call__
    return self._cached_call(args, kwargs)[0]
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/memory.py", line 398, in _cached_call
    out, metadata = self.call(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/memory.py", line 309, in call
    output = self.func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 77, in _transform_one
    output = transformer.transform(*args)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 157, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 259, in transform
    output = self.transformer.transform(*args)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 157, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 546, in transform
    X, y = self.estimator.fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/base.py", line 208, in fit_resample
    return super().fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/base.py", line 112, in fit_resample
    output = self._fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/over_sampling/_smote/base.py", line 389, in _fit_resample
    nns = self.nn_k_.kneighbors(X_class, return_distance=False)[:, 1:]
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/neighbors/_base.py", line 808, in kneighbors
    raise ValueError(
ValueError: Expected n_neighbors <= n_samples,  but n_samples = 4, n_neighbors = 6

  warnings.warn(some_fits_failed_message, FitFailedWarning)

2025-12-01 15:04:35,501:INFO:Calculating mean and std
2025-12-01 15:04:35,502:INFO:Creating metrics dataframe
2025-12-01 15:04:35,513:INFO:Uploading results into container
2025-12-01 15:04:35,514:INFO:Uploading model into container now
2025-12-01 15:04:35,514:INFO:_master_model_container: 21
2025-12-01 15:04:35,514:INFO:_display_container: 2
2025-12-01 15:04:35,515:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-12-01 15:04:35,515:INFO:create_model() successfully completed......................................
2025-12-01 15:04:35,627:WARNING:create_model() for LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001) raised an exception or returned all 0.0, trying without fit_kwargs:
2025-12-01 15:04:35,627:WARNING:Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 795, in compare_models
    np.sum(
AssertionError

2025-12-01 15:04:35,628:INFO:Initializing create_model()
2025-12-01 15:04:35,628:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f56dc1329b0>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f56dc132ec0>, model_only=True, return_train_score=False, kwargs={})
2025-12-01 15:04:35,628:INFO:Checking exceptions
2025-12-01 15:04:35,628:INFO:Importing libraries
2025-12-01 15:04:35,628:INFO:Copying training dataset
2025-12-01 15:04:35,632:INFO:Defining folds
2025-12-01 15:04:35,632:INFO:Declaring metric variables
2025-12-01 15:04:35,637:INFO:Importing untrained model
2025-12-01 15:04:35,642:INFO:Linear Discriminant Analysis Imported successfully
2025-12-01 15:04:35,652:INFO:Starting cross validation
2025-12-01 15:04:35,655:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-12-01 15:04:35,659:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 7 members, which is less than n_splits=10.
  warnings.warn(

2025-12-01 15:04:36,890:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 795, in compare_models
    np.sum(
AssertionError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 401, in _score
    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 214, in wrapper
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 627, in roc_auc_score
    return _average_binary_score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-12-01 15:04:36,893:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 15:04:37,238:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 795, in compare_models
    np.sum(
AssertionError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 401, in _score
    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 214, in wrapper
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 627, in roc_auc_score
    return _average_binary_score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-12-01 15:04:37,241:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 15:04:37,585:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 795, in compare_models
    np.sum(
AssertionError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 401, in _score
    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 214, in wrapper
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 627, in roc_auc_score
    return _average_binary_score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-12-01 15:04:37,588:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 15:04:38,095:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:425: FitFailedWarning:
5 fits failed out of a total of 10.
The score on these train-test partitions for these parameters will be set to 0.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
4 fits failed with the following error:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 795, in compare_models
    np.sum(
AssertionError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/model_selection/_validation.py", line 729, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 255, in fit
    X, y, _ = self._fit(X, y, **fit_params_steps)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 238, in _fit
    X, y = self._memory_transform(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/joblib/memory.py", line 594, in __call__
    return self._cached_call(args, kwargs)[0]
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/memory.py", line 398, in _cached_call
    out, metadata = self.call(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/memory.py", line 309, in call
    output = self.func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 77, in _transform_one
    output = transformer.transform(*args)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 157, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 259, in transform
    output = self.transformer.transform(*args)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 157, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 546, in transform
    X, y = self.estimator.fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/base.py", line 208, in fit_resample
    return super().fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/base.py", line 112, in fit_resample
    output = self._fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/over_sampling/_smote/base.py", line 389, in _fit_resample
    nns = self.nn_k_.kneighbors(X_class, return_distance=False)[:, 1:]
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/neighbors/_base.py", line 808, in kneighbors
    raise ValueError(
ValueError: Expected n_neighbors <= n_samples,  but n_samples = 5, n_neighbors = 6

--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 795, in compare_models
    np.sum(
AssertionError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/model_selection/_validation.py", line 729, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 255, in fit
    X, y, _ = self._fit(X, y, **fit_params_steps)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 238, in _fit
    X, y = self._memory_transform(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/joblib/memory.py", line 594, in __call__
    return self._cached_call(args, kwargs)[0]
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/memory.py", line 398, in _cached_call
    out, metadata = self.call(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/memory.py", line 309, in call
    output = self.func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 77, in _transform_one
    output = transformer.transform(*args)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 157, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 259, in transform
    output = self.transformer.transform(*args)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 157, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 546, in transform
    X, y = self.estimator.fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/base.py", line 208, in fit_resample
    return super().fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/base.py", line 112, in fit_resample
    output = self._fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/over_sampling/_smote/base.py", line 389, in _fit_resample
    nns = self.nn_k_.kneighbors(X_class, return_distance=False)[:, 1:]
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/neighbors/_base.py", line 808, in kneighbors
    raise ValueError(
ValueError: Expected n_neighbors <= n_samples,  but n_samples = 4, n_neighbors = 6

  warnings.warn(some_fits_failed_message, FitFailedWarning)

2025-12-01 15:04:38,096:INFO:Calculating mean and std
2025-12-01 15:04:38,096:INFO:Creating metrics dataframe
2025-12-01 15:04:38,107:INFO:Uploading results into container
2025-12-01 15:04:38,108:INFO:Uploading model into container now
2025-12-01 15:04:38,109:INFO:_master_model_container: 22
2025-12-01 15:04:38,109:INFO:_display_container: 2
2025-12-01 15:04:38,109:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-12-01 15:04:38,109:INFO:create_model() successfully completed......................................
2025-12-01 15:04:38,222:ERROR:create_model() for LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001) raised an exception or returned all 0.0:
2025-12-01 15:04:38,223:ERROR:Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 795, in compare_models
    np.sum(
AssertionError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 811, in compare_models
    np.sum(
AssertionError

2025-12-01 15:04:38,223:INFO:Initializing Extra Trees Classifier
2025-12-01 15:04:38,223:INFO:Total runtime is 1.1214452226956684 minutes
2025-12-01 15:04:38,228:INFO:SubProcess create_model() called ==================================
2025-12-01 15:04:38,229:INFO:Initializing create_model()
2025-12-01 15:04:38,229:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f56dc1329b0>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f56dc132ec0>, model_only=True, return_train_score=False, kwargs={})
2025-12-01 15:04:38,229:INFO:Checking exceptions
2025-12-01 15:04:38,229:INFO:Importing libraries
2025-12-01 15:04:38,229:INFO:Copying training dataset
2025-12-01 15:04:38,234:INFO:Defining folds
2025-12-01 15:04:38,234:INFO:Declaring metric variables
2025-12-01 15:04:38,239:INFO:Importing untrained model
2025-12-01 15:04:38,244:INFO:Extra Trees Classifier Imported successfully
2025-12-01 15:04:38,254:INFO:Starting cross validation
2025-12-01 15:04:38,256:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-12-01 15:04:38,260:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 7 members, which is less than n_splits=10.
  warnings.warn(

2025-12-01 15:04:39,314:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 15:04:40,440:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 401, in _score
    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 214, in wrapper
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 627, in roc_auc_score
    return _average_binary_score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-12-01 15:04:40,443:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 15:04:40,446:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 15:04:40,450:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1760: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2025-12-01 15:04:40,451:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:697: RuntimeWarning: invalid value encountered in double_scalars
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-12-01 15:04:41,257:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 401, in _score
    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 214, in wrapper
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 627, in roc_auc_score
    return _average_binary_score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-12-01 15:04:41,260:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 15:04:41,263:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 15:04:41,266:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1760: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2025-12-01 15:04:41,268:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:697: RuntimeWarning: invalid value encountered in double_scalars
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-12-01 15:04:42,070:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 401, in _score
    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 214, in wrapper
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 627, in roc_auc_score
    return _average_binary_score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-12-01 15:04:42,073:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 15:04:42,077:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 15:04:42,080:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1760: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2025-12-01 15:04:42,081:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:697: RuntimeWarning: invalid value encountered in double_scalars
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-12-01 15:04:42,895:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 15:04:43,051:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:425: FitFailedWarning:
5 fits failed out of a total of 10.
The score on these train-test partitions for these parameters will be set to 0.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
4 fits failed with the following error:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/model_selection/_validation.py", line 729, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 255, in fit
    X, y, _ = self._fit(X, y, **fit_params_steps)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 238, in _fit
    X, y = self._memory_transform(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/joblib/memory.py", line 594, in __call__
    return self._cached_call(args, kwargs)[0]
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/memory.py", line 398, in _cached_call
    out, metadata = self.call(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/memory.py", line 309, in call
    output = self.func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 77, in _transform_one
    output = transformer.transform(*args)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 157, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 259, in transform
    output = self.transformer.transform(*args)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 157, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 546, in transform
    X, y = self.estimator.fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/base.py", line 208, in fit_resample
    return super().fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/base.py", line 112, in fit_resample
    output = self._fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/over_sampling/_smote/base.py", line 389, in _fit_resample
    nns = self.nn_k_.kneighbors(X_class, return_distance=False)[:, 1:]
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/neighbors/_base.py", line 808, in kneighbors
    raise ValueError(
ValueError: Expected n_neighbors <= n_samples,  but n_samples = 5, n_neighbors = 6

--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/model_selection/_validation.py", line 729, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 255, in fit
    X, y, _ = self._fit(X, y, **fit_params_steps)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 238, in _fit
    X, y = self._memory_transform(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/joblib/memory.py", line 594, in __call__
    return self._cached_call(args, kwargs)[0]
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/memory.py", line 398, in _cached_call
    out, metadata = self.call(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/memory.py", line 309, in call
    output = self.func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 77, in _transform_one
    output = transformer.transform(*args)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 157, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 259, in transform
    output = self.transformer.transform(*args)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 157, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 546, in transform
    X, y = self.estimator.fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/base.py", line 208, in fit_resample
    return super().fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/base.py", line 112, in fit_resample
    output = self._fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/over_sampling/_smote/base.py", line 389, in _fit_resample
    nns = self.nn_k_.kneighbors(X_class, return_distance=False)[:, 1:]
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/neighbors/_base.py", line 808, in kneighbors
    raise ValueError(
ValueError: Expected n_neighbors <= n_samples,  but n_samples = 4, n_neighbors = 6

  warnings.warn(some_fits_failed_message, FitFailedWarning)

2025-12-01 15:04:43,052:INFO:Calculating mean and std
2025-12-01 15:04:43,052:INFO:Creating metrics dataframe
2025-12-01 15:04:43,065:INFO:Uploading results into container
2025-12-01 15:04:43,066:INFO:Uploading model into container now
2025-12-01 15:04:43,066:INFO:_master_model_container: 23
2025-12-01 15:04:43,066:INFO:_display_container: 2
2025-12-01 15:04:43,067:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=1, oob_score=False,
                     random_state=42, verbose=0, warm_start=False)
2025-12-01 15:04:43,067:INFO:create_model() successfully completed......................................
2025-12-01 15:04:43,186:WARNING:create_model() for ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=1, oob_score=False,
                     random_state=42, verbose=0, warm_start=False) raised an exception or returned all 0.0, trying without fit_kwargs:
2025-12-01 15:04:43,186:WARNING:Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 795, in compare_models
    np.sum(
AssertionError

2025-12-01 15:04:43,186:INFO:Initializing create_model()
2025-12-01 15:04:43,186:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f56dc1329b0>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f56dc132ec0>, model_only=True, return_train_score=False, kwargs={})
2025-12-01 15:04:43,186:INFO:Checking exceptions
2025-12-01 15:04:43,186:INFO:Importing libraries
2025-12-01 15:04:43,186:INFO:Copying training dataset
2025-12-01 15:04:43,191:INFO:Defining folds
2025-12-01 15:04:43,191:INFO:Declaring metric variables
2025-12-01 15:04:43,196:INFO:Importing untrained model
2025-12-01 15:04:43,201:INFO:Extra Trees Classifier Imported successfully
2025-12-01 15:04:43,211:INFO:Starting cross validation
2025-12-01 15:04:43,214:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-12-01 15:04:43,217:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 7 members, which is less than n_splits=10.
  warnings.warn(

2025-12-01 15:04:44,028:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 15:04:44,847:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 795, in compare_models
    np.sum(
AssertionError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 401, in _score
    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 214, in wrapper
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 627, in roc_auc_score
    return _average_binary_score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-12-01 15:04:44,850:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 15:04:44,853:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 15:04:44,856:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1760: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2025-12-01 15:04:44,858:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:697: RuntimeWarning: invalid value encountered in double_scalars
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-12-01 15:04:45,397:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 795, in compare_models
    np.sum(
AssertionError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 401, in _score
    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 214, in wrapper
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 627, in roc_auc_score
    return _average_binary_score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-12-01 15:04:45,400:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 15:04:45,403:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 15:04:45,406:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1760: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2025-12-01 15:04:45,408:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:697: RuntimeWarning: invalid value encountered in double_scalars
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-12-01 15:04:45,944:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 795, in compare_models
    np.sum(
AssertionError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 401, in _score
    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 214, in wrapper
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 627, in roc_auc_score
    return _average_binary_score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-12-01 15:04:45,947:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 15:04:45,950:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 15:04:45,953:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1760: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2025-12-01 15:04:45,955:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:697: RuntimeWarning: invalid value encountered in double_scalars
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-12-01 15:04:46,502:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 15:04:46,652:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:425: FitFailedWarning:
5 fits failed out of a total of 10.
The score on these train-test partitions for these parameters will be set to 0.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
4 fits failed with the following error:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 795, in compare_models
    np.sum(
AssertionError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/model_selection/_validation.py", line 729, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 255, in fit
    X, y, _ = self._fit(X, y, **fit_params_steps)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 238, in _fit
    X, y = self._memory_transform(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/joblib/memory.py", line 594, in __call__
    return self._cached_call(args, kwargs)[0]
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/memory.py", line 398, in _cached_call
    out, metadata = self.call(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/memory.py", line 309, in call
    output = self.func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 77, in _transform_one
    output = transformer.transform(*args)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 157, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 259, in transform
    output = self.transformer.transform(*args)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 157, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 546, in transform
    X, y = self.estimator.fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/base.py", line 208, in fit_resample
    return super().fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/base.py", line 112, in fit_resample
    output = self._fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/over_sampling/_smote/base.py", line 389, in _fit_resample
    nns = self.nn_k_.kneighbors(X_class, return_distance=False)[:, 1:]
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/neighbors/_base.py", line 808, in kneighbors
    raise ValueError(
ValueError: Expected n_neighbors <= n_samples,  but n_samples = 5, n_neighbors = 6

--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 795, in compare_models
    np.sum(
AssertionError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/model_selection/_validation.py", line 729, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 255, in fit
    X, y, _ = self._fit(X, y, **fit_params_steps)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 238, in _fit
    X, y = self._memory_transform(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/joblib/memory.py", line 594, in __call__
    return self._cached_call(args, kwargs)[0]
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/memory.py", line 398, in _cached_call
    out, metadata = self.call(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/memory.py", line 309, in call
    output = self.func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 77, in _transform_one
    output = transformer.transform(*args)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 157, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 259, in transform
    output = self.transformer.transform(*args)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 157, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 546, in transform
    X, y = self.estimator.fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/base.py", line 208, in fit_resample
    return super().fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/base.py", line 112, in fit_resample
    output = self._fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/over_sampling/_smote/base.py", line 389, in _fit_resample
    nns = self.nn_k_.kneighbors(X_class, return_distance=False)[:, 1:]
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/neighbors/_base.py", line 808, in kneighbors
    raise ValueError(
ValueError: Expected n_neighbors <= n_samples,  but n_samples = 4, n_neighbors = 6

  warnings.warn(some_fits_failed_message, FitFailedWarning)

2025-12-01 15:04:46,653:INFO:Calculating mean and std
2025-12-01 15:04:46,654:INFO:Creating metrics dataframe
2025-12-01 15:04:46,665:INFO:Uploading results into container
2025-12-01 15:04:46,666:INFO:Uploading model into container now
2025-12-01 15:04:46,666:INFO:_master_model_container: 24
2025-12-01 15:04:46,666:INFO:_display_container: 2
2025-12-01 15:04:46,667:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=1, oob_score=False,
                     random_state=42, verbose=0, warm_start=False)
2025-12-01 15:04:46,667:INFO:create_model() successfully completed......................................
2025-12-01 15:04:46,778:ERROR:create_model() for ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=1, oob_score=False,
                     random_state=42, verbose=0, warm_start=False) raised an exception or returned all 0.0:
2025-12-01 15:04:46,778:ERROR:Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 795, in compare_models
    np.sum(
AssertionError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 811, in compare_models
    np.sum(
AssertionError

2025-12-01 15:04:46,778:INFO:Initializing Extreme Gradient Boosting
2025-12-01 15:04:46,778:INFO:Total runtime is 1.2640346606572468 minutes
2025-12-01 15:04:46,784:INFO:SubProcess create_model() called ==================================
2025-12-01 15:04:46,784:INFO:Initializing create_model()
2025-12-01 15:04:46,784:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f56dc1329b0>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f56dc132ec0>, model_only=True, return_train_score=False, kwargs={})
2025-12-01 15:04:46,784:INFO:Checking exceptions
2025-12-01 15:04:46,784:INFO:Importing libraries
2025-12-01 15:04:46,784:INFO:Copying training dataset
2025-12-01 15:04:46,789:INFO:Defining folds
2025-12-01 15:04:46,789:INFO:Declaring metric variables
2025-12-01 15:04:46,794:INFO:Importing untrained model
2025-12-01 15:04:46,799:INFO:Extreme Gradient Boosting Imported successfully
2025-12-01 15:04:46,809:INFO:Starting cross validation
2025-12-01 15:04:46,812:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-12-01 15:04:46,816:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 7 members, which is less than n_splits=10.
  warnings.warn(

2025-12-01 15:04:48,220:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 401, in _score
    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 214, in wrapper
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 627, in roc_auc_score
    return _average_binary_score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-12-01 15:04:48,223:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 15:04:48,659:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 401, in _score
    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 214, in wrapper
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 627, in roc_auc_score
    return _average_binary_score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-12-01 15:04:48,662:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 15:04:49,101:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 401, in _score
    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 214, in wrapper
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 627, in roc_auc_score
    return _average_binary_score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-12-01 15:04:49,104:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 15:04:49,107:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 15:04:49,110:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1760: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2025-12-01 15:04:49,112:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:697: RuntimeWarning: invalid value encountered in double_scalars
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-12-01 15:04:49,703:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:425: FitFailedWarning:
5 fits failed out of a total of 10.
The score on these train-test partitions for these parameters will be set to 0.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
4 fits failed with the following error:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/model_selection/_validation.py", line 729, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 255, in fit
    X, y, _ = self._fit(X, y, **fit_params_steps)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 238, in _fit
    X, y = self._memory_transform(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/joblib/memory.py", line 594, in __call__
    return self._cached_call(args, kwargs)[0]
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/memory.py", line 398, in _cached_call
    out, metadata = self.call(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/memory.py", line 309, in call
    output = self.func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 77, in _transform_one
    output = transformer.transform(*args)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 157, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 259, in transform
    output = self.transformer.transform(*args)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 157, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 546, in transform
    X, y = self.estimator.fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/base.py", line 208, in fit_resample
    return super().fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/base.py", line 112, in fit_resample
    output = self._fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/over_sampling/_smote/base.py", line 389, in _fit_resample
    nns = self.nn_k_.kneighbors(X_class, return_distance=False)[:, 1:]
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/neighbors/_base.py", line 808, in kneighbors
    raise ValueError(
ValueError: Expected n_neighbors <= n_samples,  but n_samples = 5, n_neighbors = 6

--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/model_selection/_validation.py", line 729, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 255, in fit
    X, y, _ = self._fit(X, y, **fit_params_steps)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 238, in _fit
    X, y = self._memory_transform(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/joblib/memory.py", line 594, in __call__
    return self._cached_call(args, kwargs)[0]
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/memory.py", line 398, in _cached_call
    out, metadata = self.call(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/memory.py", line 309, in call
    output = self.func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 77, in _transform_one
    output = transformer.transform(*args)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 157, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 259, in transform
    output = self.transformer.transform(*args)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 157, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 546, in transform
    X, y = self.estimator.fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/base.py", line 208, in fit_resample
    return super().fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/base.py", line 112, in fit_resample
    output = self._fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/over_sampling/_smote/base.py", line 389, in _fit_resample
    nns = self.nn_k_.kneighbors(X_class, return_distance=False)[:, 1:]
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/neighbors/_base.py", line 808, in kneighbors
    raise ValueError(
ValueError: Expected n_neighbors <= n_samples,  but n_samples = 4, n_neighbors = 6

  warnings.warn(some_fits_failed_message, FitFailedWarning)

2025-12-01 15:04:49,704:INFO:Calculating mean and std
2025-12-01 15:04:49,705:INFO:Creating metrics dataframe
2025-12-01 15:04:49,717:INFO:Uploading results into container
2025-12-01 15:04:49,717:INFO:Uploading model into container now
2025-12-01 15:04:49,718:INFO:_master_model_container: 25
2025-12-01 15:04:49,718:INFO:_display_container: 2
2025-12-01 15:04:49,719:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2025-12-01 15:04:49,719:INFO:create_model() successfully completed......................................
2025-12-01 15:04:49,835:WARNING:create_model() for XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...) raised an exception or returned all 0.0, trying without fit_kwargs:
2025-12-01 15:04:49,835:WARNING:Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 795, in compare_models
    np.sum(
AssertionError

2025-12-01 15:04:49,835:INFO:Initializing create_model()
2025-12-01 15:04:49,835:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f56dc1329b0>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f56dc132ec0>, model_only=True, return_train_score=False, kwargs={})
2025-12-01 15:04:49,835:INFO:Checking exceptions
2025-12-01 15:04:49,835:INFO:Importing libraries
2025-12-01 15:04:49,835:INFO:Copying training dataset
2025-12-01 15:04:49,840:INFO:Defining folds
2025-12-01 15:04:49,840:INFO:Declaring metric variables
2025-12-01 15:04:49,845:INFO:Importing untrained model
2025-12-01 15:04:49,850:INFO:Extreme Gradient Boosting Imported successfully
2025-12-01 15:04:49,860:INFO:Starting cross validation
2025-12-01 15:04:49,863:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-12-01 15:04:49,866:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 7 members, which is less than n_splits=10.
  warnings.warn(

2025-12-01 15:04:51,279:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 795, in compare_models
    np.sum(
AssertionError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 401, in _score
    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 214, in wrapper
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 627, in roc_auc_score
    return _average_binary_score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-12-01 15:04:51,282:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 15:04:51,727:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 795, in compare_models
    np.sum(
AssertionError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 401, in _score
    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 214, in wrapper
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 627, in roc_auc_score
    return _average_binary_score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-12-01 15:04:51,730:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 15:04:52,190:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 795, in compare_models
    np.sum(
AssertionError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 401, in _score
    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 214, in wrapper
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 627, in roc_auc_score
    return _average_binary_score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-12-01 15:04:52,193:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 15:04:52,196:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 15:04:52,199:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1760: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2025-12-01 15:04:52,201:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:697: RuntimeWarning: invalid value encountered in double_scalars
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-12-01 15:04:52,794:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:425: FitFailedWarning:
5 fits failed out of a total of 10.
The score on these train-test partitions for these parameters will be set to 0.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
4 fits failed with the following error:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 795, in compare_models
    np.sum(
AssertionError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/model_selection/_validation.py", line 729, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 255, in fit
    X, y, _ = self._fit(X, y, **fit_params_steps)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 238, in _fit
    X, y = self._memory_transform(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/joblib/memory.py", line 594, in __call__
    return self._cached_call(args, kwargs)[0]
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/memory.py", line 398, in _cached_call
    out, metadata = self.call(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/memory.py", line 309, in call
    output = self.func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 77, in _transform_one
    output = transformer.transform(*args)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 157, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 259, in transform
    output = self.transformer.transform(*args)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 157, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 546, in transform
    X, y = self.estimator.fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/base.py", line 208, in fit_resample
    return super().fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/base.py", line 112, in fit_resample
    output = self._fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/over_sampling/_smote/base.py", line 389, in _fit_resample
    nns = self.nn_k_.kneighbors(X_class, return_distance=False)[:, 1:]
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/neighbors/_base.py", line 808, in kneighbors
    raise ValueError(
ValueError: Expected n_neighbors <= n_samples,  but n_samples = 5, n_neighbors = 6

--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 795, in compare_models
    np.sum(
AssertionError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/model_selection/_validation.py", line 729, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 255, in fit
    X, y, _ = self._fit(X, y, **fit_params_steps)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 238, in _fit
    X, y = self._memory_transform(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/joblib/memory.py", line 594, in __call__
    return self._cached_call(args, kwargs)[0]
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/memory.py", line 398, in _cached_call
    out, metadata = self.call(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/memory.py", line 309, in call
    output = self.func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 77, in _transform_one
    output = transformer.transform(*args)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 157, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 259, in transform
    output = self.transformer.transform(*args)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 157, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 546, in transform
    X, y = self.estimator.fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/base.py", line 208, in fit_resample
    return super().fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/base.py", line 112, in fit_resample
    output = self._fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/over_sampling/_smote/base.py", line 389, in _fit_resample
    nns = self.nn_k_.kneighbors(X_class, return_distance=False)[:, 1:]
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/neighbors/_base.py", line 808, in kneighbors
    raise ValueError(
ValueError: Expected n_neighbors <= n_samples,  but n_samples = 4, n_neighbors = 6

  warnings.warn(some_fits_failed_message, FitFailedWarning)

2025-12-01 15:04:52,795:INFO:Calculating mean and std
2025-12-01 15:04:52,796:INFO:Creating metrics dataframe
2025-12-01 15:04:52,808:INFO:Uploading results into container
2025-12-01 15:04:52,809:INFO:Uploading model into container now
2025-12-01 15:04:52,810:INFO:_master_model_container: 26
2025-12-01 15:04:52,810:INFO:_display_container: 2
2025-12-01 15:04:52,811:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2025-12-01 15:04:52,811:INFO:create_model() successfully completed......................................
2025-12-01 15:04:52,929:ERROR:create_model() for XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...) raised an exception or returned all 0.0:
2025-12-01 15:04:52,930:ERROR:Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 795, in compare_models
    np.sum(
AssertionError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 811, in compare_models
    np.sum(
AssertionError

2025-12-01 15:04:52,930:INFO:Initializing Light Gradient Boosting Machine
2025-12-01 15:04:52,930:INFO:Total runtime is 1.3665570219357808 minutes
2025-12-01 15:04:52,935:INFO:SubProcess create_model() called ==================================
2025-12-01 15:04:52,936:INFO:Initializing create_model()
2025-12-01 15:04:52,936:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f56dc1329b0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f56dc132ec0>, model_only=True, return_train_score=False, kwargs={})
2025-12-01 15:04:52,936:INFO:Checking exceptions
2025-12-01 15:04:52,936:INFO:Importing libraries
2025-12-01 15:04:52,936:INFO:Copying training dataset
2025-12-01 15:04:52,941:INFO:Defining folds
2025-12-01 15:04:52,941:INFO:Declaring metric variables
2025-12-01 15:04:52,946:INFO:Importing untrained model
2025-12-01 15:04:52,952:INFO:Light Gradient Boosting Machine Imported successfully
2025-12-01 15:04:52,961:INFO:Starting cross validation
2025-12-01 15:04:52,964:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-12-01 15:04:52,968:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 7 members, which is less than n_splits=10.
  warnings.warn(

2025-12-01 15:04:54,233:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 401, in _score
    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 214, in wrapper
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 627, in roc_auc_score
    return _average_binary_score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-12-01 15:04:54,236:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 15:04:54,240:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 15:04:54,243:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1760: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2025-12-01 15:04:54,245:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:697: RuntimeWarning: invalid value encountered in double_scalars
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-12-01 15:04:54,610:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 401, in _score
    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 214, in wrapper
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 627, in roc_auc_score
    return _average_binary_score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-12-01 15:04:54,613:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 15:04:54,616:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 15:04:54,619:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1760: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2025-12-01 15:04:54,621:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:697: RuntimeWarning: invalid value encountered in double_scalars
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-12-01 15:04:54,979:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 401, in _score
    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 214, in wrapper
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 627, in roc_auc_score
    return _average_binary_score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-12-01 15:04:54,982:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 15:04:55,511:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:425: FitFailedWarning:
5 fits failed out of a total of 10.
The score on these train-test partitions for these parameters will be set to 0.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
4 fits failed with the following error:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/model_selection/_validation.py", line 729, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 255, in fit
    X, y, _ = self._fit(X, y, **fit_params_steps)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 238, in _fit
    X, y = self._memory_transform(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/joblib/memory.py", line 594, in __call__
    return self._cached_call(args, kwargs)[0]
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/memory.py", line 398, in _cached_call
    out, metadata = self.call(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/memory.py", line 309, in call
    output = self.func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 77, in _transform_one
    output = transformer.transform(*args)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 157, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 259, in transform
    output = self.transformer.transform(*args)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 157, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 546, in transform
    X, y = self.estimator.fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/base.py", line 208, in fit_resample
    return super().fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/base.py", line 112, in fit_resample
    output = self._fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/over_sampling/_smote/base.py", line 389, in _fit_resample
    nns = self.nn_k_.kneighbors(X_class, return_distance=False)[:, 1:]
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/neighbors/_base.py", line 808, in kneighbors
    raise ValueError(
ValueError: Expected n_neighbors <= n_samples,  but n_samples = 5, n_neighbors = 6

--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/model_selection/_validation.py", line 729, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 255, in fit
    X, y, _ = self._fit(X, y, **fit_params_steps)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 238, in _fit
    X, y = self._memory_transform(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/joblib/memory.py", line 594, in __call__
    return self._cached_call(args, kwargs)[0]
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/memory.py", line 398, in _cached_call
    out, metadata = self.call(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/memory.py", line 309, in call
    output = self.func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 77, in _transform_one
    output = transformer.transform(*args)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 157, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 259, in transform
    output = self.transformer.transform(*args)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 157, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 546, in transform
    X, y = self.estimator.fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/base.py", line 208, in fit_resample
    return super().fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/base.py", line 112, in fit_resample
    output = self._fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/over_sampling/_smote/base.py", line 389, in _fit_resample
    nns = self.nn_k_.kneighbors(X_class, return_distance=False)[:, 1:]
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/neighbors/_base.py", line 808, in kneighbors
    raise ValueError(
ValueError: Expected n_neighbors <= n_samples,  but n_samples = 4, n_neighbors = 6

  warnings.warn(some_fits_failed_message, FitFailedWarning)

2025-12-01 15:04:55,512:INFO:Calculating mean and std
2025-12-01 15:04:55,513:INFO:Creating metrics dataframe
2025-12-01 15:04:55,525:INFO:Uploading results into container
2025-12-01 15:04:55,526:INFO:Uploading model into container now
2025-12-01 15:04:55,526:INFO:_master_model_container: 27
2025-12-01 15:04:55,526:INFO:_display_container: 2
2025-12-01 15:04:55,527:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-12-01 15:04:55,527:INFO:create_model() successfully completed......................................
2025-12-01 15:04:55,645:WARNING:create_model() for LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) raised an exception or returned all 0.0, trying without fit_kwargs:
2025-12-01 15:04:55,645:WARNING:Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 795, in compare_models
    np.sum(
AssertionError

2025-12-01 15:04:55,646:INFO:Initializing create_model()
2025-12-01 15:04:55,646:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f56dc1329b0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f56dc132ec0>, model_only=True, return_train_score=False, kwargs={})
2025-12-01 15:04:55,646:INFO:Checking exceptions
2025-12-01 15:04:55,646:INFO:Importing libraries
2025-12-01 15:04:55,646:INFO:Copying training dataset
2025-12-01 15:04:55,650:INFO:Defining folds
2025-12-01 15:04:55,650:INFO:Declaring metric variables
2025-12-01 15:04:55,655:INFO:Importing untrained model
2025-12-01 15:04:55,661:INFO:Light Gradient Boosting Machine Imported successfully
2025-12-01 15:04:55,671:INFO:Starting cross validation
2025-12-01 15:04:55,673:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-12-01 15:04:55,677:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 7 members, which is less than n_splits=10.
  warnings.warn(

2025-12-01 15:04:56,961:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 795, in compare_models
    np.sum(
AssertionError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 401, in _score
    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 214, in wrapper
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 627, in roc_auc_score
    return _average_binary_score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-12-01 15:04:56,964:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 15:04:56,968:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 15:04:56,971:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1760: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2025-12-01 15:04:56,973:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:697: RuntimeWarning: invalid value encountered in double_scalars
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-12-01 15:04:57,325:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 795, in compare_models
    np.sum(
AssertionError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 401, in _score
    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 214, in wrapper
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 627, in roc_auc_score
    return _average_binary_score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-12-01 15:04:57,328:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 15:04:57,331:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 15:04:57,334:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1760: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2025-12-01 15:04:57,336:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:697: RuntimeWarning: invalid value encountered in double_scalars
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-12-01 15:04:57,702:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 795, in compare_models
    np.sum(
AssertionError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 401, in _score
    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 214, in wrapper
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 627, in roc_auc_score
    return _average_binary_score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-12-01 15:04:57,705:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 15:04:58,229:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:425: FitFailedWarning:
5 fits failed out of a total of 10.
The score on these train-test partitions for these parameters will be set to 0.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
4 fits failed with the following error:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 795, in compare_models
    np.sum(
AssertionError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/model_selection/_validation.py", line 729, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 255, in fit
    X, y, _ = self._fit(X, y, **fit_params_steps)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 238, in _fit
    X, y = self._memory_transform(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/joblib/memory.py", line 594, in __call__
    return self._cached_call(args, kwargs)[0]
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/memory.py", line 398, in _cached_call
    out, metadata = self.call(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/memory.py", line 309, in call
    output = self.func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 77, in _transform_one
    output = transformer.transform(*args)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 157, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 259, in transform
    output = self.transformer.transform(*args)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 157, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 546, in transform
    X, y = self.estimator.fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/base.py", line 208, in fit_resample
    return super().fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/base.py", line 112, in fit_resample
    output = self._fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/over_sampling/_smote/base.py", line 389, in _fit_resample
    nns = self.nn_k_.kneighbors(X_class, return_distance=False)[:, 1:]
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/neighbors/_base.py", line 808, in kneighbors
    raise ValueError(
ValueError: Expected n_neighbors <= n_samples,  but n_samples = 5, n_neighbors = 6

--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 795, in compare_models
    np.sum(
AssertionError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/model_selection/_validation.py", line 729, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 255, in fit
    X, y, _ = self._fit(X, y, **fit_params_steps)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 238, in _fit
    X, y = self._memory_transform(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/joblib/memory.py", line 594, in __call__
    return self._cached_call(args, kwargs)[0]
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/memory.py", line 398, in _cached_call
    out, metadata = self.call(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/memory.py", line 309, in call
    output = self.func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 77, in _transform_one
    output = transformer.transform(*args)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 157, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 259, in transform
    output = self.transformer.transform(*args)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 157, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 546, in transform
    X, y = self.estimator.fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/base.py", line 208, in fit_resample
    return super().fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/base.py", line 112, in fit_resample
    output = self._fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/over_sampling/_smote/base.py", line 389, in _fit_resample
    nns = self.nn_k_.kneighbors(X_class, return_distance=False)[:, 1:]
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/neighbors/_base.py", line 808, in kneighbors
    raise ValueError(
ValueError: Expected n_neighbors <= n_samples,  but n_samples = 4, n_neighbors = 6

  warnings.warn(some_fits_failed_message, FitFailedWarning)

2025-12-01 15:04:58,229:INFO:Calculating mean and std
2025-12-01 15:04:58,230:INFO:Creating metrics dataframe
2025-12-01 15:04:58,242:INFO:Uploading results into container
2025-12-01 15:04:58,243:INFO:Uploading model into container now
2025-12-01 15:04:58,243:INFO:_master_model_container: 28
2025-12-01 15:04:58,243:INFO:_display_container: 2
2025-12-01 15:04:58,244:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-12-01 15:04:58,244:INFO:create_model() successfully completed......................................
2025-12-01 15:04:58,360:ERROR:create_model() for LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) raised an exception or returned all 0.0:
2025-12-01 15:04:58,361:ERROR:Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 795, in compare_models
    np.sum(
AssertionError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 811, in compare_models
    np.sum(
AssertionError

2025-12-01 15:04:58,361:INFO:Initializing Dummy Classifier
2025-12-01 15:04:58,361:INFO:Total runtime is 1.457078715165456 minutes
2025-12-01 15:04:58,366:INFO:SubProcess create_model() called ==================================
2025-12-01 15:04:58,367:INFO:Initializing create_model()
2025-12-01 15:04:58,367:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f56dc1329b0>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f56dc132ec0>, model_only=True, return_train_score=False, kwargs={})
2025-12-01 15:04:58,367:INFO:Checking exceptions
2025-12-01 15:04:58,367:INFO:Importing libraries
2025-12-01 15:04:58,367:INFO:Copying training dataset
2025-12-01 15:04:58,372:INFO:Defining folds
2025-12-01 15:04:58,372:INFO:Declaring metric variables
2025-12-01 15:04:58,377:INFO:Importing untrained model
2025-12-01 15:04:58,383:INFO:Dummy Classifier Imported successfully
2025-12-01 15:04:58,394:INFO:Starting cross validation
2025-12-01 15:04:58,397:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-12-01 15:04:58,402:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 7 members, which is less than n_splits=10.
  warnings.warn(

2025-12-01 15:04:58,997:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 15:04:59,622:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 401, in _score
    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 214, in wrapper
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 627, in roc_auc_score
    return _average_binary_score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-12-01 15:04:59,625:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 15:04:59,628:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 15:04:59,631:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1760: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2025-12-01 15:04:59,633:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:697: RuntimeWarning: invalid value encountered in double_scalars
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-12-01 15:04:59,972:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 401, in _score
    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 214, in wrapper
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 627, in roc_auc_score
    return _average_binary_score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-12-01 15:04:59,975:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 15:04:59,979:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 15:04:59,982:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1760: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2025-12-01 15:04:59,984:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:697: RuntimeWarning: invalid value encountered in double_scalars
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-12-01 15:05:00,323:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 401, in _score
    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 214, in wrapper
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 627, in roc_auc_score
    return _average_binary_score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-12-01 15:05:00,326:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 15:05:00,329:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 15:05:00,332:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1760: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2025-12-01 15:05:00,334:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:697: RuntimeWarning: invalid value encountered in double_scalars
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-12-01 15:05:00,679:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 15:05:00,835:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:425: FitFailedWarning:
5 fits failed out of a total of 10.
The score on these train-test partitions for these parameters will be set to 0.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
4 fits failed with the following error:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/model_selection/_validation.py", line 729, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 255, in fit
    X, y, _ = self._fit(X, y, **fit_params_steps)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 238, in _fit
    X, y = self._memory_transform(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/joblib/memory.py", line 594, in __call__
    return self._cached_call(args, kwargs)[0]
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/memory.py", line 398, in _cached_call
    out, metadata = self.call(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/memory.py", line 309, in call
    output = self.func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 77, in _transform_one
    output = transformer.transform(*args)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 157, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 259, in transform
    output = self.transformer.transform(*args)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 157, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 546, in transform
    X, y = self.estimator.fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/base.py", line 208, in fit_resample
    return super().fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/base.py", line 112, in fit_resample
    output = self._fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/over_sampling/_smote/base.py", line 389, in _fit_resample
    nns = self.nn_k_.kneighbors(X_class, return_distance=False)[:, 1:]
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/neighbors/_base.py", line 808, in kneighbors
    raise ValueError(
ValueError: Expected n_neighbors <= n_samples,  but n_samples = 5, n_neighbors = 6

--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/model_selection/_validation.py", line 729, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 255, in fit
    X, y, _ = self._fit(X, y, **fit_params_steps)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 238, in _fit
    X, y = self._memory_transform(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/joblib/memory.py", line 594, in __call__
    return self._cached_call(args, kwargs)[0]
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/memory.py", line 398, in _cached_call
    out, metadata = self.call(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/memory.py", line 309, in call
    output = self.func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 77, in _transform_one
    output = transformer.transform(*args)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 157, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 259, in transform
    output = self.transformer.transform(*args)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 157, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 546, in transform
    X, y = self.estimator.fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/base.py", line 208, in fit_resample
    return super().fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/base.py", line 112, in fit_resample
    output = self._fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/over_sampling/_smote/base.py", line 389, in _fit_resample
    nns = self.nn_k_.kneighbors(X_class, return_distance=False)[:, 1:]
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/neighbors/_base.py", line 808, in kneighbors
    raise ValueError(
ValueError: Expected n_neighbors <= n_samples,  but n_samples = 4, n_neighbors = 6

  warnings.warn(some_fits_failed_message, FitFailedWarning)

2025-12-01 15:05:00,836:INFO:Calculating mean and std
2025-12-01 15:05:00,836:INFO:Creating metrics dataframe
2025-12-01 15:05:00,849:INFO:Uploading results into container
2025-12-01 15:05:00,850:INFO:Uploading model into container now
2025-12-01 15:05:00,850:INFO:_master_model_container: 29
2025-12-01 15:05:00,850:INFO:_display_container: 2
2025-12-01 15:05:00,851:INFO:DummyClassifier(constant=None, random_state=42, strategy='prior')
2025-12-01 15:05:00,851:INFO:create_model() successfully completed......................................
2025-12-01 15:05:00,974:WARNING:create_model() for DummyClassifier(constant=None, random_state=42, strategy='prior') raised an exception or returned all 0.0, trying without fit_kwargs:
2025-12-01 15:05:00,974:WARNING:Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 795, in compare_models
    np.sum(
AssertionError

2025-12-01 15:05:00,975:INFO:Initializing create_model()
2025-12-01 15:05:00,975:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f56dc1329b0>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f56dc132ec0>, model_only=True, return_train_score=False, kwargs={})
2025-12-01 15:05:00,975:INFO:Checking exceptions
2025-12-01 15:05:00,975:INFO:Importing libraries
2025-12-01 15:05:00,975:INFO:Copying training dataset
2025-12-01 15:05:00,979:INFO:Defining folds
2025-12-01 15:05:00,979:INFO:Declaring metric variables
2025-12-01 15:05:00,985:INFO:Importing untrained model
2025-12-01 15:05:00,991:INFO:Dummy Classifier Imported successfully
2025-12-01 15:05:01,002:INFO:Starting cross validation
2025-12-01 15:05:01,005:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-12-01 15:05:01,010:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 7 members, which is less than n_splits=10.
  warnings.warn(

2025-12-01 15:05:01,841:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 15:05:02,667:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 795, in compare_models
    np.sum(
AssertionError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 401, in _score
    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 214, in wrapper
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 627, in roc_auc_score
    return _average_binary_score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-12-01 15:05:02,672:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 15:05:02,677:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 15:05:02,683:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1760: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2025-12-01 15:05:02,687:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:697: RuntimeWarning: invalid value encountered in double_scalars
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-12-01 15:05:03,227:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 795, in compare_models
    np.sum(
AssertionError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 401, in _score
    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 214, in wrapper
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 627, in roc_auc_score
    return _average_binary_score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-12-01 15:05:03,232:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 15:05:03,236:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 15:05:03,240:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1760: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2025-12-01 15:05:03,243:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:697: RuntimeWarning: invalid value encountered in double_scalars
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-12-01 15:05:03,591:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 795, in compare_models
    np.sum(
AssertionError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 401, in _score
    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 214, in wrapper
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 627, in roc_auc_score
    return _average_binary_score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-12-01 15:05:03,594:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 15:05:03,597:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 15:05:03,600:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1760: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2025-12-01 15:05:03,602:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:697: RuntimeWarning: invalid value encountered in double_scalars
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-12-01 15:05:03,950:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 15:05:04,108:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:425: FitFailedWarning:
5 fits failed out of a total of 10.
The score on these train-test partitions for these parameters will be set to 0.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
4 fits failed with the following error:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 795, in compare_models
    np.sum(
AssertionError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/model_selection/_validation.py", line 729, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 255, in fit
    X, y, _ = self._fit(X, y, **fit_params_steps)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 238, in _fit
    X, y = self._memory_transform(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/joblib/memory.py", line 594, in __call__
    return self._cached_call(args, kwargs)[0]
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/memory.py", line 398, in _cached_call
    out, metadata = self.call(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/memory.py", line 309, in call
    output = self.func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 77, in _transform_one
    output = transformer.transform(*args)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 157, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 259, in transform
    output = self.transformer.transform(*args)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 157, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 546, in transform
    X, y = self.estimator.fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/base.py", line 208, in fit_resample
    return super().fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/base.py", line 112, in fit_resample
    output = self._fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/over_sampling/_smote/base.py", line 389, in _fit_resample
    nns = self.nn_k_.kneighbors(X_class, return_distance=False)[:, 1:]
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/neighbors/_base.py", line 808, in kneighbors
    raise ValueError(
ValueError: Expected n_neighbors <= n_samples,  but n_samples = 5, n_neighbors = 6

--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 795, in compare_models
    np.sum(
AssertionError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/model_selection/_validation.py", line 729, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 255, in fit
    X, y, _ = self._fit(X, y, **fit_params_steps)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 238, in _fit
    X, y = self._memory_transform(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/joblib/memory.py", line 594, in __call__
    return self._cached_call(args, kwargs)[0]
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/memory.py", line 398, in _cached_call
    out, metadata = self.call(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/memory.py", line 309, in call
    output = self.func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 77, in _transform_one
    output = transformer.transform(*args)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 157, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 259, in transform
    output = self.transformer.transform(*args)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 157, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 546, in transform
    X, y = self.estimator.fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/base.py", line 208, in fit_resample
    return super().fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/base.py", line 112, in fit_resample
    output = self._fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/over_sampling/_smote/base.py", line 389, in _fit_resample
    nns = self.nn_k_.kneighbors(X_class, return_distance=False)[:, 1:]
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/neighbors/_base.py", line 808, in kneighbors
    raise ValueError(
ValueError: Expected n_neighbors <= n_samples,  but n_samples = 4, n_neighbors = 6

  warnings.warn(some_fits_failed_message, FitFailedWarning)

2025-12-01 15:05:04,109:INFO:Calculating mean and std
2025-12-01 15:05:04,110:INFO:Creating metrics dataframe
2025-12-01 15:05:04,122:INFO:Uploading results into container
2025-12-01 15:05:04,123:INFO:Uploading model into container now
2025-12-01 15:05:04,123:INFO:_master_model_container: 30
2025-12-01 15:05:04,123:INFO:_display_container: 2
2025-12-01 15:05:04,124:INFO:DummyClassifier(constant=None, random_state=42, strategy='prior')
2025-12-01 15:05:04,124:INFO:create_model() successfully completed......................................
2025-12-01 15:05:04,241:ERROR:create_model() for DummyClassifier(constant=None, random_state=42, strategy='prior') raised an exception or returned all 0.0:
2025-12-01 15:05:04,241:ERROR:Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 795, in compare_models
    np.sum(
AssertionError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 811, in compare_models
    np.sum(
AssertionError

2025-12-01 15:05:04,253:INFO:_master_model_container: 30
2025-12-01 15:05:04,253:INFO:_display_container: 2
2025-12-01 15:05:04,253:INFO:[]
2025-12-01 15:05:04,253:INFO:compare_models() successfully completed......................................
2025-12-01 15:08:52,353:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-12-01 15:08:52,353:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-12-01 15:08:52,353:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-12-01 15:08:52,353:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-12-01 15:08:52,840:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2025-12-01 15:08:53,210:INFO:PyCaret ClassificationExperiment
2025-12-01 15:08:53,210:INFO:Logging name: clf-default-name
2025-12-01 15:08:53,210:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-12-01 15:08:53,210:INFO:version 3.0.3
2025-12-01 15:08:53,210:INFO:Initializing setup()
2025-12-01 15:08:53,210:INFO:self.USI: ac74
2025-12-01 15:08:53,210:INFO:self._variable_keys: {'log_plots_param', 'is_multiclass', 'exp_name_log', 'logging_param', 'fold_generator', 'y', 'target_param', 'html_param', 'X_test', 'data', 'gpu_n_jobs_param', 'pipeline', 'idx', 'fold_shuffle_param', '_available_plots', '_ml_usecase', 'memory', 'exp_id', 'y_train', 'fold_groups_param', 'gpu_param', 'fix_imbalance', 'USI', 'y_test', 'X', 'X_train', 'n_jobs_param', 'seed'}
2025-12-01 15:08:53,210:INFO:Checking environment
2025-12-01 15:08:53,211:INFO:python_version: 3.10.19
2025-12-01 15:08:53,211:INFO:python_build: ('main', 'Nov  7 2025 00:05:37')
2025-12-01 15:08:53,211:INFO:machine: x86_64
2025-12-01 15:08:53,211:INFO:platform: Linux-6.8.0-x86_64-with-glibc2.39
2025-12-01 15:08:53,211:INFO:Memory: svmem(total=8345706496, available=7571124224, percent=9.3, used=774582272, free=4022337536, active=412704768, inactive=3576479744, buffers=77045760, cached=3784245248, shared=589824, slab=256548864)
2025-12-01 15:08:53,212:INFO:Physical Core: 4
2025-12-01 15:08:53,212:INFO:Logical Core: 4
2025-12-01 15:08:53,212:INFO:Checking libraries
2025-12-01 15:08:53,213:INFO:System:
2025-12-01 15:08:53,213:INFO:    python: 3.10.19 (main, Nov  7 2025, 00:05:37) [GCC 13.3.0]
2025-12-01 15:08:53,213:INFO:executable: /home/jules/.pyenv/versions/3.10.19/bin/python3.10
2025-12-01 15:08:53,213:INFO:   machine: Linux-6.8.0-x86_64-with-glibc2.39
2025-12-01 15:08:53,213:INFO:PyCaret required dependencies:
2025-12-01 15:08:53,215:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-01 15:08:53,256:INFO:                 pip: 25.3
2025-12-01 15:08:53,256:INFO:          setuptools: 79.0.1
2025-12-01 15:08:53,256:INFO:             pycaret: 3.0.3
2025-12-01 15:08:53,256:INFO:             IPython: 8.37.0
2025-12-01 15:08:53,256:INFO:          ipywidgets: 8.1.8
2025-12-01 15:08:53,256:INFO:                tqdm: 4.67.1
2025-12-01 15:08:53,256:INFO:               numpy: 1.23.5
2025-12-01 15:08:53,256:INFO:              pandas: 1.5.3
2025-12-01 15:08:53,256:INFO:              jinja2: 3.1.6
2025-12-01 15:08:53,256:INFO:               scipy: 1.10.1
2025-12-01 15:08:53,256:INFO:              joblib: 1.2.0
2025-12-01 15:08:53,256:INFO:             sklearn: 1.3.2
2025-12-01 15:08:53,256:INFO:                pyod: 2.0.5
2025-12-01 15:08:53,256:INFO:            imblearn: 0.12.4
2025-12-01 15:08:53,256:INFO:   category_encoders: 2.7.0
2025-12-01 15:08:53,256:INFO:            lightgbm: 4.6.0
2025-12-01 15:08:53,256:INFO:               numba: 0.62.1
2025-12-01 15:08:53,256:INFO:            requests: 2.32.5
2025-12-01 15:08:53,256:INFO:          matplotlib: 3.10.7
2025-12-01 15:08:53,256:INFO:          scikitplot: 0.3.7
2025-12-01 15:08:53,257:INFO:         yellowbrick: 1.5
2025-12-01 15:08:53,257:INFO:              plotly: 6.5.0
2025-12-01 15:08:53,257:INFO:    plotly-resampler: Not installed
2025-12-01 15:08:53,257:INFO:             kaleido: 1.2.0
2025-12-01 15:08:53,257:INFO:           schemdraw: 0.15
2025-12-01 15:08:53,257:INFO:         statsmodels: 0.14.5
2025-12-01 15:08:53,257:INFO:              sktime: 0.40.1
2025-12-01 15:08:53,257:INFO:               tbats: 1.1.3
2025-12-01 15:08:53,257:INFO:            pmdarima: 2.1.1
2025-12-01 15:08:53,257:INFO:              psutil: 7.1.3
2025-12-01 15:08:53,257:INFO:          markupsafe: 3.0.3
2025-12-01 15:08:53,257:INFO:             pickle5: Not installed
2025-12-01 15:08:53,257:INFO:         cloudpickle: 3.1.2
2025-12-01 15:08:53,257:INFO:         deprecation: 2.1.0
2025-12-01 15:08:53,257:INFO:              xxhash: 3.6.0
2025-12-01 15:08:53,257:INFO:           wurlitzer: 3.1.1
2025-12-01 15:08:53,257:INFO:PyCaret optional dependencies:
2025-12-01 15:08:53,353:INFO:                shap: 0.49.1
2025-12-01 15:08:53,353:INFO:           interpret: Not installed
2025-12-01 15:08:53,353:INFO:                umap: Not installed
2025-12-01 15:08:53,353:INFO:    pandas_profiling: Not installed
2025-12-01 15:08:53,353:INFO:  explainerdashboard: Not installed
2025-12-01 15:08:53,353:INFO:             autoviz: Not installed
2025-12-01 15:08:53,353:INFO:           fairlearn: Not installed
2025-12-01 15:08:53,353:INFO:          deepchecks: Not installed
2025-12-01 15:08:53,354:INFO:             xgboost: 2.1.3
2025-12-01 15:08:53,354:INFO:            catboost: Not installed
2025-12-01 15:08:53,354:INFO:              kmodes: Not installed
2025-12-01 15:08:53,354:INFO:             mlxtend: Not installed
2025-12-01 15:08:53,354:INFO:       statsforecast: Not installed
2025-12-01 15:08:53,354:INFO:        tune_sklearn: Not installed
2025-12-01 15:08:53,354:INFO:                 ray: Not installed
2025-12-01 15:08:53,354:INFO:            hyperopt: Not installed
2025-12-01 15:08:53,354:INFO:              optuna: Not installed
2025-12-01 15:08:53,354:INFO:               skopt: Not installed
2025-12-01 15:08:53,354:INFO:              mlflow: Not installed
2025-12-01 15:08:53,354:INFO:              gradio: Not installed
2025-12-01 15:08:53,354:INFO:             fastapi: Not installed
2025-12-01 15:08:53,354:INFO:             uvicorn: Not installed
2025-12-01 15:08:53,355:INFO:              m2cgen: Not installed
2025-12-01 15:08:53,355:INFO:           evidently: Not installed
2025-12-01 15:08:53,355:INFO:               fugue: Not installed
2025-12-01 15:08:53,355:INFO:           streamlit: Not installed
2025-12-01 15:08:53,355:INFO:             prophet: Not installed
2025-12-01 15:08:53,355:INFO:None
2025-12-01 15:08:53,355:INFO:Set up data.
2025-12-01 15:08:53,386:INFO:Set up train/test split.
2025-12-01 15:08:53,396:INFO:Set up index.
2025-12-01 15:08:53,397:INFO:Set up folding strategy.
2025-12-01 15:08:53,397:INFO:Assigning column types.
2025-12-01 15:08:53,404:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-12-01 15:08:53,500:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-12-01 15:08:53,507:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-01 15:08:53,558:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-01 15:08:53,562:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-01 15:08:53,635:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-12-01 15:08:53,637:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-01 15:08:53,673:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-01 15:08:53,676:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-01 15:08:53,677:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-12-01 15:08:53,736:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-01 15:08:53,773:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-01 15:08:53,777:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-01 15:08:53,837:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-01 15:08:53,873:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-01 15:08:53,876:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-01 15:08:53,877:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-12-01 15:08:53,974:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-01 15:08:53,977:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-01 15:08:54,074:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-01 15:08:54,078:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-01 15:08:54,080:INFO:Preparing preprocessing pipeline...
2025-12-01 15:08:54,081:INFO:Set up simple imputation.
2025-12-01 15:08:54,086:INFO:Set up encoding of ordinal features.
2025-12-01 15:08:54,088:INFO:Set up encoding of categorical features.
2025-12-01 15:08:54,088:INFO:Set up removing outliers.
2025-12-01 15:08:54,088:INFO:Set up imbalanced handling.
2025-12-01 15:08:54,088:INFO:Set up feature normalization.
2025-12-01 15:08:54,630:INFO:Finished creating preprocessing pipeline.
2025-12-01 15:08:54,675:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'SystolicBP',
                                             'TotalCholesterol', 'LDL',
                                             'Triglycerides', 'HbA1c',
                                             'Glucose', 'UricAcid',
                                             'Creatinine', 'BMI',
                                             'WaistCircumference', 'Height',
                                             'IncomeRatio', 'ALT_Enzyme',
                                             'AST_Enzyme', 'GGT_Enzyme',
                                             'Albumin', 'Potassium', 'Sodium'],
                                    transform...
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              n_jobs=None,
                                                                              random_state=None,
                                                                              sampling_strategy='auto')))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=RobustScaler(copy=True,
                                                             quantile_range=(25.0,
                                                                             75.0),
                                                             unit_variance=False,
                                                             with_centering=True,
                                                             with_scaling=True)))],
         verbose=False)
2025-12-01 15:08:54,675:INFO:Creating final display dataframe.
2025-12-01 15:08:55,834:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target      HeartDisease
2                   Target type            Binary
3           Original data shape        (2185, 27)
4        Transformed data shape        (3482, 33)
5   Transformed train set shape        (2826, 33)
6    Transformed test set shape         (656, 33)
7              Ordinal features                 1
8              Numeric features                19
9          Categorical features                 7
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16              Remove outliers              True
17           Outliers threshold              0.05
18                Fix imbalance              True
19         Fix imbalance method             SMOTE
20                    Normalize              True
21             Normalize method            robust
22               Fold Generator   StratifiedKFold
23                  Fold Number                10
24                     CPU Jobs                 1
25                      Use GPU             False
26               Log Experiment             False
27              Experiment Name  clf-default-name
28                          USI              ac74
2025-12-01 15:08:55,944:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-01 15:08:55,948:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-01 15:08:56,046:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-01 15:08:56,050:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-12-01 15:08:56,051:INFO:setup() successfully completed in 2.85s...............
2025-12-01 15:08:56,084:INFO:Initializing compare_models()
2025-12-01 15:08:56,084:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f72c4242ad0>, include=None, fold=None, round=4, cross_validation=True, sort=Recall, n_select=3, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x7f72c4242ad0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Recall', 'n_select': 3, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2025-12-01 15:08:56,084:INFO:Checking exceptions
2025-12-01 15:08:56,090:INFO:Preparing display monitor
2025-12-01 15:08:56,126:INFO:Initializing Logistic Regression
2025-12-01 15:08:56,126:INFO:Total runtime is 2.6067097981770834e-06 minutes
2025-12-01 15:08:56,131:INFO:SubProcess create_model() called ==================================
2025-12-01 15:08:56,131:INFO:Initializing create_model()
2025-12-01 15:08:56,131:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f72c4242ad0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f72c42410c0>, model_only=True, return_train_score=False, kwargs={})
2025-12-01 15:08:56,131:INFO:Checking exceptions
2025-12-01 15:08:56,132:INFO:Importing libraries
2025-12-01 15:08:56,132:INFO:Copying training dataset
2025-12-01 15:08:56,137:INFO:Defining folds
2025-12-01 15:08:56,138:INFO:Declaring metric variables
2025-12-01 15:08:56,142:INFO:Importing untrained model
2025-12-01 15:08:56,147:INFO:Logistic Regression Imported successfully
2025-12-01 15:08:56,157:INFO:Starting cross validation
2025-12-01 15:08:56,171:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-12-01 15:09:05,079:INFO:Calculating mean and std
2025-12-01 15:09:05,081:INFO:Creating metrics dataframe
2025-12-01 15:09:05,096:INFO:Uploading results into container
2025-12-01 15:09:05,097:INFO:Uploading model into container now
2025-12-01 15:09:05,097:INFO:_master_model_container: 1
2025-12-01 15:09:05,098:INFO:_display_container: 2
2025-12-01 15:09:05,098:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-12-01 15:09:05,098:INFO:create_model() successfully completed......................................
2025-12-01 15:09:05,211:INFO:SubProcess create_model() end ==================================
2025-12-01 15:09:05,211:INFO:Creating metrics dataframe
2025-12-01 15:09:05,225:INFO:Initializing K Neighbors Classifier
2025-12-01 15:09:05,225:INFO:Total runtime is 0.1516514301300049 minutes
2025-12-01 15:09:05,230:INFO:SubProcess create_model() called ==================================
2025-12-01 15:09:05,230:INFO:Initializing create_model()
2025-12-01 15:09:05,231:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f72c4242ad0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f72c42410c0>, model_only=True, return_train_score=False, kwargs={})
2025-12-01 15:09:05,231:INFO:Checking exceptions
2025-12-01 15:09:05,231:INFO:Importing libraries
2025-12-01 15:09:05,231:INFO:Copying training dataset
2025-12-01 15:09:05,238:INFO:Defining folds
2025-12-01 15:09:05,238:INFO:Declaring metric variables
2025-12-01 15:09:05,243:INFO:Importing untrained model
2025-12-01 15:09:05,248:INFO:K Neighbors Classifier Imported successfully
2025-12-01 15:09:05,258:INFO:Starting cross validation
2025-12-01 15:09:05,271:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-12-01 15:09:09,551:INFO:Calculating mean and std
2025-12-01 15:09:09,553:INFO:Creating metrics dataframe
2025-12-01 15:09:09,568:INFO:Uploading results into container
2025-12-01 15:09:09,568:INFO:Uploading model into container now
2025-12-01 15:09:09,569:INFO:_master_model_container: 2
2025-12-01 15:09:09,569:INFO:_display_container: 2
2025-12-01 15:09:09,569:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=1, n_neighbors=5, p=2,
                     weights='uniform')
2025-12-01 15:09:09,569:INFO:create_model() successfully completed......................................
2025-12-01 15:09:09,678:INFO:SubProcess create_model() end ==================================
2025-12-01 15:09:09,678:INFO:Creating metrics dataframe
2025-12-01 15:09:09,693:INFO:Initializing Naive Bayes
2025-12-01 15:09:09,693:INFO:Total runtime is 0.226113764444987 minutes
2025-12-01 15:09:09,698:INFO:SubProcess create_model() called ==================================
2025-12-01 15:09:09,698:INFO:Initializing create_model()
2025-12-01 15:09:09,698:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f72c4242ad0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f72c42410c0>, model_only=True, return_train_score=False, kwargs={})
2025-12-01 15:09:09,698:INFO:Checking exceptions
2025-12-01 15:09:09,698:INFO:Importing libraries
2025-12-01 15:09:09,698:INFO:Copying training dataset
2025-12-01 15:09:09,705:INFO:Defining folds
2025-12-01 15:09:09,705:INFO:Declaring metric variables
2025-12-01 15:09:09,710:INFO:Importing untrained model
2025-12-01 15:09:09,716:INFO:Naive Bayes Imported successfully
2025-12-01 15:09:09,725:INFO:Starting cross validation
2025-12-01 15:09:09,740:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-12-01 15:09:13,583:INFO:Calculating mean and std
2025-12-01 15:09:13,585:INFO:Creating metrics dataframe
2025-12-01 15:09:13,601:INFO:Uploading results into container
2025-12-01 15:09:13,602:INFO:Uploading model into container now
2025-12-01 15:09:13,602:INFO:_master_model_container: 3
2025-12-01 15:09:13,602:INFO:_display_container: 2
2025-12-01 15:09:13,603:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-12-01 15:09:13,603:INFO:create_model() successfully completed......................................
2025-12-01 15:09:13,715:INFO:SubProcess create_model() end ==================================
2025-12-01 15:09:13,715:INFO:Creating metrics dataframe
2025-12-01 15:09:13,730:INFO:Initializing Decision Tree Classifier
2025-12-01 15:09:13,731:INFO:Total runtime is 0.29341237545013427 minutes
2025-12-01 15:09:13,736:INFO:SubProcess create_model() called ==================================
2025-12-01 15:09:13,736:INFO:Initializing create_model()
2025-12-01 15:09:13,737:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f72c4242ad0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f72c42410c0>, model_only=True, return_train_score=False, kwargs={})
2025-12-01 15:09:13,737:INFO:Checking exceptions
2025-12-01 15:09:13,737:INFO:Importing libraries
2025-12-01 15:09:13,737:INFO:Copying training dataset
2025-12-01 15:09:13,743:INFO:Defining folds
2025-12-01 15:09:13,743:INFO:Declaring metric variables
2025-12-01 15:09:13,749:INFO:Importing untrained model
2025-12-01 15:09:13,754:INFO:Decision Tree Classifier Imported successfully
2025-12-01 15:09:13,765:INFO:Starting cross validation
2025-12-01 15:09:13,779:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-12-01 15:09:18,316:INFO:Calculating mean and std
2025-12-01 15:09:18,318:INFO:Creating metrics dataframe
2025-12-01 15:09:18,332:INFO:Uploading results into container
2025-12-01 15:09:18,333:INFO:Uploading model into container now
2025-12-01 15:09:18,334:INFO:_master_model_container: 4
2025-12-01 15:09:18,334:INFO:_display_container: 2
2025-12-01 15:09:18,334:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=42, splitter='best')
2025-12-01 15:09:18,334:INFO:create_model() successfully completed......................................
2025-12-01 15:09:18,440:INFO:SubProcess create_model() end ==================================
2025-12-01 15:09:18,440:INFO:Creating metrics dataframe
2025-12-01 15:09:18,456:INFO:Initializing SVM - Linear Kernel
2025-12-01 15:09:18,456:INFO:Total runtime is 0.37216518322626746 minutes
2025-12-01 15:09:18,461:INFO:SubProcess create_model() called ==================================
2025-12-01 15:09:18,461:INFO:Initializing create_model()
2025-12-01 15:09:18,461:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f72c4242ad0>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f72c42410c0>, model_only=True, return_train_score=False, kwargs={})
2025-12-01 15:09:18,462:INFO:Checking exceptions
2025-12-01 15:09:18,462:INFO:Importing libraries
2025-12-01 15:09:18,462:INFO:Copying training dataset
2025-12-01 15:09:18,468:INFO:Defining folds
2025-12-01 15:09:18,468:INFO:Declaring metric variables
2025-12-01 15:09:18,473:INFO:Importing untrained model
2025-12-01 15:09:18,479:INFO:SVM - Linear Kernel Imported successfully
2025-12-01 15:09:18,488:INFO:Starting cross validation
2025-12-01 15:09:18,502:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-12-01 15:09:18,793:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_response.py", line 181, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1939, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2025-12-01 15:09:19,097:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_response.py", line 181, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1939, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2025-12-01 15:09:19,402:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_response.py", line 181, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1939, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2025-12-01 15:09:19,708:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_response.py", line 181, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1939, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2025-12-01 15:09:20,020:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_response.py", line 181, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1939, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2025-12-01 15:09:20,352:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_response.py", line 181, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1939, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2025-12-01 15:09:20,685:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_response.py", line 181, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1939, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2025-12-01 15:09:21,013:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_response.py", line 181, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1939, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2025-12-01 15:09:21,328:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_response.py", line 181, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1939, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2025-12-01 15:09:21,639:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_response.py", line 181, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1939, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2025-12-01 15:09:21,671:INFO:Calculating mean and std
2025-12-01 15:09:21,672:INFO:Creating metrics dataframe
2025-12-01 15:09:21,688:INFO:Uploading results into container
2025-12-01 15:09:21,688:INFO:Uploading model into container now
2025-12-01 15:09:21,689:INFO:_master_model_container: 5
2025-12-01 15:09:21,689:INFO:_display_container: 2
2025-12-01 15:09:21,689:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=1, penalty='l2',
              power_t=0.5, random_state=42, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-12-01 15:09:21,689:INFO:create_model() successfully completed......................................
2025-12-01 15:09:21,795:INFO:SubProcess create_model() end ==================================
2025-12-01 15:09:21,795:INFO:Creating metrics dataframe
2025-12-01 15:09:21,811:INFO:Initializing Ridge Classifier
2025-12-01 15:09:21,811:INFO:Total runtime is 0.42809326648712154 minutes
2025-12-01 15:09:21,817:INFO:SubProcess create_model() called ==================================
2025-12-01 15:09:21,817:INFO:Initializing create_model()
2025-12-01 15:09:21,817:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f72c4242ad0>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f72c42410c0>, model_only=True, return_train_score=False, kwargs={})
2025-12-01 15:09:21,817:INFO:Checking exceptions
2025-12-01 15:09:21,817:INFO:Importing libraries
2025-12-01 15:09:21,817:INFO:Copying training dataset
2025-12-01 15:09:21,824:INFO:Defining folds
2025-12-01 15:09:21,824:INFO:Declaring metric variables
2025-12-01 15:09:21,830:INFO:Importing untrained model
2025-12-01 15:09:21,835:INFO:Ridge Classifier Imported successfully
2025-12-01 15:09:21,844:INFO:Starting cross validation
2025-12-01 15:09:21,859:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-12-01 15:09:22,142:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_response.py", line 181, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1939, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2025-12-01 15:09:22,430:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_response.py", line 181, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1939, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2025-12-01 15:09:22,726:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_response.py", line 181, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1939, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2025-12-01 15:09:23,027:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_response.py", line 181, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1939, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2025-12-01 15:09:23,325:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_response.py", line 181, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1939, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2025-12-01 15:09:23,660:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_response.py", line 181, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1939, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2025-12-01 15:09:23,957:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_response.py", line 181, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1939, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2025-12-01 15:09:24,256:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_response.py", line 181, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1939, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2025-12-01 15:09:24,553:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_response.py", line 181, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1939, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2025-12-01 15:09:24,846:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_response.py", line 181, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1939, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2025-12-01 15:09:24,878:INFO:Calculating mean and std
2025-12-01 15:09:24,880:INFO:Creating metrics dataframe
2025-12-01 15:09:24,895:INFO:Uploading results into container
2025-12-01 15:09:24,895:INFO:Uploading model into container now
2025-12-01 15:09:24,896:INFO:_master_model_container: 6
2025-12-01 15:09:24,896:INFO:_display_container: 2
2025-12-01 15:09:24,896:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001)
2025-12-01 15:09:24,896:INFO:create_model() successfully completed......................................
2025-12-01 15:09:25,007:INFO:SubProcess create_model() end ==================================
2025-12-01 15:09:25,007:INFO:Creating metrics dataframe
2025-12-01 15:09:25,024:INFO:Initializing Random Forest Classifier
2025-12-01 15:09:25,024:INFO:Total runtime is 0.4816361506779988 minutes
2025-12-01 15:09:25,029:INFO:SubProcess create_model() called ==================================
2025-12-01 15:09:25,029:INFO:Initializing create_model()
2025-12-01 15:09:25,030:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f72c4242ad0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f72c42410c0>, model_only=True, return_train_score=False, kwargs={})
2025-12-01 15:09:25,030:INFO:Checking exceptions
2025-12-01 15:09:25,030:INFO:Importing libraries
2025-12-01 15:09:25,030:INFO:Copying training dataset
2025-12-01 15:09:25,037:INFO:Defining folds
2025-12-01 15:09:25,037:INFO:Declaring metric variables
2025-12-01 15:09:25,042:INFO:Importing untrained model
2025-12-01 15:09:25,047:INFO:Random Forest Classifier Imported successfully
2025-12-01 15:09:25,057:INFO:Starting cross validation
2025-12-01 15:09:25,071:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-12-01 15:09:28,487:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 15:09:30,227:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 15:09:31,954:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 15:09:33,685:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 15:09:42,372:INFO:Calculating mean and std
2025-12-01 15:09:42,374:INFO:Creating metrics dataframe
2025-12-01 15:09:42,390:INFO:Uploading results into container
2025-12-01 15:09:42,391:INFO:Uploading model into container now
2025-12-01 15:09:42,391:INFO:_master_model_container: 7
2025-12-01 15:09:42,391:INFO:_display_container: 2
2025-12-01 15:09:42,392:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=1, oob_score=False,
                       random_state=42, verbose=0, warm_start=False)
2025-12-01 15:09:42,392:INFO:create_model() successfully completed......................................
2025-12-01 15:09:42,502:INFO:SubProcess create_model() end ==================================
2025-12-01 15:09:42,502:INFO:Creating metrics dataframe
2025-12-01 15:09:42,518:INFO:Initializing Quadratic Discriminant Analysis
2025-12-01 15:09:42,519:INFO:Total runtime is 0.7732140580813089 minutes
2025-12-01 15:09:42,524:INFO:SubProcess create_model() called ==================================
2025-12-01 15:09:42,524:INFO:Initializing create_model()
2025-12-01 15:09:42,524:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f72c4242ad0>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f72c42410c0>, model_only=True, return_train_score=False, kwargs={})
2025-12-01 15:09:42,524:INFO:Checking exceptions
2025-12-01 15:09:42,524:INFO:Importing libraries
2025-12-01 15:09:42,525:INFO:Copying training dataset
2025-12-01 15:09:42,531:INFO:Defining folds
2025-12-01 15:09:42,531:INFO:Declaring metric variables
2025-12-01 15:09:42,536:INFO:Importing untrained model
2025-12-01 15:09:42,541:INFO:Quadratic Discriminant Analysis Imported successfully
2025-12-01 15:09:42,551:INFO:Starting cross validation
2025-12-01 15:09:42,565:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-12-01 15:09:42,758:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-12-01 15:09:43,128:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-12-01 15:09:43,502:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-12-01 15:09:43,674:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 15:09:43,878:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-12-01 15:09:44,255:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-12-01 15:09:44,428:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 15:09:44,635:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-12-01 15:09:45,015:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-12-01 15:09:45,401:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-12-01 15:09:45,777:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-12-01 15:09:46,155:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-12-01 15:09:46,328:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 15:09:46,356:INFO:Calculating mean and std
2025-12-01 15:09:46,357:INFO:Creating metrics dataframe
2025-12-01 15:09:46,373:INFO:Uploading results into container
2025-12-01 15:09:46,374:INFO:Uploading model into container now
2025-12-01 15:09:46,374:INFO:_master_model_container: 8
2025-12-01 15:09:46,374:INFO:_display_container: 2
2025-12-01 15:09:46,375:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-12-01 15:09:46,375:INFO:create_model() successfully completed......................................
2025-12-01 15:09:46,483:INFO:SubProcess create_model() end ==================================
2025-12-01 15:09:46,483:INFO:Creating metrics dataframe
2025-12-01 15:09:46,500:INFO:Initializing Ada Boost Classifier
2025-12-01 15:09:46,500:INFO:Total runtime is 0.8395708322525024 minutes
2025-12-01 15:09:46,505:INFO:SubProcess create_model() called ==================================
2025-12-01 15:09:46,505:INFO:Initializing create_model()
2025-12-01 15:09:46,505:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f72c4242ad0>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f72c42410c0>, model_only=True, return_train_score=False, kwargs={})
2025-12-01 15:09:46,506:INFO:Checking exceptions
2025-12-01 15:09:46,506:INFO:Importing libraries
2025-12-01 15:09:46,506:INFO:Copying training dataset
2025-12-01 15:09:46,512:INFO:Defining folds
2025-12-01 15:09:46,512:INFO:Declaring metric variables
2025-12-01 15:09:46,517:INFO:Importing untrained model
2025-12-01 15:09:46,522:INFO:Ada Boost Classifier Imported successfully
2025-12-01 15:09:46,532:INFO:Starting cross validation
2025-12-01 15:09:46,545:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-12-01 15:09:58,246:INFO:Calculating mean and std
2025-12-01 15:09:58,248:INFO:Creating metrics dataframe
2025-12-01 15:09:58,266:INFO:Uploading results into container
2025-12-01 15:09:58,267:INFO:Uploading model into container now
2025-12-01 15:09:58,267:INFO:_master_model_container: 9
2025-12-01 15:09:58,267:INFO:_display_container: 2
2025-12-01 15:09:58,268:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=42)
2025-12-01 15:09:58,268:INFO:create_model() successfully completed......................................
2025-12-01 15:09:58,385:INFO:SubProcess create_model() end ==================================
2025-12-01 15:09:58,386:INFO:Creating metrics dataframe
2025-12-01 15:09:58,404:INFO:Initializing Gradient Boosting Classifier
2025-12-01 15:09:58,404:INFO:Total runtime is 1.0379672408103942 minutes
2025-12-01 15:09:58,409:INFO:SubProcess create_model() called ==================================
2025-12-01 15:09:58,410:INFO:Initializing create_model()
2025-12-01 15:09:58,410:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f72c4242ad0>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f72c42410c0>, model_only=True, return_train_score=False, kwargs={})
2025-12-01 15:09:58,410:INFO:Checking exceptions
2025-12-01 15:09:58,410:INFO:Importing libraries
2025-12-01 15:09:58,410:INFO:Copying training dataset
2025-12-01 15:09:58,416:INFO:Defining folds
2025-12-01 15:09:58,417:INFO:Declaring metric variables
2025-12-01 15:09:58,422:INFO:Importing untrained model
2025-12-01 15:09:58,427:INFO:Gradient Boosting Classifier Imported successfully
2025-12-01 15:09:58,437:INFO:Starting cross validation
2025-12-01 15:09:58,451:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-12-01 15:10:07,474:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 15:10:28,824:INFO:Calculating mean and std
2025-12-01 15:10:28,826:INFO:Creating metrics dataframe
2025-12-01 15:10:28,844:INFO:Uploading results into container
2025-12-01 15:10:28,845:INFO:Uploading model into container now
2025-12-01 15:10:28,846:INFO:_master_model_container: 10
2025-12-01 15:10:28,846:INFO:_display_container: 2
2025-12-01 15:10:28,846:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-12-01 15:10:28,846:INFO:create_model() successfully completed......................................
2025-12-01 15:10:28,961:INFO:SubProcess create_model() end ==================================
2025-12-01 15:10:28,961:INFO:Creating metrics dataframe
2025-12-01 15:10:28,979:INFO:Initializing Linear Discriminant Analysis
2025-12-01 15:10:28,979:INFO:Total runtime is 1.5475538770357766 minutes
2025-12-01 15:10:28,984:INFO:SubProcess create_model() called ==================================
2025-12-01 15:10:28,985:INFO:Initializing create_model()
2025-12-01 15:10:28,985:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f72c4242ad0>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f72c42410c0>, model_only=True, return_train_score=False, kwargs={})
2025-12-01 15:10:28,985:INFO:Checking exceptions
2025-12-01 15:10:28,985:INFO:Importing libraries
2025-12-01 15:10:28,985:INFO:Copying training dataset
2025-12-01 15:10:28,992:INFO:Defining folds
2025-12-01 15:10:28,992:INFO:Declaring metric variables
2025-12-01 15:10:28,997:INFO:Importing untrained model
2025-12-01 15:10:29,002:INFO:Linear Discriminant Analysis Imported successfully
2025-12-01 15:10:29,012:INFO:Starting cross validation
2025-12-01 15:10:29,026:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-12-01 15:10:33,037:INFO:Calculating mean and std
2025-12-01 15:10:33,038:INFO:Creating metrics dataframe
2025-12-01 15:10:33,057:INFO:Uploading results into container
2025-12-01 15:10:33,057:INFO:Uploading model into container now
2025-12-01 15:10:33,058:INFO:_master_model_container: 11
2025-12-01 15:10:33,058:INFO:_display_container: 2
2025-12-01 15:10:33,058:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-12-01 15:10:33,058:INFO:create_model() successfully completed......................................
2025-12-01 15:10:33,173:INFO:SubProcess create_model() end ==================================
2025-12-01 15:10:33,174:INFO:Creating metrics dataframe
2025-12-01 15:10:33,192:INFO:Initializing Extra Trees Classifier
2025-12-01 15:10:33,192:INFO:Total runtime is 1.6177763422330218 minutes
2025-12-01 15:10:33,197:INFO:SubProcess create_model() called ==================================
2025-12-01 15:10:33,198:INFO:Initializing create_model()
2025-12-01 15:10:33,198:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f72c4242ad0>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f72c42410c0>, model_only=True, return_train_score=False, kwargs={})
2025-12-01 15:10:33,198:INFO:Checking exceptions
2025-12-01 15:10:33,198:INFO:Importing libraries
2025-12-01 15:10:33,198:INFO:Copying training dataset
2025-12-01 15:10:33,205:INFO:Defining folds
2025-12-01 15:10:33,205:INFO:Declaring metric variables
2025-12-01 15:10:33,210:INFO:Importing untrained model
2025-12-01 15:10:33,216:INFO:Extra Trees Classifier Imported successfully
2025-12-01 15:10:33,225:INFO:Starting cross validation
2025-12-01 15:10:33,239:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-12-01 15:10:34,210:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 15:10:35,189:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 15:10:36,183:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 15:10:37,192:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 15:10:38,185:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 15:10:39,164:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 15:10:40,147:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 15:10:42,108:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 15:10:43,090:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 15:10:43,124:INFO:Calculating mean and std
2025-12-01 15:10:43,126:INFO:Creating metrics dataframe
2025-12-01 15:10:43,146:INFO:Uploading results into container
2025-12-01 15:10:43,147:INFO:Uploading model into container now
2025-12-01 15:10:43,147:INFO:_master_model_container: 12
2025-12-01 15:10:43,148:INFO:_display_container: 2
2025-12-01 15:10:43,148:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=1, oob_score=False,
                     random_state=42, verbose=0, warm_start=False)
2025-12-01 15:10:43,148:INFO:create_model() successfully completed......................................
2025-12-01 15:10:43,262:INFO:SubProcess create_model() end ==================================
2025-12-01 15:10:43,262:INFO:Creating metrics dataframe
2025-12-01 15:10:43,282:INFO:Initializing Extreme Gradient Boosting
2025-12-01 15:10:43,282:INFO:Total runtime is 1.7859328269958494 minutes
2025-12-01 15:10:43,287:INFO:SubProcess create_model() called ==================================
2025-12-01 15:10:43,288:INFO:Initializing create_model()
2025-12-01 15:10:43,288:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f72c4242ad0>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f72c42410c0>, model_only=True, return_train_score=False, kwargs={})
2025-12-01 15:10:43,288:INFO:Checking exceptions
2025-12-01 15:10:43,288:INFO:Importing libraries
2025-12-01 15:10:43,288:INFO:Copying training dataset
2025-12-01 15:10:43,295:INFO:Defining folds
2025-12-01 15:10:43,295:INFO:Declaring metric variables
2025-12-01 15:10:43,300:INFO:Importing untrained model
2025-12-01 15:10:43,306:INFO:Extreme Gradient Boosting Imported successfully
2025-12-01 15:10:43,316:INFO:Starting cross validation
2025-12-01 15:10:43,330:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-12-01 15:10:45,260:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 15:10:49,911:INFO:Calculating mean and std
2025-12-01 15:10:49,912:INFO:Creating metrics dataframe
2025-12-01 15:10:49,932:INFO:Uploading results into container
2025-12-01 15:10:49,933:INFO:Uploading model into container now
2025-12-01 15:10:49,934:INFO:_master_model_container: 13
2025-12-01 15:10:49,934:INFO:_display_container: 2
2025-12-01 15:10:49,935:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2025-12-01 15:10:49,935:INFO:create_model() successfully completed......................................
2025-12-01 15:10:50,050:INFO:SubProcess create_model() end ==================================
2025-12-01 15:10:50,051:INFO:Creating metrics dataframe
2025-12-01 15:10:50,070:INFO:Initializing Light Gradient Boosting Machine
2025-12-01 15:10:50,070:INFO:Total runtime is 1.899076497554779 minutes
2025-12-01 15:10:50,076:INFO:SubProcess create_model() called ==================================
2025-12-01 15:10:50,076:INFO:Initializing create_model()
2025-12-01 15:10:50,076:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f72c4242ad0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f72c42410c0>, model_only=True, return_train_score=False, kwargs={})
2025-12-01 15:10:50,076:INFO:Checking exceptions
2025-12-01 15:10:50,076:INFO:Importing libraries
2025-12-01 15:10:50,076:INFO:Copying training dataset
2025-12-01 15:10:50,083:INFO:Defining folds
2025-12-01 15:10:50,083:INFO:Declaring metric variables
2025-12-01 15:10:50,089:INFO:Importing untrained model
2025-12-01 15:10:50,094:INFO:Light Gradient Boosting Machine Imported successfully
2025-12-01 15:10:50,104:INFO:Starting cross validation
2025-12-01 15:10:50,118:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-12-01 15:10:50,330:INFO:[LightGBM] [Info] Number of positive: 1271, number of negative: 1271
2025-12-01 15:10:50,331:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000442 seconds.
2025-12-01 15:10:50,331:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-01 15:10:50,331:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-01 15:10:50,333:INFO:[LightGBM] [Info] Total Bins 7032
2025-12-01 15:10:50,333:INFO:[LightGBM] [Info] Number of data points in the train set: 2542, number of used features: 31
2025-12-01 15:10:50,334:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-01 15:10:50,337:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 15:10:51,089:INFO:[LightGBM] [Info] Number of positive: 1270, number of negative: 1270
2025-12-01 15:10:51,090:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001071 seconds.
2025-12-01 15:10:51,090:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-01 15:10:51,092:INFO:[LightGBM] [Info] Total Bins 7144
2025-12-01 15:10:51,093:INFO:[LightGBM] [Info] Number of data points in the train set: 2540, number of used features: 31
2025-12-01 15:10:51,093:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-01 15:10:51,096:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 15:10:51,634:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 15:10:51,859:INFO:[LightGBM] [Info] Number of positive: 1272, number of negative: 1272
2025-12-01 15:10:51,860:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000478 seconds.
2025-12-01 15:10:51,860:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-01 15:10:51,860:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-01 15:10:51,862:INFO:[LightGBM] [Info] Total Bins 7091
2025-12-01 15:10:51,862:INFO:[LightGBM] [Info] Number of data points in the train set: 2544, number of used features: 31
2025-12-01 15:10:51,863:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-01 15:10:51,866:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 15:10:52,409:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 15:10:52,642:INFO:[LightGBM] [Info] Number of positive: 1272, number of negative: 1272
2025-12-01 15:10:52,643:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000962 seconds.
2025-12-01 15:10:52,643:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-01 15:10:52,645:INFO:[LightGBM] [Info] Total Bins 7254
2025-12-01 15:10:52,646:INFO:[LightGBM] [Info] Number of data points in the train set: 2544, number of used features: 31
2025-12-01 15:10:52,646:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-01 15:10:52,649:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 15:10:53,435:INFO:[LightGBM] [Info] Number of positive: 1270, number of negative: 1270
2025-12-01 15:10:53,436:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000969 seconds.
2025-12-01 15:10:53,436:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-01 15:10:53,438:INFO:[LightGBM] [Info] Total Bins 7134
2025-12-01 15:10:53,439:INFO:[LightGBM] [Info] Number of data points in the train set: 2540, number of used features: 31
2025-12-01 15:10:53,439:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-01 15:10:53,442:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 15:10:54,223:INFO:[LightGBM] [Info] Number of positive: 1272, number of negative: 1272
2025-12-01 15:10:54,224:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001035 seconds.
2025-12-01 15:10:54,224:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-01 15:10:54,226:INFO:[LightGBM] [Info] Total Bins 7136
2025-12-01 15:10:54,227:INFO:[LightGBM] [Info] Number of data points in the train set: 2544, number of used features: 31
2025-12-01 15:10:54,227:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-01 15:10:54,230:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 15:10:55,009:INFO:[LightGBM] [Info] Number of positive: 1271, number of negative: 1271
2025-12-01 15:10:55,011:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000542 seconds.
2025-12-01 15:10:55,011:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-01 15:10:55,011:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-01 15:10:55,013:INFO:[LightGBM] [Info] Total Bins 7229
2025-12-01 15:10:55,013:INFO:[LightGBM] [Info] Number of data points in the train set: 2542, number of used features: 31
2025-12-01 15:10:55,014:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-01 15:10:55,016:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 15:10:55,553:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 15:10:55,778:INFO:[LightGBM] [Info] Number of positive: 1271, number of negative: 1271
2025-12-01 15:10:55,780:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000613 seconds.
2025-12-01 15:10:55,780:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-01 15:10:55,780:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-01 15:10:55,782:INFO:[LightGBM] [Info] Total Bins 7181
2025-12-01 15:10:55,782:INFO:[LightGBM] [Info] Number of data points in the train set: 2542, number of used features: 31
2025-12-01 15:10:55,782:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-01 15:10:55,785:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 15:10:56,552:INFO:[LightGBM] [Info] Number of positive: 1271, number of negative: 1271
2025-12-01 15:10:56,554:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000547 seconds.
2025-12-01 15:10:56,554:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-01 15:10:56,554:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-01 15:10:56,556:INFO:[LightGBM] [Info] Total Bins 7130
2025-12-01 15:10:56,556:INFO:[LightGBM] [Info] Number of data points in the train set: 2542, number of used features: 31
2025-12-01 15:10:56,556:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-01 15:10:56,559:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-01 15:10:57,324:INFO:[LightGBM] [Info] Number of positive: 1273, number of negative: 1273
2025-12-01 15:10:57,326:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000553 seconds.
2025-12-01 15:10:57,326:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-01 15:10:57,326:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-01 15:10:57,328:INFO:[LightGBM] [Info] Total Bins 7185
2025-12-01 15:10:57,328:INFO:[LightGBM] [Info] Number of data points in the train set: 2546, number of used features: 31
2025-12-01 15:10:57,328:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-01 15:10:57,913:INFO:Calculating mean and std
2025-12-01 15:10:57,915:INFO:Creating metrics dataframe
2025-12-01 15:10:57,936:INFO:Uploading results into container
2025-12-01 15:10:57,937:INFO:Uploading model into container now
2025-12-01 15:10:57,937:INFO:_master_model_container: 14
2025-12-01 15:10:57,937:INFO:_display_container: 2
2025-12-01 15:10:57,938:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-12-01 15:10:57,938:INFO:create_model() successfully completed......................................
2025-12-01 15:10:58,053:INFO:SubProcess create_model() end ==================================
2025-12-01 15:10:58,054:INFO:Creating metrics dataframe
2025-12-01 15:10:58,073:INFO:Initializing Dummy Classifier
2025-12-01 15:10:58,073:INFO:Total runtime is 2.032458174228668 minutes
2025-12-01 15:10:58,079:INFO:SubProcess create_model() called ==================================
2025-12-01 15:10:58,079:INFO:Initializing create_model()
2025-12-01 15:10:58,079:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f72c4242ad0>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f72c42410c0>, model_only=True, return_train_score=False, kwargs={})
2025-12-01 15:10:58,079:INFO:Checking exceptions
2025-12-01 15:10:58,079:INFO:Importing libraries
2025-12-01 15:10:58,079:INFO:Copying training dataset
2025-12-01 15:10:58,086:INFO:Defining folds
2025-12-01 15:10:58,086:INFO:Declaring metric variables
2025-12-01 15:10:58,091:INFO:Importing untrained model
2025-12-01 15:10:58,097:INFO:Dummy Classifier Imported successfully
2025-12-01 15:10:58,106:INFO:Starting cross validation
2025-12-01 15:10:58,120:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-12-01 15:10:58,481:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 15:10:58,845:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 15:10:59,223:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 15:10:59,604:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 15:10:59,983:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 15:11:00,364:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 15:11:00,761:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 15:11:01,179:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 15:11:01,570:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 15:11:01,957:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-12-01 15:11:01,995:INFO:Calculating mean and std
2025-12-01 15:11:01,997:INFO:Creating metrics dataframe
2025-12-01 15:11:02,018:INFO:Uploading results into container
2025-12-01 15:11:02,019:INFO:Uploading model into container now
2025-12-01 15:11:02,020:INFO:_master_model_container: 15
2025-12-01 15:11:02,020:INFO:_display_container: 2
2025-12-01 15:11:02,020:INFO:DummyClassifier(constant=None, random_state=42, strategy='prior')
2025-12-01 15:11:02,020:INFO:create_model() successfully completed......................................
2025-12-01 15:11:02,131:INFO:SubProcess create_model() end ==================================
2025-12-01 15:11:02,132:INFO:Creating metrics dataframe
2025-12-01 15:11:02,164:INFO:Initializing create_model()
2025-12-01 15:11:02,165:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f72c4242ad0>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2025-12-01 15:11:02,165:INFO:Checking exceptions
2025-12-01 15:11:02,167:INFO:Importing libraries
2025-12-01 15:11:02,167:INFO:Copying training dataset
2025-12-01 15:11:02,173:INFO:Defining folds
2025-12-01 15:11:02,173:INFO:Declaring metric variables
2025-12-01 15:11:02,173:INFO:Importing untrained model
2025-12-01 15:11:02,173:INFO:Declaring custom model
2025-12-01 15:11:02,174:INFO:Naive Bayes Imported successfully
2025-12-01 15:11:02,186:INFO:Cross validation set to False
2025-12-01 15:11:02,187:INFO:Fitting Model
2025-12-01 15:11:02,390:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-12-01 15:11:02,390:INFO:create_model() successfully completed......................................
2025-12-01 15:11:02,515:INFO:Initializing create_model()
2025-12-01 15:11:02,516:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f72c4242ad0>, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2025-12-01 15:11:02,516:INFO:Checking exceptions
2025-12-01 15:11:02,518:INFO:Importing libraries
2025-12-01 15:11:02,518:INFO:Copying training dataset
2025-12-01 15:11:02,524:INFO:Defining folds
2025-12-01 15:11:02,524:INFO:Declaring metric variables
2025-12-01 15:11:02,524:INFO:Importing untrained model
2025-12-01 15:11:02,524:INFO:Declaring custom model
2025-12-01 15:11:02,525:INFO:Ridge Classifier Imported successfully
2025-12-01 15:11:02,538:INFO:Cross validation set to False
2025-12-01 15:11:02,538:INFO:Fitting Model
2025-12-01 15:11:02,747:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001)
2025-12-01 15:11:02,747:INFO:create_model() successfully completed......................................
2025-12-01 15:11:02,870:INFO:Initializing create_model()
2025-12-01 15:11:02,871:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f72c4242ad0>, estimator=LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2025-12-01 15:11:02,871:INFO:Checking exceptions
2025-12-01 15:11:02,873:INFO:Importing libraries
2025-12-01 15:11:02,873:INFO:Copying training dataset
2025-12-01 15:11:02,879:INFO:Defining folds
2025-12-01 15:11:02,879:INFO:Declaring metric variables
2025-12-01 15:11:02,879:INFO:Importing untrained model
2025-12-01 15:11:02,879:INFO:Declaring custom model
2025-12-01 15:11:02,880:INFO:Linear Discriminant Analysis Imported successfully
2025-12-01 15:11:02,894:INFO:Cross validation set to False
2025-12-01 15:11:02,894:INFO:Fitting Model
2025-12-01 15:11:03,119:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-12-01 15:11:03,119:INFO:create_model() successfully completed......................................
2025-12-01 15:11:03,278:INFO:_master_model_container: 15
2025-12-01 15:11:03,278:INFO:_display_container: 2
2025-12-01 15:11:03,279:INFO:[GaussianNB(priors=None, var_smoothing=1e-09), RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001), LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)]
2025-12-01 15:11:03,279:INFO:compare_models() successfully completed......................................
2025-12-01 15:11:03,317:INFO:Initializing tune_model()
2025-12-01 15:11:03,317:INFO:tune_model(estimator=GaussianNB(priors=None, var_smoothing=1e-09), fold=None, round=4, n_iter=2, custom_grid=None, optimize=Recall, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=False, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f72c4242ad0>)
2025-12-01 15:11:03,317:INFO:Checking exceptions
2025-12-01 15:11:03,322:INFO:Copying training dataset
2025-12-01 15:11:03,326:INFO:Checking base model
2025-12-01 15:11:03,326:INFO:Base model : Naive Bayes
2025-12-01 15:11:03,327:INFO:Declaring metric variables
2025-12-01 15:11:03,327:INFO:Defining Hyperparameters
2025-12-01 15:11:03,457:INFO:Tuning with n_jobs=1
2025-12-01 15:11:03,457:INFO:Initializing RandomizedSearchCV
2025-12-01 15:11:09,316:INFO:best_params: {'actual_estimator__var_smoothing': 2e-07}
2025-12-01 15:11:09,316:INFO:Hyperparameter search completed
2025-12-01 15:11:09,316:INFO:SubProcess create_model() called ==================================
2025-12-01 15:11:09,317:INFO:Initializing create_model()
2025-12-01 15:11:09,317:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f72c4242ad0>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f726d586b00>, model_only=True, return_train_score=False, kwargs={'var_smoothing': 2e-07})
2025-12-01 15:11:09,317:INFO:Checking exceptions
2025-12-01 15:11:09,317:INFO:Importing libraries
2025-12-01 15:11:09,317:INFO:Copying training dataset
2025-12-01 15:11:09,322:INFO:Defining folds
2025-12-01 15:11:09,322:INFO:Declaring metric variables
2025-12-01 15:11:09,322:INFO:Importing untrained model
2025-12-01 15:11:09,322:INFO:Declaring custom model
2025-12-01 15:11:09,323:INFO:Naive Bayes Imported successfully
2025-12-01 15:11:09,323:INFO:Starting cross validation
2025-12-01 15:11:09,336:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-12-01 15:11:13,141:INFO:Calculating mean and std
2025-12-01 15:11:13,142:INFO:Creating metrics dataframe
2025-12-01 15:11:13,145:INFO:Finalizing model
2025-12-01 15:11:13,350:INFO:Uploading results into container
2025-12-01 15:11:13,351:INFO:Uploading model into container now
2025-12-01 15:11:13,352:INFO:_master_model_container: 16
2025-12-01 15:11:13,352:INFO:_display_container: 3
2025-12-01 15:11:13,352:INFO:GaussianNB(priors=None, var_smoothing=2e-07)
2025-12-01 15:11:13,352:INFO:create_model() successfully completed......................................
2025-12-01 15:11:13,473:INFO:SubProcess create_model() end ==================================
2025-12-01 15:11:13,473:INFO:choose_better activated
2025-12-01 15:11:13,473:INFO:SubProcess create_model() called ==================================
2025-12-01 15:11:13,474:INFO:Initializing create_model()
2025-12-01 15:11:13,474:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f72c4242ad0>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2025-12-01 15:11:13,474:INFO:Checking exceptions
2025-12-01 15:11:13,477:INFO:Importing libraries
2025-12-01 15:11:13,477:INFO:Copying training dataset
2025-12-01 15:11:13,482:INFO:Defining folds
2025-12-01 15:11:13,482:INFO:Declaring metric variables
2025-12-01 15:11:13,482:INFO:Importing untrained model
2025-12-01 15:11:13,482:INFO:Declaring custom model
2025-12-01 15:11:13,482:INFO:Naive Bayes Imported successfully
2025-12-01 15:11:13,483:INFO:Starting cross validation
2025-12-01 15:11:13,496:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-12-01 15:11:17,352:INFO:Calculating mean and std
2025-12-01 15:11:17,353:INFO:Creating metrics dataframe
2025-12-01 15:11:17,356:INFO:Finalizing model
2025-12-01 15:11:17,565:INFO:Uploading results into container
2025-12-01 15:11:17,566:INFO:Uploading model into container now
2025-12-01 15:11:17,567:INFO:_master_model_container: 17
2025-12-01 15:11:17,567:INFO:_display_container: 4
2025-12-01 15:11:17,567:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-12-01 15:11:17,567:INFO:create_model() successfully completed......................................
2025-12-01 15:11:17,682:INFO:SubProcess create_model() end ==================================
2025-12-01 15:11:17,682:INFO:GaussianNB(priors=None, var_smoothing=1e-09) result for Recall is 0.79
2025-12-01 15:11:17,683:INFO:GaussianNB(priors=None, var_smoothing=2e-07) result for Recall is 0.725
2025-12-01 15:11:17,683:INFO:GaussianNB(priors=None, var_smoothing=1e-09) is best model
2025-12-01 15:11:17,683:INFO:choose_better completed
2025-12-01 15:11:17,683:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2025-12-01 15:11:17,684:INFO:_master_model_container: 17
2025-12-01 15:11:17,684:INFO:_display_container: 3
2025-12-01 15:11:17,684:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-12-01 15:11:17,684:INFO:tune_model() successfully completed......................................
2025-12-01 15:11:17,854:INFO:Initializing predict_model()
2025-12-01 15:11:17,854:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f72c4242ad0>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), probability_threshold=None, encoded_labels=False, raw_score=True, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7f726dadadd0>)
2025-12-01 15:11:17,854:INFO:Checking exceptions
2025-12-01 15:11:17,854:INFO:Preloading libraries
2025-12-01 15:11:18,354:INFO:Initializing get_config()
2025-12-01 15:11:18,355:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f72c4242ad0>, variable=target_param)
2025-12-01 15:11:18,355:INFO:Variable:  returned as HeartDisease
2025-12-01 15:11:18,355:INFO:get_config() successfully completed......................................
2025-12-01 15:11:19,367:INFO:Initializing interpret_model()
2025-12-01 15:11:19,367:INFO:interpret_model(estimator=GaussianNB(priors=None, var_smoothing=1e-09), use_train_data=False, X_new_sample=None, y_new_sample=None, feature=None, kwargs={}, observation=None, plot=summary, save=False, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f72c4242ad0>)
2025-12-01 15:11:19,367:INFO:Checking exceptions
2025-12-01 15:11:19,367:INFO:Soft dependency imported: shap: 0.49.1
2025-12-01 15:11:19,721:INFO:Initializing finalize_model()
2025-12-01 15:11:19,721:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f72c4242ad0>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2025-12-01 15:11:19,721:INFO:Finalizing GaussianNB(priors=None, var_smoothing=1e-09)
2025-12-01 15:11:19,726:INFO:Initializing create_model()
2025-12-01 15:11:19,726:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f72c4242ad0>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2025-12-01 15:11:19,726:INFO:Checking exceptions
2025-12-01 15:11:19,729:INFO:Importing libraries
2025-12-01 15:11:19,729:INFO:Copying training dataset
2025-12-01 15:11:19,729:INFO:Defining folds
2025-12-01 15:11:19,729:INFO:Declaring metric variables
2025-12-01 15:11:19,730:INFO:Importing untrained model
2025-12-01 15:11:19,730:INFO:Declaring custom model
2025-12-01 15:11:19,730:INFO:Naive Bayes Imported successfully
2025-12-01 15:11:19,744:INFO:Cross validation set to False
2025-12-01 15:11:19,744:INFO:Fitting Model
2025-12-01 15:11:20,307:INFO:Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'SystolicBP',
                                             'TotalCholesterol', 'LDL',
                                             'Triglycerides', 'HbA1c',
                                             'Glucose', 'UricAcid',
                                             'Creatinine', 'BMI',
                                             'WaistCircumference', 'Height',
                                             'IncomeRatio', 'ALT_Enzyme',
                                             'AST_Enzyme', 'GGT_Enzyme',
                                             'Albumin', 'Potassium', 'Sodium'],
                                    transform...
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              n_jobs=None,
                                                                              random_state=None,
                                                                              sampling_strategy='auto')))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=RobustScaler(copy=True,
                                                             quantile_range=(25.0,
                                                                             75.0),
                                                             unit_variance=False,
                                                             with_centering=True,
                                                             with_scaling=True))),
                ('actual_estimator',
                 GaussianNB(priors=None, var_smoothing=1e-09))],
         verbose=False)
2025-12-01 15:11:20,307:INFO:create_model() successfully completed......................................
2025-12-01 15:11:20,434:INFO:_master_model_container: 17
2025-12-01 15:11:20,435:INFO:_display_container: 4
2025-12-01 15:11:20,481:INFO:Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'SystolicBP',
                                             'TotalCholesterol', 'LDL',
                                             'Triglycerides', 'HbA1c',
                                             'Glucose', 'UricAcid',
                                             'Creatinine', 'BMI',
                                             'WaistCircumference', 'Height',
                                             'IncomeRatio', 'ALT_Enzyme',
                                             'AST_Enzyme', 'GGT_Enzyme',
                                             'Albumin', 'Potassium', 'Sodium'],
                                    transform...
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              n_jobs=None,
                                                                              random_state=None,
                                                                              sampling_strategy='auto')))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=RobustScaler(copy=True,
                                                             quantile_range=(25.0,
                                                                             75.0),
                                                             unit_variance=False,
                                                             with_centering=True,
                                                             with_scaling=True))),
                ('actual_estimator',
                 GaussianNB(priors=None, var_smoothing=1e-09))],
         verbose=False)
2025-12-01 15:11:20,481:INFO:finalize_model() successfully completed......................................
2025-12-01 15:11:20,691:INFO:Initializing save_model()
2025-12-01 15:11:20,691:INFO:save_model(model=Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'SystolicBP',
                                             'TotalCholesterol', 'LDL',
                                             'Triglycerides', 'HbA1c',
                                             'Glucose', 'UricAcid',
                                             'Creatinine', 'BMI',
                                             'WaistCircumference', 'Height',
                                             'IncomeRatio', 'ALT_Enzyme',
                                             'AST_Enzyme', 'GGT_Enzyme',
                                             'Albumin', 'Potassium', 'Sodium'],
                                    transform...
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              n_jobs=None,
                                                                              random_state=None,
                                                                              sampling_strategy='auto')))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=RobustScaler(copy=True,
                                                             quantile_range=(25.0,
                                                                             75.0),
                                                             unit_variance=False,
                                                             with_centering=True,
                                                             with_scaling=True))),
                ('actual_estimator',
                 GaussianNB(priors=None, var_smoothing=1e-09))],
         verbose=False), model_name=../models/best_pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'SystolicBP',
                                             'TotalCholesterol', 'LDL',
                                             'Triglycerides', 'HbA1c',
                                             'Glucose', 'UricAcid',
                                             'Creatinine', 'BMI',
                                             'WaistCircumference', 'Height',
                                             'IncomeRatio', 'ALT_Enzyme',
                                             'AST_Enzyme', 'GGT_Enzyme',
                                             'Albumin', 'Potassium', 'Sodium'],
                                    transform...
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              n_jobs=None,
                                                                              random_state=None,
                                                                              sampling_strategy='auto')))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=RobustScaler(copy=True,
                                                             quantile_range=(25.0,
                                                                             75.0),
                                                             unit_variance=False,
                                                             with_centering=True,
                                                             with_scaling=True)))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2025-12-01 15:11:20,691:INFO:Adding model into prep_pipe
2025-12-01 15:11:20,691:WARNING:Only Model saved as it was a pipeline.
2025-12-01 15:11:20,792:INFO:../models/best_pipeline.pkl saved in current working directory
2025-12-01 15:11:20,838:INFO:Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'SystolicBP',
                                             'TotalCholesterol', 'LDL',
                                             'Triglycerides', 'HbA1c',
                                             'Glucose', 'UricAcid',
                                             'Creatinine', 'BMI',
                                             'WaistCircumference', 'Height',
                                             'IncomeRatio', 'ALT_Enzyme',
                                             'AST_Enzyme', 'GGT_Enzyme',
                                             'Albumin', 'Potassium', 'Sodium'],
                                    transform...
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              n_jobs=None,
                                                                              random_state=None,
                                                                              sampling_strategy='auto')))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=RobustScaler(copy=True,
                                                             quantile_range=(25.0,
                                                                             75.0),
                                                             unit_variance=False,
                                                             with_centering=True,
                                                             with_scaling=True))),
                ('actual_estimator',
                 GaussianNB(priors=None, var_smoothing=1e-09))],
         verbose=False)
2025-12-01 15:11:20,839:INFO:save_model() successfully completed......................................
2025-12-01 15:12:15,288:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-12-01 15:12:15,289:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-12-01 15:12:15,289:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-12-01 15:12:15,289:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-12-01 15:12:15,775:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2025-12-01 15:13:56,192:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-12-01 15:13:56,193:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-12-01 15:13:56,193:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-12-01 15:13:56,193:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-12-01 15:13:56,674:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2025-12-01 15:13:56,980:INFO:Initializing load_model()
2025-12-01 15:13:56,980:INFO:load_model(model_name=../models/best_pipeline, platform=None, authentication=None, verbose=True)
2025-12-01 15:13:57,049:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-01 15:13:57,221:INFO:Initializing predict_model()
2025-12-01 15:13:57,221:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f1bf4f42e90>, estimator=Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Age', 'SystolicBP',
                                             'TotalCholesterol', 'LDL',
                                             'Triglycerides', 'HbA1c',
                                             'Glucose', 'UricAcid',
                                             'Creatinine', 'BMI',
                                             'WaistCircumference', 'Height',
                                             'IncomeRatio', 'ALT_Enzyme',
                                             'AST_Enzyme', 'GGT_Enzyme',
                                             'Albumin', 'Potassium', 'Sodium'],
                                    transformer=SimpleImpu...
                 TransformerWrapper(include=['Education', 'Smoking', 'Alcohol',
                                             'PhysicalActivity'],
                                    transformer=TargetEncoder(cols=[],
                                                              handle_missing='return_nan'))),
                ('remove_outliers',
                 TransformerWrapper(transformer=RemoveOutliers(random_state=42))),
                ('balance',
                 TransformerWrapper(transformer=FixImbalancer(estimator=SMOTE()))),
                ('normalize', TransformerWrapper(transformer=RobustScaler())),
                ('actual_estimator', GaussianNB())]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7f1b9fcfdab0>)
2025-12-01 15:13:57,221:INFO:Checking exceptions
2025-12-01 15:13:57,221:INFO:Preloading libraries
2025-12-01 15:13:57,222:INFO:Set up data.
2025-12-01 15:13:57,245:INFO:Set up index.
2025-12-01 15:14:52,456:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-12-01 15:14:52,457:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-12-01 15:14:52,457:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-12-01 15:14:52,457:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-12-01 15:14:52,935:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2025-12-01 15:14:53,170:INFO:Initializing load_model()
2025-12-01 15:14:53,170:INFO:load_model(model_name=../models/best_pipeline, platform=None, authentication=None, verbose=True)
2025-12-01 15:14:53,240:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-01 15:14:53,429:INFO:Initializing predict_model()
2025-12-01 15:14:53,429:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fca3f1adf00>, estimator=Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Age', 'SystolicBP',
                                             'TotalCholesterol', 'LDL',
                                             'Triglycerides', 'HbA1c',
                                             'Glucose', 'UricAcid',
                                             'Creatinine', 'BMI',
                                             'WaistCircumference', 'Height',
                                             'IncomeRatio', 'ALT_Enzyme',
                                             'AST_Enzyme', 'GGT_Enzyme',
                                             'Albumin', 'Potassium', 'Sodium'],
                                    transformer=SimpleImpu...
                 TransformerWrapper(include=['Education', 'Smoking', 'Alcohol',
                                             'PhysicalActivity'],
                                    transformer=TargetEncoder(cols=[],
                                                              handle_missing='return_nan'))),
                ('remove_outliers',
                 TransformerWrapper(transformer=RemoveOutliers(random_state=42))),
                ('balance',
                 TransformerWrapper(transformer=FixImbalancer(estimator=SMOTE()))),
                ('normalize', TransformerWrapper(transformer=RobustScaler())),
                ('actual_estimator', GaussianNB())]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7fca3f23cee0>)
2025-12-01 15:14:53,429:INFO:Checking exceptions
2025-12-01 15:14:53,429:INFO:Preloading libraries
2025-12-01 15:14:53,429:INFO:Set up data.
2025-12-01 15:14:53,441:INFO:Set up index.
