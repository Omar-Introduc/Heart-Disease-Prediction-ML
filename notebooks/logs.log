2025-11-27 21:35:32,191:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-11-27 21:35:32,191:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-11-27 21:35:32,191:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-11-27 21:35:32,191:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-11-27 21:35:33,204:INFO:PyCaret ClassificationExperiment
2025-11-27 21:35:33,204:INFO:Logging name: clf-default-name
2025-11-27 21:35:33,204:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-11-27 21:35:33,204:INFO:version 3.3.2
2025-11-27 21:35:33,204:INFO:Initializing setup()
2025-11-27 21:35:33,204:INFO:self.USI: b0f4
2025-11-27 21:35:33,204:INFO:self._variable_keys: {'seed', 'logging_param', 'html_param', 'X', 'USI', 'is_multiclass', 'X_train', 'data', 'fold_generator', 'exp_id', 'idx', 'log_plots_param', 'fold_groups_param', 'X_test', 'pipeline', 'gpu_param', 'fix_imbalance', 'target_param', 'y_train', 'exp_name_log', 'y_test', 'y', 'fold_shuffle_param', 'n_jobs_param', 'memory', 'gpu_n_jobs_param', '_available_plots', '_ml_usecase'}
2025-11-27 21:35:33,204:INFO:Checking environment
2025-11-27 21:35:33,204:INFO:python_version: 3.10.19
2025-11-27 21:35:33,204:INFO:python_build: ('main', 'Oct 22 2025 22:23:22')
2025-11-27 21:35:33,204:INFO:machine: AMD64
2025-11-27 21:35:33,204:INFO:platform: Windows-10-10.0.26100-SP0
2025-11-27 21:35:33,204:INFO:Memory: svmem(total=16282144768, available=5985746944, percent=63.2, used=10296397824, free=5985746944)
2025-11-27 21:35:33,204:INFO:Physical Core: 6
2025-11-27 21:35:33,204:INFO:Logical Core: 12
2025-11-27 21:35:33,204:INFO:Checking libraries
2025-11-27 21:35:33,204:INFO:System:
2025-11-27 21:35:33,204:INFO:    python: 3.10.19 | packaged by conda-forge | (main, Oct 22 2025, 22:23:22) [MSC v.1944 64 bit (AMD64)]
2025-11-27 21:35:33,204:INFO:executable: c:\Users\OMAR\miniconda3\envs\xgb_env\python.exe
2025-11-27 21:35:33,204:INFO:   machine: Windows-10-10.0.26100-SP0
2025-11-27 21:35:33,204:INFO:PyCaret required dependencies:
2025-11-27 21:35:33,204:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-27 21:35:33,268:INFO:                 pip: 25.3
2025-11-27 21:35:33,268:INFO:          setuptools: 80.9.0
2025-11-27 21:35:33,268:INFO:             pycaret: 3.3.2
2025-11-27 21:35:33,268:INFO:             IPython: 8.37.0
2025-11-27 21:35:33,268:INFO:          ipywidgets: 8.1.8
2025-11-27 21:35:33,268:INFO:                tqdm: 4.67.1
2025-11-27 21:35:33,268:INFO:               numpy: 1.26.4
2025-11-27 21:35:33,268:INFO:              pandas: 2.1.4
2025-11-27 21:35:33,268:INFO:              jinja2: 3.1.6
2025-11-27 21:35:33,268:INFO:               scipy: 1.11.4
2025-11-27 21:35:33,268:INFO:              joblib: 1.3.2
2025-11-27 21:35:33,268:INFO:             sklearn: 1.4.2
2025-11-27 21:35:33,268:INFO:                pyod: 2.0.5
2025-11-27 21:35:33,268:INFO:            imblearn: 0.14.0
2025-11-27 21:35:33,268:INFO:   category_encoders: 2.7.0
2025-11-27 21:35:33,272:INFO:            lightgbm: 4.6.0
2025-11-27 21:35:33,272:INFO:               numba: 0.62.1
2025-11-27 21:35:33,272:INFO:            requests: 2.32.5
2025-11-27 21:35:33,272:INFO:          matplotlib: 3.7.5
2025-11-27 21:35:33,272:INFO:          scikitplot: 0.3.7
2025-11-27 21:35:33,272:INFO:         yellowbrick: 1.5
2025-11-27 21:35:33,272:INFO:              plotly: 6.5.0
2025-11-27 21:35:33,272:INFO:    plotly-resampler: Not installed
2025-11-27 21:35:33,272:INFO:             kaleido: 1.2.0
2025-11-27 21:35:33,272:INFO:           schemdraw: 0.15
2025-11-27 21:35:33,272:INFO:         statsmodels: 0.14.5
2025-11-27 21:35:33,272:INFO:              sktime: 0.26.0
2025-11-27 21:35:33,272:INFO:               tbats: 1.1.3
2025-11-27 21:35:33,272:INFO:            pmdarima: 2.0.4
2025-11-27 21:35:33,272:INFO:              psutil: 7.1.3
2025-11-27 21:35:33,272:INFO:          markupsafe: 3.0.3
2025-11-27 21:35:33,272:INFO:             pickle5: Not installed
2025-11-27 21:35:33,272:INFO:         cloudpickle: 3.1.2
2025-11-27 21:35:33,272:INFO:         deprecation: 2.1.0
2025-11-27 21:35:33,272:INFO:              xxhash: 3.6.0
2025-11-27 21:35:33,272:INFO:           wurlitzer: Not installed
2025-11-27 21:35:33,272:INFO:PyCaret optional dependencies:
2025-11-27 21:35:33,279:INFO:                shap: 0.48.0
2025-11-27 21:35:33,279:INFO:           interpret: Not installed
2025-11-27 21:35:33,279:INFO:                umap: Not installed
2025-11-27 21:35:33,279:INFO:     ydata_profiling: Not installed
2025-11-27 21:35:33,279:INFO:  explainerdashboard: Not installed
2025-11-27 21:35:33,279:INFO:             autoviz: Not installed
2025-11-27 21:35:33,279:INFO:           fairlearn: 0.12.0.dev0
2025-11-27 21:35:33,279:INFO:          deepchecks: Not installed
2025-11-27 21:35:33,279:INFO:             xgboost: 3.1.2
2025-11-27 21:35:33,279:INFO:            catboost: Not installed
2025-11-27 21:35:33,279:INFO:              kmodes: Not installed
2025-11-27 21:35:33,279:INFO:             mlxtend: Not installed
2025-11-27 21:35:33,279:INFO:       statsforecast: Not installed
2025-11-27 21:35:33,279:INFO:        tune_sklearn: Not installed
2025-11-27 21:35:33,279:INFO:                 ray: Not installed
2025-11-27 21:35:33,279:INFO:            hyperopt: Not installed
2025-11-27 21:35:33,279:INFO:              optuna: Not installed
2025-11-27 21:35:33,279:INFO:               skopt: Not installed
2025-11-27 21:35:33,279:INFO:              mlflow: Not installed
2025-11-27 21:35:33,279:INFO:              gradio: Not installed
2025-11-27 21:35:33,279:INFO:             fastapi: Not installed
2025-11-27 21:35:33,279:INFO:             uvicorn: Not installed
2025-11-27 21:35:33,279:INFO:              m2cgen: Not installed
2025-11-27 21:35:33,279:INFO:           evidently: Not installed
2025-11-27 21:35:33,279:INFO:               fugue: Not installed
2025-11-27 21:35:33,281:INFO:           streamlit: 1.51.0
2025-11-27 21:35:33,281:INFO:             prophet: Not installed
2025-11-27 21:35:33,281:INFO:None
2025-11-27 21:35:33,281:INFO:Set up data.
2025-11-27 21:35:33,317:INFO:Set up folding strategy.
2025-11-27 21:35:33,317:INFO:Set up train/test split.
2025-11-27 21:35:33,344:INFO:Set up index.
2025-11-27 21:35:33,344:INFO:Assigning column types.
2025-11-27 21:35:33,365:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-11-27 21:35:33,390:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-11-27 21:35:33,395:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-11-27 21:35:33,414:INFO:Soft dependency imported: xgboost: 3.1.2
2025-11-27 21:35:33,418:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-27 21:35:33,445:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-11-27 21:35:33,445:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-11-27 21:35:33,459:INFO:Soft dependency imported: xgboost: 3.1.2
2025-11-27 21:35:33,459:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-27 21:35:33,459:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-11-27 21:35:33,488:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-11-27 21:35:33,504:INFO:Soft dependency imported: xgboost: 3.1.2
2025-11-27 21:35:33,506:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-27 21:35:33,531:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-11-27 21:35:33,545:INFO:Soft dependency imported: xgboost: 3.1.2
2025-11-27 21:35:33,547:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-27 21:35:33,547:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-11-27 21:35:33,580:INFO:Soft dependency imported: xgboost: 3.1.2
2025-11-27 21:35:33,588:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-27 21:35:33,628:INFO:Soft dependency imported: xgboost: 3.1.2
2025-11-27 21:35:33,628:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-27 21:35:33,628:INFO:Preparing preprocessing pipeline...
2025-11-27 21:35:33,637:INFO:Set up simple imputation.
2025-11-27 21:35:33,645:INFO:Set up encoding of ordinal features.
2025-11-27 21:35:33,651:INFO:Set up encoding of categorical features.
2025-11-27 21:35:33,747:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'SAFETIME' 'CTELNUM1' 'CELLFON5' 'CADULT1'
 'CELLSEX1' 'PVTRESD3' 'CCLGHOUS' 'CSTATE1' 'LANDLINE' 'HHADULT'
 'LASTDEN4' 'RMVTETH4' 'BLDSTFIT' 'SDNATES1' 'PDIABTS1' 'PREDIAB2'
 'DIABTYPE' 'INSULIN1' 'CHKHEMO3' 'EYEEXAM1' 'DIABEYE1' 'DIABEDU1'
 'FEETSORE' 'TOLDCFS' 'HAVECFS' 'WORKCFS' 'IMFVPLA3' 'HPVADVC4' 'HPVADSHT'
 'SHINGLE2' 'COVIDVA1' 'COVACGET' 'COVIDNU1' 'COVIDINT' 'COVIDFS1'
 'COVIDSE1' 'COPDCOGH' 'COPDFLEM' 'COPDBRTH' 'COPDBTST' 'COPDSMOK'
 'CNCRDIFF' 'CNCRAGE' 'CNCRTYP2' 'CSRVTRT3' 'CSRVDOC1' 'CSRVSUM'
 'CSRVRTRN' 'CSRVINST' 'CSRVINSR' 'CSRVDEIN' 'CSRVCLIN' 'CSRVPAIN'
 'CSRVCTL2' 'PSATEST1' 'PSATIME1' 'PCPSARS2' 'PSASUGST' 'PCSTALK1'
 'CIMEMLOS' 'CDHOUSE' 'CDASSIST' 'CDHELP' 'CDSOCIAL' 'CDDISCUS' 'CAREGIV1'
 'CRGVREL4' 'CRGVLNG1' 'CRGVHRS1' 'CRGVPRB3' 'CRGVALZD' 'CRGVPER1'
 'CRGVHOU1' 'CRGVEXPT' 'ACEDEPRS' 'ACEDRINK' 'ACEDRUGS' 'ACEPRISN'
 'ACEDIVRC' 'ACEPUNCH' 'ACEHURT1' 'ACESWEAR' 'ACETOUCH' 'ACETTHEM'
 'ACEHVSEX' 'ACEADSAF' 'ACEADNED' 'MARIJAN1' 'MARJSMOK' 'MARJEAT'
 'MARJVAPE' 'MARJDAB' 'MARJOTHR' 'USEMRJN4' 'LASTSMK2' 'STOPSMK2'
 'MENTCIGS' 'MENTECIG' 'HEATTBCO' 'ASBIALCH' 'ASBIDRNK' 'ASBIBING'
 'ASBIADVC' 'ASBIRDUC' 'FIREARM5' 'GUNLOAD' 'LOADULK2' 'RCSXBRTH'
 'CASTHNO2' 'BIRTHSEX' 'SOMALE' 'SOFEMALE' 'TRNSGNDR' 'HADSEX' 'PFPPRVN4'
 'TYPCNTR9' 'BRTHCNT4' 'WHEREGET' 'NOBCUSE8' 'BCPREFER' 'RRCLASS3'
 'RRCOGNT2' 'RRTREAT' 'RRATWRK2' 'RRHCARE4' 'RRPHYSM2' 'CAGEG']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-27 21:35:33,806:INFO:Finished creating preprocessing pipeline.
2025-11-27 21:35:33,817:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\OMAR\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['STATE', 'FMONTH', 'DISPCODE',
                                             'PSU', 'CTELENM1', 'PVTRESD1',
                                             'COLGHOUS', 'STATERE1', 'CELPHON1',
                                             'LADULT1', 'COLGSEX1', 'NUMADULT',
                                             'LANDSEX1', 'NUMMEN', 'NUMWOMEN',
                                             'RESPSLCT', 'SAFETIME', 'CTELNUM1',
                                             'CELLFON5', 'CADULT1...
                                                                         'data_type': dtype('O'),
                                                                         'mapping': 02     0
03     1
NaN   -1
dtype: int64}],
                                                               return_df=True,
                                                               verbose=0))),
                ('onehot_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['IDATE', 'IDAY', 'IYEAR'],
                                    transformer=OneHotEncoder(cols=['IDATE',
                                                                    'IDAY',
                                                                    'IYEAR'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False)
2025-11-27 21:35:33,817:INFO:Creating final display dataframe.
2025-11-27 21:35:34,009:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'SAFETIME' 'CTELNUM1' 'CELLFON5' 'CADULT1'
 'CELLSEX1' 'PVTRESD3' 'CCLGHOUS' 'CSTATE1' 'LANDLINE' 'HHADULT'
 'LASTDEN4' 'RMVTETH4' 'BLDSTFIT' 'SDNATES1' 'PDIABTS1' 'PREDIAB2'
 'DIABTYPE' 'INSULIN1' 'CHKHEMO3' 'EYEEXAM1' 'DIABEYE1' 'DIABEDU1'
 'FEETSORE' 'TOLDCFS' 'HAVECFS' 'WORKCFS' 'IMFVPLA3' 'HPVADVC4' 'HPVADSHT'
 'SHINGLE2' 'COVIDVA1' 'COVACGET' 'COVIDNU1' 'COVIDINT' 'COVIDFS1'
 'COVIDSE1' 'COPDCOGH' 'COPDFLEM' 'COPDBRTH' 'COPDBTST' 'COPDSMOK'
 'CNCRDIFF' 'CNCRAGE' 'CNCRTYP2' 'CSRVTRT3' 'CSRVDOC1' 'CSRVSUM'
 'CSRVRTRN' 'CSRVINST' 'CSRVINSR' 'CSRVDEIN' 'CSRVCLIN' 'CSRVPAIN'
 'CSRVCTL2' 'PSATEST1' 'PSATIME1' 'PCPSARS2' 'PSASUGST' 'PCSTALK1'
 'CIMEMLOS' 'CDHOUSE' 'CDASSIST' 'CDHELP' 'CDSOCIAL' 'CDDISCUS' 'CAREGIV1'
 'CRGVREL4' 'CRGVLNG1' 'CRGVHRS1' 'CRGVPRB3' 'CRGVALZD' 'CRGVPER1'
 'CRGVHOU1' 'CRGVEXPT' 'ACEDEPRS' 'ACEDRINK' 'ACEDRUGS' 'ACEPRISN'
 'ACEDIVRC' 'ACEPUNCH' 'ACEHURT1' 'ACESWEAR' 'ACETOUCH' 'ACETTHEM'
 'ACEHVSEX' 'ACEADSAF' 'ACEADNED' 'MARIJAN1' 'MARJSMOK' 'MARJEAT'
 'MARJVAPE' 'MARJDAB' 'MARJOTHR' 'USEMRJN4' 'LASTSMK2' 'STOPSMK2'
 'MENTCIGS' 'MENTECIG' 'HEATTBCO' 'ASBIALCH' 'ASBIDRNK' 'ASBIBING'
 'ASBIADVC' 'ASBIRDUC' 'FIREARM5' 'GUNLOAD' 'LOADULK2' 'RCSXBRTH'
 'CASTHNO2' 'BIRTHSEX' 'SOMALE' 'SOFEMALE' 'TRNSGNDR' 'HADSEX' 'PFPPRVN4'
 'TYPCNTR9' 'BRTHCNT4' 'WHEREGET' 'NOBCUSE8' 'BCPREFER' 'RRCLASS3'
 'RRCOGNT2' 'RRTREAT' 'RRATWRK2' 'RRHCARE4' 'RRPHYSM2' 'CAGEG']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-27 21:35:34,131:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'SAFETIME' 'CTELNUM1' 'CELLFON5' 'CADULT1'
 'CELLSEX1' 'PVTRESD3' 'CCLGHOUS' 'CSTATE1' 'LANDLINE' 'HHADULT'
 'LASTDEN4' 'RMVTETH4' 'BLDSTFIT' 'SDNATES1' 'PDIABTS1' 'PREDIAB2'
 'DIABTYPE' 'INSULIN1' 'CHKHEMO3' 'EYEEXAM1' 'DIABEYE1' 'DIABEDU1'
 'FEETSORE' 'TOLDCFS' 'HAVECFS' 'WORKCFS' 'IMFVPLA3' 'HPVADVC4' 'HPVADSHT'
 'SHINGLE2' 'COVIDVA1' 'COVACGET' 'COVIDNU1' 'COVIDINT' 'COVIDFS1'
 'COVIDSE1' 'COPDCOGH' 'COPDFLEM' 'COPDBRTH' 'COPDBTST' 'COPDSMOK'
 'CNCRDIFF' 'CNCRAGE' 'CNCRTYP2' 'CSRVTRT3' 'CSRVDOC1' 'CSRVSUM'
 'CSRVRTRN' 'CSRVINST' 'CSRVINSR' 'CSRVDEIN' 'CSRVCLIN' 'CSRVPAIN'
 'CSRVCTL2' 'PSATEST1' 'PSATIME1' 'PCPSARS2' 'PSASUGST' 'PCSTALK1'
 'CIMEMLOS' 'CDHOUSE' 'CDASSIST' 'CDHELP' 'CDSOCIAL' 'CDDISCUS' 'CAREGIV1'
 'CRGVREL4' 'CRGVLNG1' 'CRGVHRS1' 'CRGVPRB3' 'CRGVALZD' 'CRGVPER1'
 'CRGVHOU1' 'CRGVEXPT' 'ACEDEPRS' 'ACEDRINK' 'ACEDRUGS' 'ACEPRISN'
 'ACEDIVRC' 'ACEPUNCH' 'ACEHURT1' 'ACESWEAR' 'ACETOUCH' 'ACETTHEM'
 'ACEHVSEX' 'ACEADSAF' 'ACEADNED' 'MARIJAN1' 'MARJSMOK' 'MARJEAT'
 'MARJVAPE' 'MARJDAB' 'MARJOTHR' 'USEMRJN4' 'LASTSMK2' 'STOPSMK2'
 'MENTCIGS' 'MENTECIG' 'HEATTBCO' 'ASBIALCH' 'ASBIDRNK' 'ASBIBING'
 'ASBIADVC' 'ASBIRDUC' 'FIREARM5' 'GUNLOAD' 'LOADULK2' 'RCSXBRTH'
 'CASTHNO2' 'BIRTHSEX' 'SOMALE' 'SOFEMALE' 'TRNSGNDR' 'HADSEX' 'PFPPRVN4'
 'TYPCNTR9' 'BRTHCNT4' 'WHEREGET' 'NOBCUSE8' 'BCPREFER' 'RRCLASS3'
 'RRCOGNT2' 'RRTREAT' 'RRATWRK2' 'RRHCARE4' 'RRPHYSM2' 'CAGEG']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-27 21:35:34,254:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'SAFETIME' 'CTELNUM1' 'CELLFON5' 'CADULT1'
 'CELLSEX1' 'PVTRESD3' 'CCLGHOUS' 'CSTATE1' 'LANDLINE' 'HHADULT'
 'LASTDEN4' 'RMVTETH4' 'BLDSTFIT' 'SDNATES1' 'PDIABTS1' 'PREDIAB2'
 'DIABTYPE' 'INSULIN1' 'CHKHEMO3' 'EYEEXAM1' 'DIABEYE1' 'DIABEDU1'
 'FEETSORE' 'TOLDCFS' 'HAVECFS' 'WORKCFS' 'IMFVPLA3' 'HPVADVC4' 'HPVADSHT'
 'SHINGLE2' 'COVIDVA1' 'COVACGET' 'COVIDNU1' 'COVIDINT' 'COVIDFS1'
 'COVIDSE1' 'COPDCOGH' 'COPDFLEM' 'COPDBRTH' 'COPDBTST' 'COPDSMOK'
 'CNCRDIFF' 'CNCRAGE' 'CNCRTYP2' 'CSRVTRT3' 'CSRVDOC1' 'CSRVSUM'
 'CSRVRTRN' 'CSRVINST' 'CSRVINSR' 'CSRVDEIN' 'CSRVCLIN' 'CSRVPAIN'
 'CSRVCTL2' 'PSATEST1' 'PSATIME1' 'PCPSARS2' 'PSASUGST' 'PCSTALK1'
 'CIMEMLOS' 'CDHOUSE' 'CDASSIST' 'CDHELP' 'CDSOCIAL' 'CDDISCUS' 'CAREGIV1'
 'CRGVREL4' 'CRGVLNG1' 'CRGVHRS1' 'CRGVPRB3' 'CRGVALZD' 'CRGVPER1'
 'CRGVHOU1' 'CRGVEXPT' 'ACEDEPRS' 'ACEDRINK' 'ACEDRUGS' 'ACEPRISN'
 'ACEDIVRC' 'ACEPUNCH' 'ACEHURT1' 'ACESWEAR' 'ACETOUCH' 'ACETTHEM'
 'ACEHVSEX' 'ACEADSAF' 'ACEADNED' 'MARIJAN1' 'MARJSMOK' 'MARJEAT'
 'MARJVAPE' 'MARJDAB' 'MARJOTHR' 'USEMRJN4' 'LASTSMK2' 'STOPSMK2'
 'MENTCIGS' 'MENTECIG' 'HEATTBCO' 'ASBIALCH' 'ASBIDRNK' 'ASBIBING'
 'ASBIADVC' 'ASBIRDUC' 'FIREARM5' 'GUNLOAD' 'LOADULK2' 'RCSXBRTH'
 'CASTHNO2' 'BIRTHSEX' 'SOMALE' 'SOFEMALE' 'TRNSGNDR' 'HADSEX' 'PFPPRVN4'
 'TYPCNTR9' 'BRTHCNT4' 'WHEREGET' 'NOBCUSE8' 'BCPREFER' 'RRCLASS3'
 'RRCOGNT2' 'RRTREAT' 'RRATWRK2' 'RRHCARE4' 'RRPHYSM2' 'CAGEG']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-27 21:35:34,381:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'SAFETIME' 'CTELNUM1' 'CELLFON5' 'CADULT1'
 'CELLSEX1' 'PVTRESD3' 'CCLGHOUS' 'CSTATE1' 'LANDLINE' 'HHADULT'
 'LASTDEN4' 'RMVTETH4' 'BLDSTFIT' 'SDNATES1' 'PDIABTS1' 'PREDIAB2'
 'DIABTYPE' 'INSULIN1' 'CHKHEMO3' 'EYEEXAM1' 'DIABEYE1' 'DIABEDU1'
 'FEETSORE' 'TOLDCFS' 'HAVECFS' 'WORKCFS' 'IMFVPLA3' 'HPVADVC4' 'HPVADSHT'
 'SHINGLE2' 'COVIDVA1' 'COVACGET' 'COVIDNU1' 'COVIDINT' 'COVIDFS1'
 'COVIDSE1' 'COPDCOGH' 'COPDFLEM' 'COPDBRTH' 'COPDBTST' 'COPDSMOK'
 'CNCRDIFF' 'CNCRAGE' 'CNCRTYP2' 'CSRVTRT3' 'CSRVDOC1' 'CSRVSUM'
 'CSRVRTRN' 'CSRVINST' 'CSRVINSR' 'CSRVDEIN' 'CSRVCLIN' 'CSRVPAIN'
 'CSRVCTL2' 'PSATEST1' 'PSATIME1' 'PCPSARS2' 'PSASUGST' 'PCSTALK1'
 'CIMEMLOS' 'CDHOUSE' 'CDASSIST' 'CDHELP' 'CDSOCIAL' 'CDDISCUS' 'CAREGIV1'
 'CRGVREL4' 'CRGVLNG1' 'CRGVHRS1' 'CRGVPRB3' 'CRGVALZD' 'CRGVPER1'
 'CRGVHOU1' 'CRGVEXPT' 'ACEDEPRS' 'ACEDRINK' 'ACEDRUGS' 'ACEPRISN'
 'ACEDIVRC' 'ACEPUNCH' 'ACEHURT1' 'ACESWEAR' 'ACETOUCH' 'ACETTHEM'
 'ACEHVSEX' 'ACEADSAF' 'ACEADNED' 'MARIJAN1' 'MARJSMOK' 'MARJEAT'
 'MARJVAPE' 'MARJDAB' 'MARJOTHR' 'USEMRJN4' 'LASTSMK2' 'STOPSMK2'
 'MENTCIGS' 'MENTECIG' 'HEATTBCO' 'ASBIALCH' 'ASBIDRNK' 'ASBIBING'
 'ASBIADVC' 'ASBIRDUC' 'FIREARM5' 'GUNLOAD' 'LOADULK2' 'RCSXBRTH'
 'CASTHNO2' 'BIRTHSEX' 'SOMALE' 'SOFEMALE' 'TRNSGNDR' 'HADSEX' 'PFPPRVN4'
 'TYPCNTR9' 'BRTHCNT4' 'WHEREGET' 'NOBCUSE8' 'BCPREFER' 'RRCLASS3'
 'RRCOGNT2' 'RRTREAT' 'RRATWRK2' 'RRHCARE4' 'RRPHYSM2' 'CAGEG']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-27 21:35:34,432:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target          CVDINFR4
2                   Target type            Binary
3           Original data shape         (50, 327)
4        Transformed data shape         (50, 226)
5   Transformed train set shape         (35, 226)
6    Transformed test set shape         (15, 226)
7              Numeric features               322
8          Categorical features                 4
9      Rows with missing values            100.0%
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16               Fold Generator   StratifiedKFold
17                  Fold Number                10
18                     CPU Jobs                -1
19                      Use GPU             False
20               Log Experiment             False
21              Experiment Name  clf-default-name
22                          USI              b0f4
2025-11-27 21:35:34,475:INFO:Soft dependency imported: xgboost: 3.1.2
2025-11-27 21:35:34,475:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-27 21:35:34,516:INFO:Soft dependency imported: xgboost: 3.1.2
2025-11-27 21:35:34,517:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-27 21:35:34,518:INFO:setup() successfully completed in 1.31s...............
2025-11-27 21:35:34,518:INFO:Initializing compare_models()
2025-11-27 21:35:34,518:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024612C71C30>, include=['lr', 'dt'], fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000024612C71C30>, 'include': ['lr', 'dt'], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2025-11-27 21:35:34,518:INFO:Checking exceptions
2025-11-27 21:35:34,534:INFO:Preparing display monitor
2025-11-27 21:35:34,534:INFO:Initializing Logistic Regression
2025-11-27 21:35:34,534:INFO:Total runtime is 0.0 minutes
2025-11-27 21:35:34,534:INFO:SubProcess create_model() called ==================================
2025-11-27 21:35:34,534:INFO:Initializing create_model()
2025-11-27 21:35:34,534:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024612C71C30>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024612C71090>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-27 21:35:34,534:INFO:Checking exceptions
2025-11-27 21:35:34,534:INFO:Importing libraries
2025-11-27 21:35:34,534:INFO:Copying training dataset
2025-11-27 21:35:34,558:INFO:Defining folds
2025-11-27 21:35:34,558:INFO:Declaring metric variables
2025-11-27 21:35:34,558:INFO:Importing untrained model
2025-11-27 21:35:34,558:INFO:Logistic Regression Imported successfully
2025-11-27 21:35:34,558:INFO:Starting cross validation
2025-11-27 21:35:34,560:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-27 21:35:34,569:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\model_selection\_split.py:737: UserWarning: The least populated class in y has only 6 members, which is less than n_splits=10.
  warnings.warn(

2025-11-27 21:35:38,294:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-27 21:35:38,309:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-27 21:35:38,309:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-27 21:35:38,316:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-27 21:35:38,316:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-27 21:35:38,318:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-27 21:35:38,318:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-27 21:35:38,321:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-27 21:35:38,321:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-27 21:35:38,321:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-27 21:35:38,542:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'SAFETIME' 'CTELNUM1' 'CELLFON5' 'CADULT1'
 'CELLSEX1' 'PVTRESD3' 'CCLGHOUS' 'CSTATE1' 'LANDLINE' 'HHADULT'
 'LASTDEN4' 'RMVTETH4' 'LASTSIG4' 'BLDSTFIT' 'SDNATES1' 'PDIABTS1'
 'PREDIAB2' 'DIABTYPE' 'INSULIN1' 'CHKHEMO3' 'EYEEXAM1' 'DIABEYE1'
 'DIABEDU1' 'FEETSORE' 'TOLDCFS' 'HAVECFS' 'WORKCFS' 'IMFVPLA3' 'HPVADVC4'
 'HPVADSHT' 'SHINGLE2' 'COVIDVA1' 'COVACGET' 'COVIDNU1' 'COVIDINT'
 'COVIDFS1' 'COVIDSE1' 'COPDCOGH' 'COPDFLEM' 'COPDBRTH' 'COPDBTST'
 'COPDSMOK' 'CNCRDIFF' 'CNCRAGE' 'CNCRTYP2' 'CSRVTRT3' 'CSRVDOC1'
 'CSRVSUM' 'CSRVRTRN' 'CSRVINST' 'CSRVINSR' 'CSRVDEIN' 'CSRVCLIN'
 'CSRVPAIN' 'CSRVCTL2' 'PSATEST1' 'PSATIME1' 'PCPSARS2' 'PSASUGST'
 'PCSTALK1' 'CIMEMLOS' 'CDHOUSE' 'CDASSIST' 'CDHELP' 'CDSOCIAL' 'CDDISCUS'
 'CAREGIV1' 'CRGVREL4' 'CRGVLNG1' 'CRGVHRS1' 'CRGVPRB3' 'CRGVALZD'
 'CRGVPER1' 'CRGVHOU1' 'CRGVEXPT' 'ACEDEPRS' 'ACEDRINK' 'ACEDRUGS'
 'ACEPRISN' 'ACEDIVRC' 'ACEPUNCH' 'ACEHURT1' 'ACESWEAR' 'ACETOUCH'
 'ACETTHEM' 'ACEHVSEX' 'ACEADSAF' 'ACEADNED' 'MARIJAN1' 'MARJSMOK'
 'MARJEAT' 'MARJVAPE' 'MARJDAB' 'MARJOTHR' 'USEMRJN4' 'LASTSMK2'
 'STOPSMK2' 'MENTCIGS' 'MENTECIG' 'HEATTBCO' 'ASBIALCH' 'ASBIDRNK'
 'ASBIBING' 'ASBIADVC' 'ASBIRDUC' 'FIREARM5' 'GUNLOAD' 'LOADULK2'
 'RCSXBRTH' 'CASTHNO2' 'BIRTHSEX' 'SOMALE' 'SOFEMALE' 'TRNSGNDR' 'HADSEX'
 'PFPPRVN4' 'TYPCNTR9' 'BRTHCNT4' 'WHEREGET' 'NOBCUSE8' 'BCPREFER'
 'RRCLASS3' 'RRCOGNT2' 'RRTREAT' 'RRATWRK2' 'RRHCARE4' 'RRPHYSM2' 'CAGEG']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-27 21:35:38,544:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'SAFETIME' 'CTELNUM1' 'CELLFON5' 'CADULT1'
 'CELLSEX1' 'PVTRESD3' 'CCLGHOUS' 'CSTATE1' 'LANDLINE' 'HHADULT'
 'LASTDEN4' 'RMVTETH4' 'BLDSTFIT' 'SDNATES1' 'PDIABTS1' 'PREDIAB2'
 'DIABTYPE' 'INSULIN1' 'CHKHEMO3' 'EYEEXAM1' 'DIABEYE1' 'DIABEDU1'
 'FEETSORE' 'TOLDCFS' 'HAVECFS' 'WORKCFS' 'IMFVPLA3' 'HPVADVC4' 'HPVADSHT'
 'SHINGLE2' 'COVIDVA1' 'COVACGET' 'COVIDNU1' 'COVIDINT' 'COVIDFS1'
 'COVIDSE1' 'COPDCOGH' 'COPDFLEM' 'COPDBRTH' 'COPDBTST' 'COPDSMOK'
 'CNCRDIFF' 'CNCRAGE' 'CNCRTYP2' 'CSRVTRT3' 'CSRVDOC1' 'CSRVSUM'
 'CSRVRTRN' 'CSRVINST' 'CSRVINSR' 'CSRVDEIN' 'CSRVCLIN' 'CSRVPAIN'
 'CSRVCTL2' 'PSATEST1' 'PSATIME1' 'PCPSARS2' 'PSASUGST' 'PCSTALK1'
 'CIMEMLOS' 'CDHOUSE' 'CDASSIST' 'CDHELP' 'CDSOCIAL' 'CDDISCUS' 'CAREGIV1'
 'CRGVREL4' 'CRGVLNG1' 'CRGVHRS1' 'CRGVPRB3' 'CRGVALZD' 'CRGVPER1'
 'CRGVHOU1' 'CRGVEXPT' 'ACEDEPRS' 'ACEDRINK' 'ACEDRUGS' 'ACEPRISN'
 'ACEDIVRC' 'ACEPUNCH' 'ACEHURT1' 'ACESWEAR' 'ACETOUCH' 'ACETTHEM'
 'ACEHVSEX' 'ACEADSAF' 'ACEADNED' 'MARIJAN1' 'MARJSMOK' 'MARJEAT'
 'MARJVAPE' 'MARJDAB' 'MARJOTHR' 'USEMRJN4' 'LASTSMK2' 'STOPSMK2'
 'MENTCIGS' 'MENTECIG' 'HEATTBCO' 'ASBIALCH' 'ASBIDRNK' 'ASBIBING'
 'ASBIADVC' 'ASBIRDUC' 'FIREARM5' 'GUNLOAD' 'LOADULK2' 'RCSXBRTH'
 'CASTHNO2' 'BIRTHSEX' 'SOMALE' 'SOFEMALE' 'TRNSGNDR' 'HADSEX' 'PFPPRVN4'
 'TYPCNTR9' 'BRTHCNT4' 'WHEREGET' 'NOBCUSE8' 'BCPREFER' 'RRCLASS3'
 'RRCOGNT2' 'RRTREAT' 'RRATWRK2' 'RRHCARE4' 'RRPHYSM2' 'CAGEG']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-27 21:35:38,547:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'SAFETIME' 'CTELNUM1' 'CELLFON5' 'CADULT1'
 'CELLSEX1' 'PVTRESD3' 'CCLGHOUS' 'CSTATE1' 'LANDLINE' 'HHADULT'
 'LASTDEN4' 'RMVTETH4' 'BLDSTFIT' 'SDNATES1' 'PDIABTS1' 'PREDIAB2'
 'DIABTYPE' 'INSULIN1' 'CHKHEMO3' 'EYEEXAM1' 'DIABEYE1' 'DIABEDU1'
 'FEETSORE' 'TOLDCFS' 'HAVECFS' 'WORKCFS' 'IMFVPLA3' 'HPVADVC4' 'HPVADSHT'
 'SHINGLE2' 'COVIDVA1' 'COVACGET' 'COVIDNU1' 'COVIDINT' 'COVIDFS1'
 'COVIDSE1' 'COPDCOGH' 'COPDFLEM' 'COPDBRTH' 'COPDBTST' 'COPDSMOK'
 'CNCRDIFF' 'CNCRAGE' 'CNCRTYP2' 'CSRVTRT3' 'CSRVDOC1' 'CSRVSUM'
 'CSRVRTRN' 'CSRVINST' 'CSRVINSR' 'CSRVDEIN' 'CSRVCLIN' 'CSRVPAIN'
 'CSRVCTL2' 'PSATEST1' 'PSATIME1' 'PCPSARS2' 'PSASUGST' 'PCSTALK1'
 'CIMEMLOS' 'CDHOUSE' 'CDASSIST' 'CDHELP' 'CDSOCIAL' 'CDDISCUS' 'CAREGIV1'
 'CRGVREL4' 'CRGVLNG1' 'CRGVHRS1' 'CRGVPRB3' 'CRGVALZD' 'CRGVPER1'
 'CRGVHOU1' 'CRGVEXPT' 'ACEDEPRS' 'ACEDRINK' 'ACEDRUGS' 'ACEPRISN'
 'ACEDIVRC' 'ACEPUNCH' 'ACEHURT1' 'ACESWEAR' 'ACETOUCH' 'ACETTHEM'
 'ACEHVSEX' 'ACEADSAF' 'ACEADNED' 'MARIJAN1' 'MARJSMOK' 'MARJEAT'
 'MARJVAPE' 'MARJDAB' 'MARJOTHR' 'USEMRJN4' 'LASTSMK2' 'STOPSMK2'
 'MENTCIGS' 'MENTECIG' 'HEATTBCO' 'ASBIALCH' 'ASBIDRNK' 'ASBIBING'
 'ASBIADVC' 'ASBIRDUC' 'FIREARM5' 'GUNLOAD' 'LOADULK2' 'RCSXBRTH'
 'CASTHNO2' 'BIRTHSEX' 'SOMALE' 'SOFEMALE' 'TRNSGNDR' 'HADSEX' 'PFPPRVN4'
 'TYPCNTR9' 'BRTHCNT4' 'WHEREGET' 'NOBCUSE8' 'BCPREFER' 'RRCLASS3'
 'RRCOGNT2' 'RRTREAT' 'RRATWRK2' 'RRHCARE4' 'RRPHYSM2' 'CAGEG']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-27 21:35:38,547:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'SAFETIME' 'CTELNUM1' 'CELLFON5' 'CADULT1'
 'CELLSEX1' 'PVTRESD3' 'CCLGHOUS' 'CSTATE1' 'LANDLINE' 'HHADULT'
 'LASTDEN4' 'RMVTETH4' 'BLDSTFIT' 'SDNATES1' 'PDIABTS1' 'PREDIAB2'
 'DIABTYPE' 'INSULIN1' 'CHKHEMO3' 'EYEEXAM1' 'DIABEYE1' 'DIABEDU1'
 'FEETSORE' 'TOLDCFS' 'HAVECFS' 'WORKCFS' 'IMFVPLA3' 'HPVADVC4' 'HPVADSHT'
 'SHINGLE2' 'COVIDVA1' 'COVACGET' 'COVIDNU1' 'COVIDINT' 'COVIDFS1'
 'COVIDSE1' 'COPDCOGH' 'COPDFLEM' 'COPDBRTH' 'COPDBTST' 'COPDSMOK'
 'CNCRDIFF' 'CNCRAGE' 'CNCRTYP2' 'CSRVTRT3' 'CSRVDOC1' 'CSRVSUM'
 'CSRVRTRN' 'CSRVINST' 'CSRVINSR' 'CSRVDEIN' 'CSRVCLIN' 'CSRVPAIN'
 'CSRVCTL2' 'PSATEST1' 'PSATIME1' 'PCPSARS2' 'PSASUGST' 'PCSTALK1'
 'CIMEMLOS' 'CDHOUSE' 'CDASSIST' 'CDHELP' 'CDSOCIAL' 'CDDISCUS' 'CAREGIV1'
 'CRGVREL4' 'CRGVLNG1' 'CRGVHRS1' 'CRGVPRB3' 'CRGVALZD' 'CRGVPER1'
 'CRGVHOU1' 'CRGVEXPT' 'ACEDEPRS' 'ACEDRINK' 'ACEDRUGS' 'ACEPRISN'
 'ACEDIVRC' 'ACEPUNCH' 'ACEHURT1' 'ACESWEAR' 'ACETOUCH' 'ACETTHEM'
 'ACEHVSEX' 'ACEADSAF' 'ACEADNED' 'MARIJAN1' 'MARJSMOK' 'MARJEAT'
 'MARJVAPE' 'MARJDAB' 'MARJOTHR' 'USEMRJN4' 'LASTSMK2' 'STOPSMK2'
 'MENTCIGS' 'MENTECIG' 'HEATTBCO' 'ASBIALCH' 'ASBIDRNK' 'ASBIBING'
 'ASBIADVC' 'ASBIRDUC' 'FIREARM5' 'GUNLOAD' 'LOADULK2' 'RCSXBRTH'
 'CASTHNO2' 'BIRTHSEX' 'SOMALE' 'SOFEMALE' 'TRNSGNDR' 'HADSEX' 'PFPPRVN4'
 'TYPCNTR9' 'BRTHCNT4' 'WHEREGET' 'NOBCUSE8' 'BCPREFER' 'RRCLASS3'
 'RRCOGNT2' 'RRTREAT' 'RRATWRK2' 'RRHCARE4' 'RRPHYSM2' 'CAGEG']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-27 21:35:38,552:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'SAFETIME' 'CTELNUM1' 'CELLFON5' 'CADULT1'
 'CELLSEX1' 'PVTRESD3' 'CCLGHOUS' 'CSTATE1' 'LANDLINE' 'HHADULT'
 'LASTDEN4' 'RMVTETH4' 'BLDSTFIT' 'SDNATES1' 'PDIABTS1' 'PREDIAB2'
 'DIABTYPE' 'INSULIN1' 'CHKHEMO3' 'EYEEXAM1' 'DIABEYE1' 'DIABEDU1'
 'FEETSORE' 'TOLDCFS' 'HAVECFS' 'WORKCFS' 'IMFVPLA3' 'HPVADVC4' 'HPVADSHT'
 'SHINGLE2' 'COVIDVA1' 'COVACGET' 'COVIDNU1' 'COVIDINT' 'COVIDFS1'
 'COVIDSE1' 'COPDCOGH' 'COPDFLEM' 'COPDBRTH' 'COPDBTST' 'COPDSMOK'
 'CNCRDIFF' 'CNCRAGE' 'CNCRTYP2' 'CSRVTRT3' 'CSRVDOC1' 'CSRVSUM'
 'CSRVRTRN' 'CSRVINST' 'CSRVINSR' 'CSRVDEIN' 'CSRVCLIN' 'CSRVPAIN'
 'CSRVCTL2' 'PSATEST1' 'PSATIME1' 'PCPSARS2' 'PSASUGST' 'PCSTALK1'
 'CIMEMLOS' 'CDHOUSE' 'CDASSIST' 'CDHELP' 'CDSOCIAL' 'CDDISCUS' 'CAREGIV1'
 'CRGVREL4' 'CRGVLNG1' 'CRGVHRS1' 'CRGVPRB3' 'CRGVALZD' 'CRGVPER1'
 'CRGVHOU1' 'CRGVEXPT' 'ACEDEPRS' 'ACEDRINK' 'ACEDRUGS' 'ACEPRISN'
 'ACEDIVRC' 'ACEPUNCH' 'ACEHURT1' 'ACESWEAR' 'ACETOUCH' 'ACETTHEM'
 'ACEHVSEX' 'ACEADSAF' 'ACEADNED' 'MARIJAN1' 'MARJSMOK' 'MARJEAT'
 'MARJVAPE' 'MARJDAB' 'MARJOTHR' 'USEMRJN4' 'LASTSMK2' 'STOPSMK2'
 'MENTCIGS' 'MENTECIG' 'HEATTBCO' 'ASBIALCH' 'ASBIDRNK' 'ASBIBING'
 'ASBIADVC' 'ASBIRDUC' 'FIREARM5' 'GUNLOAD' 'LOADULK2' 'RCSXBRTH'
 'CASTHNO2' 'BIRTHSEX' 'SOMALE' 'SOFEMALE' 'TRNSGNDR' 'HADSEX' 'PFPPRVN4'
 'TYPCNTR9' 'BRTHCNT4' 'WHEREGET' 'NOBCUSE8' 'BCPREFER' 'RRCLASS3'
 'RRCOGNT2' 'RRTREAT' 'RRATWRK2' 'RRHCARE4' 'RRPHYSM2' 'CAGEG']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-27 21:35:38,554:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'SAFETIME' 'CTELNUM1' 'CELLFON5' 'CADULT1'
 'CELLSEX1' 'PVTRESD3' 'CCLGHOUS' 'CSTATE1' 'LANDLINE' 'HHADULT'
 'LASTDEN4' 'RMVTETH4' 'BLDSTFIT' 'SDNATES1' 'COVIDPRM' 'PDIABTS1'
 'PREDIAB2' 'DIABTYPE' 'INSULIN1' 'CHKHEMO3' 'EYEEXAM1' 'DIABEYE1'
 'DIABEDU1' 'FEETSORE' 'TOLDCFS' 'HAVECFS' 'WORKCFS' 'IMFVPLA3' 'HPVADVC4'
 'HPVADSHT' 'SHINGLE2' 'COVIDVA1' 'COVACGET' 'COVIDNU1' 'COVIDINT'
 'COVIDFS1' 'COVIDSE1' 'COPDCOGH' 'COPDFLEM' 'COPDBRTH' 'COPDBTST'
 'COPDSMOK' 'CNCRDIFF' 'CNCRAGE' 'CNCRTYP2' 'CSRVTRT3' 'CSRVDOC1'
 'CSRVSUM' 'CSRVRTRN' 'CSRVINST' 'CSRVINSR' 'CSRVDEIN' 'CSRVCLIN'
 'CSRVPAIN' 'CSRVCTL2' 'PSATEST1' 'PSATIME1' 'PCPSARS2' 'PSASUGST'
 'PCSTALK1' 'CIMEMLOS' 'CDHOUSE' 'CDASSIST' 'CDHELP' 'CDSOCIAL' 'CDDISCUS'
 'CAREGIV1' 'CRGVREL4' 'CRGVLNG1' 'CRGVHRS1' 'CRGVPRB3' 'CRGVALZD'
 'CRGVPER1' 'CRGVHOU1' 'CRGVEXPT' 'ACEDEPRS' 'ACEDRINK' 'ACEDRUGS'
 'ACEPRISN' 'ACEDIVRC' 'ACEPUNCH' 'ACEHURT1' 'ACESWEAR' 'ACETOUCH'
 'ACETTHEM' 'ACEHVSEX' 'ACEADSAF' 'ACEADNED' 'MARIJAN1' 'MARJSMOK'
 'MARJEAT' 'MARJVAPE' 'MARJDAB' 'MARJOTHR' 'USEMRJN4' 'LASTSMK2'
 'STOPSMK2' 'MENTCIGS' 'MENTECIG' 'HEATTBCO' 'ASBIALCH' 'ASBIDRNK'
 'ASBIBING' 'ASBIADVC' 'ASBIRDUC' 'FIREARM5' 'GUNLOAD' 'LOADULK2'
 'RCSXBRTH' 'CASTHNO2' 'BIRTHSEX' 'SOMALE' 'SOFEMALE' 'TRNSGNDR' 'HADSEX'
 'PFPPRVN4' 'TYPCNTR9' 'BRTHCNT4' 'WHEREGET' 'NOBCUSE8' 'BCPREFER'
 'RRCLASS3' 'RRCOGNT2' 'RRTREAT' 'RRATWRK2' 'RRHCARE4' 'RRPHYSM2' 'CAGEG']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-27 21:35:38,558:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'SAFETIME' 'CTELNUM1' 'CELLFON5' 'CADULT1'
 'CELLSEX1' 'PVTRESD3' 'CCLGHOUS' 'CSTATE1' 'LANDLINE' 'HHADULT'
 'LASTDEN4' 'RMVTETH4' 'BLDSTFIT' 'SDNATES1' 'PDIABTS1' 'PREDIAB2'
 'DIABTYPE' 'INSULIN1' 'CHKHEMO3' 'EYEEXAM1' 'DIABEYE1' 'DIABEDU1'
 'FEETSORE' 'TOLDCFS' 'HAVECFS' 'WORKCFS' 'IMFVPLA3' 'HPVADVC4' 'HPVADSHT'
 'SHINGLE2' 'COVIDVA1' 'COVACGET' 'COVIDNU1' 'COVIDINT' 'COVIDFS1'
 'COVIDSE1' 'COPDCOGH' 'COPDFLEM' 'COPDBRTH' 'COPDBTST' 'COPDSMOK'
 'CNCRDIFF' 'CNCRAGE' 'CNCRTYP2' 'CSRVTRT3' 'CSRVDOC1' 'CSRVSUM'
 'CSRVRTRN' 'CSRVINST' 'CSRVINSR' 'CSRVDEIN' 'CSRVCLIN' 'CSRVPAIN'
 'CSRVCTL2' 'PSATEST1' 'PSATIME1' 'PCPSARS2' 'PSASUGST' 'PCSTALK1'
 'CIMEMLOS' 'CDHOUSE' 'CDASSIST' 'CDHELP' 'CDSOCIAL' 'CDDISCUS' 'CAREGIV1'
 'CRGVREL4' 'CRGVLNG1' 'CRGVHRS1' 'CRGVPRB3' 'CRGVALZD' 'CRGVPER1'
 'CRGVHOU1' 'CRGVEXPT' 'ACEDEPRS' 'ACEDRINK' 'ACEDRUGS' 'ACEPRISN'
 'ACEDIVRC' 'ACEPUNCH' 'ACEHURT1' 'ACESWEAR' 'ACETOUCH' 'ACETTHEM'
 'ACEHVSEX' 'ACEADSAF' 'ACEADNED' 'MARIJAN1' 'MARJSMOK' 'MARJEAT'
 'MARJVAPE' 'MARJDAB' 'MARJOTHR' 'USEMRJN4' 'LASTSMK2' 'STOPSMK2'
 'MENTCIGS' 'MENTECIG' 'HEATTBCO' 'ASBIALCH' 'ASBIDRNK' 'ASBIBING'
 'ASBIADVC' 'ASBIRDUC' 'FIREARM5' 'GUNLOAD' 'LOADULK2' 'RCSGEND1'
 'RCSXBRTH' 'RCSRLTN2' 'CASTHDX2' 'CASTHNO2' 'BIRTHSEX' 'SOMALE'
 'SOFEMALE' 'TRNSGNDR' 'HADSEX' 'PFPPRVN4' 'TYPCNTR9' 'BRTHCNT4'
 'WHEREGET' 'NOBCUSE8' 'BCPREFER' 'RRCLASS3' 'RRCOGNT2' 'RRTREAT'
 'RRATWRK2' 'RRHCARE4' 'RRPHYSM2' 'CRACE2' 'CPRACE2' 'CAGEG' 'CLLCPWT']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-27 21:35:38,560:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'SAFETIME' 'CTELNUM1' 'CELLFON5' 'CADULT1'
 'CELLSEX1' 'PVTRESD3' 'CCLGHOUS' 'CSTATE1' 'LANDLINE' 'HHADULT'
 'LASTDEN4' 'RMVTETH4' 'VCLNTES2' 'BLDSTFIT' 'SDNATES1' 'PDIABTS1'
 'PREDIAB2' 'DIABTYPE' 'INSULIN1' 'CHKHEMO3' 'EYEEXAM1' 'DIABEYE1'
 'DIABEDU1' 'FEETSORE' 'TOLDCFS' 'HAVECFS' 'WORKCFS' 'IMFVPLA3' 'HPVADVC4'
 'HPVADSHT' 'SHINGLE2' 'COVIDVA1' 'COVACGET' 'COVIDNU1' 'COVIDINT'
 'COVIDFS1' 'COVIDSE1' 'COPDCOGH' 'COPDFLEM' 'COPDBRTH' 'COPDBTST'
 'COPDSMOK' 'CNCRDIFF' 'CNCRAGE' 'CNCRTYP2' 'CSRVTRT3' 'CSRVDOC1'
 'CSRVSUM' 'CSRVRTRN' 'CSRVINST' 'CSRVINSR' 'CSRVDEIN' 'CSRVCLIN'
 'CSRVPAIN' 'CSRVCTL2' 'PSATEST1' 'PSATIME1' 'PCPSARS2' 'PSASUGST'
 'PCSTALK1' 'CIMEMLOS' 'CDHOUSE' 'CDASSIST' 'CDHELP' 'CDSOCIAL' 'CDDISCUS'
 'CAREGIV1' 'CRGVREL4' 'CRGVLNG1' 'CRGVHRS1' 'CRGVPRB3' 'CRGVALZD'
 'CRGVPER1' 'CRGVHOU1' 'CRGVEXPT' 'ACEDEPRS' 'ACEDRINK' 'ACEDRUGS'
 'ACEPRISN' 'ACEDIVRC' 'ACEPUNCH' 'ACEHURT1' 'ACESWEAR' 'ACETOUCH'
 'ACETTHEM' 'ACEHVSEX' 'ACEADSAF' 'ACEADNED' 'MARIJAN1' 'MARJSMOK'
 'MARJEAT' 'MARJVAPE' 'MARJDAB' 'MARJOTHR' 'USEMRJN4' 'LASTSMK2'
 'STOPSMK2' 'MENTCIGS' 'MENTECIG' 'HEATTBCO' 'ASBIALCH' 'ASBIDRNK'
 'ASBIBING' 'ASBIADVC' 'ASBIRDUC' 'FIREARM5' 'GUNLOAD' 'LOADULK2'
 'RCSXBRTH' 'CASTHNO2' 'BIRTHSEX' 'SOMALE' 'SOFEMALE' 'TRNSGNDR' 'HADSEX'
 'PFPPRVN4' 'TYPCNTR9' 'BRTHCNT4' 'WHEREGET' 'NOBCUSE8' 'BCPREFER'
 'RRCLASS3' 'RRCOGNT2' 'RRTREAT' 'RRATWRK2' 'RRHCARE4' 'RRPHYSM2' 'CAGEG']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-27 21:35:38,567:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'SAFETIME' 'CTELNUM1' 'CELLFON5' 'CADULT1'
 'CELLSEX1' 'PVTRESD3' 'CCLGHOUS' 'CSTATE1' 'LANDLINE' 'HHADULT'
 'LASTDEN4' 'RMVTETH4' 'BLDSTFIT' 'SDNATES1' 'PDIABTS1' 'PREDIAB2'
 'DIABTYPE' 'INSULIN1' 'CHKHEMO3' 'EYEEXAM1' 'DIABEYE1' 'DIABEDU1'
 'FEETSORE' 'TOLDCFS' 'HAVECFS' 'WORKCFS' 'IMFVPLA3' 'HPVADVC4' 'HPVADSHT'
 'SHINGLE2' 'COVIDVA1' 'COVACGET' 'COVIDNU1' 'COVIDINT' 'COVIDFS1'
 'COVIDSE1' 'COPDCOGH' 'COPDFLEM' 'COPDBRTH' 'COPDBTST' 'COPDSMOK'
 'CNCRDIFF' 'CNCRAGE' 'CNCRTYP2' 'CSRVTRT3' 'CSRVDOC1' 'CSRVSUM'
 'CSRVRTRN' 'CSRVINST' 'CSRVINSR' 'CSRVDEIN' 'CSRVCLIN' 'CSRVPAIN'
 'CSRVCTL2' 'PSATEST1' 'PSATIME1' 'PCPSARS2' 'PSASUGST' 'PCSTALK1'
 'CIMEMLOS' 'CDHOUSE' 'CDASSIST' 'CDHELP' 'CDSOCIAL' 'CDDISCUS' 'CAREGIV1'
 'CRGVREL4' 'CRGVLNG1' 'CRGVHRS1' 'CRGVPRB3' 'CRGVALZD' 'CRGVPER1'
 'CRGVHOU1' 'CRGVEXPT' 'ACEDEPRS' 'ACEDRINK' 'ACEDRUGS' 'ACEPRISN'
 'ACEDIVRC' 'ACEPUNCH' 'ACEHURT1' 'ACESWEAR' 'ACETOUCH' 'ACETTHEM'
 'ACEHVSEX' 'ACEADSAF' 'ACEADNED' 'MARIJAN1' 'MARJSMOK' 'MARJEAT'
 'MARJVAPE' 'MARJDAB' 'MARJOTHR' 'USEMRJN4' 'LASTSMK2' 'STOPSMK2'
 'MENTCIGS' 'MENTECIG' 'HEATTBCO' 'ASBIALCH' 'ASBIDRNK' 'ASBIBING'
 'ASBIADVC' 'ASBIRDUC' 'FIREARM5' 'GUNLOAD' 'LOADULK2' 'RCSXBRTH'
 'CASTHNO2' 'BIRTHSEX' 'SOMALE' 'SOFEMALE' 'TRNSGNDR' 'HADSEX' 'PFPPRVN4'
 'TYPCNTR9' 'BRTHCNT4' 'WHEREGET' 'NOBCUSE8' 'BCPREFER' 'RRCLASS3'
 'RRCOGNT2' 'RRTREAT' 'RRATWRK2' 'RRHCARE4' 'RRPHYSM2' 'CAGEG']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-27 21:35:38,569:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'SAFETIME' 'CTELNUM1' 'CELLFON5' 'CADULT1'
 'CELLSEX1' 'PVTRESD3' 'CCLGHOUS' 'CSTATE1' 'LANDLINE' 'HHADULT'
 'LASTDEN4' 'RMVTETH4' 'NUMPHON4' 'BLDSTFIT' 'SDNATES1' 'PDIABTS1'
 'PREDIAB2' 'DIABTYPE' 'INSULIN1' 'CHKHEMO3' 'EYEEXAM1' 'DIABEYE1'
 'DIABEDU1' 'FEETSORE' 'TOLDCFS' 'HAVECFS' 'WORKCFS' 'IMFVPLA3' 'HPVADVC4'
 'HPVADSHT' 'SHINGLE2' 'COVIDVA1' 'COVACGET' 'COVIDNU1' 'COVIDINT'
 'COVIDFS1' 'COVIDSE1' 'COPDCOGH' 'COPDFLEM' 'COPDBRTH' 'COPDBTST'
 'COPDSMOK' 'CNCRDIFF' 'CNCRAGE' 'CNCRTYP2' 'CSRVTRT3' 'CSRVDOC1'
 'CSRVSUM' 'CSRVRTRN' 'CSRVINST' 'CSRVINSR' 'CSRVDEIN' 'CSRVCLIN'
 'CSRVPAIN' 'CSRVCTL2' 'PSATEST1' 'PSATIME1' 'PCPSARS2' 'PSASUGST'
 'PCSTALK1' 'CIMEMLOS' 'CDHOUSE' 'CDASSIST' 'CDHELP' 'CDSOCIAL' 'CDDISCUS'
 'CAREGIV1' 'CRGVREL4' 'CRGVLNG1' 'CRGVHRS1' 'CRGVPRB3' 'CRGVALZD'
 'CRGVPER1' 'CRGVHOU1' 'CRGVEXPT' 'ACEDEPRS' 'ACEDRINK' 'ACEDRUGS'
 'ACEPRISN' 'ACEDIVRC' 'ACEPUNCH' 'ACEHURT1' 'ACESWEAR' 'ACETOUCH'
 'ACETTHEM' 'ACEHVSEX' 'ACEADSAF' 'ACEADNED' 'MARIJAN1' 'MARJSMOK'
 'MARJEAT' 'MARJVAPE' 'MARJDAB' 'MARJOTHR' 'USEMRJN4' 'LASTSMK2'
 'STOPSMK2' 'MENTCIGS' 'MENTECIG' 'HEATTBCO' 'ASBIALCH' 'ASBIDRNK'
 'ASBIBING' 'ASBIADVC' 'ASBIRDUC' 'FIREARM5' 'GUNLOAD' 'LOADULK2'
 'RCSXBRTH' 'CASTHNO2' 'BIRTHSEX' 'SOMALE' 'SOFEMALE' 'TRNSGNDR' 'HADSEX'
 'PFPPRVN4' 'TYPCNTR9' 'BRTHCNT4' 'WHEREGET' 'NOBCUSE8' 'BCPREFER'
 'RRCLASS3' 'RRCOGNT2' 'RRTREAT' 'RRATWRK2' 'RRHCARE4' 'RRPHYSM2' 'CAGEG']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-27 21:35:38,654:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'SAFETIME' 'CTELNUM1' 'CELLFON5' 'CADULT1'
 'CELLSEX1' 'PVTRESD3' 'CCLGHOUS' 'CSTATE1' 'LANDLINE' 'HHADULT'
 'LASTDEN4' 'RMVTETH4' 'BLDSTFIT' 'SDNATES1' 'PDIABTS1' 'PREDIAB2'
 'DIABTYPE' 'INSULIN1' 'CHKHEMO3' 'EYEEXAM1' 'DIABEYE1' 'DIABEDU1'
 'FEETSORE' 'TOLDCFS' 'HAVECFS' 'WORKCFS' 'IMFVPLA3' 'HPVADVC4' 'HPVADSHT'
 'SHINGLE2' 'COVIDVA1' 'COVACGET' 'COVIDNU1' 'COVIDINT' 'COVIDFS1'
 'COVIDSE1' 'COPDCOGH' 'COPDFLEM' 'COPDBRTH' 'COPDBTST' 'COPDSMOK'
 'CNCRDIFF' 'CNCRAGE' 'CNCRTYP2' 'CSRVTRT3' 'CSRVDOC1' 'CSRVSUM'
 'CSRVRTRN' 'CSRVINST' 'CSRVINSR' 'CSRVDEIN' 'CSRVCLIN' 'CSRVPAIN'
 'CSRVCTL2' 'PSATEST1' 'PSATIME1' 'PCPSARS2' 'PSASUGST' 'PCSTALK1'
 'CIMEMLOS' 'CDHOUSE' 'CDASSIST' 'CDHELP' 'CDSOCIAL' 'CDDISCUS' 'CAREGIV1'
 'CRGVREL4' 'CRGVLNG1' 'CRGVHRS1' 'CRGVPRB3' 'CRGVALZD' 'CRGVPER1'
 'CRGVHOU1' 'CRGVEXPT' 'ACEDEPRS' 'ACEDRINK' 'ACEDRUGS' 'ACEPRISN'
 'ACEDIVRC' 'ACEPUNCH' 'ACEHURT1' 'ACESWEAR' 'ACETOUCH' 'ACETTHEM'
 'ACEHVSEX' 'ACEADSAF' 'ACEADNED' 'MARIJAN1' 'MARJSMOK' 'MARJEAT'
 'MARJVAPE' 'MARJDAB' 'MARJOTHR' 'USEMRJN4' 'LASTSMK2' 'STOPSMK2'
 'MENTCIGS' 'MENTECIG' 'HEATTBCO' 'ASBIALCH' 'ASBIDRNK' 'ASBIBING'
 'ASBIADVC' 'ASBIRDUC' 'FIREARM5' 'GUNLOAD' 'LOADULK2' 'RCSXBRTH'
 'CASTHNO2' 'BIRTHSEX' 'SOMALE' 'SOFEMALE' 'TRNSGNDR' 'HADSEX' 'PFPPRVN4'
 'TYPCNTR9' 'BRTHCNT4' 'WHEREGET' 'NOBCUSE8' 'BCPREFER' 'RRCLASS3'
 'RRCOGNT2' 'RRTREAT' 'RRATWRK2' 'RRHCARE4' 'RRPHYSM2' 'CAGEG']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-27 21:35:38,660:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'SAFETIME' 'CTELNUM1' 'CELLFON5' 'CADULT1'
 'CELLSEX1' 'PVTRESD3' 'CCLGHOUS' 'CSTATE1' 'LANDLINE' 'HHADULT'
 'LASTDEN4' 'RMVTETH4' 'BLDSTFIT' 'SDNATES1' 'PDIABTS1' 'PREDIAB2'
 'DIABTYPE' 'INSULIN1' 'CHKHEMO3' 'EYEEXAM1' 'DIABEYE1' 'DIABEDU1'
 'FEETSORE' 'TOLDCFS' 'HAVECFS' 'WORKCFS' 'IMFVPLA3' 'HPVADVC4' 'HPVADSHT'
 'SHINGLE2' 'COVIDVA1' 'COVACGET' 'COVIDNU1' 'COVIDINT' 'COVIDFS1'
 'COVIDSE1' 'COPDCOGH' 'COPDFLEM' 'COPDBRTH' 'COPDBTST' 'COPDSMOK'
 'CNCRDIFF' 'CNCRAGE' 'CNCRTYP2' 'CSRVTRT3' 'CSRVDOC1' 'CSRVSUM'
 'CSRVRTRN' 'CSRVINST' 'CSRVINSR' 'CSRVDEIN' 'CSRVCLIN' 'CSRVPAIN'
 'CSRVCTL2' 'PSATEST1' 'PSATIME1' 'PCPSARS2' 'PSASUGST' 'PCSTALK1'
 'CIMEMLOS' 'CDHOUSE' 'CDASSIST' 'CDHELP' 'CDSOCIAL' 'CDDISCUS' 'CAREGIV1'
 'CRGVREL4' 'CRGVLNG1' 'CRGVHRS1' 'CRGVPRB3' 'CRGVALZD' 'CRGVPER1'
 'CRGVHOU1' 'CRGVEXPT' 'ACEDEPRS' 'ACEDRINK' 'ACEDRUGS' 'ACEPRISN'
 'ACEDIVRC' 'ACEPUNCH' 'ACEHURT1' 'ACESWEAR' 'ACETOUCH' 'ACETTHEM'
 'ACEHVSEX' 'ACEADSAF' 'ACEADNED' 'MARIJAN1' 'MARJSMOK' 'MARJEAT'
 'MARJVAPE' 'MARJDAB' 'MARJOTHR' 'USEMRJN4' 'LASTSMK2' 'STOPSMK2'
 'MENTCIGS' 'MENTECIG' 'HEATTBCO' 'ASBIALCH' 'ASBIDRNK' 'ASBIBING'
 'ASBIADVC' 'ASBIRDUC' 'FIREARM5' 'GUNLOAD' 'LOADULK2' 'RCSGEND1'
 'RCSXBRTH' 'RCSRLTN2' 'CASTHDX2' 'CASTHNO2' 'BIRTHSEX' 'SOMALE'
 'SOFEMALE' 'TRNSGNDR' 'HADSEX' 'PFPPRVN4' 'TYPCNTR9' 'BRTHCNT4'
 'WHEREGET' 'NOBCUSE8' 'BCPREFER' 'RRCLASS3' 'RRCOGNT2' 'RRTREAT'
 'RRATWRK2' 'RRHCARE4' 'RRPHYSM2' 'CRACE2' 'CPRACE2' 'CAGEG' 'CLLCPWT']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-27 21:35:38,672:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'SAFETIME' 'CTELNUM1' 'CELLFON5' 'CADULT1'
 'CELLSEX1' 'PVTRESD3' 'CCLGHOUS' 'CSTATE1' 'LANDLINE' 'HHADULT'
 'LASTDEN4' 'RMVTETH4' 'BLDSTFIT' 'SDNATES1' 'PDIABTS1' 'PREDIAB2'
 'DIABTYPE' 'INSULIN1' 'CHKHEMO3' 'EYEEXAM1' 'DIABEYE1' 'DIABEDU1'
 'FEETSORE' 'TOLDCFS' 'HAVECFS' 'WORKCFS' 'IMFVPLA3' 'HPVADVC4' 'HPVADSHT'
 'SHINGLE2' 'COVIDVA1' 'COVACGET' 'COVIDNU1' 'COVIDINT' 'COVIDFS1'
 'COVIDSE1' 'COPDCOGH' 'COPDFLEM' 'COPDBRTH' 'COPDBTST' 'COPDSMOK'
 'CNCRDIFF' 'CNCRAGE' 'CNCRTYP2' 'CSRVTRT3' 'CSRVDOC1' 'CSRVSUM'
 'CSRVRTRN' 'CSRVINST' 'CSRVINSR' 'CSRVDEIN' 'CSRVCLIN' 'CSRVPAIN'
 'CSRVCTL2' 'PSATEST1' 'PSATIME1' 'PCPSARS2' 'PSASUGST' 'PCSTALK1'
 'CIMEMLOS' 'CDHOUSE' 'CDASSIST' 'CDHELP' 'CDSOCIAL' 'CDDISCUS' 'CAREGIV1'
 'CRGVREL4' 'CRGVLNG1' 'CRGVHRS1' 'CRGVPRB3' 'CRGVALZD' 'CRGVPER1'
 'CRGVHOU1' 'CRGVEXPT' 'ACEDEPRS' 'ACEDRINK' 'ACEDRUGS' 'ACEPRISN'
 'ACEDIVRC' 'ACEPUNCH' 'ACEHURT1' 'ACESWEAR' 'ACETOUCH' 'ACETTHEM'
 'ACEHVSEX' 'ACEADSAF' 'ACEADNED' 'MARIJAN1' 'MARJSMOK' 'MARJEAT'
 'MARJVAPE' 'MARJDAB' 'MARJOTHR' 'USEMRJN4' 'LASTSMK2' 'STOPSMK2'
 'MENTCIGS' 'MENTECIG' 'HEATTBCO' 'ASBIALCH' 'ASBIDRNK' 'ASBIBING'
 'ASBIADVC' 'ASBIRDUC' 'FIREARM5' 'GUNLOAD' 'LOADULK2' 'RCSXBRTH'
 'CASTHNO2' 'BIRTHSEX' 'SOMALE' 'SOFEMALE' 'TRNSGNDR' 'HADSEX' 'PFPPRVN4'
 'TYPCNTR9' 'BRTHCNT4' 'WHEREGET' 'NOBCUSE8' 'BCPREFER' 'RRCLASS3'
 'RRCOGNT2' 'RRTREAT' 'RRATWRK2' 'RRHCARE4' 'RRPHYSM2' 'CAGEG']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-27 21:35:38,672:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'SAFETIME' 'CTELNUM1' 'CELLFON5' 'CADULT1'
 'CELLSEX1' 'PVTRESD3' 'CCLGHOUS' 'CSTATE1' 'LANDLINE' 'HHADULT'
 'LASTDEN4' 'RMVTETH4' 'BLDSTFIT' 'SDNATES1' 'PDIABTS1' 'PREDIAB2'
 'DIABTYPE' 'INSULIN1' 'CHKHEMO3' 'EYEEXAM1' 'DIABEYE1' 'DIABEDU1'
 'FEETSORE' 'TOLDCFS' 'HAVECFS' 'WORKCFS' 'IMFVPLA3' 'HPVADVC4' 'HPVADSHT'
 'SHINGLE2' 'COVIDVA1' 'COVACGET' 'COVIDNU1' 'COVIDINT' 'COVIDFS1'
 'COVIDSE1' 'COPDCOGH' 'COPDFLEM' 'COPDBRTH' 'COPDBTST' 'COPDSMOK'
 'CNCRDIFF' 'CNCRAGE' 'CNCRTYP2' 'CSRVTRT3' 'CSRVDOC1' 'CSRVSUM'
 'CSRVRTRN' 'CSRVINST' 'CSRVINSR' 'CSRVDEIN' 'CSRVCLIN' 'CSRVPAIN'
 'CSRVCTL2' 'PSATEST1' 'PSATIME1' 'PCPSARS2' 'PSASUGST' 'PCSTALK1'
 'CIMEMLOS' 'CDHOUSE' 'CDASSIST' 'CDHELP' 'CDSOCIAL' 'CDDISCUS' 'CAREGIV1'
 'CRGVREL4' 'CRGVLNG1' 'CRGVHRS1' 'CRGVPRB3' 'CRGVALZD' 'CRGVPER1'
 'CRGVHOU1' 'CRGVEXPT' 'ACEDEPRS' 'ACEDRINK' 'ACEDRUGS' 'ACEPRISN'
 'ACEDIVRC' 'ACEPUNCH' 'ACEHURT1' 'ACESWEAR' 'ACETOUCH' 'ACETTHEM'
 'ACEHVSEX' 'ACEADSAF' 'ACEADNED' 'MARIJAN1' 'MARJSMOK' 'MARJEAT'
 'MARJVAPE' 'MARJDAB' 'MARJOTHR' 'USEMRJN4' 'LASTSMK2' 'STOPSMK2'
 'MENTCIGS' 'MENTECIG' 'HEATTBCO' 'ASBIALCH' 'ASBIDRNK' 'ASBIBING'
 'ASBIADVC' 'ASBIRDUC' 'FIREARM5' 'GUNLOAD' 'LOADULK2' 'RCSXBRTH'
 'CASTHNO2' 'BIRTHSEX' 'SOMALE' 'SOFEMALE' 'TRNSGNDR' 'HADSEX' 'PFPPRVN4'
 'TYPCNTR9' 'BRTHCNT4' 'WHEREGET' 'NOBCUSE8' 'BCPREFER' 'RRCLASS3'
 'RRCOGNT2' 'RRTREAT' 'RRATWRK2' 'RRHCARE4' 'RRPHYSM2' 'CAGEG']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-27 21:35:38,686:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'SAFETIME' 'CTELNUM1' 'CELLFON5' 'CADULT1'
 'CELLSEX1' 'PVTRESD3' 'CCLGHOUS' 'CSTATE1' 'LANDLINE' 'HHADULT'
 'LASTDEN4' 'RMVTETH4' 'NUMPHON4' 'BLDSTFIT' 'SDNATES1' 'PDIABTS1'
 'PREDIAB2' 'DIABTYPE' 'INSULIN1' 'CHKHEMO3' 'EYEEXAM1' 'DIABEYE1'
 'DIABEDU1' 'FEETSORE' 'TOLDCFS' 'HAVECFS' 'WORKCFS' 'IMFVPLA3' 'HPVADVC4'
 'HPVADSHT' 'SHINGLE2' 'COVIDVA1' 'COVACGET' 'COVIDNU1' 'COVIDINT'
 'COVIDFS1' 'COVIDSE1' 'COPDCOGH' 'COPDFLEM' 'COPDBRTH' 'COPDBTST'
 'COPDSMOK' 'CNCRDIFF' 'CNCRAGE' 'CNCRTYP2' 'CSRVTRT3' 'CSRVDOC1'
 'CSRVSUM' 'CSRVRTRN' 'CSRVINST' 'CSRVINSR' 'CSRVDEIN' 'CSRVCLIN'
 'CSRVPAIN' 'CSRVCTL2' 'PSATEST1' 'PSATIME1' 'PCPSARS2' 'PSASUGST'
 'PCSTALK1' 'CIMEMLOS' 'CDHOUSE' 'CDASSIST' 'CDHELP' 'CDSOCIAL' 'CDDISCUS'
 'CAREGIV1' 'CRGVREL4' 'CRGVLNG1' 'CRGVHRS1' 'CRGVPRB3' 'CRGVALZD'
 'CRGVPER1' 'CRGVHOU1' 'CRGVEXPT' 'ACEDEPRS' 'ACEDRINK' 'ACEDRUGS'
 'ACEPRISN' 'ACEDIVRC' 'ACEPUNCH' 'ACEHURT1' 'ACESWEAR' 'ACETOUCH'
 'ACETTHEM' 'ACEHVSEX' 'ACEADSAF' 'ACEADNED' 'MARIJAN1' 'MARJSMOK'
 'MARJEAT' 'MARJVAPE' 'MARJDAB' 'MARJOTHR' 'USEMRJN4' 'LASTSMK2'
 'STOPSMK2' 'MENTCIGS' 'MENTECIG' 'HEATTBCO' 'ASBIALCH' 'ASBIDRNK'
 'ASBIBING' 'ASBIADVC' 'ASBIRDUC' 'FIREARM5' 'GUNLOAD' 'LOADULK2'
 'RCSXBRTH' 'CASTHNO2' 'BIRTHSEX' 'SOMALE' 'SOFEMALE' 'TRNSGNDR' 'HADSEX'
 'PFPPRVN4' 'TYPCNTR9' 'BRTHCNT4' 'WHEREGET' 'NOBCUSE8' 'BCPREFER'
 'RRCLASS3' 'RRCOGNT2' 'RRTREAT' 'RRATWRK2' 'RRHCARE4' 'RRPHYSM2' 'CAGEG']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-27 21:35:38,686:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'SAFETIME' 'CTELNUM1' 'CELLFON5' 'CADULT1'
 'CELLSEX1' 'PVTRESD3' 'CCLGHOUS' 'CSTATE1' 'LANDLINE' 'HHADULT'
 'LASTDEN4' 'RMVTETH4' 'LASTSIG4' 'BLDSTFIT' 'SDNATES1' 'PDIABTS1'
 'PREDIAB2' 'DIABTYPE' 'INSULIN1' 'CHKHEMO3' 'EYEEXAM1' 'DIABEYE1'
 'DIABEDU1' 'FEETSORE' 'TOLDCFS' 'HAVECFS' 'WORKCFS' 'IMFVPLA3' 'HPVADVC4'
 'HPVADSHT' 'SHINGLE2' 'COVIDVA1' 'COVACGET' 'COVIDNU1' 'COVIDINT'
 'COVIDFS1' 'COVIDSE1' 'COPDCOGH' 'COPDFLEM' 'COPDBRTH' 'COPDBTST'
 'COPDSMOK' 'CNCRDIFF' 'CNCRAGE' 'CNCRTYP2' 'CSRVTRT3' 'CSRVDOC1'
 'CSRVSUM' 'CSRVRTRN' 'CSRVINST' 'CSRVINSR' 'CSRVDEIN' 'CSRVCLIN'
 'CSRVPAIN' 'CSRVCTL2' 'PSATEST1' 'PSATIME1' 'PCPSARS2' 'PSASUGST'
 'PCSTALK1' 'CIMEMLOS' 'CDHOUSE' 'CDASSIST' 'CDHELP' 'CDSOCIAL' 'CDDISCUS'
 'CAREGIV1' 'CRGVREL4' 'CRGVLNG1' 'CRGVHRS1' 'CRGVPRB3' 'CRGVALZD'
 'CRGVPER1' 'CRGVHOU1' 'CRGVEXPT' 'ACEDEPRS' 'ACEDRINK' 'ACEDRUGS'
 'ACEPRISN' 'ACEDIVRC' 'ACEPUNCH' 'ACEHURT1' 'ACESWEAR' 'ACETOUCH'
 'ACETTHEM' 'ACEHVSEX' 'ACEADSAF' 'ACEADNED' 'MARIJAN1' 'MARJSMOK'
 'MARJEAT' 'MARJVAPE' 'MARJDAB' 'MARJOTHR' 'USEMRJN4' 'LASTSMK2'
 'STOPSMK2' 'MENTCIGS' 'MENTECIG' 'HEATTBCO' 'ASBIALCH' 'ASBIDRNK'
 'ASBIBING' 'ASBIADVC' 'ASBIRDUC' 'FIREARM5' 'GUNLOAD' 'LOADULK2'
 'RCSXBRTH' 'CASTHNO2' 'BIRTHSEX' 'SOMALE' 'SOFEMALE' 'TRNSGNDR' 'HADSEX'
 'PFPPRVN4' 'TYPCNTR9' 'BRTHCNT4' 'WHEREGET' 'NOBCUSE8' 'BCPREFER'
 'RRCLASS3' 'RRCOGNT2' 'RRTREAT' 'RRATWRK2' 'RRHCARE4' 'RRPHYSM2' 'CAGEG']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-27 21:35:38,686:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-27 21:35:38,694:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'SAFETIME' 'CTELNUM1' 'CELLFON5' 'CADULT1'
 'CELLSEX1' 'PVTRESD3' 'CCLGHOUS' 'CSTATE1' 'LANDLINE' 'HHADULT'
 'LASTDEN4' 'RMVTETH4' 'BLDSTFIT' 'SDNATES1' 'COVIDPRM' 'PDIABTS1'
 'PREDIAB2' 'DIABTYPE' 'INSULIN1' 'CHKHEMO3' 'EYEEXAM1' 'DIABEYE1'
 'DIABEDU1' 'FEETSORE' 'TOLDCFS' 'HAVECFS' 'WORKCFS' 'IMFVPLA3' 'HPVADVC4'
 'HPVADSHT' 'SHINGLE2' 'COVIDVA1' 'COVACGET' 'COVIDNU1' 'COVIDINT'
 'COVIDFS1' 'COVIDSE1' 'COPDCOGH' 'COPDFLEM' 'COPDBRTH' 'COPDBTST'
 'COPDSMOK' 'CNCRDIFF' 'CNCRAGE' 'CNCRTYP2' 'CSRVTRT3' 'CSRVDOC1'
 'CSRVSUM' 'CSRVRTRN' 'CSRVINST' 'CSRVINSR' 'CSRVDEIN' 'CSRVCLIN'
 'CSRVPAIN' 'CSRVCTL2' 'PSATEST1' 'PSATIME1' 'PCPSARS2' 'PSASUGST'
 'PCSTALK1' 'CIMEMLOS' 'CDHOUSE' 'CDASSIST' 'CDHELP' 'CDSOCIAL' 'CDDISCUS'
 'CAREGIV1' 'CRGVREL4' 'CRGVLNG1' 'CRGVHRS1' 'CRGVPRB3' 'CRGVALZD'
 'CRGVPER1' 'CRGVHOU1' 'CRGVEXPT' 'ACEDEPRS' 'ACEDRINK' 'ACEDRUGS'
 'ACEPRISN' 'ACEDIVRC' 'ACEPUNCH' 'ACEHURT1' 'ACESWEAR' 'ACETOUCH'
 'ACETTHEM' 'ACEHVSEX' 'ACEADSAF' 'ACEADNED' 'MARIJAN1' 'MARJSMOK'
 'MARJEAT' 'MARJVAPE' 'MARJDAB' 'MARJOTHR' 'USEMRJN4' 'LASTSMK2'
 'STOPSMK2' 'MENTCIGS' 'MENTECIG' 'HEATTBCO' 'ASBIALCH' 'ASBIDRNK'
 'ASBIBING' 'ASBIADVC' 'ASBIRDUC' 'FIREARM5' 'GUNLOAD' 'LOADULK2'
 'RCSXBRTH' 'CASTHNO2' 'BIRTHSEX' 'SOMALE' 'SOFEMALE' 'TRNSGNDR' 'HADSEX'
 'PFPPRVN4' 'TYPCNTR9' 'BRTHCNT4' 'WHEREGET' 'NOBCUSE8' 'BCPREFER'
 'RRCLASS3' 'RRCOGNT2' 'RRTREAT' 'RRATWRK2' 'RRHCARE4' 'RRPHYSM2' 'CAGEG']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-27 21:35:38,699:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-27 21:35:38,703:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'SAFETIME' 'CTELNUM1' 'CELLFON5' 'CADULT1'
 'CELLSEX1' 'PVTRESD3' 'CCLGHOUS' 'CSTATE1' 'LANDLINE' 'HHADULT'
 'LASTDEN4' 'RMVTETH4' 'VCLNTES2' 'BLDSTFIT' 'SDNATES1' 'PDIABTS1'
 'PREDIAB2' 'DIABTYPE' 'INSULIN1' 'CHKHEMO3' 'EYEEXAM1' 'DIABEYE1'
 'DIABEDU1' 'FEETSORE' 'TOLDCFS' 'HAVECFS' 'WORKCFS' 'IMFVPLA3' 'HPVADVC4'
 'HPVADSHT' 'SHINGLE2' 'COVIDVA1' 'COVACGET' 'COVIDNU1' 'COVIDINT'
 'COVIDFS1' 'COVIDSE1' 'COPDCOGH' 'COPDFLEM' 'COPDBRTH' 'COPDBTST'
 'COPDSMOK' 'CNCRDIFF' 'CNCRAGE' 'CNCRTYP2' 'CSRVTRT3' 'CSRVDOC1'
 'CSRVSUM' 'CSRVRTRN' 'CSRVINST' 'CSRVINSR' 'CSRVDEIN' 'CSRVCLIN'
 'CSRVPAIN' 'CSRVCTL2' 'PSATEST1' 'PSATIME1' 'PCPSARS2' 'PSASUGST'
 'PCSTALK1' 'CIMEMLOS' 'CDHOUSE' 'CDASSIST' 'CDHELP' 'CDSOCIAL' 'CDDISCUS'
 'CAREGIV1' 'CRGVREL4' 'CRGVLNG1' 'CRGVHRS1' 'CRGVPRB3' 'CRGVALZD'
 'CRGVPER1' 'CRGVHOU1' 'CRGVEXPT' 'ACEDEPRS' 'ACEDRINK' 'ACEDRUGS'
 'ACEPRISN' 'ACEDIVRC' 'ACEPUNCH' 'ACEHURT1' 'ACESWEAR' 'ACETOUCH'
 'ACETTHEM' 'ACEHVSEX' 'ACEADSAF' 'ACEADNED' 'MARIJAN1' 'MARJSMOK'
 'MARJEAT' 'MARJVAPE' 'MARJDAB' 'MARJOTHR' 'USEMRJN4' 'LASTSMK2'
 'STOPSMK2' 'MENTCIGS' 'MENTECIG' 'HEATTBCO' 'ASBIALCH' 'ASBIDRNK'
 'ASBIBING' 'ASBIADVC' 'ASBIRDUC' 'FIREARM5' 'GUNLOAD' 'LOADULK2'
 'RCSXBRTH' 'CASTHNO2' 'BIRTHSEX' 'SOMALE' 'SOFEMALE' 'TRNSGNDR' 'HADSEX'
 'PFPPRVN4' 'TYPCNTR9' 'BRTHCNT4' 'WHEREGET' 'NOBCUSE8' 'BCPREFER'
 'RRCLASS3' 'RRCOGNT2' 'RRTREAT' 'RRATWRK2' 'RRHCARE4' 'RRPHYSM2' 'CAGEG']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-27 21:35:38,706:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'SAFETIME' 'CTELNUM1' 'CELLFON5' 'CADULT1'
 'CELLSEX1' 'PVTRESD3' 'CCLGHOUS' 'CSTATE1' 'LANDLINE' 'HHADULT'
 'LASTDEN4' 'RMVTETH4' 'BLDSTFIT' 'SDNATES1' 'PDIABTS1' 'PREDIAB2'
 'DIABTYPE' 'INSULIN1' 'CHKHEMO3' 'EYEEXAM1' 'DIABEYE1' 'DIABEDU1'
 'FEETSORE' 'TOLDCFS' 'HAVECFS' 'WORKCFS' 'IMFVPLA3' 'HPVADVC4' 'HPVADSHT'
 'SHINGLE2' 'COVIDVA1' 'COVACGET' 'COVIDNU1' 'COVIDINT' 'COVIDFS1'
 'COVIDSE1' 'COPDCOGH' 'COPDFLEM' 'COPDBRTH' 'COPDBTST' 'COPDSMOK'
 'CNCRDIFF' 'CNCRAGE' 'CNCRTYP2' 'CSRVTRT3' 'CSRVDOC1' 'CSRVSUM'
 'CSRVRTRN' 'CSRVINST' 'CSRVINSR' 'CSRVDEIN' 'CSRVCLIN' 'CSRVPAIN'
 'CSRVCTL2' 'PSATEST1' 'PSATIME1' 'PCPSARS2' 'PSASUGST' 'PCSTALK1'
 'CIMEMLOS' 'CDHOUSE' 'CDASSIST' 'CDHELP' 'CDSOCIAL' 'CDDISCUS' 'CAREGIV1'
 'CRGVREL4' 'CRGVLNG1' 'CRGVHRS1' 'CRGVPRB3' 'CRGVALZD' 'CRGVPER1'
 'CRGVHOU1' 'CRGVEXPT' 'ACEDEPRS' 'ACEDRINK' 'ACEDRUGS' 'ACEPRISN'
 'ACEDIVRC' 'ACEPUNCH' 'ACEHURT1' 'ACESWEAR' 'ACETOUCH' 'ACETTHEM'
 'ACEHVSEX' 'ACEADSAF' 'ACEADNED' 'MARIJAN1' 'MARJSMOK' 'MARJEAT'
 'MARJVAPE' 'MARJDAB' 'MARJOTHR' 'USEMRJN4' 'LASTSMK2' 'STOPSMK2'
 'MENTCIGS' 'MENTECIG' 'HEATTBCO' 'ASBIALCH' 'ASBIDRNK' 'ASBIBING'
 'ASBIADVC' 'ASBIRDUC' 'FIREARM5' 'GUNLOAD' 'LOADULK2' 'RCSXBRTH'
 'CASTHNO2' 'BIRTHSEX' 'SOMALE' 'SOFEMALE' 'TRNSGNDR' 'HADSEX' 'PFPPRVN4'
 'TYPCNTR9' 'BRTHCNT4' 'WHEREGET' 'NOBCUSE8' 'BCPREFER' 'RRCLASS3'
 'RRCOGNT2' 'RRTREAT' 'RRATWRK2' 'RRHCARE4' 'RRPHYSM2' 'CAGEG']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-27 21:35:38,708:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-11-27 21:35:38,710:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-11-27 21:35:38,713:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-11-27 21:35:38,713:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-27 21:35:38,723:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'SAFETIME' 'CTELNUM1' 'CELLFON5' 'CADULT1'
 'CELLSEX1' 'PVTRESD3' 'CCLGHOUS' 'CSTATE1' 'LANDLINE' 'HHADULT'
 'LASTDEN4' 'RMVTETH4' 'BLDSTFIT' 'SDNATES1' 'PDIABTS1' 'PREDIAB2'
 'DIABTYPE' 'INSULIN1' 'CHKHEMO3' 'EYEEXAM1' 'DIABEYE1' 'DIABEDU1'
 'FEETSORE' 'TOLDCFS' 'HAVECFS' 'WORKCFS' 'IMFVPLA3' 'HPVADVC4' 'HPVADSHT'
 'SHINGLE2' 'COVIDVA1' 'COVACGET' 'COVIDNU1' 'COVIDINT' 'COVIDFS1'
 'COVIDSE1' 'COPDCOGH' 'COPDFLEM' 'COPDBRTH' 'COPDBTST' 'COPDSMOK'
 'CNCRDIFF' 'CNCRAGE' 'CNCRTYP2' 'CSRVTRT3' 'CSRVDOC1' 'CSRVSUM'
 'CSRVRTRN' 'CSRVINST' 'CSRVINSR' 'CSRVDEIN' 'CSRVCLIN' 'CSRVPAIN'
 'CSRVCTL2' 'PSATEST1' 'PSATIME1' 'PCPSARS2' 'PSASUGST' 'PCSTALK1'
 'CIMEMLOS' 'CDHOUSE' 'CDASSIST' 'CDHELP' 'CDSOCIAL' 'CDDISCUS' 'CAREGIV1'
 'CRGVREL4' 'CRGVLNG1' 'CRGVHRS1' 'CRGVPRB3' 'CRGVALZD' 'CRGVPER1'
 'CRGVHOU1' 'CRGVEXPT' 'ACEDEPRS' 'ACEDRINK' 'ACEDRUGS' 'ACEPRISN'
 'ACEDIVRC' 'ACEPUNCH' 'ACEHURT1' 'ACESWEAR' 'ACETOUCH' 'ACETTHEM'
 'ACEHVSEX' 'ACEADSAF' 'ACEADNED' 'MARIJAN1' 'MARJSMOK' 'MARJEAT'
 'MARJVAPE' 'MARJDAB' 'MARJOTHR' 'USEMRJN4' 'LASTSMK2' 'STOPSMK2'
 'MENTCIGS' 'MENTECIG' 'HEATTBCO' 'ASBIALCH' 'ASBIDRNK' 'ASBIBING'
 'ASBIADVC' 'ASBIRDUC' 'FIREARM5' 'GUNLOAD' 'LOADULK2' 'RCSXBRTH'
 'CASTHNO2' 'BIRTHSEX' 'SOMALE' 'SOFEMALE' 'TRNSGNDR' 'HADSEX' 'PFPPRVN4'
 'TYPCNTR9' 'BRTHCNT4' 'WHEREGET' 'NOBCUSE8' 'BCPREFER' 'RRCLASS3'
 'RRCOGNT2' 'RRTREAT' 'RRATWRK2' 'RRHCARE4' 'RRPHYSM2' 'CAGEG']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-27 21:35:38,725:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-11-27 21:35:38,733:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-11-27 21:35:38,736:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-11-27 21:35:38,739:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-11-27 21:35:38,741:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-11-27 21:35:38,741:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-27 21:35:38,743:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-27 21:35:38,743:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-11-27 21:35:38,743:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-27 21:35:38,744:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-11-27 21:35:38,751:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-11-27 21:35:38,777:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-11-27 21:35:38,782:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-11-27 21:35:38,804:INFO:Calculating mean and std
2025-11-27 21:35:38,806:INFO:Creating metrics dataframe
2025-11-27 21:35:38,808:INFO:Uploading results into container
2025-11-27 21:35:38,808:INFO:Uploading model into container now
2025-11-27 21:35:38,809:INFO:_master_model_container: 1
2025-11-27 21:35:38,809:INFO:_display_container: 2
2025-11-27 21:35:38,809:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-11-27 21:35:38,809:INFO:create_model() successfully completed......................................
2025-11-27 21:35:38,919:INFO:SubProcess create_model() end ==================================
2025-11-27 21:35:38,919:INFO:Creating metrics dataframe
2025-11-27 21:35:38,919:INFO:Initializing Decision Tree Classifier
2025-11-27 21:35:38,919:INFO:Total runtime is 0.07307968934377035 minutes
2025-11-27 21:35:38,919:INFO:SubProcess create_model() called ==================================
2025-11-27 21:35:38,919:INFO:Initializing create_model()
2025-11-27 21:35:38,919:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024612C71C30>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024612C71090>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-27 21:35:38,919:INFO:Checking exceptions
2025-11-27 21:35:38,919:INFO:Importing libraries
2025-11-27 21:35:38,919:INFO:Copying training dataset
2025-11-27 21:35:38,941:INFO:Defining folds
2025-11-27 21:35:38,941:INFO:Declaring metric variables
2025-11-27 21:35:38,941:INFO:Importing untrained model
2025-11-27 21:35:38,941:INFO:Decision Tree Classifier Imported successfully
2025-11-27 21:35:38,941:INFO:Starting cross validation
2025-11-27 21:35:38,944:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-27 21:35:38,944:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\model_selection\_split.py:737: UserWarning: The least populated class in y has only 6 members, which is less than n_splits=10.
  warnings.warn(

2025-11-27 21:35:38,994:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'SAFETIME' 'CTELNUM1' 'CELLFON5' 'CADULT1'
 'CELLSEX1' 'PVTRESD3' 'CCLGHOUS' 'CSTATE1' 'LANDLINE' 'HHADULT'
 'LASTDEN4' 'RMVTETH4' 'BLDSTFIT' 'SDNATES1' 'PDIABTS1' 'PREDIAB2'
 'DIABTYPE' 'INSULIN1' 'CHKHEMO3' 'EYEEXAM1' 'DIABEYE1' 'DIABEDU1'
 'FEETSORE' 'TOLDCFS' 'HAVECFS' 'WORKCFS' 'IMFVPLA3' 'HPVADVC4' 'HPVADSHT'
 'SHINGLE2' 'COVIDVA1' 'COVACGET' 'COVIDNU1' 'COVIDINT' 'COVIDFS1'
 'COVIDSE1' 'COPDCOGH' 'COPDFLEM' 'COPDBRTH' 'COPDBTST' 'COPDSMOK'
 'CNCRDIFF' 'CNCRAGE' 'CNCRTYP2' 'CSRVTRT3' 'CSRVDOC1' 'CSRVSUM'
 'CSRVRTRN' 'CSRVINST' 'CSRVINSR' 'CSRVDEIN' 'CSRVCLIN' 'CSRVPAIN'
 'CSRVCTL2' 'PSATEST1' 'PSATIME1' 'PCPSARS2' 'PSASUGST' 'PCSTALK1'
 'CIMEMLOS' 'CDHOUSE' 'CDASSIST' 'CDHELP' 'CDSOCIAL' 'CDDISCUS' 'CAREGIV1'
 'CRGVREL4' 'CRGVLNG1' 'CRGVHRS1' 'CRGVPRB3' 'CRGVALZD' 'CRGVPER1'
 'CRGVHOU1' 'CRGVEXPT' 'ACEDEPRS' 'ACEDRINK' 'ACEDRUGS' 'ACEPRISN'
 'ACEDIVRC' 'ACEPUNCH' 'ACEHURT1' 'ACESWEAR' 'ACETOUCH' 'ACETTHEM'
 'ACEHVSEX' 'ACEADSAF' 'ACEADNED' 'MARIJAN1' 'MARJSMOK' 'MARJEAT'
 'MARJVAPE' 'MARJDAB' 'MARJOTHR' 'USEMRJN4' 'LASTSMK2' 'STOPSMK2'
 'MENTCIGS' 'MENTECIG' 'HEATTBCO' 'ASBIALCH' 'ASBIDRNK' 'ASBIBING'
 'ASBIADVC' 'ASBIRDUC' 'FIREARM5' 'GUNLOAD' 'LOADULK2' 'RCSXBRTH'
 'CASTHNO2' 'BIRTHSEX' 'SOMALE' 'SOFEMALE' 'TRNSGNDR' 'HADSEX' 'PFPPRVN4'
 'TYPCNTR9' 'BRTHCNT4' 'WHEREGET' 'NOBCUSE8' 'BCPREFER' 'RRCLASS3'
 'RRCOGNT2' 'RRTREAT' 'RRATWRK2' 'RRHCARE4' 'RRPHYSM2' 'CAGEG']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-27 21:35:39,004:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'SAFETIME' 'CTELNUM1' 'CELLFON5' 'CADULT1'
 'CELLSEX1' 'PVTRESD3' 'CCLGHOUS' 'CSTATE1' 'LANDLINE' 'HHADULT'
 'LASTDEN4' 'RMVTETH4' 'VCLNTES2' 'BLDSTFIT' 'SDNATES1' 'PDIABTS1'
 'PREDIAB2' 'DIABTYPE' 'INSULIN1' 'CHKHEMO3' 'EYEEXAM1' 'DIABEYE1'
 'DIABEDU1' 'FEETSORE' 'TOLDCFS' 'HAVECFS' 'WORKCFS' 'IMFVPLA3' 'HPVADVC4'
 'HPVADSHT' 'SHINGLE2' 'COVIDVA1' 'COVACGET' 'COVIDNU1' 'COVIDINT'
 'COVIDFS1' 'COVIDSE1' 'COPDCOGH' 'COPDFLEM' 'COPDBRTH' 'COPDBTST'
 'COPDSMOK' 'CNCRDIFF' 'CNCRAGE' 'CNCRTYP2' 'CSRVTRT3' 'CSRVDOC1'
 'CSRVSUM' 'CSRVRTRN' 'CSRVINST' 'CSRVINSR' 'CSRVDEIN' 'CSRVCLIN'
 'CSRVPAIN' 'CSRVCTL2' 'PSATEST1' 'PSATIME1' 'PCPSARS2' 'PSASUGST'
 'PCSTALK1' 'CIMEMLOS' 'CDHOUSE' 'CDASSIST' 'CDHELP' 'CDSOCIAL' 'CDDISCUS'
 'CAREGIV1' 'CRGVREL4' 'CRGVLNG1' 'CRGVHRS1' 'CRGVPRB3' 'CRGVALZD'
 'CRGVPER1' 'CRGVHOU1' 'CRGVEXPT' 'ACEDEPRS' 'ACEDRINK' 'ACEDRUGS'
 'ACEPRISN' 'ACEDIVRC' 'ACEPUNCH' 'ACEHURT1' 'ACESWEAR' 'ACETOUCH'
 'ACETTHEM' 'ACEHVSEX' 'ACEADSAF' 'ACEADNED' 'MARIJAN1' 'MARJSMOK'
 'MARJEAT' 'MARJVAPE' 'MARJDAB' 'MARJOTHR' 'USEMRJN4' 'LASTSMK2'
 'STOPSMK2' 'MENTCIGS' 'MENTECIG' 'HEATTBCO' 'ASBIALCH' 'ASBIDRNK'
 'ASBIBING' 'ASBIADVC' 'ASBIRDUC' 'FIREARM5' 'GUNLOAD' 'LOADULK2'
 'RCSXBRTH' 'CASTHNO2' 'BIRTHSEX' 'SOMALE' 'SOFEMALE' 'TRNSGNDR' 'HADSEX'
 'PFPPRVN4' 'TYPCNTR9' 'BRTHCNT4' 'WHEREGET' 'NOBCUSE8' 'BCPREFER'
 'RRCLASS3' 'RRCOGNT2' 'RRTREAT' 'RRATWRK2' 'RRHCARE4' 'RRPHYSM2' 'CAGEG']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-27 21:35:39,004:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'SAFETIME' 'CTELNUM1' 'CELLFON5' 'CADULT1'
 'CELLSEX1' 'PVTRESD3' 'CCLGHOUS' 'CSTATE1' 'LANDLINE' 'HHADULT'
 'LASTDEN4' 'RMVTETH4' 'BLDSTFIT' 'SDNATES1' 'PDIABTS1' 'PREDIAB2'
 'DIABTYPE' 'INSULIN1' 'CHKHEMO3' 'EYEEXAM1' 'DIABEYE1' 'DIABEDU1'
 'FEETSORE' 'TOLDCFS' 'HAVECFS' 'WORKCFS' 'IMFVPLA3' 'HPVADVC4' 'HPVADSHT'
 'SHINGLE2' 'COVIDVA1' 'COVACGET' 'COVIDNU1' 'COVIDINT' 'COVIDFS1'
 'COVIDSE1' 'COPDCOGH' 'COPDFLEM' 'COPDBRTH' 'COPDBTST' 'COPDSMOK'
 'CNCRDIFF' 'CNCRAGE' 'CNCRTYP2' 'CSRVTRT3' 'CSRVDOC1' 'CSRVSUM'
 'CSRVRTRN' 'CSRVINST' 'CSRVINSR' 'CSRVDEIN' 'CSRVCLIN' 'CSRVPAIN'
 'CSRVCTL2' 'PSATEST1' 'PSATIME1' 'PCPSARS2' 'PSASUGST' 'PCSTALK1'
 'CIMEMLOS' 'CDHOUSE' 'CDASSIST' 'CDHELP' 'CDSOCIAL' 'CDDISCUS' 'CAREGIV1'
 'CRGVREL4' 'CRGVLNG1' 'CRGVHRS1' 'CRGVPRB3' 'CRGVALZD' 'CRGVPER1'
 'CRGVHOU1' 'CRGVEXPT' 'ACEDEPRS' 'ACEDRINK' 'ACEDRUGS' 'ACEPRISN'
 'ACEDIVRC' 'ACEPUNCH' 'ACEHURT1' 'ACESWEAR' 'ACETOUCH' 'ACETTHEM'
 'ACEHVSEX' 'ACEADSAF' 'ACEADNED' 'MARIJAN1' 'MARJSMOK' 'MARJEAT'
 'MARJVAPE' 'MARJDAB' 'MARJOTHR' 'USEMRJN4' 'LASTSMK2' 'STOPSMK2'
 'MENTCIGS' 'MENTECIG' 'HEATTBCO' 'ASBIALCH' 'ASBIDRNK' 'ASBIBING'
 'ASBIADVC' 'ASBIRDUC' 'FIREARM5' 'GUNLOAD' 'LOADULK2' 'RCSXBRTH'
 'CASTHNO2' 'BIRTHSEX' 'SOMALE' 'SOFEMALE' 'TRNSGNDR' 'HADSEX' 'PFPPRVN4'
 'TYPCNTR9' 'BRTHCNT4' 'WHEREGET' 'NOBCUSE8' 'BCPREFER' 'RRCLASS3'
 'RRCOGNT2' 'RRTREAT' 'RRATWRK2' 'RRHCARE4' 'RRPHYSM2' 'CAGEG']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-27 21:35:39,020:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'SAFETIME' 'CTELNUM1' 'CELLFON5' 'CADULT1'
 'CELLSEX1' 'PVTRESD3' 'CCLGHOUS' 'CSTATE1' 'LANDLINE' 'HHADULT'
 'LASTDEN4' 'RMVTETH4' 'BLDSTFIT' 'SDNATES1' 'PDIABTS1' 'PREDIAB2'
 'DIABTYPE' 'INSULIN1' 'CHKHEMO3' 'EYEEXAM1' 'DIABEYE1' 'DIABEDU1'
 'FEETSORE' 'TOLDCFS' 'HAVECFS' 'WORKCFS' 'IMFVPLA3' 'HPVADVC4' 'HPVADSHT'
 'SHINGLE2' 'COVIDVA1' 'COVACGET' 'COVIDNU1' 'COVIDINT' 'COVIDFS1'
 'COVIDSE1' 'COPDCOGH' 'COPDFLEM' 'COPDBRTH' 'COPDBTST' 'COPDSMOK'
 'CNCRDIFF' 'CNCRAGE' 'CNCRTYP2' 'CSRVTRT3' 'CSRVDOC1' 'CSRVSUM'
 'CSRVRTRN' 'CSRVINST' 'CSRVINSR' 'CSRVDEIN' 'CSRVCLIN' 'CSRVPAIN'
 'CSRVCTL2' 'PSATEST1' 'PSATIME1' 'PCPSARS2' 'PSASUGST' 'PCSTALK1'
 'CIMEMLOS' 'CDHOUSE' 'CDASSIST' 'CDHELP' 'CDSOCIAL' 'CDDISCUS' 'CAREGIV1'
 'CRGVREL4' 'CRGVLNG1' 'CRGVHRS1' 'CRGVPRB3' 'CRGVALZD' 'CRGVPER1'
 'CRGVHOU1' 'CRGVEXPT' 'ACEDEPRS' 'ACEDRINK' 'ACEDRUGS' 'ACEPRISN'
 'ACEDIVRC' 'ACEPUNCH' 'ACEHURT1' 'ACESWEAR' 'ACETOUCH' 'ACETTHEM'
 'ACEHVSEX' 'ACEADSAF' 'ACEADNED' 'MARIJAN1' 'MARJSMOK' 'MARJEAT'
 'MARJVAPE' 'MARJDAB' 'MARJOTHR' 'USEMRJN4' 'LASTSMK2' 'STOPSMK2'
 'MENTCIGS' 'MENTECIG' 'HEATTBCO' 'ASBIALCH' 'ASBIDRNK' 'ASBIBING'
 'ASBIADVC' 'ASBIRDUC' 'FIREARM5' 'GUNLOAD' 'LOADULK2' 'RCSXBRTH'
 'CASTHNO2' 'BIRTHSEX' 'SOMALE' 'SOFEMALE' 'TRNSGNDR' 'HADSEX' 'PFPPRVN4'
 'TYPCNTR9' 'BRTHCNT4' 'WHEREGET' 'NOBCUSE8' 'BCPREFER' 'RRCLASS3'
 'RRCOGNT2' 'RRTREAT' 'RRATWRK2' 'RRHCARE4' 'RRPHYSM2' 'CAGEG']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-27 21:35:39,025:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'SAFETIME' 'CTELNUM1' 'CELLFON5' 'CADULT1'
 'CELLSEX1' 'PVTRESD3' 'CCLGHOUS' 'CSTATE1' 'LANDLINE' 'HHADULT'
 'LASTDEN4' 'RMVTETH4' 'NUMPHON4' 'BLDSTFIT' 'SDNATES1' 'PDIABTS1'
 'PREDIAB2' 'DIABTYPE' 'INSULIN1' 'CHKHEMO3' 'EYEEXAM1' 'DIABEYE1'
 'DIABEDU1' 'FEETSORE' 'TOLDCFS' 'HAVECFS' 'WORKCFS' 'IMFVPLA3' 'HPVADVC4'
 'HPVADSHT' 'SHINGLE2' 'COVIDVA1' 'COVACGET' 'COVIDNU1' 'COVIDINT'
 'COVIDFS1' 'COVIDSE1' 'COPDCOGH' 'COPDFLEM' 'COPDBRTH' 'COPDBTST'
 'COPDSMOK' 'CNCRDIFF' 'CNCRAGE' 'CNCRTYP2' 'CSRVTRT3' 'CSRVDOC1'
 'CSRVSUM' 'CSRVRTRN' 'CSRVINST' 'CSRVINSR' 'CSRVDEIN' 'CSRVCLIN'
 'CSRVPAIN' 'CSRVCTL2' 'PSATEST1' 'PSATIME1' 'PCPSARS2' 'PSASUGST'
 'PCSTALK1' 'CIMEMLOS' 'CDHOUSE' 'CDASSIST' 'CDHELP' 'CDSOCIAL' 'CDDISCUS'
 'CAREGIV1' 'CRGVREL4' 'CRGVLNG1' 'CRGVHRS1' 'CRGVPRB3' 'CRGVALZD'
 'CRGVPER1' 'CRGVHOU1' 'CRGVEXPT' 'ACEDEPRS' 'ACEDRINK' 'ACEDRUGS'
 'ACEPRISN' 'ACEDIVRC' 'ACEPUNCH' 'ACEHURT1' 'ACESWEAR' 'ACETOUCH'
 'ACETTHEM' 'ACEHVSEX' 'ACEADSAF' 'ACEADNED' 'MARIJAN1' 'MARJSMOK'
 'MARJEAT' 'MARJVAPE' 'MARJDAB' 'MARJOTHR' 'USEMRJN4' 'LASTSMK2'
 'STOPSMK2' 'MENTCIGS' 'MENTECIG' 'HEATTBCO' 'ASBIALCH' 'ASBIDRNK'
 'ASBIBING' 'ASBIADVC' 'ASBIRDUC' 'FIREARM5' 'GUNLOAD' 'LOADULK2'
 'RCSXBRTH' 'CASTHNO2' 'BIRTHSEX' 'SOMALE' 'SOFEMALE' 'TRNSGNDR' 'HADSEX'
 'PFPPRVN4' 'TYPCNTR9' 'BRTHCNT4' 'WHEREGET' 'NOBCUSE8' 'BCPREFER'
 'RRCLASS3' 'RRCOGNT2' 'RRTREAT' 'RRATWRK2' 'RRHCARE4' 'RRPHYSM2' 'CAGEG']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-27 21:35:39,036:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'SAFETIME' 'CTELNUM1' 'CELLFON5' 'CADULT1'
 'CELLSEX1' 'PVTRESD3' 'CCLGHOUS' 'CSTATE1' 'LANDLINE' 'HHADULT'
 'LASTDEN4' 'RMVTETH4' 'BLDSTFIT' 'SDNATES1' 'PDIABTS1' 'PREDIAB2'
 'DIABTYPE' 'INSULIN1' 'CHKHEMO3' 'EYEEXAM1' 'DIABEYE1' 'DIABEDU1'
 'FEETSORE' 'TOLDCFS' 'HAVECFS' 'WORKCFS' 'IMFVPLA3' 'HPVADVC4' 'HPVADSHT'
 'SHINGLE2' 'COVIDVA1' 'COVACGET' 'COVIDNU1' 'COVIDINT' 'COVIDFS1'
 'COVIDSE1' 'COPDCOGH' 'COPDFLEM' 'COPDBRTH' 'COPDBTST' 'COPDSMOK'
 'CNCRDIFF' 'CNCRAGE' 'CNCRTYP2' 'CSRVTRT3' 'CSRVDOC1' 'CSRVSUM'
 'CSRVRTRN' 'CSRVINST' 'CSRVINSR' 'CSRVDEIN' 'CSRVCLIN' 'CSRVPAIN'
 'CSRVCTL2' 'PSATEST1' 'PSATIME1' 'PCPSARS2' 'PSASUGST' 'PCSTALK1'
 'CIMEMLOS' 'CDHOUSE' 'CDASSIST' 'CDHELP' 'CDSOCIAL' 'CDDISCUS' 'CAREGIV1'
 'CRGVREL4' 'CRGVLNG1' 'CRGVHRS1' 'CRGVPRB3' 'CRGVALZD' 'CRGVPER1'
 'CRGVHOU1' 'CRGVEXPT' 'ACEDEPRS' 'ACEDRINK' 'ACEDRUGS' 'ACEPRISN'
 'ACEDIVRC' 'ACEPUNCH' 'ACEHURT1' 'ACESWEAR' 'ACETOUCH' 'ACETTHEM'
 'ACEHVSEX' 'ACEADSAF' 'ACEADNED' 'MARIJAN1' 'MARJSMOK' 'MARJEAT'
 'MARJVAPE' 'MARJDAB' 'MARJOTHR' 'USEMRJN4' 'LASTSMK2' 'STOPSMK2'
 'MENTCIGS' 'MENTECIG' 'HEATTBCO' 'ASBIALCH' 'ASBIDRNK' 'ASBIBING'
 'ASBIADVC' 'ASBIRDUC' 'FIREARM5' 'GUNLOAD' 'LOADULK2' 'RCSXBRTH'
 'CASTHNO2' 'BIRTHSEX' 'SOMALE' 'SOFEMALE' 'TRNSGNDR' 'HADSEX' 'PFPPRVN4'
 'TYPCNTR9' 'BRTHCNT4' 'WHEREGET' 'NOBCUSE8' 'BCPREFER' 'RRCLASS3'
 'RRCOGNT2' 'RRTREAT' 'RRATWRK2' 'RRHCARE4' 'RRPHYSM2' 'CAGEG']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-27 21:35:39,042:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'SAFETIME' 'CTELNUM1' 'CELLFON5' 'CADULT1'
 'CELLSEX1' 'PVTRESD3' 'CCLGHOUS' 'CSTATE1' 'LANDLINE' 'HHADULT'
 'LASTDEN4' 'RMVTETH4' 'LASTSIG4' 'BLDSTFIT' 'SDNATES1' 'PDIABTS1'
 'PREDIAB2' 'DIABTYPE' 'INSULIN1' 'CHKHEMO3' 'EYEEXAM1' 'DIABEYE1'
 'DIABEDU1' 'FEETSORE' 'TOLDCFS' 'HAVECFS' 'WORKCFS' 'IMFVPLA3' 'HPVADVC4'
 'HPVADSHT' 'SHINGLE2' 'COVIDVA1' 'COVACGET' 'COVIDNU1' 'COVIDINT'
 'COVIDFS1' 'COVIDSE1' 'COPDCOGH' 'COPDFLEM' 'COPDBRTH' 'COPDBTST'
 'COPDSMOK' 'CNCRDIFF' 'CNCRAGE' 'CNCRTYP2' 'CSRVTRT3' 'CSRVDOC1'
 'CSRVSUM' 'CSRVRTRN' 'CSRVINST' 'CSRVINSR' 'CSRVDEIN' 'CSRVCLIN'
 'CSRVPAIN' 'CSRVCTL2' 'PSATEST1' 'PSATIME1' 'PCPSARS2' 'PSASUGST'
 'PCSTALK1' 'CIMEMLOS' 'CDHOUSE' 'CDASSIST' 'CDHELP' 'CDSOCIAL' 'CDDISCUS'
 'CAREGIV1' 'CRGVREL4' 'CRGVLNG1' 'CRGVHRS1' 'CRGVPRB3' 'CRGVALZD'
 'CRGVPER1' 'CRGVHOU1' 'CRGVEXPT' 'ACEDEPRS' 'ACEDRINK' 'ACEDRUGS'
 'ACEPRISN' 'ACEDIVRC' 'ACEPUNCH' 'ACEHURT1' 'ACESWEAR' 'ACETOUCH'
 'ACETTHEM' 'ACEHVSEX' 'ACEADSAF' 'ACEADNED' 'MARIJAN1' 'MARJSMOK'
 'MARJEAT' 'MARJVAPE' 'MARJDAB' 'MARJOTHR' 'USEMRJN4' 'LASTSMK2'
 'STOPSMK2' 'MENTCIGS' 'MENTECIG' 'HEATTBCO' 'ASBIALCH' 'ASBIDRNK'
 'ASBIBING' 'ASBIADVC' 'ASBIRDUC' 'FIREARM5' 'GUNLOAD' 'LOADULK2'
 'RCSXBRTH' 'CASTHNO2' 'BIRTHSEX' 'SOMALE' 'SOFEMALE' 'TRNSGNDR' 'HADSEX'
 'PFPPRVN4' 'TYPCNTR9' 'BRTHCNT4' 'WHEREGET' 'NOBCUSE8' 'BCPREFER'
 'RRCLASS3' 'RRCOGNT2' 'RRTREAT' 'RRATWRK2' 'RRHCARE4' 'RRPHYSM2' 'CAGEG']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-27 21:35:39,052:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'SAFETIME' 'CTELNUM1' 'CELLFON5' 'CADULT1'
 'CELLSEX1' 'PVTRESD3' 'CCLGHOUS' 'CSTATE1' 'LANDLINE' 'HHADULT'
 'LASTDEN4' 'RMVTETH4' 'BLDSTFIT' 'SDNATES1' 'PDIABTS1' 'PREDIAB2'
 'DIABTYPE' 'INSULIN1' 'CHKHEMO3' 'EYEEXAM1' 'DIABEYE1' 'DIABEDU1'
 'FEETSORE' 'TOLDCFS' 'HAVECFS' 'WORKCFS' 'IMFVPLA3' 'HPVADVC4' 'HPVADSHT'
 'SHINGLE2' 'COVIDVA1' 'COVACGET' 'COVIDNU1' 'COVIDINT' 'COVIDFS1'
 'COVIDSE1' 'COPDCOGH' 'COPDFLEM' 'COPDBRTH' 'COPDBTST' 'COPDSMOK'
 'CNCRDIFF' 'CNCRAGE' 'CNCRTYP2' 'CSRVTRT3' 'CSRVDOC1' 'CSRVSUM'
 'CSRVRTRN' 'CSRVINST' 'CSRVINSR' 'CSRVDEIN' 'CSRVCLIN' 'CSRVPAIN'
 'CSRVCTL2' 'PSATEST1' 'PSATIME1' 'PCPSARS2' 'PSASUGST' 'PCSTALK1'
 'CIMEMLOS' 'CDHOUSE' 'CDASSIST' 'CDHELP' 'CDSOCIAL' 'CDDISCUS' 'CAREGIV1'
 'CRGVREL4' 'CRGVLNG1' 'CRGVHRS1' 'CRGVPRB3' 'CRGVALZD' 'CRGVPER1'
 'CRGVHOU1' 'CRGVEXPT' 'ACEDEPRS' 'ACEDRINK' 'ACEDRUGS' 'ACEPRISN'
 'ACEDIVRC' 'ACEPUNCH' 'ACEHURT1' 'ACESWEAR' 'ACETOUCH' 'ACETTHEM'
 'ACEHVSEX' 'ACEADSAF' 'ACEADNED' 'MARIJAN1' 'MARJSMOK' 'MARJEAT'
 'MARJVAPE' 'MARJDAB' 'MARJOTHR' 'USEMRJN4' 'LASTSMK2' 'STOPSMK2'
 'MENTCIGS' 'MENTECIG' 'HEATTBCO' 'ASBIALCH' 'ASBIDRNK' 'ASBIBING'
 'ASBIADVC' 'ASBIRDUC' 'FIREARM5' 'GUNLOAD' 'LOADULK2' 'RCSGEND1'
 'RCSXBRTH' 'RCSRLTN2' 'CASTHDX2' 'CASTHNO2' 'BIRTHSEX' 'SOMALE'
 'SOFEMALE' 'TRNSGNDR' 'HADSEX' 'PFPPRVN4' 'TYPCNTR9' 'BRTHCNT4'
 'WHEREGET' 'NOBCUSE8' 'BCPREFER' 'RRCLASS3' 'RRCOGNT2' 'RRTREAT'
 'RRATWRK2' 'RRHCARE4' 'RRPHYSM2' 'CRACE2' 'CPRACE2' 'CAGEG' 'CLLCPWT']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-27 21:35:39,085:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'SAFETIME' 'CTELNUM1' 'CELLFON5' 'CADULT1'
 'CELLSEX1' 'PVTRESD3' 'CCLGHOUS' 'CSTATE1' 'LANDLINE' 'HHADULT'
 'LASTDEN4' 'RMVTETH4' 'VCLNTES2' 'BLDSTFIT' 'SDNATES1' 'PDIABTS1'
 'PREDIAB2' 'DIABTYPE' 'INSULIN1' 'CHKHEMO3' 'EYEEXAM1' 'DIABEYE1'
 'DIABEDU1' 'FEETSORE' 'TOLDCFS' 'HAVECFS' 'WORKCFS' 'IMFVPLA3' 'HPVADVC4'
 'HPVADSHT' 'SHINGLE2' 'COVIDVA1' 'COVACGET' 'COVIDNU1' 'COVIDINT'
 'COVIDFS1' 'COVIDSE1' 'COPDCOGH' 'COPDFLEM' 'COPDBRTH' 'COPDBTST'
 'COPDSMOK' 'CNCRDIFF' 'CNCRAGE' 'CNCRTYP2' 'CSRVTRT3' 'CSRVDOC1'
 'CSRVSUM' 'CSRVRTRN' 'CSRVINST' 'CSRVINSR' 'CSRVDEIN' 'CSRVCLIN'
 'CSRVPAIN' 'CSRVCTL2' 'PSATEST1' 'PSATIME1' 'PCPSARS2' 'PSASUGST'
 'PCSTALK1' 'CIMEMLOS' 'CDHOUSE' 'CDASSIST' 'CDHELP' 'CDSOCIAL' 'CDDISCUS'
 'CAREGIV1' 'CRGVREL4' 'CRGVLNG1' 'CRGVHRS1' 'CRGVPRB3' 'CRGVALZD'
 'CRGVPER1' 'CRGVHOU1' 'CRGVEXPT' 'ACEDEPRS' 'ACEDRINK' 'ACEDRUGS'
 'ACEPRISN' 'ACEDIVRC' 'ACEPUNCH' 'ACEHURT1' 'ACESWEAR' 'ACETOUCH'
 'ACETTHEM' 'ACEHVSEX' 'ACEADSAF' 'ACEADNED' 'MARIJAN1' 'MARJSMOK'
 'MARJEAT' 'MARJVAPE' 'MARJDAB' 'MARJOTHR' 'USEMRJN4' 'LASTSMK2'
 'STOPSMK2' 'MENTCIGS' 'MENTECIG' 'HEATTBCO' 'ASBIALCH' 'ASBIDRNK'
 'ASBIBING' 'ASBIADVC' 'ASBIRDUC' 'FIREARM5' 'GUNLOAD' 'LOADULK2'
 'RCSXBRTH' 'CASTHNO2' 'BIRTHSEX' 'SOMALE' 'SOFEMALE' 'TRNSGNDR' 'HADSEX'
 'PFPPRVN4' 'TYPCNTR9' 'BRTHCNT4' 'WHEREGET' 'NOBCUSE8' 'BCPREFER'
 'RRCLASS3' 'RRCOGNT2' 'RRTREAT' 'RRATWRK2' 'RRHCARE4' 'RRPHYSM2' 'CAGEG']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-27 21:35:39,087:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'SAFETIME' 'CTELNUM1' 'CELLFON5' 'CADULT1'
 'CELLSEX1' 'PVTRESD3' 'CCLGHOUS' 'CSTATE1' 'LANDLINE' 'HHADULT'
 'LASTDEN4' 'RMVTETH4' 'BLDSTFIT' 'SDNATES1' 'PDIABTS1' 'PREDIAB2'
 'DIABTYPE' 'INSULIN1' 'CHKHEMO3' 'EYEEXAM1' 'DIABEYE1' 'DIABEDU1'
 'FEETSORE' 'TOLDCFS' 'HAVECFS' 'WORKCFS' 'IMFVPLA3' 'HPVADVC4' 'HPVADSHT'
 'SHINGLE2' 'COVIDVA1' 'COVACGET' 'COVIDNU1' 'COVIDINT' 'COVIDFS1'
 'COVIDSE1' 'COPDCOGH' 'COPDFLEM' 'COPDBRTH' 'COPDBTST' 'COPDSMOK'
 'CNCRDIFF' 'CNCRAGE' 'CNCRTYP2' 'CSRVTRT3' 'CSRVDOC1' 'CSRVSUM'
 'CSRVRTRN' 'CSRVINST' 'CSRVINSR' 'CSRVDEIN' 'CSRVCLIN' 'CSRVPAIN'
 'CSRVCTL2' 'PSATEST1' 'PSATIME1' 'PCPSARS2' 'PSASUGST' 'PCSTALK1'
 'CIMEMLOS' 'CDHOUSE' 'CDASSIST' 'CDHELP' 'CDSOCIAL' 'CDDISCUS' 'CAREGIV1'
 'CRGVREL4' 'CRGVLNG1' 'CRGVHRS1' 'CRGVPRB3' 'CRGVALZD' 'CRGVPER1'
 'CRGVHOU1' 'CRGVEXPT' 'ACEDEPRS' 'ACEDRINK' 'ACEDRUGS' 'ACEPRISN'
 'ACEDIVRC' 'ACEPUNCH' 'ACEHURT1' 'ACESWEAR' 'ACETOUCH' 'ACETTHEM'
 'ACEHVSEX' 'ACEADSAF' 'ACEADNED' 'MARIJAN1' 'MARJSMOK' 'MARJEAT'
 'MARJVAPE' 'MARJDAB' 'MARJOTHR' 'USEMRJN4' 'LASTSMK2' 'STOPSMK2'
 'MENTCIGS' 'MENTECIG' 'HEATTBCO' 'ASBIALCH' 'ASBIDRNK' 'ASBIBING'
 'ASBIADVC' 'ASBIRDUC' 'FIREARM5' 'GUNLOAD' 'LOADULK2' 'RCSXBRTH'
 'CASTHNO2' 'BIRTHSEX' 'SOMALE' 'SOFEMALE' 'TRNSGNDR' 'HADSEX' 'PFPPRVN4'
 'TYPCNTR9' 'BRTHCNT4' 'WHEREGET' 'NOBCUSE8' 'BCPREFER' 'RRCLASS3'
 'RRCOGNT2' 'RRTREAT' 'RRATWRK2' 'RRHCARE4' 'RRPHYSM2' 'CAGEG']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-27 21:35:39,090:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'SAFETIME' 'CTELNUM1' 'CELLFON5' 'CADULT1'
 'CELLSEX1' 'PVTRESD3' 'CCLGHOUS' 'CSTATE1' 'LANDLINE' 'HHADULT'
 'LASTDEN4' 'RMVTETH4' 'BLDSTFIT' 'SDNATES1' 'PDIABTS1' 'PREDIAB2'
 'DIABTYPE' 'INSULIN1' 'CHKHEMO3' 'EYEEXAM1' 'DIABEYE1' 'DIABEDU1'
 'FEETSORE' 'TOLDCFS' 'HAVECFS' 'WORKCFS' 'IMFVPLA3' 'HPVADVC4' 'HPVADSHT'
 'SHINGLE2' 'COVIDVA1' 'COVACGET' 'COVIDNU1' 'COVIDINT' 'COVIDFS1'
 'COVIDSE1' 'COPDCOGH' 'COPDFLEM' 'COPDBRTH' 'COPDBTST' 'COPDSMOK'
 'CNCRDIFF' 'CNCRAGE' 'CNCRTYP2' 'CSRVTRT3' 'CSRVDOC1' 'CSRVSUM'
 'CSRVRTRN' 'CSRVINST' 'CSRVINSR' 'CSRVDEIN' 'CSRVCLIN' 'CSRVPAIN'
 'CSRVCTL2' 'PSATEST1' 'PSATIME1' 'PCPSARS2' 'PSASUGST' 'PCSTALK1'
 'CIMEMLOS' 'CDHOUSE' 'CDASSIST' 'CDHELP' 'CDSOCIAL' 'CDDISCUS' 'CAREGIV1'
 'CRGVREL4' 'CRGVLNG1' 'CRGVHRS1' 'CRGVPRB3' 'CRGVALZD' 'CRGVPER1'
 'CRGVHOU1' 'CRGVEXPT' 'ACEDEPRS' 'ACEDRINK' 'ACEDRUGS' 'ACEPRISN'
 'ACEDIVRC' 'ACEPUNCH' 'ACEHURT1' 'ACESWEAR' 'ACETOUCH' 'ACETTHEM'
 'ACEHVSEX' 'ACEADSAF' 'ACEADNED' 'MARIJAN1' 'MARJSMOK' 'MARJEAT'
 'MARJVAPE' 'MARJDAB' 'MARJOTHR' 'USEMRJN4' 'LASTSMK2' 'STOPSMK2'
 'MENTCIGS' 'MENTECIG' 'HEATTBCO' 'ASBIALCH' 'ASBIDRNK' 'ASBIBING'
 'ASBIADVC' 'ASBIRDUC' 'FIREARM5' 'GUNLOAD' 'LOADULK2' 'RCSXBRTH'
 'CASTHNO2' 'BIRTHSEX' 'SOMALE' 'SOFEMALE' 'TRNSGNDR' 'HADSEX' 'PFPPRVN4'
 'TYPCNTR9' 'BRTHCNT4' 'WHEREGET' 'NOBCUSE8' 'BCPREFER' 'RRCLASS3'
 'RRCOGNT2' 'RRTREAT' 'RRATWRK2' 'RRHCARE4' 'RRPHYSM2' 'CAGEG']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-27 21:35:39,104:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'SAFETIME' 'CTELNUM1' 'CELLFON5' 'CADULT1'
 'CELLSEX1' 'PVTRESD3' 'CCLGHOUS' 'CSTATE1' 'LANDLINE' 'HHADULT'
 'LASTDEN4' 'RMVTETH4' 'BLDSTFIT' 'SDNATES1' 'PDIABTS1' 'PREDIAB2'
 'DIABTYPE' 'INSULIN1' 'CHKHEMO3' 'EYEEXAM1' 'DIABEYE1' 'DIABEDU1'
 'FEETSORE' 'TOLDCFS' 'HAVECFS' 'WORKCFS' 'IMFVPLA3' 'HPVADVC4' 'HPVADSHT'
 'SHINGLE2' 'COVIDVA1' 'COVACGET' 'COVIDNU1' 'COVIDINT' 'COVIDFS1'
 'COVIDSE1' 'COPDCOGH' 'COPDFLEM' 'COPDBRTH' 'COPDBTST' 'COPDSMOK'
 'CNCRDIFF' 'CNCRAGE' 'CNCRTYP2' 'CSRVTRT3' 'CSRVDOC1' 'CSRVSUM'
 'CSRVRTRN' 'CSRVINST' 'CSRVINSR' 'CSRVDEIN' 'CSRVCLIN' 'CSRVPAIN'
 'CSRVCTL2' 'PSATEST1' 'PSATIME1' 'PCPSARS2' 'PSASUGST' 'PCSTALK1'
 'CIMEMLOS' 'CDHOUSE' 'CDASSIST' 'CDHELP' 'CDSOCIAL' 'CDDISCUS' 'CAREGIV1'
 'CRGVREL4' 'CRGVLNG1' 'CRGVHRS1' 'CRGVPRB3' 'CRGVALZD' 'CRGVPER1'
 'CRGVHOU1' 'CRGVEXPT' 'ACEDEPRS' 'ACEDRINK' 'ACEDRUGS' 'ACEPRISN'
 'ACEDIVRC' 'ACEPUNCH' 'ACEHURT1' 'ACESWEAR' 'ACETOUCH' 'ACETTHEM'
 'ACEHVSEX' 'ACEADSAF' 'ACEADNED' 'MARIJAN1' 'MARJSMOK' 'MARJEAT'
 'MARJVAPE' 'MARJDAB' 'MARJOTHR' 'USEMRJN4' 'LASTSMK2' 'STOPSMK2'
 'MENTCIGS' 'MENTECIG' 'HEATTBCO' 'ASBIALCH' 'ASBIDRNK' 'ASBIBING'
 'ASBIADVC' 'ASBIRDUC' 'FIREARM5' 'GUNLOAD' 'LOADULK2' 'RCSXBRTH'
 'CASTHNO2' 'BIRTHSEX' 'SOMALE' 'SOFEMALE' 'TRNSGNDR' 'HADSEX' 'PFPPRVN4'
 'TYPCNTR9' 'BRTHCNT4' 'WHEREGET' 'NOBCUSE8' 'BCPREFER' 'RRCLASS3'
 'RRCOGNT2' 'RRTREAT' 'RRATWRK2' 'RRHCARE4' 'RRPHYSM2' 'CAGEG']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-27 21:35:39,105:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'SAFETIME' 'CTELNUM1' 'CELLFON5' 'CADULT1'
 'CELLSEX1' 'PVTRESD3' 'CCLGHOUS' 'CSTATE1' 'LANDLINE' 'HHADULT'
 'LASTDEN4' 'RMVTETH4' 'NUMPHON4' 'BLDSTFIT' 'SDNATES1' 'PDIABTS1'
 'PREDIAB2' 'DIABTYPE' 'INSULIN1' 'CHKHEMO3' 'EYEEXAM1' 'DIABEYE1'
 'DIABEDU1' 'FEETSORE' 'TOLDCFS' 'HAVECFS' 'WORKCFS' 'IMFVPLA3' 'HPVADVC4'
 'HPVADSHT' 'SHINGLE2' 'COVIDVA1' 'COVACGET' 'COVIDNU1' 'COVIDINT'
 'COVIDFS1' 'COVIDSE1' 'COPDCOGH' 'COPDFLEM' 'COPDBRTH' 'COPDBTST'
 'COPDSMOK' 'CNCRDIFF' 'CNCRAGE' 'CNCRTYP2' 'CSRVTRT3' 'CSRVDOC1'
 'CSRVSUM' 'CSRVRTRN' 'CSRVINST' 'CSRVINSR' 'CSRVDEIN' 'CSRVCLIN'
 'CSRVPAIN' 'CSRVCTL2' 'PSATEST1' 'PSATIME1' 'PCPSARS2' 'PSASUGST'
 'PCSTALK1' 'CIMEMLOS' 'CDHOUSE' 'CDASSIST' 'CDHELP' 'CDSOCIAL' 'CDDISCUS'
 'CAREGIV1' 'CRGVREL4' 'CRGVLNG1' 'CRGVHRS1' 'CRGVPRB3' 'CRGVALZD'
 'CRGVPER1' 'CRGVHOU1' 'CRGVEXPT' 'ACEDEPRS' 'ACEDRINK' 'ACEDRUGS'
 'ACEPRISN' 'ACEDIVRC' 'ACEPUNCH' 'ACEHURT1' 'ACESWEAR' 'ACETOUCH'
 'ACETTHEM' 'ACEHVSEX' 'ACEADSAF' 'ACEADNED' 'MARIJAN1' 'MARJSMOK'
 'MARJEAT' 'MARJVAPE' 'MARJDAB' 'MARJOTHR' 'USEMRJN4' 'LASTSMK2'
 'STOPSMK2' 'MENTCIGS' 'MENTECIG' 'HEATTBCO' 'ASBIALCH' 'ASBIDRNK'
 'ASBIBING' 'ASBIADVC' 'ASBIRDUC' 'FIREARM5' 'GUNLOAD' 'LOADULK2'
 'RCSXBRTH' 'CASTHNO2' 'BIRTHSEX' 'SOMALE' 'SOFEMALE' 'TRNSGNDR' 'HADSEX'
 'PFPPRVN4' 'TYPCNTR9' 'BRTHCNT4' 'WHEREGET' 'NOBCUSE8' 'BCPREFER'
 'RRCLASS3' 'RRCOGNT2' 'RRTREAT' 'RRATWRK2' 'RRHCARE4' 'RRPHYSM2' 'CAGEG']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-27 21:35:39,114:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'SAFETIME' 'CTELNUM1' 'CELLFON5' 'CADULT1'
 'CELLSEX1' 'PVTRESD3' 'CCLGHOUS' 'CSTATE1' 'LANDLINE' 'HHADULT'
 'LASTDEN4' 'RMVTETH4' 'BLDSTFIT' 'SDNATES1' 'PDIABTS1' 'PREDIAB2'
 'DIABTYPE' 'INSULIN1' 'CHKHEMO3' 'EYEEXAM1' 'DIABEYE1' 'DIABEDU1'
 'FEETSORE' 'TOLDCFS' 'HAVECFS' 'WORKCFS' 'IMFVPLA3' 'HPVADVC4' 'HPVADSHT'
 'SHINGLE2' 'COVIDVA1' 'COVACGET' 'COVIDNU1' 'COVIDINT' 'COVIDFS1'
 'COVIDSE1' 'COPDCOGH' 'COPDFLEM' 'COPDBRTH' 'COPDBTST' 'COPDSMOK'
 'CNCRDIFF' 'CNCRAGE' 'CNCRTYP2' 'CSRVTRT3' 'CSRVDOC1' 'CSRVSUM'
 'CSRVRTRN' 'CSRVINST' 'CSRVINSR' 'CSRVDEIN' 'CSRVCLIN' 'CSRVPAIN'
 'CSRVCTL2' 'PSATEST1' 'PSATIME1' 'PCPSARS2' 'PSASUGST' 'PCSTALK1'
 'CIMEMLOS' 'CDHOUSE' 'CDASSIST' 'CDHELP' 'CDSOCIAL' 'CDDISCUS' 'CAREGIV1'
 'CRGVREL4' 'CRGVLNG1' 'CRGVHRS1' 'CRGVPRB3' 'CRGVALZD' 'CRGVPER1'
 'CRGVHOU1' 'CRGVEXPT' 'ACEDEPRS' 'ACEDRINK' 'ACEDRUGS' 'ACEPRISN'
 'ACEDIVRC' 'ACEPUNCH' 'ACEHURT1' 'ACESWEAR' 'ACETOUCH' 'ACETTHEM'
 'ACEHVSEX' 'ACEADSAF' 'ACEADNED' 'MARIJAN1' 'MARJSMOK' 'MARJEAT'
 'MARJVAPE' 'MARJDAB' 'MARJOTHR' 'USEMRJN4' 'LASTSMK2' 'STOPSMK2'
 'MENTCIGS' 'MENTECIG' 'HEATTBCO' 'ASBIALCH' 'ASBIDRNK' 'ASBIBING'
 'ASBIADVC' 'ASBIRDUC' 'FIREARM5' 'GUNLOAD' 'LOADULK2' 'RCSXBRTH'
 'CASTHNO2' 'BIRTHSEX' 'SOMALE' 'SOFEMALE' 'TRNSGNDR' 'HADSEX' 'PFPPRVN4'
 'TYPCNTR9' 'BRTHCNT4' 'WHEREGET' 'NOBCUSE8' 'BCPREFER' 'RRCLASS3'
 'RRCOGNT2' 'RRTREAT' 'RRATWRK2' 'RRHCARE4' 'RRPHYSM2' 'CAGEG']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-27 21:35:39,126:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'SAFETIME' 'CTELNUM1' 'CELLFON5' 'CADULT1'
 'CELLSEX1' 'PVTRESD3' 'CCLGHOUS' 'CSTATE1' 'LANDLINE' 'HHADULT'
 'LASTDEN4' 'RMVTETH4' 'LASTSIG4' 'BLDSTFIT' 'SDNATES1' 'PDIABTS1'
 'PREDIAB2' 'DIABTYPE' 'INSULIN1' 'CHKHEMO3' 'EYEEXAM1' 'DIABEYE1'
 'DIABEDU1' 'FEETSORE' 'TOLDCFS' 'HAVECFS' 'WORKCFS' 'IMFVPLA3' 'HPVADVC4'
 'HPVADSHT' 'SHINGLE2' 'COVIDVA1' 'COVACGET' 'COVIDNU1' 'COVIDINT'
 'COVIDFS1' 'COVIDSE1' 'COPDCOGH' 'COPDFLEM' 'COPDBRTH' 'COPDBTST'
 'COPDSMOK' 'CNCRDIFF' 'CNCRAGE' 'CNCRTYP2' 'CSRVTRT3' 'CSRVDOC1'
 'CSRVSUM' 'CSRVRTRN' 'CSRVINST' 'CSRVINSR' 'CSRVDEIN' 'CSRVCLIN'
 'CSRVPAIN' 'CSRVCTL2' 'PSATEST1' 'PSATIME1' 'PCPSARS2' 'PSASUGST'
 'PCSTALK1' 'CIMEMLOS' 'CDHOUSE' 'CDASSIST' 'CDHELP' 'CDSOCIAL' 'CDDISCUS'
 'CAREGIV1' 'CRGVREL4' 'CRGVLNG1' 'CRGVHRS1' 'CRGVPRB3' 'CRGVALZD'
 'CRGVPER1' 'CRGVHOU1' 'CRGVEXPT' 'ACEDEPRS' 'ACEDRINK' 'ACEDRUGS'
 'ACEPRISN' 'ACEDIVRC' 'ACEPUNCH' 'ACEHURT1' 'ACESWEAR' 'ACETOUCH'
 'ACETTHEM' 'ACEHVSEX' 'ACEADSAF' 'ACEADNED' 'MARIJAN1' 'MARJSMOK'
 'MARJEAT' 'MARJVAPE' 'MARJDAB' 'MARJOTHR' 'USEMRJN4' 'LASTSMK2'
 'STOPSMK2' 'MENTCIGS' 'MENTECIG' 'HEATTBCO' 'ASBIALCH' 'ASBIDRNK'
 'ASBIBING' 'ASBIADVC' 'ASBIRDUC' 'FIREARM5' 'GUNLOAD' 'LOADULK2'
 'RCSXBRTH' 'CASTHNO2' 'BIRTHSEX' 'SOMALE' 'SOFEMALE' 'TRNSGNDR' 'HADSEX'
 'PFPPRVN4' 'TYPCNTR9' 'BRTHCNT4' 'WHEREGET' 'NOBCUSE8' 'BCPREFER'
 'RRCLASS3' 'RRCOGNT2' 'RRTREAT' 'RRATWRK2' 'RRHCARE4' 'RRPHYSM2' 'CAGEG']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-27 21:35:39,168:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'SAFETIME' 'CTELNUM1' 'CELLFON5' 'CADULT1'
 'CELLSEX1' 'PVTRESD3' 'CCLGHOUS' 'CSTATE1' 'LANDLINE' 'HHADULT'
 'LASTDEN4' 'RMVTETH4' 'BLDSTFIT' 'SDNATES1' 'PDIABTS1' 'PREDIAB2'
 'DIABTYPE' 'INSULIN1' 'CHKHEMO3' 'EYEEXAM1' 'DIABEYE1' 'DIABEDU1'
 'FEETSORE' 'TOLDCFS' 'HAVECFS' 'WORKCFS' 'IMFVPLA3' 'HPVADVC4' 'HPVADSHT'
 'SHINGLE2' 'COVIDVA1' 'COVACGET' 'COVIDNU1' 'COVIDINT' 'COVIDFS1'
 'COVIDSE1' 'COPDCOGH' 'COPDFLEM' 'COPDBRTH' 'COPDBTST' 'COPDSMOK'
 'CNCRDIFF' 'CNCRAGE' 'CNCRTYP2' 'CSRVTRT3' 'CSRVDOC1' 'CSRVSUM'
 'CSRVRTRN' 'CSRVINST' 'CSRVINSR' 'CSRVDEIN' 'CSRVCLIN' 'CSRVPAIN'
 'CSRVCTL2' 'PSATEST1' 'PSATIME1' 'PCPSARS2' 'PSASUGST' 'PCSTALK1'
 'CIMEMLOS' 'CDHOUSE' 'CDASSIST' 'CDHELP' 'CDSOCIAL' 'CDDISCUS' 'CAREGIV1'
 'CRGVREL4' 'CRGVLNG1' 'CRGVHRS1' 'CRGVPRB3' 'CRGVALZD' 'CRGVPER1'
 'CRGVHOU1' 'CRGVEXPT' 'ACEDEPRS' 'ACEDRINK' 'ACEDRUGS' 'ACEPRISN'
 'ACEDIVRC' 'ACEPUNCH' 'ACEHURT1' 'ACESWEAR' 'ACETOUCH' 'ACETTHEM'
 'ACEHVSEX' 'ACEADSAF' 'ACEADNED' 'MARIJAN1' 'MARJSMOK' 'MARJEAT'
 'MARJVAPE' 'MARJDAB' 'MARJOTHR' 'USEMRJN4' 'LASTSMK2' 'STOPSMK2'
 'MENTCIGS' 'MENTECIG' 'HEATTBCO' 'ASBIALCH' 'ASBIDRNK' 'ASBIBING'
 'ASBIADVC' 'ASBIRDUC' 'FIREARM5' 'GUNLOAD' 'LOADULK2' 'RCSGEND1'
 'RCSXBRTH' 'RCSRLTN2' 'CASTHDX2' 'CASTHNO2' 'BIRTHSEX' 'SOMALE'
 'SOFEMALE' 'TRNSGNDR' 'HADSEX' 'PFPPRVN4' 'TYPCNTR9' 'BRTHCNT4'
 'WHEREGET' 'NOBCUSE8' 'BCPREFER' 'RRCLASS3' 'RRCOGNT2' 'RRTREAT'
 'RRATWRK2' 'RRHCARE4' 'RRPHYSM2' 'CRACE2' 'CPRACE2' 'CAGEG' 'CLLCPWT']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-27 21:35:39,190:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-11-27 21:35:39,192:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-11-27 21:35:39,192:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-11-27 21:35:39,195:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-11-27 21:35:39,195:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-11-27 21:35:39,196:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-11-27 21:35:39,198:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-27 21:35:39,198:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-27 21:35:39,198:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-27 21:35:39,204:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-11-27 21:35:39,204:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-11-27 21:35:39,210:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-11-27 21:35:39,210:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-11-27 21:35:39,210:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-27 21:35:39,210:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-27 21:35:39,210:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-27 21:35:39,214:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-11-27 21:35:39,217:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-11-27 21:35:39,218:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-11-27 21:35:39,220:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-11-27 21:35:39,220:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-27 21:35:39,220:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-27 21:35:39,220:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-27 21:35:40,931:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-27 21:35:40,937:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-27 21:35:41,075:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'SAFETIME' 'CTELNUM1' 'CELLFON5' 'CADULT1'
 'CELLSEX1' 'PVTRESD3' 'CCLGHOUS' 'CSTATE1' 'LANDLINE' 'HHADULT'
 'LASTDEN4' 'RMVTETH4' 'BLDSTFIT' 'SDNATES1' 'COVIDPRM' 'PDIABTS1'
 'PREDIAB2' 'DIABTYPE' 'INSULIN1' 'CHKHEMO3' 'EYEEXAM1' 'DIABEYE1'
 'DIABEDU1' 'FEETSORE' 'TOLDCFS' 'HAVECFS' 'WORKCFS' 'IMFVPLA3' 'HPVADVC4'
 'HPVADSHT' 'SHINGLE2' 'COVIDVA1' 'COVACGET' 'COVIDNU1' 'COVIDINT'
 'COVIDFS1' 'COVIDSE1' 'COPDCOGH' 'COPDFLEM' 'COPDBRTH' 'COPDBTST'
 'COPDSMOK' 'CNCRDIFF' 'CNCRAGE' 'CNCRTYP2' 'CSRVTRT3' 'CSRVDOC1'
 'CSRVSUM' 'CSRVRTRN' 'CSRVINST' 'CSRVINSR' 'CSRVDEIN' 'CSRVCLIN'
 'CSRVPAIN' 'CSRVCTL2' 'PSATEST1' 'PSATIME1' 'PCPSARS2' 'PSASUGST'
 'PCSTALK1' 'CIMEMLOS' 'CDHOUSE' 'CDASSIST' 'CDHELP' 'CDSOCIAL' 'CDDISCUS'
 'CAREGIV1' 'CRGVREL4' 'CRGVLNG1' 'CRGVHRS1' 'CRGVPRB3' 'CRGVALZD'
 'CRGVPER1' 'CRGVHOU1' 'CRGVEXPT' 'ACEDEPRS' 'ACEDRINK' 'ACEDRUGS'
 'ACEPRISN' 'ACEDIVRC' 'ACEPUNCH' 'ACEHURT1' 'ACESWEAR' 'ACETOUCH'
 'ACETTHEM' 'ACEHVSEX' 'ACEADSAF' 'ACEADNED' 'MARIJAN1' 'MARJSMOK'
 'MARJEAT' 'MARJVAPE' 'MARJDAB' 'MARJOTHR' 'USEMRJN4' 'LASTSMK2'
 'STOPSMK2' 'MENTCIGS' 'MENTECIG' 'HEATTBCO' 'ASBIALCH' 'ASBIDRNK'
 'ASBIBING' 'ASBIADVC' 'ASBIRDUC' 'FIREARM5' 'GUNLOAD' 'LOADULK2'
 'RCSXBRTH' 'CASTHNO2' 'BIRTHSEX' 'SOMALE' 'SOFEMALE' 'TRNSGNDR' 'HADSEX'
 'PFPPRVN4' 'TYPCNTR9' 'BRTHCNT4' 'WHEREGET' 'NOBCUSE8' 'BCPREFER'
 'RRCLASS3' 'RRCOGNT2' 'RRTREAT' 'RRATWRK2' 'RRHCARE4' 'RRPHYSM2' 'CAGEG']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-27 21:35:41,075:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'SAFETIME' 'CTELNUM1' 'CELLFON5' 'CADULT1'
 'CELLSEX1' 'PVTRESD3' 'CCLGHOUS' 'CSTATE1' 'LANDLINE' 'HHADULT'
 'LASTDEN4' 'RMVTETH4' 'BLDSTFIT' 'SDNATES1' 'PDIABTS1' 'PREDIAB2'
 'DIABTYPE' 'INSULIN1' 'CHKHEMO3' 'EYEEXAM1' 'DIABEYE1' 'DIABEDU1'
 'FEETSORE' 'TOLDCFS' 'HAVECFS' 'WORKCFS' 'IMFVPLA3' 'HPVADVC4' 'HPVADSHT'
 'SHINGLE2' 'COVIDVA1' 'COVACGET' 'COVIDNU1' 'COVIDINT' 'COVIDFS1'
 'COVIDSE1' 'COPDCOGH' 'COPDFLEM' 'COPDBRTH' 'COPDBTST' 'COPDSMOK'
 'CNCRDIFF' 'CNCRAGE' 'CNCRTYP2' 'CSRVTRT3' 'CSRVDOC1' 'CSRVSUM'
 'CSRVRTRN' 'CSRVINST' 'CSRVINSR' 'CSRVDEIN' 'CSRVCLIN' 'CSRVPAIN'
 'CSRVCTL2' 'PSATEST1' 'PSATIME1' 'PCPSARS2' 'PSASUGST' 'PCSTALK1'
 'CIMEMLOS' 'CDHOUSE' 'CDASSIST' 'CDHELP' 'CDSOCIAL' 'CDDISCUS' 'CAREGIV1'
 'CRGVREL4' 'CRGVLNG1' 'CRGVHRS1' 'CRGVPRB3' 'CRGVALZD' 'CRGVPER1'
 'CRGVHOU1' 'CRGVEXPT' 'ACEDEPRS' 'ACEDRINK' 'ACEDRUGS' 'ACEPRISN'
 'ACEDIVRC' 'ACEPUNCH' 'ACEHURT1' 'ACESWEAR' 'ACETOUCH' 'ACETTHEM'
 'ACEHVSEX' 'ACEADSAF' 'ACEADNED' 'MARIJAN1' 'MARJSMOK' 'MARJEAT'
 'MARJVAPE' 'MARJDAB' 'MARJOTHR' 'USEMRJN4' 'LASTSMK2' 'STOPSMK2'
 'MENTCIGS' 'MENTECIG' 'HEATTBCO' 'ASBIALCH' 'ASBIDRNK' 'ASBIBING'
 'ASBIADVC' 'ASBIRDUC' 'FIREARM5' 'GUNLOAD' 'LOADULK2' 'RCSXBRTH'
 'CASTHNO2' 'BIRTHSEX' 'SOMALE' 'SOFEMALE' 'TRNSGNDR' 'HADSEX' 'PFPPRVN4'
 'TYPCNTR9' 'BRTHCNT4' 'WHEREGET' 'NOBCUSE8' 'BCPREFER' 'RRCLASS3'
 'RRCOGNT2' 'RRTREAT' 'RRATWRK2' 'RRHCARE4' 'RRPHYSM2' 'CAGEG']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-27 21:35:41,123:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'SAFETIME' 'CTELNUM1' 'CELLFON5' 'CADULT1'
 'CELLSEX1' 'PVTRESD3' 'CCLGHOUS' 'CSTATE1' 'LANDLINE' 'HHADULT'
 'LASTDEN4' 'RMVTETH4' 'BLDSTFIT' 'SDNATES1' 'COVIDPRM' 'PDIABTS1'
 'PREDIAB2' 'DIABTYPE' 'INSULIN1' 'CHKHEMO3' 'EYEEXAM1' 'DIABEYE1'
 'DIABEDU1' 'FEETSORE' 'TOLDCFS' 'HAVECFS' 'WORKCFS' 'IMFVPLA3' 'HPVADVC4'
 'HPVADSHT' 'SHINGLE2' 'COVIDVA1' 'COVACGET' 'COVIDNU1' 'COVIDINT'
 'COVIDFS1' 'COVIDSE1' 'COPDCOGH' 'COPDFLEM' 'COPDBRTH' 'COPDBTST'
 'COPDSMOK' 'CNCRDIFF' 'CNCRAGE' 'CNCRTYP2' 'CSRVTRT3' 'CSRVDOC1'
 'CSRVSUM' 'CSRVRTRN' 'CSRVINST' 'CSRVINSR' 'CSRVDEIN' 'CSRVCLIN'
 'CSRVPAIN' 'CSRVCTL2' 'PSATEST1' 'PSATIME1' 'PCPSARS2' 'PSASUGST'
 'PCSTALK1' 'CIMEMLOS' 'CDHOUSE' 'CDASSIST' 'CDHELP' 'CDSOCIAL' 'CDDISCUS'
 'CAREGIV1' 'CRGVREL4' 'CRGVLNG1' 'CRGVHRS1' 'CRGVPRB3' 'CRGVALZD'
 'CRGVPER1' 'CRGVHOU1' 'CRGVEXPT' 'ACEDEPRS' 'ACEDRINK' 'ACEDRUGS'
 'ACEPRISN' 'ACEDIVRC' 'ACEPUNCH' 'ACEHURT1' 'ACESWEAR' 'ACETOUCH'
 'ACETTHEM' 'ACEHVSEX' 'ACEADSAF' 'ACEADNED' 'MARIJAN1' 'MARJSMOK'
 'MARJEAT' 'MARJVAPE' 'MARJDAB' 'MARJOTHR' 'USEMRJN4' 'LASTSMK2'
 'STOPSMK2' 'MENTCIGS' 'MENTECIG' 'HEATTBCO' 'ASBIALCH' 'ASBIDRNK'
 'ASBIBING' 'ASBIADVC' 'ASBIRDUC' 'FIREARM5' 'GUNLOAD' 'LOADULK2'
 'RCSXBRTH' 'CASTHNO2' 'BIRTHSEX' 'SOMALE' 'SOFEMALE' 'TRNSGNDR' 'HADSEX'
 'PFPPRVN4' 'TYPCNTR9' 'BRTHCNT4' 'WHEREGET' 'NOBCUSE8' 'BCPREFER'
 'RRCLASS3' 'RRCOGNT2' 'RRTREAT' 'RRATWRK2' 'RRHCARE4' 'RRPHYSM2' 'CAGEG']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-27 21:35:41,125:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'SAFETIME' 'CTELNUM1' 'CELLFON5' 'CADULT1'
 'CELLSEX1' 'PVTRESD3' 'CCLGHOUS' 'CSTATE1' 'LANDLINE' 'HHADULT'
 'LASTDEN4' 'RMVTETH4' 'BLDSTFIT' 'SDNATES1' 'PDIABTS1' 'PREDIAB2'
 'DIABTYPE' 'INSULIN1' 'CHKHEMO3' 'EYEEXAM1' 'DIABEYE1' 'DIABEDU1'
 'FEETSORE' 'TOLDCFS' 'HAVECFS' 'WORKCFS' 'IMFVPLA3' 'HPVADVC4' 'HPVADSHT'
 'SHINGLE2' 'COVIDVA1' 'COVACGET' 'COVIDNU1' 'COVIDINT' 'COVIDFS1'
 'COVIDSE1' 'COPDCOGH' 'COPDFLEM' 'COPDBRTH' 'COPDBTST' 'COPDSMOK'
 'CNCRDIFF' 'CNCRAGE' 'CNCRTYP2' 'CSRVTRT3' 'CSRVDOC1' 'CSRVSUM'
 'CSRVRTRN' 'CSRVINST' 'CSRVINSR' 'CSRVDEIN' 'CSRVCLIN' 'CSRVPAIN'
 'CSRVCTL2' 'PSATEST1' 'PSATIME1' 'PCPSARS2' 'PSASUGST' 'PCSTALK1'
 'CIMEMLOS' 'CDHOUSE' 'CDASSIST' 'CDHELP' 'CDSOCIAL' 'CDDISCUS' 'CAREGIV1'
 'CRGVREL4' 'CRGVLNG1' 'CRGVHRS1' 'CRGVPRB3' 'CRGVALZD' 'CRGVPER1'
 'CRGVHOU1' 'CRGVEXPT' 'ACEDEPRS' 'ACEDRINK' 'ACEDRUGS' 'ACEPRISN'
 'ACEDIVRC' 'ACEPUNCH' 'ACEHURT1' 'ACESWEAR' 'ACETOUCH' 'ACETTHEM'
 'ACEHVSEX' 'ACEADSAF' 'ACEADNED' 'MARIJAN1' 'MARJSMOK' 'MARJEAT'
 'MARJVAPE' 'MARJDAB' 'MARJOTHR' 'USEMRJN4' 'LASTSMK2' 'STOPSMK2'
 'MENTCIGS' 'MENTECIG' 'HEATTBCO' 'ASBIALCH' 'ASBIDRNK' 'ASBIBING'
 'ASBIADVC' 'ASBIRDUC' 'FIREARM5' 'GUNLOAD' 'LOADULK2' 'RCSXBRTH'
 'CASTHNO2' 'BIRTHSEX' 'SOMALE' 'SOFEMALE' 'TRNSGNDR' 'HADSEX' 'PFPPRVN4'
 'TYPCNTR9' 'BRTHCNT4' 'WHEREGET' 'NOBCUSE8' 'BCPREFER' 'RRCLASS3'
 'RRCOGNT2' 'RRTREAT' 'RRATWRK2' 'RRHCARE4' 'RRPHYSM2' 'CAGEG']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-27 21:35:41,175:INFO:Calculating mean and std
2025-11-27 21:35:41,175:INFO:Creating metrics dataframe
2025-11-27 21:35:41,177:INFO:Uploading results into container
2025-11-27 21:35:41,177:INFO:Uploading model into container now
2025-11-27 21:35:41,177:INFO:_master_model_container: 2
2025-11-27 21:35:41,177:INFO:_display_container: 2
2025-11-27 21:35:41,177:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best')
2025-11-27 21:35:41,177:INFO:create_model() successfully completed......................................
2025-11-27 21:35:41,278:INFO:SubProcess create_model() end ==================================
2025-11-27 21:35:41,278:INFO:Creating metrics dataframe
2025-11-27 21:35:41,285:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  master_display_.apply(

2025-11-27 21:35:41,285:INFO:Initializing create_model()
2025-11-27 21:35:41,285:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024612C71C30>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-27 21:35:41,285:INFO:Checking exceptions
2025-11-27 21:35:41,285:INFO:Importing libraries
2025-11-27 21:35:41,285:INFO:Copying training dataset
2025-11-27 21:35:41,308:INFO:Defining folds
2025-11-27 21:35:41,309:INFO:Declaring metric variables
2025-11-27 21:35:41,309:INFO:Importing untrained model
2025-11-27 21:35:41,309:INFO:Declaring custom model
2025-11-27 21:35:41,309:INFO:Decision Tree Classifier Imported successfully
2025-11-27 21:35:41,310:INFO:Cross validation set to False
2025-11-27 21:35:41,310:INFO:Fitting Model
2025-11-27 21:35:41,322:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'SAFETIME' 'CTELNUM1' 'CELLFON5' 'CADULT1'
 'CELLSEX1' 'PVTRESD3' 'CCLGHOUS' 'CSTATE1' 'LANDLINE' 'HHADULT'
 'LASTDEN4' 'RMVTETH4' 'BLDSTFIT' 'SDNATES1' 'PDIABTS1' 'PREDIAB2'
 'DIABTYPE' 'INSULIN1' 'CHKHEMO3' 'EYEEXAM1' 'DIABEYE1' 'DIABEDU1'
 'FEETSORE' 'TOLDCFS' 'HAVECFS' 'WORKCFS' 'IMFVPLA3' 'HPVADVC4' 'HPVADSHT'
 'SHINGLE2' 'COVIDVA1' 'COVACGET' 'COVIDNU1' 'COVIDINT' 'COVIDFS1'
 'COVIDSE1' 'COPDCOGH' 'COPDFLEM' 'COPDBRTH' 'COPDBTST' 'COPDSMOK'
 'CNCRDIFF' 'CNCRAGE' 'CNCRTYP2' 'CSRVTRT3' 'CSRVDOC1' 'CSRVSUM'
 'CSRVRTRN' 'CSRVINST' 'CSRVINSR' 'CSRVDEIN' 'CSRVCLIN' 'CSRVPAIN'
 'CSRVCTL2' 'PSATEST1' 'PSATIME1' 'PCPSARS2' 'PSASUGST' 'PCSTALK1'
 'CIMEMLOS' 'CDHOUSE' 'CDASSIST' 'CDHELP' 'CDSOCIAL' 'CDDISCUS' 'CAREGIV1'
 'CRGVREL4' 'CRGVLNG1' 'CRGVHRS1' 'CRGVPRB3' 'CRGVALZD' 'CRGVPER1'
 'CRGVHOU1' 'CRGVEXPT' 'ACEDEPRS' 'ACEDRINK' 'ACEDRUGS' 'ACEPRISN'
 'ACEDIVRC' 'ACEPUNCH' 'ACEHURT1' 'ACESWEAR' 'ACETOUCH' 'ACETTHEM'
 'ACEHVSEX' 'ACEADSAF' 'ACEADNED' 'MARIJAN1' 'MARJSMOK' 'MARJEAT'
 'MARJVAPE' 'MARJDAB' 'MARJOTHR' 'USEMRJN4' 'LASTSMK2' 'STOPSMK2'
 'MENTCIGS' 'MENTECIG' 'HEATTBCO' 'ASBIALCH' 'ASBIDRNK' 'ASBIBING'
 'ASBIADVC' 'ASBIRDUC' 'FIREARM5' 'GUNLOAD' 'LOADULK2' 'RCSXBRTH'
 'CASTHNO2' 'BIRTHSEX' 'SOMALE' 'SOFEMALE' 'TRNSGNDR' 'HADSEX' 'PFPPRVN4'
 'TYPCNTR9' 'BRTHCNT4' 'WHEREGET' 'NOBCUSE8' 'BCPREFER' 'RRCLASS3'
 'RRCOGNT2' 'RRTREAT' 'RRATWRK2' 'RRHCARE4' 'RRPHYSM2' 'CAGEG']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-27 21:35:41,364:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best')
2025-11-27 21:35:41,364:INFO:create_model() successfully completed......................................
2025-11-27 21:35:41,472:INFO:_master_model_container: 2
2025-11-27 21:35:41,472:INFO:_display_container: 2
2025-11-27 21:35:41,472:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best')
2025-11-27 21:35:41,472:INFO:compare_models() successfully completed......................................
2025-11-27 21:41:07,306:INFO:Initializing predict_model()
2025-11-27 21:41:07,306:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024612C71C30>, estimator=<__main__.MockModel object at 0x00000246A05C0CD0>, probability_threshold=None, encoded_labels=False, raw_score=True, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002467E654B80>)
2025-11-27 21:41:07,306:INFO:Checking exceptions
2025-11-27 21:41:07,306:INFO:Preloading libraries
2025-11-27 21:41:07,306:INFO:Set up data.
2025-11-27 21:41:07,308:INFO:Set up index.
2025-11-27 21:41:07,308:INFO:Initializing predict_model()
2025-11-27 21:41:07,310:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024612C71C30>, estimator=<__main__.MockModel object at 0x00000246A05C0CD0>, probability_threshold=None, encoded_labels=False, raw_score=True, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002467E654B80>)
2025-11-27 21:41:07,310:INFO:Checking exceptions
2025-11-27 21:41:07,310:INFO:Preloading libraries
2025-11-27 21:41:07,310:INFO:Set up data.
2025-11-27 21:41:07,312:INFO:Set up index.
2025-11-28 15:00:09,716:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-11-28 15:00:09,716:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-11-28 15:00:09,716:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-11-28 15:00:09,716:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-11-28 15:12:30,382:INFO:PyCaret ClassificationExperiment
2025-11-28 15:12:30,384:INFO:Logging name: clf-default-name
2025-11-28 15:12:30,384:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-11-28 15:12:30,384:INFO:version 3.3.2
2025-11-28 15:12:30,384:INFO:Initializing setup()
2025-11-28 15:12:30,384:INFO:self.USI: efbb
2025-11-28 15:12:30,384:INFO:self._variable_keys: {'USI', 'memory', '_ml_usecase', 'data', 'logging_param', 'target_param', 'y_test', 'gpu_param', 'fix_imbalance', 'exp_id', 'gpu_n_jobs_param', 'seed', 'fold_shuffle_param', 'log_plots_param', 'X', 'is_multiclass', 'pipeline', 'y', 'fold_groups_param', 'X_test', 'n_jobs_param', 'idx', 'X_train', '_available_plots', 'exp_name_log', 'y_train', 'fold_generator', 'html_param'}
2025-11-28 15:12:30,384:INFO:Checking environment
2025-11-28 15:12:30,384:INFO:python_version: 3.10.19
2025-11-28 15:12:30,384:INFO:python_build: ('main', 'Oct 22 2025 22:23:22')
2025-11-28 15:12:30,384:INFO:machine: AMD64
2025-11-28 15:12:30,384:INFO:platform: Windows-10-10.0.26200-SP0
2025-11-28 15:12:30,384:INFO:Memory: svmem(total=16282144768, available=1869496320, percent=88.5, used=14412648448, free=1869496320)
2025-11-28 15:12:30,384:INFO:Physical Core: 6
2025-11-28 15:12:30,384:INFO:Logical Core: 12
2025-11-28 15:12:30,384:INFO:Checking libraries
2025-11-28 15:12:30,384:INFO:System:
2025-11-28 15:12:30,384:INFO:    python: 3.10.19 | packaged by conda-forge | (main, Oct 22 2025, 22:23:22) [MSC v.1944 64 bit (AMD64)]
2025-11-28 15:12:30,384:INFO:executable: c:\Users\OMAR\miniconda3\envs\xgb_env\python.exe
2025-11-28 15:12:30,384:INFO:   machine: Windows-10-10.0.26200-SP0
2025-11-28 15:12:30,384:INFO:PyCaret required dependencies:
2025-11-28 15:12:30,386:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-28 15:12:30,448:INFO:                 pip: 25.3
2025-11-28 15:12:30,448:INFO:          setuptools: 80.9.0
2025-11-28 15:12:30,448:INFO:             pycaret: 3.3.2
2025-11-28 15:12:30,448:INFO:             IPython: 8.37.0
2025-11-28 15:12:30,448:INFO:          ipywidgets: 8.1.8
2025-11-28 15:12:30,448:INFO:                tqdm: 4.67.1
2025-11-28 15:12:30,448:INFO:               numpy: 1.26.4
2025-11-28 15:12:30,449:INFO:              pandas: 2.1.4
2025-11-28 15:12:30,449:INFO:              jinja2: 3.1.6
2025-11-28 15:12:30,449:INFO:               scipy: 1.11.4
2025-11-28 15:12:30,449:INFO:              joblib: 1.3.2
2025-11-28 15:12:30,449:INFO:             sklearn: 1.4.2
2025-11-28 15:12:30,449:INFO:                pyod: 2.0.5
2025-11-28 15:12:30,449:INFO:            imblearn: 0.14.0
2025-11-28 15:12:30,449:INFO:   category_encoders: 2.7.0
2025-11-28 15:12:30,449:INFO:            lightgbm: 4.6.0
2025-11-28 15:12:30,449:INFO:               numba: 0.62.1
2025-11-28 15:12:30,449:INFO:            requests: 2.32.5
2025-11-28 15:12:30,449:INFO:          matplotlib: 3.7.5
2025-11-28 15:12:30,449:INFO:          scikitplot: 0.3.7
2025-11-28 15:12:30,449:INFO:         yellowbrick: 1.5
2025-11-28 15:12:30,449:INFO:              plotly: 6.5.0
2025-11-28 15:12:30,449:INFO:    plotly-resampler: Not installed
2025-11-28 15:12:30,449:INFO:             kaleido: 1.2.0
2025-11-28 15:12:30,449:INFO:           schemdraw: 0.15
2025-11-28 15:12:30,449:INFO:         statsmodels: 0.14.5
2025-11-28 15:12:30,449:INFO:              sktime: 0.26.0
2025-11-28 15:12:30,449:INFO:               tbats: 1.1.3
2025-11-28 15:12:30,449:INFO:            pmdarima: 2.0.4
2025-11-28 15:12:30,449:INFO:              psutil: 7.1.3
2025-11-28 15:12:30,449:INFO:          markupsafe: 3.0.3
2025-11-28 15:12:30,449:INFO:             pickle5: Not installed
2025-11-28 15:12:30,449:INFO:         cloudpickle: 3.1.2
2025-11-28 15:12:30,449:INFO:         deprecation: 2.1.0
2025-11-28 15:12:30,449:INFO:              xxhash: 3.6.0
2025-11-28 15:12:30,449:INFO:           wurlitzer: Not installed
2025-11-28 15:12:30,449:INFO:PyCaret optional dependencies:
2025-11-28 15:12:30,497:INFO:                shap: 0.48.0
2025-11-28 15:12:30,497:INFO:           interpret: Not installed
2025-11-28 15:12:30,497:INFO:                umap: Not installed
2025-11-28 15:12:30,497:INFO:     ydata_profiling: Not installed
2025-11-28 15:12:30,497:INFO:  explainerdashboard: Not installed
2025-11-28 15:12:30,497:INFO:             autoviz: Not installed
2025-11-28 15:12:30,497:INFO:           fairlearn: 0.12.0.dev0
2025-11-28 15:12:30,497:INFO:          deepchecks: Not installed
2025-11-28 15:12:30,497:INFO:             xgboost: 3.1.2
2025-11-28 15:12:30,497:INFO:            catboost: Not installed
2025-11-28 15:12:30,497:INFO:              kmodes: Not installed
2025-11-28 15:12:30,497:INFO:             mlxtend: Not installed
2025-11-28 15:12:30,497:INFO:       statsforecast: Not installed
2025-11-28 15:12:30,497:INFO:        tune_sklearn: Not installed
2025-11-28 15:12:30,497:INFO:                 ray: Not installed
2025-11-28 15:12:30,498:INFO:            hyperopt: Not installed
2025-11-28 15:12:30,498:INFO:              optuna: Not installed
2025-11-28 15:12:30,498:INFO:               skopt: Not installed
2025-11-28 15:12:30,498:INFO:              mlflow: Not installed
2025-11-28 15:12:30,498:INFO:              gradio: Not installed
2025-11-28 15:12:30,498:INFO:             fastapi: Not installed
2025-11-28 15:12:30,498:INFO:             uvicorn: Not installed
2025-11-28 15:12:30,498:INFO:              m2cgen: Not installed
2025-11-28 15:12:30,498:INFO:           evidently: Not installed
2025-11-28 15:12:30,498:INFO:               fugue: Not installed
2025-11-28 15:12:30,498:INFO:           streamlit: 1.51.0
2025-11-28 15:12:30,498:INFO:             prophet: Not installed
2025-11-28 15:12:30,498:INFO:None
2025-11-28 15:12:30,498:INFO:Set up data.
2025-11-28 15:43:51,874:INFO:PyCaret ClassificationExperiment
2025-11-28 15:43:51,874:INFO:Logging name: clf-default-name
2025-11-28 15:43:51,874:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-11-28 15:43:51,874:INFO:version 3.3.2
2025-11-28 15:43:51,874:INFO:Initializing setup()
2025-11-28 15:43:51,874:INFO:self.USI: 3f34
2025-11-28 15:43:51,874:INFO:self._variable_keys: {'USI', 'memory', '_ml_usecase', 'data', 'logging_param', 'target_param', 'y_test', 'gpu_param', 'fix_imbalance', 'exp_id', 'gpu_n_jobs_param', 'seed', 'fold_shuffle_param', 'log_plots_param', 'X', 'is_multiclass', 'pipeline', 'y', 'fold_groups_param', 'X_test', 'n_jobs_param', 'idx', 'X_train', '_available_plots', 'exp_name_log', 'y_train', 'fold_generator', 'html_param'}
2025-11-28 15:43:51,874:INFO:Checking environment
2025-11-28 15:43:51,874:INFO:python_version: 3.10.19
2025-11-28 15:43:51,874:INFO:python_build: ('main', 'Oct 22 2025 22:23:22')
2025-11-28 15:43:51,874:INFO:machine: AMD64
2025-11-28 15:43:51,874:INFO:platform: Windows-10-10.0.26200-SP0
2025-11-28 15:43:51,874:INFO:Memory: svmem(total=16282144768, available=2224078848, percent=86.3, used=14058065920, free=2224078848)
2025-11-28 15:43:51,874:INFO:Physical Core: 6
2025-11-28 15:43:51,874:INFO:Logical Core: 12
2025-11-28 15:43:51,874:INFO:Checking libraries
2025-11-28 15:43:51,874:INFO:System:
2025-11-28 15:43:51,874:INFO:    python: 3.10.19 | packaged by conda-forge | (main, Oct 22 2025, 22:23:22) [MSC v.1944 64 bit (AMD64)]
2025-11-28 15:43:51,874:INFO:executable: c:\Users\OMAR\miniconda3\envs\xgb_env\python.exe
2025-11-28 15:43:51,874:INFO:   machine: Windows-10-10.0.26200-SP0
2025-11-28 15:43:51,874:INFO:PyCaret required dependencies:
2025-11-28 15:43:51,874:INFO:                 pip: 25.3
2025-11-28 15:43:51,874:INFO:          setuptools: 80.9.0
2025-11-28 15:43:51,874:INFO:             pycaret: 3.3.2
2025-11-28 15:43:51,874:INFO:             IPython: 8.37.0
2025-11-28 15:43:51,874:INFO:          ipywidgets: 8.1.8
2025-11-28 15:43:51,874:INFO:                tqdm: 4.67.1
2025-11-28 15:43:51,874:INFO:               numpy: 1.26.4
2025-11-28 15:43:51,874:INFO:              pandas: 2.1.4
2025-11-28 15:43:51,874:INFO:              jinja2: 3.1.6
2025-11-28 15:43:51,874:INFO:               scipy: 1.11.4
2025-11-28 15:43:51,874:INFO:              joblib: 1.3.2
2025-11-28 15:43:51,874:INFO:             sklearn: 1.4.2
2025-11-28 15:43:51,874:INFO:                pyod: 2.0.5
2025-11-28 15:43:51,874:INFO:            imblearn: 0.14.0
2025-11-28 15:43:51,874:INFO:   category_encoders: 2.7.0
2025-11-28 15:43:51,874:INFO:            lightgbm: 4.6.0
2025-11-28 15:43:51,874:INFO:               numba: 0.62.1
2025-11-28 15:43:51,874:INFO:            requests: 2.32.5
2025-11-28 15:43:51,874:INFO:          matplotlib: 3.7.5
2025-11-28 15:43:51,874:INFO:          scikitplot: 0.3.7
2025-11-28 15:43:51,874:INFO:         yellowbrick: 1.5
2025-11-28 15:43:51,874:INFO:              plotly: 6.5.0
2025-11-28 15:43:51,874:INFO:    plotly-resampler: Not installed
2025-11-28 15:43:51,874:INFO:             kaleido: 1.2.0
2025-11-28 15:43:51,874:INFO:           schemdraw: 0.15
2025-11-28 15:43:51,874:INFO:         statsmodels: 0.14.5
2025-11-28 15:43:51,874:INFO:              sktime: 0.26.0
2025-11-28 15:43:51,874:INFO:               tbats: 1.1.3
2025-11-28 15:43:51,874:INFO:            pmdarima: 2.0.4
2025-11-28 15:43:51,874:INFO:              psutil: 7.1.3
2025-11-28 15:43:51,874:INFO:          markupsafe: 3.0.3
2025-11-28 15:43:51,874:INFO:             pickle5: Not installed
2025-11-28 15:43:51,878:INFO:         cloudpickle: 3.1.2
2025-11-28 15:43:51,878:INFO:         deprecation: 2.1.0
2025-11-28 15:43:51,878:INFO:              xxhash: 3.6.0
2025-11-28 15:43:51,878:INFO:           wurlitzer: Not installed
2025-11-28 15:43:51,878:INFO:PyCaret optional dependencies:
2025-11-28 15:43:51,878:INFO:                shap: 0.48.0
2025-11-28 15:43:51,878:INFO:           interpret: Not installed
2025-11-28 15:43:51,878:INFO:                umap: Not installed
2025-11-28 15:43:51,878:INFO:     ydata_profiling: Not installed
2025-11-28 15:43:51,878:INFO:  explainerdashboard: Not installed
2025-11-28 15:43:51,879:INFO:             autoviz: Not installed
2025-11-28 15:43:51,879:INFO:           fairlearn: 0.12.0.dev0
2025-11-28 15:43:51,879:INFO:          deepchecks: Not installed
2025-11-28 15:43:51,879:INFO:             xgboost: 3.1.2
2025-11-28 15:43:51,879:INFO:            catboost: Not installed
2025-11-28 15:43:51,879:INFO:              kmodes: Not installed
2025-11-28 15:43:51,879:INFO:             mlxtend: Not installed
2025-11-28 15:43:51,879:INFO:       statsforecast: Not installed
2025-11-28 15:43:51,879:INFO:        tune_sklearn: Not installed
2025-11-28 15:43:51,879:INFO:                 ray: Not installed
2025-11-28 15:43:51,879:INFO:            hyperopt: Not installed
2025-11-28 15:43:51,879:INFO:              optuna: Not installed
2025-11-28 15:43:51,879:INFO:               skopt: Not installed
2025-11-28 15:43:51,879:INFO:              mlflow: Not installed
2025-11-28 15:43:51,879:INFO:              gradio: Not installed
2025-11-28 15:43:51,879:INFO:             fastapi: Not installed
2025-11-28 15:43:51,879:INFO:             uvicorn: Not installed
2025-11-28 15:43:51,879:INFO:              m2cgen: Not installed
2025-11-28 15:43:51,879:INFO:           evidently: Not installed
2025-11-28 15:43:51,879:INFO:               fugue: Not installed
2025-11-28 15:43:51,879:INFO:           streamlit: 1.51.0
2025-11-28 15:43:51,879:INFO:             prophet: Not installed
2025-11-28 15:43:51,879:INFO:None
2025-11-28 15:43:51,879:INFO:Set up data.
2025-11-28 15:43:55,003:INFO:Set up folding strategy.
2025-11-28 15:43:55,004:INFO:Set up train/test split.
2025-11-28 15:43:57,481:INFO:Set up index.
2025-11-28 15:43:57,553:INFO:Assigning column types.
2025-11-28 15:43:59,879:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-11-28 15:43:59,909:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-11-28 15:43:59,914:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-11-28 15:43:59,941:INFO:Soft dependency imported: xgboost: 3.1.2
2025-11-28 15:43:59,944:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-28 15:43:59,967:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-11-28 15:43:59,967:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-11-28 15:43:59,986:INFO:Soft dependency imported: xgboost: 3.1.2
2025-11-28 15:43:59,986:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-28 15:43:59,986:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-11-28 15:44:00,017:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-11-28 15:44:00,029:INFO:Soft dependency imported: xgboost: 3.1.2
2025-11-28 15:44:00,035:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-28 15:44:00,062:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-11-28 15:44:00,079:INFO:Soft dependency imported: xgboost: 3.1.2
2025-11-28 15:44:00,081:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-28 15:44:00,081:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-11-28 15:44:00,124:INFO:Soft dependency imported: xgboost: 3.1.2
2025-11-28 15:44:00,126:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-28 15:44:00,167:INFO:Soft dependency imported: xgboost: 3.1.2
2025-11-28 15:44:00,171:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-28 15:44:00,174:INFO:Preparing preprocessing pipeline...
2025-11-28 15:44:00,495:INFO:Set up simple imputation.
2025-11-28 15:44:01,277:INFO:Set up encoding of ordinal features.
2025-11-28 15:44:01,890:INFO:Set up encoding of categorical features.
2025-11-28 15:44:01,909:INFO:Set up imbalanced handling.
2025-11-28 15:44:06,298:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 15:44:18,641:INFO:Finished creating preprocessing pipeline.
2025-11-28 15:44:18,665:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\OMAR\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['STATE', 'FMONTH', 'DISPCODE',
                                             'PSU', 'CTELENM1', 'PVTRESD1',
                                             'COLGHOUS', 'STATERE1', 'CELPHON1',
                                             'LADULT1', 'COLGSEX1', 'NUMADULT',
                                             'LANDSEX1', 'NUMMEN', 'NUMWOMEN',
                                             'RESPSLCT', 'SAFETIME', 'CTELNUM1',
                                             'CELLFON5', 'CADULT1...
                                    transformer=TargetEncoder(cols=['IDATE',
                                                                    'IDAY'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              random_state=42,
                                                                              sampling_strategy='auto'))))],
         verbose=False)
2025-11-28 15:44:18,665:INFO:Creating final display dataframe.
2025-11-28 15:44:27,298:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\joblib\externals\loky\backend\context.py:136: UserWarning: Could not find the number of physical cores for the following reason:
[WinError 2] El sistema no puede encontrar el archivo especificado
Returning the number of logical cores instead. You can silence this warning by setting LOKY_MAX_CPU_COUNT to the number of cores you want to use.
  warnings.warn(

2025-11-28 15:44:38,246:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 15:45:00,340:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target          CVDINFR4
2                   Target type            Binary
3           Original data shape     (442067, 327)
4        Transformed data shape     (716361, 335)
5   Transformed train set shape     (583740, 335)
6    Transformed test set shape     (132621, 335)
7              Numeric features               322
8          Categorical features                 4
9      Rows with missing values            100.0%
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16                Fix imbalance              True
17         Fix imbalance method             SMOTE
18               Fold Generator   StratifiedKFold
19                  Fold Number                10
20                     CPU Jobs                -1
21                      Use GPU             False
22               Log Experiment             False
23              Experiment Name  clf-default-name
24                          USI              3f34
2025-11-28 15:45:00,390:INFO:Soft dependency imported: xgboost: 3.1.2
2025-11-28 15:45:00,393:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-28 15:45:00,437:INFO:Soft dependency imported: xgboost: 3.1.2
2025-11-28 15:45:00,440:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-28 15:45:00,441:INFO:setup() successfully completed in 68.57s...............
2025-11-28 15:45:00,448:INFO:Initializing get_config()
2025-11-28 15:45:00,448:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000205440814E0>, variable=X_train)
2025-11-28 15:45:00,448:INFO:Variable: 'X_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_train_transformed' instead.
2025-11-28 15:45:00,452:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'X_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_train_transformed' instead.
  warnings.warn(msg)  # print on screen

2025-11-28 15:45:01,658:INFO:Variable:  returned as         STATE  FMONTH     IDATE IMONTH IDAY IYEAR  DISPCODE           PSU  \
72923    12.0    10.0  12082022     12   08  2022    1200.0  2.022010e+09   
240937   33.0     3.0  03242022     03   24  2022    1100.0  2.022004e+09   
359568   49.0     1.0  03092022     03   09  2022    1100.0  2.022002e+09   
26678     6.0     1.0  02242022     02   24  2022    1200.0  2.022000e+09   
392399   53.0    12.0  12172022     12   17  2022    1200.0  2.022001e+09   
...       ...     ...       ...    ...  ...   ...       ...           ...   
340098   47.0     2.0  03152022     03   15  2022    1100.0  2.022002e+09   
212124   29.0     1.0  02062022     02   06  2022    1100.0  2.022001e+09   
78203    13.0    10.0  10212022     10   21  2022    1100.0  2.022002e+09   
167309   24.0     5.0  05092022     05   09  2022    1100.0  2.022013e+09   
313531   42.0     3.0  07272022     07   27  2022    1100.0  2.022003e+09   

        CTELENM1  PVTRESD1  COLGHOUS  STATERE1  CELPHON1  LADULT1  COLGSEX1  \
72923        NaN       NaN       NaN       NaN       NaN      NaN       NaN   
240937       NaN       NaN       NaN       NaN       NaN      NaN       NaN   
359568       NaN       NaN       NaN       NaN       NaN      NaN       NaN   
26678        NaN       NaN       NaN       NaN       NaN      NaN       NaN   
392399       NaN       NaN       NaN       NaN       NaN      NaN       NaN   
...          ...       ...       ...       ...       ...      ...       ...   
340098       NaN       NaN       NaN       NaN       NaN      NaN       NaN   
212124       1.0       1.0       NaN       1.0       2.0      1.0       NaN   
78203        1.0       1.0       NaN       1.0       2.0      1.0       NaN   
167309       NaN       NaN       NaN       NaN       NaN      NaN       NaN   
313531       NaN       NaN       NaN       NaN       NaN      NaN       NaN   

        NUMADULT  LANDSEX1  NUMMEN  NUMWOMEN  RESPSLCT  SAFETIME  CTELNUM1  \
72923        NaN       NaN     NaN       NaN       NaN       1.0       1.0   
240937       NaN       NaN     NaN       NaN       NaN       1.0       1.0   
359568       NaN       NaN     NaN       NaN       NaN       1.0       1.0   
26678        NaN       NaN     NaN       NaN       NaN       1.0       1.0   
392399       NaN       NaN     NaN       NaN       NaN       1.0       1.0   
...          ...       ...     ...       ...       ...       ...       ...   
340098       NaN       NaN     NaN       NaN       NaN       1.0       1.0   
212124       1.0       2.0     NaN       NaN       NaN       NaN       NaN   
78203        1.0       2.0     NaN       NaN       NaN       NaN       NaN   
167309       NaN       NaN     NaN       NaN       NaN       1.0       1.0   
313531       NaN       NaN     NaN       NaN       NaN       1.0       1.0   

        CELLFON5  CADULT1  CELLSEX1  PVTRESD3  CCLGHOUS  CSTATE1  LANDLINE  \
72923        1.0      1.0       2.0       1.0       NaN      1.0       1.0   
240937       1.0      1.0       1.0       1.0       NaN      1.0       1.0   
359568       1.0      1.0       2.0       1.0       NaN      1.0       2.0   
26678        1.0      1.0       1.0       1.0       NaN      2.0       2.0   
392399       1.0      1.0       1.0       1.0       NaN      2.0       2.0   
...          ...      ...       ...       ...       ...      ...       ...   
340098       1.0      1.0       1.0       1.0       NaN      1.0       2.0   
212124       NaN      NaN       NaN       NaN       NaN      NaN       NaN   
78203        NaN      NaN       NaN       NaN       NaN      NaN       NaN   
167309       1.0      1.0       1.0       1.0       NaN      1.0       2.0   
313531       1.0      1.0       1.0       1.0       NaN      1.0       2.0   

        HHADULT  SEXVAR  GENHLTH  PHYSHLTH  MENTHLTH  POORHLTH  PRIMINSR  \
72923       4.0     2.0      1.0      88.0      88.0       NaN      99.0   
240937      1.0     1.0      5.0      30.0       1.0      30.0       5.0   
359568      3.0     2.0      3.0      20.0       5.0      88.0       3.0   
26678       4.0     1.0      3.0       2.0      25.0      88.0       1.0   
392399      4.0     1.0      3.0       3.0      88.0      88.0       1.0   
...         ...     ...      ...       ...       ...       ...       ...   
340098      3.0     1.0      1.0      88.0      88.0       NaN       1.0   
212124      NaN     2.0      2.0      88.0      88.0       NaN       9.0   
78203       NaN     2.0      4.0      20.0      88.0      88.0       2.0   
167309      3.0     1.0      2.0       1.0      88.0      88.0       1.0   
313531      1.0     1.0      2.0       2.0      25.0       6.0       1.0   

        PERSDOC3  MEDCOST1  CHECKUP1  EXERANY2  SLEPTIM1  LASTDEN4  RMVTETH4  \
72923        2.0       2.0       1.0       1.0       7.0       2.0       8.0   
240937       3.0       1.0       1.0       1.0       9.0       2.0       2.0   
359568       1.0       2.0       1.0       1.0       5.0       2.0       1.0   
26678        3.0       2.0       2.0       1.0       7.0       1.0       8.0   
392399       2.0       2.0       1.0       1.0       5.0       1.0       2.0   
...          ...       ...       ...       ...       ...       ...       ...   
340098       3.0       2.0       4.0       1.0       6.0       2.0       1.0   
212124       1.0       2.0       1.0       1.0       8.0       3.0       2.0   
78203        2.0       2.0       1.0       2.0       6.0       1.0       2.0   
167309       2.0       2.0       1.0       1.0       7.0       1.0       1.0   
313531       3.0       2.0       3.0       1.0       9.0       2.0       8.0   

        CVDCRHD4  CVDSTRK3  ASTHMA3  ASTHNOW  CHCSCNC1  CHCOCNC1  CHCCOPD3  \
72923        2.0       2.0      2.0      NaN       2.0       2.0       2.0   
240937       2.0       2.0      2.0      NaN       2.0       2.0       2.0   
359568       2.0       2.0      2.0      NaN       2.0       2.0       2.0   
26678        2.0       2.0      1.0      1.0       2.0       2.0       2.0   
392399       2.0       2.0      2.0      NaN       2.0       2.0       2.0   
...          ...       ...      ...      ...       ...       ...       ...   
340098       2.0       2.0      2.0      NaN       2.0       2.0       2.0   
212124       2.0       2.0      2.0      NaN       1.0       1.0       2.0   
78203        2.0       1.0      2.0      NaN       2.0       2.0       2.0   
167309       2.0       2.0      2.0      NaN       2.0       2.0       2.0   
313531       2.0       2.0      2.0      NaN       2.0       2.0       2.0   

        ADDEPEV3  CHCKDNY2  HAVARTH4  DIABETE4  DIABAGE4  MARITAL  EDUCA  \
72923        2.0       2.0       2.0       3.0       NaN      9.0    9.0   
240937       2.0       2.0       2.0       1.0      60.0      5.0    5.0   
359568       2.0       2.0       1.0       3.0       NaN      1.0    5.0   
26678        2.0       2.0       2.0       3.0       NaN      6.0    4.0   
392399       2.0       2.0       2.0       1.0      55.0      2.0    6.0   
...          ...       ...       ...       ...       ...      ...    ...   
340098       2.0       2.0       2.0       3.0       NaN      1.0    3.0   
212124       2.0       2.0       1.0       3.0       NaN      3.0    4.0   
78203        2.0       2.0       1.0       3.0       NaN      3.0    4.0   
167309       2.0       2.0       1.0       3.0       NaN      1.0    6.0   
313531       2.0       2.0       2.0       3.0       NaN      5.0    5.0   

        RENTHOM1  NUMHHOL4  NUMPHON4  CPDEMO1C  VETERAN3  EMPLOY1  CHILDREN  \
72923        9.0       NaN       NaN       9.0       2.0      1.0      88.0   
240937       1.0       NaN       NaN       1.0       2.0      8.0      88.0   
359568       1.0       NaN       NaN       1.0       2.0      7.0      88.0   
26678        2.0       NaN       NaN       9.0       1.0      1.0      99.0   
392399       2.0       NaN       NaN       1.0       2.0      1.0      88.0   
...          ...       ...       ...       ...       ...      ...       ...   
340098       1.0       NaN       NaN       1.0       2.0      1.0       1.0   
212124       1.0       2.0       NaN       1.0       2.0      7.0      88.0   
78203        2.0       2.0       NaN       1.0       2.0      7.0      88.0   
167309       1.0       NaN       NaN       1.0       2.0      1.0      88.0   
313531       2.0       NaN       NaN       1.0       2.0      1.0      88.0   

        INCOME3  PREGNANT  WEIGHT2  HEIGHT3  DEAF  BLIND  DECIDE  DIFFWALK  \
72923      99.0       NaN   9999.0   9999.0   2.0    2.0     2.0       2.0   
240937      2.0       NaN    130.0    507.0   2.0    2.0     2.0       2.0   
359568      7.0       NaN    198.0    505.0   2.0    2.0     1.0       2.0   
26678      99.0       NaN    140.0    508.0   2.0    2.0     9.0       2.0   
392399      9.0       NaN    220.0    601.0   2.0    2.0     2.0       2.0   
...         ...       ...      ...      ...   ...    ...     ...       ...   
340098      8.0       NaN    140.0    509.0   2.0    2.0     2.0       2.0   
212124      4.0       NaN    148.0    504.0   2.0    2.0     2.0       2.0   
78203      99.0       NaN   9999.0   9999.0   9.0    9.0     2.0       2.0   
167309     11.0       NaN    192.0    600.0   2.0    2.0     2.0       2.0   
313531     11.0       NaN    155.0    601.0   2.0    2.0     2.0       2.0   

        DIFFDRES  DIFFALON  HADMAM  HOWLONG  CERVSCRN  CRVCLCNC  CRVCLPAP  \
72923        2.0       NaN     NaN      NaN       NaN       NaN       NaN   
240937       1.0       1.0     NaN      NaN       NaN       NaN       NaN   
359568       2.0       1.0     1.0      7.0       1.0       5.0       1.0   
26678        2.0       2.0     NaN      NaN       NaN       NaN       NaN   
392399       2.0       2.0     NaN      NaN       NaN       NaN       NaN   
...          ...       ...     ...      ...       ...       ...       ...   
340098       2.0       2.0     NaN      NaN       NaN       NaN       NaN   
212124       2.0       2.0     1.0      1.0       1.0       5.0       1.0   
78203        2.0       2.0     1.0      1.0       1.0       2.0       7.0   
167309       2.0       2.0     NaN      NaN       NaN       NaN       NaN   
313531       2.0       2.0     NaN      NaN       NaN       NaN       NaN   

        CRVCLHPV  HADHYST2  HADSIGM4  COLNSIGM  COLNTES1  SIGMTES1  LASTSIG4  \
72923        NaN       NaN       NaN       NaN       NaN       NaN       NaN   
240937       NaN       NaN       1.0       1.0       2.0       NaN       NaN   
359568       2.0       1.0       1.0       1.0       4.0       NaN       NaN   
26678        NaN       NaN       NaN       NaN       NaN       NaN       NaN   
392399       NaN       NaN       2.0       NaN       NaN       NaN       NaN   
...          ...       ...       ...       ...       ...       ...       ...   
340098       NaN       NaN       2.0       NaN       NaN       NaN       NaN   
212124       7.0       1.0       1.0       1.0       4.0       NaN       NaN   
78203        2.0       1.0       1.0       3.0       2.0       1.0       NaN   
167309       NaN       NaN       2.0       NaN       NaN       NaN       NaN   
313531       NaN       NaN       NaN       NaN       NaN       NaN       NaN   

        COLNCNCR  VIRCOLO1  VCLNTES2  SMALSTOL  STOLTEST  STOOLDN2  BLDSTFIT  \
72923        NaN       NaN       NaN       NaN       NaN       NaN       NaN   
240937       1.0       2.0       NaN       2.0       NaN       2.0       NaN   
359568       1.0       1.0       4.0       1.0       4.0       2.0       NaN   
26678        NaN       NaN       NaN       NaN       NaN       NaN       NaN   
392399       2.0       NaN       NaN       NaN       NaN       NaN       NaN   
...          ...       ...       ...       ...       ...       ...       ...   
340098       2.0       NaN       NaN       NaN       NaN       NaN       NaN   
212124       2.0       NaN       NaN       NaN       NaN       NaN       NaN   
78203        2.0       NaN       NaN       NaN       NaN       NaN       NaN   
167309       1.0       2.0       NaN       1.0       1.0       1.0       2.0   
313531       NaN       NaN       NaN       NaN       NaN       NaN       NaN   

        SDNATES1  SMOKE100  SMOKDAY2  USENOW3  ECIGNOW2  LCSFIRST  LCSLAST  \
72923        NaN       NaN       NaN      NaN       NaN       NaN      NaN   
240937       NaN       1.0       1.0      3.0       4.0      45.0      NaN   
359568       NaN       2.0       NaN      3.0       1.0       NaN      NaN   
26678        NaN       2.0       NaN      3.0       1.0       NaN      NaN   
392399       NaN       2.0       NaN      3.0       4.0       NaN      NaN   
...          ...       ...       ...      ...       ...       ...      ...   
340098       NaN       1.0       3.0      3.0       2.0      12.0     40.0   
212124       NaN       1.0       3.0      3.0       1.0      16.0     27.0   
78203        NaN       1.0       3.0      3.0       1.0      40.0     60.0   
167309       1.0       2.0       NaN      3.0       1.0       NaN      NaN   
313531       NaN       2.0       NaN      3.0       1.0       NaN      NaN   

        LCSNUMCG  LCSCTSC1  LCSSCNCR  LCSCTWHN  ALCDAY4  AVEDRNK3  DRNK3GE5  \
72923        NaN       NaN       NaN       NaN      NaN       NaN       NaN   
240937      10.0       1.0       2.0       NaN    203.0       1.0      88.0   
359568       NaN       2.0       NaN       NaN    888.0       NaN       NaN   
26678        NaN       2.0       NaN       NaN    888.0       NaN       NaN   
392399       NaN       2.0       NaN       NaN    888.0       NaN       NaN   
...          ...       ...       ...       ...      ...       ...       ...   
340098      40.0       1.0       2.0       NaN    888.0       NaN       NaN   
212124      15.0       1.0       2.0       NaN    888.0       NaN       NaN   
78203        2.0       1.0       2.0       NaN    888.0       NaN       NaN   
167309       NaN       1.0       2.0       NaN    103.0       3.0       2.0   
313531       NaN       1.0       2.0       NaN    103.0       3.0       4.0   

        MAXDRNKS  FLUSHOT7  FLSHTMY3  PNEUVAC4  TETANUS1  HIVTST7  HIVTSTD3  \
72923        NaN       NaN       NaN       NaN       NaN      NaN       NaN   
240937       2.0       2.0       NaN       2.0       3.0      1.0   31999.0   
359568       NaN       1.0   92021.0       2.0       2.0      2.0       NaN   
26678        NaN       1.0  999999.0       2.0       3.0      1.0  777777.0   
392399       NaN       2.0       NaN       2.0       4.0      2.0       NaN   
...          ...       ...       ...       ...       ...      ...       ...   
340098       NaN       2.0       NaN       2.0       3.0      2.0       NaN   
212124       NaN       1.0  102021.0       1.0       4.0      2.0       NaN   
78203        NaN       1.0  777777.0       1.0       4.0      2.0       NaN   
167309       6.0       1.0  112021.0       2.0       4.0      1.0  772015.0   
313531      12.0       1.0  102021.0       7.0       3.0      2.0       NaN   

        HIVRISK5  COVIDPOS  COVIDSMP  COVIDPRM  PDIABTS1  PREDIAB2  DIABTYPE  \
72923        NaN       NaN       NaN       NaN       NaN       NaN       NaN   
240937       2.0       2.0       NaN       NaN       NaN       NaN       NaN   
359568       2.0       1.0       2.0       NaN       NaN       NaN       NaN   
26678        2.0       2.0       NaN       NaN       NaN       NaN       NaN   
392399       2.0       2.0       NaN       NaN       NaN       NaN       NaN   
...          ...       ...       ...       ...       ...       ...       ...   
340098       2.0       2.0       NaN       NaN       NaN       NaN       NaN   
212124       2.0       2.0       NaN       NaN       1.0       3.0       NaN   
78203        2.0       2.0       NaN       NaN       1.0       3.0       NaN   
167309       2.0       1.0       2.0       NaN       NaN       NaN       NaN   
313531       1.0       2.0       NaN       NaN       3.0       3.0       NaN   

        INSULIN1  CHKHEMO3  EYEEXAM1  DIABEYE1  DIABEDU1  FEETSORE  TOLDCFS  \
72923        NaN       NaN       NaN       NaN       NaN       NaN      NaN   
240937       NaN       NaN       NaN       NaN       NaN       NaN      NaN   
359568       NaN       NaN       NaN       NaN       NaN       NaN      NaN   
26678        NaN       NaN       NaN       NaN       NaN       NaN      NaN   
392399       NaN       NaN       NaN       NaN       NaN       NaN      NaN   
...          ...       ...       ...       ...       ...       ...      ...   
340098       NaN       NaN       NaN       NaN       NaN       NaN      NaN   
212124       NaN       NaN       NaN       NaN       NaN       NaN      NaN   
78203        NaN       NaN       NaN       NaN       NaN       NaN      NaN   
167309       NaN       NaN       NaN       NaN       NaN       NaN      NaN   
313531       NaN       NaN       NaN       NaN       NaN       NaN      NaN   

        HAVECFS  WORKCFS  IMFVPLA3  HPVADVC4  HPVADSHT  SHINGLE2  COVIDVA1  \
72923       NaN      NaN       NaN       NaN       NaN       NaN       NaN   
240937      NaN      NaN       NaN       NaN       NaN       NaN       2.0   
359568      NaN      NaN       NaN       NaN       NaN       NaN       NaN   
26678       NaN      NaN       NaN       NaN       NaN       NaN       NaN   
392399      NaN      NaN       NaN       NaN       NaN       NaN       NaN   
...         ...      ...       ...       ...       ...       ...       ...   
340098      NaN      NaN       NaN       NaN       NaN       NaN       2.0   
212124      NaN      NaN       NaN       NaN       NaN       NaN       NaN   
78203       NaN      NaN       1.0       NaN       NaN       2.0       1.0   
167309      NaN      NaN       NaN       NaN       NaN       NaN       NaN   
313531      NaN      NaN       NaN       NaN       NaN       NaN       NaN   

        COVACGET  COVIDNU1  COVIDINT  COVIDFS1  COVIDSE1  COPDCOGH  COPDFLEM  \
72923        NaN       NaN       NaN       NaN       NaN       NaN       NaN   
240937       3.0       NaN       NaN       NaN       NaN       NaN       NaN   
359568       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
26678        NaN       NaN       NaN       NaN       NaN       NaN       NaN   
392399       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
...          ...       ...       ...       ...       ...       ...       ...   
340098       4.0       NaN       NaN       NaN       NaN       NaN       NaN   
212124       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
78203        NaN       4.0       NaN   22021.0   52021.0       2.0       2.0   
167309       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
313531       NaN       NaN       NaN       NaN       NaN       NaN       NaN   

        COPDBRTH  COPDBTST  COPDSMOK  CNCRDIFF  CNCRAGE  CNCRTYP2  CSRVTRT3  \
72923        NaN       NaN       NaN       NaN      NaN       NaN       NaN   
240937       NaN       NaN       NaN       NaN      NaN       NaN       NaN   
359568       NaN       NaN       NaN       NaN      NaN       NaN       NaN   
26678        NaN       NaN       NaN       NaN      NaN       NaN       NaN   
392399       NaN       NaN       NaN       NaN      NaN       NaN       NaN   
...          ...       ...       ...       ...      ...       ...       ...   
340098       NaN       NaN       NaN       NaN      NaN       NaN       NaN   
212124       NaN       NaN       NaN       2.0     72.0       5.0       2.0   
78203        1.0       2.0      10.0       NaN      NaN       NaN       NaN   
167309       NaN       NaN       NaN       NaN      NaN       NaN       NaN   
313531       NaN       NaN       NaN       NaN      NaN       NaN       NaN   

        CSRVDOC1  CSRVSUM  CSRVRTRN  CSRVINST  CSRVINSR  CSRVDEIN  CSRVCLIN  \
72923        NaN      NaN       NaN       NaN       NaN       NaN       NaN   
240937       NaN      NaN       NaN       NaN       NaN       NaN       NaN   
359568       NaN      NaN       NaN       NaN       NaN       NaN       NaN   
26678        NaN      NaN       NaN       NaN       NaN       NaN       NaN   
392399       NaN      NaN       NaN       NaN       NaN       NaN       NaN   
...          ...      ...       ...       ...       ...       ...       ...   
340098       NaN      NaN       NaN       NaN       NaN       NaN       NaN   
212124       2.0      2.0       2.0       NaN       1.0       2.0       2.0   
78203        NaN      NaN       NaN       NaN       NaN       NaN       NaN   
167309       NaN      NaN       NaN       NaN       NaN       NaN       NaN   
313531       NaN      NaN       NaN       NaN       NaN       NaN       NaN   

        CSRVPAIN  CSRVCTL2  PSATEST1  PSATIME1  PCPSARS2  PSASUGST  PCSTALK1  \
72923        NaN       NaN       NaN       NaN       NaN       NaN       NaN   
240937       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
359568       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
26678        NaN       NaN       NaN       NaN       NaN       NaN       NaN   
392399       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
...          ...       ...       ...       ...       ...       ...       ...   
340098       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
212124       2.0       NaN       NaN       NaN       NaN       NaN       NaN   
78203        NaN       NaN       NaN       NaN       NaN       NaN       NaN   
167309       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
313531       NaN       NaN       NaN       NaN       NaN       NaN       NaN   

        CIMEMLOS  CDHOUSE  CDASSIST  CDHELP  CDSOCIAL  CDDISCUS  CAREGIV1  \
72923        NaN      NaN       NaN     NaN       NaN       NaN       NaN   
240937       NaN      NaN       NaN     NaN       NaN       NaN       2.0   
359568       2.0      NaN       NaN     NaN       NaN       NaN       1.0   
26678        NaN      NaN       NaN     NaN       NaN       NaN       NaN   
392399       NaN      NaN       NaN     NaN       NaN       NaN       NaN   
...          ...      ...       ...     ...       ...       ...       ...   
340098       NaN      NaN       NaN     NaN       NaN       NaN       NaN   
212124       NaN      NaN       NaN     NaN       NaN       NaN       NaN   
78203        NaN      NaN       NaN     NaN       NaN       NaN       2.0   
167309       NaN      NaN       NaN     NaN       NaN       NaN       NaN   
313531       NaN      NaN       NaN     NaN       NaN       NaN       2.0   

        CRGVREL4  CRGVLNG1  CRGVHRS1  CRGVPRB3  CRGVALZD  CRGVPER1  CRGVHOU1  \
72923        NaN       NaN       NaN       NaN       NaN       NaN       NaN   
240937       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
359568       5.0       5.0       2.0      13.0       2.0       1.0       1.0   
26678        NaN       NaN       NaN       NaN       NaN       NaN       NaN   
392399       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
...          ...       ...       ...       ...       ...       ...       ...   
340098       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
212124       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
78203        NaN       NaN       NaN       NaN       NaN       NaN       NaN   
167309       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
313531       NaN       NaN       NaN       NaN       NaN       NaN       NaN   

        CRGVEXPT  ACEDEPRS  ACEDRINK  ACEDRUGS  ACEPRISN  ACEDIVRC  ACEPUNCH  \
72923        NaN       NaN       NaN       NaN       NaN       NaN       NaN   
240937       1.0       NaN       NaN       NaN       NaN       NaN       NaN   
359568       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
26678        NaN       NaN       NaN       NaN       NaN       NaN       NaN   
392399       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
...          ...       ...       ...       ...       ...       ...       ...   
340098       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
212124       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
78203        2.0       NaN       NaN       NaN       NaN       NaN       NaN   
167309       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
313531       2.0       NaN       NaN       NaN       NaN       NaN       NaN   

        ACEHURT1  ACESWEAR  ACETOUCH  ACETTHEM  ACEHVSEX  ACEADSAF  ACEADNED  \
72923        NaN       NaN       NaN       NaN       NaN       NaN       NaN   
240937       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
359568       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
26678        NaN       NaN       NaN       NaN       NaN       NaN       NaN   
392399       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
...          ...       ...       ...       ...       ...       ...       ...   
340098       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
212124       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
78203        NaN       NaN       NaN       NaN       NaN       NaN       NaN   
167309       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
313531       NaN       NaN       NaN       NaN       NaN       NaN       NaN   

        LSATISFY  EMTSUPRT  SDHISOLT  SDHEMPLY  FOODSTMP  SDHFOOD1  SDHBILLS  \
72923        NaN       NaN       NaN       NaN       NaN       NaN       NaN   
240937       2.0       1.0       5.0       2.0       1.0       2.0       2.0   
359568       1.0       1.0       5.0       2.0       2.0       5.0       2.0   
26678        NaN       NaN       NaN       NaN       NaN       NaN       NaN   
392399       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
...          ...       ...       ...       ...       ...       ...       ...   
340098       1.0       3.0       4.0       2.0       2.0       5.0       2.0   
212124       1.0       1.0       5.0       2.0       2.0       5.0       2.0   
78203        2.0       1.0       3.0       2.0       2.0       5.0       2.0   
167309       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
313531       NaN       NaN       NaN       NaN       NaN       NaN       NaN   

        SDHUTILS  SDHTRNSP  SDHSTRE1  MARIJAN1  MARJSMOK  MARJEAT  MARJVAPE  \
72923        NaN       NaN       NaN       NaN       NaN      NaN       NaN   
240937       2.0       1.0       4.0       NaN       NaN      NaN       NaN   
359568       2.0       2.0       2.0       NaN       NaN      NaN       NaN   
26678        NaN       NaN       NaN       NaN       NaN      NaN       NaN   
392399       NaN       NaN       NaN       NaN       NaN      NaN       NaN   
...          ...       ...       ...       ...       ...      ...       ...   
340098       2.0       2.0       3.0       NaN       NaN      NaN       NaN   
212124       2.0       2.0       5.0       NaN       NaN      NaN       NaN   
78203        2.0       2.0       3.0       NaN       NaN      NaN       NaN   
167309       NaN       NaN       NaN       NaN       NaN      NaN       NaN   
313531       NaN       NaN       NaN       NaN       NaN      NaN       NaN   

        MARJDAB  MARJOTHR  USEMRJN4  LASTSMK2  STOPSMK2  MENTCIGS  MENTECIG  \
72923       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
240937      NaN       NaN       NaN       NaN       NaN       NaN       NaN   
359568      NaN       NaN       NaN       NaN       NaN       NaN       NaN   
26678       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
392399      NaN       NaN       NaN       NaN       NaN       NaN       NaN   
...         ...       ...       ...       ...       ...       ...       ...   
340098      NaN       NaN       NaN       NaN       NaN       NaN       NaN   
212124      NaN       NaN       NaN       NaN       NaN       NaN       NaN   
78203       NaN       NaN       NaN       7.0       NaN       NaN       NaN   
167309      NaN       NaN       NaN       NaN       NaN       NaN       NaN   
313531      NaN       NaN       NaN       NaN       NaN       NaN       NaN   

        HEATTBCO  ASBIALCH  ASBIDRNK  ASBIBING  ASBIADVC  ASBIRDUC  FIREARM5  \
72923        NaN       NaN       NaN       NaN       NaN       NaN       NaN   
240937       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
359568       NaN       1.0       2.0       2.0       2.0       2.0       NaN   
26678        NaN       NaN       NaN       NaN       NaN       NaN       NaN   
392399       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
...          ...       ...       ...       ...       ...       ...       ...   
340098       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
212124       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
78203        NaN       NaN       NaN       NaN       NaN       NaN       NaN   
167309       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
313531       NaN       NaN       NaN       NaN       NaN       NaN       NaN   

        GUNLOAD  LOADULK2  RCSGEND1  RCSXBRTH  RCSRLTN2  CASTHDX2  CASTHNO2  \
72923       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
240937      NaN       NaN       NaN       NaN       NaN       NaN       NaN   
359568      NaN       NaN       NaN       NaN       NaN       NaN       NaN   
26678       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
392399      NaN       NaN       NaN       NaN       NaN       NaN       NaN   
...         ...       ...       ...       ...       ...       ...       ...   
340098      NaN       NaN       NaN       NaN       NaN       NaN       NaN   
212124      NaN       NaN       NaN       NaN       NaN       NaN       NaN   
78203       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
167309      NaN       NaN       NaN       NaN       NaN       NaN       NaN   
313531      NaN       NaN       NaN       NaN       NaN       NaN       NaN   

        BIRTHSEX  SOMALE  SOFEMALE  TRNSGNDR  HADSEX  PFPPRVN4  TYPCNTR9  \
72923        NaN     NaN       NaN       NaN     NaN       NaN       NaN   
240937       NaN     NaN       NaN       NaN     NaN       NaN       NaN   
359568       2.0     NaN       2.0       4.0     NaN       NaN       NaN   
26678        NaN     NaN       NaN       NaN     NaN       NaN       NaN   
392399       NaN     NaN       NaN       NaN     NaN       NaN       NaN   
...          ...     ...       ...       ...     ...       ...       ...   
340098       NaN     NaN       NaN       NaN     NaN       NaN       NaN   
212124       NaN     NaN       2.0       4.0     NaN       NaN       NaN   
78203        NaN     NaN       2.0       4.0     NaN       NaN       NaN   
167309       NaN     2.0       NaN       4.0     NaN       NaN       NaN   
313531       NaN     1.0       NaN       4.0     NaN       NaN       NaN   

        BRTHCNT4  WHEREGET  NOBCUSE8  BCPREFER  RRCLASS3  RRCOGNT2  RRTREAT  \
72923        NaN       NaN       NaN       NaN       NaN       NaN      NaN   
240937       NaN       NaN       NaN       NaN       NaN       NaN      NaN   
359568       NaN       NaN       NaN       NaN       NaN       NaN      NaN   
26678        NaN       NaN       NaN       NaN       NaN       NaN      NaN   
392399       NaN       NaN       NaN       NaN       NaN       NaN      NaN   
...          ...       ...       ...       ...       ...       ...      ...   
340098       NaN       NaN       NaN       NaN       1.0       5.0      2.0   
212124       NaN       NaN       NaN       NaN       NaN       NaN      NaN   
78203        NaN       NaN       NaN       NaN      77.0       1.0      2.0   
167309       NaN       NaN       NaN       NaN       1.0       3.0      3.0   
313531       NaN       NaN       NaN       NaN       NaN       NaN      NaN   

        RRATWRK2  RRHCARE4  RRPHYSM2  QSTVER  QSTLANG  METSTAT  URBSTAT  \
72923        NaN       NaN       NaN    20.0      1.0      1.0      1.0   
240937       NaN       NaN       NaN    20.0      1.0      1.0      1.0   
359568       NaN       NaN       NaN    21.0      1.0      2.0      1.0   
26678        NaN       NaN       NaN    20.0      1.0      1.0      1.0   
392399       NaN       NaN       NaN    20.0      1.0      1.0      1.0   
...          ...       ...       ...     ...      ...      ...      ...   
340098       2.0       2.0       2.0    20.0      1.0      1.0      1.0   
212124       NaN       NaN       NaN    10.0      1.0      2.0      2.0   
78203        NaN       2.0       1.0    10.0      1.0      2.0      1.0   
167309       2.0       2.0       2.0    23.0      1.0      1.0      1.0   
313531       NaN       NaN       NaN    20.0      1.0      1.0      1.0   

        MSCODE     STSTR       STRWT  RAWRAKE     WT2RAKE  IMPRACE  CHISPNC  \
72923      NaN  122322.0  248.452301      1.0  248.452301      1.0      9.0   
240937     NaN  332082.0   19.826805      1.0   19.826805      1.0      9.0   
359568     NaN  492091.0   12.845830      1.0   12.845830      1.0      9.0   
26678      NaN   62061.0   79.020515      1.0   79.020515      1.0      9.0   
392399     NaN  532042.0   27.861792      1.0   27.861792      1.0      9.0   
...        ...       ...         ...      ...         ...      ...      ...   
340098     NaN  472102.0   74.083954      1.0   74.083954      1.0      NaN   
212124     5.0  291061.0   39.401371      1.0   39.401371      1.0      9.0   
78203      5.0  131091.0   22.524734      1.0   22.524734      1.0      9.0   
167309     NaN  242021.0   11.215499      1.0   11.215499      1.0      9.0   
313531     NaN  422071.0  182.986099      1.0  182.986099      1.0      9.0   

        CRACE2  CPRACE2  CAGEG  CLLCPWT  DUALUSE   DUALCOR      LLCPWT2  \
72923      NaN      NaN    NaN      NaN      2.0  0.487943  6447.701660   
240937     NaN      NaN    NaN      NaN      2.0  0.378823   171.189651   
359568     NaN      NaN    NaN      NaN      9.0       NaN    97.794701   
26678      NaN      NaN    NaN      NaN      9.0       NaN  2596.461426   
392399     NaN      NaN    NaN      NaN      9.0       NaN   276.487793   
...        ...      ...    ...      ...      ...       ...          ...   
340098     NaN      NaN    NaN      NaN      9.0       NaN  1601.732788   
212124     NaN      NaN    NaN      NaN      1.0  0.484466   318.347107   
78203      NaN      NaN    NaN      NaN      1.0  0.608557   648.050659   
167309     NaN      NaN    NaN      NaN      9.0       NaN   149.325851   
313531     NaN      NaN    NaN      NaN      9.0       NaN  1313.389648   

              LLCPWT  RFHLTH  PHYS14D  MENT14D  HLTHPLN  HCVU652  TOTINDA  \
72923   11676.675781     1.0      1.0      1.0      9.0      9.0      1.0   
240937    344.872498     2.0      3.0      2.0      1.0      1.0      1.0   
359568     47.741280     1.0      3.0      2.0      1.0      9.0      1.0   
26678    1610.860840     1.0      2.0      3.0      1.0      1.0      1.0   
392399     95.158501     1.0      2.0      1.0      1.0      1.0      1.0   
...              ...     ...      ...      ...      ...      ...      ...   
340098   3215.943604     1.0      1.0      1.0      1.0      1.0      1.0   
212124    303.684662     1.0      1.0      1.0      1.0      9.0      1.0   
78203     268.017426     2.0      3.0      1.0      1.0      9.0      2.0   
167309     88.821060     1.0      2.0      1.0      1.0      1.0      1.0   
313531   1464.617065     1.0      2.0      3.0      1.0      1.0      1.0   

        EXTETH3  ALTETH3  DENVST3  MICHD  LTASTH1  CASTHM1  ASTHMS1  DRDXAR2  \
72923       1.0      9.0      2.0    2.0      1.0      1.0      3.0      2.0   
240937      2.0      NaN      2.0    2.0      1.0      1.0      3.0      2.0   
359568      2.0      1.0      2.0    2.0      1.0      1.0      3.0      1.0   
26678       1.0      NaN      1.0    2.0      2.0      2.0      1.0      2.0   
392399      2.0      NaN      1.0    2.0      1.0      1.0      3.0      2.0   
...         ...      ...      ...    ...      ...      ...      ...      ...   
340098      2.0      NaN      2.0    2.0      1.0      1.0      3.0      2.0   
212124      2.0      1.0      2.0    2.0      1.0      1.0      3.0      1.0   
78203       2.0      1.0      1.0    2.0      1.0      1.0      3.0      1.0   
167309      2.0      NaN      1.0    2.0      1.0      1.0      3.0      1.0   
313531      1.0      NaN      2.0    2.0      1.0      1.0      3.0      2.0   

        PRACE2  MRACE2  HISPANC  RACE1  RACEG22  RACEGR4  RACEPR1  SEX  \
72923      1.0     1.0      2.0    1.0      1.0      1.0      1.0  2.0   
240937     1.0     1.0      2.0    1.0      1.0      1.0      1.0  1.0   
359568     1.0     1.0      2.0    1.0      1.0      1.0      1.0  2.0   
26678     99.0    99.0      9.0    9.0      9.0      9.0      1.0  1.0   
392399     1.0     1.0      2.0    1.0      1.0      1.0      1.0  1.0   
...        ...     ...      ...    ...      ...      ...      ...  ...   
340098     1.0     1.0      2.0    1.0      1.0      1.0      1.0  1.0   
212124     1.0     1.0      2.0    1.0      1.0      1.0      1.0  2.0   
78203      1.0     1.0      2.0    1.0      1.0      1.0      1.0  2.0   
167309     1.0     1.0      2.0    1.0      1.0      1.0      1.0  1.0   
313531     1.0     1.0      2.0    1.0      1.0      1.0      1.0  1.0   

        AGEG5YR  AGE65YR  AGE80  AGE_G  HTIN4   HTM4   WTKG3    BMI5  BMI5CAT  \
72923      14.0      3.0   52.0    4.0    NaN    NaN     NaN     NaN      NaN   
240937      9.0      1.0   62.0    5.0   67.0  170.0  5897.0  2036.0      2.0   
359568     11.0      2.0   73.0    6.0   65.0  165.0  8981.0  3295.0      4.0   
26678       1.0      1.0   24.0    1.0   68.0  173.0  6350.0  2129.0      2.0   
392399      9.0      1.0   60.0    5.0   73.0  185.0  9979.0  2903.0      3.0   
...         ...      ...    ...    ...    ...    ...     ...     ...      ...   
340098      6.0      1.0   48.0    4.0   69.0  175.0  6350.0  2067.0      2.0   
212124     13.0      2.0   80.0    6.0   64.0  163.0  6713.0  2540.0      3.0   
78203      13.0      2.0   80.0    6.0    NaN    NaN     NaN     NaN      NaN   
167309      7.0      1.0   50.0    4.0   72.0  183.0  8709.0  2604.0      3.0   
313531      3.0      1.0   30.0    2.0   73.0  185.0  7031.0  2045.0      2.0   

        RFBMI5  CHLDCNT  EDUCAG  INCOMG1  RFMAM22  MAM5023  HADCOLN  CLNSCP1  \
72923      9.0      1.0     9.0      9.0      NaN      NaN      NaN      NaN   
240937     1.0      1.0     3.0      1.0      NaN      NaN      1.0      1.0   
359568     2.0      1.0     3.0      5.0      9.0      NaN      1.0      1.0   
26678      1.0      9.0     2.0      9.0      NaN      NaN      NaN      NaN   
392399     2.0      1.0     4.0      6.0      NaN      NaN      2.0      3.0   
...        ...      ...     ...      ...      ...      ...      ...      ...   
340098     1.0      2.0     1.0      5.0      NaN      NaN      2.0      3.0   
212124     2.0      1.0     2.0      2.0      1.0      NaN      1.0      NaN   
78203      9.0      1.0     2.0      9.0      1.0      NaN      1.0      NaN   
167309     2.0      1.0     4.0      7.0      NaN      NaN      2.0      3.0   
313531     1.0      1.0     3.0      7.0      NaN      NaN      NaN      NaN   

        HADSIGM  SGMSCP1  SGMS101  RFBLDS5  STOLDN1  VIRCOL1  SBONTI1  \
72923       NaN      NaN      NaN      NaN      NaN      NaN      NaN   
240937      2.0      3.0      3.0      3.0      3.0      3.0      3.0   
359568      2.0      3.0      3.0      2.0      3.0      2.0      2.0   
26678       NaN      NaN      NaN      NaN      NaN      NaN      NaN   
392399      2.0      3.0      3.0      3.0      3.0      3.0      3.0   
...         ...      ...      ...      ...      ...      ...      ...   
340098      2.0      3.0      3.0      3.0      3.0      3.0      3.0   
212124      2.0      NaN      NaN      NaN      NaN      NaN      NaN   
78203       1.0      NaN      NaN      NaN      NaN      NaN      NaN   
167309      2.0      3.0      3.0      1.0      1.0      3.0      2.0   
313531      NaN      NaN      NaN      NaN      NaN      NaN      NaN   

        CRCREC2  SMOKER3  RFSMOK3  CURECI2  YRSSMOK  PACKDAY  PACKYRS  \
72923       NaN      9.0      9.0      9.0      NaN      NaN      NaN   
240937      1.0      1.0      2.0      1.0     17.0     0.50      9.0   
359568      1.0      4.0      1.0      1.0      NaN      NaN      NaN   
26678       NaN      4.0      1.0      1.0      NaN      NaN      NaN   
392399      3.0      4.0      1.0      1.0      NaN      NaN      NaN   
...         ...      ...      ...      ...      ...      ...      ...   
340098      3.0      3.0      1.0      2.0     28.0     2.00     56.0   
212124      NaN      3.0      1.0      1.0     11.0     0.75      8.0   
78203       NaN      3.0      1.0      1.0     20.0     0.10      2.0   
167309      1.0      4.0      1.0      1.0      NaN      NaN      NaN   
313531      NaN      4.0      1.0      1.0      NaN      NaN      NaN   

        YRSQUIT  SMOKGRP  LCSREC  DRNKANY6  DROCDY4_  RFBING6  DRNKWK2  \
72923       NaN      NaN     NaN       9.0     900.0      9.0  99900.0   
240937      NaN      3.0     2.0       1.0      10.0      1.0     70.0   
359568      NaN      4.0     NaN       2.0       0.0      1.0      0.0   
26678       NaN      4.0     NaN       2.0       0.0      1.0      0.0   
392399      NaN      4.0     NaN       2.0       0.0      1.0      0.0   
...         ...      ...     ...       ...       ...      ...      ...   
340098      8.0      2.0     NaN       2.0       0.0      1.0      0.0   
212124     54.0      3.0     NaN       2.0       0.0      1.0      0.0   
78203      25.0      3.0     NaN       2.0       0.0      1.0      0.0   
167309      NaN      4.0     NaN       1.0      43.0      2.0    900.0   
313531      NaN      4.0     NaN       1.0      43.0      2.0    900.0   

        RFDRHV8  FLSHOT7  PNEUMO3  AIDTST4  
72923       9.0      9.0      9.0      NaN  
240937      1.0      NaN      NaN      1.0  
359568      1.0      1.0      2.0      2.0  
26678       1.0      NaN      NaN      1.0  
392399      1.0      NaN      NaN      2.0  
...         ...      ...      ...      ...  
340098      1.0      NaN      NaN      2.0  
212124      1.0      1.0      1.0      2.0  
78203       1.0      1.0      1.0      2.0  
167309      1.0      NaN      NaN      1.0  
313531      1.0      NaN      NaN      2.0  

[309446 rows x 326 columns]
2025-11-28 15:45:01,663:INFO:get_config() successfully completed......................................
2025-11-28 15:45:01,680:INFO:Initializing get_config()
2025-11-28 15:45:01,680:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000205440814E0>, variable=X_test)
2025-11-28 15:45:01,680:INFO:Variable: 'X_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_test_transformed' instead.
2025-11-28 15:45:01,680:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'X_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_test_transformed' instead.
  warnings.warn(msg)  # print on screen

2025-11-28 15:45:02,318:INFO:Variable:  returned as         STATE  FMONTH     IDATE IMONTH IDAY IYEAR  DISPCODE           PSU  \
410792   53.0    12.0  12202022     12   20  2022    1100.0  2.022024e+09   
75448    12.0     7.0  07152022     07   15  2022    1200.0  2.022013e+09   
439484   72.0     9.0  11202022     11   20  2022    1100.0  2.022004e+09   
179447   25.0     6.0  06212022     06   21  2022    1200.0  2.022009e+09   
390924   53.0    11.0  12022022     12   02  2022    1100.0  2.022005e+09   
...       ...     ...       ...    ...  ...   ...       ...           ...   
321216   45.0     3.0  03102022     03   10  2022    1100.0  2.022001e+09   
420811   55.0     8.0  08262022     08   26  2022    1200.0  2.022000e+09   
189121   26.0     4.0  04202022     04   20  2022    1100.0  2.022008e+09   
238196   33.0     6.0  06102022     06   10  2022    1100.0  2.022001e+09   
181731   26.0    11.0  11152022     11   15  2022    1100.0  2.022001e+09   

        CTELENM1  PVTRESD1  COLGHOUS  STATERE1  CELPHON1  LADULT1  COLGSEX1  \
410792       NaN       NaN       NaN       NaN       NaN      NaN       NaN   
75448        NaN       NaN       NaN       NaN       NaN      NaN       NaN   
439484       NaN       NaN       NaN       NaN       NaN      NaN       NaN   
179447       NaN       NaN       NaN       NaN       NaN      NaN       NaN   
390924       1.0       1.0       NaN       1.0       2.0      1.0       NaN   
...          ...       ...       ...       ...       ...      ...       ...   
321216       1.0       1.0       NaN       1.0       2.0      1.0       NaN   
420811       NaN       NaN       NaN       NaN       NaN      NaN       NaN   
189121       NaN       NaN       NaN       NaN       NaN      NaN       NaN   
238196       1.0       1.0       NaN       1.0       2.0      1.0       NaN   
181731       1.0       1.0       NaN       1.0       2.0      1.0       NaN   

        NUMADULT  LANDSEX1  NUMMEN  NUMWOMEN  RESPSLCT  SAFETIME  CTELNUM1  \
410792       NaN       NaN     NaN       NaN       NaN       1.0       1.0   
75448        NaN       NaN     NaN       NaN       NaN       1.0       1.0   
439484       NaN       NaN     NaN       NaN       NaN       1.0       1.0   
179447       NaN       NaN     NaN       NaN       NaN       1.0       1.0   
390924       2.0       NaN     1.0       1.0       2.0       NaN       NaN   
...          ...       ...     ...       ...       ...       ...       ...   
321216       1.0       2.0     NaN       NaN       NaN       NaN       NaN   
420811       NaN       NaN     NaN       NaN       NaN       1.0       1.0   
189121       NaN       NaN     NaN       NaN       NaN       1.0       1.0   
238196       3.0       NaN     1.0       2.0       1.0       NaN       NaN   
181731       2.0       NaN     1.0       1.0       2.0       NaN       NaN   

        CELLFON5  CADULT1  CELLSEX1  PVTRESD3  CCLGHOUS  CSTATE1  LANDLINE  \
410792       1.0      1.0       2.0       1.0       NaN      1.0       1.0   
75448        1.0      1.0       1.0       1.0       NaN      2.0       2.0   
439484       1.0      1.0       2.0       1.0       NaN      1.0       2.0   
179447       1.0      1.0       2.0       1.0       NaN      1.0       2.0   
390924       NaN      NaN       NaN       NaN       NaN      NaN       NaN   
...          ...      ...       ...       ...       ...      ...       ...   
321216       NaN      NaN       NaN       NaN       NaN      NaN       NaN   
420811       1.0      1.0       2.0       1.0       NaN      2.0       2.0   
189121       1.0      1.0       2.0       1.0       NaN      1.0       2.0   
238196       NaN      NaN       NaN       NaN       NaN      NaN       NaN   
181731       NaN      NaN       NaN       NaN       NaN      NaN       NaN   

        HHADULT  SEXVAR  GENHLTH  PHYSHLTH  MENTHLTH  POORHLTH  PRIMINSR  \
410792      2.0     2.0      4.0      15.0      30.0      30.0       3.0   
75448       2.0     1.0      1.0       1.0      88.0      88.0       1.0   
439484      2.0     2.0      4.0      88.0      88.0       NaN       3.0   
179447      2.0     2.0      4.0       7.0      30.0      88.0       5.0   
390924      NaN     2.0      2.0      88.0      88.0       NaN       1.0   
...         ...     ...      ...       ...       ...       ...       ...   
321216      NaN     2.0      5.0      30.0      30.0      30.0       3.0   
420811      1.0     2.0      3.0       8.0      88.0      88.0       3.0   
189121      2.0     2.0      2.0      88.0       2.0      88.0       1.0   
238196      NaN     1.0      2.0      88.0      88.0       NaN       3.0   
181731      NaN     2.0      3.0       2.0       7.0      88.0       3.0   

        PERSDOC3  MEDCOST1  CHECKUP1  EXERANY2  SLEPTIM1  LASTDEN4  RMVTETH4  \
410792       1.0       2.0       1.0       2.0       9.0       3.0       8.0   
75448        1.0       2.0       1.0       1.0       7.0       2.0       8.0   
439484       1.0       2.0       1.0       2.0       8.0       1.0       2.0   
179447       1.0       2.0       1.0       1.0       4.0       1.0       1.0   
390924       2.0       2.0       1.0       1.0       8.0       1.0       2.0   
...          ...       ...       ...       ...       ...       ...       ...   
321216       2.0       2.0       1.0       2.0      12.0       1.0       8.0   
420811       1.0       2.0       2.0       1.0       6.0       1.0       8.0   
189121       1.0       2.0       1.0       1.0       7.0       1.0       8.0   
238196       2.0       2.0       1.0       1.0       9.0       1.0       8.0   
181731       1.0       2.0       1.0       1.0       8.0       1.0       2.0   

        CVDCRHD4  CVDSTRK3  ASTHMA3  ASTHNOW  CHCSCNC1  CHCOCNC1  CHCCOPD3  \
410792       2.0       2.0      2.0      NaN       2.0       2.0       2.0   
75448        2.0       2.0      2.0      NaN       1.0       2.0       2.0   
439484       2.0       2.0      2.0      NaN       2.0       2.0       2.0   
179447       2.0       2.0      2.0      NaN       2.0       2.0       2.0   
390924       2.0       2.0      1.0      7.0       2.0       1.0       2.0   
...          ...       ...      ...      ...       ...       ...       ...   
321216       2.0       2.0      2.0      NaN       1.0       1.0       2.0   
420811       2.0       2.0      1.0      1.0       2.0       2.0       2.0   
189121       2.0       2.0      2.0      NaN       2.0       2.0       2.0   
238196       1.0       2.0      2.0      NaN       2.0       1.0       2.0   
181731       2.0       2.0      2.0      NaN       1.0       2.0       2.0   

        ADDEPEV3  CHCKDNY2  HAVARTH4  DIABETE4  DIABAGE4  MARITAL  EDUCA  \
410792       7.0       2.0       1.0       3.0       NaN      5.0    6.0   
75448        2.0       2.0       2.0       3.0       NaN      1.0    5.0   
439484       2.0       2.0       2.0       1.0      25.0      1.0    5.0   
179447       1.0       2.0       2.0       3.0       NaN      5.0    4.0   
390924       1.0       2.0       1.0       4.0       NaN      1.0    6.0   
...          ...       ...       ...       ...       ...      ...    ...   
321216       1.0       2.0       1.0       3.0       NaN      3.0    6.0   
420811       1.0       2.0       1.0       1.0      40.0      2.0    5.0   
189121       2.0       2.0       1.0       3.0       NaN      1.0    6.0   
238196       2.0       2.0       2.0       3.0       NaN      1.0    6.0   
181731       1.0       2.0       1.0       3.0       NaN      1.0    4.0   

        RENTHOM1  NUMHHOL4  NUMPHON4  CPDEMO1C  VETERAN3  EMPLOY1  CHILDREN  \
410792       2.0       NaN       NaN       1.0       2.0      7.0      88.0   
75448        1.0       NaN       NaN       1.0       1.0      7.0      88.0   
439484       1.0       NaN       NaN       1.0       2.0      5.0      88.0   
179447       2.0       NaN       NaN       1.0       2.0      4.0       3.0   
390924       1.0       2.0       NaN       1.0       2.0      7.0      88.0   
...          ...       ...       ...       ...       ...      ...       ...   
321216       1.0       2.0       NaN       8.0       2.0      7.0      88.0   
420811       1.0       NaN       NaN       1.0       2.0      8.0      88.0   
189121       1.0       NaN       NaN       1.0       1.0      1.0      88.0   
238196       1.0       2.0       NaN       1.0       1.0      7.0      88.0   
181731       1.0       2.0       NaN       1.0       2.0      5.0      88.0   

        INCOME3  PREGNANT  WEIGHT2  HEIGHT3  DEAF  BLIND  DECIDE  DIFFWALK  \
410792      5.0       NaN    200.0    510.0   2.0    2.0     2.0       1.0   
75448       9.0       NaN    150.0    506.0   2.0    2.0     2.0       2.0   
439484      3.0       NaN    200.0    504.0   2.0    2.0     2.0       1.0   
179447      NaN       NaN      NaN      NaN   NaN    NaN     NaN       NaN   
390924      9.0       NaN    121.0    501.0   2.0    2.0     2.0       2.0   
...         ...       ...      ...      ...   ...    ...     ...       ...   
321216      6.0       NaN    167.0    506.0   2.0    2.0     1.0       1.0   
420811      2.0       NaN    248.0    507.0   1.0    1.0     1.0       1.0   
189121      9.0       NaN    180.0    505.0   2.0    2.0     2.0       2.0   
238196      9.0       NaN    165.0    504.0   2.0    2.0     2.0       2.0   
181731     77.0       NaN    155.0    503.0   2.0    2.0     1.0       2.0   

        DIFFDRES  DIFFALON  HADMAM  HOWLONG  CERVSCRN  CRVCLCNC  CRVCLPAP  \
410792       1.0       2.0     1.0      1.0       1.0       5.0       2.0   
75448        2.0       2.0     NaN      NaN       NaN       NaN       NaN   
439484       2.0       2.0     1.0      3.0       1.0       5.0       1.0   
179447       NaN       NaN     NaN      NaN       NaN       NaN       NaN   
390924       2.0       2.0     1.0      5.0       1.0       5.0       1.0   
...          ...       ...     ...      ...       ...       ...       ...   
321216       1.0       1.0     1.0      5.0       1.0       5.0       1.0   
420811       2.0       2.0     1.0      4.0       1.0       5.0       1.0   
189121       2.0       2.0     2.0      NaN       2.0       NaN       NaN   
238196       2.0       2.0     NaN      NaN       NaN       NaN       NaN   
181731       2.0       2.0     1.0      4.0       1.0       5.0       1.0   

        CRVCLHPV  HADHYST2  HADSIGM4  COLNSIGM  COLNTES1  SIGMTES1  LASTSIG4  \
410792       2.0       2.0       1.0       1.0       5.0       NaN       NaN   
75448        NaN       NaN       1.0       1.0       2.0       NaN       NaN   
439484       1.0       2.0       2.0       NaN       NaN       NaN       NaN   
179447       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
390924       2.0       1.0       1.0       1.0       2.0       NaN       NaN   
...          ...       ...       ...       ...       ...       ...       ...   
321216       2.0       2.0       1.0       1.0       5.0       NaN       NaN   
420811       7.0       1.0       1.0       1.0       3.0       NaN       NaN   
189121       NaN       2.0       1.0       1.0       3.0       NaN       NaN   
238196       NaN       NaN       1.0       3.0       3.0       5.0       NaN   
181731       7.0       1.0       1.0       3.0       3.0       7.0       NaN   

        COLNCNCR  VIRCOLO1  VCLNTES2  SMALSTOL  STOLTEST  STOOLDN2  BLDSTFIT  \
410792       1.0       2.0       NaN       1.0       2.0       2.0       NaN   
75448        7.0       NaN       NaN       NaN       NaN       NaN       NaN   
439484       1.0       2.0       NaN       1.0       1.0       2.0       NaN   
179447       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
390924       2.0       NaN       NaN       NaN       NaN       NaN       NaN   
...          ...       ...       ...       ...       ...       ...       ...   
321216       1.0       2.0       NaN       1.0       2.0       2.0       NaN   
420811       2.0       NaN       NaN       NaN       NaN       NaN       NaN   
189121       1.0       2.0       NaN       2.0       NaN       2.0       NaN   
238196       1.0       2.0       NaN       1.0       7.0       2.0       NaN   
181731       1.0       2.0       NaN       1.0       4.0       2.0       NaN   

        SDNATES1  SMOKE100  SMOKDAY2  USENOW3  ECIGNOW2  LCSFIRST  LCSLAST  \
410792       NaN       2.0       NaN      3.0       1.0       NaN      NaN   
75448        NaN       2.0       NaN      3.0       1.0       NaN      NaN   
439484       NaN       2.0       NaN      3.0       1.0       NaN      NaN   
179447       NaN       NaN       NaN      NaN       NaN       NaN      NaN   
390924       NaN       1.0       3.0      3.0       4.0      16.0     29.0   
...          ...       ...       ...      ...       ...       ...      ...   
321216       NaN       2.0       NaN      3.0       1.0       NaN      NaN   
420811       NaN       2.0       NaN      3.0       1.0       NaN      NaN   
189121       NaN       1.0       3.0      3.0       1.0      22.0     41.0   
238196       NaN       1.0       3.0      3.0       4.0      16.0     21.0   
181731       NaN       1.0       3.0      3.0       1.0      20.0     60.0   

        LCSNUMCG  LCSCTSC1  LCSSCNCR  LCSCTWHN  ALCDAY4  AVEDRNK3  DRNK3GE5  \
410792       NaN       2.0       NaN       NaN    105.0       6.0      20.0   
75448        NaN       1.0       2.0       NaN    203.0       1.0      88.0   
439484       NaN       1.0       2.0       NaN    888.0       NaN       NaN   
179447       NaN       NaN       NaN       NaN      NaN       NaN       NaN   
390924      10.0       7.0       NaN       NaN    888.0       NaN       NaN   
...          ...       ...       ...       ...      ...       ...       ...   
321216       NaN       1.0       7.0       NaN    888.0       NaN       NaN   
420811       NaN       7.0       NaN       NaN    777.0       NaN       NaN   
189121      10.0       2.0       NaN       NaN    201.0       2.0       2.0   
238196       5.0       2.0       NaN       NaN    102.0       2.0      88.0   
181731       3.0       1.0       7.0       NaN    101.0       1.0      88.0   

        MAXDRNKS  FLUSHOT7  FLSHTMY3  PNEUVAC4  TETANUS1  HIVTST7  HIVTSTD3  \
410792       5.0       1.0  112022.0       2.0       4.0      1.0  777777.0   
75448        2.0       2.0       NaN       2.0       3.0      1.0  772018.0   
439484       NaN       2.0       NaN       2.0       3.0      2.0       NaN   
179447       NaN       NaN       NaN       NaN       NaN      NaN       NaN   
390924       NaN       1.0  102022.0       1.0       1.0      1.0   81991.0   
...          ...       ...       ...       ...       ...      ...       ...   
321216       NaN       1.0   22022.0       1.0       3.0      7.0       NaN   
420811       NaN       2.0       NaN       2.0       1.0      1.0  777777.0   
189121       6.0       1.0   92021.0       2.0       1.0      1.0  777777.0   
238196       2.0       7.0       NaN       1.0       4.0      2.0       NaN   
181731       2.0       1.0  777777.0       1.0       1.0      2.0       NaN   

        HIVRISK5  COVIDPOS  COVIDSMP  COVIDPRM  PDIABTS1  PREDIAB2  DIABTYPE  \
410792       2.0       2.0       NaN       NaN       NaN       NaN       NaN   
75448        2.0       1.0       2.0       NaN       NaN       NaN       NaN   
439484       2.0       2.0       NaN       NaN       NaN       NaN       NaN   
179447       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
390924       2.0       2.0       NaN       NaN       NaN       NaN       NaN   
...          ...       ...       ...       ...       ...       ...       ...   
321216       2.0       2.0       NaN       NaN       1.0       1.0       NaN   
420811       1.0       2.0       NaN       NaN       NaN       NaN       NaN   
189121       2.0       1.0       2.0       NaN       1.0       3.0       NaN   
238196       2.0       2.0       NaN       NaN       1.0       3.0       NaN   
181731       2.0       3.0       2.0       NaN       1.0       3.0       NaN   

        INSULIN1  CHKHEMO3  EYEEXAM1  DIABEYE1  DIABEDU1  FEETSORE  TOLDCFS  \
410792       NaN       NaN       NaN       NaN       NaN       NaN      NaN   
75448        NaN       NaN       NaN       NaN       NaN       NaN      NaN   
439484       NaN       NaN       NaN       NaN       NaN       NaN      NaN   
179447       NaN       NaN       NaN       NaN       NaN       NaN      NaN   
390924       NaN       NaN       NaN       NaN       NaN       NaN      NaN   
...          ...       ...       ...       ...       ...       ...      ...   
321216       NaN       NaN       NaN       NaN       NaN       NaN      NaN   
420811       NaN       NaN       NaN       NaN       NaN       NaN      NaN   
189121       NaN       NaN       NaN       NaN       NaN       NaN      NaN   
238196       NaN       NaN       NaN       NaN       NaN       NaN      NaN   
181731       NaN       NaN       NaN       NaN       NaN       NaN      NaN   

        HAVECFS  WORKCFS  IMFVPLA3  HPVADVC4  HPVADSHT  SHINGLE2  COVIDVA1  \
410792      NaN      NaN       NaN       NaN       NaN       NaN       NaN   
75448       NaN      NaN       NaN       NaN       NaN       NaN       NaN   
439484      NaN      NaN       NaN       NaN       NaN       NaN       1.0   
179447      NaN      NaN       NaN       NaN       NaN       NaN       NaN   
390924      NaN      NaN       NaN       NaN       NaN       NaN       NaN   
...         ...      ...       ...       ...       ...       ...       ...   
321216      NaN      NaN       NaN       NaN       NaN       NaN       1.0   
420811      NaN      NaN       NaN       NaN       NaN       NaN       NaN   
189121      NaN      NaN       NaN       NaN       NaN       NaN       NaN   
238196      NaN      NaN       NaN       NaN       NaN       NaN       1.0   
181731      NaN      NaN       NaN       NaN       NaN       NaN       NaN   

        COVACGET  COVIDNU1  COVIDINT  COVIDFS1  COVIDSE1  COPDCOGH  COPDFLEM  \
410792       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
75448        NaN       NaN       NaN       NaN       NaN       NaN       NaN   
439484       NaN       4.0       NaN  777777.0  777777.0       NaN       NaN   
179447       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
390924       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
...          ...       ...       ...       ...       ...       ...       ...   
321216       NaN       1.0       7.0   42021.0       NaN       NaN       NaN   
420811       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
189121       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
238196       NaN       3.0       NaN   32020.0   42020.0       NaN       NaN   
181731       NaN       NaN       NaN       NaN       NaN       NaN       NaN   

        COPDBRTH  COPDBTST  COPDSMOK  CNCRDIFF  CNCRAGE  CNCRTYP2  CSRVTRT3  \
410792       NaN       NaN       NaN       NaN      NaN       NaN       NaN   
75448        NaN       NaN       NaN       NaN      NaN       NaN       NaN   
439484       NaN       NaN       NaN       NaN      NaN       NaN       NaN   
179447       NaN       NaN       NaN       NaN      NaN       NaN       NaN   
390924       NaN       NaN       NaN       NaN      NaN       NaN       NaN   
...          ...       ...       ...       ...      ...       ...       ...   
321216       NaN       NaN       NaN       NaN      NaN       NaN       NaN   
420811       NaN       NaN       NaN       NaN      NaN       NaN       NaN   
189121       NaN       NaN       NaN       NaN      NaN       NaN       NaN   
238196       NaN       NaN       NaN       NaN      NaN       NaN       NaN   
181731       NaN       NaN       NaN       1.0     98.0      77.0       NaN   

        CSRVDOC1  CSRVSUM  CSRVRTRN  CSRVINST  CSRVINSR  CSRVDEIN  CSRVCLIN  \
410792       NaN      NaN       NaN       NaN       NaN       NaN       NaN   
75448        NaN      NaN       NaN       NaN       NaN       NaN       NaN   
439484       NaN      NaN       NaN       NaN       NaN       NaN       NaN   
179447       NaN      NaN       NaN       NaN       NaN       NaN       NaN   
390924       NaN      NaN       NaN       NaN       NaN       NaN       NaN   
...          ...      ...       ...       ...       ...       ...       ...   
321216       NaN      NaN       NaN       NaN       NaN       NaN       NaN   
420811       NaN      NaN       NaN       NaN       NaN       NaN       NaN   
189121       NaN      NaN       NaN       NaN       NaN       NaN       NaN   
238196       NaN      NaN       NaN       NaN       NaN       NaN       NaN   
181731       NaN      NaN       NaN       NaN       NaN       NaN       NaN   

        CSRVPAIN  CSRVCTL2  PSATEST1  PSATIME1  PCPSARS2  PSASUGST  PCSTALK1  \
410792       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
75448        NaN       NaN       NaN       NaN       NaN       NaN       NaN   
439484       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
179447       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
390924       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
...          ...       ...       ...       ...       ...       ...       ...   
321216       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
420811       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
189121       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
238196       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
181731       2.0       NaN       NaN       NaN       NaN       NaN       NaN   

        CIMEMLOS  CDHOUSE  CDASSIST  CDHELP  CDSOCIAL  CDDISCUS  CAREGIV1  \
410792       NaN      NaN       NaN     NaN       NaN       NaN       1.0   
75448        NaN      NaN       NaN     NaN       NaN       NaN       NaN   
439484       NaN      NaN       NaN     NaN       NaN       NaN       1.0   
179447       NaN      NaN       NaN     NaN       NaN       NaN       NaN   
390924       NaN      NaN       NaN     NaN       NaN       NaN       1.0   
...          ...      ...       ...     ...       ...       ...       ...   
321216       2.0      NaN       NaN     NaN       NaN       NaN       NaN   
420811       NaN      NaN       NaN     NaN       NaN       NaN       NaN   
189121       NaN      NaN       NaN     NaN       NaN       NaN       NaN   
238196       NaN      NaN       NaN     NaN       NaN       NaN       2.0   
181731       NaN      NaN       NaN     NaN       NaN       NaN       NaN   

        CRGVREL4  CRGVLNG1  CRGVHRS1  CRGVPRB3  CRGVALZD  CRGVPER1  CRGVHOU1  \
410792      15.0       4.0       1.0      15.0       1.0       2.0       1.0   
75448        NaN       NaN       NaN       NaN       NaN       NaN       NaN   
439484      10.0       5.0       4.0       6.0       2.0       2.0       1.0   
179447       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
390924       3.0       5.0       2.0      14.0       7.0       2.0       1.0   
...          ...       ...       ...       ...       ...       ...       ...   
321216       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
420811       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
189121       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
238196       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
181731       NaN       NaN       NaN       NaN       NaN       NaN       NaN   

        CRGVEXPT  ACEDEPRS  ACEDRINK  ACEDRUGS  ACEPRISN  ACEDIVRC  ACEPUNCH  \
410792       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
75448        NaN       NaN       NaN       NaN       NaN       NaN       NaN   
439484       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
179447       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
390924       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
...          ...       ...       ...       ...       ...       ...       ...   
321216       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
420811       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
189121       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
238196       2.0       NaN       NaN       NaN       NaN       NaN       NaN   
181731       NaN       NaN       NaN       NaN       NaN       NaN       NaN   

        ACEHURT1  ACESWEAR  ACETOUCH  ACETTHEM  ACEHVSEX  ACEADSAF  ACEADNED  \
410792       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
75448        NaN       NaN       NaN       NaN       NaN       NaN       NaN   
439484       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
179447       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
390924       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
...          ...       ...       ...       ...       ...       ...       ...   
321216       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
420811       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
189121       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
238196       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
181731       NaN       NaN       NaN       NaN       NaN       NaN       NaN   

        LSATISFY  EMTSUPRT  SDHISOLT  SDHEMPLY  FOODSTMP  SDHFOOD1  SDHBILLS  \
410792       3.0       4.0       3.0       2.0       2.0       5.0       2.0   
75448        NaN       NaN       NaN       NaN       NaN       NaN       NaN   
439484       1.0       1.0       5.0       2.0       2.0       3.0       1.0   
179447       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
390924       1.0       1.0       5.0       2.0       2.0       5.0       2.0   
...          ...       ...       ...       ...       ...       ...       ...   
321216       4.0       3.0       2.0       2.0       2.0       5.0       2.0   
420811       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
189121       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
238196       1.0       1.0       5.0       2.0       2.0       5.0       2.0   
181731       NaN       NaN       NaN       NaN       NaN       NaN       NaN   

        SDHUTILS  SDHTRNSP  SDHSTRE1  MARIJAN1  MARJSMOK  MARJEAT  MARJVAPE  \
410792       2.0       2.0       4.0       NaN       NaN      NaN       NaN   
75448        NaN       NaN       NaN       NaN       NaN      NaN       NaN   
439484       2.0       2.0       5.0       NaN       NaN      NaN       NaN   
179447       NaN       NaN       NaN       NaN       NaN      NaN       NaN   
390924       2.0       2.0       5.0       NaN       NaN      NaN       NaN   
...          ...       ...       ...       ...       ...      ...       ...   
321216       2.0       1.0       3.0       NaN       NaN      NaN       NaN   
420811       NaN       NaN       NaN       NaN       NaN      NaN       NaN   
189121       NaN       NaN       NaN       NaN       NaN      NaN       NaN   
238196       2.0       2.0       5.0       NaN       NaN      NaN       NaN   
181731       NaN       NaN       NaN       NaN       NaN      NaN       NaN   

        MARJDAB  MARJOTHR  USEMRJN4  LASTSMK2  STOPSMK2  MENTCIGS  MENTECIG  \
410792      NaN       NaN       NaN       NaN       NaN       NaN       NaN   
75448       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
439484      NaN       NaN       NaN       NaN       NaN       NaN       NaN   
179447      NaN       NaN       NaN       NaN       NaN       NaN       NaN   
390924      NaN       NaN       NaN       6.0       NaN       NaN       NaN   
...         ...       ...       ...       ...       ...       ...       ...   
321216      NaN       NaN       NaN       NaN       NaN       NaN       NaN   
420811      NaN       NaN       NaN       NaN       NaN       NaN       NaN   
189121      NaN       NaN       NaN       NaN       NaN       NaN       NaN   
238196      NaN       NaN       NaN       NaN       NaN       NaN       NaN   
181731      NaN       NaN       NaN       NaN       NaN       NaN       NaN   

        HEATTBCO  ASBIALCH  ASBIDRNK  ASBIBING  ASBIADVC  ASBIRDUC  FIREARM5  \
410792       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
75448        NaN       NaN       NaN       NaN       NaN       NaN       NaN   
439484       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
179447       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
390924       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
...          ...       ...       ...       ...       ...       ...       ...   
321216       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
420811       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
189121       NaN       1.0       1.0       7.0       7.0       2.0       NaN   
238196       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
181731       NaN       2.0       2.0       2.0       2.0       NaN       NaN   

        GUNLOAD  LOADULK2  RCSGEND1  RCSXBRTH  RCSRLTN2  CASTHDX2  CASTHNO2  \
410792      NaN       NaN       NaN       NaN       NaN       NaN       NaN   
75448       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
439484      NaN       NaN       NaN       NaN       NaN       NaN       NaN   
179447      NaN       NaN       NaN       NaN       NaN       NaN       NaN   
390924      NaN       NaN       NaN       NaN       NaN       NaN       NaN   
...         ...       ...       ...       ...       ...       ...       ...   
321216      NaN       NaN       NaN       NaN       NaN       NaN       NaN   
420811      NaN       NaN       NaN       NaN       NaN       NaN       NaN   
189121      NaN       NaN       NaN       NaN       NaN       NaN       NaN   
238196      NaN       NaN       NaN       NaN       NaN       NaN       NaN   
181731      NaN       NaN       NaN       NaN       NaN       NaN       NaN   

        BIRTHSEX  SOMALE  SOFEMALE  TRNSGNDR  HADSEX  PFPPRVN4  TYPCNTR9  \
410792       NaN     NaN       1.0       4.0     NaN       NaN       NaN   
75448        NaN     NaN       NaN       NaN     NaN       NaN       NaN   
439484       NaN     NaN       NaN       NaN     NaN       NaN       NaN   
179447       NaN     NaN       3.0       4.0     NaN       NaN       NaN   
390924       NaN     NaN       2.0       4.0     NaN       NaN       NaN   
...          ...     ...       ...       ...     ...       ...       ...   
321216       NaN     NaN       NaN       NaN     NaN       NaN       NaN   
420811       NaN     NaN       NaN       NaN     NaN       NaN       NaN   
189121       NaN     NaN       2.0       4.0     NaN       NaN       NaN   
238196       NaN     NaN       NaN       NaN     NaN       NaN       NaN   
181731       NaN     NaN       2.0       4.0     NaN       NaN       NaN   

        BRTHCNT4  WHEREGET  NOBCUSE8  BCPREFER  RRCLASS3  RRCOGNT2  RRTREAT  \
410792       NaN       NaN       NaN       NaN       NaN       NaN      NaN   
75448        NaN       NaN       NaN       NaN       NaN       NaN      NaN   
439484       NaN       NaN       NaN       NaN       NaN       NaN      NaN   
179447       NaN       NaN       NaN       NaN       NaN       NaN      NaN   
390924       NaN       NaN       NaN       NaN       NaN       NaN      NaN   
...          ...       ...       ...       ...       ...       ...      ...   
321216       NaN       NaN       NaN       NaN       1.0       7.0      2.0   
420811       NaN       NaN       NaN       NaN       NaN       NaN      NaN   
189121       NaN       NaN       NaN       NaN       NaN       NaN      NaN   
238196       NaN       NaN       NaN       NaN       NaN       NaN      NaN   
181731       NaN       NaN       NaN       NaN       NaN       NaN      NaN   

        RRATWRK2  RRHCARE4  RRPHYSM2  QSTVER  QSTLANG  METSTAT  URBSTAT  \
410792       NaN       NaN       NaN    20.0      1.0      1.0      1.0   
75448        NaN       NaN       NaN    20.0      1.0      1.0      1.0   
439484       NaN       NaN       NaN    20.0      2.0      NaN      NaN   
179447       NaN       NaN       NaN    23.0      1.0      1.0      1.0   
390924       NaN       NaN       NaN    10.0      1.0      1.0      1.0   
...          ...       ...       ...     ...      ...      ...      ...   
321216       NaN       2.0       2.0    10.0      1.0      1.0      1.0   
420811       NaN       NaN       NaN    20.0      1.0      2.0      2.0   
189121       NaN       NaN       NaN    23.0      1.0      1.0      1.0   
238196       NaN       NaN       NaN    10.0      1.0      1.0      1.0   
181731       NaN       NaN       NaN    11.0      1.0      1.0      1.0   

        MSCODE     STSTR       STRWT  RAWRAKE     WT2RAKE  IMPRACE  CHISPNC  \
410792     NaN  532011.0   34.399036      1.0   34.399036      1.0      9.0   
75448      NaN  122141.0  172.734833      1.0  172.734833      1.0      9.0   
439484     NaN  722011.0  140.162384      1.0  140.162384      5.0      9.0   
179447     NaN  252092.0   28.653528      1.0   28.653528      5.0      9.0   
390924     1.0  531161.0   12.983629      2.0   25.967258      3.0      9.0   
...        ...       ...         ...      ...         ...      ...      ...   
321216     3.0  451061.0    3.292533      1.0    3.292533      1.0      NaN   
420811     NaN  552062.0   12.734881      1.0   12.734881      1.0      9.0   
189121     NaN  262041.0   75.429985      1.0   75.429985      1.0      9.0   
238196     3.0  331081.0    7.434364      3.0   22.303093      1.0      9.0   
181731     1.0  261091.0   17.746788      2.0   35.493576      1.0      9.0   

        CRACE2  CPRACE2  CAGEG  CLLCPWT  DUALUSE   DUALCOR      LLCPWT2  \
410792     NaN      NaN    NaN      NaN      2.0  0.656351   388.521027   
75448      NaN      NaN    NaN      NaN      9.0       NaN  2796.276611   
439484     NaN      NaN    NaN      NaN      9.0       NaN   551.805725   
179447     NaN      NaN    NaN      NaN      9.0       NaN   430.192139   
390924     NaN      NaN    NaN      NaN      1.0  0.343649   153.558273   
...        ...      ...    ...      ...      ...       ...          ...   
321216     NaN      NaN    NaN      NaN      9.0       NaN   100.302292   
420811     NaN      NaN    NaN      NaN      9.0       NaN   382.623993   
189121     NaN      NaN    NaN      NaN      9.0       NaN   967.920349   
238196     NaN      NaN    NaN      NaN      1.0  0.621177   315.768005   
181731     NaN      NaN    NaN      NaN      1.0  0.490989   420.190948   

             LLCPWT  RFHLTH  PHYS14D  MENT14D  HLTHPLN  HCVU652  TOTINDA  \
410792   152.656052     2.0      3.0      3.0      1.0      1.0      2.0   
75448   1881.282349     1.0      2.0      1.0      1.0      1.0      1.0   
439484   188.245804     2.0      1.0      1.0      1.0      9.0      2.0   
179447   632.091187     2.0      2.0      3.0      1.0      1.0      1.0   
390924   541.812378     1.0      1.0      1.0      1.0      1.0      1.0   
...             ...     ...      ...      ...      ...      ...      ...   
321216    40.995720     2.0      3.0      3.0      1.0      9.0      2.0   
420811   322.629639     1.0      2.0      1.0      1.0      1.0      1.0   
189121   527.158508     1.0      1.0      2.0      1.0      1.0      1.0   
238196   112.328415     1.0      1.0      1.0      1.0      9.0      1.0   
181731   285.703003     1.0      2.0      2.0      1.0      9.0      1.0   

        EXTETH3  ALTETH3  DENVST3  MICHD  LTASTH1  CASTHM1  ASTHMS1  DRDXAR2  \
410792      1.0      NaN      2.0    2.0      1.0      1.0      3.0      1.0   
75448       1.0      NaN      2.0    2.0      1.0      1.0      3.0      2.0   
439484      2.0      1.0      1.0    2.0      1.0      1.0      3.0      2.0   
179447      2.0      NaN      1.0    2.0      1.0      1.0      3.0      2.0   
390924      2.0      NaN      1.0    2.0      2.0      9.0      9.0      1.0   
...         ...      ...      ...    ...      ...      ...      ...      ...   
321216      1.0      1.0      1.0    2.0      1.0      1.0      3.0      1.0   
420811      1.0      NaN      1.0    2.0      2.0      2.0      1.0      1.0   
189121      1.0      NaN      1.0    2.0      1.0      1.0      3.0      1.0   
238196      1.0      1.0      1.0    1.0      1.0      1.0      3.0      2.0   
181731      2.0      1.0      1.0    2.0      1.0      1.0      3.0      1.0   

        PRACE2  MRACE2  HISPANC  RACE1  RACEG22  RACEGR4  RACEPR1  SEX  \
410792     1.0     1.0      2.0    1.0      1.0      1.0      1.0  2.0   
75448     99.0    99.0      2.0    9.0      9.0      9.0      1.0  1.0   
439484     2.0     2.0      1.0    8.0      2.0      5.0      7.0  2.0   
179447     1.0     1.0      1.0    8.0      2.0      5.0      7.0  2.0   
390924     4.0     4.0      2.0    4.0      2.0      3.0      4.0  2.0   
...        ...     ...      ...    ...      ...      ...      ...  ...   
321216     1.0     1.0      2.0    1.0      1.0      1.0      1.0  2.0   
420811     1.0     1.0      2.0    1.0      1.0      1.0      1.0  2.0   
189121     1.0     1.0      2.0    1.0      1.0      1.0      1.0  2.0   
238196     1.0     1.0      2.0    1.0      1.0      1.0      1.0  1.0   
181731     1.0     1.0      2.0    1.0      1.0      1.0      1.0  2.0   

        AGEG5YR  AGE65YR  AGE80  AGE_G  HTIN4   HTM4    WTKG3    BMI5  \
410792      9.0      1.0   64.0    5.0   70.0  178.0   9072.0  2870.0   
75448       8.0      1.0   55.0    5.0   66.0  168.0   6804.0  2421.0   
439484     11.0      2.0   70.0    6.0   64.0  163.0   9072.0  3433.0   
179447      3.0      1.0   33.0    2.0    NaN    NaN      NaN     NaN   
390924      9.0      1.0   61.0    5.0   61.0  155.0   5488.0  2286.0   
...         ...      ...    ...    ...    ...    ...      ...     ...   
321216     12.0      2.0   76.0    6.0   66.0  168.0   7575.0  2695.0   
420811      7.0      1.0   52.0    4.0   67.0  170.0  11249.0  3884.0   
189121      7.0      1.0   54.0    4.0   65.0  165.0   8165.0  2995.0   
238196     12.0      2.0   79.0    6.0   64.0  163.0   7484.0  2832.0   
181731     13.0      2.0   80.0    6.0   63.0  160.0   7031.0  2746.0   

        BMI5CAT  RFBMI5  CHLDCNT  EDUCAG  INCOMG1  RFMAM22  MAM5023  HADCOLN  \
410792      3.0     2.0      1.0     4.0      3.0      1.0      1.0      1.0   
75448       2.0     1.0      1.0     3.0      6.0      NaN      NaN      1.0   
439484      4.0     2.0      1.0     3.0      2.0      2.0      2.0      2.0   
179447      NaN     9.0      4.0     2.0      9.0      NaN      NaN      NaN   
390924      2.0     1.0      1.0     4.0      6.0      2.0      2.0      1.0   
...         ...     ...      ...     ...      ...      ...      ...      ...   
321216      3.0     2.0      1.0     4.0      4.0      2.0      NaN      1.0   
420811      4.0     2.0      1.0     3.0      1.0      2.0      2.0      1.0   
189121      3.0     2.0      1.0     4.0      6.0      2.0      2.0      1.0   
238196      3.0     2.0      1.0     4.0      6.0      NaN      NaN      1.0   
181731      3.0     2.0      1.0     2.0      9.0      2.0      NaN      1.0   

        CLNSCP1  HADSIGM  SGMSCP1  SGMS101  RFBLDS5  STOLDN1  VIRCOL1  \
410792      2.0      2.0      3.0      3.0      2.0      3.0      3.0   
75448       1.0      2.0      3.0      3.0      NaN      NaN      NaN   
439484      3.0      2.0      3.0      3.0      1.0      3.0      3.0   
179447      NaN      NaN      NaN      NaN      NaN      NaN      NaN   
390924      1.0      2.0      3.0      3.0      3.0      3.0      3.0   
...         ...      ...      ...      ...      ...      ...      ...   
321216      NaN      2.0      NaN      NaN      NaN      NaN      NaN   
420811      1.0      2.0      3.0      3.0      3.0      3.0      3.0   
189121      1.0      2.0      3.0      3.0      3.0      3.0      3.0   
238196      NaN      1.0      NaN      NaN      NaN      NaN      NaN   
181731      NaN      1.0      NaN      NaN      NaN      NaN      NaN   

        SBONTI1  CRCREC2  SMOKER3  RFSMOK3  CURECI2  YRSSMOK  PACKDAY  \
410792      2.0      2.0      4.0      1.0      1.0      NaN      NaN   
75448       NaN      1.0      4.0      1.0      1.0      NaN      NaN   
439484      2.0      1.0      4.0      1.0      1.0      NaN      NaN   
179447      NaN      NaN      9.0      9.0      9.0      NaN      NaN   
390924      3.0      1.0      3.0      1.0      1.0     13.0     0.50   
...         ...      ...      ...      ...      ...      ...      ...   
321216      NaN      NaN      4.0      1.0      1.0      NaN      NaN   
420811      3.0      1.0      4.0      1.0      1.0      NaN      NaN   
189121      3.0      1.0      3.0      1.0      1.0     19.0     0.50   
238196      NaN      NaN      3.0      1.0      1.0      5.0     0.25   
181731      NaN      NaN      3.0      1.0      1.0     40.0     0.15   

        PACKYRS  YRSQUIT  SMOKGRP  LCSREC  DRNKANY6  DROCDY4_  RFBING6  \
410792      NaN      NaN      4.0     NaN       1.0      71.0      2.0   
75448       NaN      NaN      4.0     NaN       1.0      10.0      1.0   
439484      NaN      NaN      4.0     NaN       2.0       0.0      1.0   
179447      NaN      NaN      NaN     NaN       9.0     900.0      9.0   
390924      7.0     32.0      3.0     NaN       2.0       0.0      1.0   
...         ...      ...      ...     ...       ...       ...      ...   
321216      NaN      NaN      4.0     NaN       2.0       0.0      1.0   
420811      NaN      NaN      4.0     NaN       7.0     900.0      9.0   
189121     10.0     13.0      3.0     NaN       1.0       3.0      2.0   
238196      1.0     58.0      3.0     NaN       1.0      29.0      1.0   
181731      6.0     21.0      3.0     NaN       1.0      14.0      1.0   

        DRNKWK2  RFDRHV8  FLSHOT7  PNEUMO3  AIDTST4  
410792   3000.0      2.0      NaN      NaN      1.0  
75448      70.0      1.0      NaN      NaN      1.0  
439484      0.0      1.0      2.0      2.0      2.0  
179447  99900.0      9.0      NaN      NaN      NaN  
390924      0.0      1.0      NaN      NaN      1.0  
...         ...      ...      ...      ...      ...  
321216      0.0      1.0      1.0      1.0      9.0  
420811  99900.0      9.0      NaN      NaN      1.0  
189121     47.0      1.0      NaN      NaN      1.0  
238196    400.0      1.0      9.0      1.0      2.0  
181731    100.0      1.0      1.0      1.0      2.0  

[132621 rows x 326 columns]
2025-11-28 15:45:02,318:INFO:get_config() successfully completed......................................
2025-11-28 15:51:56,417:INFO:PyCaret ClassificationExperiment
2025-11-28 15:51:56,417:INFO:Logging name: clf-default-name
2025-11-28 15:51:56,417:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-11-28 15:51:56,417:INFO:version 3.3.2
2025-11-28 15:51:56,417:INFO:Initializing setup()
2025-11-28 15:51:56,417:INFO:self.USI: 97a8
2025-11-28 15:51:56,417:INFO:self._variable_keys: {'USI', 'memory', '_ml_usecase', 'data', 'logging_param', 'target_param', 'y_test', 'gpu_param', 'fix_imbalance', 'exp_id', 'gpu_n_jobs_param', 'seed', 'fold_shuffle_param', 'log_plots_param', 'X', 'is_multiclass', 'pipeline', 'y', 'fold_groups_param', 'X_test', 'n_jobs_param', 'idx', 'X_train', '_available_plots', 'exp_name_log', 'y_train', 'fold_generator', 'html_param'}
2025-11-28 15:51:56,417:INFO:Checking environment
2025-11-28 15:51:56,417:INFO:python_version: 3.10.19
2025-11-28 15:51:56,417:INFO:python_build: ('main', 'Oct 22 2025 22:23:22')
2025-11-28 15:51:56,417:INFO:machine: AMD64
2025-11-28 15:51:56,417:INFO:platform: Windows-10-10.0.26200-SP0
2025-11-28 15:51:56,417:INFO:Memory: svmem(total=16282144768, available=3864506368, percent=76.3, used=12417638400, free=3864506368)
2025-11-28 15:51:56,417:INFO:Physical Core: 6
2025-11-28 15:51:56,417:INFO:Logical Core: 12
2025-11-28 15:51:56,417:INFO:Checking libraries
2025-11-28 15:51:56,417:INFO:System:
2025-11-28 15:51:56,417:INFO:    python: 3.10.19 | packaged by conda-forge | (main, Oct 22 2025, 22:23:22) [MSC v.1944 64 bit (AMD64)]
2025-11-28 15:51:56,417:INFO:executable: c:\Users\OMAR\miniconda3\envs\xgb_env\python.exe
2025-11-28 15:51:56,417:INFO:   machine: Windows-10-10.0.26200-SP0
2025-11-28 15:51:56,417:INFO:PyCaret required dependencies:
2025-11-28 15:51:56,417:INFO:                 pip: 25.3
2025-11-28 15:51:56,417:INFO:          setuptools: 80.9.0
2025-11-28 15:51:56,417:INFO:             pycaret: 3.3.2
2025-11-28 15:51:56,417:INFO:             IPython: 8.37.0
2025-11-28 15:51:56,417:INFO:          ipywidgets: 8.1.8
2025-11-28 15:51:56,417:INFO:                tqdm: 4.67.1
2025-11-28 15:51:56,417:INFO:               numpy: 1.26.4
2025-11-28 15:51:56,417:INFO:              pandas: 2.1.4
2025-11-28 15:51:56,417:INFO:              jinja2: 3.1.6
2025-11-28 15:51:56,417:INFO:               scipy: 1.11.4
2025-11-28 15:51:56,417:INFO:              joblib: 1.3.2
2025-11-28 15:51:56,417:INFO:             sklearn: 1.4.2
2025-11-28 15:51:56,417:INFO:                pyod: 2.0.5
2025-11-28 15:51:56,417:INFO:            imblearn: 0.14.0
2025-11-28 15:51:56,417:INFO:   category_encoders: 2.7.0
2025-11-28 15:51:56,417:INFO:            lightgbm: 4.6.0
2025-11-28 15:51:56,417:INFO:               numba: 0.62.1
2025-11-28 15:51:56,417:INFO:            requests: 2.32.5
2025-11-28 15:51:56,417:INFO:          matplotlib: 3.7.5
2025-11-28 15:51:56,417:INFO:          scikitplot: 0.3.7
2025-11-28 15:51:56,417:INFO:         yellowbrick: 1.5
2025-11-28 15:51:56,417:INFO:              plotly: 6.5.0
2025-11-28 15:51:56,417:INFO:    plotly-resampler: Not installed
2025-11-28 15:51:56,417:INFO:             kaleido: 1.2.0
2025-11-28 15:51:56,417:INFO:           schemdraw: 0.15
2025-11-28 15:51:56,417:INFO:         statsmodels: 0.14.5
2025-11-28 15:51:56,417:INFO:              sktime: 0.26.0
2025-11-28 15:51:56,417:INFO:               tbats: 1.1.3
2025-11-28 15:51:56,417:INFO:            pmdarima: 2.0.4
2025-11-28 15:51:56,417:INFO:              psutil: 7.1.3
2025-11-28 15:51:56,417:INFO:          markupsafe: 3.0.3
2025-11-28 15:51:56,417:INFO:             pickle5: Not installed
2025-11-28 15:51:56,417:INFO:         cloudpickle: 3.1.2
2025-11-28 15:51:56,417:INFO:         deprecation: 2.1.0
2025-11-28 15:51:56,417:INFO:              xxhash: 3.6.0
2025-11-28 15:51:56,417:INFO:           wurlitzer: Not installed
2025-11-28 15:51:56,417:INFO:PyCaret optional dependencies:
2025-11-28 15:51:56,417:INFO:                shap: 0.48.0
2025-11-28 15:51:56,417:INFO:           interpret: Not installed
2025-11-28 15:51:56,417:INFO:                umap: Not installed
2025-11-28 15:51:56,417:INFO:     ydata_profiling: Not installed
2025-11-28 15:51:56,417:INFO:  explainerdashboard: Not installed
2025-11-28 15:51:56,417:INFO:             autoviz: Not installed
2025-11-28 15:51:56,417:INFO:           fairlearn: 0.12.0.dev0
2025-11-28 15:51:56,417:INFO:          deepchecks: Not installed
2025-11-28 15:51:56,417:INFO:             xgboost: 3.1.2
2025-11-28 15:51:56,417:INFO:            catboost: Not installed
2025-11-28 15:51:56,417:INFO:              kmodes: Not installed
2025-11-28 15:51:56,417:INFO:             mlxtend: Not installed
2025-11-28 15:51:56,417:INFO:       statsforecast: Not installed
2025-11-28 15:51:56,417:INFO:        tune_sklearn: Not installed
2025-11-28 15:51:56,417:INFO:                 ray: Not installed
2025-11-28 15:51:56,417:INFO:            hyperopt: Not installed
2025-11-28 15:51:56,417:INFO:              optuna: Not installed
2025-11-28 15:51:56,417:INFO:               skopt: Not installed
2025-11-28 15:51:56,417:INFO:              mlflow: Not installed
2025-11-28 15:51:56,417:INFO:              gradio: Not installed
2025-11-28 15:51:56,417:INFO:             fastapi: Not installed
2025-11-28 15:51:56,417:INFO:             uvicorn: Not installed
2025-11-28 15:51:56,417:INFO:              m2cgen: Not installed
2025-11-28 15:51:56,417:INFO:           evidently: Not installed
2025-11-28 15:51:56,417:INFO:               fugue: Not installed
2025-11-28 15:51:56,417:INFO:           streamlit: 1.51.0
2025-11-28 15:51:56,417:INFO:             prophet: Not installed
2025-11-28 15:51:56,417:INFO:None
2025-11-28 15:51:56,417:INFO:Set up data.
2025-11-28 15:51:56,509:INFO:Set up folding strategy.
2025-11-28 15:51:56,509:INFO:Set up train/test split.
2025-11-28 15:51:56,607:INFO:Set up index.
2025-11-28 15:51:56,611:INFO:Assigning column types.
2025-11-28 15:51:56,731:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-11-28 15:51:56,756:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-11-28 15:51:56,756:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-11-28 15:51:56,774:INFO:Soft dependency imported: xgboost: 3.1.2
2025-11-28 15:51:56,775:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-28 15:51:56,802:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-11-28 15:51:56,802:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-11-28 15:51:56,819:INFO:Soft dependency imported: xgboost: 3.1.2
2025-11-28 15:51:56,820:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-28 15:51:56,820:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-11-28 15:51:56,848:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-11-28 15:51:56,865:INFO:Soft dependency imported: xgboost: 3.1.2
2025-11-28 15:51:56,866:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-28 15:51:56,894:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-11-28 15:51:56,910:INFO:Soft dependency imported: xgboost: 3.1.2
2025-11-28 15:51:56,912:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-28 15:51:56,912:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-11-28 15:51:56,952:INFO:Soft dependency imported: xgboost: 3.1.2
2025-11-28 15:51:56,957:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-28 15:51:56,998:INFO:Soft dependency imported: xgboost: 3.1.2
2025-11-28 15:51:56,998:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-28 15:51:57,002:INFO:Preparing preprocessing pipeline...
2025-11-28 15:51:57,020:INFO:Set up simple imputation.
2025-11-28 15:51:57,062:INFO:Set up encoding of ordinal features.
2025-11-28 15:51:57,091:INFO:Set up encoding of categorical features.
2025-11-28 15:51:57,096:INFO:Set up imbalanced handling.
2025-11-28 15:51:57,335:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 15:51:57,630:INFO:Finished creating preprocessing pipeline.
2025-11-28 15:51:57,640:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\OMAR\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['STATE', 'FMONTH', 'DISPCODE',
                                             'PSU', 'CTELENM1', 'PVTRESD1',
                                             'COLGHOUS', 'STATERE1', 'CELPHON1',
                                             'LADULT1', 'COLGSEX1', 'NUMADULT',
                                             'LANDSEX1', 'NUMMEN', 'NUMWOMEN',
                                             'RESPSLCT', 'SAFETIME', 'CTELNUM1',
                                             'CELLFON5', 'CADULT1...
                                    transformer=TargetEncoder(cols=['IDATE',
                                                                    'IDAY'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              random_state=42,
                                                                              sampling_strategy='auto'))))],
         verbose=False)
2025-11-28 15:51:57,640:INFO:Creating final display dataframe.
2025-11-28 15:51:57,843:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 15:51:58,914:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 15:52:00,353:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target          CVDINFR4
2                   Target type            Binary
3           Original data shape      (13262, 327)
4        Transformed data shape      (21507, 333)
5   Transformed train set shape      (17528, 333)
6    Transformed test set shape       (3979, 333)
7              Numeric features               322
8          Categorical features                 4
9      Rows with missing values            100.0%
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16                Fix imbalance              True
17         Fix imbalance method             SMOTE
18               Fold Generator   StratifiedKFold
19                  Fold Number                10
20                     CPU Jobs                -1
21                      Use GPU             False
22               Log Experiment             False
23              Experiment Name  clf-default-name
24                          USI              97a8
2025-11-28 15:52:00,399:INFO:Soft dependency imported: xgboost: 3.1.2
2025-11-28 15:52:00,399:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-28 15:52:00,441:INFO:Soft dependency imported: xgboost: 3.1.2
2025-11-28 15:52:00,445:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-28 15:52:00,445:INFO:setup() successfully completed in 4.04s...............
2025-11-28 15:52:00,502:INFO:Initializing get_config()
2025-11-28 15:52:00,502:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020508BC6920>, variable=X_train)
2025-11-28 15:52:00,502:INFO:Variable: 'X_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_train_transformed' instead.
2025-11-28 15:52:00,502:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'X_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_train_transformed' instead.
  warnings.warn(msg)  # print on screen

2025-11-28 15:52:00,625:INFO:Variable:  returned as        STATE  FMONTH     IDATE IMONTH IDAY IYEAR  DISPCODE           PSU  \
720     54.0     1.0  01192022     01   19  2022    1100.0  2.022002e+09   
3896    20.0     8.0  09042022     09   04  2022    1200.0  2.022005e+09   
12399    9.0     1.0  02282022     02   28  2022    1200.0  2.022006e+09   
1720    22.0     1.0  03212022     03   21  2022    1100.0  2.022002e+09   
4419    51.0     7.0  07082022     07   08  2022    1100.0  2.022007e+09   
...      ...     ...       ...    ...  ...   ...       ...           ...   
868     51.0     7.0  07072022     07   07  2022    1100.0  2.022007e+09   
11800    8.0     1.0  01252022     01   25  2022    1100.0  2.022001e+09   
10049   53.0    10.0  11102022     11   10  2022    1200.0  2.022021e+09   
4993    50.0     7.0  08022022     08   02  2022    1100.0  2.022005e+09   
9992    53.0     4.0  04212022     04   21  2022    1100.0  2.022010e+09   

       CTELENM1  PVTRESD1  COLGHOUS  STATERE1  CELPHON1  LADULT1  COLGSEX1  \
720         NaN       NaN       NaN       NaN       NaN      NaN       NaN   
3896        NaN       NaN       NaN       NaN       NaN      NaN       NaN   
12399       NaN       NaN       NaN       NaN       NaN      NaN       NaN   
1720        NaN       NaN       NaN       NaN       NaN      NaN       NaN   
4419        NaN       NaN       NaN       NaN       NaN      NaN       NaN   
...         ...       ...       ...       ...       ...      ...       ...   
868         NaN       NaN       NaN       NaN       NaN      NaN       NaN   
11800       NaN       NaN       NaN       NaN       NaN      NaN       NaN   
10049       NaN       NaN       NaN       NaN       NaN      NaN       NaN   
4993        NaN       NaN       NaN       NaN       NaN      NaN       NaN   
9992        NaN       NaN       NaN       NaN       NaN      NaN       NaN   

       NUMADULT  LANDSEX1  NUMMEN  NUMWOMEN  RESPSLCT  SAFETIME  CTELNUM1  \
720         NaN       NaN     NaN       NaN       NaN       1.0       1.0   
3896        NaN       NaN     NaN       NaN       NaN       1.0       1.0   
12399       NaN       NaN     NaN       NaN       NaN       1.0       1.0   
1720        NaN       NaN     NaN       NaN       NaN       1.0       1.0   
4419        NaN       NaN     NaN       NaN       NaN       1.0       1.0   
...         ...       ...     ...       ...       ...       ...       ...   
868         NaN       NaN     NaN       NaN       NaN       1.0       1.0   
11800       NaN       NaN     NaN       NaN       NaN       1.0       1.0   
10049       NaN       NaN     NaN       NaN       NaN       1.0       1.0   
4993        NaN       NaN     NaN       NaN       NaN       1.0       1.0   
9992        NaN       NaN     NaN       NaN       NaN       1.0       1.0   

       CELLFON5  CADULT1  CELLSEX1  PVTRESD3  CCLGHOUS  CSTATE1  LANDLINE  \
720         1.0      1.0       1.0       1.0       NaN      1.0       1.0   
3896        1.0      1.0       2.0       1.0       NaN      1.0       1.0   
12399       1.0      1.0       2.0       1.0       NaN      1.0       2.0   
1720        1.0      1.0       2.0       1.0       NaN      1.0       2.0   
4419        1.0      1.0       1.0       1.0       NaN      1.0       1.0   
...         ...      ...       ...       ...       ...      ...       ...   
868         1.0      1.0       1.0       1.0       NaN      1.0       2.0   
11800       1.0      1.0       2.0       1.0       NaN      1.0       2.0   
10049       1.0      1.0       2.0       1.0       NaN      1.0       2.0   
4993        1.0      1.0       2.0       1.0       NaN      1.0       2.0   
9992        1.0      1.0       1.0       1.0       NaN      1.0       2.0   

       HHADULT  SEXVAR  GENHLTH  PHYSHLTH  MENTHLTH  POORHLTH  PRIMINSR  \
720        1.0     1.0      3.0      88.0       3.0      88.0       1.0   
3896       2.0     2.0      1.0      88.0      88.0       NaN       1.0   
12399      4.0     2.0      2.0      88.0      30.0      88.0       1.0   
1720       2.0     2.0      3.0      88.0      88.0       NaN       3.0   
4419       2.0     1.0      2.0      88.0      88.0       NaN       5.0   
...        ...     ...      ...       ...       ...       ...       ...   
868        2.0     1.0      2.0      88.0      88.0       NaN       2.0   
11800      2.0     2.0      4.0      20.0      15.0      20.0       3.0   
10049      2.0     2.0      1.0       5.0      88.0      88.0       1.0   
4993       2.0     2.0      3.0      88.0       5.0      88.0       1.0   
9992       2.0     1.0      3.0      88.0      88.0       NaN      10.0   

       PERSDOC3  MEDCOST1  CHECKUP1  EXERANY2  SLEPTIM1  LASTDEN4  RMVTETH4  \
720         2.0       2.0       1.0       1.0       5.0       1.0       1.0   
3896        1.0       2.0       1.0       1.0       7.0       1.0       8.0   
12399       1.0       1.0       1.0       2.0       7.0       1.0       8.0   
1720        1.0       2.0       1.0       1.0       7.0       1.0       1.0   
4419        3.0       2.0       4.0       1.0       8.0       1.0       8.0   
...         ...       ...       ...       ...       ...       ...       ...   
868         1.0       2.0       1.0       1.0       7.0       1.0       1.0   
11800       2.0       1.0       1.0       2.0      10.0       1.0       8.0   
10049       1.0       2.0       1.0       1.0       6.0       1.0       1.0   
4993        2.0       2.0       1.0       1.0       7.0       1.0       1.0   
9992        2.0       2.0       1.0       1.0       8.0       1.0       1.0   

       CVDCRHD4  CVDSTRK3  ASTHMA3  ASTHNOW  CHCSCNC1  CHCOCNC1  CHCCOPD3  \
720         2.0       2.0      2.0      NaN       1.0       2.0       2.0   
3896        2.0       2.0      2.0      NaN       2.0       2.0       2.0   
12399       2.0       2.0      1.0      1.0       2.0       2.0       2.0   
1720        2.0       2.0      2.0      NaN       2.0       2.0       2.0   
4419        2.0       2.0      2.0      NaN       2.0       2.0       2.0   
...         ...       ...      ...      ...       ...       ...       ...   
868         2.0       2.0      2.0      NaN       2.0       2.0       2.0   
11800       2.0       2.0      1.0      1.0       2.0       2.0       1.0   
10049       2.0       2.0      2.0      NaN       2.0       2.0       2.0   
4993        2.0       2.0      2.0      NaN       2.0       2.0       2.0   
9992        1.0       2.0      2.0      NaN       2.0       2.0       2.0   

       ADDEPEV3  CHCKDNY2  HAVARTH4  DIABETE4  DIABAGE4  MARITAL  EDUCA  \
720         2.0       2.0       2.0       1.0      46.0      1.0    5.0   
3896        2.0       2.0       2.0       3.0       NaN      1.0    6.0   
12399       1.0       2.0       2.0       3.0       NaN      1.0    6.0   
1720        2.0       2.0       2.0       3.0       NaN      1.0    4.0   
4419        2.0       2.0       2.0       3.0       NaN      5.0    4.0   
...         ...       ...       ...       ...       ...      ...    ...   
868         2.0       2.0       2.0       3.0       NaN      1.0    6.0   
11800       1.0       2.0       1.0       3.0       NaN      1.0    6.0   
10049       2.0       2.0       2.0       3.0       NaN      2.0    6.0   
4993        2.0       2.0       2.0       2.0       NaN      1.0    6.0   
9992        2.0       2.0       2.0       3.0       NaN      1.0    4.0   

       RENTHOM1  NUMHHOL4  NUMPHON4  CPDEMO1C  VETERAN3  EMPLOY1  CHILDREN  \
720         1.0       NaN       NaN       1.0       2.0      2.0      88.0   
3896        1.0       NaN       NaN       1.0       2.0      1.0      99.0   
12399       1.0       NaN       NaN       1.0       2.0      1.0       2.0   
1720        1.0       NaN       NaN       1.0       2.0      7.0      88.0   
4419        3.0       NaN       NaN       2.0       2.0      3.0      88.0   
...         ...       ...       ...       ...       ...      ...       ...   
868         1.0       NaN       NaN       1.0       2.0      2.0       1.0   
11800       1.0       NaN       NaN       1.0       2.0      8.0      88.0   
10049       1.0       NaN       NaN       1.0       2.0      1.0      88.0   
4993        1.0       NaN       NaN       1.0       2.0      1.0       3.0   
9992        1.0       NaN       NaN       1.0       2.0      7.0      88.0   

       INCOME3  PREGNANT  WEIGHT2  HEIGHT3  DEAF  BLIND  DECIDE  DIFFWALK  \
720        9.0       NaN    171.0    507.0   2.0    1.0     2.0       2.0   
3896      10.0       2.0   9999.0   9999.0   2.0    2.0     2.0       2.0   
12399     10.0       2.0      NaN      NaN   NaN    NaN     NaN       NaN   
1720       6.0       NaN    125.0    411.0   2.0    2.0     2.0       2.0   
4419      77.0       NaN    230.0    509.0   2.0    2.0     2.0       2.0   
...        ...       ...      ...      ...   ...    ...     ...       ...   
868       99.0       NaN    212.0    601.0   2.0    2.0     2.0       2.0   
11800      6.0       NaN    150.0    509.0   2.0    2.0     2.0       1.0   
10049      9.0       NaN      NaN      NaN   NaN    NaN     NaN       NaN   
4993      10.0       NaN    198.0    504.0   2.0    2.0     2.0       2.0   
9992       9.0       NaN    228.0    600.0   2.0    2.0     2.0       2.0   

       DIFFDRES  DIFFALON  HADMAM  HOWLONG  CERVSCRN  CRVCLCNC  CRVCLPAP  \
720         1.0       2.0     NaN      NaN       NaN       NaN       NaN   
3896        2.0       2.0     1.0      1.0       1.0       2.0       1.0   
12399       NaN       NaN     NaN      NaN       NaN       NaN       NaN   
1720        2.0       2.0     1.0      1.0       1.0       2.0       1.0   
4419        2.0       2.0     NaN      NaN       NaN       NaN       NaN   
...         ...       ...     ...      ...       ...       ...       ...   
868         2.0       2.0     NaN      NaN       NaN       NaN       NaN   
11800       2.0       1.0     1.0      3.0       1.0       3.0       1.0   
10049       NaN       NaN     NaN      NaN       NaN       NaN       NaN   
4993        2.0       2.0     1.0      2.0       1.0       1.0       1.0   
9992        2.0       2.0     NaN      NaN       NaN       NaN       NaN   

       CRVCLHPV  HADHYST2  HADSIGM4  COLNSIGM  COLNTES1  SIGMTES1  LASTSIG4  \
720         NaN       NaN       1.0       1.0       3.0       NaN       NaN   
3896        7.0       2.0       1.0       1.0       1.0       NaN       NaN   
12399       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
1720        2.0       1.0       1.0       1.0       3.0       NaN       NaN   
4419        NaN       NaN       NaN       NaN       NaN       NaN       NaN   
...         ...       ...       ...       ...       ...       ...       ...   
868         NaN       NaN       1.0       1.0       1.0       NaN       NaN   
11800       1.0       2.0       2.0       NaN       NaN       NaN       NaN   
10049       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
4993        1.0       2.0       2.0       NaN       NaN       NaN       NaN   
9992        NaN       NaN       1.0       1.0       5.0       NaN       NaN   

       COLNCNCR  VIRCOLO1  VCLNTES2  SMALSTOL  STOLTEST  STOOLDN2  BLDSTFIT  \
720         2.0       NaN       NaN       NaN       NaN       NaN       NaN   
3896        2.0       NaN       NaN       NaN       NaN       NaN       NaN   
12399       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
1720        2.0       NaN       NaN       NaN       NaN       NaN       NaN   
4419        NaN       NaN       NaN       NaN       NaN       NaN       NaN   
...         ...       ...       ...       ...       ...       ...       ...   
868         2.0       NaN       NaN       NaN       NaN       NaN       NaN   
11800       1.0       2.0       NaN       2.0       NaN       2.0       NaN   
10049       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
4993        2.0       NaN       NaN       NaN       NaN       NaN       NaN   
9992        2.0       NaN       NaN       NaN       NaN       NaN       NaN   

       SDNATES1  SMOKE100  SMOKDAY2  USENOW3  ECIGNOW2  LCSFIRST  LCSLAST  \
720         NaN       1.0       3.0      3.0       4.0      17.0     18.0   
3896        NaN       1.0       1.0      3.0       1.0       NaN      NaN   
12399       NaN       NaN       NaN      NaN       NaN       NaN      NaN   
1720        NaN       2.0       NaN      3.0       1.0       NaN      NaN   
4419        NaN       1.0       1.0      3.0       4.0      20.0      NaN   
...         ...       ...       ...      ...       ...       ...      ...   
868         NaN       2.0       NaN      3.0       1.0       NaN      NaN   
11800       NaN       2.0       NaN      3.0       1.0       NaN      NaN   
10049       NaN       NaN       NaN      NaN       NaN       NaN      NaN   
4993        NaN       2.0       NaN      3.0       1.0       NaN      NaN   
9992        NaN       1.0       3.0      3.0       1.0      16.0     58.0   

       LCSNUMCG  LCSCTSC1  LCSSCNCR  LCSCTWHN  ALCDAY4  AVEDRNK3  DRNK3GE5  \
720         3.0       1.0       2.0       NaN    215.0       1.0      88.0   
3896        NaN       NaN       NaN       NaN      NaN       NaN       NaN   
12399       NaN       NaN       NaN       NaN      NaN       NaN       NaN   
1720        NaN       2.0       NaN       NaN    102.0       1.0      88.0   
4419       20.0       2.0       NaN       NaN    202.0       4.0      88.0   
...         ...       ...       ...       ...      ...       ...       ...   
868         NaN       2.0       NaN       NaN    888.0       NaN       NaN   
11800       NaN       1.0       2.0       NaN    888.0       NaN       NaN   
10049       NaN       NaN       NaN       NaN      NaN       NaN       NaN   
4993        NaN       2.0       NaN       NaN    101.0       1.0      88.0   
9992       20.0       2.0       NaN       NaN    101.0       2.0      88.0   

       MAXDRNKS  FLUSHOT7  FLSHTMY3  PNEUVAC4  TETANUS1  HIVTST7  HIVTSTD3  \
720         2.0       1.0  112021.0       1.0       1.0      1.0   62017.0   
3896        NaN       NaN       NaN       NaN       NaN      NaN       NaN   
12399       NaN       NaN       NaN       NaN       NaN      NaN       NaN   
1720        2.0       1.0  102021.0       1.0       3.0      2.0       NaN   
4419        2.0       2.0       NaN       2.0       4.0      2.0       NaN   
...         ...       ...       ...       ...       ...      ...       ...   
868         NaN       1.0   92021.0       2.0       1.0      1.0  771990.0   
11800       NaN       2.0       NaN       2.0       4.0      2.0       NaN   
10049       NaN       NaN       NaN       NaN       NaN      NaN       NaN   
4993        1.0       2.0       NaN       1.0       1.0      2.0       NaN   
9992        2.0       2.0       NaN       2.0       7.0      2.0       NaN   

       HIVRISK5  COVIDPOS  COVIDSMP  COVIDPRM  PDIABTS1  PREDIAB2  DIABTYPE  \
720         2.0       2.0       NaN       NaN       NaN       NaN       NaN   
3896        NaN       NaN       NaN       NaN       NaN       NaN       NaN   
12399       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
1720        2.0       2.0       NaN       NaN       NaN       NaN       NaN   
4419        2.0       2.0       NaN       NaN       NaN       NaN       NaN   
...         ...       ...       ...       ...       ...       ...       ...   
868         2.0       2.0       NaN       NaN       NaN       NaN       NaN   
11800       2.0       1.0       1.0       2.0       NaN       NaN       NaN   
10049       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
4993        2.0       2.0       NaN       NaN       NaN       NaN       NaN   
9992        2.0       2.0       NaN       NaN       NaN       NaN       NaN   

       INSULIN1  CHKHEMO3  EYEEXAM1  DIABEYE1  DIABEDU1  FEETSORE  TOLDCFS  \
720         NaN       NaN       NaN       NaN       NaN       NaN      NaN   
3896        NaN       NaN       NaN       NaN       NaN       NaN      NaN   
12399       NaN       NaN       NaN       NaN       NaN       NaN      NaN   
1720        NaN       NaN       NaN       NaN       NaN       NaN      NaN   
4419        NaN       NaN       NaN       NaN       NaN       NaN      NaN   
...         ...       ...       ...       ...       ...       ...      ...   
868         NaN       NaN       NaN       NaN       NaN       NaN      NaN   
11800       NaN       NaN       NaN       NaN       NaN       NaN      NaN   
10049       NaN       NaN       NaN       NaN       NaN       NaN      NaN   
4993        NaN       NaN       NaN       NaN       NaN       NaN      NaN   
9992        NaN       NaN       NaN       NaN       NaN       NaN      NaN   

       HAVECFS  WORKCFS  IMFVPLA3  HPVADVC4  HPVADSHT  SHINGLE2  COVIDVA1  \
720        NaN      NaN       NaN       NaN       NaN       NaN       1.0   
3896       NaN      NaN       NaN       NaN       NaN       NaN       NaN   
12399      NaN      NaN       NaN       NaN       NaN       NaN       NaN   
1720       NaN      NaN       NaN       NaN       NaN       NaN       1.0   
4419       NaN      NaN       NaN       NaN       NaN       NaN       NaN   
...        ...      ...       ...       ...       ...       ...       ...   
868        NaN      NaN       NaN       NaN       NaN       1.0       NaN   
11800      NaN      NaN       NaN       NaN       NaN       NaN       NaN   
10049      NaN      NaN       NaN       NaN       NaN       NaN       NaN   
4993       NaN      NaN       NaN       NaN       NaN       NaN       NaN   
9992       NaN      NaN       NaN       NaN       NaN       NaN       NaN   

       COVACGET  COVIDNU1  COVIDINT  COVIDFS1  COVIDSE1  COPDCOGH  COPDFLEM  \
720         NaN       3.0       NaN   42020.0   52020.0       NaN       NaN   
3896        NaN       NaN       NaN       NaN       NaN       NaN       NaN   
12399       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
1720        NaN       3.0       NaN   12022.0   22022.0       NaN       NaN   
4419        NaN       NaN       NaN       NaN       NaN       NaN       NaN   
...         ...       ...       ...       ...       ...       ...       ...   
868         NaN       NaN       NaN       NaN       NaN       NaN       NaN   
11800       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
10049       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
4993        NaN       NaN       NaN       NaN       NaN       NaN       NaN   
9992        NaN       NaN       NaN       NaN       NaN       NaN       NaN   

       COPDBRTH  COPDBTST  COPDSMOK  CNCRDIFF  CNCRAGE  CNCRTYP2  CSRVTRT3  \
720         NaN       NaN       NaN       NaN      NaN       NaN       NaN   
3896        NaN       NaN       NaN       NaN      NaN       NaN       NaN   
12399       NaN       NaN       NaN       NaN      NaN       NaN       NaN   
1720        NaN       NaN       NaN       NaN      NaN       NaN       NaN   
4419        NaN       NaN       NaN       NaN      NaN       NaN       NaN   
...         ...       ...       ...       ...      ...       ...       ...   
868         NaN       NaN       NaN       NaN      NaN       NaN       NaN   
11800       NaN       NaN       NaN       NaN      NaN       NaN       NaN   
10049       NaN       NaN       NaN       NaN      NaN       NaN       NaN   
4993        NaN       NaN       NaN       NaN      NaN       NaN       NaN   
9992        NaN       NaN       NaN       NaN      NaN       NaN       NaN   

       CSRVDOC1  CSRVSUM  CSRVRTRN  CSRVINST  CSRVINSR  CSRVDEIN  CSRVCLIN  \
720         NaN      NaN       NaN       NaN       NaN       NaN       NaN   
3896        NaN      NaN       NaN       NaN       NaN       NaN       NaN   
12399       NaN      NaN       NaN       NaN       NaN       NaN       NaN   
1720        NaN      NaN       NaN       NaN       NaN       NaN       NaN   
4419        NaN      NaN       NaN       NaN       NaN       NaN       NaN   
...         ...      ...       ...       ...       ...       ...       ...   
868         NaN      NaN       NaN       NaN       NaN       NaN       NaN   
11800       NaN      NaN       NaN       NaN       NaN       NaN       NaN   
10049       NaN      NaN       NaN       NaN       NaN       NaN       NaN   
4993        NaN      NaN       NaN       NaN       NaN       NaN       NaN   
9992        NaN      NaN       NaN       NaN       NaN       NaN       NaN   

       CSRVPAIN  CSRVCTL2  PSATEST1  PSATIME1  PCPSARS2  PSASUGST  PCSTALK1  \
720         NaN       NaN       NaN       NaN       NaN       NaN       NaN   
3896        NaN       NaN       NaN       NaN       NaN       NaN       NaN   
12399       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
1720        NaN       NaN       NaN       NaN       NaN       NaN       NaN   
4419        NaN       NaN       NaN       NaN       NaN       NaN       NaN   
...         ...       ...       ...       ...       ...       ...       ...   
868         NaN       NaN       NaN       NaN       NaN       NaN       NaN   
11800       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
10049       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
4993        NaN       NaN       NaN       NaN       NaN       NaN       NaN   
9992        NaN       NaN       NaN       NaN       NaN       NaN       NaN   

       CIMEMLOS  CDHOUSE  CDASSIST  CDHELP  CDSOCIAL  CDDISCUS  CAREGIV1  \
720         NaN      NaN       NaN     NaN       NaN       NaN       NaN   
3896        NaN      NaN       NaN     NaN       NaN       NaN       NaN   
12399       NaN      NaN       NaN     NaN       NaN       NaN       NaN   
1720        NaN      NaN       NaN     NaN       NaN       NaN       2.0   
4419        NaN      NaN       NaN     NaN       NaN       NaN       2.0   
...         ...      ...       ...     ...       ...       ...       ...   
868         2.0      NaN       NaN     NaN       NaN       NaN       2.0   
11800       NaN      NaN       NaN     NaN       NaN       NaN       NaN   
10049       NaN      NaN       NaN     NaN       NaN       NaN       NaN   
4993        2.0      NaN       NaN     NaN       NaN       NaN       NaN   
9992        NaN      NaN       NaN     NaN       NaN       NaN       2.0   

       CRGVREL4  CRGVLNG1  CRGVHRS1  CRGVPRB3  CRGVALZD  CRGVPER1  CRGVHOU1  \
720         NaN       NaN       NaN       NaN       NaN       NaN       NaN   
3896        NaN       NaN       NaN       NaN       NaN       NaN       NaN   
12399       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
1720        NaN       NaN       NaN       NaN       NaN       NaN       NaN   
4419        NaN       NaN       NaN       NaN       NaN       NaN       NaN   
...         ...       ...       ...       ...       ...       ...       ...   
868         NaN       NaN       NaN       NaN       NaN       NaN       NaN   
11800       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
10049       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
4993        NaN       NaN       NaN       NaN       NaN       NaN       NaN   
9992        NaN       NaN       NaN       NaN       NaN       NaN       NaN   

       CRGVEXPT  ACEDEPRS  ACEDRINK  ACEDRUGS  ACEPRISN  ACEDIVRC  ACEPUNCH  \
720         NaN       NaN       NaN       NaN       NaN       NaN       NaN   
3896        NaN       NaN       NaN       NaN       NaN       NaN       NaN   
12399       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
1720        1.0       NaN       NaN       NaN       NaN       NaN       NaN   
4419        1.0       2.0       2.0       2.0       2.0       1.0       1.0   
...         ...       ...       ...       ...       ...       ...       ...   
868         1.0       1.0       2.0       2.0       2.0       2.0       3.0   
11800       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
10049       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
4993        NaN       NaN       NaN       NaN       NaN       NaN       NaN   
9992        2.0       NaN       NaN       NaN       NaN       NaN       NaN   

       ACEHURT1  ACESWEAR  ACETOUCH  ACETTHEM  ACEHVSEX  ACEADSAF  ACEADNED  \
720         NaN       NaN       NaN       NaN       NaN       NaN       NaN   
3896        NaN       NaN       NaN       NaN       NaN       NaN       NaN   
12399       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
1720        NaN       NaN       NaN       NaN       NaN       NaN       NaN   
4419        1.0       1.0       1.0       1.0       1.0       5.0       5.0   
...         ...       ...       ...       ...       ...       ...       ...   
868         1.0       1.0       1.0       1.0       1.0       5.0       5.0   
11800       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
10049       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
4993        NaN       NaN       NaN       NaN       NaN       NaN       NaN   
9992        NaN       NaN       NaN       NaN       NaN       NaN       NaN   

       LSATISFY  EMTSUPRT  SDHISOLT  SDHEMPLY  FOODSTMP  SDHFOOD1  SDHBILLS  \
720         3.0       7.0       7.0       2.0       2.0       5.0       2.0   
3896        NaN       NaN       NaN       NaN       NaN       NaN       NaN   
12399       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
1720        NaN       NaN       NaN       NaN       NaN       NaN       NaN   
4419        NaN       NaN       NaN       NaN       NaN       NaN       NaN   
...         ...       ...       ...       ...       ...       ...       ...   
868         NaN       NaN       NaN       NaN       NaN       NaN       NaN   
11800       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
10049       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
4993        2.0       2.0       3.0       2.0       1.0       5.0       2.0   
9992        1.0       1.0       4.0       2.0       2.0       5.0       2.0   

       SDHUTILS  SDHTRNSP  SDHSTRE1  MARIJAN1  MARJSMOK  MARJEAT  MARJVAPE  \
720         2.0       2.0       2.0       NaN       NaN      NaN       NaN   
3896        NaN       NaN       NaN       NaN       NaN      NaN       NaN   
12399       NaN       NaN       NaN       NaN       NaN      NaN       NaN   
1720        NaN       NaN       NaN       NaN       NaN      NaN       NaN   
4419        NaN       NaN       NaN      88.0       NaN      NaN       NaN   
...         ...       ...       ...       ...       ...      ...       ...   
868         NaN       NaN       NaN      88.0       NaN      NaN       NaN   
11800       NaN       NaN       NaN       NaN       NaN      NaN       NaN   
10049       NaN       NaN       NaN       NaN       NaN      NaN       NaN   
4993        2.0       2.0       4.0       NaN       NaN      NaN       NaN   
9992        2.0       2.0       4.0       NaN       NaN      NaN       NaN   

       MARJDAB  MARJOTHR  USEMRJN4  LASTSMK2  STOPSMK2  MENTCIGS  MENTECIG  \
720        NaN       NaN       NaN       NaN       NaN       NaN       NaN   
3896       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
12399      NaN       NaN       NaN       NaN       NaN       NaN       NaN   
1720       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
4419       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
...        ...       ...       ...       ...       ...       ...       ...   
868        NaN       NaN       NaN       NaN       NaN       NaN       NaN   
11800      NaN       NaN       NaN       NaN       NaN       NaN       NaN   
10049      NaN       NaN       NaN       NaN       NaN       NaN       NaN   
4993       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
9992       NaN       NaN       NaN       5.0       NaN       NaN       NaN   

       HEATTBCO  ASBIALCH  ASBIDRNK  ASBIBING  ASBIADVC  ASBIRDUC  FIREARM5  \
720         NaN       1.0       1.0       1.0       1.0       2.0       NaN   
3896        NaN       NaN       NaN       NaN       NaN       NaN       NaN   
12399       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
1720        NaN       NaN       NaN       NaN       NaN       NaN       NaN   
4419        NaN       NaN       NaN       NaN       NaN       NaN       NaN   
...         ...       ...       ...       ...       ...       ...       ...   
868         NaN       NaN       NaN       NaN       NaN       NaN       NaN   
11800       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
10049       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
4993        NaN       NaN       NaN       NaN       NaN       NaN       NaN   
9992        NaN       NaN       NaN       NaN       NaN       NaN       NaN   

       GUNLOAD  LOADULK2  RCSGEND1  RCSXBRTH  RCSRLTN2  CASTHDX2  CASTHNO2  \
720        NaN       NaN       NaN       NaN       NaN       NaN       NaN   
3896       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
12399      NaN       NaN       NaN       NaN       NaN       NaN       NaN   
1720       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
4419       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
...        ...       ...       ...       ...       ...       ...       ...   
868        NaN       NaN       NaN       NaN       NaN       NaN       NaN   
11800      NaN       NaN       NaN       NaN       NaN       NaN       NaN   
10049      NaN       NaN       NaN       NaN       NaN       NaN       NaN   
4993       NaN       NaN       2.0       NaN       1.0       2.0       NaN   
9992       NaN       NaN       NaN       NaN       NaN       NaN       NaN   

       BIRTHSEX  SOMALE  SOFEMALE  TRNSGNDR  HADSEX  PFPPRVN4  TYPCNTR9  \
720         1.0     2.0       NaN       4.0     NaN       NaN       NaN   
3896        NaN     NaN       2.0       4.0     NaN       NaN       NaN   
12399       NaN     NaN       2.0       4.0     NaN       NaN       NaN   
1720        2.0     NaN       2.0       4.0     NaN       NaN       NaN   
4419        NaN     2.0       NaN       4.0     NaN       NaN       NaN   
...         ...     ...       ...       ...     ...       ...       ...   
868         NaN     2.0       NaN       4.0     NaN       NaN       NaN   
11800       NaN     NaN       2.0       4.0     NaN       NaN       NaN   
10049       NaN     NaN       2.0       4.0     NaN       NaN       NaN   
4993        2.0     NaN       2.0       4.0     NaN       NaN       NaN   
9992        NaN     2.0       NaN       4.0     NaN       NaN       NaN   

       BRTHCNT4  WHEREGET  NOBCUSE8  BCPREFER  RRCLASS3  RRCOGNT2  RRTREAT  \
720         NaN       NaN       NaN       NaN       1.0       4.0      7.0   
3896        NaN       NaN       NaN       NaN       NaN       NaN      NaN   
12399       NaN       NaN       NaN       NaN       NaN       NaN      NaN   
1720        NaN       NaN       NaN       NaN       1.0       1.0      2.0   
4419        NaN       NaN       NaN       NaN       2.0       1.0      2.0   
...         ...       ...       ...       ...       ...       ...      ...   
868         NaN       NaN       NaN       NaN       1.0       5.0      3.0   
11800       NaN       NaN       NaN       NaN       NaN       NaN      NaN   
10049       NaN       NaN       NaN       NaN       NaN       NaN      NaN   
4993        NaN       NaN       NaN       NaN       3.0       8.0      2.0   
9992        NaN       NaN       NaN       NaN       NaN       NaN      NaN   

       RRATWRK2  RRHCARE4  RRPHYSM2  QSTVER  QSTLANG  METSTAT  URBSTAT  \
720         2.0       2.0       2.0    20.0      1.0      1.0      1.0   
3896        NaN       NaN       NaN    21.0      1.0      1.0      1.0   
12399       NaN       NaN       NaN    22.0      1.0      1.0      1.0   
1720        NaN       2.0       2.0    20.0      1.0      1.0      1.0   
4419        NaN       2.0       2.0    20.0      1.0      1.0      1.0   
...         ...       ...       ...     ...      ...      ...      ...   
868         2.0       3.0       2.0    20.0      1.0      1.0      1.0   
11800       NaN       NaN       NaN    21.0      1.0      2.0      1.0   
10049       NaN       NaN       NaN    20.0      1.0      1.0      1.0   
4993        2.0       2.0       2.0    20.0      1.0      1.0      1.0   
9992        NaN       NaN       NaN    20.0      1.0      1.0      1.0   

       MSCODE     STSTR      STRWT  RAWRAKE    WT2RAKE  IMPRACE  CHISPNC  \
720       NaN  542011.0  31.419962      1.0  31.419962      1.0      NaN   
3896      NaN  202031.0  25.224237      1.0  25.224237      1.0      9.0   
12399     NaN   92082.0   8.240453      1.0   8.240453      1.0      9.0   
1720      NaN  222101.0  30.394903      1.0  30.394903      1.0      NaN   
4419      NaN  512101.0  26.973183      1.0  26.973183      2.0      NaN   
...       ...       ...        ...      ...        ...      ...      ...   
868       NaN  512131.0  27.471043      1.0  27.471043      1.0      NaN   
11800     NaN   82011.0  32.891766      1.0  32.891766      1.0      NaN   
10049     NaN  532031.0  29.512003      1.0  29.512003      1.0      9.0   
4993      NaN  502041.0   4.915876      1.0   4.915876      5.0      1.0   
9992      NaN  532111.0  24.901403      1.0  24.901403      1.0      9.0   

       CRACE2  CPRACE2  CAGEG     CLLCPWT  DUALUSE   DUALCOR     LLCPWT2  \
720       NaN      NaN    NaN         NaN      2.0  0.549764  227.480301   
3896      NaN      NaN    NaN         NaN      2.0  0.464215  205.222443   
12399     NaN      NaN    NaN         NaN      9.0       NaN  119.102203   
1720      NaN      NaN    NaN         NaN      9.0       NaN  562.665955   
4419      NaN      NaN    NaN         NaN      2.0  0.427727  817.554260   
...       ...      ...    ...         ...      ...       ...         ...   
868       NaN      NaN    NaN         NaN      9.0       NaN  595.094177   
11800     NaN      NaN    NaN         NaN      9.0       NaN  389.329376   
10049     NaN      NaN    NaN         NaN      9.0       NaN  263.843597   
4993     88.0      NaN    3.0  219.474854      9.0       NaN   68.351936   
9992      NaN      NaN    NaN         NaN      9.0       NaN  245.326355   

            LLCPWT  RFHLTH  PHYS14D  MENT14D  HLTHPLN  HCVU652  TOTINDA  \
720     221.263245     1.0      1.0      2.0      1.0      1.0      1.0   
3896    172.647430     1.0      1.0      1.0      1.0      9.0      1.0   
12399   103.267838     1.0      1.0      3.0      1.0      1.0      2.0   
1720    268.984131     1.0      1.0      1.0      1.0      9.0      1.0   
4419   2100.551270     1.0      1.0      1.0      1.0      1.0      1.0   
...            ...     ...      ...      ...      ...      ...      ...   
868     321.381378     1.0      1.0      1.0      1.0      1.0      1.0   
11800   177.848862     2.0      3.0      3.0      1.0      1.0      2.0   
10049   166.740921     1.0      2.0      1.0      1.0      1.0      1.0   
4993     33.581871     1.0      1.0      2.0      1.0      1.0      1.0   
9992    176.818588     1.0      1.0      1.0      1.0      1.0      1.0   

       EXTETH3  ALTETH3  DENVST3  MICHD  LTASTH1  CASTHM1  ASTHMS1  DRDXAR2  \
720        2.0      NaN      1.0    2.0      1.0      1.0      3.0      2.0   
3896       1.0      9.0      1.0    2.0      1.0      1.0      3.0      2.0   
12399      1.0      NaN      1.0    2.0      2.0      2.0      1.0      2.0   
1720       2.0      1.0      1.0    2.0      1.0      1.0      3.0      2.0   
4419       1.0      NaN      1.0    2.0      1.0      1.0      3.0      2.0   
...        ...      ...      ...    ...      ...      ...      ...      ...   
868        2.0      NaN      1.0    2.0      1.0      1.0      3.0      2.0   
11800      1.0      NaN      1.0    2.0      2.0      2.0      1.0      1.0   
10049      2.0      NaN      1.0    2.0      1.0      1.0      3.0      2.0   
4993       2.0      NaN      1.0    2.0      1.0      1.0      3.0      2.0   
9992       2.0      NaN      1.0    1.0      1.0      1.0      3.0      2.0   

       PRACE2  MRACE2  HISPANC  RACE1  RACEG22  RACEGR4  RACEPR1  SEX  \
720      88.0    88.0      2.0    9.0      9.0      9.0      1.0  1.0   
3896      1.0     1.0      2.0    1.0      1.0      1.0      1.0  2.0   
12399     1.0     1.0      2.0    1.0      1.0      1.0      1.0  2.0   
1720      1.0     1.0      2.0    1.0      1.0      1.0      1.0  2.0   
4419      2.0     2.0      2.0    2.0      2.0      2.0      2.0  1.0   
...       ...     ...      ...    ...      ...      ...      ...  ...   
868       1.0     1.0      2.0    1.0      1.0      1.0      1.0  1.0   
11800     1.0     1.0      2.0    1.0      1.0      1.0      1.0  2.0   
10049     1.0     1.0      2.0    1.0      1.0      1.0      1.0  2.0   
4993     88.0    88.0      1.0    8.0      2.0      5.0      7.0  2.0   
9992      1.0     1.0      2.0    1.0      1.0      1.0      1.0  1.0   

       AGEG5YR  AGE65YR  AGE80  AGE_G  HTIN4   HTM4    WTKG3    BMI5  BMI5CAT  \
720        9.0      1.0   63.0    5.0   67.0  170.0   7756.0  2678.0      3.0   
3896      14.0      3.0   52.0    4.0    NaN    NaN      NaN     NaN      NaN   
12399      5.0      1.0   40.0    3.0    NaN    NaN      NaN     NaN      NaN   
1720      12.0      2.0   75.0    6.0   59.0  150.0   5670.0  2525.0      3.0   
4419       2.0      1.0   25.0    2.0   69.0  175.0  10433.0  3396.0      4.0   
...        ...      ...    ...    ...    ...    ...      ...     ...      ...   
868        7.0      1.0   52.0    4.0   73.0  185.0   9616.0  2797.0      3.0   
11800      8.0      1.0   55.0    5.0   69.0  175.0   6804.0  2215.0      2.0   
10049      7.0      1.0   52.0    4.0    NaN    NaN      NaN     NaN      NaN   
4993       7.0      1.0   50.0    4.0   64.0  163.0   8981.0  3399.0      4.0   
9992       9.0      1.0   62.0    5.0   72.0  183.0  10342.0  3092.0      4.0   

       RFBMI5  CHLDCNT  EDUCAG  INCOMG1  RFMAM22  MAM5023  HADCOLN  CLNSCP1  \
720       2.0      1.0     3.0      6.0      NaN      NaN      1.0      1.0   
3896      9.0      9.0     4.0      6.0      NaN      NaN      1.0      NaN   
12399     9.0      3.0     4.0      6.0      9.0      NaN      NaN      NaN   
1720      2.0      1.0     2.0      4.0      1.0      NaN      1.0      1.0   
4419      2.0      1.0     2.0      9.0      NaN      NaN      NaN      NaN   
...       ...      ...     ...      ...      ...      ...      ...      ...   
868       2.0      2.0     4.0      9.0      NaN      NaN      1.0      1.0   
11800     1.0      1.0     4.0      4.0      2.0      2.0      2.0      3.0   
10049     9.0      1.0     4.0      6.0      9.0      NaN      NaN      NaN   
4993      2.0      4.0     4.0      6.0      1.0      1.0      2.0      3.0   
9992      2.0      1.0     2.0      6.0      NaN      NaN      1.0      2.0   

       HADSIGM  SGMSCP1  SGMS101  RFBLDS5  STOLDN1  VIRCOL1  SBONTI1  CRCREC2  \
720        2.0      3.0      3.0      3.0      3.0      3.0      3.0      1.0   
3896       2.0      NaN      NaN      NaN      NaN      NaN      NaN      NaN   
12399      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN   
1720       2.0      3.0      3.0      3.0      3.0      3.0      3.0      1.0   
4419       NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN   
...        ...      ...      ...      ...      ...      ...      ...      ...   
868        2.0      3.0      3.0      3.0      3.0      3.0      3.0      1.0   
11800      2.0      3.0      3.0      3.0      3.0      3.0      3.0      3.0   
10049      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN   
4993       2.0      3.0      3.0      3.0      3.0      3.0      3.0      3.0   
9992       2.0      3.0      3.0      3.0      3.0      3.0      3.0      2.0   

       SMOKER3  RFSMOK3  CURECI2  YRSSMOK  PACKDAY  PACKYRS  YRSQUIT  SMOKGRP  \
720        3.0      1.0      1.0      1.0     0.15      0.0     45.0      3.0   
3896       1.0      2.0      1.0      NaN      NaN      NaN      NaN      3.0   
12399      9.0      9.0      9.0      NaN      NaN      NaN      NaN      NaN   
1720       4.0      1.0      1.0      NaN      NaN      NaN      NaN      4.0   
4419       1.0      2.0      1.0      5.0     1.00      5.0      NaN      3.0   
...        ...      ...      ...      ...      ...      ...      ...      ...   
868        4.0      1.0      1.0      NaN      NaN      NaN      NaN      4.0   
11800      4.0      1.0      1.0      NaN      NaN      NaN      NaN      4.0   
10049      9.0      9.0      9.0      NaN      NaN      NaN      NaN      NaN   
4993       4.0      1.0      1.0      NaN      NaN      NaN      NaN      4.0   
9992       3.0      1.0      1.0     42.0     1.00     42.0      4.0      2.0   

       LCSREC  DRNKANY6  DROCDY4_  RFBING6  DRNKWK2  RFDRHV8  FLSHOT7  \
720       2.0       1.0      50.0      1.0    350.0      1.0      NaN   
3896      NaN       9.0     900.0      9.0  99900.0      9.0      9.0   
12399     NaN       9.0     900.0      9.0  99900.0      9.0      NaN   
1720      NaN       1.0      29.0      1.0    200.0      1.0      1.0   
4419      NaN       1.0       7.0      1.0    187.0      1.0      NaN   
...       ...       ...       ...      ...      ...      ...      ...   
868       NaN       2.0       0.0      1.0      0.0      1.0      NaN   
11800     NaN       2.0       0.0      1.0      0.0      1.0      NaN   
10049     NaN       9.0     900.0      9.0  99900.0      9.0      NaN   
4993      NaN       1.0      14.0      1.0    100.0      1.0      NaN   
9992      NaN       1.0      14.0      1.0    200.0      1.0      NaN   

       PNEUMO3  AIDTST4  
720        NaN      1.0  
3896       9.0      NaN  
12399      NaN      NaN  
1720       1.0      2.0  
4419       NaN      2.0  
...        ...      ...  
868        NaN      1.0  
11800      NaN      2.0  
10049      NaN      NaN  
4993       NaN      2.0  
9992       NaN      2.0  

[9283 rows x 326 columns]
2025-11-28 15:52:00,625:INFO:get_config() successfully completed......................................
2025-11-28 15:52:00,629:INFO:Initializing get_config()
2025-11-28 15:52:00,629:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020508BC6920>, variable=X_test)
2025-11-28 15:52:00,629:INFO:Variable: 'X_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_test_transformed' instead.
2025-11-28 15:52:00,629:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'X_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_test_transformed' instead.
  warnings.warn(msg)  # print on screen

2025-11-28 15:52:00,746:INFO:Variable:  returned as       STATE  FMONTH     IDATE IMONTH IDAY IYEAR  DISPCODE           PSU  \
3064   28.0     1.0  04202022     04   20  2022    1200.0  2.022001e+09   
7094   49.0     7.0  08022022     08   02  2022    1100.0  2.022001e+09   
2690   55.0    11.0  11192022     11   19  2022    1200.0  2.022009e+09   
5406   33.0     1.0  01302022     01   30  2022    1100.0  2.022001e+09   
4078   19.0     5.0  05242022     05   24  2022    1100.0  2.022007e+09   
...     ...     ...       ...    ...  ...   ...       ...           ...   
3848   12.0     5.0  05102022     05   10  2022    1100.0  2.022007e+09   
9966   45.0     8.0  09022022     09   02  2022    1100.0  2.022007e+09   
7841   29.0     9.0  09192022     09   19  2022    1100.0  2.022006e+09   
7411   15.0    10.0  10292022     10   29  2022    1100.0  2.022006e+09   
7035   27.0     7.0  08042022     08   04  2022    1100.0  2.022008e+09   

      CTELENM1  PVTRESD1  COLGHOUS  STATERE1  CELPHON1  LADULT1  COLGSEX1  \
3064       NaN       NaN       NaN       NaN       NaN      NaN       NaN   
7094       1.0       1.0       NaN       1.0       2.0      1.0       NaN   
2690       NaN       NaN       NaN       NaN       NaN      NaN       NaN   
5406       1.0       1.0       NaN       1.0       2.0      1.0       NaN   
4078       NaN       NaN       NaN       NaN       NaN      NaN       NaN   
...        ...       ...       ...       ...       ...      ...       ...   
3848       NaN       NaN       NaN       NaN       NaN      NaN       NaN   
9966       NaN       NaN       NaN       NaN       NaN      NaN       NaN   
7841       NaN       NaN       NaN       NaN       NaN      NaN       NaN   
7411       NaN       NaN       NaN       NaN       NaN      NaN       NaN   
7035       NaN       NaN       NaN       NaN       NaN      NaN       NaN   

      NUMADULT  LANDSEX1  NUMMEN  NUMWOMEN  RESPSLCT  SAFETIME  CTELNUM1  \
3064       NaN       NaN     NaN       NaN       NaN       1.0       1.0   
7094       2.0       NaN     1.0       1.0       2.0       NaN       NaN   
2690       NaN       NaN     NaN       NaN       NaN       1.0       1.0   
5406       1.0       2.0     NaN       NaN       NaN       NaN       NaN   
4078       NaN       NaN     NaN       NaN       NaN       1.0       1.0   
...        ...       ...     ...       ...       ...       ...       ...   
3848       NaN       NaN     NaN       NaN       NaN       1.0       1.0   
9966       NaN       NaN     NaN       NaN       NaN       1.0       1.0   
7841       NaN       NaN     NaN       NaN       NaN       1.0       1.0   
7411       NaN       NaN     NaN       NaN       NaN       1.0       1.0   
7035       NaN       NaN     NaN       NaN       NaN       1.0       1.0   

      CELLFON5  CADULT1  CELLSEX1  PVTRESD3  CCLGHOUS  CSTATE1  LANDLINE  \
3064       1.0      1.0       2.0       1.0       NaN      1.0       2.0   
7094       NaN      NaN       NaN       NaN       NaN      NaN       NaN   
2690       1.0      1.0       1.0       1.0       NaN      1.0       2.0   
5406       NaN      NaN       NaN       NaN       NaN      NaN       NaN   
4078       1.0      1.0       1.0       1.0       NaN      1.0       2.0   
...        ...      ...       ...       ...       ...      ...       ...   
3848       1.0      1.0       2.0       1.0       NaN      1.0       2.0   
9966       1.0      1.0       2.0       1.0       NaN      1.0       2.0   
7841       1.0      1.0       2.0       1.0       NaN      1.0       2.0   
7411       1.0      1.0       1.0       1.0       NaN      1.0       2.0   
7035       1.0      1.0       2.0       1.0       NaN      1.0       2.0   

      HHADULT  SEXVAR  GENHLTH  PHYSHLTH  MENTHLTH  POORHLTH  PRIMINSR  \
3064      3.0     2.0      3.0       2.0       1.0       1.0       1.0   
7094      NaN     2.0      4.0      88.0      15.0      88.0       3.0   
2690      2.0     1.0      1.0      88.0      88.0       NaN       1.0   
5406      NaN     2.0      4.0      30.0      10.0      88.0       3.0   
4078      2.0     1.0      1.0      88.0      88.0       NaN       1.0   
...       ...     ...      ...       ...       ...       ...       ...   
3848      2.0     2.0      1.0      88.0       2.0      88.0       1.0   
9966      2.0     2.0      1.0      88.0      88.0       NaN       1.0   
7841      2.0     2.0      2.0      88.0      88.0       NaN       3.0   
7411      4.0     1.0      3.0      88.0      88.0       NaN       1.0   
7035      5.0     2.0      3.0      88.0      88.0       NaN       1.0   

      PERSDOC3  MEDCOST1  CHECKUP1  EXERANY2  SLEPTIM1  LASTDEN4  RMVTETH4  \
3064       1.0       2.0       1.0       2.0       6.0       1.0       1.0   
7094       1.0       2.0       1.0       1.0       8.0       1.0       8.0   
2690       1.0       2.0       1.0       1.0       6.0       1.0       8.0   
5406       2.0       2.0       1.0       2.0       6.0       4.0       3.0   
4078       1.0       2.0       1.0       1.0       8.0       1.0       2.0   
...        ...       ...       ...       ...       ...       ...       ...   
3848       2.0       2.0       1.0       1.0       7.0       1.0       8.0   
9966       3.0       2.0       1.0       1.0       6.0       1.0       8.0   
7841       3.0       2.0       1.0       2.0       5.0       1.0       2.0   
7411       1.0       2.0       2.0       2.0       5.0       4.0       8.0   
7035       3.0       2.0       1.0       1.0       8.0       1.0       1.0   

      CVDCRHD4  CVDSTRK3  ASTHMA3  ASTHNOW  CHCSCNC1  CHCOCNC1  CHCCOPD3  \
3064       2.0       2.0      2.0      NaN       1.0       2.0       2.0   
7094       2.0       2.0      1.0      2.0       2.0       2.0       2.0   
2690       2.0       2.0      2.0      NaN       2.0       2.0       2.0   
5406       1.0       1.0      1.0      1.0       2.0       2.0       1.0   
4078       2.0       2.0      2.0      NaN       2.0       2.0       2.0   
...        ...       ...      ...      ...       ...       ...       ...   
3848       2.0       2.0      2.0      NaN       2.0       2.0       2.0   
9966       2.0       2.0      2.0      NaN       2.0       2.0       2.0   
7841       2.0       2.0      2.0      NaN       2.0       2.0       2.0   
7411       2.0       2.0      2.0      NaN       2.0       2.0       2.0   
7035       2.0       2.0      2.0      NaN       2.0       2.0       2.0   

      ADDEPEV3  CHCKDNY2  HAVARTH4  DIABETE4  DIABAGE4  MARITAL  EDUCA  \
3064       2.0       2.0       2.0       3.0       NaN      1.0    5.0   
7094       1.0       2.0       1.0       3.0       NaN      1.0    5.0   
2690       2.0       2.0       2.0       3.0       NaN      1.0    5.0   
5406       2.0       2.0       1.0       1.0      65.0      9.0    6.0   
4078       2.0       2.0       2.0       3.0       NaN      1.0    4.0   
...        ...       ...       ...       ...       ...      ...    ...   
3848       7.0       2.0       2.0       3.0       NaN      1.0    6.0   
9966       2.0       2.0       2.0       3.0       NaN      5.0    6.0   
7841       1.0       2.0       7.0       3.0       NaN      1.0    4.0   
7411       2.0       2.0       2.0       3.0       NaN      2.0    5.0   
7035       2.0       2.0       1.0       3.0       NaN      1.0    6.0   

      RENTHOM1  NUMHHOL4  NUMPHON4  CPDEMO1C  VETERAN3  EMPLOY1  CHILDREN  \
3064       1.0       NaN       NaN       1.0       2.0      1.0       1.0   
7094       1.0       1.0       1.0       1.0       2.0      7.0      88.0   
2690       1.0       NaN       NaN       1.0       2.0      1.0      88.0   
5406       1.0       2.0       NaN       8.0       2.0      7.0      88.0   
4078       1.0       NaN       NaN       1.0       2.0      1.0      88.0   
...        ...       ...       ...       ...       ...      ...       ...   
3848       1.0       NaN       NaN       2.0       2.0      1.0       3.0   
9966       2.0       NaN       NaN       1.0       2.0      1.0      88.0   
7841       1.0       NaN       NaN       1.0       2.0      1.0      88.0   
7411       2.0       NaN       NaN       1.0       2.0      1.0       1.0   
7035       1.0       NaN       NaN       1.0       2.0      1.0      88.0   

      INCOME3  PREGNANT  WEIGHT2  HEIGHT3  DEAF  BLIND  DECIDE  DIFFWALK  \
3064     99.0       2.0   9999.0   9999.0   NaN    NaN     NaN       NaN   
7094     77.0       NaN    140.0    503.0   2.0    2.0     2.0       2.0   
2690      6.0       NaN    176.0    600.0   2.0    2.0     2.0       2.0   
5406     99.0       NaN    240.0    406.0   2.0    2.0     2.0       1.0   
4078      9.0       NaN    200.0    600.0   2.0    2.0     2.0       2.0   
...       ...       ...      ...      ...   ...    ...     ...       ...   
3848     11.0       2.0    120.0    504.0   2.0    2.0     2.0       2.0   
9966     11.0       2.0    115.0    502.0   2.0    2.0     2.0       2.0   
7841      4.0       NaN    170.0    507.0   2.0    2.0     2.0       2.0   
7411      9.0       NaN    180.0    507.0   2.0    2.0     2.0       2.0   
7035      9.0       NaN    170.0    506.0   2.0    2.0     2.0       2.0   

      DIFFDRES  DIFFALON  HADMAM  HOWLONG  CERVSCRN  CRVCLCNC  CRVCLPAP  \
3064       NaN       NaN     NaN      NaN       NaN       NaN       NaN   
7094       2.0       2.0     1.0      1.0       1.0       7.0       2.0   
2690       2.0       2.0     NaN      NaN       NaN       NaN       NaN   
5406       2.0       2.0     1.0      2.0       1.0       2.0       2.0   
4078       2.0       2.0     NaN      NaN       NaN       NaN       NaN   
...        ...       ...     ...      ...       ...       ...       ...   
3848       2.0       2.0     2.0      NaN       7.0       NaN       NaN   
9966       2.0       2.0     2.0      NaN       1.0       1.0       1.0   
7841       2.0       2.0     1.0      1.0       1.0       2.0       1.0   
7411       2.0       2.0     NaN      NaN       NaN       NaN       NaN   
7035       2.0       2.0     1.0      1.0       1.0       4.0       1.0   

      CRVCLHPV  HADHYST2  HADSIGM4  COLNSIGM  COLNTES1  SIGMTES1  LASTSIG4  \
3064       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
7094       7.0       1.0       1.0       1.0       1.0       NaN       NaN   
2690       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
5406       2.0       2.0       1.0       1.0       1.0       NaN       NaN   
4078       NaN       NaN       1.0       1.0       4.0       NaN       NaN   
...        ...       ...       ...       ...       ...       ...       ...   
3848       NaN       2.0       NaN       NaN       NaN       NaN       NaN   
9966       1.0       2.0       NaN       NaN       NaN       NaN       NaN   
7841       7.0       2.0       1.0       1.0       5.0       NaN       NaN   
7411       NaN       NaN       2.0       NaN       NaN       NaN       NaN   
7035       7.0       2.0       1.0       1.0       2.0       NaN       NaN   

      COLNCNCR  VIRCOLO1  VCLNTES2  SMALSTOL  STOLTEST  STOOLDN2  BLDSTFIT  \
3064       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
7094       2.0       NaN       NaN       NaN       NaN       NaN       NaN   
2690       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
5406       2.0       NaN       NaN       NaN       NaN       NaN       NaN   
4078       2.0       NaN       NaN       NaN       NaN       NaN       NaN   
...        ...       ...       ...       ...       ...       ...       ...   
3848       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
9966       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
7841       1.0       2.0       NaN       1.0       1.0       2.0       NaN   
7411       2.0       NaN       NaN       NaN       NaN       NaN       NaN   
7035       2.0       NaN       NaN       NaN       NaN       NaN       NaN   

      SDNATES1  SMOKE100  SMOKDAY2  USENOW3  ECIGNOW2  LCSFIRST  LCSLAST  \
3064       NaN       NaN       NaN      NaN       NaN       NaN      NaN   
7094       NaN       2.0       NaN      3.0       1.0       NaN      NaN   
2690       NaN       2.0       NaN      3.0       1.0       NaN      NaN   
5406       NaN       1.0       3.0      3.0       1.0      16.0     65.0   
4078       NaN       1.0       3.0      2.0       1.0      23.0     40.0   
...        ...       ...       ...      ...       ...       ...      ...   
3848       NaN       2.0       NaN      3.0       1.0       NaN      NaN   
9966       NaN       2.0       NaN      3.0       1.0       NaN      NaN   
7841       NaN       2.0       NaN      3.0       1.0       NaN      NaN   
7411       NaN       2.0       NaN      3.0       1.0       NaN      NaN   
7035       NaN       2.0       NaN      3.0       1.0       NaN      NaN   

      LCSNUMCG  LCSCTSC1  LCSSCNCR  LCSCTWHN  ALCDAY4  AVEDRNK3  DRNK3GE5  \
3064       NaN       NaN       NaN       NaN      NaN       NaN       NaN   
7094       NaN       2.0       NaN       NaN    888.0       NaN       NaN   
2690       NaN       2.0       NaN       NaN    201.0       2.0      88.0   
5406      30.0       1.0       1.0       1.0    888.0       NaN       NaN   
4078      20.0       2.0       NaN       NaN    101.0       2.0       1.0   
...        ...       ...       ...       ...      ...       ...       ...   
3848       NaN       2.0       NaN       NaN    205.0       4.0       1.0   
9966       NaN       2.0       NaN       NaN    888.0       NaN       NaN   
7841       NaN       2.0       NaN       NaN    204.0       1.0      88.0   
7411       NaN       2.0       NaN       NaN    888.0       NaN       NaN   
7035       NaN       1.0       2.0       NaN    103.0       2.0      88.0   

      MAXDRNKS  FLUSHOT7  FLSHTMY3  PNEUVAC4  TETANUS1  HIVTST7  HIVTSTD3  \
3064       NaN       NaN       NaN       NaN       NaN      NaN       NaN   
7094       NaN       2.0       NaN       1.0       1.0      2.0       NaN   
2690       2.0       2.0       NaN       1.0       1.0      1.0       NaN   
5406       NaN       1.0  112021.0       1.0       1.0      2.0       NaN   
4078       5.0       2.0       NaN       2.0       3.0      1.0  777777.0   
...        ...       ...       ...       ...       ...      ...       ...   
3848       6.0       2.0       NaN       1.0       3.0      1.0   22021.0   
9966       NaN       1.0  102021.0       2.0       4.0      1.0  777777.0   
7841       1.0       2.0       NaN       2.0       4.0      2.0       NaN   
7411       NaN       2.0       NaN       2.0       4.0      2.0       NaN   
7035       3.0       1.0   42022.0       2.0       3.0      2.0       NaN   

      HIVRISK5  COVIDPOS  COVIDSMP  COVIDPRM  PDIABTS1  PREDIAB2  DIABTYPE  \
3064       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
7094       2.0       2.0       NaN       NaN       NaN       NaN       NaN   
2690       NaN       NaN       NaN       NaN       1.0       3.0       NaN   
5406       2.0       2.0       NaN       NaN       NaN       NaN       NaN   
4078       2.0       1.0       2.0       NaN       1.0       3.0       NaN   
...        ...       ...       ...       ...       ...       ...       ...   
3848       2.0       2.0       NaN       NaN       NaN       NaN       NaN   
9966       2.0       1.0       2.0       NaN       8.0       3.0       NaN   
7841       2.0       1.0       2.0       NaN       7.0       3.0       NaN   
7411       2.0       2.0       NaN       NaN       3.0       3.0       NaN   
7035       2.0       2.0       NaN       NaN       7.0       3.0       NaN   

      INSULIN1  CHKHEMO3  EYEEXAM1  DIABEYE1  DIABEDU1  FEETSORE  TOLDCFS  \
3064       NaN       NaN       NaN       NaN       NaN       NaN      NaN   
7094       NaN       NaN       NaN       NaN       NaN       NaN      NaN   
2690       NaN       NaN       NaN       NaN       NaN       NaN      NaN   
5406       NaN       NaN       NaN       NaN       NaN       NaN      NaN   
4078       NaN       NaN       NaN       NaN       NaN       NaN      NaN   
...        ...       ...       ...       ...       ...       ...      ...   
3848       NaN       NaN       NaN       NaN       NaN       NaN      NaN   
9966       NaN       NaN       NaN       NaN       NaN       NaN      NaN   
7841       NaN       NaN       NaN       NaN       NaN       NaN      NaN   
7411       NaN       NaN       NaN       NaN       NaN       NaN      NaN   
7035       NaN       NaN       NaN       NaN       NaN       NaN      NaN   

      HAVECFS  WORKCFS  IMFVPLA3  HPVADVC4  HPVADSHT  SHINGLE2  COVIDVA1  \
3064      NaN      NaN       NaN       NaN       NaN       NaN       NaN   
7094      NaN      NaN       NaN       NaN       NaN       NaN       NaN   
2690      NaN      NaN       NaN       NaN       NaN       NaN       NaN   
5406      NaN      NaN       NaN       NaN       NaN       NaN       1.0   
4078      NaN      NaN       NaN       NaN       NaN       NaN       2.0   
...       ...      ...       ...       ...       ...       ...       ...   
3848      NaN      NaN       NaN       NaN       NaN       NaN       NaN   
9966      NaN      NaN       NaN       NaN       NaN       NaN       1.0   
7841      NaN      NaN       NaN       NaN       NaN       NaN       NaN   
7411      NaN      NaN       NaN       2.0       NaN       NaN       1.0   
7035      NaN      NaN       NaN       NaN       NaN       NaN       NaN   

      COVACGET  COVIDNU1  COVIDINT  COVIDFS1  COVIDSE1  COPDCOGH  COPDFLEM  \
3064       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
7094       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
2690       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
5406       NaN       3.0       NaN   12021.0   22021.0       NaN       NaN   
4078       4.0       NaN       NaN       NaN       NaN       NaN       NaN   
...        ...       ...       ...       ...       ...       ...       ...   
3848       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
9966       NaN       3.0       NaN  122020.0   62021.0       NaN       NaN   
7841       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
7411       NaN       4.0       NaN   32020.0   72020.0       NaN       NaN   
7035       NaN       NaN       NaN       NaN       NaN       NaN       NaN   

      COPDBRTH  COPDBTST  COPDSMOK  CNCRDIFF  CNCRAGE  CNCRTYP2  CSRVTRT3  \
3064       NaN       NaN       NaN       NaN      NaN       NaN       NaN   
7094       NaN       NaN       NaN       NaN      NaN       NaN       NaN   
2690       NaN       NaN       NaN       NaN      NaN       NaN       NaN   
5406       NaN       NaN       NaN       NaN      NaN       NaN       NaN   
4078       NaN       NaN       NaN       NaN      NaN       NaN       NaN   
...        ...       ...       ...       ...      ...       ...       ...   
3848       NaN       NaN       NaN       NaN      NaN       NaN       NaN   
9966       NaN       NaN       NaN       NaN      NaN       NaN       NaN   
7841       NaN       NaN       NaN       NaN      NaN       NaN       NaN   
7411       NaN       NaN       NaN       NaN      NaN       NaN       NaN   
7035       NaN       NaN       NaN       NaN      NaN       NaN       NaN   

      CSRVDOC1  CSRVSUM  CSRVRTRN  CSRVINST  CSRVINSR  CSRVDEIN  CSRVCLIN  \
3064       NaN      NaN       NaN       NaN       NaN       NaN       NaN   
7094       NaN      NaN       NaN       NaN       NaN       NaN       NaN   
2690       NaN      NaN       NaN       NaN       NaN       NaN       NaN   
5406       NaN      NaN       NaN       NaN       NaN       NaN       NaN   
4078       NaN      NaN       NaN       NaN       NaN       NaN       NaN   
...        ...      ...       ...       ...       ...       ...       ...   
3848       NaN      NaN       NaN       NaN       NaN       NaN       NaN   
9966       NaN      NaN       NaN       NaN       NaN       NaN       NaN   
7841       NaN      NaN       NaN       NaN       NaN       NaN       NaN   
7411       NaN      NaN       NaN       NaN       NaN       NaN       NaN   
7035       NaN      NaN       NaN       NaN       NaN       NaN       NaN   

      CSRVPAIN  CSRVCTL2  PSATEST1  PSATIME1  PCPSARS2  PSASUGST  PCSTALK1  \
3064       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
7094       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
2690       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
5406       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
4078       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
...        ...       ...       ...       ...       ...       ...       ...   
3848       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
9966       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
7841       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
7411       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
7035       NaN       NaN       NaN       NaN       NaN       NaN       NaN   

      CIMEMLOS  CDHOUSE  CDASSIST  CDHELP  CDSOCIAL  CDDISCUS  CAREGIV1  \
3064       NaN      NaN       NaN     NaN       NaN       NaN       NaN   
7094       2.0      NaN       NaN     NaN       NaN       NaN       1.0   
2690       NaN      NaN       NaN     NaN       NaN       NaN       NaN   
5406       NaN      NaN       NaN     NaN       NaN       NaN       2.0   
4078       NaN      NaN       NaN     NaN       NaN       NaN       NaN   
...        ...      ...       ...     ...       ...       ...       ...   
3848       NaN      NaN       NaN     NaN       NaN       NaN       NaN   
9966       NaN      NaN       NaN     NaN       NaN       NaN       NaN   
7841       NaN      NaN       NaN     NaN       NaN       NaN       NaN   
7411       NaN      NaN       NaN     NaN       NaN       NaN       NaN   
7035       NaN      NaN       NaN     NaN       NaN       NaN       NaN   

      CRGVREL4  CRGVLNG1  CRGVHRS1  CRGVPRB3  CRGVALZD  CRGVPER1  CRGVHOU1  \
3064       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
7094       6.0       4.0       4.0      13.0       1.0       1.0       1.0   
2690       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
5406       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
4078       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
...        ...       ...       ...       ...       ...       ...       ...   
3848       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
9966       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
7841       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
7411       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
7035       NaN       NaN       NaN       NaN       NaN       NaN       NaN   

      CRGVEXPT  ACEDEPRS  ACEDRINK  ACEDRUGS  ACEPRISN  ACEDIVRC  ACEPUNCH  \
3064       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
7094       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
2690       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
5406       2.0       NaN       NaN       NaN       NaN       NaN       NaN   
4078       NaN       2.0       2.0       2.0       2.0       2.0       1.0   
...        ...       ...       ...       ...       ...       ...       ...   
3848       NaN       2.0       1.0       2.0       2.0       2.0       1.0   
9966       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
7841       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
7411       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
7035       NaN       NaN       NaN       NaN       NaN       NaN       NaN   

      ACEHURT1  ACESWEAR  ACETOUCH  ACETTHEM  ACEHVSEX  ACEADSAF  ACEADNED  \
3064       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
7094       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
2690       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
5406       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
4078       1.0       1.0       1.0       1.0       1.0       5.0       5.0   
...        ...       ...       ...       ...       ...       ...       ...   
3848       1.0       1.0       1.0       1.0       1.0       5.0       5.0   
9966       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
7841       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
7411       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
7035       NaN       NaN       NaN       NaN       NaN       NaN       NaN   

      LSATISFY  EMTSUPRT  SDHISOLT  SDHEMPLY  FOODSTMP  SDHFOOD1  SDHBILLS  \
3064       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
7094       2.0       2.0       4.0       2.0       2.0       5.0       2.0   
2690       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
5406       3.0       5.0       3.0       2.0       1.0       5.0       2.0   
4078       1.0       1.0       5.0       2.0       2.0       5.0       2.0   
...        ...       ...       ...       ...       ...       ...       ...   
3848       1.0       2.0       4.0       2.0       2.0       5.0       2.0   
9966       2.0       1.0       4.0       2.0       2.0       5.0       2.0   
7841       2.0       3.0       3.0       2.0       2.0       5.0       2.0   
7411       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
7035       1.0       2.0       4.0       2.0       2.0       5.0       2.0   

      SDHUTILS  SDHTRNSP  SDHSTRE1  MARIJAN1  MARJSMOK  MARJEAT  MARJVAPE  \
3064       NaN       NaN       NaN       NaN       NaN      NaN       NaN   
7094       2.0       2.0       5.0       NaN       NaN      NaN       NaN   
2690       NaN       NaN       NaN       NaN       NaN      NaN       NaN   
5406       2.0       2.0       3.0       NaN       NaN      NaN       NaN   
4078       2.0       2.0       4.0       NaN       NaN      NaN       NaN   
...        ...       ...       ...       ...       ...      ...       ...   
3848       2.0       2.0       5.0       NaN       NaN      NaN       NaN   
9966       2.0       2.0       3.0       NaN       NaN      NaN       NaN   
7841       2.0       2.0       1.0       NaN       NaN      NaN       NaN   
7411       NaN       NaN       NaN      88.0       NaN      NaN       NaN   
7035       2.0       2.0       4.0       NaN       NaN      NaN       NaN   

      MARJDAB  MARJOTHR  USEMRJN4  LASTSMK2  STOPSMK2  MENTCIGS  MENTECIG  \
3064      NaN       NaN       NaN       NaN       NaN       NaN       NaN   
7094      NaN       NaN       NaN       NaN       NaN       NaN       NaN   
2690      NaN       NaN       NaN       NaN       NaN       NaN       NaN   
5406      NaN       NaN       NaN       NaN       NaN       NaN       NaN   
4078      NaN       NaN       NaN       NaN       NaN       NaN       NaN   
...       ...       ...       ...       ...       ...       ...       ...   
3848      NaN       NaN       NaN       NaN       NaN       NaN       NaN   
9966      NaN       NaN       NaN       NaN       NaN       NaN       NaN   
7841      NaN       NaN       NaN       NaN       NaN       NaN       NaN   
7411      NaN       NaN       NaN       NaN       NaN       NaN       NaN   
7035      NaN       NaN       NaN       NaN       NaN       NaN       NaN   

      HEATTBCO  ASBIALCH  ASBIDRNK  ASBIBING  ASBIADVC  ASBIRDUC  FIREARM5  \
3064       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
7094       NaN       1.0       1.0       7.0       2.0       2.0       NaN   
2690       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
5406       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
4078       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
...        ...       ...       ...       ...       ...       ...       ...   
3848       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
9966       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
7841       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
7411       NaN       NaN       NaN       NaN       NaN       NaN       NaN   
7035       NaN       1.0       7.0       1.0       7.0       2.0       1.0   

      GUNLOAD  LOADULK2  RCSGEND1  RCSXBRTH  RCSRLTN2  CASTHDX2  CASTHNO2  \
3064      NaN       NaN       NaN       NaN       NaN       NaN       NaN   
7094      NaN       NaN       NaN       NaN       NaN       NaN       NaN   
2690      NaN       NaN       NaN       NaN       NaN       NaN       NaN   
5406      NaN       NaN       NaN       NaN       NaN       NaN       NaN   
4078      NaN       NaN       NaN       NaN       NaN       NaN       NaN   
...       ...       ...       ...       ...       ...       ...       ...   
3848      NaN       NaN       2.0       NaN       1.0       2.0       NaN   
9966      NaN       NaN       NaN       NaN       NaN       NaN       NaN   
7841      NaN       NaN       NaN       NaN       NaN       NaN       NaN   
7411      NaN       NaN       2.0       NaN       1.0       2.0       NaN   
7035      2.0       NaN       NaN       NaN       NaN       NaN       NaN   

      BIRTHSEX  SOMALE  SOFEMALE  TRNSGNDR  HADSEX  PFPPRVN4  TYPCNTR9  \
3064       NaN     NaN       NaN       NaN     NaN       NaN       NaN   
7094       2.0     NaN       2.0       4.0     NaN       NaN       NaN   
2690       NaN     NaN       NaN       NaN     NaN       NaN       NaN   
5406       NaN     NaN       NaN       NaN     NaN       NaN       NaN   
4078       1.0     2.0       NaN       4.0     NaN       NaN       NaN   
...        ...     ...       ...       ...     ...       ...       ...   
3848       NaN     NaN       NaN       NaN     NaN       NaN       NaN   
9966       NaN     NaN       NaN       NaN     1.0       1.0       6.0   
7841       NaN     NaN       2.0       4.0     NaN       NaN       NaN   
7411       1.0     2.0       NaN       4.0     NaN       NaN       NaN   
7035       NaN     NaN       2.0       4.0     NaN       NaN       NaN   

      BRTHCNT4  WHEREGET  NOBCUSE8  BCPREFER  RRCLASS3  RRCOGNT2  RRTREAT  \
3064       NaN       NaN       NaN       NaN       NaN       NaN      NaN   
7094       NaN       NaN       NaN       NaN       NaN       NaN      NaN   
2690       NaN       NaN       NaN       NaN       NaN       NaN      NaN   
5406       NaN       NaN       NaN       NaN       NaN       NaN      NaN   
4078       NaN       NaN       NaN       NaN       NaN       NaN      NaN   
...        ...       ...       ...       ...       ...       ...      ...   
3848       NaN       NaN       NaN       NaN       NaN       NaN      NaN   
9966       0.0       1.0       NaN       6.0       1.0       3.0      3.0   
7841       NaN       NaN       NaN       NaN       NaN       NaN      NaN   
7411       NaN       NaN       NaN       NaN       NaN       NaN      NaN   
7035       NaN       NaN       NaN       NaN       1.0       4.0      3.0   

      RRATWRK2  RRHCARE4  RRPHYSM2  QSTVER  QSTLANG  METSTAT  URBSTAT  MSCODE  \
3064       NaN       NaN       NaN    20.0      1.0      2.0      1.0     NaN   
7094       NaN       NaN       NaN    11.0      1.0      1.0      1.0     2.0   
2690       NaN       NaN       NaN    20.0      1.0      1.0      1.0     NaN   
5406       NaN       NaN       NaN    10.0      1.0      2.0      1.0     5.0   
4078       NaN       NaN       NaN    22.0      1.0      1.0      1.0     NaN   
...        ...       ...       ...     ...      ...      ...      ...     ...   
3848       NaN       NaN       NaN    20.0      1.0      1.0      1.0     NaN   
9966       3.0       3.0       2.0    20.0      1.0      1.0      1.0     NaN   
7841       NaN       NaN       NaN    20.0      1.0      2.0      2.0     NaN   
7411       NaN       NaN       NaN    20.0      1.0      1.0      1.0     NaN   
7035       2.0       2.0       2.0    20.0      1.0      2.0      1.0     NaN   

         STSTR       STRWT  RAWRAKE     WT2RAKE  IMPRACE  CHISPNC  CRACE2  \
3064  282081.0   28.492376      1.0   28.492376      1.0      9.0     NaN   
7094  491031.0   10.145546      2.0   20.291092      1.0      9.0     NaN   
2690  552021.0   27.905266      1.0   27.905266      1.0      9.0     NaN   
5406  331071.0    5.338731      1.0    5.338731      1.0      9.0     NaN   
4078  192011.0   62.956829      1.0   62.956829      1.0      NaN     NaN   
...        ...         ...      ...         ...      ...      ...     ...   
3848  122361.0  278.095062      1.0  278.095062      1.0      2.0     1.0   
9966  452041.0   40.883793      1.0   40.883793      1.0      NaN     NaN   
7841  292092.0   49.860222      1.0   49.860222      1.0      9.0     NaN   
7411  152011.0   33.954716      1.0   33.954716      3.0      2.0     4.0   
7035  272051.0   10.358928      1.0   10.358928      1.0      9.0     NaN   

      CPRACE2  CAGEG      CLLCPWT  DUALUSE   DUALCOR      LLCPWT2  \
3064      NaN    NaN          NaN      9.0       NaN   444.960327   
7094      NaN    NaN          NaN      1.0  0.329513   100.684883   
2690      NaN    NaN          NaN      9.0       NaN   796.997192   
5406      NaN    NaN          NaN      9.0       NaN    77.780647   
4078      NaN    NaN          NaN      9.0       NaN   459.487732   
...       ...    ...          ...      ...       ...          ...   
3848      1.0    1.0  7634.865723      9.0       NaN  3486.888428   
9966      NaN    NaN          NaN      9.0       NaN   598.121826   
7841      NaN    NaN          NaN      9.0       NaN   374.905426   
7411      4.0    3.0    64.473625      9.0       NaN   177.631119   
7035      NaN    NaN          NaN      9.0       NaN   294.094330   

           LLCPWT  RFHLTH  PHYS14D  MENT14D  HLTHPLN  HCVU652  TOTINDA  \
3064   432.689270     1.0      2.0      2.0      1.0      1.0      2.0   
7094    67.612061     2.0      1.0      3.0      1.0      9.0      1.0   
2690  2129.954102     1.0      1.0      1.0      1.0      1.0      1.0   
5406    51.311665     2.0      3.0      2.0      1.0      9.0      2.0   
4078   364.324219     1.0      1.0      1.0      1.0      1.0      1.0   
...           ...     ...      ...      ...      ...      ...      ...   
3848  3365.920410     1.0      1.0      2.0      1.0      1.0      1.0   
9966   443.944580     1.0      1.0      1.0      1.0      1.0      1.0   
7841   229.813339     1.0      1.0      1.0      1.0      9.0      2.0   
7411   138.597214     1.0      1.0      1.0      1.0      1.0      2.0   
7035   117.460205     1.0      1.0      1.0      1.0      1.0      1.0   

      EXTETH3  ALTETH3  DENVST3  MICHD  LTASTH1  CASTHM1  ASTHMS1  DRDXAR2  \
3064      2.0      NaN      1.0    2.0      1.0      1.0      3.0      2.0   
7094      1.0      1.0      1.0    2.0      2.0      1.0      2.0      1.0   
2690      1.0      NaN      1.0    2.0      1.0      1.0      3.0      2.0   
5406      2.0      2.0      2.0    1.0      2.0      2.0      1.0      1.0   
4078      2.0      NaN      1.0    2.0      1.0      1.0      3.0      2.0   
...       ...      ...      ...    ...      ...      ...      ...      ...   
3848      1.0      NaN      1.0    2.0      1.0      1.0      3.0      2.0   
9966      1.0      NaN      1.0    2.0      1.0      1.0      3.0      2.0   
7841      2.0      1.0      1.0    2.0      1.0      1.0      3.0      NaN   
7411      1.0      NaN      2.0    2.0      1.0      1.0      3.0      2.0   
7035      2.0      NaN      1.0    2.0      1.0      1.0      3.0      1.0   

      PRACE2  MRACE2  HISPANC  RACE1  RACEG22  RACEGR4  RACEPR1  SEX  AGEG5YR  \
3064     1.0     1.0      2.0    1.0      1.0      1.0      1.0  2.0      6.0   
7094     1.0     1.0      2.0    1.0      1.0      1.0      1.0  2.0     12.0   
2690     1.0     1.0      2.0    1.0      1.0      1.0      1.0  1.0      3.0   
5406     1.0     1.0      2.0    1.0      1.0      1.0      1.0  2.0     11.0   
4078     1.0     1.0      2.0    1.0      1.0      1.0      1.0  1.0      8.0   
...      ...     ...      ...    ...      ...      ...      ...  ...      ...   
3848     1.0     1.0      2.0    1.0      1.0      1.0      1.0  2.0      4.0   
9966     1.0     1.0      2.0    1.0      1.0      1.0      1.0  2.0      3.0   
7841     1.0     1.0      2.0    1.0      1.0      1.0      1.0  2.0     10.0   
7411     4.0     4.0      2.0    4.0      2.0      3.0      4.0  1.0      6.0   
7035     1.0     1.0      2.0    1.0      1.0      1.0      1.0  2.0      9.0   

      AGE65YR  AGE80  AGE_G  HTIN4   HTM4    WTKG3    BMI5  BMI5CAT  RFBMI5  \
3064      1.0   48.0    4.0    NaN    NaN      NaN     NaN      NaN     9.0   
7094      2.0   79.0    6.0   63.0  160.0   6350.0  2480.0      2.0     1.0   
2690      1.0   34.0    2.0   72.0  183.0   7983.0  2387.0      2.0     1.0   
5406      2.0   72.0    6.0   54.0  137.0  10886.0  5787.0      4.0     2.0   
4078      1.0   58.0    5.0   72.0  183.0   9072.0  2712.0      3.0     2.0   
...       ...    ...    ...    ...    ...      ...     ...      ...     ...   
3848      1.0   36.0    3.0   64.0  163.0   5443.0  2060.0      2.0     1.0   
9966      1.0   31.0    2.0   62.0  157.0   5216.0  2103.0      2.0     1.0   
7841      2.0   65.0    6.0   67.0  170.0   7711.0  2663.0      3.0     2.0   
7411      1.0   49.0    4.0   67.0  170.0   8165.0  2819.0      3.0     2.0   
7035      1.0   62.0    5.0   66.0  168.0   7711.0  2744.0      3.0     2.0   

      CHLDCNT  EDUCAG  INCOMG1  RFMAM22  MAM5023  HADCOLN  CLNSCP1  HADSIGM  \
3064      2.0     3.0      9.0      9.0      NaN      NaN      NaN      NaN   
7094      1.0     3.0      9.0      1.0      NaN      1.0      NaN      2.0   
2690      1.0     3.0      4.0      NaN      NaN      NaN      NaN      NaN   
5406      1.0     4.0      9.0      1.0      1.0      1.0      1.0      2.0   
4078      1.0     2.0      6.0      NaN      NaN      1.0      1.0      2.0   
...       ...     ...      ...      ...      ...      ...      ...      ...   
3848      4.0     4.0      7.0      NaN      NaN      NaN      NaN      NaN   
9966      1.0     4.0      7.0      NaN      NaN      NaN      NaN      NaN   
7841      1.0     2.0      2.0      1.0      1.0      1.0      2.0      2.0   
7411      2.0     3.0      6.0      NaN      NaN      2.0      3.0      2.0   
7035      1.0     4.0      6.0      1.0      1.0      1.0      1.0      2.0   

      SGMSCP1  SGMS101  RFBLDS5  STOLDN1  VIRCOL1  SBONTI1  CRCREC2  SMOKER3  \
3064      NaN      NaN      NaN      NaN      NaN      NaN      NaN      9.0   
7094      NaN      NaN      NaN      NaN      NaN      NaN      NaN      4.0   
2690      NaN      NaN      NaN      NaN      NaN      NaN      NaN      4.0   
5406      3.0      3.0      3.0      3.0      3.0      3.0      1.0      3.0   
4078      3.0      3.0      3.0      3.0      3.0      3.0      1.0      3.0   
...       ...      ...      ...      ...      ...      ...      ...      ...   
3848      NaN      NaN      NaN      NaN      NaN      NaN      NaN      4.0   
9966      NaN      NaN      NaN      NaN      NaN      NaN      NaN      4.0   
7841      3.0      3.0      1.0      3.0      3.0      2.0      1.0      4.0   
7411      3.0      3.0      3.0      3.0      3.0      3.0      3.0      4.0   
7035      3.0      3.0      3.0      3.0      3.0      3.0      1.0      4.0   

      RFSMOK3  CURECI2  YRSSMOK  PACKDAY  PACKYRS  YRSQUIT  SMOKGRP  LCSREC  \
3064      9.0      9.0      NaN      NaN      NaN      NaN      NaN     NaN   
7094      1.0      1.0      NaN      NaN      NaN      NaN      4.0     NaN   
2690      1.0      1.0      NaN      NaN      NaN      NaN      4.0     NaN   
5406      1.0      1.0     49.0      1.5     74.0      7.0      2.0     1.0   
4078      1.0      1.0     17.0      1.0     17.0     18.0      3.0     NaN   
...       ...      ...      ...      ...      ...      ...      ...     ...   
3848      1.0      1.0      NaN      NaN      NaN      NaN      4.0     NaN   
9966      1.0      1.0      NaN      NaN      NaN      NaN      4.0     NaN   
7841      1.0      1.0      NaN      NaN      NaN      NaN      4.0     NaN   
7411      1.0      1.0      NaN      NaN      NaN      NaN      4.0     NaN   
7035      1.0      1.0      NaN      NaN      NaN      NaN      4.0     NaN   

      DRNKANY6  DROCDY4_  RFBING6  DRNKWK2  RFDRHV8  FLSHOT7  PNEUMO3  AIDTST4  
3064       9.0     900.0      9.0  99900.0      9.0      NaN      NaN      NaN  
7094       2.0       0.0      1.0      0.0      1.0      2.0      1.0      2.0  
2690       1.0       3.0      1.0     47.0      1.0      NaN      NaN      1.0  
5406       2.0       0.0      1.0      0.0      1.0      1.0      1.0      2.0  
4078       1.0      14.0      2.0    200.0      1.0      NaN      NaN      1.0  
...        ...       ...      ...      ...      ...      ...      ...      ...  
3848       1.0      17.0      2.0    467.0      1.0      NaN      NaN      1.0  
9966       2.0       0.0      1.0      0.0      1.0      NaN      NaN      1.0  
7841       1.0      13.0      1.0     93.0      1.0      2.0      2.0      2.0  
7411       2.0       0.0      1.0      0.0      1.0      NaN      NaN      2.0  
7035       1.0      43.0      1.0    600.0      1.0      NaN      NaN      2.0  

[3979 rows x 326 columns]
2025-11-28 15:52:00,749:INFO:get_config() successfully completed......................................
2025-11-28 15:52:59,135:INFO:Initializing compare_models()
2025-11-28 15:52:59,135:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020508BC6920>, include=['xgboost', 'lightgbm', 'rf', 'gbc'], fold=None, round=4, cross_validation=True, sort=Recall, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000020508BC6920>, 'include': ['xgboost', 'lightgbm', 'rf', 'gbc'], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Recall', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2025-11-28 15:52:59,135:INFO:Checking exceptions
2025-11-28 15:52:59,215:INFO:Preparing display monitor
2025-11-28 15:52:59,241:INFO:Initializing Extreme Gradient Boosting
2025-11-28 15:52:59,242:INFO:Total runtime is 1.6681353251139323e-05 minutes
2025-11-28 15:52:59,245:INFO:SubProcess create_model() called ==================================
2025-11-28 15:52:59,245:INFO:Initializing create_model()
2025-11-28 15:52:59,246:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020508BC6920>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002051006BC40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-28 15:52:59,246:INFO:Checking exceptions
2025-11-28 15:52:59,246:INFO:Importing libraries
2025-11-28 15:52:59,246:INFO:Copying training dataset
2025-11-28 15:52:59,367:INFO:Defining folds
2025-11-28 15:52:59,367:INFO:Declaring metric variables
2025-11-28 15:52:59,370:INFO:Importing untrained model
2025-11-28 15:52:59,373:INFO:Extreme Gradient Boosting Imported successfully
2025-11-28 15:52:59,376:INFO:Starting cross validation
2025-11-28 15:52:59,379:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-28 15:53:04,359:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-28 15:53:04,359:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-28 15:53:04,359:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-28 15:53:04,359:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-28 15:53:04,359:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-28 15:53:04,359:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-28 15:53:04,359:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-28 15:53:04,359:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-28 15:53:04,359:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-28 15:53:04,947:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 15:53:04,958:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 15:53:04,960:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 15:53:04,972:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 15:53:04,976:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 15:53:04,995:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 15:53:05,002:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 15:53:05,002:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 15:53:05,005:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 15:53:05,012:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 15:53:09,417:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 15:53:09,444:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 15:53:09,447:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 15:53:09,457:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 15:53:09,474:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 15:53:09,475:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 15:53:09,477:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 15:53:09,501:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 15:53:09,510:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 15:53:09,526:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 15:53:09,705:INFO:Calculating mean and std
2025-11-28 15:53:09,705:INFO:Creating metrics dataframe
2025-11-28 15:53:09,709:INFO:Uploading results into container
2025-11-28 15:53:09,709:INFO:Uploading model into container now
2025-11-28 15:53:09,709:INFO:_master_model_container: 1
2025-11-28 15:53:09,709:INFO:_display_container: 2
2025-11-28 15:53:09,711:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              feature_weights=None, gamma=None, grow_policy=None,
              importance_type=None, interaction_constraints=None,
              learning_rate=None, max_bin=None, max_cat_threshold=None,
              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,
              max_leaves=None, min_child_weight=None, missing=nan,
              monotone_constraints=None, multi_strategy=None, n_estimators=None,
              n_jobs=-1, num_parallel_tree=None, ...)
2025-11-28 15:53:09,711:INFO:create_model() successfully completed......................................
2025-11-28 15:53:09,880:INFO:SubProcess create_model() end ==================================
2025-11-28 15:53:09,880:INFO:Creating metrics dataframe
2025-11-28 15:53:09,885:INFO:Initializing Light Gradient Boosting Machine
2025-11-28 15:53:09,885:INFO:Total runtime is 0.1773943305015564 minutes
2025-11-28 15:53:09,885:INFO:SubProcess create_model() called ==================================
2025-11-28 15:53:09,889:INFO:Initializing create_model()
2025-11-28 15:53:09,889:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020508BC6920>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002051006BC40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-28 15:53:09,889:INFO:Checking exceptions
2025-11-28 15:53:09,889:INFO:Importing libraries
2025-11-28 15:53:09,889:INFO:Copying training dataset
2025-11-28 15:53:10,003:INFO:Defining folds
2025-11-28 15:53:10,003:INFO:Declaring metric variables
2025-11-28 15:53:10,005:INFO:Importing untrained model
2025-11-28 15:53:10,010:INFO:Light Gradient Boosting Machine Imported successfully
2025-11-28 15:53:10,010:INFO:Starting cross validation
2025-11-28 15:53:10,017:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-28 15:53:10,287:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 15:53:10,382:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 15:53:10,444:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 15:53:10,547:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 15:53:10,602:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 15:53:10,719:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 15:53:10,809:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 15:53:10,905:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 15:53:16,887:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-28 15:53:17,119:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 15:53:17,185:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-28 15:53:17,457:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 15:53:22,995:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 15:53:23,012:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 15:53:23,098:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 15:53:23,971:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 15:53:23,979:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 15:53:24,004:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 15:53:24,018:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 15:53:24,165:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 15:53:24,825:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 15:53:24,837:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 15:53:24,989:INFO:Calculating mean and std
2025-11-28 15:53:24,991:INFO:Creating metrics dataframe
2025-11-28 15:53:24,994:INFO:Uploading results into container
2025-11-28 15:53:24,994:INFO:Uploading model into container now
2025-11-28 15:53:24,995:INFO:_master_model_container: 2
2025-11-28 15:53:24,995:INFO:_display_container: 2
2025-11-28 15:53:24,995:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-11-28 15:53:24,996:INFO:create_model() successfully completed......................................
2025-11-28 15:53:25,209:INFO:SubProcess create_model() end ==================================
2025-11-28 15:53:25,209:INFO:Creating metrics dataframe
2025-11-28 15:53:25,216:INFO:Initializing Random Forest Classifier
2025-11-28 15:53:25,216:INFO:Total runtime is 0.43291822671890257 minutes
2025-11-28 15:53:25,220:INFO:SubProcess create_model() called ==================================
2025-11-28 15:53:25,220:INFO:Initializing create_model()
2025-11-28 15:53:25,220:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020508BC6920>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002051006BC40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-28 15:53:25,220:INFO:Checking exceptions
2025-11-28 15:53:25,220:INFO:Importing libraries
2025-11-28 15:53:25,220:INFO:Copying training dataset
2025-11-28 15:53:25,341:INFO:Defining folds
2025-11-28 15:53:25,341:INFO:Declaring metric variables
2025-11-28 15:53:25,349:INFO:Importing untrained model
2025-11-28 15:53:25,353:INFO:Random Forest Classifier Imported successfully
2025-11-28 15:53:25,357:INFO:Starting cross validation
2025-11-28 15:53:25,359:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-28 15:53:25,581:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 15:53:25,642:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 15:53:25,714:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 15:53:25,759:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 15:53:25,847:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 15:53:25,976:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 15:53:26,095:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 15:53:26,176:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 15:53:26,311:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 15:53:26,441:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 15:53:29,629:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 15:53:29,631:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 15:53:29,712:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 15:53:30,266:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 15:53:32,680:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 15:53:32,798:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 15:53:32,799:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 15:53:32,912:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 15:53:33,349:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 15:53:33,403:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 15:53:33,547:INFO:Calculating mean and std
2025-11-28 15:53:33,548:INFO:Creating metrics dataframe
2025-11-28 15:53:33,548:INFO:Uploading results into container
2025-11-28 15:53:33,548:INFO:Uploading model into container now
2025-11-28 15:53:33,548:INFO:_master_model_container: 3
2025-11-28 15:53:33,548:INFO:_display_container: 2
2025-11-28 15:53:33,548:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2025-11-28 15:53:33,551:INFO:create_model() successfully completed......................................
2025-11-28 15:53:33,679:INFO:SubProcess create_model() end ==================================
2025-11-28 15:53:33,679:INFO:Creating metrics dataframe
2025-11-28 15:53:33,685:INFO:Initializing Gradient Boosting Classifier
2025-11-28 15:53:33,685:INFO:Total runtime is 0.5740575075149537 minutes
2025-11-28 15:53:33,685:INFO:SubProcess create_model() called ==================================
2025-11-28 15:53:33,685:INFO:Initializing create_model()
2025-11-28 15:53:33,685:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020508BC6920>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002051006BC40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-28 15:53:33,685:INFO:Checking exceptions
2025-11-28 15:53:33,685:INFO:Importing libraries
2025-11-28 15:53:33,685:INFO:Copying training dataset
2025-11-28 15:53:33,794:INFO:Defining folds
2025-11-28 15:53:33,794:INFO:Declaring metric variables
2025-11-28 15:53:33,800:INFO:Importing untrained model
2025-11-28 15:53:33,803:INFO:Gradient Boosting Classifier Imported successfully
2025-11-28 15:53:33,804:INFO:Starting cross validation
2025-11-28 15:53:33,809:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-28 15:53:34,017:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 15:53:34,071:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 15:53:34,120:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 15:53:34,218:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 15:53:34,340:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 15:53:34,403:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 15:53:34,517:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 15:53:34,669:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 15:53:34,764:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 15:53:34,898:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 15:54:10,392:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 15:54:10,492:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 15:54:10,530:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 15:54:10,595:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 15:54:10,670:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 15:54:10,713:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 15:54:10,916:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 15:54:10,923:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 15:54:10,961:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 15:54:11,337:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 15:54:11,418:INFO:Calculating mean and std
2025-11-28 15:54:11,419:INFO:Creating metrics dataframe
2025-11-28 15:54:11,420:INFO:Uploading results into container
2025-11-28 15:54:11,421:INFO:Uploading model into container now
2025-11-28 15:54:11,421:INFO:_master_model_container: 4
2025-11-28 15:54:11,421:INFO:_display_container: 2
2025-11-28 15:54:11,421:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-11-28 15:54:11,423:INFO:create_model() successfully completed......................................
2025-11-28 15:54:11,555:INFO:SubProcess create_model() end ==================================
2025-11-28 15:54:11,555:INFO:Creating metrics dataframe
2025-11-28 15:54:11,563:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  master_display_.apply(

2025-11-28 15:54:11,566:INFO:Initializing create_model()
2025-11-28 15:54:11,566:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020508BC6920>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-28 15:54:11,566:INFO:Checking exceptions
2025-11-28 15:54:11,570:INFO:Importing libraries
2025-11-28 15:54:11,570:INFO:Copying training dataset
2025-11-28 15:54:11,674:INFO:Defining folds
2025-11-28 15:54:11,674:INFO:Declaring metric variables
2025-11-28 15:54:11,674:INFO:Importing untrained model
2025-11-28 15:54:11,674:INFO:Declaring custom model
2025-11-28 15:54:11,674:INFO:Gradient Boosting Classifier Imported successfully
2025-11-28 15:54:11,675:INFO:Cross validation set to False
2025-11-28 15:54:11,675:INFO:Fitting Model
2025-11-28 15:54:11,751:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 15:54:43,151:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-11-28 15:54:43,151:INFO:create_model() successfully completed......................................
2025-11-28 15:54:43,309:INFO:_master_model_container: 4
2025-11-28 15:54:43,309:INFO:_display_container: 2
2025-11-28 15:54:43,309:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-11-28 15:54:43,309:INFO:compare_models() successfully completed......................................
2025-11-28 16:20:33,299:INFO:Initializing tune_model()
2025-11-28 16:20:33,299:INFO:tune_model(estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=None, round=4, n_iter=20, custom_grid=None, optimize=Recall, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020508BC6920>)
2025-11-28 16:20:33,299:INFO:Checking exceptions
2025-11-28 16:20:33,361:INFO:Copying training dataset
2025-11-28 16:20:33,444:INFO:Checking base model
2025-11-28 16:20:33,444:INFO:Base model : Gradient Boosting Classifier
2025-11-28 16:20:33,448:INFO:Declaring metric variables
2025-11-28 16:20:33,450:INFO:Defining Hyperparameters
2025-11-28 16:20:33,583:INFO:Tuning with n_jobs=-1
2025-11-28 16:20:33,583:INFO:Initializing RandomizedSearchCV
2025-11-28 16:20:37,285:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-28 16:20:37,325:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-28 16:20:37,364:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-28 16:20:37,399:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-28 16:20:37,488:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-28 16:20:37,607:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-28 16:20:37,638:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-28 16:20:37,689:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:20:37,711:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-28 16:20:37,723:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-28 16:20:37,738:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:20:37,775:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:20:37,841:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:20:37,853:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-28 16:20:37,972:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-28 16:20:38,018:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:20:38,343:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:20:38,423:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-28 16:20:38,581:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:20:38,694:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:20:38,748:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:20:38,760:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:20:39,011:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:20:39,515:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:20:41,359:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:20:41,653:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:20:41,709:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:20:42,082:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:20:43,534:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:20:43,805:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:20:44,463:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:20:44,749:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:20:45,594:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:20:45,885:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:20:46,578:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:20:46,872:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:20:47,755:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:20:48,037:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:20:48,721:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:20:49,003:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:20:49,946:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:20:50,240:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:20:50,899:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:20:51,193:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:20:51,788:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:20:52,068:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:20:52,554:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:20:52,844:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:20:53,446:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:20:53,763:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:20:54,176:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:20:54,460:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:20:55,128:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:20:55,478:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:20:55,776:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:20:56,164:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:20:56,859:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:20:57,121:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:20:57,441:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:20:57,755:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:20:58,474:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:20:58,756:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:20:59,050:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:20:59,341:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:21:01,808:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:21:02,072:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:21:02,086:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:21:02,381:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:21:05,059:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:21:05,332:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:21:05,349:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:21:05,635:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:21:08,308:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:21:08,453:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:21:08,564:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:21:08,741:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:21:11,672:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:21:11,682:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:21:11,955:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:21:12,036:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:21:15,036:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:21:15,379:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:21:15,404:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:21:15,796:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:21:17,341:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:21:17,584:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:21:17,737:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:21:18,053:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:21:19,517:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:21:19,779:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:21:19,932:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:21:20,220:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:21:21,771:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:21:22,050:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:21:22,140:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:21:22,421:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:21:24,152:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:21:24,402:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:21:24,416:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:21:24,663:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:21:26,453:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:21:26,604:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:21:26,743:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:21:26,874:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:21:30,463:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:21:30,575:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:21:30,771:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:21:30,997:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:21:34,672:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:21:34,977:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:21:34,999:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:21:35,394:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:21:38,695:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:21:38,944:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:21:39,143:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:21:39,446:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:21:42,626:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:21:42,879:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:21:43,200:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:21:43,488:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:21:46,552:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:21:46,818:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:21:47,068:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:21:47,388:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:21:52,863:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:21:53,141:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:21:53,391:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:21:53,682:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:21:58,448:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:21:58,827:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:21:59,031:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:21:59,353:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:21:59,414:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:21:59,583:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:21:59,711:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:00,061:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:00,310:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:00,573:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:00,740:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:00,755:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:00,867:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:01,055:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:01,063:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:01,204:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:01,362:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:01,464:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:01,729:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:01,899:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:01,987:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:02,693:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:04,527:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:04,907:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:04,911:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:04,994:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:05,125:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:05,208:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:05,325:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:05,398:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:05,436:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:05,713:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:05,794:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:05,949:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:05,990:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:06,268:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:06,476:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:06,823:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:06,999:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:07,059:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:07,460:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:07,539:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:08,000:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:08,391:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:08,764:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:08,815:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:09,151:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:09,227:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:09,294:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:09,346:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:09,713:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:09,815:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:09,909:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:10,014:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:10,392:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:10,499:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:12,782:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:12,892:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:13,094:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:13,260:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:15,473:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:15,507:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:15,676:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:15,763:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:15,796:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:15,909:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:16,102:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:16,190:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:16,227:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:16,893:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:16,921:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:16,993:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:17,372:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:17,555:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:17,703:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:18,119:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:18,515:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:18,628:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:18,694:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:18,722:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:18,836:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:18,896:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:18,991:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:19,087:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:19,233:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:19,277:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:19,357:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:19,425:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:19,534:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:19,659:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:19,796:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:20,087:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:20,325:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:20,387:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:20,489:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:20,545:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:20,996:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:21,093:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:21,418:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:21,839:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:22,155:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:22,406:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:22,440:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:22,494:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:22,816:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:22,881:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:23,019:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:23,057:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:23,063:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:23,188:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:23,580:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:23,634:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:23,719:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:23,813:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:23,981:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:24,187:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:24,191:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:24,224:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:24,271:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:24,774:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:24,952:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:25,065:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:25,178:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:25,709:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:25,981:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:26,319:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:26,392:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:26,627:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:26,740:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:26,769:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:26,905:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:27,021:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:27,203:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:27,293:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:27,322:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:27,669:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:32,432:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:32,650:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:32,734:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:32,991:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:37,813:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:38,063:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:38,105:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:38,380:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:43,099:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:43,383:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:43,387:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:43,702:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:48,208:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:48,478:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:48,692:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:49,041:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:53,790:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:54,074:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:54,192:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:54,501:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:55,817:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:56,103:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:56,117:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:56,417:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:57,708:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:57,971:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:57,974:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:58,263:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:59,626:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:59,818:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:22:59,906:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:23:00,128:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:23:01,652:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:23:01,772:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:23:02,035:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:23:02,145:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:26:47,792:INFO:Initializing compare_models()
2025-11-28 16:26:47,792:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020508BC6920>, include=['xgboost', 'lightgbm'], fold=None, round=4, cross_validation=True, sort=Recall, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000020508BC6920>, 'include': ['xgboost', 'lightgbm'], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Recall', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2025-11-28 16:26:47,792:INFO:Checking exceptions
2025-11-28 16:26:47,830:INFO:Preparing display monitor
2025-11-28 16:26:47,849:INFO:Initializing Extreme Gradient Boosting
2025-11-28 16:26:47,849:INFO:Total runtime is 0.0 minutes
2025-11-28 16:26:47,851:INFO:SubProcess create_model() called ==================================
2025-11-28 16:26:47,851:INFO:Initializing create_model()
2025-11-28 16:26:47,851:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020508BC6920>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020502D29360>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-28 16:26:47,851:INFO:Checking exceptions
2025-11-28 16:26:47,851:INFO:Importing libraries
2025-11-28 16:26:47,851:INFO:Copying training dataset
2025-11-28 16:26:47,968:INFO:Defining folds
2025-11-28 16:26:47,968:INFO:Declaring metric variables
2025-11-28 16:26:47,971:INFO:Importing untrained model
2025-11-28 16:26:47,974:INFO:Extreme Gradient Boosting Imported successfully
2025-11-28 16:26:47,979:INFO:Starting cross validation
2025-11-28 16:26:47,979:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-28 16:26:51,327:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-28 16:26:51,327:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-28 16:26:51,327:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-28 16:26:51,353:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-28 16:26:51,392:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-28 16:26:51,440:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-28 16:26:51,440:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-28 16:26:51,496:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-28 16:26:51,537:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-28 16:26:51,612:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-28 16:26:51,693:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:26:51,704:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:26:51,707:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:26:51,735:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:26:51,821:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:26:51,950:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:26:51,960:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:26:52,223:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:26:52,392:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:26:52,630:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:26:55,956:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:26:56,022:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:26:56,032:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:26:56,071:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:26:56,224:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:26:56,227:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:26:56,247:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:26:56,327:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:26:56,356:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:26:56,403:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:26:56,516:INFO:Calculating mean and std
2025-11-28 16:26:56,517:INFO:Creating metrics dataframe
2025-11-28 16:26:56,518:INFO:Uploading results into container
2025-11-28 16:26:56,519:INFO:Uploading model into container now
2025-11-28 16:26:56,519:INFO:_master_model_container: 5
2025-11-28 16:26:56,519:INFO:_display_container: 3
2025-11-28 16:26:56,519:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              feature_weights=None, gamma=None, grow_policy=None,
              importance_type=None, interaction_constraints=None,
              learning_rate=None, max_bin=None, max_cat_threshold=None,
              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,
              max_leaves=None, min_child_weight=None, missing=nan,
              monotone_constraints=None, multi_strategy=None, n_estimators=None,
              n_jobs=-1, num_parallel_tree=None, ...)
2025-11-28 16:26:56,519:INFO:create_model() successfully completed......................................
2025-11-28 16:26:56,855:INFO:SubProcess create_model() end ==================================
2025-11-28 16:26:56,855:INFO:Creating metrics dataframe
2025-11-28 16:26:56,860:INFO:Initializing Light Gradient Boosting Machine
2025-11-28 16:26:56,860:INFO:Total runtime is 0.15018306573232015 minutes
2025-11-28 16:26:56,860:INFO:SubProcess create_model() called ==================================
2025-11-28 16:26:56,860:INFO:Initializing create_model()
2025-11-28 16:26:56,860:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020508BC6920>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020502D29360>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-28 16:26:56,860:INFO:Checking exceptions
2025-11-28 16:26:56,860:INFO:Importing libraries
2025-11-28 16:26:56,860:INFO:Copying training dataset
2025-11-28 16:26:56,968:INFO:Defining folds
2025-11-28 16:26:56,969:INFO:Declaring metric variables
2025-11-28 16:26:56,971:INFO:Importing untrained model
2025-11-28 16:26:56,973:INFO:Light Gradient Boosting Machine Imported successfully
2025-11-28 16:26:56,973:INFO:Starting cross validation
2025-11-28 16:26:56,983:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-28 16:26:57,275:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:26:57,369:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:26:57,429:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:26:57,506:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:26:57,604:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:26:57,727:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:26:57,841:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:26:57,958:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:27:04,137:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-28 16:27:04,174:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-28 16:27:04,398:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:27:04,438:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:27:09,872:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:27:09,891:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:27:09,908:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:27:10,073:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:27:10,754:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:27:10,759:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:27:10,775:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:27:10,831:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:27:11,542:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:27:11,550:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:27:11,665:INFO:Calculating mean and std
2025-11-28 16:27:11,665:INFO:Creating metrics dataframe
2025-11-28 16:27:11,669:INFO:Uploading results into container
2025-11-28 16:27:11,669:INFO:Uploading model into container now
2025-11-28 16:27:11,669:INFO:_master_model_container: 6
2025-11-28 16:27:11,669:INFO:_display_container: 3
2025-11-28 16:27:11,670:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-11-28 16:27:11,670:INFO:create_model() successfully completed......................................
2025-11-28 16:27:11,903:INFO:SubProcess create_model() end ==================================
2025-11-28 16:27:11,903:INFO:Creating metrics dataframe
2025-11-28 16:27:11,909:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  master_display_.apply(

2025-11-28 16:27:11,917:INFO:Initializing create_model()
2025-11-28 16:27:11,917:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020508BC6920>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-28 16:27:11,917:INFO:Checking exceptions
2025-11-28 16:27:11,917:INFO:Importing libraries
2025-11-28 16:27:11,917:INFO:Copying training dataset
2025-11-28 16:27:12,032:INFO:Defining folds
2025-11-28 16:27:12,032:INFO:Declaring metric variables
2025-11-28 16:27:12,032:INFO:Importing untrained model
2025-11-28 16:27:12,032:INFO:Declaring custom model
2025-11-28 16:27:12,033:INFO:Light Gradient Boosting Machine Imported successfully
2025-11-28 16:27:12,035:INFO:Cross validation set to False
2025-11-28 16:27:12,035:INFO:Fitting Model
2025-11-28 16:27:12,109:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:27:12,737:INFO:[LightGBM] [Info] Number of positive: 8764, number of negative: 8764
2025-11-28 16:27:12,765:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021939 seconds.
2025-11-28 16:27:12,766:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-11-28 16:27:12,766:INFO:[LightGBM] [Info] Total Bins 76025
2025-11-28 16:27:12,770:INFO:[LightGBM] [Info] Number of data points in the train set: 17528, number of used features: 323
2025-11-28 16:27:12,770:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-11-28 16:27:13,494:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-11-28 16:27:13,494:INFO:create_model() successfully completed......................................
2025-11-28 16:27:13,673:INFO:_master_model_container: 6
2025-11-28 16:27:13,673:INFO:_display_container: 3
2025-11-28 16:27:13,673:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-11-28 16:27:13,673:INFO:compare_models() successfully completed......................................
2025-11-28 16:30:43,431:INFO:Initializing tune_model()
2025-11-28 16:30:43,431:INFO:tune_model(estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=4, custom_grid=None, optimize=Recall, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020508BC6920>)
2025-11-28 16:30:43,431:INFO:Checking exceptions
2025-11-28 16:30:43,480:INFO:Copying training dataset
2025-11-28 16:30:43,551:INFO:Checking base model
2025-11-28 16:30:43,551:INFO:Base model : Light Gradient Boosting Machine
2025-11-28 16:30:43,553:INFO:Declaring metric variables
2025-11-28 16:30:43,555:INFO:Defining Hyperparameters
2025-11-28 16:30:43,709:INFO:Tuning with n_jobs=-1
2025-11-28 16:30:43,709:INFO:Initializing RandomizedSearchCV
2025-11-28 16:30:43,929:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:30:43,998:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:30:44,058:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:30:44,165:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:30:44,248:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:30:44,378:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:30:44,468:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:30:44,559:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:30:44,698:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:30:44,977:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:30:45,090:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:30:45,376:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:30:49,948:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:30:50,437:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:30:50,440:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:30:50,945:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:30:53,274:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:30:53,355:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:30:53,675:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:30:53,710:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:30:53,714:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:30:53,741:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:30:54,111:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:30:54,133:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:30:54,555:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:30:59,700:INFO:Initializing tune_model()
2025-11-28 16:30:59,700:INFO:tune_model(estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=1, custom_grid=None, optimize=Recall, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020508BC6920>)
2025-11-28 16:30:59,700:INFO:Checking exceptions
2025-11-28 16:30:59,750:INFO:Copying training dataset
2025-11-28 16:30:59,822:INFO:Checking base model
2025-11-28 16:30:59,823:INFO:Base model : Light Gradient Boosting Machine
2025-11-28 16:30:59,827:INFO:Declaring metric variables
2025-11-28 16:30:59,830:INFO:Defining Hyperparameters
2025-11-28 16:30:59,991:INFO:Tuning with n_jobs=-1
2025-11-28 16:30:59,991:INFO:Initializing RandomizedSearchCV
2025-11-28 16:31:03,398:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-28 16:31:03,426:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-28 16:31:03,439:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-28 16:31:03,479:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-28 16:31:03,485:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-28 16:31:03,559:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-28 16:31:03,571:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:31:03,628:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-28 16:31:03,631:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:31:03,650:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:31:03,667:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-28 16:31:03,709:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-28 16:31:03,735:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:31:03,747:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:31:03,895:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:31:03,981:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-28 16:31:03,990:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:31:04,035:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:31:04,106:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:31:04,449:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:31:09,846:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:31:10,409:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:31:10,453:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:31:10,453:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:31:10,678:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:31:10,689:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:31:10,750:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:31:10,938:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:31:10,950:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:31:10,956:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:31:11,069:INFO:best_params: {'actual_estimator__reg_lambda': 0.05, 'actual_estimator__reg_alpha': 0.1, 'actual_estimator__num_leaves': 10, 'actual_estimator__n_estimators': 190, 'actual_estimator__min_split_gain': 0.3, 'actual_estimator__min_child_samples': 100, 'actual_estimator__learning_rate': 0.5, 'actual_estimator__feature_fraction': 1.0, 'actual_estimator__bagging_freq': 3, 'actual_estimator__bagging_fraction': 0.8}
2025-11-28 16:31:11,069:INFO:Hyperparameter search completed
2025-11-28 16:31:11,069:INFO:SubProcess create_model() called ==================================
2025-11-28 16:31:11,071:INFO:Initializing create_model()
2025-11-28 16:31:11,071:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020508BC6920>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020502D71750>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'reg_lambda': 0.05, 'reg_alpha': 0.1, 'num_leaves': 10, 'n_estimators': 190, 'min_split_gain': 0.3, 'min_child_samples': 100, 'learning_rate': 0.5, 'feature_fraction': 1.0, 'bagging_freq': 3, 'bagging_fraction': 0.8})
2025-11-28 16:31:11,071:INFO:Checking exceptions
2025-11-28 16:31:11,071:INFO:Importing libraries
2025-11-28 16:31:11,071:INFO:Copying training dataset
2025-11-28 16:31:11,211:INFO:Defining folds
2025-11-28 16:31:11,211:INFO:Declaring metric variables
2025-11-28 16:31:11,216:INFO:Importing untrained model
2025-11-28 16:31:11,216:INFO:Declaring custom model
2025-11-28 16:31:11,221:INFO:Light Gradient Boosting Machine Imported successfully
2025-11-28 16:31:11,223:INFO:Starting cross validation
2025-11-28 16:31:11,228:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-28 16:31:11,544:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:31:11,618:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:31:11,713:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:31:11,789:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:31:11,839:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:31:11,923:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:31:12,036:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:31:12,126:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:31:17,689:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:31:17,735:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:31:18,381:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:31:18,402:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:31:18,445:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:31:18,463:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:31:18,613:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:31:18,668:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:31:18,712:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-28 16:31:18,759:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-28 16:31:18,868:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:31:18,941:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:31:20,609:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:31:20,617:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:31:20,734:INFO:Calculating mean and std
2025-11-28 16:31:20,736:INFO:Creating metrics dataframe
2025-11-28 16:31:20,740:INFO:Finalizing model
2025-11-28 16:31:20,839:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:31:21,283:INFO:[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0
2025-11-28 16:31:21,285:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
2025-11-28 16:31:21,285:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-11-28 16:31:21,512:INFO:[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0
2025-11-28 16:31:21,513:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
2025-11-28 16:31:21,513:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-11-28 16:31:21,513:INFO:[LightGBM] [Info] Number of positive: 8764, number of negative: 8764
2025-11-28 16:31:21,537:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021056 seconds.
2025-11-28 16:31:21,537:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-11-28 16:31:21,540:INFO:[LightGBM] [Info] Total Bins 75973
2025-11-28 16:31:21,541:INFO:[LightGBM] [Info] Number of data points in the train set: 17528, number of used features: 319
2025-11-28 16:31:21,543:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-11-28 16:31:21,680:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,682:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,685:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,687:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,687:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,689:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,691:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,693:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,693:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,696:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,697:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,698:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,698:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,700:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,700:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,700:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,700:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,702:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,702:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,702:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,702:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,702:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,702:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,705:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,705:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,705:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,705:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,707:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,707:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,707:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,707:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,709:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,709:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,710:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,710:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,710:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,710:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,712:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,712:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,713:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,713:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,713:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,713:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,715:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,715:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,717:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,717:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,718:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,718:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,718:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,718:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,720:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,720:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,720:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,720:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,720:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,720:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,723:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,723:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,723:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,723:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,725:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,725:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,725:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,725:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,727:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,727:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,728:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,729:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,731:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,731:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,732:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,732:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,734:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,735:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,735:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,736:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,736:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,736:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,736:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,736:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,738:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,738:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,738:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,738:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,739:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,739:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,739:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,739:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,740:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,740:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,740:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,740:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,740:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,740:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,742:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,742:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,742:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,742:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,742:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,742:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,742:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,742:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,745:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,745:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,747:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,747:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,747:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,747:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,749:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,749:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,749:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,749:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,749:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,749:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,751:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,751:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,751:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,751:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,751:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,751:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,753:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,753:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,753:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,753:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,753:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,753:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,755:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,755:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,755:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,755:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,755:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,755:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,757:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,757:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,757:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,757:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,757:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,757:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,757:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,759:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,759:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,759:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,759:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,759:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,759:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,759:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,761:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,761:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,762:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,762:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,765:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,765:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,765:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,765:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,766:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,766:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,766:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,766:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,768:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,768:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,769:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,769:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,771:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,771:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,772:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,772:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,773:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,773:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,773:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,773:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,775:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,775:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,775:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,775:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,775:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,777:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,777:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,777:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,779:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,779:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,780:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,780:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,782:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,782:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,784:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,784:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,786:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,786:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,787:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,787:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,789:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,789:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,789:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,789:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,789:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,789:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,791:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,791:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,792:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,792:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,792:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,792:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,792:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,792:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,794:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,794:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,794:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,794:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,794:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,794:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,796:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,796:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,796:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,796:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,798:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,798:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,799:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,799:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,799:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,799:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,799:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,799:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,801:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,801:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,801:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,801:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,801:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,801:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,803:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,803:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,803:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,803:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,803:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,803:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,805:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,805:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,805:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,805:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,805:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,805:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,805:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,807:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,807:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,807:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,807:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,807:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,807:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,807:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,810:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,810:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,810:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,810:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,810:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,810:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,812:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,812:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,813:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,813:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,815:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,815:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,815:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,815:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,817:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,817:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,817:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,817:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,817:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,817:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,819:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,819:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,819:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,819:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,821:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,821:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,821:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,821:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,822:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,822:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,822:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,822:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,823:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,823:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,823:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,823:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,823:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,823:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,825:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,825:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,825:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,825:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,825:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,825:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,825:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,827:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,827:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-28 16:31:21,827:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-11-28 16:31:21,840:INFO:Uploading results into container
2025-11-28 16:31:21,840:INFO:Uploading model into container now
2025-11-28 16:31:21,840:INFO:_master_model_container: 7
2025-11-28 16:31:21,840:INFO:_display_container: 4
2025-11-28 16:31:21,840:INFO:LGBMClassifier(bagging_fraction=0.8, bagging_freq=3, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=1.0,
               importance_type='split', learning_rate=0.5, max_depth=-1,
               min_child_samples=100, min_child_weight=0.001,
               min_split_gain=0.3, n_estimators=190, n_jobs=-1, num_leaves=10,
               objective=None, random_state=42, reg_alpha=0.1, reg_lambda=0.05,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2025-11-28 16:31:21,842:INFO:create_model() successfully completed......................................
2025-11-28 16:31:22,009:INFO:SubProcess create_model() end ==================================
2025-11-28 16:31:22,009:INFO:choose_better activated
2025-11-28 16:31:22,013:INFO:SubProcess create_model() called ==================================
2025-11-28 16:31:22,013:INFO:Initializing create_model()
2025-11-28 16:31:22,013:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020508BC6920>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-28 16:31:22,013:INFO:Checking exceptions
2025-11-28 16:31:22,013:INFO:Importing libraries
2025-11-28 16:31:22,013:INFO:Copying training dataset
2025-11-28 16:31:22,113:INFO:Defining folds
2025-11-28 16:31:22,113:INFO:Declaring metric variables
2025-11-28 16:31:22,114:INFO:Importing untrained model
2025-11-28 16:31:22,114:INFO:Declaring custom model
2025-11-28 16:31:22,114:INFO:Light Gradient Boosting Machine Imported successfully
2025-11-28 16:31:22,114:INFO:Starting cross validation
2025-11-28 16:31:22,117:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-28 16:31:22,386:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:31:22,446:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:31:22,458:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:31:22,539:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:31:22,649:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:31:22,750:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:31:22,822:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:31:22,927:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:31:23,047:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:31:23,134:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:31:33,184:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:31:33,600:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:31:34,229:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:31:34,402:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:31:34,627:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:31:34,645:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:31:34,661:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:31:34,692:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:31:34,737:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:31:34,820:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:31:34,941:INFO:Calculating mean and std
2025-11-28 16:31:34,941:INFO:Creating metrics dataframe
2025-11-28 16:31:34,942:INFO:Finalizing model
2025-11-28 16:31:35,060:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:31:35,711:INFO:[LightGBM] [Info] Number of positive: 8764, number of negative: 8764
2025-11-28 16:31:35,735:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.018627 seconds.
2025-11-28 16:31:35,735:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-11-28 16:31:35,736:INFO:[LightGBM] [Info] Total Bins 76025
2025-11-28 16:31:35,740:INFO:[LightGBM] [Info] Number of data points in the train set: 17528, number of used features: 323
2025-11-28 16:31:35,741:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-11-28 16:31:36,368:INFO:Uploading results into container
2025-11-28 16:31:36,370:INFO:Uploading model into container now
2025-11-28 16:31:36,370:INFO:_master_model_container: 8
2025-11-28 16:31:36,370:INFO:_display_container: 5
2025-11-28 16:31:36,371:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-11-28 16:31:36,371:INFO:create_model() successfully completed......................................
2025-11-28 16:31:36,545:INFO:SubProcess create_model() end ==================================
2025-11-28 16:31:36,545:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for Recall is 0.7515
2025-11-28 16:31:36,546:INFO:LGBMClassifier(bagging_fraction=0.8, bagging_freq=3, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=1.0,
               importance_type='split', learning_rate=0.5, max_depth=-1,
               min_child_samples=100, min_child_weight=0.001,
               min_split_gain=0.3, n_estimators=190, n_jobs=-1, num_leaves=10,
               objective=None, random_state=42, reg_alpha=0.1, reg_lambda=0.05,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0) result for Recall is 0.7418
2025-11-28 16:31:36,546:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) is best model
2025-11-28 16:31:36,546:INFO:choose_better completed
2025-11-28 16:31:36,546:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2025-11-28 16:31:36,554:INFO:_master_model_container: 8
2025-11-28 16:31:36,554:INFO:_display_container: 4
2025-11-28 16:31:36,554:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-11-28 16:31:36,554:INFO:tune_model() successfully completed......................................
2025-11-28 16:34:37,651:INFO:Initializing predict_model()
2025-11-28 16:34:37,651:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020508BC6920>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=True, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000020507C8A830>)
2025-11-28 16:34:37,653:INFO:Checking exceptions
2025-11-28 16:34:37,653:INFO:Preloading libraries
2025-11-28 16:39:43,417:INFO:Initializing finalize_model()
2025-11-28 16:39:43,417:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020508BC6920>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2025-11-28 16:39:43,418:INFO:Finalizing LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-11-28 16:39:43,491:INFO:Initializing create_model()
2025-11-28 16:39:43,491:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020508BC6920>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2025-11-28 16:39:43,491:INFO:Checking exceptions
2025-11-28 16:39:43,492:INFO:Importing libraries
2025-11-28 16:39:43,492:INFO:Copying training dataset
2025-11-28 16:39:43,505:INFO:Defining folds
2025-11-28 16:39:43,505:INFO:Declaring metric variables
2025-11-28 16:39:43,505:INFO:Importing untrained model
2025-11-28 16:39:43,505:INFO:Declaring custom model
2025-11-28 16:39:43,506:INFO:Light Gradient Boosting Machine Imported successfully
2025-11-28 16:39:43,509:INFO:Cross validation set to False
2025-11-28 16:39:43,510:INFO:Fitting Model
2025-11-28 16:39:43,579:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:39:44,381:INFO:[LightGBM] [Info] Number of positive: 12520, number of negative: 12520
2025-11-28 16:39:44,410:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.025714 seconds.
2025-11-28 16:39:44,410:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-11-28 16:39:44,412:INFO:[LightGBM] [Info] Total Bins 76811
2025-11-28 16:39:44,416:INFO:[LightGBM] [Info] Number of data points in the train set: 25040, number of used features: 323
2025-11-28 16:39:44,417:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-11-28 16:39:45,187:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['STATE', 'FMONTH', 'DISPCODE',
                                             'PSU', 'CTELENM1', 'PVTRESD1',
                                             'COLGHOUS', 'STATERE1', 'CELPHON1',
                                             'LADULT1', 'COLGSEX1', 'NUMADULT',
                                             'LANDSEX1', 'NUMMEN', 'NUMWOMEN',
                                             'RESPSLCT', 'SAFETIME', 'CTELNUM1',
                                             'CELLFON5', 'CADULT1', 'CELLSEX1',
                                             'PVTRESD3', 'CCLGHOUS', 'CST...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=42,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2025-11-28 16:39:45,187:INFO:create_model() successfully completed......................................
2025-11-28 16:39:45,348:INFO:_master_model_container: 8
2025-11-28 16:39:45,348:INFO:_display_container: 5
2025-11-28 16:39:45,360:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['STATE', 'FMONTH', 'DISPCODE',
                                             'PSU', 'CTELENM1', 'PVTRESD1',
                                             'COLGHOUS', 'STATERE1', 'CELPHON1',
                                             'LADULT1', 'COLGSEX1', 'NUMADULT',
                                             'LANDSEX1', 'NUMMEN', 'NUMWOMEN',
                                             'RESPSLCT', 'SAFETIME', 'CTELNUM1',
                                             'CELLFON5', 'CADULT1', 'CELLSEX1',
                                             'PVTRESD3', 'CCLGHOUS', 'CST...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=42,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2025-11-28 16:39:45,360:INFO:finalize_model() successfully completed......................................
2025-11-28 16:39:45,535:INFO:Initializing save_model()
2025-11-28 16:39:45,535:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['STATE', 'FMONTH', 'DISPCODE',
                                             'PSU', 'CTELENM1', 'PVTRESD1',
                                             'COLGHOUS', 'STATERE1', 'CELPHON1',
                                             'LADULT1', 'COLGSEX1', 'NUMADULT',
                                             'LANDSEX1', 'NUMMEN', 'NUMWOMEN',
                                             'RESPSLCT', 'SAFETIME', 'CTELNUM1',
                                             'CELLFON5', 'CADULT1', 'CELLSEX1',
                                             'PVTRESD3', 'CCLGHOUS', 'CST...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=42,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), model_name=../models\final_pipeline_v1, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\OMAR\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['STATE', 'FMONTH', 'DISPCODE',
                                             'PSU', 'CTELENM1', 'PVTRESD1',
                                             'COLGHOUS', 'STATERE1', 'CELPHON1',
                                             'LADULT1', 'COLGSEX1', 'NUMADULT',
                                             'LANDSEX1', 'NUMMEN', 'NUMWOMEN',
                                             'RESPSLCT', 'SAFETIME', 'CTELNUM1',
                                             'CELLFON5', 'CADULT1...
                                    transformer=TargetEncoder(cols=['IDATE',
                                                                    'IDAY'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              random_state=42,
                                                                              sampling_strategy='auto'))))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2025-11-28 16:39:45,535:INFO:Adding model into prep_pipe
2025-11-28 16:39:45,535:WARNING:Only Model saved as it was a pipeline.
2025-11-28 16:39:45,554:INFO:../models\final_pipeline_v1.pkl saved in current working directory
2025-11-28 16:39:45,574:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['STATE', 'FMONTH', 'DISPCODE',
                                             'PSU', 'CTELENM1', 'PVTRESD1',
                                             'COLGHOUS', 'STATERE1', 'CELPHON1',
                                             'LADULT1', 'COLGSEX1', 'NUMADULT',
                                             'LANDSEX1', 'NUMMEN', 'NUMWOMEN',
                                             'RESPSLCT', 'SAFETIME', 'CTELNUM1',
                                             'CELLFON5', 'CADULT1', 'CELLSEX1',
                                             'PVTRESD3', 'CCLGHOUS', 'CST...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=42,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2025-11-28 16:39:45,574:INFO:save_model() successfully completed......................................
2025-11-28 16:41:05,175:INFO:Initializing finalize_model()
2025-11-28 16:41:05,175:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020508BC6920>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2025-11-28 16:41:05,176:INFO:Finalizing LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-11-28 16:41:05,248:INFO:Initializing create_model()
2025-11-28 16:41:05,248:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020508BC6920>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2025-11-28 16:41:05,248:INFO:Checking exceptions
2025-11-28 16:41:05,248:INFO:Importing libraries
2025-11-28 16:41:05,248:INFO:Copying training dataset
2025-11-28 16:41:05,260:INFO:Defining folds
2025-11-28 16:41:05,260:INFO:Declaring metric variables
2025-11-28 16:41:05,261:INFO:Importing untrained model
2025-11-28 16:41:05,261:INFO:Declaring custom model
2025-11-28 16:41:05,261:INFO:Light Gradient Boosting Machine Imported successfully
2025-11-28 16:41:05,264:INFO:Cross validation set to False
2025-11-28 16:41:05,264:INFO:Fitting Model
2025-11-28 16:41:05,330:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:41:06,109:INFO:[LightGBM] [Info] Number of positive: 12520, number of negative: 12520
2025-11-28 16:41:06,139:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.024391 seconds.
2025-11-28 16:41:06,139:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-11-28 16:41:06,140:INFO:[LightGBM] [Info] Total Bins 76811
2025-11-28 16:41:06,145:INFO:[LightGBM] [Info] Number of data points in the train set: 25040, number of used features: 323
2025-11-28 16:41:06,145:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-11-28 16:41:06,912:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['STATE', 'FMONTH', 'DISPCODE',
                                             'PSU', 'CTELENM1', 'PVTRESD1',
                                             'COLGHOUS', 'STATERE1', 'CELPHON1',
                                             'LADULT1', 'COLGSEX1', 'NUMADULT',
                                             'LANDSEX1', 'NUMMEN', 'NUMWOMEN',
                                             'RESPSLCT', 'SAFETIME', 'CTELNUM1',
                                             'CELLFON5', 'CADULT1', 'CELLSEX1',
                                             'PVTRESD3', 'CCLGHOUS', 'CST...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=42,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2025-11-28 16:41:06,912:INFO:create_model() successfully completed......................................
2025-11-28 16:41:07,074:INFO:_master_model_container: 8
2025-11-28 16:41:07,074:INFO:_display_container: 5
2025-11-28 16:41:07,085:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['STATE', 'FMONTH', 'DISPCODE',
                                             'PSU', 'CTELENM1', 'PVTRESD1',
                                             'COLGHOUS', 'STATERE1', 'CELPHON1',
                                             'LADULT1', 'COLGSEX1', 'NUMADULT',
                                             'LANDSEX1', 'NUMMEN', 'NUMWOMEN',
                                             'RESPSLCT', 'SAFETIME', 'CTELNUM1',
                                             'CELLFON5', 'CADULT1', 'CELLSEX1',
                                             'PVTRESD3', 'CCLGHOUS', 'CST...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=42,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2025-11-28 16:41:07,085:INFO:finalize_model() successfully completed......................................
2025-11-28 16:41:07,255:INFO:Initializing save_model()
2025-11-28 16:41:07,255:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['STATE', 'FMONTH', 'DISPCODE',
                                             'PSU', 'CTELENM1', 'PVTRESD1',
                                             'COLGHOUS', 'STATERE1', 'CELPHON1',
                                             'LADULT1', 'COLGSEX1', 'NUMADULT',
                                             'LANDSEX1', 'NUMMEN', 'NUMWOMEN',
                                             'RESPSLCT', 'SAFETIME', 'CTELNUM1',
                                             'CELLFON5', 'CADULT1', 'CELLSEX1',
                                             'PVTRESD3', 'CCLGHOUS', 'CST...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=42,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), model_name=../models\final_pipeline_v1, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\OMAR\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['STATE', 'FMONTH', 'DISPCODE',
                                             'PSU', 'CTELENM1', 'PVTRESD1',
                                             'COLGHOUS', 'STATERE1', 'CELPHON1',
                                             'LADULT1', 'COLGSEX1', 'NUMADULT',
                                             'LANDSEX1', 'NUMMEN', 'NUMWOMEN',
                                             'RESPSLCT', 'SAFETIME', 'CTELNUM1',
                                             'CELLFON5', 'CADULT1...
                                    transformer=TargetEncoder(cols=['IDATE',
                                                                    'IDAY'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              random_state=42,
                                                                              sampling_strategy='auto'))))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2025-11-28 16:41:07,255:INFO:Adding model into prep_pipe
2025-11-28 16:41:07,255:WARNING:Only Model saved as it was a pipeline.
2025-11-28 16:41:07,273:INFO:../models\final_pipeline_v1.pkl saved in current working directory
2025-11-28 16:41:07,290:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['STATE', 'FMONTH', 'DISPCODE',
                                             'PSU', 'CTELENM1', 'PVTRESD1',
                                             'COLGHOUS', 'STATERE1', 'CELPHON1',
                                             'LADULT1', 'COLGSEX1', 'NUMADULT',
                                             'LANDSEX1', 'NUMMEN', 'NUMWOMEN',
                                             'RESPSLCT', 'SAFETIME', 'CTELNUM1',
                                             'CELLFON5', 'CADULT1', 'CELLSEX1',
                                             'PVTRESD3', 'CCLGHOUS', 'CST...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=42,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2025-11-28 16:41:07,290:INFO:save_model() successfully completed......................................
2025-11-28 16:41:07,452:INFO:Initializing get_config()
2025-11-28 16:41:07,452:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020508BC6920>, variable=X_train)
2025-11-28 16:41:07,452:INFO:Variable: 'X_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_train_transformed' instead.
2025-11-28 16:41:07,452:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'X_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_train_transformed' instead.
  warnings.warn(msg)  # print on screen

2025-11-28 16:41:07,490:INFO:Variable:  returned as        STATE  FMONTH     IDATE IMONTH IDAY IYEAR  DISPCODE           PSU  \
720     54.0     1.0  01192022     01   19  2022    1100.0  2.022002e+09   
3896    20.0     8.0  09042022     09   04  2022    1200.0  2.022005e+09   
12399    9.0     1.0  02282022     02   28  2022    1200.0  2.022006e+09   
1720    22.0     1.0  03212022     03   21  2022    1100.0  2.022002e+09   
4419    51.0     7.0  07082022     07   08  2022    1100.0  2.022007e+09   
...      ...     ...       ...    ...  ...   ...       ...           ...   
868     51.0     7.0  07072022     07   07  2022    1100.0  2.022007e+09   
11800    8.0     1.0  01252022     01   25  2022    1100.0  2.022001e+09   
10049   53.0    10.0  11102022     11   10  2022    1200.0  2.022021e+09   
4993    50.0     7.0  08022022     08   02  2022    1100.0  2.022005e+09   
9992    53.0     4.0  04212022     04   21  2022    1100.0  2.022010e+09   

       CTELENM1  PVTRESD1  ...  SMOKGRP  LCSREC  DRNKANY6  DROCDY4_  RFBING6  \
720         NaN       NaN  ...      3.0     2.0       1.0      50.0      1.0   
3896        NaN       NaN  ...      3.0     NaN       9.0     900.0      9.0   
12399       NaN       NaN  ...      NaN     NaN       9.0     900.0      9.0   
1720        NaN       NaN  ...      4.0     NaN       1.0      29.0      1.0   
4419        NaN       NaN  ...      3.0     NaN       1.0       7.0      1.0   
...         ...       ...  ...      ...     ...       ...       ...      ...   
868         NaN       NaN  ...      4.0     NaN       2.0       0.0      1.0   
11800       NaN       NaN  ...      4.0     NaN       2.0       0.0      1.0   
10049       NaN       NaN  ...      NaN     NaN       9.0     900.0      9.0   
4993        NaN       NaN  ...      4.0     NaN       1.0      14.0      1.0   
9992        NaN       NaN  ...      2.0     NaN       1.0      14.0      1.0   

       DRNKWK2  RFDRHV8  FLSHOT7  PNEUMO3  AIDTST4  
720      350.0      1.0      NaN      NaN      1.0  
3896   99900.0      9.0      9.0      9.0      NaN  
12399  99900.0      9.0      NaN      NaN      NaN  
1720     200.0      1.0      1.0      1.0      2.0  
4419     187.0      1.0      NaN      NaN      2.0  
...        ...      ...      ...      ...      ...  
868        0.0      1.0      NaN      NaN      1.0  
11800      0.0      1.0      NaN      NaN      2.0  
10049  99900.0      9.0      NaN      NaN      NaN  
4993     100.0      1.0      NaN      NaN      2.0  
9992     200.0      1.0      NaN      NaN      2.0  

[9283 rows x 326 columns]
2025-11-28 16:41:07,490:INFO:get_config() successfully completed......................................
2025-11-28 16:41:23,356:INFO:Initializing finalize_model()
2025-11-28 16:41:23,356:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020508BC6920>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2025-11-28 16:41:23,356:INFO:Finalizing LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-11-28 16:41:23,417:INFO:Initializing create_model()
2025-11-28 16:41:23,417:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020508BC6920>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2025-11-28 16:41:23,417:INFO:Checking exceptions
2025-11-28 16:41:23,418:INFO:Importing libraries
2025-11-28 16:41:23,418:INFO:Copying training dataset
2025-11-28 16:41:23,430:INFO:Defining folds
2025-11-28 16:41:23,430:INFO:Declaring metric variables
2025-11-28 16:41:23,430:INFO:Importing untrained model
2025-11-28 16:41:23,430:INFO:Declaring custom model
2025-11-28 16:41:23,431:INFO:Light Gradient Boosting Machine Imported successfully
2025-11-28 16:41:23,435:INFO:Cross validation set to False
2025-11-28 16:41:23,435:INFO:Fitting Model
2025-11-28 16:41:23,509:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:41:24,310:INFO:[LightGBM] [Info] Number of positive: 12520, number of negative: 12520
2025-11-28 16:41:24,343:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026326 seconds.
2025-11-28 16:41:24,343:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-11-28 16:41:24,345:INFO:[LightGBM] [Info] Total Bins 76811
2025-11-28 16:41:24,349:INFO:[LightGBM] [Info] Number of data points in the train set: 25040, number of used features: 323
2025-11-28 16:41:24,350:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-11-28 16:41:25,190:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['STATE', 'FMONTH', 'DISPCODE',
                                             'PSU', 'CTELENM1', 'PVTRESD1',
                                             'COLGHOUS', 'STATERE1', 'CELPHON1',
                                             'LADULT1', 'COLGSEX1', 'NUMADULT',
                                             'LANDSEX1', 'NUMMEN', 'NUMWOMEN',
                                             'RESPSLCT', 'SAFETIME', 'CTELNUM1',
                                             'CELLFON5', 'CADULT1', 'CELLSEX1',
                                             'PVTRESD3', 'CCLGHOUS', 'CST...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=42,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2025-11-28 16:41:25,190:INFO:create_model() successfully completed......................................
2025-11-28 16:41:25,361:INFO:_master_model_container: 8
2025-11-28 16:41:25,361:INFO:_display_container: 5
2025-11-28 16:41:25,374:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['STATE', 'FMONTH', 'DISPCODE',
                                             'PSU', 'CTELENM1', 'PVTRESD1',
                                             'COLGHOUS', 'STATERE1', 'CELPHON1',
                                             'LADULT1', 'COLGSEX1', 'NUMADULT',
                                             'LANDSEX1', 'NUMMEN', 'NUMWOMEN',
                                             'RESPSLCT', 'SAFETIME', 'CTELNUM1',
                                             'CELLFON5', 'CADULT1', 'CELLSEX1',
                                             'PVTRESD3', 'CCLGHOUS', 'CST...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=42,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2025-11-28 16:41:25,374:INFO:finalize_model() successfully completed......................................
2025-11-28 16:41:25,550:INFO:Initializing save_model()
2025-11-28 16:41:25,550:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['STATE', 'FMONTH', 'DISPCODE',
                                             'PSU', 'CTELENM1', 'PVTRESD1',
                                             'COLGHOUS', 'STATERE1', 'CELPHON1',
                                             'LADULT1', 'COLGSEX1', 'NUMADULT',
                                             'LANDSEX1', 'NUMMEN', 'NUMWOMEN',
                                             'RESPSLCT', 'SAFETIME', 'CTELNUM1',
                                             'CELLFON5', 'CADULT1', 'CELLSEX1',
                                             'PVTRESD3', 'CCLGHOUS', 'CST...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=42,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), model_name=../models\final_pipeline_v1, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\OMAR\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['STATE', 'FMONTH', 'DISPCODE',
                                             'PSU', 'CTELENM1', 'PVTRESD1',
                                             'COLGHOUS', 'STATERE1', 'CELPHON1',
                                             'LADULT1', 'COLGSEX1', 'NUMADULT',
                                             'LANDSEX1', 'NUMMEN', 'NUMWOMEN',
                                             'RESPSLCT', 'SAFETIME', 'CTELNUM1',
                                             'CELLFON5', 'CADULT1...
                                    transformer=TargetEncoder(cols=['IDATE',
                                                                    'IDAY'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              random_state=42,
                                                                              sampling_strategy='auto'))))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2025-11-28 16:41:25,550:INFO:Adding model into prep_pipe
2025-11-28 16:41:25,550:WARNING:Only Model saved as it was a pipeline.
2025-11-28 16:41:25,569:INFO:../models\final_pipeline_v1.pkl saved in current working directory
2025-11-28 16:41:25,587:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['STATE', 'FMONTH', 'DISPCODE',
                                             'PSU', 'CTELENM1', 'PVTRESD1',
                                             'COLGHOUS', 'STATERE1', 'CELPHON1',
                                             'LADULT1', 'COLGSEX1', 'NUMADULT',
                                             'LANDSEX1', 'NUMMEN', 'NUMWOMEN',
                                             'RESPSLCT', 'SAFETIME', 'CTELNUM1',
                                             'CELLFON5', 'CADULT1', 'CELLSEX1',
                                             'PVTRESD3', 'CCLGHOUS', 'CST...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=42,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2025-11-28 16:41:25,587:INFO:save_model() successfully completed......................................
2025-11-28 16:41:33,335:INFO:Initializing get_config()
2025-11-28 16:41:33,335:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020508BC6920>, variable=X_train)
2025-11-28 16:41:33,335:INFO:Variable: 'X_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_train_transformed' instead.
2025-11-28 16:41:33,335:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'X_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_train_transformed' instead.
  warnings.warn(msg)  # print on screen

2025-11-28 16:41:33,382:INFO:Variable:  returned as        STATE  FMONTH     IDATE IMONTH IDAY IYEAR  DISPCODE           PSU  \
720     54.0     1.0  01192022     01   19  2022    1100.0  2.022002e+09   
3896    20.0     8.0  09042022     09   04  2022    1200.0  2.022005e+09   
12399    9.0     1.0  02282022     02   28  2022    1200.0  2.022006e+09   
1720    22.0     1.0  03212022     03   21  2022    1100.0  2.022002e+09   
4419    51.0     7.0  07082022     07   08  2022    1100.0  2.022007e+09   
...      ...     ...       ...    ...  ...   ...       ...           ...   
868     51.0     7.0  07072022     07   07  2022    1100.0  2.022007e+09   
11800    8.0     1.0  01252022     01   25  2022    1100.0  2.022001e+09   
10049   53.0    10.0  11102022     11   10  2022    1200.0  2.022021e+09   
4993    50.0     7.0  08022022     08   02  2022    1100.0  2.022005e+09   
9992    53.0     4.0  04212022     04   21  2022    1100.0  2.022010e+09   

       CTELENM1  PVTRESD1  ...  SMOKGRP  LCSREC  DRNKANY6  DROCDY4_  RFBING6  \
720         NaN       NaN  ...      3.0     2.0       1.0      50.0      1.0   
3896        NaN       NaN  ...      3.0     NaN       9.0     900.0      9.0   
12399       NaN       NaN  ...      NaN     NaN       9.0     900.0      9.0   
1720        NaN       NaN  ...      4.0     NaN       1.0      29.0      1.0   
4419        NaN       NaN  ...      3.0     NaN       1.0       7.0      1.0   
...         ...       ...  ...      ...     ...       ...       ...      ...   
868         NaN       NaN  ...      4.0     NaN       2.0       0.0      1.0   
11800       NaN       NaN  ...      4.0     NaN       2.0       0.0      1.0   
10049       NaN       NaN  ...      NaN     NaN       9.0     900.0      9.0   
4993        NaN       NaN  ...      4.0     NaN       1.0      14.0      1.0   
9992        NaN       NaN  ...      2.0     NaN       1.0      14.0      1.0   

       DRNKWK2  RFDRHV8  FLSHOT7  PNEUMO3  AIDTST4  
720      350.0      1.0      NaN      NaN      1.0  
3896   99900.0      9.0      9.0      9.0      NaN  
12399  99900.0      9.0      NaN      NaN      NaN  
1720     200.0      1.0      1.0      1.0      2.0  
4419     187.0      1.0      NaN      NaN      2.0  
...        ...      ...      ...      ...      ...  
868        0.0      1.0      NaN      NaN      1.0  
11800      0.0      1.0      NaN      NaN      2.0  
10049  99900.0      9.0      NaN      NaN      NaN  
4993     100.0      1.0      NaN      NaN      2.0  
9992     200.0      1.0      NaN      NaN      2.0  

[9283 rows x 326 columns]
2025-11-28 16:41:33,382:INFO:get_config() successfully completed......................................
2025-11-28 16:50:07,909:INFO:Initializing load_model()
2025-11-28 16:50:07,913:INFO:load_model(model_name=../models\final_pipeline_v1, platform=None, authentication=None, verbose=True)
2025-11-28 16:50:07,976:INFO:Initializing predict_model()
2025-11-28 16:50:07,976:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020508BC6920>, estimator=Pipeline(memory=FastMemory(location=C:\Users\OMAR\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['STATE', 'FMONTH', 'DISPCODE',
                                             'PSU', 'CTELENM1', 'PVTRESD1',
                                             'COLGHOUS', 'STATERE1', 'CELPHON1',
                                             'LADULT1', 'COLGSEX1', 'NUMADULT',
                                             'LANDSEX1', 'NUMMEN', 'NUMWOMEN',
                                             'RESPSLCT', 'SAFETIME', 'CTELNUM1',
                                             'CELLFON5', 'CADULT1...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=42,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=True, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000020507DE05E0>)
2025-11-28 16:50:07,976:INFO:Checking exceptions
2025-11-28 16:50:07,976:INFO:Preloading libraries
2025-11-28 16:50:07,979:INFO:Set up data.
2025-11-28 16:50:08,029:INFO:Set up index.
2025-11-28 16:50:08,042:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\impute\_base.py:577: UserWarning: Skipping features without any observed values: ['COLGHOUS' 'COLGSEX1' 'TOLDCFS' 'HAVECFS' 'WORKCFS']. At least one non-missing value is needed for imputation with strategy='mean'.
  warnings.warn(

2025-11-28 16:50:08,096:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\utils\generic.py:585: UserWarning: Traceback (most recent call last):
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\utils\generic.py", line 580, in _calculate_metric
    calculated_metric = score_func(y_test, target, sample_weight=weights, **kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\utils\generic.py", line 583, in _calculate_metric
    calculated_metric = score_func(y_test, target, **kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(traceback.format_exc())

2025-11-28 16:50:08,102:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-11-28 16:50:08,105:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-11-28 16:50:08,106:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-11-28 16:50:08,108:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-28 16:50:08,108:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-28 16:50:08,109:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-29 10:00:05,094:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-11-29 10:00:05,094:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-11-29 10:00:05,094:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-11-29 10:00:05,094:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-11-29 10:32:00,396:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-11-29 10:32:00,396:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-11-29 10:32:00,396:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-11-29 10:32:00,396:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-11-29 10:45:58,415:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-11-29 10:45:58,415:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-11-29 10:45:58,415:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-11-29 10:45:58,415:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-11-29 10:46:45,867:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-11-29 10:46:45,867:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-11-29 10:46:45,867:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-11-29 10:46:45,867:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-11-29 10:47:53,850:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-11-29 10:47:53,850:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-11-29 10:47:53,850:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-11-29 10:47:53,850:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-11-29 10:52:13,250:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-11-29 10:52:13,250:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-11-29 10:52:13,250:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-11-29 10:52:13,250:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-11-29 11:22:47,280:INFO:PyCaret ClassificationExperiment
2025-11-29 11:22:47,280:INFO:Logging name: clf-default-name
2025-11-29 11:22:47,280:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-11-29 11:22:47,280:INFO:version 3.3.2
2025-11-29 11:22:47,280:INFO:Initializing setup()
2025-11-29 11:22:47,280:INFO:self.USI: 7743
2025-11-29 11:22:47,280:INFO:self._variable_keys: {'y_train', 'idx', 'logging_param', 'data', 'y', 'fix_imbalance', 'pipeline', 'log_plots_param', 'html_param', 'X_train', 'fold_groups_param', '_ml_usecase', 'n_jobs_param', 'memory', 'gpu_param', 'X', 'X_test', 'exp_id', 'fold_shuffle_param', 'y_test', 'exp_name_log', 'USI', 'is_multiclass', 'gpu_n_jobs_param', 'fold_generator', 'target_param', '_available_plots', 'seed'}
2025-11-29 11:22:47,280:INFO:Checking environment
2025-11-29 11:22:47,280:INFO:python_version: 3.10.19
2025-11-29 11:22:47,280:INFO:python_build: ('main', 'Oct 22 2025 22:23:22')
2025-11-29 11:22:47,280:INFO:machine: AMD64
2025-11-29 11:22:47,280:INFO:platform: Windows-10-10.0.26100-SP0
2025-11-29 11:22:47,280:INFO:Memory: svmem(total=16282144768, available=3520397312, percent=78.4, used=12761747456, free=3520397312)
2025-11-29 11:22:47,281:INFO:Physical Core: 6
2025-11-29 11:22:47,281:INFO:Logical Core: 12
2025-11-29 11:22:47,281:INFO:Checking libraries
2025-11-29 11:22:47,281:INFO:System:
2025-11-29 11:22:47,281:INFO:    python: 3.10.19 | packaged by conda-forge | (main, Oct 22 2025, 22:23:22) [MSC v.1944 64 bit (AMD64)]
2025-11-29 11:22:47,281:INFO:executable: c:\Users\OMAR\miniconda3\envs\xgb_env\python.exe
2025-11-29 11:22:47,281:INFO:   machine: Windows-10-10.0.26100-SP0
2025-11-29 11:22:47,281:INFO:PyCaret required dependencies:
2025-11-29 11:22:47,285:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-29 11:22:47,363:INFO:                 pip: 25.3
2025-11-29 11:22:47,363:INFO:          setuptools: 80.9.0
2025-11-29 11:22:47,363:INFO:             pycaret: 3.3.2
2025-11-29 11:22:47,363:INFO:             IPython: 8.37.0
2025-11-29 11:22:47,363:INFO:          ipywidgets: 8.1.8
2025-11-29 11:22:47,363:INFO:                tqdm: 4.67.1
2025-11-29 11:22:47,363:INFO:               numpy: 1.26.4
2025-11-29 11:22:47,363:INFO:              pandas: 2.1.4
2025-11-29 11:22:47,363:INFO:              jinja2: 3.1.6
2025-11-29 11:22:47,363:INFO:               scipy: 1.11.4
2025-11-29 11:22:47,363:INFO:              joblib: 1.3.2
2025-11-29 11:22:47,363:INFO:             sklearn: 1.4.2
2025-11-29 11:22:47,363:INFO:                pyod: 2.0.5
2025-11-29 11:22:47,364:INFO:            imblearn: 0.14.0
2025-11-29 11:22:47,364:INFO:   category_encoders: 2.7.0
2025-11-29 11:22:47,364:INFO:            lightgbm: 4.6.0
2025-11-29 11:22:47,364:INFO:               numba: 0.62.1
2025-11-29 11:22:47,364:INFO:            requests: 2.32.5
2025-11-29 11:22:47,364:INFO:          matplotlib: 3.7.5
2025-11-29 11:22:47,364:INFO:          scikitplot: 0.3.7
2025-11-29 11:22:47,364:INFO:         yellowbrick: 1.5
2025-11-29 11:22:47,364:INFO:              plotly: 6.5.0
2025-11-29 11:22:47,364:INFO:    plotly-resampler: Not installed
2025-11-29 11:22:47,364:INFO:             kaleido: 1.2.0
2025-11-29 11:22:47,364:INFO:           schemdraw: 0.15
2025-11-29 11:22:47,364:INFO:         statsmodels: 0.14.5
2025-11-29 11:22:47,364:INFO:              sktime: 0.26.0
2025-11-29 11:22:47,364:INFO:               tbats: 1.1.3
2025-11-29 11:22:47,364:INFO:            pmdarima: 2.0.4
2025-11-29 11:22:47,364:INFO:              psutil: 7.1.3
2025-11-29 11:22:47,364:INFO:          markupsafe: 3.0.3
2025-11-29 11:22:47,364:INFO:             pickle5: Not installed
2025-11-29 11:22:47,364:INFO:         cloudpickle: 3.1.2
2025-11-29 11:22:47,364:INFO:         deprecation: 2.1.0
2025-11-29 11:22:47,364:INFO:              xxhash: 3.6.0
2025-11-29 11:22:47,364:INFO:           wurlitzer: Not installed
2025-11-29 11:22:47,364:INFO:PyCaret optional dependencies:
2025-11-29 11:22:47,413:INFO:                shap: 0.48.0
2025-11-29 11:22:47,414:INFO:           interpret: Not installed
2025-11-29 11:22:47,414:INFO:                umap: Not installed
2025-11-29 11:22:47,414:INFO:     ydata_profiling: Not installed
2025-11-29 11:22:47,414:INFO:  explainerdashboard: Not installed
2025-11-29 11:22:47,414:INFO:             autoviz: Not installed
2025-11-29 11:22:47,414:INFO:           fairlearn: 0.12.0.dev0
2025-11-29 11:22:47,414:INFO:          deepchecks: Not installed
2025-11-29 11:22:47,414:INFO:             xgboost: 3.1.2
2025-11-29 11:22:47,414:INFO:            catboost: Not installed
2025-11-29 11:22:47,414:INFO:              kmodes: Not installed
2025-11-29 11:22:47,414:INFO:             mlxtend: Not installed
2025-11-29 11:22:47,414:INFO:       statsforecast: Not installed
2025-11-29 11:22:47,414:INFO:        tune_sklearn: Not installed
2025-11-29 11:22:47,414:INFO:                 ray: Not installed
2025-11-29 11:22:47,414:INFO:            hyperopt: Not installed
2025-11-29 11:22:47,414:INFO:              optuna: Not installed
2025-11-29 11:22:47,414:INFO:               skopt: Not installed
2025-11-29 11:22:47,414:INFO:              mlflow: Not installed
2025-11-29 11:22:47,414:INFO:              gradio: Not installed
2025-11-29 11:22:47,414:INFO:             fastapi: Not installed
2025-11-29 11:22:47,414:INFO:             uvicorn: Not installed
2025-11-29 11:22:47,414:INFO:              m2cgen: Not installed
2025-11-29 11:22:47,414:INFO:           evidently: Not installed
2025-11-29 11:22:47,414:INFO:               fugue: Not installed
2025-11-29 11:22:47,414:INFO:           streamlit: 1.51.0
2025-11-29 11:22:47,414:INFO:             prophet: Not installed
2025-11-29 11:22:47,414:INFO:None
2025-11-29 11:22:47,414:INFO:Set up data.
2025-11-29 11:22:47,420:INFO:Set up folding strategy.
2025-11-29 11:22:47,420:INFO:Set up train/test split.
2025-11-29 11:22:47,424:INFO:Set up index.
2025-11-29 11:22:47,425:INFO:Assigning column types.
2025-11-29 11:22:47,428:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-11-29 11:22:47,455:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-11-29 11:22:47,458:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-11-29 11:22:47,480:INFO:Soft dependency imported: xgboost: 3.1.2
2025-11-29 11:22:47,482:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-29 11:22:47,507:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-11-29 11:22:47,508:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-11-29 11:22:47,525:INFO:Soft dependency imported: xgboost: 3.1.2
2025-11-29 11:22:47,527:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-29 11:22:47,527:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-11-29 11:22:47,553:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-11-29 11:22:47,568:INFO:Soft dependency imported: xgboost: 3.1.2
2025-11-29 11:22:47,569:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-29 11:22:47,596:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-11-29 11:22:47,612:INFO:Soft dependency imported: xgboost: 3.1.2
2025-11-29 11:22:47,613:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-29 11:22:47,613:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-11-29 11:22:47,667:INFO:Soft dependency imported: xgboost: 3.1.2
2025-11-29 11:22:47,670:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-29 11:22:47,713:INFO:Soft dependency imported: xgboost: 3.1.2
2025-11-29 11:22:47,714:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-29 11:22:47,720:INFO:Preparing preprocessing pipeline...
2025-11-29 11:22:47,721:INFO:Set up simple imputation.
2025-11-29 11:22:47,725:INFO:Set up encoding of ordinal features.
2025-11-29 11:22:47,730:INFO:Set up encoding of categorical features.
2025-11-29 11:22:47,730:INFO:Set up removing outliers.
2025-11-29 11:22:47,730:INFO:Set up imbalanced handling.
2025-11-29 11:22:47,730:INFO:Set up feature normalization.
2025-11-29 11:22:47,945:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\joblib\externals\loky\backend\context.py:136: UserWarning: Could not find the number of physical cores for the following reason:
[WinError 2] El sistema no puede encontrar el archivo especificado
Returning the number of logical cores instead. You can silence this warning by setting LOKY_MAX_CPU_COUNT to the number of cores you want to use.
  warnings.warn(

2025-11-29 11:22:47,967:INFO:Finished creating preprocessing pipeline.
2025-11-29 11:22:48,015:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\OMAR\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'SystolicBP',
                                             'TotalCholesterol', 'LDL',
                                             'Triglycerides', 'HbA1c',
                                             'Glucose', 'UricAcid',
                                             'Creatinine', 'BMI',
                                             'WaistCircumference', 'Height',
                                             'IncomeRatio', 'ALT_Enzyme',
                                             'AST_Enzyme', 'GGT_Enzyme',
                                             'Albumin', 'Po...
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              random_state=123,
                                                                              sampling_strategy='auto')))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=RobustScaler(copy=True,
                                                             quantile_range=(25.0,
                                                                             75.0),
                                                             unit_variance=False,
                                                             with_centering=True,
                                                             with_scaling=True)))],
         verbose=False)
2025-11-29 11:22:48,015:INFO:Creating final display dataframe.
2025-11-29 11:22:48,575:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target      HeartDisease
2                   Target type            Binary
3           Original data shape        (2185, 27)
4        Transformed data shape        (3484, 36)
5   Transformed train set shape        (2828, 36)
6    Transformed test set shape         (656, 36)
7              Numeric features                19
8          Categorical features                 7
9      Rows with missing values             87.6%
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16              Remove outliers              True
17           Outliers threshold              0.05
18                Fix imbalance              True
19         Fix imbalance method             SMOTE
20                    Normalize              True
21             Normalize method            robust
22               Fold Generator   StratifiedKFold
23                  Fold Number                10
24                     CPU Jobs                -1
25                      Use GPU             False
26               Log Experiment             False
27              Experiment Name  clf-default-name
28                          USI              7743
2025-11-29 11:22:48,626:INFO:Soft dependency imported: xgboost: 3.1.2
2025-11-29 11:22:48,627:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-29 11:22:48,671:INFO:Soft dependency imported: xgboost: 3.1.2
2025-11-29 11:22:48,673:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-29 11:22:48,675:INFO:setup() successfully completed in 1.41s...............
2025-11-29 11:30:52,503:INFO:Initializing compare_models()
2025-11-29 11:30:52,503:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025EE79BDC00>, include=['xgboost', 'lightgbm'], fold=None, round=4, cross_validation=True, sort=Recall, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000025EE79BDC00>, 'include': ['xgboost', 'lightgbm'], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Recall', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2025-11-29 11:30:52,503:INFO:Checking exceptions
2025-11-29 11:30:52,509:INFO:Preparing display monitor
2025-11-29 11:30:52,530:INFO:Initializing Extreme Gradient Boosting
2025-11-29 11:30:52,530:INFO:Total runtime is 0.0 minutes
2025-11-29 11:30:52,532:INFO:SubProcess create_model() called ==================================
2025-11-29 11:30:52,532:INFO:Initializing create_model()
2025-11-29 11:30:52,532:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025EE79BDC00>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025EE4FEEBF0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-29 11:30:52,532:INFO:Checking exceptions
2025-11-29 11:30:52,532:INFO:Importing libraries
2025-11-29 11:30:52,532:INFO:Copying training dataset
2025-11-29 11:30:52,537:INFO:Defining folds
2025-11-29 11:30:52,537:INFO:Declaring metric variables
2025-11-29 11:30:52,540:INFO:Importing untrained model
2025-11-29 11:30:52,544:INFO:Extreme Gradient Boosting Imported successfully
2025-11-29 11:30:52,550:INFO:Starting cross validation
2025-11-29 11:30:52,558:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-29 11:30:56,153:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-29 11:30:56,161:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-29 11:30:56,165:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-29 11:30:56,167:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-29 11:30:56,169:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-29 11:30:56,169:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-29 11:30:56,176:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-29 11:30:56,176:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-29 11:30:56,180:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-29 11:30:56,187:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-29 11:30:56,803:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-11-29 11:30:56,806:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-11-29 11:30:56,817:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-11-29 11:30:56,844:INFO:Calculating mean and std
2025-11-29 11:30:56,846:INFO:Creating metrics dataframe
2025-11-29 11:30:56,848:INFO:Uploading results into container
2025-11-29 11:30:56,850:INFO:Uploading model into container now
2025-11-29 11:30:56,850:INFO:_master_model_container: 1
2025-11-29 11:30:56,850:INFO:_display_container: 2
2025-11-29 11:30:56,853:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              feature_weights=None, gamma=None, grow_policy=None,
              importance_type=None, interaction_constraints=None,
              learning_rate=None, max_bin=None, max_cat_threshold=None,
              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,
              max_leaves=None, min_child_weight=None, missing=nan,
              monotone_constraints=None, multi_strategy=None, n_estimators=None,
              n_jobs=-1, num_parallel_tree=None, ...)
2025-11-29 11:30:56,853:INFO:create_model() successfully completed......................................
2025-11-29 11:30:57,026:INFO:SubProcess create_model() end ==================================
2025-11-29 11:30:57,026:INFO:Creating metrics dataframe
2025-11-29 11:30:57,032:INFO:Initializing Light Gradient Boosting Machine
2025-11-29 11:30:57,032:INFO:Total runtime is 0.0750348687171936 minutes
2025-11-29 11:30:57,037:INFO:SubProcess create_model() called ==================================
2025-11-29 11:30:57,037:INFO:Initializing create_model()
2025-11-29 11:30:57,037:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025EE79BDC00>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025EE4FEEBF0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-29 11:30:57,037:INFO:Checking exceptions
2025-11-29 11:30:57,037:INFO:Importing libraries
2025-11-29 11:30:57,037:INFO:Copying training dataset
2025-11-29 11:30:57,044:INFO:Defining folds
2025-11-29 11:30:57,044:INFO:Declaring metric variables
2025-11-29 11:30:57,049:INFO:Importing untrained model
2025-11-29 11:30:57,049:INFO:Light Gradient Boosting Machine Imported successfully
2025-11-29 11:30:57,056:INFO:Starting cross validation
2025-11-29 11:30:57,064:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-29 11:30:58,553:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-11-29 11:30:58,616:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-11-29 11:30:58,780:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-11-29 11:30:58,840:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-11-29 11:30:59,726:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-29 11:30:59,740:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-29 11:31:00,090:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-11-29 11:31:00,099:INFO:Calculating mean and std
2025-11-29 11:31:00,100:INFO:Creating metrics dataframe
2025-11-29 11:31:00,103:INFO:Uploading results into container
2025-11-29 11:31:00,103:INFO:Uploading model into container now
2025-11-29 11:31:00,104:INFO:_master_model_container: 2
2025-11-29 11:31:00,104:INFO:_display_container: 2
2025-11-29 11:31:00,105:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-11-29 11:31:00,105:INFO:create_model() successfully completed......................................
2025-11-29 11:31:00,246:INFO:SubProcess create_model() end ==================================
2025-11-29 11:31:00,246:INFO:Creating metrics dataframe
2025-11-29 11:31:00,259:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  master_display_.apply(

2025-11-29 11:31:00,266:INFO:Initializing create_model()
2025-11-29 11:31:00,266:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025EE79BDC00>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              feature_weights=None, gamma=None, grow_policy=None,
              importance_type=None, interaction_constraints=None,
              learning_rate=None, max_bin=None, max_cat_threshold=None,
              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,
              max_leaves=None, min_child_weight=None, missing=nan,
              monotone_constraints=None, multi_strategy=None, n_estimators=None,
              n_jobs=-1, num_parallel_tree=None, ...), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-29 11:31:00,266:INFO:Checking exceptions
2025-11-29 11:31:00,267:INFO:Importing libraries
2025-11-29 11:31:00,267:INFO:Copying training dataset
2025-11-29 11:31:00,267:INFO:Defining folds
2025-11-29 11:31:00,267:INFO:Declaring metric variables
2025-11-29 11:31:00,267:INFO:Importing untrained model
2025-11-29 11:31:00,267:INFO:Declaring custom model
2025-11-29 11:31:00,267:INFO:Extreme Gradient Boosting Imported successfully
2025-11-29 11:31:00,280:INFO:Cross validation set to False
2025-11-29 11:31:00,280:INFO:Fitting Model
2025-11-29 11:31:00,492:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              feature_weights=None, gamma=None, grow_policy=None,
              importance_type=None, interaction_constraints=None,
              learning_rate=None, max_bin=None, max_cat_threshold=None,
              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,
              max_leaves=None, min_child_weight=None, missing=nan,
              monotone_constraints=None, multi_strategy=None, n_estimators=None,
              n_jobs=-1, num_parallel_tree=None, ...)
2025-11-29 11:31:00,492:INFO:create_model() successfully completed......................................
2025-11-29 11:31:00,630:INFO:_master_model_container: 2
2025-11-29 11:31:00,630:INFO:_display_container: 2
2025-11-29 11:31:00,631:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              feature_weights=None, gamma=None, grow_policy=None,
              importance_type=None, interaction_constraints=None,
              learning_rate=None, max_bin=None, max_cat_threshold=None,
              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,
              max_leaves=None, min_child_weight=None, missing=nan,
              monotone_constraints=None, multi_strategy=None, n_estimators=None,
              n_jobs=-1, num_parallel_tree=None, ...)
2025-11-29 11:31:00,631:INFO:compare_models() successfully completed......................................
2025-11-29 11:31:22,717:INFO:Initializing tune_model()
2025-11-29 11:31:22,717:INFO:tune_model(estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              feature_weights=None, gamma=None, grow_policy=None,
              importance_type=None, interaction_constraints=None,
              learning_rate=None, max_bin=None, max_cat_threshold=None,
              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,
              max_leaves=None, min_child_weight=None, missing=nan,
              monotone_constraints=None, multi_strategy=None, n_estimators=None,
              n_jobs=-1, num_parallel_tree=None, ...), fold=None, round=4, n_iter=5, custom_grid=None, optimize=Recall, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=False, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025EE79BDC00>)
2025-11-29 11:31:22,717:INFO:Checking exceptions
2025-11-29 11:31:22,723:INFO:Copying training dataset
2025-11-29 11:31:22,728:INFO:Checking base model
2025-11-29 11:31:22,728:INFO:Base model : Extreme Gradient Boosting
2025-11-29 11:31:22,729:INFO:Declaring metric variables
2025-11-29 11:31:22,729:INFO:Defining Hyperparameters
2025-11-29 11:31:22,861:INFO:Tuning with n_jobs=-1
2025-11-29 11:31:22,861:INFO:Initializing RandomizedSearchCV
2025-11-29 11:31:26,292:INFO:best_params: {'actual_estimator__subsample': 0.5, 'actual_estimator__scale_pos_weight': 2.1, 'actual_estimator__reg_lambda': 5, 'actual_estimator__reg_alpha': 0.05, 'actual_estimator__n_estimators': 300, 'actual_estimator__min_child_weight': 1, 'actual_estimator__max_depth': 10, 'actual_estimator__learning_rate': 0.0005, 'actual_estimator__colsample_bytree': 1}
2025-11-29 11:31:26,292:INFO:Hyperparameter search completed
2025-11-29 11:31:26,292:INFO:SubProcess create_model() called ==================================
2025-11-29 11:31:26,293:INFO:Initializing create_model()
2025-11-29 11:31:26,293:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025EE79BDC00>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              feature_weights=None, gamma=None, grow_policy=None,
              importance_type=None, interaction_constraints=None,
              learning_rate=None, max_bin=None, max_cat_threshold=None,
              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,
              max_leaves=None, min_child_weight=None, missing=nan,
              monotone_constraints=None, multi_strategy=None, n_estimators=None,
              n_jobs=-1, num_parallel_tree=None, ...), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025EE4E877F0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'subsample': 0.5, 'scale_pos_weight': 2.1, 'reg_lambda': 5, 'reg_alpha': 0.05, 'n_estimators': 300, 'min_child_weight': 1, 'max_depth': 10, 'learning_rate': 0.0005, 'colsample_bytree': 1})
2025-11-29 11:31:26,293:INFO:Checking exceptions
2025-11-29 11:31:26,293:INFO:Importing libraries
2025-11-29 11:31:26,293:INFO:Copying training dataset
2025-11-29 11:31:26,296:INFO:Defining folds
2025-11-29 11:31:26,296:INFO:Declaring metric variables
2025-11-29 11:31:26,296:INFO:Importing untrained model
2025-11-29 11:31:26,296:INFO:Declaring custom model
2025-11-29 11:31:26,296:INFO:Extreme Gradient Boosting Imported successfully
2025-11-29 11:31:26,296:INFO:Starting cross validation
2025-11-29 11:31:26,303:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-29 11:31:28,026:INFO:Calculating mean and std
2025-11-29 11:31:28,026:INFO:Creating metrics dataframe
2025-11-29 11:31:28,026:INFO:Finalizing model
2025-11-29 11:31:28,477:INFO:Uploading results into container
2025-11-29 11:31:28,477:INFO:Uploading model into container now
2025-11-29 11:31:28,477:INFO:_master_model_container: 3
2025-11-29 11:31:28,477:INFO:_display_container: 3
2025-11-29 11:31:28,479:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None, colsample_bytree=1,
              device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              feature_weights=None, gamma=None, grow_policy=None,
              importance_type=None, interaction_constraints=None,
              learning_rate=0.0005, max_bin=None, max_cat_threshold=None,
              max_cat_to_onehot=None, max_delta_step=None, max_depth=10,
              max_leaves=None, min_child_weight=1, missing=nan,
              monotone_constraints=None, multi_strategy=None, n_estimators=300,
              n_jobs=-1, num_parallel_tree=None, ...)
2025-11-29 11:31:28,479:INFO:create_model() successfully completed......................................
2025-11-29 11:31:28,602:INFO:SubProcess create_model() end ==================================
2025-11-29 11:31:28,602:INFO:choose_better activated
2025-11-29 11:31:28,603:INFO:SubProcess create_model() called ==================================
2025-11-29 11:31:28,603:INFO:Initializing create_model()
2025-11-29 11:31:28,603:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025EE79BDC00>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              feature_weights=None, gamma=None, grow_policy=None,
              importance_type=None, interaction_constraints=None,
              learning_rate=None, max_bin=None, max_cat_threshold=None,
              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,
              max_leaves=None, min_child_weight=None, missing=nan,
              monotone_constraints=None, multi_strategy=None, n_estimators=None,
              n_jobs=-1, num_parallel_tree=None, ...), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-29 11:31:28,603:INFO:Checking exceptions
2025-11-29 11:31:28,603:INFO:Importing libraries
2025-11-29 11:31:28,603:INFO:Copying training dataset
2025-11-29 11:31:28,606:INFO:Defining folds
2025-11-29 11:31:28,606:INFO:Declaring metric variables
2025-11-29 11:31:28,606:INFO:Importing untrained model
2025-11-29 11:31:28,606:INFO:Declaring custom model
2025-11-29 11:31:28,609:INFO:Extreme Gradient Boosting Imported successfully
2025-11-29 11:31:28,609:INFO:Starting cross validation
2025-11-29 11:31:28,613:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-29 11:31:29,053:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-11-29 11:31:29,060:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-11-29 11:31:29,067:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-11-29 11:31:29,076:INFO:Calculating mean and std
2025-11-29 11:31:29,076:INFO:Creating metrics dataframe
2025-11-29 11:31:29,078:INFO:Finalizing model
2025-11-29 11:31:29,277:INFO:Uploading results into container
2025-11-29 11:31:29,277:INFO:Uploading model into container now
2025-11-29 11:31:29,277:INFO:_master_model_container: 4
2025-11-29 11:31:29,277:INFO:_display_container: 4
2025-11-29 11:31:29,280:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              feature_weights=None, gamma=None, grow_policy=None,
              importance_type=None, interaction_constraints=None,
              learning_rate=None, max_bin=None, max_cat_threshold=None,
              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,
              max_leaves=None, min_child_weight=None, missing=nan,
              monotone_constraints=None, multi_strategy=None, n_estimators=None,
              n_jobs=-1, num_parallel_tree=None, ...)
2025-11-29 11:31:29,280:INFO:create_model() successfully completed......................................
2025-11-29 11:31:29,404:INFO:SubProcess create_model() end ==================================
2025-11-29 11:31:29,404:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              feature_weights=None, gamma=None, grow_policy=None,
              importance_type=None, interaction_constraints=None,
              learning_rate=None, max_bin=None, max_cat_threshold=None,
              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,
              max_leaves=None, min_child_weight=None, missing=nan,
              monotone_constraints=None, multi_strategy=None, n_estimators=None,
              n_jobs=-1, num_parallel_tree=None, ...) result for Recall is 0.065
2025-11-29 11:31:29,404:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None, colsample_bytree=1,
              device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              feature_weights=None, gamma=None, grow_policy=None,
              importance_type=None, interaction_constraints=None,
              learning_rate=0.0005, max_bin=None, max_cat_threshold=None,
              max_cat_to_onehot=None, max_delta_step=None, max_depth=10,
              max_leaves=None, min_child_weight=1, missing=nan,
              monotone_constraints=None, multi_strategy=None, n_estimators=300,
              n_jobs=-1, num_parallel_tree=None, ...) result for Recall is 1.0
2025-11-29 11:31:29,404:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None, colsample_bytree=1,
              device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              feature_weights=None, gamma=None, grow_policy=None,
              importance_type=None, interaction_constraints=None,
              learning_rate=0.0005, max_bin=None, max_cat_threshold=None,
              max_cat_to_onehot=None, max_delta_step=None, max_depth=10,
              max_leaves=None, min_child_weight=1, missing=nan,
              monotone_constraints=None, multi_strategy=None, n_estimators=300,
              n_jobs=-1, num_parallel_tree=None, ...) is best model
2025-11-29 11:31:29,404:INFO:choose_better completed
2025-11-29 11:31:29,406:INFO:_master_model_container: 4
2025-11-29 11:31:29,406:INFO:_display_container: 3
2025-11-29 11:31:29,406:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None, colsample_bytree=1,
              device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              feature_weights=None, gamma=None, grow_policy=None,
              importance_type=None, interaction_constraints=None,
              learning_rate=0.0005, max_bin=None, max_cat_threshold=None,
              max_cat_to_onehot=None, max_delta_step=None, max_depth=10,
              max_leaves=None, min_child_weight=1, missing=nan,
              monotone_constraints=None, multi_strategy=None, n_estimators=300,
              n_jobs=-1, num_parallel_tree=None, ...)
2025-11-29 11:31:29,406:INFO:tune_model() successfully completed......................................
2025-11-29 11:32:35,163:INFO:Initializing finalize_model()
2025-11-29 11:32:35,163:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025EE79BDC00>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None, colsample_bytree=1,
              device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              feature_weights=None, gamma=None, grow_policy=None,
              importance_type=None, interaction_constraints=None,
              learning_rate=0.0005, max_bin=None, max_cat_threshold=None,
              max_cat_to_onehot=None, max_delta_step=None, max_depth=10,
              max_leaves=None, min_child_weight=1, missing=nan,
              monotone_constraints=None, multi_strategy=None, n_estimators=300,
              n_jobs=-1, num_parallel_tree=None, ...), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2025-11-29 11:32:35,164:INFO:Finalizing XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None, colsample_bytree=1,
              device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              feature_weights=None, gamma=None, grow_policy=None,
              importance_type=None, interaction_constraints=None,
              learning_rate=0.0005, max_bin=None, max_cat_threshold=None,
              max_cat_to_onehot=None, max_delta_step=None, max_depth=10,
              max_leaves=None, min_child_weight=1, missing=nan,
              monotone_constraints=None, multi_strategy=None, n_estimators=300,
              n_jobs=-1, num_parallel_tree=None, ...)
2025-11-29 11:32:35,167:INFO:Initializing create_model()
2025-11-29 11:32:35,167:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025EE79BDC00>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None, colsample_bytree=1,
              device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              feature_weights=None, gamma=None, grow_policy=None,
              importance_type=None, interaction_constraints=None,
              learning_rate=0.0005, max_bin=None, max_cat_threshold=None,
              max_cat_to_onehot=None, max_delta_step=None, max_depth=10,
              max_leaves=None, min_child_weight=1, missing=nan,
              monotone_constraints=None, multi_strategy=None, n_estimators=300,
              n_jobs=-1, num_parallel_tree=None, ...), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2025-11-29 11:32:35,167:INFO:Checking exceptions
2025-11-29 11:32:35,169:INFO:Importing libraries
2025-11-29 11:32:35,169:INFO:Copying training dataset
2025-11-29 11:32:35,169:INFO:Defining folds
2025-11-29 11:32:35,169:INFO:Declaring metric variables
2025-11-29 11:32:35,169:INFO:Importing untrained model
2025-11-29 11:32:35,169:INFO:Declaring custom model
2025-11-29 11:32:35,171:INFO:Extreme Gradient Boosting Imported successfully
2025-11-29 11:32:35,176:INFO:Cross validation set to False
2025-11-29 11:32:35,176:INFO:Fitting Model
2025-11-29 11:32:35,797:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'SystolicBP',
                                             'TotalCholesterol', 'LDL',
                                             'Triglycerides', 'HbA1c',
                                             'Glucose', 'UricAcid',
                                             'Creatinine', 'BMI',
                                             'WaistCircumference', 'Height',
                                             'IncomeRatio', 'ALT_Enzyme',
                                             'AST_Enzyme', 'GGT_Enzyme',
                                             'Albumin', 'Potassium', 'Sodium'],
                                    transformer=SimpleIm...
                               gamma=None, grow_policy=None,
                               importance_type=None,
                               interaction_constraints=None,
                               learning_rate=0.0005, max_bin=None,
                               max_cat_threshold=None, max_cat_to_onehot=None,
                               max_delta_step=None, max_depth=10,
                               max_leaves=None, min_child_weight=1, missing=nan,
                               monotone_constraints=None, multi_strategy=None,
                               n_estimators=300, n_jobs=-1,
                               num_parallel_tree=None, ...))],
         verbose=False)
2025-11-29 11:32:35,797:INFO:create_model() successfully completed......................................
2025-11-29 11:32:35,910:INFO:_master_model_container: 4
2025-11-29 11:32:35,910:INFO:_display_container: 3
2025-11-29 11:32:35,959:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'SystolicBP',
                                             'TotalCholesterol', 'LDL',
                                             'Triglycerides', 'HbA1c',
                                             'Glucose', 'UricAcid',
                                             'Creatinine', 'BMI',
                                             'WaistCircumference', 'Height',
                                             'IncomeRatio', 'ALT_Enzyme',
                                             'AST_Enzyme', 'GGT_Enzyme',
                                             'Albumin', 'Potassium', 'Sodium'],
                                    transformer=SimpleIm...
                               gamma=None, grow_policy=None,
                               importance_type=None,
                               interaction_constraints=None,
                               learning_rate=0.0005, max_bin=None,
                               max_cat_threshold=None, max_cat_to_onehot=None,
                               max_delta_step=None, max_depth=10,
                               max_leaves=None, min_child_weight=1, missing=nan,
                               monotone_constraints=None, multi_strategy=None,
                               n_estimators=300, n_jobs=-1,
                               num_parallel_tree=None, ...))],
         verbose=False)
2025-11-29 11:32:35,959:INFO:finalize_model() successfully completed......................................
2025-11-29 11:32:36,167:INFO:Initializing save_model()
2025-11-29 11:32:36,167:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'SystolicBP',
                                             'TotalCholesterol', 'LDL',
                                             'Triglycerides', 'HbA1c',
                                             'Glucose', 'UricAcid',
                                             'Creatinine', 'BMI',
                                             'WaistCircumference', 'Height',
                                             'IncomeRatio', 'ALT_Enzyme',
                                             'AST_Enzyme', 'GGT_Enzyme',
                                             'Albumin', 'Potassium', 'Sodium'],
                                    transformer=SimpleIm...
                               gamma=None, grow_policy=None,
                               importance_type=None,
                               interaction_constraints=None,
                               learning_rate=0.0005, max_bin=None,
                               max_cat_threshold=None, max_cat_to_onehot=None,
                               max_delta_step=None, max_depth=10,
                               max_leaves=None, min_child_weight=1, missing=nan,
                               monotone_constraints=None, multi_strategy=None,
                               n_estimators=300, n_jobs=-1,
                               num_parallel_tree=None, ...))],
         verbose=False), model_name=../models\best_pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\OMAR\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'SystolicBP',
                                             'TotalCholesterol', 'LDL',
                                             'Triglycerides', 'HbA1c',
                                             'Glucose', 'UricAcid',
                                             'Creatinine', 'BMI',
                                             'WaistCircumference', 'Height',
                                             'IncomeRatio', 'ALT_Enzyme',
                                             'AST_Enzyme', 'GGT_Enzyme',
                                             'Albumin', 'Po...
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              random_state=123,
                                                                              sampling_strategy='auto')))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=RobustScaler(copy=True,
                                                             quantile_range=(25.0,
                                                                             75.0),
                                                             unit_variance=False,
                                                             with_centering=True,
                                                             with_scaling=True)))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2025-11-29 11:32:36,167:INFO:Adding model into prep_pipe
2025-11-29 11:32:36,167:WARNING:Only Model saved as it was a pipeline.
2025-11-29 11:32:36,207:INFO:../models\best_pipeline.pkl saved in current working directory
2025-11-29 11:32:36,273:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'SystolicBP',
                                             'TotalCholesterol', 'LDL',
                                             'Triglycerides', 'HbA1c',
                                             'Glucose', 'UricAcid',
                                             'Creatinine', 'BMI',
                                             'WaistCircumference', 'Height',
                                             'IncomeRatio', 'ALT_Enzyme',
                                             'AST_Enzyme', 'GGT_Enzyme',
                                             'Albumin', 'Potassium', 'Sodium'],
                                    transformer=SimpleIm...
                               gamma=None, grow_policy=None,
                               importance_type=None,
                               interaction_constraints=None,
                               learning_rate=0.0005, max_bin=None,
                               max_cat_threshold=None, max_cat_to_onehot=None,
                               max_delta_step=None, max_depth=10,
                               max_leaves=None, min_child_weight=1, missing=nan,
                               monotone_constraints=None, multi_strategy=None,
                               n_estimators=300, n_jobs=-1,
                               num_parallel_tree=None, ...))],
         verbose=False)
2025-11-29 11:32:36,273:INFO:save_model() successfully completed......................................
2025-11-29 11:32:56,840:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-11-29 11:32:56,840:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-11-29 11:32:56,840:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-11-29 11:32:56,840:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-11-29 11:33:01,238:INFO:Initializing load_model()
2025-11-29 11:33:01,238:INFO:load_model(model_name=../models/best_pipeline, platform=None, authentication=None, verbose=True)
2025-11-29 11:33:01,297:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-29 11:33:11,410:INFO:Initializing predict_model()
2025-11-29 11:33:11,410:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021219F935B0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Age', 'SystolicBP',
                                             'TotalCholesterol', 'LDL',
                                             'Triglycerides', 'HbA1c',
                                             'Glucose', 'UricAcid',
                                             'Creatinine', 'BMI',
                                             'WaistCircumference', 'Height',
                                             'IncomeRatio', 'ALT_Enzyme',
                                             'AST_Enzyme', 'GGT_Enzyme',
                                             'Albumin', 'Potassium', 'Sodium'],
                                    transformer=SimpleImputer())),
                ('c...
                               feature_types=None, feature_weights=None,
                               gamma=None, grow_policy=None,
                               importance_type=None,
                               interaction_constraints=None,
                               learning_rate=0.0005, max_bin=None,
                               max_cat_threshold=None, max_cat_to_onehot=None,
                               max_delta_step=None, max_depth=10,
                               max_leaves=None, min_child_weight=1, missing=nan,
                               monotone_constraints=None, multi_strategy=None,
                               n_estimators=300, n_jobs=-1,
                               num_parallel_tree=None, ...))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000021219DFA170>)
2025-11-29 11:33:11,410:INFO:Checking exceptions
2025-11-29 11:33:11,410:INFO:Preloading libraries
2025-11-29 11:33:11,410:INFO:Set up data.
2025-11-29 11:33:11,421:INFO:Set up index.
2025-11-29 11:33:27,570:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-11-29 11:33:27,574:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-11-29 11:33:27,574:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-11-29 11:48:23,953:INFO:Initializing load_model()
2025-11-29 11:48:23,954:INFO:load_model(model_name=../models/best_pipeline, platform=None, authentication=None, verbose=True)
2025-11-29 11:48:33,828:INFO:Initializing predict_model()
2025-11-29 11:48:33,828:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002124DF96EC0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Age', 'SystolicBP',
                                             'TotalCholesterol', 'LDL',
                                             'Triglycerides', 'HbA1c',
                                             'Glucose', 'UricAcid',
                                             'Creatinine', 'BMI',
                                             'WaistCircumference', 'Height',
                                             'IncomeRatio', 'ALT_Enzyme',
                                             'AST_Enzyme', 'GGT_Enzyme',
                                             'Albumin', 'Potassium', 'Sodium'],
                                    transformer=SimpleImputer())),
                ('c...
                               feature_types=None, feature_weights=None,
                               gamma=None, grow_policy=None,
                               importance_type=None,
                               interaction_constraints=None,
                               learning_rate=0.0005, max_bin=None,
                               max_cat_threshold=None, max_cat_to_onehot=None,
                               max_delta_step=None, max_depth=10,
                               max_leaves=None, min_child_weight=1, missing=nan,
                               monotone_constraints=None, multi_strategy=None,
                               n_estimators=300, n_jobs=-1,
                               num_parallel_tree=None, ...))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000021232187880>)
2025-11-29 11:48:33,828:INFO:Checking exceptions
2025-11-29 11:48:33,828:INFO:Preloading libraries
2025-11-29 11:48:33,828:INFO:Set up data.
2025-11-29 11:48:33,837:INFO:Set up index.
2025-11-29 11:48:39,864:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-11-29 11:48:39,867:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-11-29 11:48:39,869:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-11-29 11:53:13,069:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-11-29 11:53:13,069:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-11-29 11:53:13,069:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-11-29 11:53:13,069:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-11-29 11:53:22,473:INFO:Initializing load_model()
2025-11-29 11:53:22,473:INFO:load_model(model_name=../models/best_pipeline, platform=None, authentication=None, verbose=True)
2025-11-29 11:53:22,530:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-29 12:00:24,813:INFO:Initializing load_model()
2025-11-29 12:00:24,813:INFO:load_model(model_name=../models/best_pipeline, platform=None, authentication=None, verbose=True)
2025-11-29 12:00:50,055:INFO:Initializing predict_model()
2025-11-29 12:00:50,055:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017F198DB070>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Age', 'SystolicBP',
                                             'TotalCholesterol', 'LDL',
                                             'Triglycerides', 'HbA1c',
                                             'Glucose', 'UricAcid',
                                             'Creatinine', 'BMI',
                                             'WaistCircumference', 'Height',
                                             'IncomeRatio', 'ALT_Enzyme',
                                             'AST_Enzyme', 'GGT_Enzyme',
                                             'Albumin', 'Potassium', 'Sodium'],
                                    transformer=SimpleImputer())),
                ('c...
                               feature_types=None, feature_weights=None,
                               gamma=None, grow_policy=None,
                               importance_type=None,
                               interaction_constraints=None,
                               learning_rate=0.0005, max_bin=None,
                               max_cat_threshold=None, max_cat_to_onehot=None,
                               max_delta_step=None, max_depth=10,
                               max_leaves=None, min_child_weight=1, missing=nan,
                               monotone_constraints=None, multi_strategy=None,
                               n_estimators=300, n_jobs=-1,
                               num_parallel_tree=None, ...))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000017F1AC72B00>)
2025-11-29 12:00:50,055:INFO:Checking exceptions
2025-11-29 12:00:50,055:INFO:Preloading libraries
2025-11-29 12:00:50,055:INFO:Set up data.
2025-11-29 12:00:50,058:INFO:Set up index.
2025-11-29 12:04:17,178:INFO:Initializing predict_model()
2025-11-29 12:04:17,179:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017F198DB1F0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Age', 'SystolicBP',
                                             'TotalCholesterol', 'LDL',
                                             'Triglycerides', 'HbA1c',
                                             'Glucose', 'UricAcid',
                                             'Creatinine', 'BMI',
                                             'WaistCircumference', 'Height',
                                             'IncomeRatio', 'ALT_Enzyme',
                                             'AST_Enzyme', 'GGT_Enzyme',
                                             'Albumin', 'Potassium', 'Sodium'],
                                    transformer=SimpleImputer())),
                ('c...
                               feature_types=None, feature_weights=None,
                               gamma=None, grow_policy=None,
                               importance_type=None,
                               interaction_constraints=None,
                               learning_rate=0.0005, max_bin=None,
                               max_cat_threshold=None, max_cat_to_onehot=None,
                               max_delta_step=None, max_depth=10,
                               max_leaves=None, min_child_weight=1, missing=nan,
                               monotone_constraints=None, multi_strategy=None,
                               n_estimators=300, n_jobs=-1,
                               num_parallel_tree=None, ...))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000017F1D1B6560>)
2025-11-29 12:04:17,179:INFO:Checking exceptions
2025-11-29 12:04:17,179:INFO:Preloading libraries
2025-11-29 12:04:17,179:INFO:Set up data.
2025-11-29 12:04:17,183:INFO:Set up index.
2025-11-29 12:04:44,535:INFO:Initializing predict_model()
2025-11-29 12:04:44,535:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017F1991A7A0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Age', 'SystolicBP',
                                             'TotalCholesterol', 'LDL',
                                             'Triglycerides', 'HbA1c',
                                             'Glucose', 'UricAcid',
                                             'Creatinine', 'BMI',
                                             'WaistCircumference', 'Height',
                                             'IncomeRatio', 'ALT_Enzyme',
                                             'AST_Enzyme', 'GGT_Enzyme',
                                             'Albumin', 'Potassium', 'Sodium'],
                                    transformer=SimpleImputer())),
                ('c...
                               feature_types=None, feature_weights=None,
                               gamma=None, grow_policy=None,
                               importance_type=None,
                               interaction_constraints=None,
                               learning_rate=0.0005, max_bin=None,
                               max_cat_threshold=None, max_cat_to_onehot=None,
                               max_delta_step=None, max_depth=10,
                               max_leaves=None, min_child_weight=1, missing=nan,
                               monotone_constraints=None, multi_strategy=None,
                               n_estimators=300, n_jobs=-1,
                               num_parallel_tree=None, ...))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000017F1B370A60>)
2025-11-29 12:04:44,535:INFO:Checking exceptions
2025-11-29 12:04:44,535:INFO:Preloading libraries
2025-11-29 12:04:44,535:INFO:Set up data.
2025-11-29 12:04:44,538:INFO:Set up index.
2025-11-29 12:31:07,015:INFO:Initializing load_model()
2025-11-29 12:31:07,020:INFO:load_model(model_name=../models/best_pipeline, platform=None, authentication=None, verbose=True)
2025-11-29 12:31:12,746:INFO:Initializing predict_model()
2025-11-29 12:31:12,746:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017F199197B0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Age', 'SystolicBP',
                                             'TotalCholesterol', 'LDL',
                                             'Triglycerides', 'HbA1c',
                                             'Glucose', 'UricAcid',
                                             'Creatinine', 'BMI',
                                             'WaistCircumference', 'Height',
                                             'IncomeRatio', 'ALT_Enzyme',
                                             'AST_Enzyme', 'GGT_Enzyme',
                                             'Albumin', 'Potassium', 'Sodium'],
                                    transformer=SimpleImputer())),
                ('c...
                               feature_types=None, feature_weights=None,
                               gamma=None, grow_policy=None,
                               importance_type=None,
                               interaction_constraints=None,
                               learning_rate=0.0005, max_bin=None,
                               max_cat_threshold=None, max_cat_to_onehot=None,
                               max_delta_step=None, max_depth=10,
                               max_leaves=None, min_child_weight=1, missing=nan,
                               monotone_constraints=None, multi_strategy=None,
                               n_estimators=300, n_jobs=-1,
                               num_parallel_tree=None, ...))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000017F1B370E50>)
2025-11-29 12:31:12,746:INFO:Checking exceptions
2025-11-29 12:31:12,746:INFO:Preloading libraries
2025-11-29 12:31:12,748:INFO:Set up data.
2025-11-29 12:31:12,757:INFO:Set up index.
2025-11-29 12:31:43,603:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-11-29 12:31:43,603:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-11-29 12:31:43,603:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-11-29 12:31:43,603:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-11-29 12:31:47,347:INFO:Initializing load_model()
2025-11-29 12:31:47,347:INFO:load_model(model_name=../models/best_pipeline, platform=None, authentication=None, verbose=True)
2025-11-29 12:31:47,433:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-29 12:31:54,176:INFO:Initializing predict_model()
2025-11-29 12:31:54,177:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000015B4E3BB370>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Age', 'SystolicBP',
                                             'TotalCholesterol', 'LDL',
                                             'Triglycerides', 'HbA1c',
                                             'Glucose', 'UricAcid',
                                             'Creatinine', 'BMI',
                                             'WaistCircumference', 'Height',
                                             'IncomeRatio', 'ALT_Enzyme',
                                             'AST_Enzyme', 'GGT_Enzyme',
                                             'Albumin', 'Potassium', 'Sodium'],
                                    transformer=SimpleImputer())),
                ('c...
                               feature_types=None, feature_weights=None,
                               gamma=None, grow_policy=None,
                               importance_type=None,
                               interaction_constraints=None,
                               learning_rate=0.0005, max_bin=None,
                               max_cat_threshold=None, max_cat_to_onehot=None,
                               max_delta_step=None, max_depth=10,
                               max_leaves=None, min_child_weight=1, missing=nan,
                               monotone_constraints=None, multi_strategy=None,
                               n_estimators=300, n_jobs=-1,
                               num_parallel_tree=None, ...))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000015B4F759900>)
2025-11-29 12:31:54,177:INFO:Checking exceptions
2025-11-29 12:31:54,177:INFO:Preloading libraries
2025-11-29 12:31:54,177:INFO:Set up data.
2025-11-29 12:31:54,181:INFO:Set up index.
2025-11-29 12:38:30,568:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-11-29 12:38:30,569:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-11-29 12:38:30,569:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-11-29 12:38:30,569:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-11-29 13:55:29,461:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-11-29 13:55:29,461:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-11-29 13:55:29,461:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-11-29 13:55:29,461:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-11-29 13:55:32,238:INFO:Initializing load_model()
2025-11-29 13:55:32,239:INFO:load_model(model_name=../models/best_pipeline, platform=None, authentication=None, verbose=True)
2025-11-29 13:55:32,321:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-29 13:55:36,208:INFO:Initializing predict_model()
2025-11-29 13:55:36,208:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A8E62365C0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Age', 'SystolicBP',
                                             'TotalCholesterol', 'LDL',
                                             'Triglycerides', 'HbA1c',
                                             'Glucose', 'UricAcid',
                                             'Creatinine', 'BMI',
                                             'WaistCircumference', 'Height',
                                             'IncomeRatio', 'ALT_Enzyme',
                                             'AST_Enzyme', 'GGT_Enzyme',
                                             'Albumin', 'Potassium', 'Sodium'],
                                    transformer=SimpleImputer())),
                ('c...
                               feature_types=None, feature_weights=None,
                               gamma=None, grow_policy=None,
                               importance_type=None,
                               interaction_constraints=None,
                               learning_rate=0.0005, max_bin=None,
                               max_cat_threshold=None, max_cat_to_onehot=None,
                               max_delta_step=None, max_depth=10,
                               max_leaves=None, min_child_weight=1, missing=nan,
                               monotone_constraints=None, multi_strategy=None,
                               n_estimators=300, n_jobs=-1,
                               num_parallel_tree=None, ...))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002A8E609A560>)
2025-11-29 13:55:36,208:INFO:Checking exceptions
2025-11-29 13:55:36,208:INFO:Preloading libraries
2025-11-29 13:55:36,208:INFO:Set up data.
2025-11-29 13:55:36,222:INFO:Set up index.
2025-11-29 13:55:45,988:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-11-29 13:55:45,991:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-11-29 13:55:45,992:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-11-30 01:49:46,864:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-11-30 01:49:46,865:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-11-30 01:49:46,865:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-11-30 01:49:46,865:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-11-30 01:49:47,369:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2025-11-30 01:51:01,117:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-11-30 01:51:01,118:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-11-30 01:51:01,118:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-11-30 01:51:01,118:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-11-30 01:51:01,991:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2025-11-30 01:51:02,569:INFO:PyCaret ClassificationExperiment
2025-11-30 01:51:02,570:INFO:Logging name: clf-default-name
2025-11-30 01:51:02,570:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-11-30 01:51:02,570:INFO:version 3.0.3
2025-11-30 01:51:02,570:INFO:Initializing setup()
2025-11-30 01:51:02,570:INFO:self.USI: d751
2025-11-30 01:51:02,570:INFO:self._variable_keys: {'target_param', 'X_train', 'y', 'seed', 'X_test', 'pipeline', '_ml_usecase', 'gpu_param', 'y_train', 'exp_id', 'logging_param', 'USI', 'exp_name_log', '_available_plots', 'n_jobs_param', 'data', 'y_test', 'fold_shuffle_param', 'X', 'is_multiclass', 'html_param', 'memory', 'fold_generator', 'fold_groups_param', 'idx', 'fix_imbalance', 'gpu_n_jobs_param', 'log_plots_param'}
2025-11-30 01:51:02,570:INFO:Checking environment
2025-11-30 01:51:02,570:INFO:python_version: 3.10.19
2025-11-30 01:51:02,570:INFO:python_build: ('main', 'Nov  7 2025 00:05:37')
2025-11-30 01:51:02,570:INFO:machine: x86_64
2025-11-30 01:51:02,570:INFO:platform: Linux-6.8.0-x86_64-with-glibc2.39
2025-11-30 01:51:02,571:INFO:Memory: svmem(total=8345706496, available=7554994176, percent=9.5, used=790712320, free=3790553088, active=281694208, inactive=3908857856, buffers=71065600, cached=4005851136, shared=557056, slab=293490688)
2025-11-30 01:51:02,573:INFO:Physical Core: 4
2025-11-30 01:51:02,573:INFO:Logical Core: 4
2025-11-30 01:51:02,573:INFO:Checking libraries
2025-11-30 01:51:02,573:INFO:System:
2025-11-30 01:51:02,573:INFO:    python: 3.10.19 (main, Nov  7 2025, 00:05:37) [GCC 13.3.0]
2025-11-30 01:51:02,573:INFO:executable: /home/jules/.pyenv/versions/3.10.19/bin/python
2025-11-30 01:51:02,574:INFO:   machine: Linux-6.8.0-x86_64-with-glibc2.39
2025-11-30 01:51:02,574:INFO:PyCaret required dependencies:
2025-11-30 01:51:02,581:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-30 01:51:02,691:INFO:                 pip: 25.3
2025-11-30 01:51:02,691:INFO:          setuptools: 79.0.1
2025-11-30 01:51:02,692:INFO:             pycaret: 3.0.3
2025-11-30 01:51:02,692:INFO:             IPython: 8.37.0
2025-11-30 01:51:02,692:INFO:          ipywidgets: 8.1.8
2025-11-30 01:51:02,692:INFO:                tqdm: 4.67.1
2025-11-30 01:51:02,692:INFO:               numpy: 1.23.5
2025-11-30 01:51:02,692:INFO:              pandas: 1.5.3
2025-11-30 01:51:02,692:INFO:              jinja2: 3.1.6
2025-11-30 01:51:02,692:INFO:               scipy: 1.10.1
2025-11-30 01:51:02,692:INFO:              joblib: 1.2.0
2025-11-30 01:51:02,692:INFO:             sklearn: 1.3.2
2025-11-30 01:51:02,692:INFO:                pyod: 2.0.5
2025-11-30 01:51:02,692:INFO:            imblearn: 0.12.4
2025-11-30 01:51:02,692:INFO:   category_encoders: 2.7.0
2025-11-30 01:51:02,692:INFO:            lightgbm: 4.6.0
2025-11-30 01:51:02,692:INFO:               numba: 0.59.0
2025-11-30 01:51:02,692:INFO:            requests: 2.32.5
2025-11-30 01:51:02,692:INFO:          matplotlib: 3.10.7
2025-11-30 01:51:02,692:INFO:          scikitplot: 0.3.7
2025-11-30 01:51:02,692:INFO:         yellowbrick: 1.5
2025-11-30 01:51:02,692:INFO:              plotly: 6.5.0
2025-11-30 01:51:02,692:INFO:    plotly-resampler: Not installed
2025-11-30 01:51:02,692:INFO:             kaleido: 1.2.0
2025-11-30 01:51:02,692:INFO:           schemdraw: 0.15
2025-11-30 01:51:02,692:INFO:         statsmodels: 0.14.5
2025-11-30 01:51:02,692:INFO:              sktime: 0.40.1
2025-11-30 01:51:02,692:INFO:               tbats: 1.1.3
2025-11-30 01:51:02,693:INFO:            pmdarima: 2.1.1
2025-11-30 01:51:02,693:INFO:              psutil: 7.1.3
2025-11-30 01:51:02,693:INFO:          markupsafe: 3.0.3
2025-11-30 01:51:02,693:INFO:             pickle5: Not installed
2025-11-30 01:51:02,693:INFO:         cloudpickle: 3.1.2
2025-11-30 01:51:02,693:INFO:         deprecation: 2.1.0
2025-11-30 01:51:02,693:INFO:              xxhash: 3.6.0
2025-11-30 01:51:02,693:INFO:           wurlitzer: 3.1.1
2025-11-30 01:51:02,693:INFO:PyCaret optional dependencies:
2025-11-30 01:51:03,576:INFO:                shap: 0.48.0
2025-11-30 01:51:03,576:INFO:           interpret: Not installed
2025-11-30 01:51:03,576:INFO:                umap: Not installed
2025-11-30 01:51:03,576:INFO:    pandas_profiling: Not installed
2025-11-30 01:51:03,576:INFO:  explainerdashboard: Not installed
2025-11-30 01:51:03,576:INFO:             autoviz: Not installed
2025-11-30 01:51:03,576:INFO:           fairlearn: 0.9.0
2025-11-30 01:51:03,576:INFO:          deepchecks: Not installed
2025-11-30 01:51:03,577:INFO:             xgboost: 3.1.2
2025-11-30 01:51:03,577:INFO:            catboost: Not installed
2025-11-30 01:51:03,577:INFO:              kmodes: Not installed
2025-11-30 01:51:03,577:INFO:             mlxtend: Not installed
2025-11-30 01:51:03,577:INFO:       statsforecast: Not installed
2025-11-30 01:51:03,577:INFO:        tune_sklearn: Not installed
2025-11-30 01:51:03,577:INFO:                 ray: Not installed
2025-11-30 01:51:03,577:INFO:            hyperopt: Not installed
2025-11-30 01:51:03,577:INFO:              optuna: Not installed
2025-11-30 01:51:03,577:INFO:               skopt: Not installed
2025-11-30 01:51:03,577:INFO:              mlflow: Not installed
2025-11-30 01:51:03,577:INFO:              gradio: Not installed
2025-11-30 01:51:03,577:INFO:             fastapi: 0.122.0
2025-11-30 01:51:03,577:INFO:             uvicorn: 0.38.0
2025-11-30 01:51:03,577:INFO:              m2cgen: Not installed
2025-11-30 01:51:03,577:INFO:           evidently: Not installed
2025-11-30 01:51:03,577:INFO:               fugue: Not installed
2025-11-30 01:51:03,577:INFO:           streamlit: 1.50.0
2025-11-30 01:51:03,577:INFO:             prophet: Not installed
2025-11-30 01:51:03,577:INFO:None
2025-11-30 01:51:03,577:INFO:Set up data.
2025-11-30 01:51:03,597:INFO:Set up train/test split.
2025-11-30 01:51:03,604:INFO:Set up index.
2025-11-30 01:51:03,604:INFO:Set up folding strategy.
2025-11-30 01:51:03,604:INFO:Assigning column types.
2025-11-30 01:51:03,608:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-11-30 01:51:03,683:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-11-30 01:51:03,688:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-11-30 01:51:03,738:INFO:Soft dependency imported: xgboost: 3.1.2
2025-11-30 01:51:03,743:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-30 01:51:03,814:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-11-30 01:51:03,815:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-11-30 01:51:03,854:INFO:Soft dependency imported: xgboost: 3.1.2
2025-11-30 01:51:03,858:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-30 01:51:03,859:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-11-30 01:51:03,931:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-11-30 01:51:03,970:INFO:Soft dependency imported: xgboost: 3.1.2
2025-11-30 01:51:03,974:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-30 01:51:04,045:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-11-30 01:51:04,084:INFO:Soft dependency imported: xgboost: 3.1.2
2025-11-30 01:51:04,088:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-30 01:51:04,088:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-11-30 01:51:04,199:INFO:Soft dependency imported: xgboost: 3.1.2
2025-11-30 01:51:04,202:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-30 01:51:04,313:INFO:Soft dependency imported: xgboost: 3.1.2
2025-11-30 01:51:04,317:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-30 01:51:04,320:INFO:Preparing preprocessing pipeline...
2025-11-30 01:51:04,321:INFO:Set up simple imputation.
2025-11-30 01:51:04,327:INFO:Set up encoding of ordinal features.
2025-11-30 01:51:04,336:INFO:Set up encoding of categorical features.
2025-11-30 01:51:04,336:INFO:Set up removing outliers.
2025-11-30 01:51:04,336:INFO:Set up imbalanced handling.
2025-11-30 01:51:04,336:INFO:Set up feature normalization.
2025-11-30 01:51:04,950:INFO:Finished creating preprocessing pipeline.
2025-11-30 01:51:05,085:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'SystolicBP',
                                             'TotalCholesterol', 'LDL',
                                             'Triglycerides', 'HbA1c',
                                             'Glucose', 'UricAcid',
                                             'Creatinine', 'BMI',
                                             'WaistCircumference', 'Height',
                                             'IncomeRatio', 'ALT_Enzyme',
                                             'AST_Enzyme', 'GGT_Enzyme',
                                             'Albumin', 'Potassium', 'Sodium'],
                                    transform...
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              n_jobs=None,
                                                                              random_state=None,
                                                                              sampling_strategy='auto')))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=RobustScaler(copy=True,
                                                             quantile_range=(25.0,
                                                                             75.0),
                                                             unit_variance=False,
                                                             with_centering=True,
                                                             with_scaling=True)))],
         verbose=False)
2025-11-30 01:51:05,085:INFO:Creating final display dataframe.
2025-11-30 01:51:06,384:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target      HeartDisease
2                   Target type            Binary
3           Original data shape         (437, 27)
4        Transformed data shape         (696, 35)
5   Transformed train set shape         (564, 35)
6    Transformed test set shape         (132, 35)
7              Ordinal features                 5
8              Numeric features                19
9          Categorical features                 7
10     Rows with missing values             88.6%
11                   Preprocess              True
12              Imputation type            simple
13           Numeric imputation              mean
14       Categorical imputation              mode
15     Maximum one-hot encoding                25
16              Encoding method              None
17              Remove outliers              True
18           Outliers threshold              0.05
19                Fix imbalance              True
20         Fix imbalance method             SMOTE
21                    Normalize              True
22             Normalize method            robust
23               Fold Generator   StratifiedKFold
24                  Fold Number                10
25                     CPU Jobs                -1
26                      Use GPU             False
27               Log Experiment             False
28              Experiment Name  clf-default-name
29                          USI              d751
2025-11-30 01:51:06,504:INFO:Soft dependency imported: xgboost: 3.1.2
2025-11-30 01:51:06,508:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-30 01:51:06,614:INFO:Soft dependency imported: xgboost: 3.1.2
2025-11-30 01:51:06,618:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-30 01:51:06,620:INFO:setup() successfully completed in 4.05s...............
2025-11-30 01:51:06,654:INFO:Initializing compare_models()
2025-11-30 01:51:06,654:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fc53b4f3580>, include=['xgboost', 'lightgbm'], fold=None, round=4, cross_validation=True, sort=Recall, n_select=3, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=False, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x7fc53b4f3580>, 'include': ['xgboost', 'lightgbm'], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Recall', 'n_select': 3, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': False, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2025-11-30 01:51:06,654:INFO:Checking exceptions
2025-11-30 01:51:06,661:INFO:Preparing display monitor
2025-11-30 01:51:06,666:INFO:Initializing Extreme Gradient Boosting
2025-11-30 01:51:06,666:INFO:Total runtime is 2.658367156982422e-06 minutes
2025-11-30 01:51:06,666:INFO:SubProcess create_model() called ==================================
2025-11-30 01:51:06,667:INFO:Initializing create_model()
2025-11-30 01:51:06,667:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fc53b4f3580>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc53b1fb2e0>, model_only=True, return_train_score=False, kwargs={})
2025-11-30 01:51:06,667:INFO:Checking exceptions
2025-11-30 01:51:06,667:INFO:Importing libraries
2025-11-30 01:51:06,667:INFO:Copying training dataset
2025-11-30 01:51:06,673:INFO:Defining folds
2025-11-30 01:51:06,673:INFO:Declaring metric variables
2025-11-30 01:51:06,673:INFO:Importing untrained model
2025-11-30 01:51:06,674:INFO:Extreme Gradient Boosting Imported successfully
2025-11-30 01:51:06,675:INFO:Starting cross validation
2025-11-30 01:51:06,705:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-30 01:51:06,750:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 7 members, which is less than n_splits=10.
  warnings.warn(

2025-11-30 01:51:11,019:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-30 01:51:11,039:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-30 01:51:11,059:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-30 01:51:11,397:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-30 01:51:12,752:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-11-30 01:51:13,792:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 401, in _score
    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 214, in wrapper
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 627, in roc_auc_score
    return _average_binary_score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-11-30 01:51:13,795:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-11-30 01:51:13,798:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-11-30 01:51:13,801:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1760: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2025-11-30 01:51:13,803:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:697: RuntimeWarning: invalid value encountered in double_scalars
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-30 01:51:13,837:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 401, in _score
    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 214, in wrapper
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 627, in roc_auc_score
    return _average_binary_score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-11-30 01:51:13,843:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-11-30 01:51:13,901:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 401, in _score
    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 214, in wrapper
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 627, in roc_auc_score
    return _average_binary_score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-11-30 01:51:13,907:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-11-30 01:51:14,115:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-11-30 01:51:14,299:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:425: FitFailedWarning:
3 fits failed out of a total of 10.
The score on these train-test partitions for these parameters will be set to 0.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
3 fits failed with the following error:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/model_selection/_validation.py", line 729, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 255, in fit
    X, y, _ = self._fit(X, y, **fit_params_steps)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 238, in _fit
    X, y = self._memory_transform(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/joblib/memory.py", line 594, in __call__
    return self._cached_call(args, kwargs)[0]
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/memory.py", line 398, in _cached_call
    out, metadata = self.call(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/memory.py", line 309, in call
    output = self.func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 77, in _transform_one
    output = transformer.transform(*args)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 157, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 259, in transform
    output = self.transformer.transform(*args)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 157, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 546, in transform
    X, y = self.estimator.fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/base.py", line 208, in fit_resample
    return super().fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/base.py", line 112, in fit_resample
    output = self._fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/over_sampling/_smote/base.py", line 389, in _fit_resample
    nns = self.nn_k_.kneighbors(X_class, return_distance=False)[:, 1:]
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/neighbors/_base.py", line 808, in kneighbors
    raise ValueError(
ValueError: Expected n_neighbors <= n_samples,  but n_samples = 5, n_neighbors = 6

  warnings.warn(some_fits_failed_message, FitFailedWarning)

2025-11-30 01:51:14,301:INFO:Calculating mean and std
2025-11-30 01:51:14,302:INFO:Creating metrics dataframe
2025-11-30 01:51:14,313:INFO:Uploading results into container
2025-11-30 01:51:14,315:INFO:Uploading model into container now
2025-11-30 01:51:14,315:INFO:_master_model_container: 1
2025-11-30 01:51:14,315:INFO:_display_container: 2
2025-11-30 01:51:14,317:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              feature_weights=None, gamma=None, grow_policy=None,
              importance_type=None, interaction_constraints=None,
              learning_rate=None, max_bin=None, max_cat_threshold=None,
              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,
              max_leaves=None, min_child_weight=None, missing=nan,
              monotone_constraints=None, multi_strategy=None, n_estimators=None,
              n_jobs=-1, num_parallel_tree=None, ...)
2025-11-30 01:51:14,317:INFO:create_model() successfully completed......................................
2025-11-30 01:51:14,504:INFO:SubProcess create_model() end ==================================
2025-11-30 01:51:14,505:INFO:Creating metrics dataframe
2025-11-30 01:51:14,512:INFO:Initializing Light Gradient Boosting Machine
2025-11-30 01:51:14,513:INFO:Total runtime is 0.13078117767969769 minutes
2025-11-30 01:51:14,513:INFO:SubProcess create_model() called ==================================
2025-11-30 01:51:14,513:INFO:Initializing create_model()
2025-11-30 01:51:14,513:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fc53b4f3580>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc53b1fb2e0>, model_only=True, return_train_score=False, kwargs={})
2025-11-30 01:51:14,514:INFO:Checking exceptions
2025-11-30 01:51:14,514:INFO:Importing libraries
2025-11-30 01:51:14,514:INFO:Copying training dataset
2025-11-30 01:51:14,519:INFO:Defining folds
2025-11-30 01:51:14,519:INFO:Declaring metric variables
2025-11-30 01:51:14,520:INFO:Importing untrained model
2025-11-30 01:51:14,520:INFO:Light Gradient Boosting Machine Imported successfully
2025-11-30 01:51:14,521:INFO:Starting cross validation
2025-11-30 01:51:14,545:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-30 01:51:14,550:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 7 members, which is less than n_splits=10.
  warnings.warn(

2025-11-30 01:52:08,921:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.70s to run.
If this happens often in your code, it can cause performance problems
(results will be correct in all cases).
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2025-11-30 01:53:00,189:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.71s to run.
If this happens often in your code, it can cause performance problems
(results will be correct in all cases).
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2025-11-30 01:53:00,351:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 401, in _score
    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 214, in wrapper
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 627, in roc_auc_score
    return _average_binary_score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-11-30 01:53:00,354:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-11-30 01:53:00,374:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-11-30 01:53:00,377:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1760: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2025-11-30 01:53:00,387:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:697: RuntimeWarning: invalid value encountered in double_scalars
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-30 01:53:12,301:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.74s to run.
If this happens often in your code, it can cause performance problems
(results will be correct in all cases).
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2025-11-30 01:54:22,153:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.80s to run.
If this happens often in your code, it can cause performance problems
(results will be correct in all cases).
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2025-11-30 01:54:28,976:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 401, in _score
    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 214, in wrapper
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 627, in roc_auc_score
    return _average_binary_score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-11-30 01:54:28,982:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-11-30 01:54:28,985:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-11-30 01:54:28,988:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1760: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2025-11-30 01:54:28,990:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:697: RuntimeWarning: invalid value encountered in double_scalars
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-30 01:55:18,956:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 401, in _score
    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 214, in wrapper
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 627, in roc_auc_score
    return _average_binary_score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-11-30 01:55:18,959:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-11-30 01:55:18,962:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-11-30 01:55:18,965:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1760: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2025-11-30 01:55:18,967:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:697: RuntimeWarning: invalid value encountered in double_scalars
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-30 01:55:18,997:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-11-30 01:55:19,005:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:425: FitFailedWarning:
3 fits failed out of a total of 10.
The score on these train-test partitions for these parameters will be set to 0.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
3 fits failed with the following error:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/model_selection/_validation.py", line 729, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 255, in fit
    X, y, _ = self._fit(X, y, **fit_params_steps)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 238, in _fit
    X, y = self._memory_transform(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/joblib/memory.py", line 594, in __call__
    return self._cached_call(args, kwargs)[0]
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/memory.py", line 398, in _cached_call
    out, metadata = self.call(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/memory.py", line 309, in call
    output = self.func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 77, in _transform_one
    output = transformer.transform(*args)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 157, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 259, in transform
    output = self.transformer.transform(*args)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 157, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 546, in transform
    X, y = self.estimator.fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/base.py", line 208, in fit_resample
    return super().fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/base.py", line 112, in fit_resample
    output = self._fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/over_sampling/_smote/base.py", line 389, in _fit_resample
    nns = self.nn_k_.kneighbors(X_class, return_distance=False)[:, 1:]
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/neighbors/_base.py", line 808, in kneighbors
    raise ValueError(
ValueError: Expected n_neighbors <= n_samples,  but n_samples = 5, n_neighbors = 6

  warnings.warn(some_fits_failed_message, FitFailedWarning)

2025-11-30 01:55:19,007:INFO:Calculating mean and std
2025-11-30 01:55:19,007:INFO:Creating metrics dataframe
2025-11-30 01:55:19,020:INFO:Uploading results into container
2025-11-30 01:55:19,021:INFO:Uploading model into container now
2025-11-30 01:55:19,021:INFO:_master_model_container: 2
2025-11-30 01:55:19,021:INFO:_display_container: 2
2025-11-30 01:55:19,022:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-11-30 01:55:19,022:INFO:create_model() successfully completed......................................
2025-11-30 01:55:19,168:INFO:SubProcess create_model() end ==================================
2025-11-30 01:55:19,168:INFO:Creating metrics dataframe
2025-11-30 01:55:19,179:INFO:Initializing create_model()
2025-11-30 01:55:19,179:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fc53b4f3580>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              feature_weights=None, gamma=None, grow_policy=None,
              importance_type=None, interaction_constraints=None,
              learning_rate=None, max_bin=None, max_cat_threshold=None,
              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,
              max_leaves=None, min_child_weight=None, missing=nan,
              monotone_constraints=None, multi_strategy=None, n_estimators=None,
              n_jobs=-1, num_parallel_tree=None, ...), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2025-11-30 01:55:19,179:INFO:Checking exceptions
2025-11-30 01:55:19,182:INFO:Importing libraries
2025-11-30 01:55:19,182:INFO:Copying training dataset
2025-11-30 01:55:19,186:INFO:Defining folds
2025-11-30 01:55:19,187:INFO:Declaring metric variables
2025-11-30 01:55:19,187:INFO:Importing untrained model
2025-11-30 01:55:19,187:INFO:Declaring custom model
2025-11-30 01:55:19,189:INFO:Extreme Gradient Boosting Imported successfully
2025-11-30 01:55:19,202:INFO:Cross validation set to False
2025-11-30 01:55:19,202:INFO:Fitting Model
2025-11-30 01:55:19,587:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              feature_weights=None, gamma=None, grow_policy=None,
              importance_type=None, interaction_constraints=None,
              learning_rate=None, max_bin=None, max_cat_threshold=None,
              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,
              max_leaves=None, min_child_weight=None, missing=nan,
              monotone_constraints=None, multi_strategy=None, n_estimators=None,
              n_jobs=-1, num_parallel_tree=None, ...)
2025-11-30 01:55:19,587:INFO:create_model() successfully completed......................................
2025-11-30 01:55:19,723:INFO:Initializing create_model()
2025-11-30 01:55:19,723:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fc53b4f3580>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2025-11-30 01:55:19,723:INFO:Checking exceptions
2025-11-30 01:55:19,726:INFO:Importing libraries
2025-11-30 01:55:19,726:INFO:Copying training dataset
2025-11-30 01:55:19,730:INFO:Defining folds
2025-11-30 01:55:19,730:INFO:Declaring metric variables
2025-11-30 01:55:19,730:INFO:Importing untrained model
2025-11-30 01:55:19,730:INFO:Declaring custom model
2025-11-30 01:55:19,732:INFO:Light Gradient Boosting Machine Imported successfully
2025-11-30 01:55:19,745:INFO:Cross validation set to False
2025-11-30 01:55:19,745:INFO:Fitting Model
2025-11-30 01:55:19,953:INFO:[LightGBM] [Info] Number of positive: 282, number of negative: 282
2025-11-30 01:55:19,954:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000364 seconds.
2025-11-30 01:55:19,954:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-11-30 01:55:19,956:INFO:[LightGBM] [Info] Total Bins 3055
2025-11-30 01:55:19,960:INFO:[LightGBM] [Info] Number of data points in the train set: 564, number of used features: 33
2025-11-30 01:55:19,961:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-11-30 01:55:19,961:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-30 01:55:19,962:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-30 01:55:19,962:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-30 01:55:19,963:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-30 01:55:19,964:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-30 01:55:19,965:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-30 01:55:19,966:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-30 01:55:19,966:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-30 01:55:19,967:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-30 01:55:19,968:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-30 01:55:19,969:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-30 01:55:19,969:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-30 01:55:19,970:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-30 01:55:19,971:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-30 01:55:19,972:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-30 01:55:19,973:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-30 01:55:19,974:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-30 01:55:19,974:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-30 01:55:19,975:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-30 01:55:19,976:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-30 01:55:19,977:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-30 01:55:19,978:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-30 01:55:19,979:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-30 01:55:19,979:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-30 01:55:19,980:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-30 01:55:19,981:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-30 01:55:19,982:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-30 01:55:19,983:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-30 01:55:19,984:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-30 01:55:19,984:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-30 01:55:19,985:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-30 01:55:19,986:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-30 01:55:19,987:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-30 01:55:19,988:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-30 01:55:19,989:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-30 01:55:19,990:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-30 01:55:19,991:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-30 01:55:19,991:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-30 01:55:19,992:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-30 01:55:19,993:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-30 01:55:19,994:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-30 01:55:19,995:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-30 01:55:19,996:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-30 01:55:19,997:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-30 01:55:19,998:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-30 01:55:19,999:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-30 01:55:20,000:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-30 01:55:20,001:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-30 01:55:20,001:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-30 01:55:20,002:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-30 01:55:20,003:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-30 01:55:20,004:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-30 01:55:20,005:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-30 01:55:20,006:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-30 01:55:20,007:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-30 01:55:20,008:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-30 01:55:20,009:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-30 01:55:20,010:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-30 01:55:20,011:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-30 01:55:20,012:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-30 01:55:20,013:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-30 01:55:20,013:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-30 01:55:20,014:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-30 01:55:20,015:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-30 01:55:20,016:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-30 01:55:20,017:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-30 01:55:20,018:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-30 01:55:20,019:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-30 01:55:20,020:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-30 01:55:20,021:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-30 01:55:20,023:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-30 01:55:20,024:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-30 01:55:20,025:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-30 01:55:20,026:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-30 01:55:20,027:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-30 01:55:20,028:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-30 01:55:20,030:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-30 01:55:20,031:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-30 01:55:20,032:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-30 01:55:20,033:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-30 01:55:20,034:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-30 01:55:20,035:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-30 01:55:20,036:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-30 01:55:20,037:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-30 01:55:20,038:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-30 01:55:20,039:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-30 01:55:20,040:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-30 01:55:20,041:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-30 01:55:20,042:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-30 01:55:20,043:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-30 01:55:20,044:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-30 01:55:20,045:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-30 01:55:20,046:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-30 01:55:20,047:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-30 01:55:20,047:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-30 01:55:20,048:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-30 01:55:20,049:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-30 01:55:20,096:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-11-30 01:55:20,096:INFO:create_model() successfully completed......................................
2025-11-30 01:55:20,231:INFO:_master_model_container: 2
2025-11-30 01:55:20,231:INFO:_display_container: 2
2025-11-30 01:55:20,233:INFO:[XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              feature_weights=None, gamma=None, grow_policy=None,
              importance_type=None, interaction_constraints=None,
              learning_rate=None, max_bin=None, max_cat_threshold=None,
              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,
              max_leaves=None, min_child_weight=None, missing=nan,
              monotone_constraints=None, multi_strategy=None, n_estimators=None,
              n_jobs=-1, num_parallel_tree=None, ...), LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)]
2025-11-30 01:55:20,233:INFO:compare_models() successfully completed......................................
2025-11-30 01:55:20,275:INFO:Initializing tune_model()
2025-11-30 01:55:20,276:INFO:tune_model(estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              feature_weights=None, gamma=None, grow_policy=None,
              importance_type=None, interaction_constraints=None,
              learning_rate=None, max_bin=None, max_cat_threshold=None,
              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,
              max_leaves=None, min_child_weight=None, missing=nan,
              monotone_constraints=None, multi_strategy=None, n_estimators=None,
              n_jobs=-1, num_parallel_tree=None, ...), fold=None, round=4, n_iter=2, custom_grid=None, optimize=Recall, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=False, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fc53b4f3580>)
2025-11-30 01:55:20,276:INFO:Checking exceptions
2025-11-30 01:55:20,281:INFO:Copying training dataset
2025-11-30 01:55:20,285:INFO:Checking base model
2025-11-30 01:55:20,285:INFO:Base model : Extreme Gradient Boosting
2025-11-30 01:55:20,286:INFO:Declaring metric variables
2025-11-30 01:55:20,286:INFO:Defining Hyperparameters
2025-11-30 01:55:20,438:INFO:Tuning with n_jobs=-1
2025-11-30 01:55:20,438:INFO:Initializing RandomizedSearchCV
2025-11-30 01:55:20,448:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 7 members, which is less than n_splits=10.
  warnings.warn(

2025-11-30 01:55:21,169:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-11-30 01:55:21,180:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-11-30 01:55:21,204:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-11-30 01:55:21,730:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-11-30 01:55:21,739:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-11-30 01:55:22,065:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-11-30 01:55:22,084:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:425: FitFailedWarning:
6 fits failed out of a total of 20.
The score on these train-test partitions for these parameters will be set to nan.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
6 fits failed with the following error:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/model_selection/_validation.py", line 729, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 255, in fit
    X, y, _ = self._fit(X, y, **fit_params_steps)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 238, in _fit
    X, y = self._memory_transform(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/joblib/memory.py", line 594, in __call__
    return self._cached_call(args, kwargs)[0]
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/memory.py", line 398, in _cached_call
    out, metadata = self.call(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/memory.py", line 309, in call
    output = self.func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 77, in _transform_one
    output = transformer.transform(*args)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 157, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 259, in transform
    output = self.transformer.transform(*args)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 157, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 546, in transform
    X, y = self.estimator.fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/base.py", line 208, in fit_resample
    return super().fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/base.py", line 112, in fit_resample
    output = self._fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/over_sampling/_smote/base.py", line 389, in _fit_resample
    nns = self.nn_k_.kneighbors(X_class, return_distance=False)[:, 1:]
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/neighbors/_base.py", line 808, in kneighbors
    raise ValueError(
ValueError: Expected n_neighbors <= n_samples,  but n_samples = 5, n_neighbors = 6

  warnings.warn(some_fits_failed_message, FitFailedWarning)

2025-11-30 01:55:22,086:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/model_selection/_search.py:979: UserWarning: One or more of the test scores are non-finite: [nan nan]
  warnings.warn(

2025-11-30 01:55:22,097:INFO:best_params: {'actual_estimator__subsample': 1, 'actual_estimator__scale_pos_weight': 8.5, 'actual_estimator__reg_lambda': 0.0005, 'actual_estimator__reg_alpha': 0.001, 'actual_estimator__n_estimators': 10, 'actual_estimator__min_child_weight': 3, 'actual_estimator__max_depth': 8, 'actual_estimator__learning_rate': 0.0001, 'actual_estimator__colsample_bytree': 0.7}
2025-11-30 01:55:22,097:INFO:Hyperparameter search completed
2025-11-30 01:55:22,097:INFO:SubProcess create_model() called ==================================
2025-11-30 01:55:22,099:INFO:Initializing create_model()
2025-11-30 01:55:22,099:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fc53b4f3580>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              feature_weights=None, gamma=None, grow_policy=None,
              importance_type=None, interaction_constraints=None,
              learning_rate=None, max_bin=None, max_cat_threshold=None,
              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,
              max_leaves=None, min_child_weight=None, missing=nan,
              monotone_constraints=None, multi_strategy=None, n_estimators=None,
              n_jobs=-1, num_parallel_tree=None, ...), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc4f2406290>, model_only=True, return_train_score=False, kwargs={'subsample': 1, 'scale_pos_weight': 8.5, 'reg_lambda': 0.0005, 'reg_alpha': 0.001, 'n_estimators': 10, 'min_child_weight': 3, 'max_depth': 8, 'learning_rate': 0.0001, 'colsample_bytree': 0.7})
2025-11-30 01:55:22,099:INFO:Checking exceptions
2025-11-30 01:55:22,099:INFO:Importing libraries
2025-11-30 01:55:22,099:INFO:Copying training dataset
2025-11-30 01:55:22,105:INFO:Defining folds
2025-11-30 01:55:22,105:INFO:Declaring metric variables
2025-11-30 01:55:22,105:INFO:Importing untrained model
2025-11-30 01:55:22,106:INFO:Declaring custom model
2025-11-30 01:55:22,108:INFO:Extreme Gradient Boosting Imported successfully
2025-11-30 01:55:22,108:INFO:Starting cross validation
2025-11-30 01:55:22,128:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-30 01:55:22,133:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 7 members, which is less than n_splits=10.
  warnings.warn(

2025-11-30 01:55:22,954:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 401, in _score
    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 214, in wrapper
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 627, in roc_auc_score
    return _average_binary_score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-11-30 01:55:22,957:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-11-30 01:55:23,050:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 401, in _score
    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 214, in wrapper
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 627, in roc_auc_score
    return _average_binary_score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-11-30 01:55:23,053:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-11-30 01:55:23,055:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 401, in _score
    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 214, in wrapper
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 627, in roc_auc_score
    return _average_binary_score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-11-30 01:55:23,058:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-11-30 01:55:23,135:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:425: FitFailedWarning:
3 fits failed out of a total of 10.
The score on these train-test partitions for these parameters will be set to 0.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
3 fits failed with the following error:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/model_selection/_validation.py", line 729, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 255, in fit
    X, y, _ = self._fit(X, y, **fit_params_steps)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 238, in _fit
    X, y = self._memory_transform(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/joblib/memory.py", line 594, in __call__
    return self._cached_call(args, kwargs)[0]
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/memory.py", line 398, in _cached_call
    out, metadata = self.call(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/memory.py", line 309, in call
    output = self.func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 77, in _transform_one
    output = transformer.transform(*args)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 157, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 259, in transform
    output = self.transformer.transform(*args)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 157, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 546, in transform
    X, y = self.estimator.fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/base.py", line 208, in fit_resample
    return super().fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/base.py", line 112, in fit_resample
    output = self._fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/over_sampling/_smote/base.py", line 389, in _fit_resample
    nns = self.nn_k_.kneighbors(X_class, return_distance=False)[:, 1:]
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/neighbors/_base.py", line 808, in kneighbors
    raise ValueError(
ValueError: Expected n_neighbors <= n_samples,  but n_samples = 5, n_neighbors = 6

  warnings.warn(some_fits_failed_message, FitFailedWarning)

2025-11-30 01:55:23,138:INFO:Calculating mean and std
2025-11-30 01:55:23,139:INFO:Creating metrics dataframe
2025-11-30 01:55:23,142:INFO:Finalizing model
2025-11-30 01:55:23,388:INFO:Uploading results into container
2025-11-30 01:55:23,389:INFO:Uploading model into container now
2025-11-30 01:55:23,390:INFO:_master_model_container: 3
2025-11-30 01:55:23,390:INFO:_display_container: 3
2025-11-30 01:55:23,391:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=0.7, device=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              feature_weights=None, gamma=None, grow_policy=None,
              importance_type=None, interaction_constraints=None,
              learning_rate=0.0001, max_bin=None, max_cat_threshold=None,
              max_cat_to_onehot=None, max_delta_step=None, max_depth=8,
              max_leaves=None, min_child_weight=3, missing=nan,
              monotone_constraints=None, multi_strategy=None, n_estimators=10,
              n_jobs=-1, num_parallel_tree=None, ...)
2025-11-30 01:55:23,391:INFO:create_model() successfully completed......................................
2025-11-30 01:55:23,529:INFO:SubProcess create_model() end ==================================
2025-11-30 01:55:23,529:INFO:choose_better activated
2025-11-30 01:55:23,529:INFO:SubProcess create_model() called ==================================
2025-11-30 01:55:23,531:INFO:Initializing create_model()
2025-11-30 01:55:23,531:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fc53b4f3580>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              feature_weights=None, gamma=None, grow_policy=None,
              importance_type=None, interaction_constraints=None,
              learning_rate=None, max_bin=None, max_cat_threshold=None,
              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,
              max_leaves=None, min_child_weight=None, missing=nan,
              monotone_constraints=None, multi_strategy=None, n_estimators=None,
              n_jobs=-1, num_parallel_tree=None, ...), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2025-11-30 01:55:23,531:INFO:Checking exceptions
2025-11-30 01:55:23,534:INFO:Importing libraries
2025-11-30 01:55:23,534:INFO:Copying training dataset
2025-11-30 01:55:23,539:INFO:Defining folds
2025-11-30 01:55:23,539:INFO:Declaring metric variables
2025-11-30 01:55:23,539:INFO:Importing untrained model
2025-11-30 01:55:23,539:INFO:Declaring custom model
2025-11-30 01:55:23,541:INFO:Extreme Gradient Boosting Imported successfully
2025-11-30 01:55:23,541:INFO:Starting cross validation
2025-11-30 01:55:23,555:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-30 01:55:23,559:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 7 members, which is less than n_splits=10.
  warnings.warn(

2025-11-30 01:55:24,065:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-11-30 01:55:24,420:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 401, in _score
    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 214, in wrapper
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 627, in roc_auc_score
    return _average_binary_score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-11-30 01:55:24,423:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-11-30 01:55:24,426:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-11-30 01:55:24,429:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1760: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2025-11-30 01:55:24,430:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:697: RuntimeWarning: invalid value encountered in double_scalars
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-30 01:55:24,548:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 401, in _score
    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 214, in wrapper
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 627, in roc_auc_score
    return _average_binary_score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-11-30 01:55:24,551:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-11-30 01:55:24,563:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 401, in _score
    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 214, in wrapper
    return func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 627, in roc_auc_score
    return _average_binary_score(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-11-30 01:55:24,567:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-11-30 01:55:24,569:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-11-30 01:55:24,572:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1760: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2025-11-30 01:55:24,574:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:697: RuntimeWarning: invalid value encountered in double_scalars
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-30 01:55:24,772:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-11-30 01:55:24,781:WARNING:/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:425: FitFailedWarning:
3 fits failed out of a total of 10.
The score on these train-test partitions for these parameters will be set to 0.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
3 fits failed with the following error:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/model_selection/_validation.py", line 729, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 255, in fit
    X, y, _ = self._fit(X, y, **fit_params_steps)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 238, in _fit
    X, y = self._memory_transform(
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/joblib/memory.py", line 594, in __call__
    return self._cached_call(args, kwargs)[0]
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/memory.py", line 398, in _cached_call
    out, metadata = self.call(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/memory.py", line 309, in call
    output = self.func(*args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 77, in _transform_one
    output = transformer.transform(*args)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 157, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 259, in transform
    output = self.transformer.transform(*args)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 157, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/pycaret/internal/preprocess/transformers.py", line 546, in transform
    X, y = self.estimator.fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/base.py", line 208, in fit_resample
    return super().fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/base.py", line 112, in fit_resample
    output = self._fit_resample(X, y)
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/imblearn/over_sampling/_smote/base.py", line 389, in _fit_resample
    nns = self.nn_k_.kneighbors(X_class, return_distance=False)[:, 1:]
  File "/home/jules/.pyenv/versions/3.10.19/lib/python3.10/site-packages/sklearn/neighbors/_base.py", line 808, in kneighbors
    raise ValueError(
ValueError: Expected n_neighbors <= n_samples,  but n_samples = 5, n_neighbors = 6

  warnings.warn(some_fits_failed_message, FitFailedWarning)

2025-11-30 01:55:24,783:INFO:Calculating mean and std
2025-11-30 01:55:24,783:INFO:Creating metrics dataframe
2025-11-30 01:55:24,787:INFO:Finalizing model
2025-11-30 01:55:25,043:INFO:Uploading results into container
2025-11-30 01:55:25,043:INFO:Uploading model into container now
2025-11-30 01:55:25,044:INFO:_master_model_container: 4
2025-11-30 01:55:25,044:INFO:_display_container: 4
2025-11-30 01:55:25,045:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              feature_weights=None, gamma=None, grow_policy=None,
              importance_type=None, interaction_constraints=None,
              learning_rate=None, max_bin=None, max_cat_threshold=None,
              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,
              max_leaves=None, min_child_weight=None, missing=nan,
              monotone_constraints=None, multi_strategy=None, n_estimators=None,
              n_jobs=-1, num_parallel_tree=None, ...)
2025-11-30 01:55:25,045:INFO:create_model() successfully completed......................................
2025-11-30 01:55:25,179:INFO:SubProcess create_model() end ==================================
2025-11-30 01:55:25,181:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              feature_weights=None, gamma=None, grow_policy=None,
              importance_type=None, interaction_constraints=None,
              learning_rate=None, max_bin=None, max_cat_threshold=None,
              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,
              max_leaves=None, min_child_weight=None, missing=nan,
              monotone_constraints=None, multi_strategy=None, n_estimators=None,
              n_jobs=-1, num_parallel_tree=None, ...) result for Recall is 0.0
2025-11-30 01:55:25,182:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=0.7, device=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              feature_weights=None, gamma=None, grow_policy=None,
              importance_type=None, interaction_constraints=None,
              learning_rate=0.0001, max_bin=None, max_cat_threshold=None,
              max_cat_to_onehot=None, max_delta_step=None, max_depth=8,
              max_leaves=None, min_child_weight=3, missing=nan,
              monotone_constraints=None, multi_strategy=None, n_estimators=10,
              n_jobs=-1, num_parallel_tree=None, ...) result for Recall is 0.4
2025-11-30 01:55:25,183:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=0.7, device=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              feature_weights=None, gamma=None, grow_policy=None,
              importance_type=None, interaction_constraints=None,
              learning_rate=0.0001, max_bin=None, max_cat_threshold=None,
              max_cat_to_onehot=None, max_delta_step=None, max_depth=8,
              max_leaves=None, min_child_weight=3, missing=nan,
              monotone_constraints=None, multi_strategy=None, n_estimators=10,
              n_jobs=-1, num_parallel_tree=None, ...) is best model
2025-11-30 01:55:25,183:INFO:choose_better completed
2025-11-30 01:55:25,184:INFO:_master_model_container: 4
2025-11-30 01:55:25,184:INFO:_display_container: 3
2025-11-30 01:55:25,185:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=0.7, device=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              feature_weights=None, gamma=None, grow_policy=None,
              importance_type=None, interaction_constraints=None,
              learning_rate=0.0001, max_bin=None, max_cat_threshold=None,
              max_cat_to_onehot=None, max_delta_step=None, max_depth=8,
              max_leaves=None, min_child_weight=3, missing=nan,
              monotone_constraints=None, multi_strategy=None, n_estimators=10,
              n_jobs=-1, num_parallel_tree=None, ...)
2025-11-30 01:55:25,185:INFO:tune_model() successfully completed......................................
2025-11-30 01:55:25,365:INFO:Initializing predict_model()
2025-11-30 01:55:25,365:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fc53b4f3580>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=0.7, device=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              feature_weights=None, gamma=None, grow_policy=None,
              importance_type=None, interaction_constraints=None,
              learning_rate=0.0001, max_bin=None, max_cat_threshold=None,
              max_cat_to_onehot=None, max_delta_step=None, max_depth=8,
              max_leaves=None, min_child_weight=3, missing=nan,
              monotone_constraints=None, multi_strategy=None, n_estimators=10,
              n_jobs=-1, num_parallel_tree=None, ...), probability_threshold=None, encoded_labels=False, raw_score=True, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7fc541dcea70>)
2025-11-30 01:55:25,365:INFO:Checking exceptions
2025-11-30 01:55:25,365:INFO:Preloading libraries
2025-11-30 01:55:25,963:INFO:Initializing get_config()
2025-11-30 01:55:25,963:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fc53b4f3580>, variable=target_param)
2025-11-30 01:55:25,963:INFO:Variable:  returned as HeartDisease
2025-11-30 01:55:25,963:INFO:get_config() successfully completed......................................
2025-11-30 01:55:27,052:INFO:Initializing interpret_model()
2025-11-30 01:55:27,052:INFO:interpret_model(estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=0.7, device=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              feature_weights=None, gamma=None, grow_policy=None,
              importance_type=None, interaction_constraints=None,
              learning_rate=0.0001, max_bin=None, max_cat_threshold=None,
              max_cat_to_onehot=None, max_delta_step=None, max_depth=8,
              max_leaves=None, min_child_weight=3, missing=nan,
              monotone_constraints=None, multi_strategy=None, n_estimators=10,
              n_jobs=-1, num_parallel_tree=None, ...), use_train_data=False, X_new_sample=None, y_new_sample=None, feature=None, kwargs={}, observation=None, plot=summary, save=False, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fc53b4f3580>)
2025-11-30 01:55:27,052:INFO:Checking exceptions
2025-11-30 01:55:27,052:INFO:Soft dependency imported: shap: 0.48.0
2025-11-30 01:55:27,812:INFO:plot type: summary
2025-11-30 01:55:27,812:INFO:Creating TreeExplainer
2025-11-30 01:55:27,851:INFO:Initializing finalize_model()
2025-11-30 01:55:27,851:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fc53b4f3580>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=0.7, device=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              feature_weights=None, gamma=None, grow_policy=None,
              importance_type=None, interaction_constraints=None,
              learning_rate=0.0001, max_bin=None, max_cat_threshold=None,
              max_cat_to_onehot=None, max_delta_step=None, max_depth=8,
              max_leaves=None, min_child_weight=3, missing=nan,
              monotone_constraints=None, multi_strategy=None, n_estimators=10,
              n_jobs=-1, num_parallel_tree=None, ...), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2025-11-30 01:55:27,852:INFO:Finalizing XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=0.7, device=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              feature_weights=None, gamma=None, grow_policy=None,
              importance_type=None, interaction_constraints=None,
              learning_rate=0.0001, max_bin=None, max_cat_threshold=None,
              max_cat_to_onehot=None, max_delta_step=None, max_depth=8,
              max_leaves=None, min_child_weight=3, missing=nan,
              monotone_constraints=None, multi_strategy=None, n_estimators=10,
              n_jobs=-1, num_parallel_tree=None, ...)
2025-11-30 01:55:27,858:INFO:Initializing create_model()
2025-11-30 01:55:27,858:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fc53b4f3580>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=0.7, device=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              feature_weights=None, gamma=None, grow_policy=None,
              importance_type=None, interaction_constraints=None,
              learning_rate=0.0001, max_bin=None, max_cat_threshold=None,
              max_cat_to_onehot=None, max_delta_step=None, max_depth=8,
              max_leaves=None, min_child_weight=3, missing=nan,
              monotone_constraints=None, multi_strategy=None, n_estimators=10,
              n_jobs=-1, num_parallel_tree=None, ...), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2025-11-30 01:55:27,859:INFO:Checking exceptions
2025-11-30 01:55:27,861:INFO:Importing libraries
2025-11-30 01:55:27,861:INFO:Copying training dataset
2025-11-30 01:55:27,861:INFO:Defining folds
2025-11-30 01:55:27,861:INFO:Declaring metric variables
2025-11-30 01:55:27,862:INFO:Importing untrained model
2025-11-30 01:55:27,862:INFO:Declaring custom model
2025-11-30 01:55:27,864:INFO:Extreme Gradient Boosting Imported successfully
2025-11-30 01:55:27,896:INFO:Cross validation set to False
2025-11-30 01:55:27,897:INFO:Fitting Model
2025-11-30 01:55:28,597:INFO:Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'SystolicBP',
                                             'TotalCholesterol', 'LDL',
                                             'Triglycerides', 'HbA1c',
                                             'Glucose', 'UricAcid',
                                             'Creatinine', 'BMI',
                                             'WaistCircumference', 'Height',
                                             'IncomeRatio', 'ALT_Enzyme',
                                             'AST_Enzyme', 'GGT_Enzyme',
                                             'Albumin', 'Potassium', 'Sodium'],
                                    transform...
                               gamma=None, grow_policy=None,
                               importance_type=None,
                               interaction_constraints=None,
                               learning_rate=0.0001, max_bin=None,
                               max_cat_threshold=None, max_cat_to_onehot=None,
                               max_delta_step=None, max_depth=8,
                               max_leaves=None, min_child_weight=3, missing=nan,
                               monotone_constraints=None, multi_strategy=None,
                               n_estimators=10, n_jobs=-1,
                               num_parallel_tree=None, ...))],
         verbose=False)
2025-11-30 01:55:28,597:INFO:create_model() successfully completed......................................
2025-11-30 01:55:28,765:INFO:_master_model_container: 4
2025-11-30 01:55:28,765:INFO:_display_container: 4
2025-11-30 01:55:28,903:INFO:Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'SystolicBP',
                                             'TotalCholesterol', 'LDL',
                                             'Triglycerides', 'HbA1c',
                                             'Glucose', 'UricAcid',
                                             'Creatinine', 'BMI',
                                             'WaistCircumference', 'Height',
                                             'IncomeRatio', 'ALT_Enzyme',
                                             'AST_Enzyme', 'GGT_Enzyme',
                                             'Albumin', 'Potassium', 'Sodium'],
                                    transform...
                               gamma=None, grow_policy=None,
                               importance_type=None,
                               interaction_constraints=None,
                               learning_rate=0.0001, max_bin=None,
                               max_cat_threshold=None, max_cat_to_onehot=None,
                               max_delta_step=None, max_depth=8,
                               max_leaves=None, min_child_weight=3, missing=nan,
                               monotone_constraints=None, multi_strategy=None,
                               n_estimators=10, n_jobs=-1,
                               num_parallel_tree=None, ...))],
         verbose=False)
2025-11-30 01:55:28,903:INFO:finalize_model() successfully completed......................................
2025-11-30 01:55:29,323:INFO:Initializing save_model()
2025-11-30 01:55:29,323:INFO:save_model(model=Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'SystolicBP',
                                             'TotalCholesterol', 'LDL',
                                             'Triglycerides', 'HbA1c',
                                             'Glucose', 'UricAcid',
                                             'Creatinine', 'BMI',
                                             'WaistCircumference', 'Height',
                                             'IncomeRatio', 'ALT_Enzyme',
                                             'AST_Enzyme', 'GGT_Enzyme',
                                             'Albumin', 'Potassium', 'Sodium'],
                                    transform...
                               gamma=None, grow_policy=None,
                               importance_type=None,
                               interaction_constraints=None,
                               learning_rate=0.0001, max_bin=None,
                               max_cat_threshold=None, max_cat_to_onehot=None,
                               max_delta_step=None, max_depth=8,
                               max_leaves=None, min_child_weight=3, missing=nan,
                               monotone_constraints=None, multi_strategy=None,
                               n_estimators=10, n_jobs=-1,
                               num_parallel_tree=None, ...))],
         verbose=False), model_name=../models/best_pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'SystolicBP',
                                             'TotalCholesterol', 'LDL',
                                             'Triglycerides', 'HbA1c',
                                             'Glucose', 'UricAcid',
                                             'Creatinine', 'BMI',
                                             'WaistCircumference', 'Height',
                                             'IncomeRatio', 'ALT_Enzyme',
                                             'AST_Enzyme', 'GGT_Enzyme',
                                             'Albumin', 'Potassium', 'Sodium'],
                                    transform...
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              n_jobs=None,
                                                                              random_state=None,
                                                                              sampling_strategy='auto')))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=RobustScaler(copy=True,
                                                             quantile_range=(25.0,
                                                                             75.0),
                                                             unit_variance=False,
                                                             with_centering=True,
                                                             with_scaling=True)))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2025-11-30 01:55:29,323:INFO:Adding model into prep_pipe
2025-11-30 01:55:29,323:WARNING:Only Model saved as it was a pipeline.
2025-11-30 01:55:29,433:INFO:../models/best_pipeline.pkl saved in current working directory
2025-11-30 01:55:29,571:INFO:Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'SystolicBP',
                                             'TotalCholesterol', 'LDL',
                                             'Triglycerides', 'HbA1c',
                                             'Glucose', 'UricAcid',
                                             'Creatinine', 'BMI',
                                             'WaistCircumference', 'Height',
                                             'IncomeRatio', 'ALT_Enzyme',
                                             'AST_Enzyme', 'GGT_Enzyme',
                                             'Albumin', 'Potassium', 'Sodium'],
                                    transform...
                               gamma=None, grow_policy=None,
                               importance_type=None,
                               interaction_constraints=None,
                               learning_rate=0.0001, max_bin=None,
                               max_cat_threshold=None, max_cat_to_onehot=None,
                               max_delta_step=None, max_depth=8,
                               max_leaves=None, min_child_weight=3, missing=nan,
                               monotone_constraints=None, multi_strategy=None,
                               n_estimators=10, n_jobs=-1,
                               num_parallel_tree=None, ...))],
         verbose=False)
2025-11-30 01:55:29,571:INFO:save_model() successfully completed......................................
2025-12-02 13:04:23,706:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-12-02 13:04:23,706:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-12-02 13:04:23,706:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-12-02 13:04:23,706:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-12-02 13:04:38,147:INFO:PyCaret ClassificationExperiment
2025-12-02 13:04:38,147:INFO:Logging name: clf-default-name
2025-12-02 13:04:38,147:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-12-02 13:04:38,147:INFO:version 3.3.2
2025-12-02 13:04:38,147:INFO:Initializing setup()
2025-12-02 13:04:38,147:INFO:self.USI: a24a
2025-12-02 13:04:38,147:INFO:self._variable_keys: {'is_multiclass', 'fix_imbalance', 'y_test', 'X', 'y_train', 'fold_shuffle_param', 'X_train', 'target_param', 'idx', '_ml_usecase', 'html_param', 'n_jobs_param', '_available_plots', 'memory', 'seed', 'fold_generator', 'gpu_n_jobs_param', 'data', 'log_plots_param', 'fold_groups_param', 'exp_id', 'logging_param', 'pipeline', 'y', 'X_test', 'USI', 'exp_name_log', 'gpu_param'}
2025-12-02 13:04:38,147:INFO:Checking environment
2025-12-02 13:04:38,147:INFO:python_version: 3.10.19
2025-12-02 13:04:38,147:INFO:python_build: ('main', 'Oct 21 2025 16:41:31')
2025-12-02 13:04:38,147:INFO:machine: AMD64
2025-12-02 13:04:38,147:INFO:platform: Windows-10-10.0.26100-SP0
2025-12-02 13:04:38,147:INFO:Memory: svmem(total=16282144768, available=2553122816, percent=84.3, used=13729021952, free=2553122816)
2025-12-02 13:04:38,147:INFO:Physical Core: 6
2025-12-02 13:04:38,147:INFO:Logical Core: 12
2025-12-02 13:04:38,149:INFO:Checking libraries
2025-12-02 13:04:38,149:INFO:System:
2025-12-02 13:04:38,149:INFO:    python: 3.10.19 | packaged by Anaconda, Inc. | (main, Oct 21 2025, 16:41:31) [MSC v.1929 64 bit (AMD64)]
2025-12-02 13:04:38,149:INFO:executable: c:\Users\OMAR\miniconda3\envs\xgb_env\python.exe
2025-12-02 13:04:38,149:INFO:   machine: Windows-10-10.0.26100-SP0
2025-12-02 13:04:38,149:INFO:PyCaret required dependencies:
2025-12-02 13:04:38,151:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-02 13:04:38,946:INFO:                 pip: 25.3
2025-12-02 13:04:38,946:INFO:          setuptools: 80.9.0
2025-12-02 13:04:38,946:INFO:             pycaret: 3.3.2
2025-12-02 13:04:38,946:INFO:             IPython: 8.37.0
2025-12-02 13:04:38,946:INFO:          ipywidgets: 8.1.8
2025-12-02 13:04:38,946:INFO:                tqdm: 4.67.1
2025-12-02 13:04:38,946:INFO:               numpy: 1.26.4
2025-12-02 13:04:38,946:INFO:              pandas: 2.1.4
2025-12-02 13:04:38,946:INFO:              jinja2: 3.1.6
2025-12-02 13:04:38,946:INFO:               scipy: 1.11.4
2025-12-02 13:04:38,949:INFO:              joblib: 1.3.2
2025-12-02 13:04:38,949:INFO:             sklearn: 1.4.2
2025-12-02 13:04:38,949:INFO:                pyod: 2.0.5
2025-12-02 13:04:38,949:INFO:            imblearn: 0.14.0
2025-12-02 13:04:38,949:INFO:   category_encoders: 2.7.0
2025-12-02 13:04:38,949:INFO:            lightgbm: 4.6.0
2025-12-02 13:04:38,949:INFO:               numba: 0.62.1
2025-12-02 13:04:38,949:INFO:            requests: 2.32.5
2025-12-02 13:04:38,949:INFO:          matplotlib: 3.7.5
2025-12-02 13:04:38,949:INFO:          scikitplot: 0.3.7
2025-12-02 13:04:38,949:INFO:         yellowbrick: 1.5
2025-12-02 13:04:38,949:INFO:              plotly: 5.24.1
2025-12-02 13:04:38,949:INFO:    plotly-resampler: Not installed
2025-12-02 13:04:38,949:INFO:             kaleido: 1.2.0
2025-12-02 13:04:38,949:INFO:           schemdraw: 0.15
2025-12-02 13:04:38,949:INFO:         statsmodels: 0.14.5
2025-12-02 13:04:38,949:INFO:              sktime: 0.26.0
2025-12-02 13:04:38,949:INFO:               tbats: 1.1.3
2025-12-02 13:04:38,949:INFO:            pmdarima: 2.0.4
2025-12-02 13:04:38,949:INFO:              psutil: 7.1.3
2025-12-02 13:04:38,949:INFO:          markupsafe: 3.0.3
2025-12-02 13:04:38,949:INFO:             pickle5: Not installed
2025-12-02 13:04:38,949:INFO:         cloudpickle: 3.1.2
2025-12-02 13:04:38,949:INFO:         deprecation: 2.1.0
2025-12-02 13:04:38,949:INFO:              xxhash: 3.6.0
2025-12-02 13:04:38,949:INFO:           wurlitzer: Not installed
2025-12-02 13:04:38,949:INFO:PyCaret optional dependencies:
2025-12-02 13:04:42,471:INFO:                shap: 0.44.1
2025-12-02 13:04:42,471:INFO:           interpret: 0.7.3
2025-12-02 13:04:42,471:INFO:                umap: 0.5.7
2025-12-02 13:04:42,471:INFO:     ydata_profiling: 4.18.0
2025-12-02 13:04:42,471:INFO:  explainerdashboard: 0.5.1
2025-12-02 13:04:42,471:INFO:             autoviz: Not installed
2025-12-02 13:04:42,471:INFO:           fairlearn: 0.7.0
2025-12-02 13:04:42,471:INFO:          deepchecks: Not installed
2025-12-02 13:04:42,471:INFO:             xgboost: 3.1.2
2025-12-02 13:04:42,471:INFO:            catboost: 1.2.8
2025-12-02 13:04:42,471:INFO:              kmodes: 0.12.2
2025-12-02 13:04:42,471:INFO:             mlxtend: 0.23.4
2025-12-02 13:04:42,471:INFO:       statsforecast: 1.5.0
2025-12-02 13:04:42,471:INFO:        tune_sklearn: Not installed
2025-12-02 13:04:42,471:INFO:                 ray: Not installed
2025-12-02 13:04:42,471:INFO:            hyperopt: 0.2.7
2025-12-02 13:04:42,471:INFO:              optuna: 4.6.0
2025-12-02 13:04:42,471:INFO:               skopt: 0.10.2
2025-12-02 13:04:42,471:INFO:              mlflow: 3.6.0
2025-12-02 13:04:42,471:INFO:              gradio: 6.0.1
2025-12-02 13:04:42,471:INFO:             fastapi: 0.123.0
2025-12-02 13:04:42,471:INFO:             uvicorn: 0.38.0
2025-12-02 13:04:42,471:INFO:              m2cgen: 0.10.0
2025-12-02 13:04:42,471:INFO:           evidently: 0.4.40
2025-12-02 13:04:42,471:INFO:               fugue: 0.8.7
2025-12-02 13:04:42,471:INFO:           streamlit: 1.51.0
2025-12-02 13:04:42,471:INFO:             prophet: Not installed
2025-12-02 13:04:42,471:INFO:None
2025-12-02 13:04:42,471:INFO:Set up data.
2025-12-02 13:04:42,473:INFO:Set up folding strategy.
2025-12-02 13:04:42,473:INFO:Set up train/test split.
2025-12-02 13:04:42,480:INFO:Set up index.
2025-12-02 13:04:42,480:INFO:Assigning column types.
2025-12-02 13:04:42,484:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-12-02 13:04:42,508:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-12-02 13:04:42,512:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-02 13:04:42,533:INFO:Soft dependency imported: xgboost: 3.1.2
2025-12-02 13:04:42,533:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-02 13:04:42,668:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-12-02 13:04:42,671:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-02 13:04:42,684:INFO:Soft dependency imported: xgboost: 3.1.2
2025-12-02 13:04:42,689:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-02 13:04:42,690:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-12-02 13:04:42,716:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-02 13:04:42,730:INFO:Soft dependency imported: xgboost: 3.1.2
2025-12-02 13:04:42,732:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-02 13:04:42,757:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-02 13:04:42,772:INFO:Soft dependency imported: xgboost: 3.1.2
2025-12-02 13:04:42,773:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-02 13:04:42,773:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-12-02 13:04:42,814:INFO:Soft dependency imported: xgboost: 3.1.2
2025-12-02 13:04:42,816:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-02 13:04:42,856:INFO:Soft dependency imported: xgboost: 3.1.2
2025-12-02 13:04:42,858:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-02 13:04:42,860:INFO:Preparing preprocessing pipeline...
2025-12-02 13:04:42,862:INFO:Set up simple imputation.
2025-12-02 13:04:42,862:INFO:Set up removing outliers.
2025-12-02 13:04:42,862:INFO:Set up imbalanced handling.
2025-12-02 13:04:42,862:INFO:Set up feature normalization.
2025-12-02 13:04:42,982:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\joblib\externals\loky\backend\context.py:136: UserWarning: Could not find the number of physical cores for the following reason:
[WinError 2] El sistema no puede encontrar el archivo especificado
Returning the number of logical cores instead. You can silence this warning by setting LOKY_MAX_CPU_COUNT to the number of cores you want to use.

2025-12-02 13:04:43,007:INFO:Finished creating preprocessing pipeline.
2025-12-02 13:04:43,014:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\OMAR\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['SEQN', 'Sex', 'Age', 'Race',
                                             'Education', 'IncomeRatio',
                                             'SystolicBP', 'BMI',
                                             'WaistCircumference', 'Height',
                                             'TotalCholesterol',
                                             'Triglycerides', 'LDL', 'HDL',
                                             'HbA1c', 'Glucose', 'Creatinine',
                                             'UricAcid', 'ALT_Enzyme',
                                             '...
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              random_state=42,
                                                                              sampling_strategy='auto')))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=RobustScaler(copy=True,
                                                             quantile_range=(25.0,
                                                                             75.0),
                                                             unit_variance=False,
                                                             with_centering=True,
                                                             with_scaling=True)))],
         verbose=False)
2025-12-02 13:04:43,014:INFO:Creating final display dataframe.
2025-12-02 13:04:43,382:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target      HeartDisease
2                   Target type            Binary
3           Original data shape         (437, 29)
4        Transformed data shape         (698, 29)
5   Transformed train set shape         (566, 29)
6    Transformed test set shape         (132, 29)
7              Numeric features                28
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12              Remove outliers              True
13           Outliers threshold              0.05
14                Fix imbalance              True
15         Fix imbalance method             SMOTE
16                    Normalize              True
17             Normalize method            robust
18               Fold Generator   StratifiedKFold
19                  Fold Number                10
20                     CPU Jobs                -1
21                      Use GPU             False
22               Log Experiment             False
23              Experiment Name  clf-default-name
24                          USI              a24a
2025-12-02 13:04:43,430:INFO:Soft dependency imported: xgboost: 3.1.2
2025-12-02 13:04:43,432:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-02 13:04:43,473:INFO:Soft dependency imported: xgboost: 3.1.2
2025-12-02 13:04:43,473:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-02 13:04:43,473:INFO:setup() successfully completed in 5.34s...............
2025-12-02 13:04:54,796:INFO:Initializing compare_models()
2025-12-02 13:04:54,796:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000217C7B631F0>, include=['xgboost', 'lightgbm'], fold=None, round=4, cross_validation=True, sort=Recall, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=False, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x00000217C7B631F0>, 'include': ['xgboost', 'lightgbm'], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Recall', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': False, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2025-12-02 13:04:54,796:INFO:Checking exceptions
2025-12-02 13:04:54,800:INFO:Preparing display monitor
2025-12-02 13:04:54,801:INFO:Initializing Extreme Gradient Boosting
2025-12-02 13:04:54,803:INFO:Total runtime is 3.465414047241211e-05 minutes
2025-12-02 13:04:54,803:INFO:SubProcess create_model() called ==================================
2025-12-02 13:04:54,803:INFO:Initializing create_model()
2025-12-02 13:04:54,803:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000217C7B631F0>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000217C7B63040>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-02 13:04:54,803:INFO:Checking exceptions
2025-12-02 13:04:54,803:INFO:Importing libraries
2025-12-02 13:04:54,803:INFO:Copying training dataset
2025-12-02 13:04:54,806:INFO:Defining folds
2025-12-02 13:04:54,808:INFO:Declaring metric variables
2025-12-02 13:04:54,808:INFO:Importing untrained model
2025-12-02 13:04:54,808:INFO:Extreme Gradient Boosting Imported successfully
2025-12-02 13:04:54,808:INFO:Starting cross validation
2025-12-02 13:04:54,816:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-02 13:04:54,827:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\model_selection\_split.py:737: UserWarning: The least populated class in y has only 7 members, which is less than n_splits=10.

2025-12-02 13:04:58,214:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-02 13:04:58,224:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-02 13:04:58,224:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-02 13:04:58,224:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-02 13:04:58,229:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-02 13:04:58,232:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-02 13:04:58,232:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-02 13:04:58,232:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-02 13:04:58,240:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-02 13:04:58,247:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-02 13:04:59,632:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-12-02 13:04:59,632:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-12-02 13:04:59,636:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-02 13:04:59,636:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-02 13:04:59,636:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-02 13:04:59,653:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-12-02 13:04:59,656:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-02 13:04:59,658:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-02 13:04:59,659:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-02 13:04:59,660:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-12-02 13:04:59,660:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-12-02 13:04:59,661:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-12-02 13:04:59,664:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\model_selection\_validation.py:547: FitFailedWarning: 
2 fits failed out of a total of 10.
The score on these train-test partitions for these parameters will be set to 0.0.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
2 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pipeline.py", line 256, in _fit
    X, y = self._memory_transform(
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pipeline.py", line 80, in _transform_one
    output = transformer.transform(*args)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 255, in transform
    output = self.transformer.transform(*args)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 536, in transform
    X, y = self.estimator.fit_resample(X, y)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\imblearn\base.py", line 202, in fit_resample
    return super().fit_resample(X, y, **params)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\base.py", line 1474, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\imblearn\base.py", line 105, in fit_resample
    output = self._fit_resample(X, y, **params)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\imblearn\over_sampling\_smote\base.py", line 359, in _fit_resample
    nns = self.nn_k_.kneighbors(X_class, return_distance=False)[:, 1:]
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\neighbors\_base.py", line 835, in kneighbors
    raise ValueError(
ValueError: Expected n_neighbors <= n_samples_fit, but n_neighbors = 6, n_samples_fit = 5, n_samples = 5


2025-12-02 13:04:59,665:INFO:Calculating mean and std
2025-12-02 13:04:59,665:INFO:Creating metrics dataframe
2025-12-02 13:04:59,666:INFO:Uploading results into container
2025-12-02 13:04:59,666:INFO:Uploading model into container now
2025-12-02 13:04:59,666:INFO:_master_model_container: 1
2025-12-02 13:04:59,668:INFO:_display_container: 2
2025-12-02 13:04:59,668:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              feature_weights=None, gamma=None, grow_policy=None,
              importance_type=None, interaction_constraints=None,
              learning_rate=None, max_bin=None, max_cat_threshold=None,
              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,
              max_leaves=None, min_child_weight=None, missing=nan,
              monotone_constraints=None, multi_strategy=None, n_estimators=None,
              n_jobs=-1, num_parallel_tree=None, ...)
2025-12-02 13:04:59,668:INFO:create_model() successfully completed......................................
2025-12-02 13:04:59,874:WARNING:create_model() for XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              feature_weights=None, gamma=None, grow_policy=None,
              importance_type=None, interaction_constraints=None,
              learning_rate=None, max_bin=None, max_cat_threshold=None,
              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,
              max_leaves=None, min_child_weight=None, missing=nan,
              monotone_constraints=None, multi_strategy=None, n_estimators=None,
              n_jobs=-1, num_parallel_tree=None, ...) raised an exception or returned all 0.0, trying without fit_kwargs:
2025-12-02 13:04:59,874:WARNING:Traceback (most recent call last):
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 797, in compare_models
    np.sum(
AssertionError

2025-12-02 13:04:59,874:INFO:Initializing create_model()
2025-12-02 13:04:59,879:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000217C7B631F0>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000217C7B63040>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-02 13:04:59,879:INFO:Checking exceptions
2025-12-02 13:04:59,879:INFO:Importing libraries
2025-12-02 13:04:59,879:INFO:Copying training dataset
2025-12-02 13:04:59,882:INFO:Defining folds
2025-12-02 13:04:59,882:INFO:Declaring metric variables
2025-12-02 13:04:59,882:INFO:Importing untrained model
2025-12-02 13:04:59,882:INFO:Extreme Gradient Boosting Imported successfully
2025-12-02 13:04:59,882:INFO:Starting cross validation
2025-12-02 13:04:59,882:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-02 13:04:59,889:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\model_selection\_split.py:737: UserWarning: The least populated class in y has only 7 members, which is less than n_splits=10.

2025-12-02 13:05:00,103:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-12-02 13:05:00,108:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-02 13:05:00,111:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-02 13:05:00,112:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-02 13:05:00,112:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-12-02 13:05:00,114:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-12-02 13:05:00,114:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-12-02 13:05:00,116:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-12-02 13:05:00,116:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-02 13:05:00,116:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-12-02 13:05:00,118:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-02 13:05:00,118:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-02 13:05:01,903:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-02 13:05:01,903:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-02 13:05:02,853:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\model_selection\_validation.py:547: FitFailedWarning: 
2 fits failed out of a total of 10.
The score on these train-test partitions for these parameters will be set to 0.0.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
2 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pipeline.py", line 256, in _fit
    X, y = self._memory_transform(
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pipeline.py", line 80, in _transform_one
    output = transformer.transform(*args)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 255, in transform
    output = self.transformer.transform(*args)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 536, in transform
    X, y = self.estimator.fit_resample(X, y)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\imblearn\base.py", line 202, in fit_resample
    return super().fit_resample(X, y, **params)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\base.py", line 1474, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\imblearn\base.py", line 105, in fit_resample
    output = self._fit_resample(X, y, **params)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\imblearn\over_sampling\_smote\base.py", line 359, in _fit_resample
    nns = self.nn_k_.kneighbors(X_class, return_distance=False)[:, 1:]
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\neighbors\_base.py", line 835, in kneighbors
    raise ValueError(
ValueError: Expected n_neighbors <= n_samples_fit, but n_neighbors = 6, n_samples_fit = 5, n_samples = 5


2025-12-02 13:05:02,853:INFO:Calculating mean and std
2025-12-02 13:05:02,854:INFO:Creating metrics dataframe
2025-12-02 13:05:02,854:INFO:Uploading results into container
2025-12-02 13:05:02,856:INFO:Uploading model into container now
2025-12-02 13:05:02,856:INFO:_master_model_container: 2
2025-12-02 13:05:02,856:INFO:_display_container: 2
2025-12-02 13:05:02,856:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              feature_weights=None, gamma=None, grow_policy=None,
              importance_type=None, interaction_constraints=None,
              learning_rate=None, max_bin=None, max_cat_threshold=None,
              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,
              max_leaves=None, min_child_weight=None, missing=nan,
              monotone_constraints=None, multi_strategy=None, n_estimators=None,
              n_jobs=-1, num_parallel_tree=None, ...)
2025-12-02 13:05:02,856:INFO:create_model() successfully completed......................................
2025-12-02 13:05:03,019:ERROR:create_model() for XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              feature_weights=None, gamma=None, grow_policy=None,
              importance_type=None, interaction_constraints=None,
              learning_rate=None, max_bin=None, max_cat_threshold=None,
              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,
              max_leaves=None, min_child_weight=None, missing=nan,
              monotone_constraints=None, multi_strategy=None, n_estimators=None,
              n_jobs=-1, num_parallel_tree=None, ...) raised an exception or returned all 0.0:
2025-12-02 13:05:03,019:ERROR:Traceback (most recent call last):
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 797, in compare_models
    np.sum(
AssertionError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 818, in compare_models
    np.sum(
AssertionError

2025-12-02 13:05:03,019:INFO:Initializing Light Gradient Boosting Machine
2025-12-02 13:05:03,019:INFO:Total runtime is 0.13696820338567098 minutes
2025-12-02 13:05:03,019:INFO:SubProcess create_model() called ==================================
2025-12-02 13:05:03,019:INFO:Initializing create_model()
2025-12-02 13:05:03,019:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000217C7B631F0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000217C7B63040>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-02 13:05:03,019:INFO:Checking exceptions
2025-12-02 13:05:03,019:INFO:Importing libraries
2025-12-02 13:05:03,019:INFO:Copying training dataset
2025-12-02 13:05:03,022:INFO:Defining folds
2025-12-02 13:05:03,022:INFO:Declaring metric variables
2025-12-02 13:05:03,022:INFO:Importing untrained model
2025-12-02 13:05:03,024:INFO:Light Gradient Boosting Machine Imported successfully
2025-12-02 13:05:03,024:INFO:Starting cross validation
2025-12-02 13:05:03,029:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-02 13:05:03,030:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\model_selection\_split.py:737: UserWarning: The least populated class in y has only 7 members, which is less than n_splits=10.

2025-12-02 13:05:03,506:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-12-02 13:05:03,508:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-02 13:05:03,509:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-02 13:05:03,509:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-12-02 13:05:03,512:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-02 13:05:03,538:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-12-02 13:05:03,540:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-02 13:05:03,570:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-02 13:05:03,618:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-02 13:05:03,634:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\model_selection\_validation.py:547: FitFailedWarning: 
2 fits failed out of a total of 10.
The score on these train-test partitions for these parameters will be set to 0.0.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
2 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pipeline.py", line 256, in _fit
    X, y = self._memory_transform(
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pipeline.py", line 80, in _transform_one
    output = transformer.transform(*args)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 255, in transform
    output = self.transformer.transform(*args)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 536, in transform
    X, y = self.estimator.fit_resample(X, y)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\imblearn\base.py", line 202, in fit_resample
    return super().fit_resample(X, y, **params)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\base.py", line 1474, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\imblearn\base.py", line 105, in fit_resample
    output = self._fit_resample(X, y, **params)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\imblearn\over_sampling\_smote\base.py", line 359, in _fit_resample
    nns = self.nn_k_.kneighbors(X_class, return_distance=False)[:, 1:]
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\neighbors\_base.py", line 835, in kneighbors
    raise ValueError(
ValueError: Expected n_neighbors <= n_samples_fit, but n_neighbors = 6, n_samples_fit = 5, n_samples = 5


2025-12-02 13:05:03,634:INFO:Calculating mean and std
2025-12-02 13:05:03,635:INFO:Creating metrics dataframe
2025-12-02 13:05:03,635:INFO:Uploading results into container
2025-12-02 13:05:03,635:INFO:Uploading model into container now
2025-12-02 13:05:03,635:INFO:_master_model_container: 3
2025-12-02 13:05:03,635:INFO:_display_container: 2
2025-12-02 13:05:03,638:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-12-02 13:05:03,638:INFO:create_model() successfully completed......................................
2025-12-02 13:05:03,818:WARNING:create_model() for LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) raised an exception or returned all 0.0, trying without fit_kwargs:
2025-12-02 13:05:03,818:WARNING:Traceback (most recent call last):
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 797, in compare_models
    np.sum(
AssertionError

2025-12-02 13:05:03,818:INFO:Initializing create_model()
2025-12-02 13:05:03,818:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000217C7B631F0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000217C7B63040>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-02 13:05:03,818:INFO:Checking exceptions
2025-12-02 13:05:03,818:INFO:Importing libraries
2025-12-02 13:05:03,818:INFO:Copying training dataset
2025-12-02 13:05:03,822:INFO:Defining folds
2025-12-02 13:05:03,822:INFO:Declaring metric variables
2025-12-02 13:05:03,822:INFO:Importing untrained model
2025-12-02 13:05:03,822:INFO:Light Gradient Boosting Machine Imported successfully
2025-12-02 13:05:03,822:INFO:Starting cross validation
2025-12-02 13:05:03,827:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-02 13:05:03,829:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\model_selection\_split.py:737: UserWarning: The least populated class in y has only 7 members, which is less than n_splits=10.

2025-12-02 13:05:04,279:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-12-02 13:05:04,281:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-02 13:05:04,297:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-12-02 13:05:04,297:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-02 13:05:04,299:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-02 13:05:04,322:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-12-02 13:05:04,324:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-02 13:05:04,351:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-02 13:05:04,400:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-02 13:05:04,418:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\model_selection\_validation.py:547: FitFailedWarning: 
2 fits failed out of a total of 10.
The score on these train-test partitions for these parameters will be set to 0.0.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
2 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pipeline.py", line 256, in _fit
    X, y = self._memory_transform(
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pipeline.py", line 80, in _transform_one
    output = transformer.transform(*args)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 255, in transform
    output = self.transformer.transform(*args)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 536, in transform
    X, y = self.estimator.fit_resample(X, y)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\imblearn\base.py", line 202, in fit_resample
    return super().fit_resample(X, y, **params)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\base.py", line 1474, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\imblearn\base.py", line 105, in fit_resample
    output = self._fit_resample(X, y, **params)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\imblearn\over_sampling\_smote\base.py", line 359, in _fit_resample
    nns = self.nn_k_.kneighbors(X_class, return_distance=False)[:, 1:]
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\neighbors\_base.py", line 835, in kneighbors
    raise ValueError(
ValueError: Expected n_neighbors <= n_samples_fit, but n_neighbors = 6, n_samples_fit = 5, n_samples = 5


2025-12-02 13:05:04,418:INFO:Calculating mean and std
2025-12-02 13:05:04,418:INFO:Creating metrics dataframe
2025-12-02 13:05:04,420:INFO:Uploading results into container
2025-12-02 13:05:04,421:INFO:Uploading model into container now
2025-12-02 13:05:04,421:INFO:_master_model_container: 4
2025-12-02 13:05:04,421:INFO:_display_container: 2
2025-12-02 13:05:04,421:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-12-02 13:05:04,421:INFO:create_model() successfully completed......................................
2025-12-02 13:05:04,594:ERROR:create_model() for LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) raised an exception or returned all 0.0:
2025-12-02 13:05:04,594:ERROR:Traceback (most recent call last):
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 797, in compare_models
    np.sum(
AssertionError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 818, in compare_models
    np.sum(
AssertionError

2025-12-02 13:05:04,594:INFO:_master_model_container: 4
2025-12-02 13:05:04,594:INFO:_display_container: 2
2025-12-02 13:05:04,594:INFO:[]
2025-12-02 13:05:04,594:INFO:compare_models() successfully completed......................................
2025-12-02 13:05:41,841:INFO:Initializing compare_models()
2025-12-02 13:05:41,841:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000217C7B631F0>, include=['xgboost', 'lightgbm'], fold=None, round=4, cross_validation=True, sort=Recall, n_select=3, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=False, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x00000217C7B631F0>, 'include': ['xgboost', 'lightgbm'], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Recall', 'n_select': 3, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': False, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2025-12-02 13:05:41,841:INFO:Checking exceptions
2025-12-02 13:05:41,844:INFO:Preparing display monitor
2025-12-02 13:05:41,846:INFO:Initializing Extreme Gradient Boosting
2025-12-02 13:05:41,846:INFO:Total runtime is 0.0 minutes
2025-12-02 13:05:41,848:INFO:SubProcess create_model() called ==================================
2025-12-02 13:05:41,848:INFO:Initializing create_model()
2025-12-02 13:05:41,848:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000217C7B631F0>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000217A8C1BB20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-02 13:05:41,848:INFO:Checking exceptions
2025-12-02 13:05:41,848:INFO:Importing libraries
2025-12-02 13:05:41,848:INFO:Copying training dataset
2025-12-02 13:05:41,853:INFO:Defining folds
2025-12-02 13:05:41,853:INFO:Declaring metric variables
2025-12-02 13:05:41,853:INFO:Importing untrained model
2025-12-02 13:05:41,853:INFO:Extreme Gradient Boosting Imported successfully
2025-12-02 13:05:41,853:INFO:Starting cross validation
2025-12-02 13:05:41,860:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-02 13:05:41,862:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\model_selection\_split.py:737: UserWarning: The least populated class in y has only 7 members, which is less than n_splits=10.

2025-12-02 13:05:42,059:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-12-02 13:05:42,060:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-02 13:05:42,066:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-12-02 13:05:42,068:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-02 13:05:42,072:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-02 13:05:42,075:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-12-02 13:05:42,076:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-02 13:05:42,077:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-02 13:05:42,079:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-02 13:05:42,079:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-12-02 13:05:42,079:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-12-02 13:05:42,080:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-12-02 13:05:42,090:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\model_selection\_validation.py:547: FitFailedWarning: 
2 fits failed out of a total of 10.
The score on these train-test partitions for these parameters will be set to 0.0.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
2 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pipeline.py", line 256, in _fit
    X, y = self._memory_transform(
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pipeline.py", line 80, in _transform_one
    output = transformer.transform(*args)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 255, in transform
    output = self.transformer.transform(*args)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 536, in transform
    X, y = self.estimator.fit_resample(X, y)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\imblearn\base.py", line 202, in fit_resample
    return super().fit_resample(X, y, **params)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\base.py", line 1474, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\imblearn\base.py", line 105, in fit_resample
    output = self._fit_resample(X, y, **params)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\imblearn\over_sampling\_smote\base.py", line 359, in _fit_resample
    nns = self.nn_k_.kneighbors(X_class, return_distance=False)[:, 1:]
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\neighbors\_base.py", line 835, in kneighbors
    raise ValueError(
ValueError: Expected n_neighbors <= n_samples_fit, but n_neighbors = 6, n_samples_fit = 5, n_samples = 5


2025-12-02 13:05:42,090:INFO:Calculating mean and std
2025-12-02 13:05:42,090:INFO:Creating metrics dataframe
2025-12-02 13:05:42,090:INFO:Uploading results into container
2025-12-02 13:05:42,090:INFO:Uploading model into container now
2025-12-02 13:05:42,093:INFO:_master_model_container: 5
2025-12-02 13:05:42,093:INFO:_display_container: 3
2025-12-02 13:05:42,093:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              feature_weights=None, gamma=None, grow_policy=None,
              importance_type=None, interaction_constraints=None,
              learning_rate=None, max_bin=None, max_cat_threshold=None,
              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,
              max_leaves=None, min_child_weight=None, missing=nan,
              monotone_constraints=None, multi_strategy=None, n_estimators=None,
              n_jobs=-1, num_parallel_tree=None, ...)
2025-12-02 13:05:42,093:INFO:create_model() successfully completed......................................
2025-12-02 13:05:42,244:WARNING:create_model() for XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              feature_weights=None, gamma=None, grow_policy=None,
              importance_type=None, interaction_constraints=None,
              learning_rate=None, max_bin=None, max_cat_threshold=None,
              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,
              max_leaves=None, min_child_weight=None, missing=nan,
              monotone_constraints=None, multi_strategy=None, n_estimators=None,
              n_jobs=-1, num_parallel_tree=None, ...) raised an exception or returned all 0.0, trying without fit_kwargs:
2025-12-02 13:05:42,244:WARNING:Traceback (most recent call last):
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 797, in compare_models
    np.sum(
AssertionError

2025-12-02 13:05:42,244:INFO:Initializing create_model()
2025-12-02 13:05:42,244:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000217C7B631F0>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000217A8C1BB20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-02 13:05:42,244:INFO:Checking exceptions
2025-12-02 13:05:42,244:INFO:Importing libraries
2025-12-02 13:05:42,244:INFO:Copying training dataset
2025-12-02 13:05:42,244:INFO:Defining folds
2025-12-02 13:05:42,244:INFO:Declaring metric variables
2025-12-02 13:05:42,244:INFO:Importing untrained model
2025-12-02 13:05:42,250:INFO:Extreme Gradient Boosting Imported successfully
2025-12-02 13:05:42,250:INFO:Starting cross validation
2025-12-02 13:05:42,256:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-02 13:05:42,258:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\model_selection\_split.py:737: UserWarning: The least populated class in y has only 7 members, which is less than n_splits=10.

2025-12-02 13:05:42,459:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-12-02 13:05:42,461:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-02 13:05:42,462:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-12-02 13:05:42,462:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-02 13:05:42,462:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-02 13:05:42,462:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-02 13:05:42,466:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-02 13:05:42,466:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-12-02 13:05:42,466:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-12-02 13:05:42,466:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-12-02 13:05:42,471:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-12-02 13:05:42,471:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-02 13:05:42,493:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\model_selection\_validation.py:547: FitFailedWarning: 
2 fits failed out of a total of 10.
The score on these train-test partitions for these parameters will be set to 0.0.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
2 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pipeline.py", line 256, in _fit
    X, y = self._memory_transform(
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pipeline.py", line 80, in _transform_one
    output = transformer.transform(*args)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 255, in transform
    output = self.transformer.transform(*args)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 536, in transform
    X, y = self.estimator.fit_resample(X, y)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\imblearn\base.py", line 202, in fit_resample
    return super().fit_resample(X, y, **params)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\base.py", line 1474, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\imblearn\base.py", line 105, in fit_resample
    output = self._fit_resample(X, y, **params)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\imblearn\over_sampling\_smote\base.py", line 359, in _fit_resample
    nns = self.nn_k_.kneighbors(X_class, return_distance=False)[:, 1:]
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\neighbors\_base.py", line 835, in kneighbors
    raise ValueError(
ValueError: Expected n_neighbors <= n_samples_fit, but n_neighbors = 6, n_samples_fit = 5, n_samples = 5


2025-12-02 13:05:42,494:INFO:Calculating mean and std
2025-12-02 13:05:42,494:INFO:Creating metrics dataframe
2025-12-02 13:05:42,496:INFO:Uploading results into container
2025-12-02 13:05:42,496:INFO:Uploading model into container now
2025-12-02 13:05:42,496:INFO:_master_model_container: 6
2025-12-02 13:05:42,496:INFO:_display_container: 3
2025-12-02 13:05:42,496:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              feature_weights=None, gamma=None, grow_policy=None,
              importance_type=None, interaction_constraints=None,
              learning_rate=None, max_bin=None, max_cat_threshold=None,
              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,
              max_leaves=None, min_child_weight=None, missing=nan,
              monotone_constraints=None, multi_strategy=None, n_estimators=None,
              n_jobs=-1, num_parallel_tree=None, ...)
2025-12-02 13:05:42,496:INFO:create_model() successfully completed......................................
2025-12-02 13:05:42,653:ERROR:create_model() for XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              feature_weights=None, gamma=None, grow_policy=None,
              importance_type=None, interaction_constraints=None,
              learning_rate=None, max_bin=None, max_cat_threshold=None,
              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,
              max_leaves=None, min_child_weight=None, missing=nan,
              monotone_constraints=None, multi_strategy=None, n_estimators=None,
              n_jobs=-1, num_parallel_tree=None, ...) raised an exception or returned all 0.0:
2025-12-02 13:05:42,653:ERROR:Traceback (most recent call last):
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 797, in compare_models
    np.sum(
AssertionError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 818, in compare_models
    np.sum(
AssertionError

2025-12-02 13:05:42,653:INFO:Initializing Light Gradient Boosting Machine
2025-12-02 13:05:42,653:INFO:Total runtime is 0.013455402851104737 minutes
2025-12-02 13:05:42,653:INFO:SubProcess create_model() called ==================================
2025-12-02 13:05:42,653:INFO:Initializing create_model()
2025-12-02 13:05:42,653:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000217C7B631F0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000217A8C1BB20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-02 13:05:42,653:INFO:Checking exceptions
2025-12-02 13:05:42,653:INFO:Importing libraries
2025-12-02 13:05:42,653:INFO:Copying training dataset
2025-12-02 13:05:42,658:INFO:Defining folds
2025-12-02 13:05:42,658:INFO:Declaring metric variables
2025-12-02 13:05:42,658:INFO:Importing untrained model
2025-12-02 13:05:42,658:INFO:Light Gradient Boosting Machine Imported successfully
2025-12-02 13:05:42,660:INFO:Starting cross validation
2025-12-02 13:05:42,662:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-02 13:05:42,666:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\model_selection\_split.py:737: UserWarning: The least populated class in y has only 7 members, which is less than n_splits=10.

2025-12-02 13:05:43,069:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-12-02 13:05:43,071:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-02 13:05:43,084:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-02 13:05:43,086:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-12-02 13:05:43,086:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-02 13:05:43,086:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-02 13:05:43,118:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-12-02 13:05:43,121:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-02 13:05:43,182:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-02 13:05:43,194:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\model_selection\_validation.py:547: FitFailedWarning: 
2 fits failed out of a total of 10.
The score on these train-test partitions for these parameters will be set to 0.0.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
2 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pipeline.py", line 256, in _fit
    X, y = self._memory_transform(
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pipeline.py", line 80, in _transform_one
    output = transformer.transform(*args)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 255, in transform
    output = self.transformer.transform(*args)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 536, in transform
    X, y = self.estimator.fit_resample(X, y)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\imblearn\base.py", line 202, in fit_resample
    return super().fit_resample(X, y, **params)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\base.py", line 1474, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\imblearn\base.py", line 105, in fit_resample
    output = self._fit_resample(X, y, **params)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\imblearn\over_sampling\_smote\base.py", line 359, in _fit_resample
    nns = self.nn_k_.kneighbors(X_class, return_distance=False)[:, 1:]
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\neighbors\_base.py", line 835, in kneighbors
    raise ValueError(
ValueError: Expected n_neighbors <= n_samples_fit, but n_neighbors = 6, n_samples_fit = 5, n_samples = 5


2025-12-02 13:05:43,194:INFO:Calculating mean and std
2025-12-02 13:05:43,194:INFO:Creating metrics dataframe
2025-12-02 13:05:43,196:INFO:Uploading results into container
2025-12-02 13:05:43,196:INFO:Uploading model into container now
2025-12-02 13:05:43,196:INFO:_master_model_container: 7
2025-12-02 13:05:43,196:INFO:_display_container: 3
2025-12-02 13:05:43,196:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-12-02 13:05:43,196:INFO:create_model() successfully completed......................................
2025-12-02 13:05:43,368:WARNING:create_model() for LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) raised an exception or returned all 0.0, trying without fit_kwargs:
2025-12-02 13:05:43,369:WARNING:Traceback (most recent call last):
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 797, in compare_models
    np.sum(
AssertionError

2025-12-02 13:05:43,369:INFO:Initializing create_model()
2025-12-02 13:05:43,369:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000217C7B631F0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000217A8C1BB20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-02 13:05:43,369:INFO:Checking exceptions
2025-12-02 13:05:43,369:INFO:Importing libraries
2025-12-02 13:05:43,369:INFO:Copying training dataset
2025-12-02 13:05:43,371:INFO:Defining folds
2025-12-02 13:05:43,371:INFO:Declaring metric variables
2025-12-02 13:05:43,371:INFO:Importing untrained model
2025-12-02 13:05:43,371:INFO:Light Gradient Boosting Machine Imported successfully
2025-12-02 13:05:43,371:INFO:Starting cross validation
2025-12-02 13:05:43,379:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-02 13:05:43,380:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\model_selection\_split.py:737: UserWarning: The least populated class in y has only 7 members, which is less than n_splits=10.

2025-12-02 13:05:43,791:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-02 13:05:43,806:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-12-02 13:05:43,808:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-02 13:05:43,833:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-12-02 13:05:43,835:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-02 13:05:43,846:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-02 13:05:43,866:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-12-02 13:05:43,866:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-02 13:05:43,918:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-02 13:05:43,927:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\model_selection\_validation.py:547: FitFailedWarning: 
2 fits failed out of a total of 10.
The score on these train-test partitions for these parameters will be set to 0.0.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
2 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pipeline.py", line 256, in _fit
    X, y = self._memory_transform(
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pipeline.py", line 80, in _transform_one
    output = transformer.transform(*args)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 255, in transform
    output = self.transformer.transform(*args)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 536, in transform
    X, y = self.estimator.fit_resample(X, y)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\imblearn\base.py", line 202, in fit_resample
    return super().fit_resample(X, y, **params)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\base.py", line 1474, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\imblearn\base.py", line 105, in fit_resample
    output = self._fit_resample(X, y, **params)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\imblearn\over_sampling\_smote\base.py", line 359, in _fit_resample
    nns = self.nn_k_.kneighbors(X_class, return_distance=False)[:, 1:]
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\neighbors\_base.py", line 835, in kneighbors
    raise ValueError(
ValueError: Expected n_neighbors <= n_samples_fit, but n_neighbors = 6, n_samples_fit = 5, n_samples = 5


2025-12-02 13:05:43,928:INFO:Calculating mean and std
2025-12-02 13:05:43,928:INFO:Creating metrics dataframe
2025-12-02 13:05:43,929:INFO:Uploading results into container
2025-12-02 13:05:43,929:INFO:Uploading model into container now
2025-12-02 13:05:43,930:INFO:_master_model_container: 8
2025-12-02 13:05:43,930:INFO:_display_container: 3
2025-12-02 13:05:43,930:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-12-02 13:05:43,930:INFO:create_model() successfully completed......................................
2025-12-02 13:05:44,112:ERROR:create_model() for LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) raised an exception or returned all 0.0:
2025-12-02 13:05:44,112:ERROR:Traceback (most recent call last):
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 797, in compare_models
    np.sum(
AssertionError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 818, in compare_models
    np.sum(
AssertionError

2025-12-02 13:05:44,112:INFO:_master_model_container: 8
2025-12-02 13:05:44,112:INFO:_display_container: 3
2025-12-02 13:05:44,112:INFO:[]
2025-12-02 13:05:44,112:INFO:compare_models() successfully completed......................................
2025-12-02 13:06:00,195:INFO:Initializing compare_models()
2025-12-02 13:06:00,195:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000217C7B631F0>, include=['xgboost', 'lightgbm'], fold=None, round=4, cross_validation=True, sort=Recall, n_select=3, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=False, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x00000217C7B631F0>, 'include': ['xgboost', 'lightgbm'], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Recall', 'n_select': 3, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': False, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2025-12-02 13:06:00,195:INFO:Checking exceptions
2025-12-02 13:06:00,197:INFO:Preparing display monitor
2025-12-02 13:06:00,199:INFO:Initializing Extreme Gradient Boosting
2025-12-02 13:06:00,199:INFO:Total runtime is 0.0 minutes
2025-12-02 13:06:00,199:INFO:SubProcess create_model() called ==================================
2025-12-02 13:06:00,199:INFO:Initializing create_model()
2025-12-02 13:06:00,199:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000217C7B631F0>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000217D01CEE90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-02 13:06:00,199:INFO:Checking exceptions
2025-12-02 13:06:00,199:INFO:Importing libraries
2025-12-02 13:06:00,199:INFO:Copying training dataset
2025-12-02 13:06:00,203:INFO:Defining folds
2025-12-02 13:06:00,203:INFO:Declaring metric variables
2025-12-02 13:06:00,203:INFO:Importing untrained model
2025-12-02 13:06:00,203:INFO:Extreme Gradient Boosting Imported successfully
2025-12-02 13:06:00,203:INFO:Starting cross validation
2025-12-02 13:06:00,209:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-02 13:06:00,212:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\model_selection\_split.py:737: UserWarning: The least populated class in y has only 7 members, which is less than n_splits=10.

2025-12-02 13:06:00,398:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-12-02 13:06:00,398:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-12-02 13:06:00,399:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-02 13:06:00,401:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-02 13:06:00,404:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-02 13:06:00,404:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-12-02 13:06:00,404:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-12-02 13:06:00,404:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-12-02 13:06:00,410:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-12-02 13:06:00,412:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-02 13:06:00,413:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-02 13:06:00,432:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\model_selection\_validation.py:547: FitFailedWarning: 
2 fits failed out of a total of 10.
The score on these train-test partitions for these parameters will be set to 0.0.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
2 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pipeline.py", line 256, in _fit
    X, y = self._memory_transform(
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pipeline.py", line 80, in _transform_one
    output = transformer.transform(*args)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 255, in transform
    output = self.transformer.transform(*args)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 536, in transform
    X, y = self.estimator.fit_resample(X, y)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\imblearn\base.py", line 202, in fit_resample
    return super().fit_resample(X, y, **params)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\base.py", line 1474, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\imblearn\base.py", line 105, in fit_resample
    output = self._fit_resample(X, y, **params)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\imblearn\over_sampling\_smote\base.py", line 359, in _fit_resample
    nns = self.nn_k_.kneighbors(X_class, return_distance=False)[:, 1:]
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\neighbors\_base.py", line 835, in kneighbors
    raise ValueError(
ValueError: Expected n_neighbors <= n_samples_fit, but n_neighbors = 6, n_samples_fit = 5, n_samples = 5


2025-12-02 13:06:00,432:INFO:Calculating mean and std
2025-12-02 13:06:00,432:INFO:Creating metrics dataframe
2025-12-02 13:06:00,432:INFO:Uploading results into container
2025-12-02 13:06:00,432:INFO:Uploading model into container now
2025-12-02 13:06:00,432:INFO:_master_model_container: 9
2025-12-02 13:06:00,432:INFO:_display_container: 4
2025-12-02 13:06:00,432:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              feature_weights=None, gamma=None, grow_policy=None,
              importance_type=None, interaction_constraints=None,
              learning_rate=None, max_bin=None, max_cat_threshold=None,
              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,
              max_leaves=None, min_child_weight=None, missing=nan,
              monotone_constraints=None, multi_strategy=None, n_estimators=None,
              n_jobs=-1, num_parallel_tree=None, ...)
2025-12-02 13:06:00,432:INFO:create_model() successfully completed......................................
2025-12-02 13:06:00,589:WARNING:create_model() for XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              feature_weights=None, gamma=None, grow_policy=None,
              importance_type=None, interaction_constraints=None,
              learning_rate=None, max_bin=None, max_cat_threshold=None,
              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,
              max_leaves=None, min_child_weight=None, missing=nan,
              monotone_constraints=None, multi_strategy=None, n_estimators=None,
              n_jobs=-1, num_parallel_tree=None, ...) raised an exception or returned all 0.0, trying without fit_kwargs:
2025-12-02 13:06:00,589:WARNING:Traceback (most recent call last):
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 797, in compare_models
    np.sum(
AssertionError

2025-12-02 13:06:00,589:INFO:Initializing create_model()
2025-12-02 13:06:00,589:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000217C7B631F0>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000217D01CEE90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-02 13:06:00,589:INFO:Checking exceptions
2025-12-02 13:06:00,590:INFO:Importing libraries
2025-12-02 13:06:00,590:INFO:Copying training dataset
2025-12-02 13:06:00,590:INFO:Defining folds
2025-12-02 13:06:00,590:INFO:Declaring metric variables
2025-12-02 13:06:00,590:INFO:Importing untrained model
2025-12-02 13:06:00,594:INFO:Extreme Gradient Boosting Imported successfully
2025-12-02 13:06:00,594:INFO:Starting cross validation
2025-12-02 13:06:00,597:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-02 13:06:00,601:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\model_selection\_split.py:737: UserWarning: The least populated class in y has only 7 members, which is less than n_splits=10.

2025-12-02 13:06:00,797:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-12-02 13:06:00,798:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-02 13:06:00,799:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-02 13:06:00,799:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-02 13:06:00,801:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-02 13:06:00,802:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-12-02 13:06:00,802:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-12-02 13:06:00,803:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-12-02 13:06:00,805:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-12-02 13:06:00,807:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-02 13:06:00,809:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-12-02 13:06:00,811:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-02 13:06:00,818:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\model_selection\_validation.py:547: FitFailedWarning: 
2 fits failed out of a total of 10.
The score on these train-test partitions for these parameters will be set to 0.0.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
2 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pipeline.py", line 256, in _fit
    X, y = self._memory_transform(
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pipeline.py", line 80, in _transform_one
    output = transformer.transform(*args)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 255, in transform
    output = self.transformer.transform(*args)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 536, in transform
    X, y = self.estimator.fit_resample(X, y)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\imblearn\base.py", line 202, in fit_resample
    return super().fit_resample(X, y, **params)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\base.py", line 1474, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\imblearn\base.py", line 105, in fit_resample
    output = self._fit_resample(X, y, **params)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\imblearn\over_sampling\_smote\base.py", line 359, in _fit_resample
    nns = self.nn_k_.kneighbors(X_class, return_distance=False)[:, 1:]
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\neighbors\_base.py", line 835, in kneighbors
    raise ValueError(
ValueError: Expected n_neighbors <= n_samples_fit, but n_neighbors = 6, n_samples_fit = 5, n_samples = 5


2025-12-02 13:06:00,818:INFO:Calculating mean and std
2025-12-02 13:06:00,818:INFO:Creating metrics dataframe
2025-12-02 13:06:00,818:INFO:Uploading results into container
2025-12-02 13:06:00,821:INFO:Uploading model into container now
2025-12-02 13:06:00,821:INFO:_master_model_container: 10
2025-12-02 13:06:00,821:INFO:_display_container: 4
2025-12-02 13:06:00,821:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              feature_weights=None, gamma=None, grow_policy=None,
              importance_type=None, interaction_constraints=None,
              learning_rate=None, max_bin=None, max_cat_threshold=None,
              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,
              max_leaves=None, min_child_weight=None, missing=nan,
              monotone_constraints=None, multi_strategy=None, n_estimators=None,
              n_jobs=-1, num_parallel_tree=None, ...)
2025-12-02 13:06:00,821:INFO:create_model() successfully completed......................................
2025-12-02 13:06:00,980:ERROR:create_model() for XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              feature_weights=None, gamma=None, grow_policy=None,
              importance_type=None, interaction_constraints=None,
              learning_rate=None, max_bin=None, max_cat_threshold=None,
              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,
              max_leaves=None, min_child_weight=None, missing=nan,
              monotone_constraints=None, multi_strategy=None, n_estimators=None,
              n_jobs=-1, num_parallel_tree=None, ...) raised an exception or returned all 0.0:
2025-12-02 13:06:00,980:ERROR:Traceback (most recent call last):
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 797, in compare_models
    np.sum(
AssertionError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 818, in compare_models
    np.sum(
AssertionError

2025-12-02 13:06:00,980:INFO:Initializing Light Gradient Boosting Machine
2025-12-02 13:06:00,980:INFO:Total runtime is 0.013014022509257 minutes
2025-12-02 13:06:00,980:INFO:SubProcess create_model() called ==================================
2025-12-02 13:06:00,980:INFO:Initializing create_model()
2025-12-02 13:06:00,980:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000217C7B631F0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000217D01CEE90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-02 13:06:00,980:INFO:Checking exceptions
2025-12-02 13:06:00,980:INFO:Importing libraries
2025-12-02 13:06:00,980:INFO:Copying training dataset
2025-12-02 13:06:00,983:INFO:Defining folds
2025-12-02 13:06:00,983:INFO:Declaring metric variables
2025-12-02 13:06:00,983:INFO:Importing untrained model
2025-12-02 13:06:00,983:INFO:Light Gradient Boosting Machine Imported successfully
2025-12-02 13:06:00,983:INFO:Starting cross validation
2025-12-02 13:06:00,989:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-02 13:06:00,990:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\model_selection\_split.py:737: UserWarning: The least populated class in y has only 7 members, which is less than n_splits=10.

2025-12-02 13:06:01,447:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-12-02 13:06:01,449:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-02 13:06:01,457:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-12-02 13:06:01,459:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-02 13:06:01,490:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-12-02 13:06:01,494:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-02 13:06:01,516:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-02 13:06:01,533:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-02 13:06:01,571:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-02 13:06:01,579:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\model_selection\_validation.py:547: FitFailedWarning: 
2 fits failed out of a total of 10.
The score on these train-test partitions for these parameters will be set to 0.0.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
2 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pipeline.py", line 256, in _fit
    X, y = self._memory_transform(
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pipeline.py", line 80, in _transform_one
    output = transformer.transform(*args)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 255, in transform
    output = self.transformer.transform(*args)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 536, in transform
    X, y = self.estimator.fit_resample(X, y)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\imblearn\base.py", line 202, in fit_resample
    return super().fit_resample(X, y, **params)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\base.py", line 1474, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\imblearn\base.py", line 105, in fit_resample
    output = self._fit_resample(X, y, **params)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\imblearn\over_sampling\_smote\base.py", line 359, in _fit_resample
    nns = self.nn_k_.kneighbors(X_class, return_distance=False)[:, 1:]
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\neighbors\_base.py", line 835, in kneighbors
    raise ValueError(
ValueError: Expected n_neighbors <= n_samples_fit, but n_neighbors = 6, n_samples_fit = 5, n_samples = 5


2025-12-02 13:06:01,579:INFO:Calculating mean and std
2025-12-02 13:06:01,580:INFO:Creating metrics dataframe
2025-12-02 13:06:01,580:INFO:Uploading results into container
2025-12-02 13:06:01,582:INFO:Uploading model into container now
2025-12-02 13:06:01,582:INFO:_master_model_container: 11
2025-12-02 13:06:01,582:INFO:_display_container: 4
2025-12-02 13:06:01,583:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-12-02 13:06:01,583:INFO:create_model() successfully completed......................................
2025-12-02 13:06:01,773:WARNING:create_model() for LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) raised an exception or returned all 0.0, trying without fit_kwargs:
2025-12-02 13:06:01,773:WARNING:Traceback (most recent call last):
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 797, in compare_models
    np.sum(
AssertionError

2025-12-02 13:06:01,773:INFO:Initializing create_model()
2025-12-02 13:06:01,773:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000217C7B631F0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000217D01CEE90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-02 13:06:01,773:INFO:Checking exceptions
2025-12-02 13:06:01,773:INFO:Importing libraries
2025-12-02 13:06:01,773:INFO:Copying training dataset
2025-12-02 13:06:01,777:INFO:Defining folds
2025-12-02 13:06:01,777:INFO:Declaring metric variables
2025-12-02 13:06:01,777:INFO:Importing untrained model
2025-12-02 13:06:01,777:INFO:Light Gradient Boosting Machine Imported successfully
2025-12-02 13:06:01,777:INFO:Starting cross validation
2025-12-02 13:06:01,782:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-12-02 13:06:01,782:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\model_selection\_split.py:737: UserWarning: The least populated class in y has only 7 members, which is less than n_splits=10.

2025-12-02 13:06:02,218:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-12-02 13:06:02,220:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-02 13:06:02,242:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-12-02 13:06:02,243:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-02 13:06:02,243:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-02 13:06:02,266:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-12-02 13:06:02,269:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-02 13:06:02,289:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-02 13:06:02,336:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-02 13:06:02,347:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\model_selection\_validation.py:547: FitFailedWarning: 
2 fits failed out of a total of 10.
The score on these train-test partitions for these parameters will be set to 0.0.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
2 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pipeline.py", line 256, in _fit
    X, y = self._memory_transform(
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pipeline.py", line 80, in _transform_one
    output = transformer.transform(*args)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 255, in transform
    output = self.transformer.transform(*args)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 536, in transform
    X, y = self.estimator.fit_resample(X, y)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\imblearn\base.py", line 202, in fit_resample
    return super().fit_resample(X, y, **params)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\base.py", line 1474, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\imblearn\base.py", line 105, in fit_resample
    output = self._fit_resample(X, y, **params)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\imblearn\over_sampling\_smote\base.py", line 359, in _fit_resample
    nns = self.nn_k_.kneighbors(X_class, return_distance=False)[:, 1:]
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\neighbors\_base.py", line 835, in kneighbors
    raise ValueError(
ValueError: Expected n_neighbors <= n_samples_fit, but n_neighbors = 6, n_samples_fit = 5, n_samples = 5


2025-12-02 13:06:02,347:INFO:Calculating mean and std
2025-12-02 13:06:02,348:INFO:Creating metrics dataframe
2025-12-02 13:06:02,348:INFO:Uploading results into container
2025-12-02 13:06:02,350:INFO:Uploading model into container now
2025-12-02 13:06:02,350:INFO:_master_model_container: 12
2025-12-02 13:06:02,350:INFO:_display_container: 4
2025-12-02 13:06:02,351:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-12-02 13:06:02,351:INFO:create_model() successfully completed......................................
2025-12-02 13:06:02,529:ERROR:create_model() for LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) raised an exception or returned all 0.0:
2025-12-02 13:06:02,530:ERROR:Traceback (most recent call last):
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 797, in compare_models
    np.sum(
AssertionError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 818, in compare_models
    np.sum(
AssertionError

2025-12-02 13:06:02,531:INFO:_master_model_container: 12
2025-12-02 13:06:02,531:INFO:_display_container: 4
2025-12-02 13:06:02,531:INFO:[]
2025-12-02 13:06:02,531:INFO:compare_models() successfully completed......................................
2025-12-02 13:14:12,406:INFO:PyCaret ClassificationExperiment
2025-12-02 13:14:12,406:INFO:Logging name: clf-default-name
2025-12-02 13:14:12,406:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-12-02 13:14:12,406:INFO:version 3.3.2
2025-12-02 13:14:12,406:INFO:Initializing setup()
2025-12-02 13:14:12,406:INFO:self.USI: c9e5
2025-12-02 13:14:12,406:INFO:self._variable_keys: {'is_multiclass', 'fix_imbalance', 'y_test', 'X', 'y_train', 'fold_shuffle_param', 'X_train', 'target_param', 'idx', '_ml_usecase', 'html_param', 'n_jobs_param', '_available_plots', 'memory', 'seed', 'fold_generator', 'gpu_n_jobs_param', 'data', 'log_plots_param', 'fold_groups_param', 'exp_id', 'logging_param', 'pipeline', 'y', 'X_test', 'USI', 'exp_name_log', 'gpu_param'}
2025-12-02 13:14:12,406:INFO:Checking environment
2025-12-02 13:14:12,406:INFO:python_version: 3.10.19
2025-12-02 13:14:12,406:INFO:python_build: ('main', 'Oct 21 2025 16:41:31')
2025-12-02 13:14:12,406:INFO:machine: AMD64
2025-12-02 13:14:12,406:INFO:platform: Windows-10-10.0.26100-SP0
2025-12-02 13:14:12,406:INFO:Memory: svmem(total=16282144768, available=4251631616, percent=73.9, used=12030513152, free=4251631616)
2025-12-02 13:14:12,406:INFO:Physical Core: 6
2025-12-02 13:14:12,406:INFO:Logical Core: 12
2025-12-02 13:14:12,406:INFO:Checking libraries
2025-12-02 13:14:12,406:INFO:System:
2025-12-02 13:14:12,406:INFO:    python: 3.10.19 | packaged by Anaconda, Inc. | (main, Oct 21 2025, 16:41:31) [MSC v.1929 64 bit (AMD64)]
2025-12-02 13:14:12,406:INFO:executable: c:\Users\OMAR\miniconda3\envs\xgb_env\python.exe
2025-12-02 13:14:12,406:INFO:   machine: Windows-10-10.0.26100-SP0
2025-12-02 13:14:12,406:INFO:PyCaret required dependencies:
2025-12-02 13:14:12,406:INFO:                 pip: 25.3
2025-12-02 13:14:12,406:INFO:          setuptools: 80.9.0
2025-12-02 13:14:12,406:INFO:             pycaret: 3.3.2
2025-12-02 13:14:12,406:INFO:             IPython: 8.37.0
2025-12-02 13:14:12,406:INFO:          ipywidgets: 8.1.8
2025-12-02 13:14:12,406:INFO:                tqdm: 4.67.1
2025-12-02 13:14:12,406:INFO:               numpy: 1.26.4
2025-12-02 13:14:12,406:INFO:              pandas: 2.1.4
2025-12-02 13:14:12,406:INFO:              jinja2: 3.1.6
2025-12-02 13:14:12,406:INFO:               scipy: 1.11.4
2025-12-02 13:14:12,406:INFO:              joblib: 1.3.2
2025-12-02 13:14:12,406:INFO:             sklearn: 1.4.2
2025-12-02 13:14:12,406:INFO:                pyod: 2.0.5
2025-12-02 13:14:12,406:INFO:            imblearn: 0.14.0
2025-12-02 13:14:12,406:INFO:   category_encoders: 2.7.0
2025-12-02 13:14:12,406:INFO:            lightgbm: 4.6.0
2025-12-02 13:14:12,406:INFO:               numba: 0.62.1
2025-12-02 13:14:12,406:INFO:            requests: 2.32.5
2025-12-02 13:14:12,406:INFO:          matplotlib: 3.7.5
2025-12-02 13:14:12,406:INFO:          scikitplot: 0.3.7
2025-12-02 13:14:12,406:INFO:         yellowbrick: 1.5
2025-12-02 13:14:12,406:INFO:              plotly: 5.24.1
2025-12-02 13:14:12,406:INFO:    plotly-resampler: Not installed
2025-12-02 13:14:12,406:INFO:             kaleido: 1.2.0
2025-12-02 13:14:12,406:INFO:           schemdraw: 0.15
2025-12-02 13:14:12,406:INFO:         statsmodels: 0.14.5
2025-12-02 13:14:12,406:INFO:              sktime: 0.26.0
2025-12-02 13:14:12,408:INFO:               tbats: 1.1.3
2025-12-02 13:14:12,408:INFO:            pmdarima: 2.0.4
2025-12-02 13:14:12,408:INFO:              psutil: 7.1.3
2025-12-02 13:14:12,408:INFO:          markupsafe: 3.0.3
2025-12-02 13:14:12,408:INFO:             pickle5: Not installed
2025-12-02 13:14:12,408:INFO:         cloudpickle: 3.1.2
2025-12-02 13:14:12,408:INFO:         deprecation: 2.1.0
2025-12-02 13:14:12,408:INFO:              xxhash: 3.6.0
2025-12-02 13:14:12,408:INFO:           wurlitzer: Not installed
2025-12-02 13:14:12,408:INFO:PyCaret optional dependencies:
2025-12-02 13:14:12,408:INFO:                shap: 0.44.1
2025-12-02 13:14:12,408:INFO:           interpret: 0.7.3
2025-12-02 13:14:12,408:INFO:                umap: 0.5.7
2025-12-02 13:14:12,408:INFO:     ydata_profiling: 4.18.0
2025-12-02 13:14:12,408:INFO:  explainerdashboard: 0.5.1
2025-12-02 13:14:12,408:INFO:             autoviz: Not installed
2025-12-02 13:14:12,408:INFO:           fairlearn: 0.7.0
2025-12-02 13:14:12,408:INFO:          deepchecks: Not installed
2025-12-02 13:14:12,408:INFO:             xgboost: 3.1.2
2025-12-02 13:14:12,408:INFO:            catboost: 1.2.8
2025-12-02 13:14:12,408:INFO:              kmodes: 0.12.2
2025-12-02 13:14:12,408:INFO:             mlxtend: 0.23.4
2025-12-02 13:14:12,408:INFO:       statsforecast: 1.5.0
2025-12-02 13:14:12,408:INFO:        tune_sklearn: Not installed
2025-12-02 13:14:12,408:INFO:                 ray: Not installed
2025-12-02 13:14:12,408:INFO:            hyperopt: 0.2.7
2025-12-02 13:14:12,408:INFO:              optuna: 4.6.0
2025-12-02 13:14:12,408:INFO:               skopt: 0.10.2
2025-12-02 13:14:12,408:INFO:              mlflow: 3.6.0
2025-12-02 13:14:12,408:INFO:              gradio: 6.0.1
2025-12-02 13:14:12,408:INFO:             fastapi: 0.123.0
2025-12-02 13:14:12,408:INFO:             uvicorn: 0.38.0
2025-12-02 13:14:12,408:INFO:              m2cgen: 0.10.0
2025-12-02 13:14:12,408:INFO:           evidently: 0.4.40
2025-12-02 13:14:12,408:INFO:               fugue: 0.8.7
2025-12-02 13:14:12,408:INFO:           streamlit: 1.51.0
2025-12-02 13:14:12,408:INFO:             prophet: Not installed
2025-12-02 13:14:12,408:INFO:None
2025-12-02 13:14:12,409:INFO:Set up data.
2025-12-02 13:14:12,414:INFO:Set up folding strategy.
2025-12-02 13:14:12,414:INFO:Set up train/test split.
2025-12-02 13:14:12,417:INFO:Set up index.
2025-12-02 13:14:12,418:INFO:Assigning column types.
2025-12-02 13:14:12,421:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-12-02 13:14:12,445:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-12-02 13:14:12,446:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-02 13:14:12,462:INFO:Soft dependency imported: xgboost: 3.1.2
2025-12-02 13:14:12,463:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-02 13:14:12,489:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-12-02 13:14:12,490:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-02 13:14:12,506:INFO:Soft dependency imported: xgboost: 3.1.2
2025-12-02 13:14:12,506:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-02 13:14:12,508:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-12-02 13:14:12,533:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-02 13:14:12,549:INFO:Soft dependency imported: xgboost: 3.1.2
2025-12-02 13:14:12,549:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-02 13:14:12,576:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-02 13:14:12,590:INFO:Soft dependency imported: xgboost: 3.1.2
2025-12-02 13:14:12,593:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-02 13:14:12,593:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-12-02 13:14:12,634:INFO:Soft dependency imported: xgboost: 3.1.2
2025-12-02 13:14:12,636:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-02 13:14:12,673:INFO:Soft dependency imported: xgboost: 3.1.2
2025-12-02 13:14:12,679:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-02 13:14:12,680:INFO:Preparing preprocessing pipeline...
2025-12-02 13:14:12,680:INFO:Set up simple imputation.
2025-12-02 13:14:12,680:INFO:Set up removing outliers.
2025-12-02 13:14:12,680:INFO:Set up imbalanced handling.
2025-12-02 13:14:12,680:INFO:Set up feature normalization.
2025-12-02 13:14:12,802:INFO:Finished creating preprocessing pipeline.
2025-12-02 13:14:12,806:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\OMAR\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['SEQN', 'Sex', 'Age', 'Race',
                                             'Education', 'IncomeRatio',
                                             'SystolicBP', 'BMI',
                                             'WaistCircumference', 'Height',
                                             'TotalCholesterol',
                                             'Triglycerides', 'LDL', 'HDL',
                                             'HbA1c', 'Glucose', 'Creatinine',
                                             'UricAcid', 'ALT_Enzyme',
                                             '...
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              random_state=42,
                                                                              sampling_strategy='auto')))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=RobustScaler(copy=True,
                                                             quantile_range=(25.0,
                                                                             75.0),
                                                             unit_variance=False,
                                                             with_centering=True,
                                                             with_scaling=True)))],
         verbose=False)
2025-12-02 13:14:12,806:INFO:Creating final display dataframe.
2025-12-02 13:14:12,993:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target      HeartDisease
2                   Target type            Binary
3           Original data shape         (437, 29)
4        Transformed data shape         (698, 29)
5   Transformed train set shape         (566, 29)
6    Transformed test set shape         (132, 29)
7              Numeric features                28
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12              Remove outliers              True
13           Outliers threshold              0.05
14                Fix imbalance              True
15         Fix imbalance method             SMOTE
16                    Normalize              True
17             Normalize method            robust
18               Fold Generator   StratifiedKFold
19                  Fold Number                10
20                     CPU Jobs                 1
21                      Use GPU             False
22               Log Experiment             False
23              Experiment Name  clf-default-name
24                          USI              c9e5
2025-12-02 13:14:13,044:INFO:Soft dependency imported: xgboost: 3.1.2
2025-12-02 13:14:13,046:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-02 13:14:13,089:INFO:Soft dependency imported: xgboost: 3.1.2
2025-12-02 13:14:13,090:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-02 13:14:13,090:INFO:setup() successfully completed in 0.69s...............
2025-12-02 13:14:38,463:INFO:Initializing compare_models()
2025-12-02 13:14:38,463:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000217D01CC1F0>, include=['xgboost', 'lightgbm'], fold=None, round=4, cross_validation=True, sort=Recall, n_select=3, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x00000217D01CC1F0>, 'include': ['xgboost', 'lightgbm'], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Recall', 'n_select': 3, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2025-12-02 13:14:38,463:INFO:Checking exceptions
2025-12-02 13:14:38,467:INFO:Preparing display monitor
2025-12-02 13:14:38,482:INFO:Initializing Extreme Gradient Boosting
2025-12-02 13:14:38,482:INFO:Total runtime is 0.0 minutes
2025-12-02 13:14:38,482:INFO:SubProcess create_model() called ==================================
2025-12-02 13:14:38,482:INFO:Initializing create_model()
2025-12-02 13:14:38,482:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000217D01CC1F0>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000217CFFE9FC0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-02 13:14:38,482:INFO:Checking exceptions
2025-12-02 13:14:38,482:INFO:Importing libraries
2025-12-02 13:14:38,489:INFO:Copying training dataset
2025-12-02 13:14:38,491:INFO:Defining folds
2025-12-02 13:14:38,491:INFO:Declaring metric variables
2025-12-02 13:14:38,495:INFO:Importing untrained model
2025-12-02 13:14:38,499:INFO:Extreme Gradient Boosting Imported successfully
2025-12-02 13:14:38,504:INFO:Starting cross validation
2025-12-02 13:14:38,513:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-12-02 13:14:38,515:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\model_selection\_split.py:737: UserWarning: The least populated class in y has only 7 members, which is less than n_splits=10.

2025-12-02 13:14:39,232:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.


2025-12-02 13:14:39,232:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.

2025-12-02 13:14:39,232:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-12-02 13:14:39,237:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.

2025-12-02 13:14:39,237:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.

2025-12-02 13:14:39,237:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide

2025-12-02 13:14:39,237:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.

2025-12-02 13:14:39,359:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.


2025-12-02 13:14:39,361:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.

2025-12-02 13:14:39,488:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.


2025-12-02 13:14:39,489:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.

2025-12-02 13:14:39,745:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-12-02 13:14:39,745:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\model_selection\_validation.py:547: FitFailedWarning: 
2 fits failed out of a total of 10.
The score on these train-test partitions for these parameters will be set to 0.0.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
2 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pipeline.py", line 256, in _fit
    X, y = self._memory_transform(
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pipeline.py", line 80, in _transform_one
    output = transformer.transform(*args)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 255, in transform
    output = self.transformer.transform(*args)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 536, in transform
    X, y = self.estimator.fit_resample(X, y)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\imblearn\base.py", line 202, in fit_resample
    return super().fit_resample(X, y, **params)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\base.py", line 1474, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\imblearn\base.py", line 105, in fit_resample
    output = self._fit_resample(X, y, **params)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\imblearn\over_sampling\_smote\base.py", line 359, in _fit_resample
    nns = self.nn_k_.kneighbors(X_class, return_distance=False)[:, 1:]
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\neighbors\_base.py", line 835, in kneighbors
    raise ValueError(
ValueError: Expected n_neighbors <= n_samples_fit, but n_neighbors = 6, n_samples_fit = 5, n_samples = 5


2025-12-02 13:14:39,745:INFO:Calculating mean and std
2025-12-02 13:14:39,751:INFO:Creating metrics dataframe
2025-12-02 13:14:39,753:INFO:Uploading results into container
2025-12-02 13:14:39,753:INFO:Uploading model into container now
2025-12-02 13:14:39,753:INFO:_master_model_container: 1
2025-12-02 13:14:39,753:INFO:_display_container: 2
2025-12-02 13:14:39,753:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              feature_weights=None, gamma=None, grow_policy=None,
              importance_type=None, interaction_constraints=None,
              learning_rate=None, max_bin=None, max_cat_threshold=None,
              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,
              max_leaves=None, min_child_weight=None, missing=nan,
              monotone_constraints=None, multi_strategy=None, n_estimators=None,
              n_jobs=1, num_parallel_tree=None, ...)
2025-12-02 13:14:39,753:INFO:create_model() successfully completed......................................
2025-12-02 13:14:39,912:WARNING:create_model() for XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              feature_weights=None, gamma=None, grow_policy=None,
              importance_type=None, interaction_constraints=None,
              learning_rate=None, max_bin=None, max_cat_threshold=None,
              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,
              max_leaves=None, min_child_weight=None, missing=nan,
              monotone_constraints=None, multi_strategy=None, n_estimators=None,
              n_jobs=1, num_parallel_tree=None, ...) raised an exception or returned all 0.0, trying without fit_kwargs:
2025-12-02 13:14:39,912:WARNING:Traceback (most recent call last):
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 797, in compare_models
    np.sum(
AssertionError

2025-12-02 13:14:39,912:INFO:Initializing create_model()
2025-12-02 13:14:39,912:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000217D01CC1F0>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000217CFFE9FC0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-02 13:14:39,912:INFO:Checking exceptions
2025-12-02 13:14:39,912:INFO:Importing libraries
2025-12-02 13:14:39,912:INFO:Copying training dataset
2025-12-02 13:14:39,919:INFO:Defining folds
2025-12-02 13:14:39,919:INFO:Declaring metric variables
2025-12-02 13:14:39,922:INFO:Importing untrained model
2025-12-02 13:14:39,926:INFO:Extreme Gradient Boosting Imported successfully
2025-12-02 13:14:39,930:INFO:Starting cross validation
2025-12-02 13:14:39,934:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-12-02 13:14:39,939:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\model_selection\_split.py:737: UserWarning: The least populated class in y has only 7 members, which is less than n_splits=10.

2025-12-02 13:14:40,589:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 797, in compare_models
    np.sum(
AssertionError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.


2025-12-02 13:14:40,591:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.

2025-12-02 13:14:40,591:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-12-02 13:14:40,591:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.

2025-12-02 13:14:40,591:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.

2025-12-02 13:14:40,591:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide

2025-12-02 13:14:40,594:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.

2025-12-02 13:14:40,713:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 797, in compare_models
    np.sum(
AssertionError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.


2025-12-02 13:14:40,713:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.

2025-12-02 13:14:40,839:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 797, in compare_models
    np.sum(
AssertionError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.


2025-12-02 13:14:40,840:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.

2025-12-02 13:14:41,090:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-12-02 13:14:41,094:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\model_selection\_validation.py:547: FitFailedWarning: 
2 fits failed out of a total of 10.
The score on these train-test partitions for these parameters will be set to 0.0.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
2 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 797, in compare_models
    np.sum(
AssertionError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pipeline.py", line 256, in _fit
    X, y = self._memory_transform(
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pipeline.py", line 80, in _transform_one
    output = transformer.transform(*args)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 255, in transform
    output = self.transformer.transform(*args)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 536, in transform
    X, y = self.estimator.fit_resample(X, y)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\imblearn\base.py", line 202, in fit_resample
    return super().fit_resample(X, y, **params)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\base.py", line 1474, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\imblearn\base.py", line 105, in fit_resample
    output = self._fit_resample(X, y, **params)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\imblearn\over_sampling\_smote\base.py", line 359, in _fit_resample
    nns = self.nn_k_.kneighbors(X_class, return_distance=False)[:, 1:]
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\neighbors\_base.py", line 835, in kneighbors
    raise ValueError(
ValueError: Expected n_neighbors <= n_samples_fit, but n_neighbors = 6, n_samples_fit = 5, n_samples = 5


2025-12-02 13:14:41,094:INFO:Calculating mean and std
2025-12-02 13:14:41,095:INFO:Creating metrics dataframe
2025-12-02 13:14:41,096:INFO:Uploading results into container
2025-12-02 13:14:41,096:INFO:Uploading model into container now
2025-12-02 13:14:41,096:INFO:_master_model_container: 2
2025-12-02 13:14:41,096:INFO:_display_container: 2
2025-12-02 13:14:41,096:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              feature_weights=None, gamma=None, grow_policy=None,
              importance_type=None, interaction_constraints=None,
              learning_rate=None, max_bin=None, max_cat_threshold=None,
              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,
              max_leaves=None, min_child_weight=None, missing=nan,
              monotone_constraints=None, multi_strategy=None, n_estimators=None,
              n_jobs=1, num_parallel_tree=None, ...)
2025-12-02 13:14:41,096:INFO:create_model() successfully completed......................................
2025-12-02 13:14:41,271:ERROR:create_model() for XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              feature_weights=None, gamma=None, grow_policy=None,
              importance_type=None, interaction_constraints=None,
              learning_rate=None, max_bin=None, max_cat_threshold=None,
              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,
              max_leaves=None, min_child_weight=None, missing=nan,
              monotone_constraints=None, multi_strategy=None, n_estimators=None,
              n_jobs=1, num_parallel_tree=None, ...) raised an exception or returned all 0.0:
2025-12-02 13:14:41,271:ERROR:Traceback (most recent call last):
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 797, in compare_models
    np.sum(
AssertionError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 818, in compare_models
    np.sum(
AssertionError

2025-12-02 13:14:41,271:INFO:Initializing Light Gradient Boosting Machine
2025-12-02 13:14:41,271:INFO:Total runtime is 0.04647761185963949 minutes
2025-12-02 13:14:41,275:INFO:SubProcess create_model() called ==================================
2025-12-02 13:14:41,275:INFO:Initializing create_model()
2025-12-02 13:14:41,275:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000217D01CC1F0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000217CFFE9FC0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-02 13:14:41,275:INFO:Checking exceptions
2025-12-02 13:14:41,275:INFO:Importing libraries
2025-12-02 13:14:41,275:INFO:Copying training dataset
2025-12-02 13:14:41,281:INFO:Defining folds
2025-12-02 13:14:41,281:INFO:Declaring metric variables
2025-12-02 13:14:41,282:INFO:Importing untrained model
2025-12-02 13:14:41,285:INFO:Light Gradient Boosting Machine Imported successfully
2025-12-02 13:14:41,290:INFO:Starting cross validation
2025-12-02 13:14:41,297:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-12-02 13:14:41,299:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\model_selection\_split.py:737: UserWarning: The least populated class in y has only 7 members, which is less than n_splits=10.

2025-12-02 13:14:41,473:INFO:[LightGBM] [Info] Number of positive: 254, number of negative: 254
2025-12-02 13:14:41,473:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000036 seconds.
2025-12-02 13:14:41,473:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-02 13:14:41,473:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-02 13:14:41,473:INFO:[LightGBM] [Info] Total Bins 3963
2025-12-02 13:14:41,473:INFO:[LightGBM] [Info] Number of data points in the train set: 508, number of used features: 28
2025-12-02 13:14:41,479:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-02 13:14:41,479:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,479:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,479:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,480:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,480:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,480:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,480:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,482:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,482:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,482:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,484:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,484:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,484:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,484:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,484:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,484:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,484:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,484:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,484:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,489:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,489:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,490:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,490:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,490:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,490:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,490:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,494:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,494:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,494:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,494:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,496:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,497:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,497:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,497:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,497:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,497:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,497:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,497:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,501:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,501:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,502:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,503:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,503:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,503:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,503:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,503:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,503:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,506:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,506:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,508:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,508:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,509:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,509:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,510:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,510:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,510:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,512:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,513:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,513:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,513:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,513:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,513:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,516:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,517:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,517:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,518:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,518:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,518:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,518:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,521:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,521:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,521:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,521:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,524:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,524:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,524:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,524:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,524:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,524:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,524:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,524:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,529:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,530:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,530:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,530:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,532:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,532:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,532:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,532:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,532:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,532:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,532:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,532:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,532:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,532:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,532:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,539:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,540:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,540:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,540:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,648:INFO:[LightGBM] [Info] Number of positive: 254, number of negative: 254
2025-12-02 13:14:41,649:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000075 seconds.
2025-12-02 13:14:41,649:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-02 13:14:41,649:INFO:[LightGBM] [Info] Total Bins 3942
2025-12-02 13:14:41,649:INFO:[LightGBM] [Info] Number of data points in the train set: 508, number of used features: 28
2025-12-02 13:14:41,649:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-02 13:14:41,649:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,650:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,650:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,650:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,650:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,650:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,650:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,653:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,653:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,653:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,653:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,653:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,653:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,656:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,656:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,656:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,658:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,658:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,659:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,659:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,660:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,660:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,662:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,662:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,663:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,664:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,664:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,664:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,666:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,667:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,667:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,667:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,669:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,669:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,669:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,671:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,671:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,671:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,671:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,673:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,673:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,673:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,673:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,673:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,673:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,673:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,678:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,679:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,680:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,680:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,680:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,680:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,682:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,682:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,682:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,682:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,682:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,682:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,682:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,682:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,682:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,682:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,689:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,690:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,690:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,690:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,690:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,690:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,694:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,694:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,694:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,695:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,695:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,697:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,697:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,697:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,697:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,700:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,701:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,701:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,701:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,702:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,703:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,703:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,703:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,703:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,706:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,706:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,706:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,708:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,708:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,709:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,709:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,710:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,710:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,712:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,712:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,713:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,714:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,714:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,723:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-12-02 13:14:41,821:INFO:[LightGBM] [Info] Number of positive: 254, number of negative: 254
2025-12-02 13:14:41,821:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000090 seconds.
2025-12-02 13:14:41,821:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-02 13:14:41,821:INFO:[LightGBM] [Info] Total Bins 3941
2025-12-02 13:14:41,821:INFO:[LightGBM] [Info] Number of data points in the train set: 508, number of used features: 28
2025-12-02 13:14:41,821:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-02 13:14:41,823:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,823:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,823:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,823:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,823:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,823:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,823:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,823:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,823:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,823:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,829:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,829:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,829:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,831:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,831:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,831:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,832:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,832:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,832:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,832:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,832:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,832:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,832:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,832:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,832:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,832:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,832:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,832:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,839:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,840:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,840:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,840:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,840:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,840:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,840:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,840:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,844:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,844:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,844:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,846:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,847:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,847:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,847:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,847:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,847:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,850:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,851:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,851:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,851:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,853:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,853:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,853:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,853:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,853:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,856:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,856:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,856:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,856:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,859:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,859:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,859:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,860:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,860:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,862:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,862:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,863:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,863:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,864:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,865:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,866:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,867:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,867:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,867:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,869:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,869:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,869:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,871:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,871:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,871:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,872:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,873:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,873:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,873:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,873:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,873:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,873:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,873:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,873:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,878:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,879:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,879:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,880:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,880:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,880:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,882:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,882:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,882:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,882:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,882:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:41,882:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,067:INFO:[LightGBM] [Info] Number of positive: 255, number of negative: 255
2025-12-02 13:14:42,067:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000086 seconds.
2025-12-02 13:14:42,067:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-02 13:14:42,067:INFO:[LightGBM] [Info] Total Bins 3934
2025-12-02 13:14:42,067:INFO:[LightGBM] [Info] Number of data points in the train set: 510, number of used features: 28
2025-12-02 13:14:42,067:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-02 13:14:42,067:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,067:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,067:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,068:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,068:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,068:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,068:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,068:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,070:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,070:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,070:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,070:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,070:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,070:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,073:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,073:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,073:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,073:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,073:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,073:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,073:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,073:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,073:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,073:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,073:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,073:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,079:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,079:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,079:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,081:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,081:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,081:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,082:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,082:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,082:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,082:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,082:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,082:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,082:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,082:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,082:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,082:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,082:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,082:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,089:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,090:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,091:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,091:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,091:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,091:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,091:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,094:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,094:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,094:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,094:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,096:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,097:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,097:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,097:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,097:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,097:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,097:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,101:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,101:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,101:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,103:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,103:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,103:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,103:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,103:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,103:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,106:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,106:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,106:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,108:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,108:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,108:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,109:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,109:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,110:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,110:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,110:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,112:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,113:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,114:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,114:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,114:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,116:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,116:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,116:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,116:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,116:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,119:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,119:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,119:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,121:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,121:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,121:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,121:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,123:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,133:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.


2025-12-02 13:14:42,133:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.

2025-12-02 13:14:42,231:INFO:[LightGBM] [Info] Number of positive: 255, number of negative: 255
2025-12-02 13:14:42,231:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000028 seconds.
2025-12-02 13:14:42,231:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-02 13:14:42,231:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-02 13:14:42,231:INFO:[LightGBM] [Info] Total Bins 3935
2025-12-02 13:14:42,231:INFO:[LightGBM] [Info] Number of data points in the train set: 510, number of used features: 28
2025-12-02 13:14:42,231:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-02 13:14:42,231:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,232:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,232:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,232:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,232:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,232:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,232:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,232:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,232:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,232:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,232:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,232:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,232:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,232:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,232:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,232:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,232:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,232:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,239:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,239:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,240:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,240:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,240:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,240:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,240:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,240:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,240:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,244:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,244:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,244:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,244:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,244:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,247:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,248:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,248:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,248:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,248:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,248:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,251:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,251:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,251:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,251:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,253:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,253:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,253:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,253:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,253:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,256:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,256:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,256:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,256:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,258:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,258:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,259:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,259:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,259:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,261:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,261:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,262:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,262:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,264:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,264:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,264:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,264:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,266:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,267:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,267:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,267:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,269:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,269:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,269:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,271:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,271:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,271:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,271:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,271:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,274:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,274:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,274:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,274:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,274:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,274:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,274:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,274:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,279:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,279:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,279:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,281:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,282:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,282:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,283:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,283:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,283:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,283:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,283:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,283:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,283:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,283:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,283:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,283:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,298:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.


2025-12-02 13:14:42,298:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.

2025-12-02 13:14:42,394:INFO:[LightGBM] [Info] Number of positive: 254, number of negative: 254
2025-12-02 13:14:42,394:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000026 seconds.
2025-12-02 13:14:42,394:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-02 13:14:42,394:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-02 13:14:42,394:INFO:[LightGBM] [Info] Total Bins 3901
2025-12-02 13:14:42,394:INFO:[LightGBM] [Info] Number of data points in the train set: 508, number of used features: 28
2025-12-02 13:14:42,398:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-02 13:14:42,398:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,398:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,399:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,399:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,399:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,399:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,401:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,401:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,401:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,402:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,403:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,403:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,403:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,403:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,403:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,403:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,406:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,406:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,406:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,408:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,408:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,409:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,409:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,409:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,411:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,411:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,411:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,412:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,412:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,412:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,414:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,414:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,414:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,416:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,416:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,416:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,416:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,416:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,418:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,418:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,418:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,418:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,421:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,421:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,421:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,421:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,423:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,423:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,423:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,423:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,423:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,423:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,423:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,423:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,429:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,429:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,430:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,430:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,431:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,431:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,432:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,432:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,432:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,432:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,432:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,432:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,432:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,432:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,432:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,432:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,439:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,439:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,439:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,440:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,440:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,440:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,440:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,440:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,444:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,444:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,444:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,444:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,446:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,447:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,447:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,448:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,448:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,448:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,448:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,448:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,451:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,451:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,452:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,453:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,453:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,453:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,453:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,453:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,456:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,456:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,466:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.


2025-12-02 13:14:42,468:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.

2025-12-02 13:14:42,563:INFO:[LightGBM] [Info] Number of positive: 255, number of negative: 255
2025-12-02 13:14:42,564:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000027 seconds.
2025-12-02 13:14:42,564:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-02 13:14:42,564:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-02 13:14:42,564:INFO:[LightGBM] [Info] Total Bins 3961
2025-12-02 13:14:42,564:INFO:[LightGBM] [Info] Number of data points in the train set: 510, number of used features: 28
2025-12-02 13:14:42,564:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-02 13:14:42,564:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,565:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,565:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,565:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,566:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,566:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,566:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,566:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,566:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,566:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,566:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,569:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,569:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,569:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,569:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,569:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,571:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,571:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,571:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,571:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,571:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,573:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,573:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,573:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,573:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,573:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,573:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,573:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,573:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,573:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,573:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,573:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,578:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,579:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,579:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,580:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,581:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,581:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,582:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,582:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,583:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,583:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,584:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,585:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,585:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,585:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,585:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,585:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,585:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,585:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,585:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,589:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,590:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,590:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,590:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,590:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,590:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,590:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,590:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,594:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,594:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,594:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,594:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,594:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,594:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,598:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,598:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,599:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,599:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,599:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,601:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,601:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,602:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,603:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,603:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,603:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,603:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,603:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,606:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,606:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,606:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,608:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,608:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,609:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,609:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,611:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,611:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,612:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,612:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,612:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,614:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,614:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,614:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,616:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,616:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,616:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,616:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,616:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,618:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,618:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,631:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-12-02 13:14:42,724:INFO:[LightGBM] [Info] Number of positive: 255, number of negative: 255
2025-12-02 13:14:42,724:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000042 seconds.
2025-12-02 13:14:42,724:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-02 13:14:42,724:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-02 13:14:42,724:INFO:[LightGBM] [Info] Total Bins 3937
2025-12-02 13:14:42,724:INFO:[LightGBM] [Info] Number of data points in the train set: 510, number of used features: 28
2025-12-02 13:14:42,724:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-02 13:14:42,724:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,724:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,724:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,724:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,724:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,729:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,729:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,729:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,729:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,731:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,732:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,732:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,732:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,732:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,732:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,732:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,732:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,732:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,732:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,732:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,732:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,732:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,732:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,739:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,740:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,740:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,740:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,740:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,740:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,740:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,744:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,744:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,744:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,744:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,744:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,747:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,748:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,748:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,748:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,748:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,751:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,751:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,751:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,753:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,753:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,753:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,753:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,753:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,756:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,756:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,756:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,758:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,758:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,759:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,759:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,761:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,762:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,762:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,762:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,764:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,765:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,765:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,766:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,766:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,766:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,768:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,768:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,768:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,768:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,771:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,771:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,771:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,771:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,773:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,773:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,773:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,773:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,773:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,773:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,773:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,779:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,779:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,779:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,781:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,781:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,782:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,782:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,782:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,782:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,782:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,782:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,782:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,782:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,782:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,782:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,789:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,789:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,791:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,791:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,791:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:42,803:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-12-02 13:14:42,806:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\model_selection\_validation.py:547: FitFailedWarning: 
2 fits failed out of a total of 10.
The score on these train-test partitions for these parameters will be set to 0.0.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
2 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pipeline.py", line 256, in _fit
    X, y = self._memory_transform(
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pipeline.py", line 80, in _transform_one
    output = transformer.transform(*args)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 255, in transform
    output = self.transformer.transform(*args)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 536, in transform
    X, y = self.estimator.fit_resample(X, y)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\imblearn\base.py", line 202, in fit_resample
    return super().fit_resample(X, y, **params)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\base.py", line 1474, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\imblearn\base.py", line 105, in fit_resample
    output = self._fit_resample(X, y, **params)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\imblearn\over_sampling\_smote\base.py", line 359, in _fit_resample
    nns = self.nn_k_.kneighbors(X_class, return_distance=False)[:, 1:]
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\neighbors\_base.py", line 835, in kneighbors
    raise ValueError(
ValueError: Expected n_neighbors <= n_samples_fit, but n_neighbors = 6, n_samples_fit = 5, n_samples = 5


2025-12-02 13:14:42,806:INFO:Calculating mean and std
2025-12-02 13:14:42,808:INFO:Creating metrics dataframe
2025-12-02 13:14:42,813:INFO:Uploading results into container
2025-12-02 13:14:42,813:INFO:Uploading model into container now
2025-12-02 13:14:42,814:INFO:_master_model_container: 3
2025-12-02 13:14:42,814:INFO:_display_container: 2
2025-12-02 13:14:42,814:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-12-02 13:14:42,814:INFO:create_model() successfully completed......................................
2025-12-02 13:14:42,975:WARNING:create_model() for LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) raised an exception or returned all 0.0, trying without fit_kwargs:
2025-12-02 13:14:42,975:WARNING:Traceback (most recent call last):
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 797, in compare_models
    np.sum(
AssertionError

2025-12-02 13:14:42,975:INFO:Initializing create_model()
2025-12-02 13:14:42,975:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000217D01CC1F0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000217CFFE9FC0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-02 13:14:42,975:INFO:Checking exceptions
2025-12-02 13:14:42,975:INFO:Importing libraries
2025-12-02 13:14:42,975:INFO:Copying training dataset
2025-12-02 13:14:42,979:INFO:Defining folds
2025-12-02 13:14:42,979:INFO:Declaring metric variables
2025-12-02 13:14:42,980:INFO:Importing untrained model
2025-12-02 13:14:42,983:INFO:Light Gradient Boosting Machine Imported successfully
2025-12-02 13:14:42,987:INFO:Starting cross validation
2025-12-02 13:14:42,994:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-12-02 13:14:42,995:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\model_selection\_split.py:737: UserWarning: The least populated class in y has only 7 members, which is less than n_splits=10.

2025-12-02 13:14:43,168:INFO:[LightGBM] [Info] Number of positive: 254, number of negative: 254
2025-12-02 13:14:43,168:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000077 seconds.
2025-12-02 13:14:43,168:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-02 13:14:43,168:INFO:[LightGBM] [Info] Total Bins 3963
2025-12-02 13:14:43,168:INFO:[LightGBM] [Info] Number of data points in the train set: 508, number of used features: 28
2025-12-02 13:14:43,168:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-02 13:14:43,169:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,169:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,169:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,169:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,169:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,171:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,171:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,171:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,171:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,173:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,173:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,173:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,175:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,175:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,175:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,175:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,175:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,175:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,179:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,179:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,179:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,180:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,180:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,181:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,182:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,182:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,183:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,184:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,184:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,184:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,184:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,184:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,184:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,184:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,184:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,189:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,189:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,190:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,190:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,190:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,190:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,190:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,194:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,194:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,194:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,194:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,194:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,194:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,194:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,198:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,198:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,199:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,199:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,201:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,201:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,201:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,202:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,203:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,203:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,203:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,203:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,206:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,206:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,206:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,208:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,209:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,209:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,209:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,211:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,211:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,212:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,212:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,212:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,212:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,215:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,216:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,216:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,217:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,217:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,219:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,219:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,219:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,221:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,221:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,221:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,223:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,223:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,223:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,223:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,223:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,223:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,223:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,223:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,228:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,228:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,229:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,229:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,231:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,232:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,232:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,340:INFO:[LightGBM] [Info] Number of positive: 254, number of negative: 254
2025-12-02 13:14:43,340:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000085 seconds.
2025-12-02 13:14:43,340:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-02 13:14:43,340:INFO:[LightGBM] [Info] Total Bins 3942
2025-12-02 13:14:43,341:INFO:[LightGBM] [Info] Number of data points in the train set: 508, number of used features: 28
2025-12-02 13:14:43,341:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-02 13:14:43,341:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,341:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,341:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,341:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,344:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,344:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,344:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,344:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,344:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,344:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,344:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,344:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,348:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,348:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,349:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,349:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,351:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,351:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,351:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,352:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,353:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,353:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,353:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,353:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,353:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,356:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,356:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,356:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,358:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,359:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,360:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,360:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,360:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,362:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,362:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,362:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,362:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,362:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,366:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,367:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,367:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,368:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,369:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,369:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,369:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,371:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,371:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,371:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,371:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,374:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,374:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,375:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,375:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,375:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,375:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,375:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,379:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,379:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,379:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,380:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,380:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,382:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,382:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,383:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,384:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,385:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,385:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,385:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,385:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,385:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,385:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,389:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,390:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,390:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,390:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,390:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,390:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,394:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,394:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,394:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,394:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,394:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,394:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,394:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,398:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,399:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,399:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,400:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,400:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,400:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,403:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,403:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,404:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,404:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,404:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,406:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,406:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,406:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,408:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,408:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,424:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-12-02 13:14:43,521:INFO:[LightGBM] [Info] Number of positive: 254, number of negative: 254
2025-12-02 13:14:43,521:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000077 seconds.
2025-12-02 13:14:43,521:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-02 13:14:43,521:INFO:[LightGBM] [Info] Total Bins 3941
2025-12-02 13:14:43,521:INFO:[LightGBM] [Info] Number of data points in the train set: 508, number of used features: 28
2025-12-02 13:14:43,521:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-02 13:14:43,521:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,523:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,523:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,523:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,523:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,523:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,523:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,523:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,527:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,527:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,528:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,529:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,529:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,529:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,530:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,530:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,532:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,532:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,532:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,533:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,533:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,534:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,534:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,535:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,535:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,535:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,535:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,535:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,539:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,539:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,540:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,540:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,540:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,540:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,540:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,540:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,544:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,544:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,544:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,546:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,546:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,546:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,546:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,549:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,549:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,550:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,551:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,551:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,551:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,553:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,553:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,553:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,553:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,553:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,553:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,556:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,556:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,556:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,558:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,558:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,559:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,559:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,560:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,560:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,562:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,562:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,562:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,562:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,562:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,565:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,566:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,566:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,567:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,567:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,567:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,569:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,569:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,569:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,571:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,571:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,571:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,571:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,574:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,574:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,574:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,576:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,576:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,576:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,576:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,576:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,579:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,579:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,579:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,580:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,580:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,582:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,582:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,582:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,582:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,582:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,774:INFO:[LightGBM] [Info] Number of positive: 255, number of negative: 255
2025-12-02 13:14:43,774:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000080 seconds.
2025-12-02 13:14:43,774:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-02 13:14:43,774:INFO:[LightGBM] [Info] Total Bins 3934
2025-12-02 13:14:43,774:INFO:[LightGBM] [Info] Number of data points in the train set: 510, number of used features: 28
2025-12-02 13:14:43,774:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-02 13:14:43,774:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,774:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,774:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,776:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,776:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,776:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,776:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,776:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,776:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,779:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,779:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,779:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,779:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,779:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,780:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,780:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,780:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,780:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,783:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,783:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,783:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,784:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,784:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,784:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,784:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,784:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,784:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,784:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,784:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,784:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,789:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,789:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,790:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,790:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,790:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,790:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,790:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,790:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,794:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,794:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,795:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,795:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,795:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,795:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,795:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,795:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,795:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,799:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,800:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,800:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,801:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,801:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,801:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,803:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,803:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,803:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,803:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,803:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,803:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,806:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,806:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,806:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,809:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,809:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,809:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,809:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,810:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,810:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,812:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,812:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,812:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,812:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,812:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,812:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,816:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,816:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,816:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,816:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,816:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,819:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,819:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,819:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,821:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,821:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,821:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,823:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,823:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,823:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,826:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,826:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,826:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,828:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,829:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,830:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,832:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,836:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,837:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,838:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,838:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,839:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,853:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 797, in compare_models
    np.sum(
AssertionError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.


2025-12-02 13:14:43,854:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.

2025-12-02 13:14:43,962:INFO:[LightGBM] [Info] Number of positive: 255, number of negative: 255
2025-12-02 13:14:43,962:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000087 seconds.
2025-12-02 13:14:43,962:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-02 13:14:43,962:INFO:[LightGBM] [Info] Total Bins 3935
2025-12-02 13:14:43,962:INFO:[LightGBM] [Info] Number of data points in the train set: 510, number of used features: 28
2025-12-02 13:14:43,962:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-02 13:14:43,962:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,962:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,962:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,962:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,962:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,966:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,966:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,966:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,966:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,966:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,966:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,969:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,969:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,969:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,969:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,971:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,971:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,971:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,971:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,971:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,973:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,973:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,973:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,973:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,973:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,973:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,973:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,973:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,973:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,973:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,973:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,979:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,979:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,980:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,980:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,982:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,983:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,983:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,983:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,983:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,983:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,983:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,983:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,983:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,983:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,983:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,983:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,989:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,990:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,990:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,990:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,990:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,990:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,990:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,990:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,994:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,994:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,994:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,994:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,994:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,994:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,994:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,998:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,999:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:43,999:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,001:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,001:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,002:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,003:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,004:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,004:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,004:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,006:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,006:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,006:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,008:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,008:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,009:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,009:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,010:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,010:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,010:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,012:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,012:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,012:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,012:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,015:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,016:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,016:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,016:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,016:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,019:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,019:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,021:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,021:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,021:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,021:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,021:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,024:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,024:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,033:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 797, in compare_models
    np.sum(
AssertionError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.


2025-12-02 13:14:44,033:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.

2025-12-02 13:14:44,140:INFO:[LightGBM] [Info] Number of positive: 254, number of negative: 254
2025-12-02 13:14:44,140:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000075 seconds.
2025-12-02 13:14:44,140:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-02 13:14:44,140:INFO:[LightGBM] [Info] Total Bins 3901
2025-12-02 13:14:44,140:INFO:[LightGBM] [Info] Number of data points in the train set: 508, number of used features: 28
2025-12-02 13:14:44,140:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-02 13:14:44,140:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,140:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,142:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,142:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,144:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,144:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,144:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,144:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,144:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,144:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,144:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,148:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,148:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,150:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,151:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,151:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,151:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,153:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,153:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,153:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,153:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,153:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,153:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,156:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,156:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,156:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,156:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,158:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,159:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,159:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,160:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,160:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,162:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,162:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,162:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,162:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,162:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,162:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,166:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,166:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,167:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,167:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,168:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,169:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,169:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,171:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,171:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,171:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,171:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,173:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,173:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,173:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,173:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,173:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,173:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,173:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,173:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,179:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,179:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,179:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,181:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,181:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,182:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,182:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,182:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,184:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,184:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,184:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,184:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,184:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,184:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,184:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,189:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,189:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,191:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,191:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,191:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,193:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,193:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,194:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,194:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,194:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,194:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,194:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,194:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,194:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,194:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,194:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,194:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,200:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,200:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,200:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,202:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,203:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,203:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,203:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,203:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,203:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,206:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,206:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,221:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 797, in compare_models
    np.sum(
AssertionError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.


2025-12-02 13:14:44,223:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.

2025-12-02 13:14:44,327:INFO:[LightGBM] [Info] Number of positive: 255, number of negative: 255
2025-12-02 13:14:44,327:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000026 seconds.
2025-12-02 13:14:44,327:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-02 13:14:44,327:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-02 13:14:44,327:INFO:[LightGBM] [Info] Total Bins 3961
2025-12-02 13:14:44,327:INFO:[LightGBM] [Info] Number of data points in the train set: 510, number of used features: 28
2025-12-02 13:14:44,327:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-02 13:14:44,327:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,329:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,329:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,329:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,329:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,329:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,330:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,330:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,330:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,332:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,332:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,333:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,333:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,333:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,333:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,333:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,333:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,333:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,333:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,333:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,333:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,333:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,333:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,339:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,339:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,339:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,340:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,340:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,340:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,340:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,342:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,342:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,342:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,344:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,344:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,344:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,344:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,344:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,344:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,344:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,344:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,344:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,349:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,349:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,350:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,351:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,351:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,351:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,352:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,353:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,353:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,353:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,353:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,353:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,356:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,356:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,356:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,358:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,358:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,359:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,359:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,360:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,360:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,362:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,362:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,362:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,362:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,362:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,362:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,362:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,366:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,366:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,367:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,367:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,369:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,370:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,371:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,371:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,371:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,371:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,374:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,374:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,374:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,374:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,374:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,374:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,374:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,378:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,379:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,379:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,381:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,381:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,381:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,382:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,383:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,383:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,383:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,383:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,383:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,383:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,398:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-12-02 13:14:44,493:INFO:[LightGBM] [Info] Number of positive: 255, number of negative: 255
2025-12-02 13:14:44,500:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000102 seconds.
2025-12-02 13:14:44,500:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-02 13:14:44,500:INFO:[LightGBM] [Info] Total Bins 3937
2025-12-02 13:14:44,500:INFO:[LightGBM] [Info] Number of data points in the train set: 510, number of used features: 28
2025-12-02 13:14:44,500:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-02 13:14:44,501:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,501:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,501:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,502:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,503:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,503:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,503:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,503:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,503:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,503:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,506:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,506:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,506:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,506:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,508:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,509:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,509:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,509:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,511:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,511:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,512:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,512:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,512:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,512:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,512:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,512:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,516:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,517:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,517:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,517:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,519:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,519:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,519:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,521:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,521:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,521:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,521:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,523:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,524:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,524:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,524:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,524:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,524:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,524:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,524:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,529:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,529:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,530:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,531:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,531:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,532:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,533:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,533:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,533:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,533:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,533:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,533:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,533:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,533:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,539:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,540:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,540:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,540:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,540:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,543:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,544:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,544:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,544:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,544:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,544:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,544:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,544:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,544:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,550:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,550:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,551:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,551:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,553:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,553:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,553:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,553:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,556:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,556:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,556:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,556:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,558:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,559:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,560:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,561:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,561:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,562:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,562:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,562:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,562:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,562:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,566:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,566:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,567:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,567:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,568:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-12-02 13:14:44,580:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-12-02 13:14:44,584:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\model_selection\_validation.py:547: FitFailedWarning: 
2 fits failed out of a total of 10.
The score on these train-test partitions for these parameters will be set to 0.0.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
2 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 797, in compare_models
    np.sum(
AssertionError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pipeline.py", line 273, in fit
    X, y, _ = self._fit(X, y, routed_params)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pipeline.py", line 256, in _fit
    X, y = self._memory_transform(
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pipeline.py", line 80, in _transform_one
    output = transformer.transform(*args)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 255, in transform
    output = self.transformer.transform(*args)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 536, in transform
    X, y = self.estimator.fit_resample(X, y)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\imblearn\base.py", line 202, in fit_resample
    return super().fit_resample(X, y, **params)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\base.py", line 1474, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\imblearn\base.py", line 105, in fit_resample
    output = self._fit_resample(X, y, **params)
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\imblearn\over_sampling\_smote\base.py", line 359, in _fit_resample
    nns = self.nn_k_.kneighbors(X_class, return_distance=False)[:, 1:]
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\neighbors\_base.py", line 835, in kneighbors
    raise ValueError(
ValueError: Expected n_neighbors <= n_samples_fit, but n_neighbors = 6, n_samples_fit = 5, n_samples = 5


2025-12-02 13:14:44,584:INFO:Calculating mean and std
2025-12-02 13:14:44,585:INFO:Creating metrics dataframe
2025-12-02 13:14:44,586:INFO:Uploading results into container
2025-12-02 13:14:44,586:INFO:Uploading model into container now
2025-12-02 13:14:44,586:INFO:_master_model_container: 4
2025-12-02 13:14:44,586:INFO:_display_container: 2
2025-12-02 13:14:44,587:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-12-02 13:14:44,587:INFO:create_model() successfully completed......................................
2025-12-02 13:14:44,769:ERROR:create_model() for LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) raised an exception or returned all 0.0:
2025-12-02 13:14:44,770:ERROR:Traceback (most recent call last):
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 797, in compare_models
    np.sum(
AssertionError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 818, in compare_models
    np.sum(
AssertionError

2025-12-02 13:14:44,779:INFO:_master_model_container: 4
2025-12-02 13:14:44,779:INFO:_display_container: 2
2025-12-02 13:14:44,779:INFO:[]
2025-12-02 13:14:44,779:INFO:compare_models() successfully completed......................................
2025-12-02 13:20:10,501:INFO:PyCaret ClassificationExperiment
2025-12-02 13:20:10,501:INFO:Logging name: clf-default-name
2025-12-02 13:20:10,501:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-12-02 13:20:10,501:INFO:version 3.3.2
2025-12-02 13:20:10,501:INFO:Initializing setup()
2025-12-02 13:20:10,501:INFO:self.USI: 1bc8
2025-12-02 13:20:10,501:INFO:self._variable_keys: {'is_multiclass', 'fix_imbalance', 'y_test', 'X', 'y_train', 'fold_shuffle_param', 'X_train', 'target_param', 'idx', '_ml_usecase', 'html_param', 'n_jobs_param', '_available_plots', 'memory', 'seed', 'fold_generator', 'gpu_n_jobs_param', 'data', 'log_plots_param', 'fold_groups_param', 'exp_id', 'logging_param', 'pipeline', 'y', 'X_test', 'USI', 'exp_name_log', 'gpu_param'}
2025-12-02 13:20:10,501:INFO:Checking environment
2025-12-02 13:20:10,501:INFO:python_version: 3.10.19
2025-12-02 13:20:10,501:INFO:python_build: ('main', 'Oct 21 2025 16:41:31')
2025-12-02 13:20:10,501:INFO:machine: AMD64
2025-12-02 13:20:10,501:INFO:platform: Windows-10-10.0.26100-SP0
2025-12-02 13:20:10,501:INFO:Memory: svmem(total=16282144768, available=4751458304, percent=70.8, used=11530686464, free=4751458304)
2025-12-02 13:20:10,501:INFO:Physical Core: 6
2025-12-02 13:20:10,501:INFO:Logical Core: 12
2025-12-02 13:20:10,501:INFO:Checking libraries
2025-12-02 13:20:10,501:INFO:System:
2025-12-02 13:20:10,501:INFO:    python: 3.10.19 | packaged by Anaconda, Inc. | (main, Oct 21 2025, 16:41:31) [MSC v.1929 64 bit (AMD64)]
2025-12-02 13:20:10,501:INFO:executable: c:\Users\OMAR\miniconda3\envs\xgb_env\python.exe
2025-12-02 13:20:10,501:INFO:   machine: Windows-10-10.0.26100-SP0
2025-12-02 13:20:10,501:INFO:PyCaret required dependencies:
2025-12-02 13:20:10,501:INFO:                 pip: 25.3
2025-12-02 13:20:10,501:INFO:          setuptools: 80.9.0
2025-12-02 13:20:10,501:INFO:             pycaret: 3.3.2
2025-12-02 13:20:10,501:INFO:             IPython: 8.37.0
2025-12-02 13:20:10,501:INFO:          ipywidgets: 8.1.8
2025-12-02 13:20:10,501:INFO:                tqdm: 4.67.1
2025-12-02 13:20:10,501:INFO:               numpy: 1.26.4
2025-12-02 13:20:10,501:INFO:              pandas: 2.1.4
2025-12-02 13:20:10,501:INFO:              jinja2: 3.1.6
2025-12-02 13:20:10,501:INFO:               scipy: 1.11.4
2025-12-02 13:20:10,501:INFO:              joblib: 1.3.2
2025-12-02 13:20:10,501:INFO:             sklearn: 1.4.2
2025-12-02 13:20:10,501:INFO:                pyod: 2.0.5
2025-12-02 13:20:10,501:INFO:            imblearn: 0.14.0
2025-12-02 13:20:10,501:INFO:   category_encoders: 2.7.0
2025-12-02 13:20:10,501:INFO:            lightgbm: 4.6.0
2025-12-02 13:20:10,501:INFO:               numba: 0.62.1
2025-12-02 13:20:10,501:INFO:            requests: 2.32.5
2025-12-02 13:20:10,501:INFO:          matplotlib: 3.7.5
2025-12-02 13:20:10,501:INFO:          scikitplot: 0.3.7
2025-12-02 13:20:10,501:INFO:         yellowbrick: 1.5
2025-12-02 13:20:10,501:INFO:              plotly: 5.24.1
2025-12-02 13:20:10,501:INFO:    plotly-resampler: Not installed
2025-12-02 13:20:10,501:INFO:             kaleido: 1.2.0
2025-12-02 13:20:10,501:INFO:           schemdraw: 0.15
2025-12-02 13:20:10,501:INFO:         statsmodels: 0.14.5
2025-12-02 13:20:10,503:INFO:              sktime: 0.26.0
2025-12-02 13:20:10,503:INFO:               tbats: 1.1.3
2025-12-02 13:20:10,503:INFO:            pmdarima: 2.0.4
2025-12-02 13:20:10,503:INFO:              psutil: 7.1.3
2025-12-02 13:20:10,503:INFO:          markupsafe: 3.0.3
2025-12-02 13:20:10,503:INFO:             pickle5: Not installed
2025-12-02 13:20:10,503:INFO:         cloudpickle: 3.1.2
2025-12-02 13:20:10,503:INFO:         deprecation: 2.1.0
2025-12-02 13:20:10,503:INFO:              xxhash: 3.6.0
2025-12-02 13:20:10,503:INFO:           wurlitzer: Not installed
2025-12-02 13:20:10,503:INFO:PyCaret optional dependencies:
2025-12-02 13:20:10,503:INFO:                shap: 0.44.1
2025-12-02 13:20:10,503:INFO:           interpret: 0.7.3
2025-12-02 13:20:10,503:INFO:                umap: 0.5.7
2025-12-02 13:20:10,503:INFO:     ydata_profiling: 4.18.0
2025-12-02 13:20:10,503:INFO:  explainerdashboard: 0.5.1
2025-12-02 13:20:10,503:INFO:             autoviz: Not installed
2025-12-02 13:20:10,503:INFO:           fairlearn: 0.7.0
2025-12-02 13:20:10,503:INFO:          deepchecks: Not installed
2025-12-02 13:20:10,503:INFO:             xgboost: 3.1.2
2025-12-02 13:20:10,503:INFO:            catboost: 1.2.8
2025-12-02 13:20:10,503:INFO:              kmodes: 0.12.2
2025-12-02 13:20:10,503:INFO:             mlxtend: 0.23.4
2025-12-02 13:20:10,503:INFO:       statsforecast: 1.5.0
2025-12-02 13:20:10,503:INFO:        tune_sklearn: Not installed
2025-12-02 13:20:10,503:INFO:                 ray: Not installed
2025-12-02 13:20:10,503:INFO:            hyperopt: 0.2.7
2025-12-02 13:20:10,503:INFO:              optuna: 4.6.0
2025-12-02 13:20:10,503:INFO:               skopt: 0.10.2
2025-12-02 13:20:10,503:INFO:              mlflow: 3.6.0
2025-12-02 13:20:10,503:INFO:              gradio: 6.0.1
2025-12-02 13:20:10,503:INFO:             fastapi: 0.123.0
2025-12-02 13:20:10,503:INFO:             uvicorn: 0.38.0
2025-12-02 13:20:10,503:INFO:              m2cgen: 0.10.0
2025-12-02 13:20:10,503:INFO:           evidently: 0.4.40
2025-12-02 13:20:10,503:INFO:               fugue: 0.8.7
2025-12-02 13:20:10,503:INFO:           streamlit: 1.51.0
2025-12-02 13:20:10,503:INFO:             prophet: Not installed
2025-12-02 13:20:10,503:INFO:None
2025-12-02 13:20:10,503:INFO:Set up data.
2025-12-02 13:20:10,508:INFO:Set up folding strategy.
2025-12-02 13:20:10,508:INFO:Set up train/test split.
2025-12-02 13:20:10,513:INFO:Set up index.
2025-12-02 13:20:10,514:INFO:Assigning column types.
2025-12-02 13:20:10,518:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-12-02 13:20:10,544:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-12-02 13:20:10,544:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-02 13:20:10,559:INFO:Soft dependency imported: xgboost: 3.1.2
2025-12-02 13:20:10,561:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-02 13:20:10,582:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-12-02 13:20:10,582:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-02 13:20:10,603:INFO:Soft dependency imported: xgboost: 3.1.2
2025-12-02 13:20:10,603:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-02 13:20:10,603:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-12-02 13:20:10,630:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-02 13:20:10,645:INFO:Soft dependency imported: xgboost: 3.1.2
2025-12-02 13:20:10,645:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-02 13:20:10,672:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-02 13:20:10,688:INFO:Soft dependency imported: xgboost: 3.1.2
2025-12-02 13:20:10,689:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-02 13:20:10,689:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-12-02 13:20:10,730:INFO:Soft dependency imported: xgboost: 3.1.2
2025-12-02 13:20:10,732:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-02 13:20:10,774:INFO:Soft dependency imported: xgboost: 3.1.2
2025-12-02 13:20:10,774:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-02 13:20:10,779:INFO:Preparing preprocessing pipeline...
2025-12-02 13:20:10,780:INFO:Set up simple imputation.
2025-12-02 13:20:10,780:INFO:Set up removing outliers.
2025-12-02 13:20:10,780:INFO:Set up imbalanced handling.
2025-12-02 13:20:10,780:INFO:Set up feature normalization.
2025-12-02 13:20:10,931:INFO:Finished creating preprocessing pipeline.
2025-12-02 13:20:10,932:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\OMAR\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['SEQN', 'Sex', 'Age', 'Race',
                                             'Education', 'IncomeRatio',
                                             'SystolicBP', 'BMI',
                                             'WaistCircumference', 'Height',
                                             'TotalCholesterol',
                                             'Triglycerides', 'LDL', 'HDL',
                                             'HbA1c', 'Glucose', 'Creatinine',
                                             'UricAcid', 'ALT_Enzyme',
                                             '...
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              random_state=42,
                                                                              sampling_strategy='auto')))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=RobustScaler(copy=True,
                                                             quantile_range=(25.0,
                                                                             75.0),
                                                             unit_variance=False,
                                                             with_centering=True,
                                                             with_scaling=True)))],
         verbose=False)
2025-12-02 13:20:10,932:INFO:Creating final display dataframe.
2025-12-02 13:20:11,340:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target      HeartDisease
2                   Target type            Binary
3           Original data shape        (4370, 29)
4        Transformed data shape        (6963, 29)
5   Transformed train set shape        (5652, 29)
6    Transformed test set shape        (1311, 29)
7              Numeric features                28
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12              Remove outliers              True
13           Outliers threshold              0.05
14                Fix imbalance              True
15         Fix imbalance method             SMOTE
16                    Normalize              True
17             Normalize method            robust
18               Fold Generator   StratifiedKFold
19                  Fold Number                10
20                     CPU Jobs                 1
21                      Use GPU             False
22               Log Experiment             False
23              Experiment Name  clf-default-name
24                          USI              1bc8
2025-12-02 13:20:11,391:INFO:Soft dependency imported: xgboost: 3.1.2
2025-12-02 13:20:11,393:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-02 13:20:11,434:INFO:Soft dependency imported: xgboost: 3.1.2
2025-12-02 13:20:11,434:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-02 13:20:11,434:INFO:setup() successfully completed in 0.94s...............
2025-12-02 13:20:18,716:INFO:Initializing compare_models()
2025-12-02 13:20:18,716:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000217CFFEA950>, include=['xgboost', 'lightgbm'], fold=None, round=4, cross_validation=True, sort=Recall, n_select=3, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x00000217CFFEA950>, 'include': ['xgboost', 'lightgbm'], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Recall', 'n_select': 3, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2025-12-02 13:20:18,716:INFO:Checking exceptions
2025-12-02 13:20:18,723:INFO:Preparing display monitor
2025-12-02 13:20:18,742:INFO:Initializing Extreme Gradient Boosting
2025-12-02 13:20:18,742:INFO:Total runtime is 0.0 minutes
2025-12-02 13:20:18,745:INFO:SubProcess create_model() called ==================================
2025-12-02 13:20:18,745:INFO:Initializing create_model()
2025-12-02 13:20:18,745:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000217CFFEA950>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000217CF5122C0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-02 13:20:18,745:INFO:Checking exceptions
2025-12-02 13:20:18,745:INFO:Importing libraries
2025-12-02 13:20:18,745:INFO:Copying training dataset
2025-12-02 13:20:18,751:INFO:Defining folds
2025-12-02 13:20:18,751:INFO:Declaring metric variables
2025-12-02 13:20:18,756:INFO:Importing untrained model
2025-12-02 13:20:18,758:INFO:Extreme Gradient Boosting Imported successfully
2025-12-02 13:20:18,762:INFO:Starting cross validation
2025-12-02 13:20:18,769:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-12-02 13:20:21,637:INFO:Calculating mean and std
2025-12-02 13:20:21,639:INFO:Creating metrics dataframe
2025-12-02 13:20:21,641:INFO:Uploading results into container
2025-12-02 13:20:21,641:INFO:Uploading model into container now
2025-12-02 13:20:21,641:INFO:_master_model_container: 1
2025-12-02 13:20:21,642:INFO:_display_container: 2
2025-12-02 13:20:21,642:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              feature_weights=None, gamma=None, grow_policy=None,
              importance_type=None, interaction_constraints=None,
              learning_rate=None, max_bin=None, max_cat_threshold=None,
              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,
              max_leaves=None, min_child_weight=None, missing=nan,
              monotone_constraints=None, multi_strategy=None, n_estimators=None,
              n_jobs=1, num_parallel_tree=None, ...)
2025-12-02 13:20:21,642:INFO:create_model() successfully completed......................................
2025-12-02 13:20:21,803:INFO:SubProcess create_model() end ==================================
2025-12-02 13:20:21,803:INFO:Creating metrics dataframe
2025-12-02 13:20:21,812:INFO:Initializing Light Gradient Boosting Machine
2025-12-02 13:20:21,812:INFO:Total runtime is 0.05116743246714274 minutes
2025-12-02 13:20:21,816:INFO:SubProcess create_model() called ==================================
2025-12-02 13:20:21,816:INFO:Initializing create_model()
2025-12-02 13:20:21,816:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000217CFFEA950>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000217CF5122C0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-02 13:20:21,816:INFO:Checking exceptions
2025-12-02 13:20:21,816:INFO:Importing libraries
2025-12-02 13:20:21,816:INFO:Copying training dataset
2025-12-02 13:20:21,821:INFO:Defining folds
2025-12-02 13:20:21,821:INFO:Declaring metric variables
2025-12-02 13:20:21,824:INFO:Importing untrained model
2025-12-02 13:20:21,827:INFO:Light Gradient Boosting Machine Imported successfully
2025-12-02 13:20:21,832:INFO:Starting cross validation
2025-12-02 13:20:21,832:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-12-02 13:20:21,973:INFO:[LightGBM] [Info] Number of positive: 2544, number of negative: 2544
2025-12-02 13:20:21,973:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000655 seconds.
2025-12-02 13:20:21,973:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-02 13:20:21,973:INFO:[LightGBM] [Info] Total Bins 7119
2025-12-02 13:20:21,973:INFO:[LightGBM] [Info] Number of data points in the train set: 5088, number of used features: 28
2025-12-02 13:20:21,973:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-02 13:20:22,323:INFO:[LightGBM] [Info] Number of positive: 2546, number of negative: 2546
2025-12-02 13:20:22,324:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000283 seconds.
2025-12-02 13:20:22,324:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-02 13:20:22,324:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-02 13:20:22,324:INFO:[LightGBM] [Info] Total Bins 7119
2025-12-02 13:20:22,324:INFO:[LightGBM] [Info] Number of data points in the train set: 5092, number of used features: 28
2025-12-02 13:20:22,324:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-02 13:20:22,658:INFO:[LightGBM] [Info] Number of positive: 2543, number of negative: 2543
2025-12-02 13:20:22,659:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000645 seconds.
2025-12-02 13:20:22,659:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-02 13:20:22,659:INFO:[LightGBM] [Info] Total Bins 7106
2025-12-02 13:20:22,660:INFO:[LightGBM] [Info] Number of data points in the train set: 5086, number of used features: 28
2025-12-02 13:20:22,660:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-02 13:20:23,021:INFO:[LightGBM] [Info] Number of positive: 2543, number of negative: 2543
2025-12-02 13:20:23,021:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000628 seconds.
2025-12-02 13:20:23,021:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-02 13:20:23,021:INFO:[LightGBM] [Info] Total Bins 7139
2025-12-02 13:20:23,021:INFO:[LightGBM] [Info] Number of data points in the train set: 5086, number of used features: 28
2025-12-02 13:20:23,021:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-02 13:20:23,360:INFO:[LightGBM] [Info] Number of positive: 2543, number of negative: 2543
2025-12-02 13:20:23,360:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000639 seconds.
2025-12-02 13:20:23,360:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-02 13:20:23,360:INFO:[LightGBM] [Info] Total Bins 7128
2025-12-02 13:20:23,360:INFO:[LightGBM] [Info] Number of data points in the train set: 5086, number of used features: 28
2025-12-02 13:20:23,362:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-02 13:20:23,694:INFO:[LightGBM] [Info] Number of positive: 2544, number of negative: 2544
2025-12-02 13:20:23,694:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000645 seconds.
2025-12-02 13:20:23,694:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-02 13:20:23,694:INFO:[LightGBM] [Info] Total Bins 7140
2025-12-02 13:20:23,694:INFO:[LightGBM] [Info] Number of data points in the train set: 5088, number of used features: 28
2025-12-02 13:20:23,694:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-02 13:20:23,906:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-12-02 13:20:24,042:INFO:[LightGBM] [Info] Number of positive: 2544, number of negative: 2544
2025-12-02 13:20:24,042:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000746 seconds.
2025-12-02 13:20:24,042:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-02 13:20:24,042:INFO:[LightGBM] [Info] Total Bins 7116
2025-12-02 13:20:24,042:INFO:[LightGBM] [Info] Number of data points in the train set: 5088, number of used features: 28
2025-12-02 13:20:24,044:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-02 13:20:24,376:INFO:[LightGBM] [Info] Number of positive: 2544, number of negative: 2544
2025-12-02 13:20:24,377:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000653 seconds.
2025-12-02 13:20:24,377:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-02 13:20:24,377:INFO:[LightGBM] [Info] Total Bins 6961
2025-12-02 13:20:24,378:INFO:[LightGBM] [Info] Number of data points in the train set: 5088, number of used features: 28
2025-12-02 13:20:24,378:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-02 13:20:24,712:INFO:[LightGBM] [Info] Number of positive: 2544, number of negative: 2544
2025-12-02 13:20:24,712:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000282 seconds.
2025-12-02 13:20:24,712:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-02 13:20:24,712:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-02 13:20:24,712:INFO:[LightGBM] [Info] Total Bins 7123
2025-12-02 13:20:24,712:INFO:[LightGBM] [Info] Number of data points in the train set: 5088, number of used features: 28
2025-12-02 13:20:24,712:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-02 13:20:25,045:INFO:[LightGBM] [Info] Number of positive: 2544, number of negative: 2544
2025-12-02 13:20:25,046:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000642 seconds.
2025-12-02 13:20:25,046:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-02 13:20:25,046:INFO:[LightGBM] [Info] Total Bins 7115
2025-12-02 13:20:25,046:INFO:[LightGBM] [Info] Number of data points in the train set: 5088, number of used features: 28
2025-12-02 13:20:25,046:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-02 13:20:25,253:INFO:Calculating mean and std
2025-12-02 13:20:25,253:INFO:Creating metrics dataframe
2025-12-02 13:20:25,253:INFO:Uploading results into container
2025-12-02 13:20:25,256:INFO:Uploading model into container now
2025-12-02 13:20:25,256:INFO:_master_model_container: 2
2025-12-02 13:20:25,256:INFO:_display_container: 2
2025-12-02 13:20:25,256:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-12-02 13:20:25,256:INFO:create_model() successfully completed......................................
2025-12-02 13:20:25,412:INFO:SubProcess create_model() end ==================================
2025-12-02 13:20:25,412:INFO:Creating metrics dataframe
2025-12-02 13:20:25,424:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.

2025-12-02 13:20:25,432:INFO:Initializing create_model()
2025-12-02 13:20:25,432:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000217CFFEA950>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              feature_weights=None, gamma=None, grow_policy=None,
              importance_type=None, interaction_constraints=None,
              learning_rate=None, max_bin=None, max_cat_threshold=None,
              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,
              max_leaves=None, min_child_weight=None, missing=nan,
              monotone_constraints=None, multi_strategy=None, n_estimators=None,
              n_jobs=1, num_parallel_tree=None, ...), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-02 13:20:25,432:INFO:Checking exceptions
2025-12-02 13:20:25,432:INFO:Importing libraries
2025-12-02 13:20:25,432:INFO:Copying training dataset
2025-12-02 13:20:25,436:INFO:Defining folds
2025-12-02 13:20:25,436:INFO:Declaring metric variables
2025-12-02 13:20:25,436:INFO:Importing untrained model
2025-12-02 13:20:25,436:INFO:Declaring custom model
2025-12-02 13:20:25,439:INFO:Extreme Gradient Boosting Imported successfully
2025-12-02 13:20:25,445:INFO:Cross validation set to False
2025-12-02 13:20:25,445:INFO:Fitting Model
2025-12-02 13:20:25,737:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              feature_weights=None, gamma=None, grow_policy=None,
              importance_type=None, interaction_constraints=None,
              learning_rate=None, max_bin=None, max_cat_threshold=None,
              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,
              max_leaves=None, min_child_weight=None, missing=nan,
              monotone_constraints=None, multi_strategy=None, n_estimators=None,
              n_jobs=1, num_parallel_tree=None, ...)
2025-12-02 13:20:25,737:INFO:create_model() successfully completed......................................
2025-12-02 13:20:25,895:INFO:Initializing create_model()
2025-12-02 13:20:25,895:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000217CFFEA950>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-02 13:20:25,896:INFO:Checking exceptions
2025-12-02 13:20:25,897:INFO:Importing libraries
2025-12-02 13:20:25,897:INFO:Copying training dataset
2025-12-02 13:20:25,901:INFO:Defining folds
2025-12-02 13:20:25,901:INFO:Declaring metric variables
2025-12-02 13:20:25,902:INFO:Importing untrained model
2025-12-02 13:20:25,902:INFO:Declaring custom model
2025-12-02 13:20:25,903:INFO:Light Gradient Boosting Machine Imported successfully
2025-12-02 13:20:25,909:INFO:Cross validation set to False
2025-12-02 13:20:25,909:INFO:Fitting Model
2025-12-02 13:20:26,044:INFO:[LightGBM] [Info] Number of positive: 2826, number of negative: 2826
2025-12-02 13:20:26,045:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000708 seconds.
2025-12-02 13:20:26,045:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-02 13:20:26,045:INFO:[LightGBM] [Info] Total Bins 7127
2025-12-02 13:20:26,045:INFO:[LightGBM] [Info] Number of data points in the train set: 5652, number of used features: 28
2025-12-02 13:20:26,045:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-02 13:20:26,245:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-12-02 13:20:26,245:INFO:create_model() successfully completed......................................
2025-12-02 13:20:26,412:INFO:_master_model_container: 2
2025-12-02 13:20:26,412:INFO:_display_container: 2
2025-12-02 13:20:26,414:INFO:[XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              feature_weights=None, gamma=None, grow_policy=None,
              importance_type=None, interaction_constraints=None,
              learning_rate=None, max_bin=None, max_cat_threshold=None,
              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,
              max_leaves=None, min_child_weight=None, missing=nan,
              monotone_constraints=None, multi_strategy=None, n_estimators=None,
              n_jobs=1, num_parallel_tree=None, ...), LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)]
2025-12-02 13:20:26,414:INFO:compare_models() successfully completed......................................
2025-12-02 13:20:48,308:INFO:Initializing tune_model()
2025-12-02 13:20:48,308:INFO:tune_model(estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              feature_weights=None, gamma=None, grow_policy=None,
              importance_type=None, interaction_constraints=None,
              learning_rate=None, max_bin=None, max_cat_threshold=None,
              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,
              max_leaves=None, min_child_weight=None, missing=nan,
              monotone_constraints=None, multi_strategy=None, n_estimators=None,
              n_jobs=1, num_parallel_tree=None, ...), fold=None, round=4, n_iter=5, custom_grid=None, optimize=Recall, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=False, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000217CFFEA950>)
2025-12-02 13:20:48,308:INFO:Checking exceptions
2025-12-02 13:20:48,312:INFO:Copying training dataset
2025-12-02 13:20:48,318:INFO:Checking base model
2025-12-02 13:20:48,318:INFO:Base model : Extreme Gradient Boosting
2025-12-02 13:20:48,318:INFO:Declaring metric variables
2025-12-02 13:20:48,318:INFO:Defining Hyperparameters
2025-12-02 13:20:48,490:INFO:Tuning with n_jobs=1
2025-12-02 13:20:48,490:INFO:Initializing RandomizedSearchCV
2025-12-02 13:21:04,506:INFO:best_params: {'actual_estimator__subsample': 1, 'actual_estimator__scale_pos_weight': 8.5, 'actual_estimator__reg_lambda': 0.0005, 'actual_estimator__reg_alpha': 0.001, 'actual_estimator__n_estimators': 10, 'actual_estimator__min_child_weight': 3, 'actual_estimator__max_depth': 8, 'actual_estimator__learning_rate': 0.0001, 'actual_estimator__colsample_bytree': 0.7}
2025-12-02 13:21:04,506:INFO:Hyperparameter search completed
2025-12-02 13:21:04,506:INFO:SubProcess create_model() called ==================================
2025-12-02 13:21:04,508:INFO:Initializing create_model()
2025-12-02 13:21:04,508:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000217CFFEA950>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              feature_weights=None, gamma=None, grow_policy=None,
              importance_type=None, interaction_constraints=None,
              learning_rate=None, max_bin=None, max_cat_threshold=None,
              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,
              max_leaves=None, min_child_weight=None, missing=nan,
              monotone_constraints=None, multi_strategy=None, n_estimators=None,
              n_jobs=1, num_parallel_tree=None, ...), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000217A8C189D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'subsample': 1, 'scale_pos_weight': 8.5, 'reg_lambda': 0.0005, 'reg_alpha': 0.001, 'n_estimators': 10, 'min_child_weight': 3, 'max_depth': 8, 'learning_rate': 0.0001, 'colsample_bytree': 0.7})
2025-12-02 13:21:04,508:INFO:Checking exceptions
2025-12-02 13:21:04,508:INFO:Importing libraries
2025-12-02 13:21:04,508:INFO:Copying training dataset
2025-12-02 13:21:04,512:INFO:Defining folds
2025-12-02 13:21:04,512:INFO:Declaring metric variables
2025-12-02 13:21:04,512:INFO:Importing untrained model
2025-12-02 13:21:04,512:INFO:Declaring custom model
2025-12-02 13:21:04,512:INFO:Extreme Gradient Boosting Imported successfully
2025-12-02 13:21:04,512:INFO:Starting cross validation
2025-12-02 13:21:04,520:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-12-02 13:21:06,137:INFO:Calculating mean and std
2025-12-02 13:21:06,139:INFO:Creating metrics dataframe
2025-12-02 13:21:06,139:INFO:Finalizing model
2025-12-02 13:21:06,301:INFO:Uploading results into container
2025-12-02 13:21:06,301:INFO:Uploading model into container now
2025-12-02 13:21:06,302:INFO:_master_model_container: 3
2025-12-02 13:21:06,302:INFO:_display_container: 3
2025-12-02 13:21:06,303:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=0.7, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              feature_weights=None, gamma=None, grow_policy=None,
              importance_type=None, interaction_constraints=None,
              learning_rate=0.0001, max_bin=None, max_cat_threshold=None,
              max_cat_to_onehot=None, max_delta_step=None, max_depth=8,
              max_leaves=None, min_child_weight=3, missing=nan,
              monotone_constraints=None, multi_strategy=None, n_estimators=10,
              n_jobs=1, num_parallel_tree=None, ...)
2025-12-02 13:21:06,303:INFO:create_model() successfully completed......................................
2025-12-02 13:21:06,463:INFO:SubProcess create_model() end ==================================
2025-12-02 13:21:06,463:INFO:choose_better activated
2025-12-02 13:21:06,463:INFO:SubProcess create_model() called ==================================
2025-12-02 13:21:06,466:INFO:Initializing create_model()
2025-12-02 13:21:06,466:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000217CFFEA950>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              feature_weights=None, gamma=None, grow_policy=None,
              importance_type=None, interaction_constraints=None,
              learning_rate=None, max_bin=None, max_cat_threshold=None,
              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,
              max_leaves=None, min_child_weight=None, missing=nan,
              monotone_constraints=None, multi_strategy=None, n_estimators=None,
              n_jobs=1, num_parallel_tree=None, ...), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-02 13:21:06,466:INFO:Checking exceptions
2025-12-02 13:21:06,467:INFO:Importing libraries
2025-12-02 13:21:06,467:INFO:Copying training dataset
2025-12-02 13:21:06,472:INFO:Defining folds
2025-12-02 13:21:06,472:INFO:Declaring metric variables
2025-12-02 13:21:06,472:INFO:Importing untrained model
2025-12-02 13:21:06,472:INFO:Declaring custom model
2025-12-02 13:21:06,472:INFO:Extreme Gradient Boosting Imported successfully
2025-12-02 13:21:06,474:INFO:Starting cross validation
2025-12-02 13:21:06,480:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-12-02 13:21:09,282:INFO:Calculating mean and std
2025-12-02 13:21:09,282:INFO:Creating metrics dataframe
2025-12-02 13:21:09,290:INFO:Finalizing model
2025-12-02 13:21:09,573:INFO:Uploading results into container
2025-12-02 13:21:09,573:INFO:Uploading model into container now
2025-12-02 13:21:09,574:INFO:_master_model_container: 4
2025-12-02 13:21:09,574:INFO:_display_container: 4
2025-12-02 13:21:09,575:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              feature_weights=None, gamma=None, grow_policy=None,
              importance_type=None, interaction_constraints=None,
              learning_rate=None, max_bin=None, max_cat_threshold=None,
              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,
              max_leaves=None, min_child_weight=None, missing=nan,
              monotone_constraints=None, multi_strategy=None, n_estimators=None,
              n_jobs=1, num_parallel_tree=None, ...)
2025-12-02 13:21:09,575:INFO:create_model() successfully completed......................................
2025-12-02 13:21:09,732:INFO:SubProcess create_model() end ==================================
2025-12-02 13:21:09,733:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              feature_weights=None, gamma=None, grow_policy=None,
              importance_type=None, interaction_constraints=None,
              learning_rate=None, max_bin=None, max_cat_threshold=None,
              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,
              max_leaves=None, min_child_weight=None, missing=nan,
              monotone_constraints=None, multi_strategy=None, n_estimators=None,
              n_jobs=1, num_parallel_tree=None, ...) result for Recall is 0.1486
2025-12-02 13:21:09,733:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=0.7, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              feature_weights=None, gamma=None, grow_policy=None,
              importance_type=None, interaction_constraints=None,
              learning_rate=0.0001, max_bin=None, max_cat_threshold=None,
              max_cat_to_onehot=None, max_delta_step=None, max_depth=8,
              max_leaves=None, min_child_weight=3, missing=nan,
              monotone_constraints=None, multi_strategy=None, n_estimators=10,
              n_jobs=1, num_parallel_tree=None, ...) result for Recall is 1.0
2025-12-02 13:21:09,733:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=0.7, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              feature_weights=None, gamma=None, grow_policy=None,
              importance_type=None, interaction_constraints=None,
              learning_rate=0.0001, max_bin=None, max_cat_threshold=None,
              max_cat_to_onehot=None, max_delta_step=None, max_depth=8,
              max_leaves=None, min_child_weight=3, missing=nan,
              monotone_constraints=None, multi_strategy=None, n_estimators=10,
              n_jobs=1, num_parallel_tree=None, ...) is best model
2025-12-02 13:21:09,733:INFO:choose_better completed
2025-12-02 13:21:09,733:INFO:_master_model_container: 4
2025-12-02 13:21:09,733:INFO:_display_container: 3
2025-12-02 13:21:09,733:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=0.7, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              feature_weights=None, gamma=None, grow_policy=None,
              importance_type=None, interaction_constraints=None,
              learning_rate=0.0001, max_bin=None, max_cat_threshold=None,
              max_cat_to_onehot=None, max_delta_step=None, max_depth=8,
              max_leaves=None, min_child_weight=3, missing=nan,
              monotone_constraints=None, multi_strategy=None, n_estimators=10,
              n_jobs=1, num_parallel_tree=None, ...)
2025-12-02 13:21:09,733:INFO:tune_model() successfully completed......................................
2025-12-02 13:21:21,667:INFO:Initializing predict_model()
2025-12-02 13:21:21,667:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000217CFFEA950>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=0.7, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              feature_weights=None, gamma=None, grow_policy=None,
              importance_type=None, interaction_constraints=None,
              learning_rate=0.0001, max_bin=None, max_cat_threshold=None,
              max_cat_to_onehot=None, max_delta_step=None, max_depth=8,
              max_leaves=None, min_child_weight=3, missing=nan,
              monotone_constraints=None, multi_strategy=None, n_estimators=10,
              n_jobs=1, num_parallel_tree=None, ...), probability_threshold=None, encoded_labels=False, raw_score=True, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000217D12ABB50>)
2025-12-02 13:21:21,667:INFO:Checking exceptions
2025-12-02 13:21:21,667:INFO:Preloading libraries
2025-12-02 13:21:21,938:INFO:Initializing get_config()
2025-12-02 13:21:21,938:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000217CFFEA950>, variable=target_param)
2025-12-02 13:21:21,938:INFO:Variable:  returned as HeartDisease
2025-12-02 13:21:21,938:INFO:get_config() successfully completed......................................
2025-12-02 13:21:37,285:INFO:Initializing interpret_model()
2025-12-02 13:21:37,285:INFO:interpret_model(estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=0.7, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              feature_weights=None, gamma=None, grow_policy=None,
              importance_type=None, interaction_constraints=None,
              learning_rate=0.0001, max_bin=None, max_cat_threshold=None,
              max_cat_to_onehot=None, max_delta_step=None, max_depth=8,
              max_leaves=None, min_child_weight=3, missing=nan,
              monotone_constraints=None, multi_strategy=None, n_estimators=10,
              n_jobs=1, num_parallel_tree=None, ...), use_train_data=False, X_new_sample=None, y_new_sample=None, feature=None, kwargs={}, observation=None, plot=summary, save=False, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000217CFFEA950>)
2025-12-02 13:21:37,285:INFO:Checking exceptions
2025-12-02 13:21:37,286:INFO:Soft dependency imported: shap: 0.44.1
2025-12-02 13:21:37,338:INFO:plot type: summary
2025-12-02 13:21:37,338:INFO:Creating TreeExplainer
2025-12-02 13:21:48,171:INFO:Initializing finalize_model()
2025-12-02 13:21:48,171:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000217CFFEA950>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=0.7, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              feature_weights=None, gamma=None, grow_policy=None,
              importance_type=None, interaction_constraints=None,
              learning_rate=0.0001, max_bin=None, max_cat_threshold=None,
              max_cat_to_onehot=None, max_delta_step=None, max_depth=8,
              max_leaves=None, min_child_weight=3, missing=nan,
              monotone_constraints=None, multi_strategy=None, n_estimators=10,
              n_jobs=1, num_parallel_tree=None, ...), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2025-12-02 13:21:48,173:INFO:Finalizing XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=0.7, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              feature_weights=None, gamma=None, grow_policy=None,
              importance_type=None, interaction_constraints=None,
              learning_rate=0.0001, max_bin=None, max_cat_threshold=None,
              max_cat_to_onehot=None, max_delta_step=None, max_depth=8,
              max_leaves=None, min_child_weight=3, missing=nan,
              monotone_constraints=None, multi_strategy=None, n_estimators=10,
              n_jobs=1, num_parallel_tree=None, ...)
2025-12-02 13:21:48,174:INFO:Initializing create_model()
2025-12-02 13:21:48,174:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000217CFFEA950>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=0.7, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              feature_weights=None, gamma=None, grow_policy=None,
              importance_type=None, interaction_constraints=None,
              learning_rate=0.0001, max_bin=None, max_cat_threshold=None,
              max_cat_to_onehot=None, max_delta_step=None, max_depth=8,
              max_leaves=None, min_child_weight=3, missing=nan,
              monotone_constraints=None, multi_strategy=None, n_estimators=10,
              n_jobs=1, num_parallel_tree=None, ...), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2025-12-02 13:21:48,174:INFO:Checking exceptions
2025-12-02 13:21:48,179:INFO:Importing libraries
2025-12-02 13:21:48,179:INFO:Copying training dataset
2025-12-02 13:21:48,179:INFO:Defining folds
2025-12-02 13:21:48,179:INFO:Declaring metric variables
2025-12-02 13:21:48,179:INFO:Importing untrained model
2025-12-02 13:21:48,179:INFO:Declaring custom model
2025-12-02 13:21:48,180:INFO:Extreme Gradient Boosting Imported successfully
2025-12-02 13:21:48,187:INFO:Cross validation set to False
2025-12-02 13:21:48,187:INFO:Fitting Model
2025-12-02 13:21:48,384:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['SEQN', 'Sex', 'Age', 'Race',
                                             'Education', 'IncomeRatio',
                                             'SystolicBP', 'BMI',
                                             'WaistCircumference', 'Height',
                                             'TotalCholesterol',
                                             'Triglycerides', 'LDL', 'HDL',
                                             'HbA1c', 'Glucose', 'Creatinine',
                                             'UricAcid', 'ALT_Enzyme',
                                             'Albumin', 'Potassium', 'Sodium',
                                             'GGT_Enzy...
                               gamma=None, grow_policy=None,
                               importance_type=None,
                               interaction_constraints=None,
                               learning_rate=0.0001, max_bin=None,
                               max_cat_threshold=None, max_cat_to_onehot=None,
                               max_delta_step=None, max_depth=8,
                               max_leaves=None, min_child_weight=3, missing=nan,
                               monotone_constraints=None, multi_strategy=None,
                               n_estimators=10, n_jobs=1,
                               num_parallel_tree=None, ...))],
         verbose=False)
2025-12-02 13:21:48,384:INFO:create_model() successfully completed......................................
2025-12-02 13:21:48,552:INFO:_master_model_container: 4
2025-12-02 13:21:48,552:INFO:_display_container: 4
2025-12-02 13:21:48,558:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['SEQN', 'Sex', 'Age', 'Race',
                                             'Education', 'IncomeRatio',
                                             'SystolicBP', 'BMI',
                                             'WaistCircumference', 'Height',
                                             'TotalCholesterol',
                                             'Triglycerides', 'LDL', 'HDL',
                                             'HbA1c', 'Glucose', 'Creatinine',
                                             'UricAcid', 'ALT_Enzyme',
                                             'Albumin', 'Potassium', 'Sodium',
                                             'GGT_Enzy...
                               gamma=None, grow_policy=None,
                               importance_type=None,
                               interaction_constraints=None,
                               learning_rate=0.0001, max_bin=None,
                               max_cat_threshold=None, max_cat_to_onehot=None,
                               max_delta_step=None, max_depth=8,
                               max_leaves=None, min_child_weight=3, missing=nan,
                               monotone_constraints=None, multi_strategy=None,
                               n_estimators=10, n_jobs=1,
                               num_parallel_tree=None, ...))],
         verbose=False)
2025-12-02 13:21:48,559:INFO:finalize_model() successfully completed......................................
2025-12-02 13:21:48,729:INFO:Initializing save_model()
2025-12-02 13:21:48,729:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['SEQN', 'Sex', 'Age', 'Race',
                                             'Education', 'IncomeRatio',
                                             'SystolicBP', 'BMI',
                                             'WaistCircumference', 'Height',
                                             'TotalCholesterol',
                                             'Triglycerides', 'LDL', 'HDL',
                                             'HbA1c', 'Glucose', 'Creatinine',
                                             'UricAcid', 'ALT_Enzyme',
                                             'Albumin', 'Potassium', 'Sodium',
                                             'GGT_Enzy...
                               gamma=None, grow_policy=None,
                               importance_type=None,
                               interaction_constraints=None,
                               learning_rate=0.0001, max_bin=None,
                               max_cat_threshold=None, max_cat_to_onehot=None,
                               max_delta_step=None, max_depth=8,
                               max_leaves=None, min_child_weight=3, missing=nan,
                               monotone_constraints=None, multi_strategy=None,
                               n_estimators=10, n_jobs=1,
                               num_parallel_tree=None, ...))],
         verbose=False), model_name=../models\best_pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\OMAR\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['SEQN', 'Sex', 'Age', 'Race',
                                             'Education', 'IncomeRatio',
                                             'SystolicBP', 'BMI',
                                             'WaistCircumference', 'Height',
                                             'TotalCholesterol',
                                             'Triglycerides', 'LDL', 'HDL',
                                             'HbA1c', 'Glucose', 'Creatinine',
                                             'UricAcid', 'ALT_Enzyme',
                                             '...
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              random_state=42,
                                                                              sampling_strategy='auto')))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=RobustScaler(copy=True,
                                                             quantile_range=(25.0,
                                                                             75.0),
                                                             unit_variance=False,
                                                             with_centering=True,
                                                             with_scaling=True)))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2025-12-02 13:21:48,729:INFO:Adding model into prep_pipe
2025-12-02 13:21:48,729:WARNING:Only Model saved as it was a pipeline.
2025-12-02 13:21:48,762:INFO:../models\best_pipeline.pkl saved in current working directory
2025-12-02 13:21:48,769:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['SEQN', 'Sex', 'Age', 'Race',
                                             'Education', 'IncomeRatio',
                                             'SystolicBP', 'BMI',
                                             'WaistCircumference', 'Height',
                                             'TotalCholesterol',
                                             'Triglycerides', 'LDL', 'HDL',
                                             'HbA1c', 'Glucose', 'Creatinine',
                                             'UricAcid', 'ALT_Enzyme',
                                             'Albumin', 'Potassium', 'Sodium',
                                             'GGT_Enzy...
                               gamma=None, grow_policy=None,
                               importance_type=None,
                               interaction_constraints=None,
                               learning_rate=0.0001, max_bin=None,
                               max_cat_threshold=None, max_cat_to_onehot=None,
                               max_delta_step=None, max_depth=8,
                               max_leaves=None, min_child_weight=3, missing=nan,
                               monotone_constraints=None, multi_strategy=None,
                               n_estimators=10, n_jobs=1,
                               num_parallel_tree=None, ...))],
         verbose=False)
2025-12-02 13:21:48,769:INFO:save_model() successfully completed......................................
2025-12-02 13:26:54,612:INFO:Initializing interpret_model()
2025-12-02 13:26:54,612:INFO:interpret_model(estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=0.7, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              feature_weights=None, gamma=None, grow_policy=None,
              importance_type=None, interaction_constraints=None,
              learning_rate=0.0001, max_bin=None, max_cat_threshold=None,
              max_cat_to_onehot=None, max_delta_step=None, max_depth=8,
              max_leaves=None, min_child_weight=3, missing=nan,
              monotone_constraints=None, multi_strategy=None, n_estimators=10,
              n_jobs=1, num_parallel_tree=None, ...), use_train_data=False, X_new_sample=None, y_new_sample=None, feature=None, kwargs={}, observation=None, plot=summary, save=False, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000217CFFEA950>)
2025-12-02 13:26:54,612:INFO:Checking exceptions
2025-12-02 13:26:54,612:INFO:Soft dependency imported: shap: 0.44.1
2025-12-02 13:26:54,666:INFO:plot type: summary
2025-12-02 13:26:54,666:INFO:Creating TreeExplainer
2025-12-02 13:47:49,559:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-12-02 13:47:49,559:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-12-02 13:47:49,559:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-12-02 13:47:49,559:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-12-02 13:48:29,906:INFO:PyCaret ClassificationExperiment
2025-12-02 13:48:29,906:INFO:Logging name: clf-default-name
2025-12-02 13:48:29,906:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-12-02 13:48:29,906:INFO:version 3.3.2
2025-12-02 13:48:29,906:INFO:Initializing setup()
2025-12-02 13:48:29,906:INFO:self.USI: 0550
2025-12-02 13:48:29,906:INFO:self._variable_keys: {'fold_generator', 'data', 'log_plots_param', 'X', '_ml_usecase', 'y', 'y_train', 'fix_imbalance', 'idx', 'fold_shuffle_param', 'USI', '_available_plots', 'pipeline', 'seed', 'fold_groups_param', 'target_param', 'exp_name_log', 'y_test', 'X_train', 'X_test', 'n_jobs_param', 'is_multiclass', 'gpu_n_jobs_param', 'memory', 'gpu_param', 'logging_param', 'html_param', 'exp_id'}
2025-12-02 13:48:29,907:INFO:Checking environment
2025-12-02 13:48:29,907:INFO:python_version: 3.10.19
2025-12-02 13:48:29,907:INFO:python_build: ('main', 'Oct 21 2025 16:41:31')
2025-12-02 13:48:29,907:INFO:machine: AMD64
2025-12-02 13:48:29,907:INFO:platform: Windows-10-10.0.26100-SP0
2025-12-02 13:48:29,907:INFO:Memory: svmem(total=16282144768, available=5376307200, percent=67.0, used=10905837568, free=5376307200)
2025-12-02 13:48:29,907:INFO:Physical Core: 6
2025-12-02 13:48:29,907:INFO:Logical Core: 12
2025-12-02 13:48:29,907:INFO:Checking libraries
2025-12-02 13:48:29,907:INFO:System:
2025-12-02 13:48:29,908:INFO:    python: 3.10.19 | packaged by Anaconda, Inc. | (main, Oct 21 2025, 16:41:31) [MSC v.1929 64 bit (AMD64)]
2025-12-02 13:48:29,908:INFO:executable: c:\Users\OMAR\miniconda3\envs\xgb_env\python.exe
2025-12-02 13:48:29,908:INFO:   machine: Windows-10-10.0.26100-SP0
2025-12-02 13:48:29,908:INFO:PyCaret required dependencies:
2025-12-02 13:48:29,909:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-02 13:48:30,494:INFO:                 pip: 25.3
2025-12-02 13:48:30,494:INFO:          setuptools: 80.9.0
2025-12-02 13:48:30,494:INFO:             pycaret: 3.3.2
2025-12-02 13:48:30,494:INFO:             IPython: 8.37.0
2025-12-02 13:48:30,494:INFO:          ipywidgets: 8.1.8
2025-12-02 13:48:30,494:INFO:                tqdm: 4.67.1
2025-12-02 13:48:30,494:INFO:               numpy: 1.26.4
2025-12-02 13:48:30,494:INFO:              pandas: 2.1.4
2025-12-02 13:48:30,494:INFO:              jinja2: 3.1.6
2025-12-02 13:48:30,494:INFO:               scipy: 1.11.4
2025-12-02 13:48:30,494:INFO:              joblib: 1.3.2
2025-12-02 13:48:30,494:INFO:             sklearn: 1.4.2
2025-12-02 13:48:30,494:INFO:                pyod: 2.0.5
2025-12-02 13:48:30,494:INFO:            imblearn: 0.14.0
2025-12-02 13:48:30,494:INFO:   category_encoders: 2.7.0
2025-12-02 13:48:30,494:INFO:            lightgbm: 4.6.0
2025-12-02 13:48:30,494:INFO:               numba: 0.62.1
2025-12-02 13:48:30,494:INFO:            requests: 2.32.5
2025-12-02 13:48:30,494:INFO:          matplotlib: 3.7.5
2025-12-02 13:48:30,494:INFO:          scikitplot: 0.3.7
2025-12-02 13:48:30,494:INFO:         yellowbrick: 1.5
2025-12-02 13:48:30,494:INFO:              plotly: 5.24.1
2025-12-02 13:48:30,494:INFO:    plotly-resampler: Not installed
2025-12-02 13:48:30,494:INFO:             kaleido: 1.2.0
2025-12-02 13:48:30,494:INFO:           schemdraw: 0.15
2025-12-02 13:48:30,494:INFO:         statsmodels: 0.14.5
2025-12-02 13:48:30,494:INFO:              sktime: 0.26.0
2025-12-02 13:48:30,494:INFO:               tbats: 1.1.3
2025-12-02 13:48:30,494:INFO:            pmdarima: 2.0.4
2025-12-02 13:48:30,494:INFO:              psutil: 7.1.3
2025-12-02 13:48:30,494:INFO:          markupsafe: 3.0.3
2025-12-02 13:48:30,494:INFO:             pickle5: Not installed
2025-12-02 13:48:30,494:INFO:         cloudpickle: 3.1.2
2025-12-02 13:48:30,494:INFO:         deprecation: 2.1.0
2025-12-02 13:48:30,494:INFO:              xxhash: 3.6.0
2025-12-02 13:48:30,494:INFO:           wurlitzer: Not installed
2025-12-02 13:48:30,494:INFO:PyCaret optional dependencies:
2025-12-02 13:48:33,271:INFO:                shap: 0.49.1
2025-12-02 13:48:33,271:INFO:           interpret: 0.7.3
2025-12-02 13:48:33,271:INFO:                umap: 0.5.7
2025-12-02 13:48:33,271:INFO:     ydata_profiling: 4.18.0
2025-12-02 13:48:33,271:INFO:  explainerdashboard: 0.5.1
2025-12-02 13:48:33,271:INFO:             autoviz: Not installed
2025-12-02 13:48:33,271:INFO:           fairlearn: 0.7.0
2025-12-02 13:48:33,271:INFO:          deepchecks: Not installed
2025-12-02 13:48:33,271:INFO:             xgboost: 2.1.3
2025-12-02 13:48:33,271:INFO:            catboost: 1.2.8
2025-12-02 13:48:33,271:INFO:              kmodes: 0.12.2
2025-12-02 13:48:33,271:INFO:             mlxtend: 0.23.4
2025-12-02 13:48:33,271:INFO:       statsforecast: 1.5.0
2025-12-02 13:48:33,271:INFO:        tune_sklearn: Not installed
2025-12-02 13:48:33,271:INFO:                 ray: Not installed
2025-12-02 13:48:33,271:INFO:            hyperopt: 0.2.7
2025-12-02 13:48:33,271:INFO:              optuna: 4.6.0
2025-12-02 13:48:33,271:INFO:               skopt: 0.10.2
2025-12-02 13:48:33,271:INFO:              mlflow: 3.6.0
2025-12-02 13:48:33,271:INFO:              gradio: 6.0.1
2025-12-02 13:48:33,271:INFO:             fastapi: 0.123.0
2025-12-02 13:48:33,271:INFO:             uvicorn: 0.38.0
2025-12-02 13:48:33,271:INFO:              m2cgen: 0.10.0
2025-12-02 13:48:33,271:INFO:           evidently: 0.4.40
2025-12-02 13:48:33,271:INFO:               fugue: 0.8.7
2025-12-02 13:48:33,271:INFO:           streamlit: 1.51.0
2025-12-02 13:48:33,271:INFO:             prophet: Not installed
2025-12-02 13:48:33,271:INFO:None
2025-12-02 13:48:33,271:INFO:Set up data.
2025-12-02 13:48:33,279:INFO:Set up folding strategy.
2025-12-02 13:48:33,279:INFO:Set up train/test split.
2025-12-02 13:48:33,282:INFO:Set up index.
2025-12-02 13:48:33,282:INFO:Assigning column types.
2025-12-02 13:48:33,282:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-12-02 13:48:33,316:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-12-02 13:48:33,318:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-02 13:48:33,340:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-02 13:48:33,344:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-02 13:48:33,554:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-12-02 13:48:33,554:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-02 13:48:33,571:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-02 13:48:33,571:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-02 13:48:33,574:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-12-02 13:48:33,599:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-02 13:48:33,615:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-02 13:48:33,616:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-02 13:48:33,645:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-02 13:48:33,660:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-02 13:48:33,662:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-02 13:48:33,662:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-12-02 13:48:33,703:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-02 13:48:33,704:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-02 13:48:33,745:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-02 13:48:33,750:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-02 13:48:33,753:INFO:Preparing preprocessing pipeline...
2025-12-02 13:48:33,754:INFO:Set up simple imputation.
2025-12-02 13:48:33,754:INFO:Set up removing outliers.
2025-12-02 13:48:33,754:INFO:Set up imbalanced handling.
2025-12-02 13:48:33,754:INFO:Set up feature normalization.
2025-12-02 13:48:33,932:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\joblib\externals\loky\backend\context.py:136: UserWarning: Could not find the number of physical cores for the following reason:
[WinError 2] El sistema no puede encontrar el archivo especificado
Returning the number of logical cores instead. You can silence this warning by setting LOKY_MAX_CPU_COUNT to the number of cores you want to use.

2025-12-02 13:48:33,959:INFO:Finished creating preprocessing pipeline.
2025-12-02 13:48:33,962:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\OMAR\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['SEQN', 'Sex', 'Age', 'Race',
                                             'Education', 'IncomeRatio',
                                             'SystolicBP', 'BMI',
                                             'WaistCircumference', 'Height',
                                             'TotalCholesterol',
                                             'Triglycerides', 'LDL', 'HDL',
                                             'HbA1c', 'Glucose', 'Creatinine',
                                             'UricAcid', 'ALT_Enzyme',
                                             '...
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              random_state=42,
                                                                              sampling_strategy='auto')))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=RobustScaler(copy=True,
                                                             quantile_range=(25.0,
                                                                             75.0),
                                                             unit_variance=False,
                                                             with_centering=True,
                                                             with_scaling=True)))],
         verbose=False)
2025-12-02 13:48:33,962:INFO:Creating final display dataframe.
2025-12-02 13:48:34,158:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target      HeartDisease
2                   Target type            Binary
3           Original data shape        (4370, 29)
4        Transformed data shape        (6963, 29)
5   Transformed train set shape        (5652, 29)
6    Transformed test set shape        (1311, 29)
7              Numeric features                28
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12              Remove outliers              True
13           Outliers threshold              0.05
14                Fix imbalance              True
15         Fix imbalance method             SMOTE
16                    Normalize              True
17             Normalize method            robust
18               Fold Generator   StratifiedKFold
19                  Fold Number                10
20                     CPU Jobs                 1
21                      Use GPU             False
22               Log Experiment             False
23              Experiment Name  clf-default-name
24                          USI              0550
2025-12-02 13:48:34,208:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-02 13:48:34,211:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-02 13:48:34,255:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-02 13:48:34,256:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-02 13:48:34,258:INFO:setup() successfully completed in 4.36s...............
2025-12-02 13:48:55,894:INFO:PyCaret ClassificationExperiment
2025-12-02 13:48:55,894:INFO:Logging name: clf-default-name
2025-12-02 13:48:55,894:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-12-02 13:48:55,894:INFO:version 3.3.2
2025-12-02 13:48:55,894:INFO:Initializing setup()
2025-12-02 13:48:55,894:INFO:self.USI: d18f
2025-12-02 13:48:55,894:INFO:self._variable_keys: {'fold_generator', 'data', 'log_plots_param', 'X', '_ml_usecase', 'y', 'y_train', 'fix_imbalance', 'idx', 'fold_shuffle_param', 'USI', '_available_plots', 'pipeline', 'seed', 'fold_groups_param', 'target_param', 'exp_name_log', 'y_test', 'X_train', 'X_test', 'n_jobs_param', 'is_multiclass', 'gpu_n_jobs_param', 'memory', 'gpu_param', 'logging_param', 'html_param', 'exp_id'}
2025-12-02 13:48:55,894:INFO:Checking environment
2025-12-02 13:48:55,894:INFO:python_version: 3.10.19
2025-12-02 13:48:55,894:INFO:python_build: ('main', 'Oct 21 2025 16:41:31')
2025-12-02 13:48:55,894:INFO:machine: AMD64
2025-12-02 13:48:55,894:INFO:platform: Windows-10-10.0.26100-SP0
2025-12-02 13:48:55,894:INFO:Memory: svmem(total=16282144768, available=5205602304, percent=68.0, used=11076542464, free=5205602304)
2025-12-02 13:48:55,894:INFO:Physical Core: 6
2025-12-02 13:48:55,894:INFO:Logical Core: 12
2025-12-02 13:48:55,894:INFO:Checking libraries
2025-12-02 13:48:55,894:INFO:System:
2025-12-02 13:48:55,894:INFO:    python: 3.10.19 | packaged by Anaconda, Inc. | (main, Oct 21 2025, 16:41:31) [MSC v.1929 64 bit (AMD64)]
2025-12-02 13:48:55,894:INFO:executable: c:\Users\OMAR\miniconda3\envs\xgb_env\python.exe
2025-12-02 13:48:55,894:INFO:   machine: Windows-10-10.0.26100-SP0
2025-12-02 13:48:55,894:INFO:PyCaret required dependencies:
2025-12-02 13:48:55,894:INFO:                 pip: 25.3
2025-12-02 13:48:55,894:INFO:          setuptools: 80.9.0
2025-12-02 13:48:55,894:INFO:             pycaret: 3.3.2
2025-12-02 13:48:55,894:INFO:             IPython: 8.37.0
2025-12-02 13:48:55,894:INFO:          ipywidgets: 8.1.8
2025-12-02 13:48:55,894:INFO:                tqdm: 4.67.1
2025-12-02 13:48:55,894:INFO:               numpy: 1.26.4
2025-12-02 13:48:55,894:INFO:              pandas: 2.1.4
2025-12-02 13:48:55,894:INFO:              jinja2: 3.1.6
2025-12-02 13:48:55,894:INFO:               scipy: 1.11.4
2025-12-02 13:48:55,894:INFO:              joblib: 1.3.2
2025-12-02 13:48:55,894:INFO:             sklearn: 1.4.2
2025-12-02 13:48:55,894:INFO:                pyod: 2.0.5
2025-12-02 13:48:55,894:INFO:            imblearn: 0.14.0
2025-12-02 13:48:55,894:INFO:   category_encoders: 2.7.0
2025-12-02 13:48:55,894:INFO:            lightgbm: 4.6.0
2025-12-02 13:48:55,894:INFO:               numba: 0.62.1
2025-12-02 13:48:55,894:INFO:            requests: 2.32.5
2025-12-02 13:48:55,894:INFO:          matplotlib: 3.7.5
2025-12-02 13:48:55,894:INFO:          scikitplot: 0.3.7
2025-12-02 13:48:55,894:INFO:         yellowbrick: 1.5
2025-12-02 13:48:55,894:INFO:              plotly: 5.24.1
2025-12-02 13:48:55,894:INFO:    plotly-resampler: Not installed
2025-12-02 13:48:55,894:INFO:             kaleido: 1.2.0
2025-12-02 13:48:55,894:INFO:           schemdraw: 0.15
2025-12-02 13:48:55,894:INFO:         statsmodels: 0.14.5
2025-12-02 13:48:55,894:INFO:              sktime: 0.26.0
2025-12-02 13:48:55,894:INFO:               tbats: 1.1.3
2025-12-02 13:48:55,894:INFO:            pmdarima: 2.0.4
2025-12-02 13:48:55,894:INFO:              psutil: 7.1.3
2025-12-02 13:48:55,894:INFO:          markupsafe: 3.0.3
2025-12-02 13:48:55,894:INFO:             pickle5: Not installed
2025-12-02 13:48:55,894:INFO:         cloudpickle: 3.1.2
2025-12-02 13:48:55,894:INFO:         deprecation: 2.1.0
2025-12-02 13:48:55,894:INFO:              xxhash: 3.6.0
2025-12-02 13:48:55,894:INFO:           wurlitzer: Not installed
2025-12-02 13:48:55,894:INFO:PyCaret optional dependencies:
2025-12-02 13:48:55,894:INFO:                shap: 0.49.1
2025-12-02 13:48:55,894:INFO:           interpret: 0.7.3
2025-12-02 13:48:55,894:INFO:                umap: 0.5.7
2025-12-02 13:48:55,894:INFO:     ydata_profiling: 4.18.0
2025-12-02 13:48:55,894:INFO:  explainerdashboard: 0.5.1
2025-12-02 13:48:55,894:INFO:             autoviz: Not installed
2025-12-02 13:48:55,894:INFO:           fairlearn: 0.7.0
2025-12-02 13:48:55,894:INFO:          deepchecks: Not installed
2025-12-02 13:48:55,894:INFO:             xgboost: 2.1.3
2025-12-02 13:48:55,894:INFO:            catboost: 1.2.8
2025-12-02 13:48:55,894:INFO:              kmodes: 0.12.2
2025-12-02 13:48:55,894:INFO:             mlxtend: 0.23.4
2025-12-02 13:48:55,894:INFO:       statsforecast: 1.5.0
2025-12-02 13:48:55,894:INFO:        tune_sklearn: Not installed
2025-12-02 13:48:55,894:INFO:                 ray: Not installed
2025-12-02 13:48:55,894:INFO:            hyperopt: 0.2.7
2025-12-02 13:48:55,894:INFO:              optuna: 4.6.0
2025-12-02 13:48:55,894:INFO:               skopt: 0.10.2
2025-12-02 13:48:55,894:INFO:              mlflow: 3.6.0
2025-12-02 13:48:55,894:INFO:              gradio: 6.0.1
2025-12-02 13:48:55,894:INFO:             fastapi: 0.123.0
2025-12-02 13:48:55,894:INFO:             uvicorn: 0.38.0
2025-12-02 13:48:55,894:INFO:              m2cgen: 0.10.0
2025-12-02 13:48:55,894:INFO:           evidently: 0.4.40
2025-12-02 13:48:55,900:INFO:               fugue: 0.8.7
2025-12-02 13:48:55,900:INFO:           streamlit: 1.51.0
2025-12-02 13:48:55,900:INFO:             prophet: Not installed
2025-12-02 13:48:55,900:INFO:None
2025-12-02 13:48:55,900:INFO:Set up data.
2025-12-02 13:48:55,905:INFO:Set up folding strategy.
2025-12-02 13:48:55,905:INFO:Set up train/test split.
2025-12-02 13:48:55,910:INFO:Set up index.
2025-12-02 13:48:55,910:INFO:Assigning column types.
2025-12-02 13:48:55,912:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-12-02 13:48:55,940:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-12-02 13:48:55,941:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-02 13:48:55,954:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-02 13:48:55,956:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-02 13:48:55,982:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-12-02 13:48:55,982:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-02 13:48:55,999:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-02 13:48:56,001:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-02 13:48:56,002:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-12-02 13:48:56,026:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-02 13:48:56,040:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-02 13:48:56,045:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-02 13:48:56,071:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-02 13:48:56,086:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-02 13:48:56,088:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-02 13:48:56,089:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-12-02 13:48:56,129:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-02 13:48:56,130:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-02 13:48:56,173:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-02 13:48:56,173:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-02 13:48:56,173:INFO:Preparing preprocessing pipeline...
2025-12-02 13:48:56,173:INFO:Set up simple imputation.
2025-12-02 13:48:56,173:INFO:Set up removing outliers.
2025-12-02 13:48:56,173:INFO:Set up imbalanced handling.
2025-12-02 13:48:56,173:INFO:Set up feature normalization.
2025-12-02 13:48:56,240:INFO:Finished creating preprocessing pipeline.
2025-12-02 13:48:56,244:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\OMAR\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['SEQN', 'Sex', 'Age', 'Race',
                                             'Education', 'IncomeRatio',
                                             'SystolicBP', 'BMI',
                                             'WaistCircumference', 'Height',
                                             'TotalCholesterol',
                                             'Triglycerides', 'LDL', 'HDL',
                                             'HbA1c', 'Glucose', 'Creatinine',
                                             'UricAcid', 'ALT_Enzyme',
                                             '...
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              random_state=42,
                                                                              sampling_strategy='auto')))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=RobustScaler(copy=True,
                                                             quantile_range=(25.0,
                                                                             75.0),
                                                             unit_variance=False,
                                                             with_centering=True,
                                                             with_scaling=True)))],
         verbose=False)
2025-12-02 13:48:56,244:INFO:Creating final display dataframe.
2025-12-02 13:48:56,362:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target      HeartDisease
2                   Target type            Binary
3           Original data shape        (4370, 29)
4        Transformed data shape        (6963, 29)
5   Transformed train set shape        (5652, 29)
6    Transformed test set shape        (1311, 29)
7              Numeric features                28
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12              Remove outliers              True
13           Outliers threshold              0.05
14                Fix imbalance              True
15         Fix imbalance method             SMOTE
16                    Normalize              True
17             Normalize method            robust
18               Fold Generator   StratifiedKFold
19                  Fold Number                10
20                     CPU Jobs                 1
21                      Use GPU             False
22               Log Experiment             False
23              Experiment Name  clf-default-name
24                          USI              d18f
2025-12-02 13:48:56,411:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-02 13:48:56,412:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-02 13:48:56,453:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-02 13:48:56,455:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-02 13:48:56,456:INFO:setup() successfully completed in 0.57s...............
2025-12-02 13:49:04,101:INFO:Initializing compare_models()
2025-12-02 13:49:04,101:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000252509EBF70>, include=['xgboost', 'lightgbm'], fold=None, round=4, cross_validation=True, sort=Recall, n_select=3, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x00000252509EBF70>, 'include': ['xgboost', 'lightgbm'], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Recall', 'n_select': 3, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2025-12-02 13:49:04,101:INFO:Checking exceptions
2025-12-02 13:49:04,106:INFO:Preparing display monitor
2025-12-02 13:49:04,129:INFO:Initializing Extreme Gradient Boosting
2025-12-02 13:49:04,129:INFO:Total runtime is 0.0 minutes
2025-12-02 13:49:04,132:INFO:SubProcess create_model() called ==================================
2025-12-02 13:49:04,133:INFO:Initializing create_model()
2025-12-02 13:49:04,133:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000252509EBF70>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000252509EB460>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-02 13:49:04,133:INFO:Checking exceptions
2025-12-02 13:49:04,133:INFO:Importing libraries
2025-12-02 13:49:04,133:INFO:Copying training dataset
2025-12-02 13:49:04,140:INFO:Defining folds
2025-12-02 13:49:04,140:INFO:Declaring metric variables
2025-12-02 13:49:04,143:INFO:Importing untrained model
2025-12-02 13:49:04,148:INFO:Extreme Gradient Boosting Imported successfully
2025-12-02 13:49:04,153:INFO:Starting cross validation
2025-12-02 13:49:04,155:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-12-02 13:49:07,190:INFO:Calculating mean and std
2025-12-02 13:49:07,190:INFO:Creating metrics dataframe
2025-12-02 13:49:07,190:INFO:Uploading results into container
2025-12-02 13:49:07,190:INFO:Uploading model into container now
2025-12-02 13:49:07,190:INFO:_master_model_container: 1
2025-12-02 13:49:07,190:INFO:_display_container: 2
2025-12-02 13:49:07,194:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2025-12-02 13:49:07,194:INFO:create_model() successfully completed......................................
2025-12-02 13:49:07,364:INFO:SubProcess create_model() end ==================================
2025-12-02 13:49:07,364:INFO:Creating metrics dataframe
2025-12-02 13:49:07,368:INFO:Initializing Light Gradient Boosting Machine
2025-12-02 13:49:07,368:INFO:Total runtime is 0.053984049956003824 minutes
2025-12-02 13:49:07,371:INFO:SubProcess create_model() called ==================================
2025-12-02 13:49:07,371:INFO:Initializing create_model()
2025-12-02 13:49:07,371:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000252509EBF70>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000252509EB460>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-02 13:49:07,371:INFO:Checking exceptions
2025-12-02 13:49:07,371:INFO:Importing libraries
2025-12-02 13:49:07,371:INFO:Copying training dataset
2025-12-02 13:49:07,379:INFO:Defining folds
2025-12-02 13:49:07,379:INFO:Declaring metric variables
2025-12-02 13:49:07,381:INFO:Importing untrained model
2025-12-02 13:49:07,384:INFO:Light Gradient Boosting Machine Imported successfully
2025-12-02 13:49:07,389:INFO:Starting cross validation
2025-12-02 13:49:07,390:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-12-02 13:49:07,523:INFO:[LightGBM] [Info] Number of positive: 2544, number of negative: 2544
2025-12-02 13:49:07,523:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000296 seconds.
2025-12-02 13:49:07,523:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-02 13:49:07,523:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-02 13:49:07,523:INFO:[LightGBM] [Info] Total Bins 7119
2025-12-02 13:49:07,523:INFO:[LightGBM] [Info] Number of data points in the train set: 5088, number of used features: 28
2025-12-02 13:49:07,523:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-02 13:49:07,853:INFO:[LightGBM] [Info] Number of positive: 2546, number of negative: 2546
2025-12-02 13:49:07,853:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000646 seconds.
2025-12-02 13:49:07,853:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-02 13:49:07,853:INFO:[LightGBM] [Info] Total Bins 7119
2025-12-02 13:49:07,853:INFO:[LightGBM] [Info] Number of data points in the train set: 5092, number of used features: 28
2025-12-02 13:49:07,853:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-02 13:49:08,191:INFO:[LightGBM] [Info] Number of positive: 2543, number of negative: 2543
2025-12-02 13:49:08,192:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000705 seconds.
2025-12-02 13:49:08,192:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-02 13:49:08,192:INFO:[LightGBM] [Info] Total Bins 7106
2025-12-02 13:49:08,193:INFO:[LightGBM] [Info] Number of data points in the train set: 5086, number of used features: 28
2025-12-02 13:49:08,193:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-02 13:49:08,540:INFO:[LightGBM] [Info] Number of positive: 2543, number of negative: 2543
2025-12-02 13:49:08,540:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000370 seconds.
2025-12-02 13:49:08,540:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-02 13:49:08,540:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-02 13:49:08,540:INFO:[LightGBM] [Info] Total Bins 7139
2025-12-02 13:49:08,540:INFO:[LightGBM] [Info] Number of data points in the train set: 5086, number of used features: 28
2025-12-02 13:49:08,540:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-02 13:49:08,873:INFO:[LightGBM] [Info] Number of positive: 2543, number of negative: 2543
2025-12-02 13:49:08,873:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000286 seconds.
2025-12-02 13:49:08,873:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-02 13:49:08,873:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-02 13:49:08,873:INFO:[LightGBM] [Info] Total Bins 7128
2025-12-02 13:49:08,873:INFO:[LightGBM] [Info] Number of data points in the train set: 5086, number of used features: 28
2025-12-02 13:49:08,873:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-02 13:49:09,218:INFO:[LightGBM] [Info] Number of positive: 2544, number of negative: 2544
2025-12-02 13:49:09,218:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000644 seconds.
2025-12-02 13:49:09,218:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-02 13:49:09,218:INFO:[LightGBM] [Info] Total Bins 7140
2025-12-02 13:49:09,218:INFO:[LightGBM] [Info] Number of data points in the train set: 5088, number of used features: 28
2025-12-02 13:49:09,218:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-02 13:49:09,429:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-12-02 13:49:09,567:INFO:[LightGBM] [Info] Number of positive: 2544, number of negative: 2544
2025-12-02 13:49:09,567:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000301 seconds.
2025-12-02 13:49:09,567:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-02 13:49:09,567:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-02 13:49:09,567:INFO:[LightGBM] [Info] Total Bins 7116
2025-12-02 13:49:09,569:INFO:[LightGBM] [Info] Number of data points in the train set: 5088, number of used features: 28
2025-12-02 13:49:09,569:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-02 13:49:09,900:INFO:[LightGBM] [Info] Number of positive: 2544, number of negative: 2544
2025-12-02 13:49:09,900:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000657 seconds.
2025-12-02 13:49:09,900:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-02 13:49:09,900:INFO:[LightGBM] [Info] Total Bins 6961
2025-12-02 13:49:09,900:INFO:[LightGBM] [Info] Number of data points in the train set: 5088, number of used features: 28
2025-12-02 13:49:09,900:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-02 13:49:10,240:INFO:[LightGBM] [Info] Number of positive: 2544, number of negative: 2544
2025-12-02 13:49:10,240:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000652 seconds.
2025-12-02 13:49:10,240:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-02 13:49:10,240:INFO:[LightGBM] [Info] Total Bins 7123
2025-12-02 13:49:10,240:INFO:[LightGBM] [Info] Number of data points in the train set: 5088, number of used features: 28
2025-12-02 13:49:10,240:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-02 13:49:10,582:INFO:[LightGBM] [Info] Number of positive: 2544, number of negative: 2544
2025-12-02 13:49:10,582:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000642 seconds.
2025-12-02 13:49:10,582:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-02 13:49:10,582:INFO:[LightGBM] [Info] Total Bins 7115
2025-12-02 13:49:10,584:INFO:[LightGBM] [Info] Number of data points in the train set: 5088, number of used features: 28
2025-12-02 13:49:10,584:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-02 13:49:10,793:INFO:Calculating mean and std
2025-12-02 13:49:10,793:INFO:Creating metrics dataframe
2025-12-02 13:49:10,793:INFO:Uploading results into container
2025-12-02 13:49:10,793:INFO:Uploading model into container now
2025-12-02 13:49:10,793:INFO:_master_model_container: 2
2025-12-02 13:49:10,793:INFO:_display_container: 2
2025-12-02 13:49:10,800:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-12-02 13:49:10,800:INFO:create_model() successfully completed......................................
2025-12-02 13:49:10,960:INFO:SubProcess create_model() end ==================================
2025-12-02 13:49:10,962:INFO:Creating metrics dataframe
2025-12-02 13:49:10,968:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.

2025-12-02 13:49:10,973:INFO:Initializing create_model()
2025-12-02 13:49:10,973:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000252509EBF70>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-02 13:49:10,973:INFO:Checking exceptions
2025-12-02 13:49:10,973:INFO:Importing libraries
2025-12-02 13:49:10,973:INFO:Copying training dataset
2025-12-02 13:49:10,981:INFO:Defining folds
2025-12-02 13:49:10,981:INFO:Declaring metric variables
2025-12-02 13:49:10,981:INFO:Importing untrained model
2025-12-02 13:49:10,981:INFO:Declaring custom model
2025-12-02 13:49:10,982:INFO:Extreme Gradient Boosting Imported successfully
2025-12-02 13:49:10,982:INFO:Cross validation set to False
2025-12-02 13:49:10,982:INFO:Fitting Model
2025-12-02 13:49:11,276:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2025-12-02 13:49:11,276:INFO:create_model() successfully completed......................................
2025-12-02 13:49:11,461:INFO:Initializing create_model()
2025-12-02 13:49:11,461:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000252509EBF70>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-02 13:49:11,461:INFO:Checking exceptions
2025-12-02 13:49:11,462:INFO:Importing libraries
2025-12-02 13:49:11,462:INFO:Copying training dataset
2025-12-02 13:49:11,466:INFO:Defining folds
2025-12-02 13:49:11,466:INFO:Declaring metric variables
2025-12-02 13:49:11,466:INFO:Importing untrained model
2025-12-02 13:49:11,466:INFO:Declaring custom model
2025-12-02 13:49:11,469:INFO:Light Gradient Boosting Machine Imported successfully
2025-12-02 13:49:11,469:INFO:Cross validation set to False
2025-12-02 13:49:11,469:INFO:Fitting Model
2025-12-02 13:49:11,603:INFO:[LightGBM] [Info] Number of positive: 2826, number of negative: 2826
2025-12-02 13:49:11,604:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000342 seconds.
2025-12-02 13:49:11,604:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-02 13:49:11,604:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-02 13:49:11,604:INFO:[LightGBM] [Info] Total Bins 7127
2025-12-02 13:49:11,604:INFO:[LightGBM] [Info] Number of data points in the train set: 5652, number of used features: 28
2025-12-02 13:49:11,604:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-02 13:49:11,800:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-12-02 13:49:11,800:INFO:create_model() successfully completed......................................
2025-12-02 13:49:11,974:INFO:_master_model_container: 2
2025-12-02 13:49:11,979:INFO:_display_container: 2
2025-12-02 13:49:11,979:INFO:[XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...), LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)]
2025-12-02 13:49:11,980:INFO:compare_models() successfully completed......................................
2025-12-02 13:49:17,334:INFO:Initializing tune_model()
2025-12-02 13:49:17,334:INFO:tune_model(estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...), fold=None, round=4, n_iter=5, custom_grid=None, optimize=Recall, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=False, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000252509EBF70>)
2025-12-02 13:49:17,334:INFO:Checking exceptions
2025-12-02 13:49:17,341:INFO:Copying training dataset
2025-12-02 13:49:17,346:INFO:Checking base model
2025-12-02 13:49:17,346:INFO:Base model : Extreme Gradient Boosting
2025-12-02 13:49:17,346:INFO:Declaring metric variables
2025-12-02 13:49:17,346:INFO:Defining Hyperparameters
2025-12-02 13:49:17,504:INFO:Tuning with n_jobs=1
2025-12-02 13:49:17,504:INFO:Initializing RandomizedSearchCV
2025-12-02 13:49:33,690:INFO:best_params: {'actual_estimator__subsample': 1, 'actual_estimator__scale_pos_weight': 8.5, 'actual_estimator__reg_lambda': 0.0005, 'actual_estimator__reg_alpha': 0.001, 'actual_estimator__n_estimators': 10, 'actual_estimator__min_child_weight': 3, 'actual_estimator__max_depth': 8, 'actual_estimator__learning_rate': 0.0001, 'actual_estimator__colsample_bytree': 0.7}
2025-12-02 13:49:33,690:INFO:Hyperparameter search completed
2025-12-02 13:49:33,690:INFO:SubProcess create_model() called ==================================
2025-12-02 13:49:33,690:INFO:Initializing create_model()
2025-12-02 13:49:33,690:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000252509EBF70>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025250992BC0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'subsample': 1, 'scale_pos_weight': 8.5, 'reg_lambda': 0.0005, 'reg_alpha': 0.001, 'n_estimators': 10, 'min_child_weight': 3, 'max_depth': 8, 'learning_rate': 0.0001, 'colsample_bytree': 0.7})
2025-12-02 13:49:33,690:INFO:Checking exceptions
2025-12-02 13:49:33,690:INFO:Importing libraries
2025-12-02 13:49:33,690:INFO:Copying training dataset
2025-12-02 13:49:33,693:INFO:Defining folds
2025-12-02 13:49:33,693:INFO:Declaring metric variables
2025-12-02 13:49:33,693:INFO:Importing untrained model
2025-12-02 13:49:33,693:INFO:Declaring custom model
2025-12-02 13:49:33,693:INFO:Extreme Gradient Boosting Imported successfully
2025-12-02 13:49:33,693:INFO:Starting cross validation
2025-12-02 13:49:33,693:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-12-02 13:49:35,490:INFO:Calculating mean and std
2025-12-02 13:49:35,490:INFO:Creating metrics dataframe
2025-12-02 13:49:35,493:INFO:Finalizing model
2025-12-02 13:49:35,654:INFO:Uploading results into container
2025-12-02 13:49:35,654:INFO:Uploading model into container now
2025-12-02 13:49:35,654:INFO:_master_model_container: 3
2025-12-02 13:49:35,654:INFO:_display_container: 3
2025-12-02 13:49:35,656:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=0.7, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=0.0001, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=8, max_leaves=None,
              min_child_weight=3, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=10, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2025-12-02 13:49:35,656:INFO:create_model() successfully completed......................................
2025-12-02 13:49:35,832:INFO:SubProcess create_model() end ==================================
2025-12-02 13:49:35,832:INFO:choose_better activated
2025-12-02 13:49:35,832:INFO:SubProcess create_model() called ==================================
2025-12-02 13:49:35,832:INFO:Initializing create_model()
2025-12-02 13:49:35,832:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000252509EBF70>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-02 13:49:35,832:INFO:Checking exceptions
2025-12-02 13:49:35,832:INFO:Importing libraries
2025-12-02 13:49:35,832:INFO:Copying training dataset
2025-12-02 13:49:35,839:INFO:Defining folds
2025-12-02 13:49:35,839:INFO:Declaring metric variables
2025-12-02 13:49:35,839:INFO:Importing untrained model
2025-12-02 13:49:35,839:INFO:Declaring custom model
2025-12-02 13:49:35,839:INFO:Extreme Gradient Boosting Imported successfully
2025-12-02 13:49:35,841:INFO:Starting cross validation
2025-12-02 13:49:35,841:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-12-02 13:49:38,733:INFO:Calculating mean and std
2025-12-02 13:49:38,733:INFO:Creating metrics dataframe
2025-12-02 13:49:38,733:INFO:Finalizing model
2025-12-02 13:49:39,031:INFO:Uploading results into container
2025-12-02 13:49:39,031:INFO:Uploading model into container now
2025-12-02 13:49:39,032:INFO:_master_model_container: 4
2025-12-02 13:49:39,032:INFO:_display_container: 4
2025-12-02 13:49:39,032:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2025-12-02 13:49:39,032:INFO:create_model() successfully completed......................................
2025-12-02 13:49:39,208:INFO:SubProcess create_model() end ==================================
2025-12-02 13:49:39,209:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...) result for Recall is 0.1486
2025-12-02 13:49:39,209:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=0.7, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=0.0001, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=8, max_leaves=None,
              min_child_weight=3, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=10, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...) result for Recall is 1.0
2025-12-02 13:49:39,209:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=0.7, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=0.0001, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=8, max_leaves=None,
              min_child_weight=3, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=10, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...) is best model
2025-12-02 13:49:39,209:INFO:choose_better completed
2025-12-02 13:49:39,210:INFO:_master_model_container: 4
2025-12-02 13:49:39,210:INFO:_display_container: 3
2025-12-02 13:49:39,210:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=0.7, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=0.0001, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=8, max_leaves=None,
              min_child_weight=3, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=10, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2025-12-02 13:49:39,210:INFO:tune_model() successfully completed......................................
2025-12-02 13:49:42,954:INFO:Initializing predict_model()
2025-12-02 13:49:42,954:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000252509EBF70>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=0.7, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=0.0001, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=8, max_leaves=None,
              min_child_weight=3, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=10, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...), probability_threshold=None, encoded_labels=False, raw_score=True, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000025258F105E0>)
2025-12-02 13:49:42,954:INFO:Checking exceptions
2025-12-02 13:49:42,954:INFO:Preloading libraries
2025-12-02 13:49:43,185:INFO:Initializing get_config()
2025-12-02 13:49:43,185:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000252509EBF70>, variable=target_param)
2025-12-02 13:49:43,185:INFO:Variable:  returned as HeartDisease
2025-12-02 13:49:43,185:INFO:get_config() successfully completed......................................
2025-12-02 13:49:48,866:INFO:Initializing interpret_model()
2025-12-02 13:49:48,866:INFO:interpret_model(estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=0.7, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=0.0001, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=8, max_leaves=None,
              min_child_weight=3, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=10, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...), use_train_data=False, X_new_sample=None, y_new_sample=None, feature=None, kwargs={}, observation=None, plot=summary, save=False, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000252509EBF70>)
2025-12-02 13:49:48,866:INFO:Checking exceptions
2025-12-02 13:49:48,866:INFO:Soft dependency imported: shap: 0.49.1
2025-12-02 13:49:48,889:INFO:plot type: summary
2025-12-02 13:49:48,889:INFO:Creating TreeExplainer
2025-12-02 13:49:48,892:INFO:Compiling shap values
2025-12-02 13:49:48,939:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:4145: FutureWarning: The NumPy global RNG was seeded by calling `np.random.seed`. In a future version this function will no longer use the global RNG. Pass `rng` explicitly to opt-in to the new behaviour and silence this warning.

2025-12-02 13:49:49,283:INFO:Visual Rendered Successfully
2025-12-02 13:49:49,283:INFO:interpret_model() successfully completed......................................
2025-12-02 13:49:57,179:INFO:Initializing finalize_model()
2025-12-02 13:49:57,179:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000252509EBF70>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=0.7, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=0.0001, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=8, max_leaves=None,
              min_child_weight=3, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=10, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2025-12-02 13:49:57,180:INFO:Finalizing XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=0.7, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=0.0001, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=8, max_leaves=None,
              min_child_weight=3, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=10, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2025-12-02 13:49:57,184:INFO:Initializing create_model()
2025-12-02 13:49:57,184:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000252509EBF70>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=0.7, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=0.0001, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=8, max_leaves=None,
              min_child_weight=3, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=10, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2025-12-02 13:49:57,184:INFO:Checking exceptions
2025-12-02 13:49:57,186:INFO:Importing libraries
2025-12-02 13:49:57,186:INFO:Copying training dataset
2025-12-02 13:49:57,186:INFO:Defining folds
2025-12-02 13:49:57,186:INFO:Declaring metric variables
2025-12-02 13:49:57,186:INFO:Importing untrained model
2025-12-02 13:49:57,186:INFO:Declaring custom model
2025-12-02 13:49:57,187:INFO:Extreme Gradient Boosting Imported successfully
2025-12-02 13:49:57,188:INFO:Cross validation set to False
2025-12-02 13:49:57,188:INFO:Fitting Model
2025-12-02 13:49:57,386:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['SEQN', 'Sex', 'Age', 'Race',
                                             'Education', 'IncomeRatio',
                                             'SystolicBP', 'BMI',
                                             'WaistCircumference', 'Height',
                                             'TotalCholesterol',
                                             'Triglycerides', 'LDL', 'HDL',
                                             'HbA1c', 'Glucose', 'Creatinine',
                                             'UricAcid', 'ALT_Enzyme',
                                             'Albumin', 'Potassium', 'Sodium',
                                             'GGT_Enzy...
                               importance_type=None,
                               interaction_constraints=None,
                               learning_rate=0.0001, max_bin=None,
                               max_cat_threshold=None, max_cat_to_onehot=None,
                               max_delta_step=None, max_depth=8,
                               max_leaves=None, min_child_weight=3, missing=nan,
                               monotone_constraints=None, multi_strategy=None,
                               n_estimators=10, n_jobs=1,
                               num_parallel_tree=None,
                               objective='binary:logistic', ...))],
         verbose=False)
2025-12-02 13:49:57,386:INFO:create_model() successfully completed......................................
2025-12-02 13:49:57,560:INFO:_master_model_container: 4
2025-12-02 13:49:57,560:INFO:_display_container: 4
2025-12-02 13:49:57,566:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['SEQN', 'Sex', 'Age', 'Race',
                                             'Education', 'IncomeRatio',
                                             'SystolicBP', 'BMI',
                                             'WaistCircumference', 'Height',
                                             'TotalCholesterol',
                                             'Triglycerides', 'LDL', 'HDL',
                                             'HbA1c', 'Glucose', 'Creatinine',
                                             'UricAcid', 'ALT_Enzyme',
                                             'Albumin', 'Potassium', 'Sodium',
                                             'GGT_Enzy...
                               importance_type=None,
                               interaction_constraints=None,
                               learning_rate=0.0001, max_bin=None,
                               max_cat_threshold=None, max_cat_to_onehot=None,
                               max_delta_step=None, max_depth=8,
                               max_leaves=None, min_child_weight=3, missing=nan,
                               monotone_constraints=None, multi_strategy=None,
                               n_estimators=10, n_jobs=1,
                               num_parallel_tree=None,
                               objective='binary:logistic', ...))],
         verbose=False)
2025-12-02 13:49:57,566:INFO:finalize_model() successfully completed......................................
2025-12-02 13:49:57,730:INFO:Initializing save_model()
2025-12-02 13:49:57,730:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['SEQN', 'Sex', 'Age', 'Race',
                                             'Education', 'IncomeRatio',
                                             'SystolicBP', 'BMI',
                                             'WaistCircumference', 'Height',
                                             'TotalCholesterol',
                                             'Triglycerides', 'LDL', 'HDL',
                                             'HbA1c', 'Glucose', 'Creatinine',
                                             'UricAcid', 'ALT_Enzyme',
                                             'Albumin', 'Potassium', 'Sodium',
                                             'GGT_Enzy...
                               importance_type=None,
                               interaction_constraints=None,
                               learning_rate=0.0001, max_bin=None,
                               max_cat_threshold=None, max_cat_to_onehot=None,
                               max_delta_step=None, max_depth=8,
                               max_leaves=None, min_child_weight=3, missing=nan,
                               monotone_constraints=None, multi_strategy=None,
                               n_estimators=10, n_jobs=1,
                               num_parallel_tree=None,
                               objective='binary:logistic', ...))],
         verbose=False), model_name=../models\best_pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\OMAR\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['SEQN', 'Sex', 'Age', 'Race',
                                             'Education', 'IncomeRatio',
                                             'SystolicBP', 'BMI',
                                             'WaistCircumference', 'Height',
                                             'TotalCholesterol',
                                             'Triglycerides', 'LDL', 'HDL',
                                             'HbA1c', 'Glucose', 'Creatinine',
                                             'UricAcid', 'ALT_Enzyme',
                                             '...
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              random_state=42,
                                                                              sampling_strategy='auto')))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=RobustScaler(copy=True,
                                                             quantile_range=(25.0,
                                                                             75.0),
                                                             unit_variance=False,
                                                             with_centering=True,
                                                             with_scaling=True)))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2025-12-02 13:49:57,730:INFO:Adding model into prep_pipe
2025-12-02 13:49:57,730:WARNING:Only Model saved as it was a pipeline.
2025-12-02 13:49:57,762:INFO:../models\best_pipeline.pkl saved in current working directory
2025-12-02 13:49:57,768:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['SEQN', 'Sex', 'Age', 'Race',
                                             'Education', 'IncomeRatio',
                                             'SystolicBP', 'BMI',
                                             'WaistCircumference', 'Height',
                                             'TotalCholesterol',
                                             'Triglycerides', 'LDL', 'HDL',
                                             'HbA1c', 'Glucose', 'Creatinine',
                                             'UricAcid', 'ALT_Enzyme',
                                             'Albumin', 'Potassium', 'Sodium',
                                             'GGT_Enzy...
                               importance_type=None,
                               interaction_constraints=None,
                               learning_rate=0.0001, max_bin=None,
                               max_cat_threshold=None, max_cat_to_onehot=None,
                               max_delta_step=None, max_depth=8,
                               max_leaves=None, min_child_weight=3, missing=nan,
                               monotone_constraints=None, multi_strategy=None,
                               n_estimators=10, n_jobs=1,
                               num_parallel_tree=None,
                               objective='binary:logistic', ...))],
         verbose=False)
2025-12-02 13:49:57,768:INFO:save_model() successfully completed......................................
2025-12-02 13:50:12,460:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-12-02 13:50:12,460:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-12-02 13:50:12,460:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-12-02 13:50:12,460:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-12-02 13:50:22,477:INFO:Initializing load_model()
2025-12-02 13:50:22,477:INFO:load_model(model_name=../models/best_pipeline, platform=None, authentication=None, verbose=True)
2025-12-02 13:50:22,528:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-02 13:53:03,989:INFO:Initializing load_model()
2025-12-02 13:53:03,989:INFO:load_model(model_name=../models/best_pipeline, platform=None, authentication=None, verbose=True)
2025-12-02 13:53:08,651:INFO:Initializing predict_model()
2025-12-02 13:53:08,651:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FF2DF81ED0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['SEQN', 'Sex', 'Age', 'Race',
                                             'Education', 'IncomeRatio',
                                             'SystolicBP', 'BMI',
                                             'WaistCircumference', 'Height',
                                             'TotalCholesterol',
                                             'Triglycerides', 'LDL', 'HDL',
                                             'HbA1c', 'Glucose', 'Creatinine',
                                             'UricAcid', 'ALT_Enzyme',
                                             'Albumin', 'Potassium', 'Sodium',
                                             'GGT_Enzyme', 'AST_Enzy...
                               feature_types=None, gamma=None, grow_policy=None,
                               importance_type=None,
                               interaction_constraints=None,
                               learning_rate=0.0001, max_bin=None,
                               max_cat_threshold=None, max_cat_to_onehot=None,
                               max_delta_step=None, max_depth=8,
                               max_leaves=None, min_child_weight=3, missing=nan,
                               monotone_constraints=None, multi_strategy=None,
                               n_estimators=10, n_jobs=1,
                               num_parallel_tree=None, random_state=42, ...))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001FF0C886B00>)
2025-12-02 13:53:08,651:INFO:Checking exceptions
2025-12-02 13:53:08,651:INFO:Preloading libraries
2025-12-02 13:53:08,651:INFO:Set up data.
2025-12-02 13:53:08,660:INFO:Set up index.
2025-12-02 13:53:25,153:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-02 13:53:25,157:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-02 13:53:25,159:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-02 13:53:53,056:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-12-02 13:53:53,056:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-12-02 13:53:53,056:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-12-02 13:53:53,056:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-12-02 13:53:58,058:INFO:Initializing load_model()
2025-12-02 13:53:58,058:INFO:load_model(model_name=../models/best_pipeline, platform=None, authentication=None, verbose=True)
2025-12-02 13:53:58,206:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-02 13:54:08,814:INFO:Initializing predict_model()
2025-12-02 13:54:08,814:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BBD6C8F2B0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['SEQN', 'Sex', 'Age', 'Race',
                                             'Education', 'IncomeRatio',
                                             'SystolicBP', 'BMI',
                                             'WaistCircumference', 'Height',
                                             'TotalCholesterol',
                                             'Triglycerides', 'LDL', 'HDL',
                                             'HbA1c', 'Glucose', 'Creatinine',
                                             'UricAcid', 'ALT_Enzyme',
                                             'Albumin', 'Potassium', 'Sodium',
                                             'GGT_Enzyme', 'AST_Enzy...
                               feature_types=None, gamma=None, grow_policy=None,
                               importance_type=None,
                               interaction_constraints=None,
                               learning_rate=0.0001, max_bin=None,
                               max_cat_threshold=None, max_cat_to_onehot=None,
                               max_delta_step=None, max_depth=8,
                               max_leaves=None, min_child_weight=3, missing=nan,
                               monotone_constraints=None, multi_strategy=None,
                               n_estimators=10, n_jobs=1,
                               num_parallel_tree=None, random_state=42, ...))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001BBF7EC1480>)
2025-12-02 13:54:08,814:INFO:Checking exceptions
2025-12-02 13:54:08,814:INFO:Preloading libraries
2025-12-02 13:54:08,816:INFO:Set up data.
2025-12-02 13:54:08,821:INFO:Set up index.
2025-12-02 13:56:42,962:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-12-02 13:56:42,962:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-12-02 13:56:42,962:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-12-02 13:56:42,962:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-12-02 13:56:46,309:INFO:Initializing load_model()
2025-12-02 13:56:46,309:INFO:load_model(model_name=../models/best_pipeline, platform=None, authentication=None, verbose=True)
2025-12-02 13:56:46,453:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-02 13:56:56,744:INFO:Initializing predict_model()
2025-12-02 13:56:56,744:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000026994C2FD00>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['SEQN', 'Sex', 'Age', 'Race',
                                             'Education', 'IncomeRatio',
                                             'SystolicBP', 'BMI',
                                             'WaistCircumference', 'Height',
                                             'TotalCholesterol',
                                             'Triglycerides', 'LDL', 'HDL',
                                             'HbA1c', 'Glucose', 'Creatinine',
                                             'UricAcid', 'ALT_Enzyme',
                                             'Albumin', 'Potassium', 'Sodium',
                                             'GGT_Enzyme', 'AST_Enzy...
                               feature_types=None, gamma=None, grow_policy=None,
                               importance_type=None,
                               interaction_constraints=None,
                               learning_rate=0.0001, max_bin=None,
                               max_cat_threshold=None, max_cat_to_onehot=None,
                               max_delta_step=None, max_depth=8,
                               max_leaves=None, min_child_weight=3, missing=nan,
                               monotone_constraints=None, multi_strategy=None,
                               n_estimators=10, n_jobs=1,
                               num_parallel_tree=None, random_state=42, ...))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000269B3D02290>)
2025-12-02 13:56:56,744:INFO:Checking exceptions
2025-12-02 13:56:56,744:INFO:Preloading libraries
2025-12-02 13:56:56,744:INFO:Set up data.
2025-12-02 13:56:56,748:INFO:Set up index.
2025-12-02 13:57:30,653:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-12-02 13:57:30,653:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-12-02 13:57:30,653:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-12-02 13:57:30,653:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-12-02 13:57:33,801:INFO:Initializing load_model()
2025-12-02 13:57:33,801:INFO:load_model(model_name=../models/best_pipeline, platform=None, authentication=None, verbose=True)
2025-12-02 13:57:33,949:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-02 13:57:40,921:INFO:Initializing predict_model()
2025-12-02 13:57:40,921:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025D0FC2F7C0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['SEQN', 'Sex', 'Age', 'Race',
                                             'Education', 'IncomeRatio',
                                             'SystolicBP', 'BMI',
                                             'WaistCircumference', 'Height',
                                             'TotalCholesterol',
                                             'Triglycerides', 'LDL', 'HDL',
                                             'HbA1c', 'Glucose', 'Creatinine',
                                             'UricAcid', 'ALT_Enzyme',
                                             'Albumin', 'Potassium', 'Sodium',
                                             'GGT_Enzyme', 'AST_Enzy...
                               feature_types=None, gamma=None, grow_policy=None,
                               importance_type=None,
                               interaction_constraints=None,
                               learning_rate=0.0001, max_bin=None,
                               max_cat_threshold=None, max_cat_to_onehot=None,
                               max_delta_step=None, max_depth=8,
                               max_leaves=None, min_child_weight=3, missing=nan,
                               monotone_constraints=None, multi_strategy=None,
                               n_estimators=10, n_jobs=1,
                               num_parallel_tree=None, random_state=42, ...))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000025D6F90D5A0>)
2025-12-02 13:57:40,921:INFO:Checking exceptions
2025-12-02 13:57:40,921:INFO:Preloading libraries
2025-12-02 13:57:40,921:INFO:Set up data.
2025-12-02 13:57:40,926:INFO:Set up index.
2025-12-02 14:16:21,625:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-12-02 14:16:21,625:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-12-02 14:16:21,625:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-12-02 14:16:21,625:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-12-02 14:16:34,739:INFO:PyCaret ClassificationExperiment
2025-12-02 14:16:34,739:INFO:Logging name: clf-default-name
2025-12-02 14:16:34,739:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-12-02 14:16:34,739:INFO:version 3.3.2
2025-12-02 14:16:34,739:INFO:Initializing setup()
2025-12-02 14:16:34,739:INFO:self.USI: 2858
2025-12-02 14:16:34,740:INFO:self._variable_keys: {'gpu_n_jobs_param', '_available_plots', 'pipeline', 'USI', 'y_train', 'y', 'logging_param', 'n_jobs_param', 'gpu_param', 'X', 'fold_groups_param', 'memory', '_ml_usecase', 'target_param', 'fold_shuffle_param', 'fix_imbalance', 'html_param', 'log_plots_param', 'exp_id', 'X_test', 'X_train', 'seed', 'is_multiclass', 'idx', 'exp_name_log', 'y_test', 'fold_generator', 'data'}
2025-12-02 14:16:34,740:INFO:Checking environment
2025-12-02 14:16:34,740:INFO:python_version: 3.10.19
2025-12-02 14:16:34,740:INFO:python_build: ('main', 'Oct 21 2025 16:41:31')
2025-12-02 14:16:34,740:INFO:machine: AMD64
2025-12-02 14:16:34,740:INFO:platform: Windows-10-10.0.26100-SP0
2025-12-02 14:16:34,740:INFO:Memory: svmem(total=16282144768, available=4702765056, percent=71.1, used=11579379712, free=4702765056)
2025-12-02 14:16:34,740:INFO:Physical Core: 6
2025-12-02 14:16:34,740:INFO:Logical Core: 12
2025-12-02 14:16:34,740:INFO:Checking libraries
2025-12-02 14:16:34,740:INFO:System:
2025-12-02 14:16:34,740:INFO:    python: 3.10.19 | packaged by Anaconda, Inc. | (main, Oct 21 2025, 16:41:31) [MSC v.1929 64 bit (AMD64)]
2025-12-02 14:16:34,740:INFO:executable: c:\Users\OMAR\miniconda3\envs\xgb_env\python.exe
2025-12-02 14:16:34,740:INFO:   machine: Windows-10-10.0.26100-SP0
2025-12-02 14:16:34,740:INFO:PyCaret required dependencies:
2025-12-02 14:16:34,740:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-02 14:16:35,282:INFO:                 pip: 25.3
2025-12-02 14:16:35,282:INFO:          setuptools: 80.9.0
2025-12-02 14:16:35,282:INFO:             pycaret: 3.3.2
2025-12-02 14:16:35,282:INFO:             IPython: 8.37.0
2025-12-02 14:16:35,282:INFO:          ipywidgets: 8.1.8
2025-12-02 14:16:35,282:INFO:                tqdm: 4.67.1
2025-12-02 14:16:35,282:INFO:               numpy: 1.26.4
2025-12-02 14:16:35,282:INFO:              pandas: 2.1.4
2025-12-02 14:16:35,282:INFO:              jinja2: 3.1.6
2025-12-02 14:16:35,282:INFO:               scipy: 1.11.4
2025-12-02 14:16:35,282:INFO:              joblib: 1.3.2
2025-12-02 14:16:35,282:INFO:             sklearn: 1.4.2
2025-12-02 14:16:35,282:INFO:                pyod: 2.0.5
2025-12-02 14:16:35,282:INFO:            imblearn: 0.14.0
2025-12-02 14:16:35,282:INFO:   category_encoders: 2.7.0
2025-12-02 14:16:35,282:INFO:            lightgbm: 4.6.0
2025-12-02 14:16:35,282:INFO:               numba: 0.62.1
2025-12-02 14:16:35,282:INFO:            requests: 2.32.5
2025-12-02 14:16:35,282:INFO:          matplotlib: 3.7.5
2025-12-02 14:16:35,282:INFO:          scikitplot: 0.3.7
2025-12-02 14:16:35,282:INFO:         yellowbrick: 1.5
2025-12-02 14:16:35,282:INFO:              plotly: 5.24.1
2025-12-02 14:16:35,282:INFO:    plotly-resampler: Not installed
2025-12-02 14:16:35,282:INFO:             kaleido: 1.2.0
2025-12-02 14:16:35,282:INFO:           schemdraw: 0.15
2025-12-02 14:16:35,282:INFO:         statsmodels: 0.14.5
2025-12-02 14:16:35,282:INFO:              sktime: 0.26.0
2025-12-02 14:16:35,282:INFO:               tbats: 1.1.3
2025-12-02 14:16:35,282:INFO:            pmdarima: 2.0.4
2025-12-02 14:16:35,282:INFO:              psutil: 7.1.3
2025-12-02 14:16:35,282:INFO:          markupsafe: 3.0.3
2025-12-02 14:16:35,282:INFO:             pickle5: Not installed
2025-12-02 14:16:35,282:INFO:         cloudpickle: 3.1.2
2025-12-02 14:16:35,282:INFO:         deprecation: 2.1.0
2025-12-02 14:16:35,282:INFO:              xxhash: 3.6.0
2025-12-02 14:16:35,282:INFO:           wurlitzer: Not installed
2025-12-02 14:16:35,282:INFO:PyCaret optional dependencies:
2025-12-02 14:16:38,003:INFO:                shap: 0.49.1
2025-12-02 14:16:38,003:INFO:           interpret: 0.7.3
2025-12-02 14:16:38,003:INFO:                umap: 0.5.7
2025-12-02 14:16:38,003:INFO:     ydata_profiling: 4.18.0
2025-12-02 14:16:38,003:INFO:  explainerdashboard: 0.5.1
2025-12-02 14:16:38,003:INFO:             autoviz: Not installed
2025-12-02 14:16:38,003:INFO:           fairlearn: 0.7.0
2025-12-02 14:16:38,003:INFO:          deepchecks: Not installed
2025-12-02 14:16:38,003:INFO:             xgboost: 2.1.3
2025-12-02 14:16:38,003:INFO:            catboost: 1.2.8
2025-12-02 14:16:38,003:INFO:              kmodes: 0.12.2
2025-12-02 14:16:38,003:INFO:             mlxtend: 0.23.4
2025-12-02 14:16:38,003:INFO:       statsforecast: 1.5.0
2025-12-02 14:16:38,003:INFO:        tune_sklearn: Not installed
2025-12-02 14:16:38,003:INFO:                 ray: Not installed
2025-12-02 14:16:38,003:INFO:            hyperopt: 0.2.7
2025-12-02 14:16:38,003:INFO:              optuna: 4.6.0
2025-12-02 14:16:38,003:INFO:               skopt: 0.10.2
2025-12-02 14:16:38,003:INFO:              mlflow: 3.6.0
2025-12-02 14:16:38,003:INFO:              gradio: 6.0.1
2025-12-02 14:16:38,003:INFO:             fastapi: 0.123.0
2025-12-02 14:16:38,003:INFO:             uvicorn: 0.38.0
2025-12-02 14:16:38,003:INFO:              m2cgen: 0.10.0
2025-12-02 14:16:38,003:INFO:           evidently: 0.4.40
2025-12-02 14:16:38,003:INFO:               fugue: 0.8.7
2025-12-02 14:16:38,003:INFO:           streamlit: 1.51.0
2025-12-02 14:16:38,003:INFO:             prophet: Not installed
2025-12-02 14:16:38,003:INFO:None
2025-12-02 14:16:38,003:INFO:Set up data.
2025-12-02 14:16:38,011:INFO:Set up folding strategy.
2025-12-02 14:16:38,011:INFO:Set up train/test split.
2025-12-02 14:16:38,016:INFO:Set up index.
2025-12-02 14:16:38,016:INFO:Assigning column types.
2025-12-02 14:16:38,018:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-12-02 14:16:38,043:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-12-02 14:16:38,043:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-02 14:16:38,066:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-02 14:16:38,068:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-02 14:16:38,112:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-12-02 14:16:38,112:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-02 14:16:38,126:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-02 14:16:38,129:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-02 14:16:38,129:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-12-02 14:16:38,153:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-02 14:16:38,169:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-02 14:16:38,171:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-02 14:16:38,194:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-02 14:16:38,211:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-02 14:16:38,212:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-02 14:16:38,212:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-12-02 14:16:38,256:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-02 14:16:38,256:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-02 14:16:38,300:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-02 14:16:38,301:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-02 14:16:38,303:INFO:Preparing preprocessing pipeline...
2025-12-02 14:16:38,303:INFO:Set up simple imputation.
2025-12-02 14:16:38,306:INFO:Set up encoding of ordinal features.
2025-12-02 14:16:38,309:INFO:Set up encoding of categorical features.
2025-12-02 14:16:38,309:INFO:Set up removing outliers.
2025-12-02 14:16:38,309:INFO:Set up imbalanced handling.
2025-12-02 14:16:38,309:INFO:Set up feature normalization.
2025-12-02 14:16:38,482:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\joblib\externals\loky\backend\context.py:136: UserWarning: Could not find the number of physical cores for the following reason:
[WinError 2] El sistema no puede encontrar el archivo especificado
Returning the number of logical cores instead. You can silence this warning by setting LOKY_MAX_CPU_COUNT to the number of cores you want to use.

2025-12-02 14:16:38,516:INFO:Finished creating preprocessing pipeline.
2025-12-02 14:16:38,532:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\OMAR\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'IncomeRatio', 'SystolicBP',
                                             'BMI', 'WaistCircumference',
                                             'Height', 'TotalCholesterol',
                                             'Triglycerides', 'LDL', 'HDL',
                                             'HbA1c', 'Glucose', 'Creatinine',
                                             'UricAcid', 'ALT_Enzyme',
                                             'Albumin', 'Potassium', 'Sodium',
                                             'G...
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              random_state=42,
                                                                              sampling_strategy='auto')))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=RobustScaler(copy=True,
                                                             quantile_range=(25.0,
                                                                             75.0),
                                                             unit_variance=False,
                                                             with_centering=True,
                                                             with_scaling=True)))],
         verbose=False)
2025-12-02 14:16:38,532:INFO:Creating final display dataframe.
2025-12-02 14:16:39,098:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target      HeartDisease
2                   Target type            Binary
3           Original data shape        (4370, 28)
4        Transformed data shape        (6963, 41)
5   Transformed train set shape        (5652, 41)
6    Transformed test set shape        (1311, 41)
7              Numeric features                20
8          Categorical features                 7
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15              Remove outliers              True
16           Outliers threshold              0.05
17                Fix imbalance              True
18         Fix imbalance method             SMOTE
19                    Normalize              True
20             Normalize method            robust
21               Fold Generator   StratifiedKFold
22                  Fold Number                10
23                     CPU Jobs                 1
24                      Use GPU             False
25               Log Experiment             False
26              Experiment Name  clf-default-name
27                          USI              2858
2025-12-02 14:16:39,147:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-02 14:16:39,148:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-02 14:16:39,191:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-02 14:16:39,194:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-02 14:16:39,195:INFO:setup() successfully completed in 4.46s...............
2025-12-02 14:16:48,566:INFO:Initializing compare_models()
2025-12-02 14:16:48,566:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018E7713F670>, include=['xgboost', 'lightgbm'], fold=None, round=4, cross_validation=True, sort=Recall, n_select=3, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000018E7713F670>, 'include': ['xgboost', 'lightgbm'], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Recall', 'n_select': 3, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2025-12-02 14:16:48,566:INFO:Checking exceptions
2025-12-02 14:16:48,571:INFO:Preparing display monitor
2025-12-02 14:16:48,589:INFO:Initializing Extreme Gradient Boosting
2025-12-02 14:16:48,590:INFO:Total runtime is 1.674493153889974e-05 minutes
2025-12-02 14:16:48,592:INFO:SubProcess create_model() called ==================================
2025-12-02 14:16:48,592:INFO:Initializing create_model()
2025-12-02 14:16:48,592:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018E7713F670>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000018E1E8AAB90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-02 14:16:48,592:INFO:Checking exceptions
2025-12-02 14:16:48,592:INFO:Importing libraries
2025-12-02 14:16:48,592:INFO:Copying training dataset
2025-12-02 14:16:48,595:INFO:Defining folds
2025-12-02 14:16:48,595:INFO:Declaring metric variables
2025-12-02 14:16:48,601:INFO:Importing untrained model
2025-12-02 14:16:48,604:INFO:Extreme Gradient Boosting Imported successfully
2025-12-02 14:16:48,608:INFO:Starting cross validation
2025-12-02 14:16:48,615:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-12-02 14:16:49,789:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-12-02 14:16:52,521:INFO:Calculating mean and std
2025-12-02 14:16:52,524:INFO:Creating metrics dataframe
2025-12-02 14:16:52,527:INFO:Uploading results into container
2025-12-02 14:16:52,527:INFO:Uploading model into container now
2025-12-02 14:16:52,527:INFO:_master_model_container: 1
2025-12-02 14:16:52,527:INFO:_display_container: 2
2025-12-02 14:16:52,529:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2025-12-02 14:16:52,529:INFO:create_model() successfully completed......................................
2025-12-02 14:16:52,689:INFO:SubProcess create_model() end ==================================
2025-12-02 14:16:52,689:INFO:Creating metrics dataframe
2025-12-02 14:16:52,694:INFO:Initializing Light Gradient Boosting Machine
2025-12-02 14:16:52,694:INFO:Total runtime is 0.06841349999109904 minutes
2025-12-02 14:16:52,694:INFO:SubProcess create_model() called ==================================
2025-12-02 14:16:52,694:INFO:Initializing create_model()
2025-12-02 14:16:52,694:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018E7713F670>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000018E1E8AAB90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-02 14:16:52,694:INFO:Checking exceptions
2025-12-02 14:16:52,694:INFO:Importing libraries
2025-12-02 14:16:52,694:INFO:Copying training dataset
2025-12-02 14:16:52,703:INFO:Defining folds
2025-12-02 14:16:52,703:INFO:Declaring metric variables
2025-12-02 14:16:52,709:INFO:Importing untrained model
2025-12-02 14:16:52,712:INFO:Light Gradient Boosting Machine Imported successfully
2025-12-02 14:16:52,716:INFO:Starting cross validation
2025-12-02 14:16:52,725:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-12-02 14:16:52,917:INFO:[LightGBM] [Info] Number of positive: 2543, number of negative: 2543
2025-12-02 14:16:52,918:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000768 seconds.
2025-12-02 14:16:52,918:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-02 14:16:52,918:INFO:[LightGBM] [Info] Total Bins 7795
2025-12-02 14:16:52,918:INFO:[LightGBM] [Info] Number of data points in the train set: 5086, number of used features: 32
2025-12-02 14:16:52,918:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-02 14:16:53,310:INFO:[LightGBM] [Info] Number of positive: 2542, number of negative: 2542
2025-12-02 14:16:53,312:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000438 seconds.
2025-12-02 14:16:53,312:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-02 14:16:53,312:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-02 14:16:53,312:INFO:[LightGBM] [Info] Total Bins 8112
2025-12-02 14:16:53,312:INFO:[LightGBM] [Info] Number of data points in the train set: 5084, number of used features: 32
2025-12-02 14:16:53,312:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-02 14:16:53,693:INFO:[LightGBM] [Info] Number of positive: 2542, number of negative: 2542
2025-12-02 14:16:53,700:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000790 seconds.
2025-12-02 14:16:53,700:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-02 14:16:53,700:INFO:[LightGBM] [Info] Total Bins 7729
2025-12-02 14:16:53,700:INFO:[LightGBM] [Info] Number of data points in the train set: 5084, number of used features: 32
2025-12-02 14:16:53,700:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-02 14:16:54,089:INFO:[LightGBM] [Info] Number of positive: 2543, number of negative: 2543
2025-12-02 14:16:54,089:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000754 seconds.
2025-12-02 14:16:54,090:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-02 14:16:54,090:INFO:[LightGBM] [Info] Total Bins 8008
2025-12-02 14:16:54,090:INFO:[LightGBM] [Info] Number of data points in the train set: 5086, number of used features: 32
2025-12-02 14:16:54,090:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-02 14:16:54,482:INFO:[LightGBM] [Info] Number of positive: 2545, number of negative: 2545
2025-12-02 14:16:54,486:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000778 seconds.
2025-12-02 14:16:54,486:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-02 14:16:54,486:INFO:[LightGBM] [Info] Total Bins 8098
2025-12-02 14:16:54,486:INFO:[LightGBM] [Info] Number of data points in the train set: 5090, number of used features: 32
2025-12-02 14:16:54,486:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-02 14:16:54,713:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-12-02 14:16:54,876:INFO:[LightGBM] [Info] Number of positive: 2543, number of negative: 2543
2025-12-02 14:16:54,877:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000782 seconds.
2025-12-02 14:16:54,877:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-02 14:16:54,877:INFO:[LightGBM] [Info] Total Bins 8053
2025-12-02 14:16:54,879:INFO:[LightGBM] [Info] Number of data points in the train set: 5086, number of used features: 32
2025-12-02 14:16:54,879:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-02 14:16:55,271:INFO:[LightGBM] [Info] Number of positive: 2544, number of negative: 2544
2025-12-02 14:16:55,271:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000762 seconds.
2025-12-02 14:16:55,271:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-02 14:16:55,271:INFO:[LightGBM] [Info] Total Bins 8002
2025-12-02 14:16:55,271:INFO:[LightGBM] [Info] Number of data points in the train set: 5088, number of used features: 32
2025-12-02 14:16:55,271:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-02 14:16:55,661:INFO:[LightGBM] [Info] Number of positive: 2543, number of negative: 2543
2025-12-02 14:16:55,662:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000775 seconds.
2025-12-02 14:16:55,662:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-02 14:16:55,662:INFO:[LightGBM] [Info] Total Bins 7696
2025-12-02 14:16:55,662:INFO:[LightGBM] [Info] Number of data points in the train set: 5086, number of used features: 32
2025-12-02 14:16:55,662:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-02 14:16:56,054:INFO:[LightGBM] [Info] Number of positive: 2544, number of negative: 2544
2025-12-02 14:16:56,056:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000428 seconds.
2025-12-02 14:16:56,056:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-02 14:16:56,056:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-02 14:16:56,056:INFO:[LightGBM] [Info] Total Bins 8012
2025-12-02 14:16:56,056:INFO:[LightGBM] [Info] Number of data points in the train set: 5088, number of used features: 32
2025-12-02 14:16:56,056:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-02 14:16:56,440:INFO:[LightGBM] [Info] Number of positive: 2542, number of negative: 2542
2025-12-02 14:16:56,440:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000770 seconds.
2025-12-02 14:16:56,440:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-02 14:16:56,440:INFO:[LightGBM] [Info] Total Bins 7962
2025-12-02 14:16:56,440:INFO:[LightGBM] [Info] Number of data points in the train set: 5084, number of used features: 32
2025-12-02 14:16:56,440:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-02 14:16:56,666:INFO:Calculating mean and std
2025-12-02 14:16:56,666:INFO:Creating metrics dataframe
2025-12-02 14:16:56,668:INFO:Uploading results into container
2025-12-02 14:16:56,670:INFO:Uploading model into container now
2025-12-02 14:16:56,671:INFO:_master_model_container: 2
2025-12-02 14:16:56,671:INFO:_display_container: 2
2025-12-02 14:16:56,671:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-12-02 14:16:56,672:INFO:create_model() successfully completed......................................
2025-12-02 14:16:56,829:INFO:SubProcess create_model() end ==================================
2025-12-02 14:16:56,829:INFO:Creating metrics dataframe
2025-12-02 14:16:56,832:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.

2025-12-02 14:16:56,840:INFO:Initializing create_model()
2025-12-02 14:16:56,840:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018E7713F670>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-02 14:16:56,840:INFO:Checking exceptions
2025-12-02 14:16:56,844:INFO:Importing libraries
2025-12-02 14:16:56,844:INFO:Copying training dataset
2025-12-02 14:16:56,850:INFO:Defining folds
2025-12-02 14:16:56,850:INFO:Declaring metric variables
2025-12-02 14:16:56,850:INFO:Importing untrained model
2025-12-02 14:16:56,850:INFO:Declaring custom model
2025-12-02 14:16:56,851:INFO:Extreme Gradient Boosting Imported successfully
2025-12-02 14:16:56,856:INFO:Cross validation set to False
2025-12-02 14:16:56,856:INFO:Fitting Model
2025-12-02 14:16:56,890:INFO:Warning: No categorical columns found. Calling 'transform' will only return input data.
2025-12-02 14:16:57,206:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2025-12-02 14:16:57,206:INFO:create_model() successfully completed......................................
2025-12-02 14:16:57,382:INFO:Initializing create_model()
2025-12-02 14:16:57,382:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018E7713F670>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-02 14:16:57,383:INFO:Checking exceptions
2025-12-02 14:16:57,384:INFO:Importing libraries
2025-12-02 14:16:57,384:INFO:Copying training dataset
2025-12-02 14:16:57,389:INFO:Defining folds
2025-12-02 14:16:57,389:INFO:Declaring metric variables
2025-12-02 14:16:57,389:INFO:Importing untrained model
2025-12-02 14:16:57,389:INFO:Declaring custom model
2025-12-02 14:16:57,389:INFO:Light Gradient Boosting Machine Imported successfully
2025-12-02 14:16:57,396:INFO:Cross validation set to False
2025-12-02 14:16:57,396:INFO:Fitting Model
2025-12-02 14:16:57,428:INFO:Warning: No categorical columns found. Calling 'transform' will only return input data.
2025-12-02 14:16:57,563:INFO:[LightGBM] [Info] Number of positive: 2826, number of negative: 2826
2025-12-02 14:16:57,566:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000840 seconds.
2025-12-02 14:16:57,566:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-02 14:16:57,566:INFO:[LightGBM] [Info] Total Bins 8098
2025-12-02 14:16:57,566:INFO:[LightGBM] [Info] Number of data points in the train set: 5652, number of used features: 32
2025-12-02 14:16:57,566:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-02 14:16:57,773:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-12-02 14:16:57,773:INFO:create_model() successfully completed......................................
2025-12-02 14:16:57,940:INFO:_master_model_container: 2
2025-12-02 14:16:57,940:INFO:_display_container: 2
2025-12-02 14:16:57,940:INFO:[XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...), LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)]
2025-12-02 14:16:57,940:INFO:compare_models() successfully completed......................................
2025-12-02 14:17:05,121:INFO:Initializing tune_model()
2025-12-02 14:17:05,121:INFO:tune_model(estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...), fold=None, round=4, n_iter=5, custom_grid=None, optimize=Recall, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=False, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018E7713F670>)
2025-12-02 14:17:05,121:INFO:Checking exceptions
2025-12-02 14:17:05,123:INFO:Copying training dataset
2025-12-02 14:17:05,129:INFO:Checking base model
2025-12-02 14:17:05,129:INFO:Base model : Extreme Gradient Boosting
2025-12-02 14:17:05,129:INFO:Declaring metric variables
2025-12-02 14:17:05,129:INFO:Defining Hyperparameters
2025-12-02 14:17:05,297:INFO:Tuning with n_jobs=1
2025-12-02 14:17:05,297:INFO:Initializing RandomizedSearchCV
2025-12-02 14:17:25,642:INFO:best_params: {'actual_estimator__subsample': 1, 'actual_estimator__scale_pos_weight': 8.5, 'actual_estimator__reg_lambda': 0.0005, 'actual_estimator__reg_alpha': 0.001, 'actual_estimator__n_estimators': 10, 'actual_estimator__min_child_weight': 3, 'actual_estimator__max_depth': 8, 'actual_estimator__learning_rate': 0.0001, 'actual_estimator__colsample_bytree': 0.7}
2025-12-02 14:17:25,642:INFO:Hyperparameter search completed
2025-12-02 14:17:25,642:INFO:SubProcess create_model() called ==================================
2025-12-02 14:17:25,644:INFO:Initializing create_model()
2025-12-02 14:17:25,644:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018E7713F670>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000018E7713ECE0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'subsample': 1, 'scale_pos_weight': 8.5, 'reg_lambda': 0.0005, 'reg_alpha': 0.001, 'n_estimators': 10, 'min_child_weight': 3, 'max_depth': 8, 'learning_rate': 0.0001, 'colsample_bytree': 0.7})
2025-12-02 14:17:25,644:INFO:Checking exceptions
2025-12-02 14:17:25,644:INFO:Importing libraries
2025-12-02 14:17:25,644:INFO:Copying training dataset
2025-12-02 14:17:25,648:INFO:Defining folds
2025-12-02 14:17:25,648:INFO:Declaring metric variables
2025-12-02 14:17:25,648:INFO:Importing untrained model
2025-12-02 14:17:25,648:INFO:Declaring custom model
2025-12-02 14:17:25,650:INFO:Extreme Gradient Boosting Imported successfully
2025-12-02 14:17:25,650:INFO:Starting cross validation
2025-12-02 14:17:25,655:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-12-02 14:17:27,982:INFO:Calculating mean and std
2025-12-02 14:17:27,982:INFO:Creating metrics dataframe
2025-12-02 14:17:27,982:INFO:Finalizing model
2025-12-02 14:17:28,013:INFO:Warning: No categorical columns found. Calling 'transform' will only return input data.
2025-12-02 14:17:28,190:INFO:Uploading results into container
2025-12-02 14:17:28,190:INFO:Uploading model into container now
2025-12-02 14:17:28,190:INFO:_master_model_container: 3
2025-12-02 14:17:28,190:INFO:_display_container: 3
2025-12-02 14:17:28,192:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=0.7, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=0.0001, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=8, max_leaves=None,
              min_child_weight=3, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=10, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2025-12-02 14:17:28,192:INFO:create_model() successfully completed......................................
2025-12-02 14:17:28,363:INFO:SubProcess create_model() end ==================================
2025-12-02 14:17:28,363:INFO:choose_better activated
2025-12-02 14:17:28,363:INFO:SubProcess create_model() called ==================================
2025-12-02 14:17:28,366:INFO:Initializing create_model()
2025-12-02 14:17:28,366:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018E7713F670>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-02 14:17:28,366:INFO:Checking exceptions
2025-12-02 14:17:28,366:INFO:Importing libraries
2025-12-02 14:17:28,366:INFO:Copying training dataset
2025-12-02 14:17:28,371:INFO:Defining folds
2025-12-02 14:17:28,371:INFO:Declaring metric variables
2025-12-02 14:17:28,371:INFO:Importing untrained model
2025-12-02 14:17:28,371:INFO:Declaring custom model
2025-12-02 14:17:28,371:INFO:Extreme Gradient Boosting Imported successfully
2025-12-02 14:17:28,371:INFO:Starting cross validation
2025-12-02 14:17:28,373:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-12-02 14:17:29,512:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-12-02 14:17:32,162:INFO:Calculating mean and std
2025-12-02 14:17:32,162:INFO:Creating metrics dataframe
2025-12-02 14:17:32,162:INFO:Finalizing model
2025-12-02 14:17:32,191:INFO:Warning: No categorical columns found. Calling 'transform' will only return input data.
2025-12-02 14:17:32,504:INFO:Uploading results into container
2025-12-02 14:17:32,506:INFO:Uploading model into container now
2025-12-02 14:17:32,506:INFO:_master_model_container: 4
2025-12-02 14:17:32,506:INFO:_display_container: 4
2025-12-02 14:17:32,506:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2025-12-02 14:17:32,506:INFO:create_model() successfully completed......................................
2025-12-02 14:17:32,680:INFO:SubProcess create_model() end ==================================
2025-12-02 14:17:32,682:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...) result for Recall is 0.0708
2025-12-02 14:17:32,683:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=0.7, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=0.0001, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=8, max_leaves=None,
              min_child_weight=3, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=10, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...) result for Recall is 1.0
2025-12-02 14:17:32,684:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=0.7, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=0.0001, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=8, max_leaves=None,
              min_child_weight=3, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=10, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...) is best model
2025-12-02 14:17:32,684:INFO:choose_better completed
2025-12-02 14:17:32,684:INFO:_master_model_container: 4
2025-12-02 14:17:32,684:INFO:_display_container: 3
2025-12-02 14:17:32,684:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=0.7, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=0.0001, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=8, max_leaves=None,
              min_child_weight=3, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=10, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2025-12-02 14:17:32,684:INFO:tune_model() successfully completed......................................
2025-12-02 14:17:36,755:INFO:Initializing predict_model()
2025-12-02 14:17:36,755:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018E7713F670>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=0.7, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=0.0001, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=8, max_leaves=None,
              min_child_weight=3, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=10, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...), probability_threshold=None, encoded_labels=False, raw_score=True, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000018E1E81C940>)
2025-12-02 14:17:36,755:INFO:Checking exceptions
2025-12-02 14:17:36,755:INFO:Preloading libraries
2025-12-02 14:17:37,112:INFO:Initializing get_config()
2025-12-02 14:17:37,112:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018E7713F670>, variable=target_param)
2025-12-02 14:17:37,112:INFO:Variable:  returned as HeartDisease
2025-12-02 14:17:37,112:INFO:get_config() successfully completed......................................
2025-12-02 14:17:44,690:INFO:Initializing interpret_model()
2025-12-02 14:17:44,690:INFO:interpret_model(estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=0.7, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=0.0001, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=8, max_leaves=None,
              min_child_weight=3, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=10, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...), use_train_data=False, X_new_sample=None, y_new_sample=None, feature=None, kwargs={}, observation=None, plot=summary, save=False, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018E7713F670>)
2025-12-02 14:17:44,690:INFO:Checking exceptions
2025-12-02 14:17:44,690:INFO:Soft dependency imported: shap: 0.49.1
2025-12-02 14:17:44,784:INFO:plot type: summary
2025-12-02 14:17:44,784:INFO:Creating TreeExplainer
2025-12-02 14:17:44,784:INFO:Compiling shap values
2025-12-02 14:17:44,840:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:4145: FutureWarning: The NumPy global RNG was seeded by calling `np.random.seed`. In a future version this function will no longer use the global RNG. Pass `rng` explicitly to opt-in to the new behaviour and silence this warning.

2025-12-02 14:17:45,181:INFO:Visual Rendered Successfully
2025-12-02 14:17:45,181:INFO:interpret_model() successfully completed......................................
2025-12-02 14:17:49,776:INFO:Initializing finalize_model()
2025-12-02 14:17:49,776:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018E7713F670>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=0.7, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=0.0001, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=8, max_leaves=None,
              min_child_weight=3, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=10, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2025-12-02 14:17:49,776:INFO:Finalizing XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=0.7, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=0.0001, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=8, max_leaves=None,
              min_child_weight=3, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=10, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2025-12-02 14:17:49,782:INFO:Initializing create_model()
2025-12-02 14:17:49,782:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018E7713F670>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=0.7, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=0.0001, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=8, max_leaves=None,
              min_child_weight=3, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=10, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2025-12-02 14:17:49,782:INFO:Checking exceptions
2025-12-02 14:17:49,785:INFO:Importing libraries
2025-12-02 14:17:49,785:INFO:Copying training dataset
2025-12-02 14:17:49,785:INFO:Defining folds
2025-12-02 14:17:49,785:INFO:Declaring metric variables
2025-12-02 14:17:49,785:INFO:Importing untrained model
2025-12-02 14:17:49,785:INFO:Declaring custom model
2025-12-02 14:17:49,786:INFO:Extreme Gradient Boosting Imported successfully
2025-12-02 14:17:49,790:INFO:Cross validation set to False
2025-12-02 14:17:49,790:INFO:Fitting Model
2025-12-02 14:17:49,824:INFO:Warning: No categorical columns found. Calling 'transform' will only return input data.
2025-12-02 14:21:15,655:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-12-02 14:21:15,655:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-12-02 14:21:15,655:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-12-02 14:21:15,655:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-12-02 14:21:42,329:INFO:PyCaret ClassificationExperiment
2025-12-02 14:21:42,329:INFO:Logging name: clf-default-name
2025-12-02 14:21:42,329:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-12-02 14:21:42,329:INFO:version 3.3.2
2025-12-02 14:21:42,329:INFO:Initializing setup()
2025-12-02 14:21:42,329:INFO:self.USI: 447b
2025-12-02 14:21:42,330:INFO:self._variable_keys: {'html_param', 'X_test', 'fold_shuffle_param', 'fix_imbalance', 'memory', 'gpu_n_jobs_param', 'log_plots_param', 'X_train', 'idx', 'y_train', '_available_plots', 'logging_param', '_ml_usecase', 'data', 'y_test', 'seed', 'exp_id', 'fold_groups_param', 'gpu_param', 'X', 'is_multiclass', 'y', 'pipeline', 'fold_generator', 'n_jobs_param', 'exp_name_log', 'target_param', 'USI'}
2025-12-02 14:21:42,330:INFO:Checking environment
2025-12-02 14:21:42,330:INFO:python_version: 3.10.19
2025-12-02 14:21:42,330:INFO:python_build: ('main', 'Oct 21 2025 16:41:31')
2025-12-02 14:21:42,330:INFO:machine: AMD64
2025-12-02 14:21:42,330:INFO:platform: Windows-10-10.0.26100-SP0
2025-12-02 14:21:42,330:INFO:Memory: svmem(total=16282144768, available=4728811520, percent=71.0, used=11553333248, free=4728811520)
2025-12-02 14:21:42,330:INFO:Physical Core: 6
2025-12-02 14:21:42,330:INFO:Logical Core: 12
2025-12-02 14:21:42,330:INFO:Checking libraries
2025-12-02 14:21:42,330:INFO:System:
2025-12-02 14:21:42,330:INFO:    python: 3.10.19 | packaged by Anaconda, Inc. | (main, Oct 21 2025, 16:41:31) [MSC v.1929 64 bit (AMD64)]
2025-12-02 14:21:42,330:INFO:executable: c:\Users\OMAR\miniconda3\envs\xgb_env\python.exe
2025-12-02 14:21:42,330:INFO:   machine: Windows-10-10.0.26100-SP0
2025-12-02 14:21:42,330:INFO:PyCaret required dependencies:
2025-12-02 14:21:42,332:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-02 14:21:42,907:INFO:                 pip: 25.3
2025-12-02 14:21:42,907:INFO:          setuptools: 80.9.0
2025-12-02 14:21:42,907:INFO:             pycaret: 3.3.2
2025-12-02 14:21:42,907:INFO:             IPython: 8.37.0
2025-12-02 14:21:42,907:INFO:          ipywidgets: 8.1.8
2025-12-02 14:21:42,907:INFO:                tqdm: 4.67.1
2025-12-02 14:21:42,907:INFO:               numpy: 1.26.4
2025-12-02 14:21:42,907:INFO:              pandas: 2.1.4
2025-12-02 14:21:42,907:INFO:              jinja2: 3.1.6
2025-12-02 14:21:42,907:INFO:               scipy: 1.11.4
2025-12-02 14:21:42,907:INFO:              joblib: 1.3.2
2025-12-02 14:21:42,907:INFO:             sklearn: 1.4.2
2025-12-02 14:21:42,907:INFO:                pyod: 2.0.5
2025-12-02 14:21:42,907:INFO:            imblearn: 0.14.0
2025-12-02 14:21:42,907:INFO:   category_encoders: 2.7.0
2025-12-02 14:21:42,907:INFO:            lightgbm: 4.6.0
2025-12-02 14:21:42,907:INFO:               numba: 0.62.1
2025-12-02 14:21:42,907:INFO:            requests: 2.32.5
2025-12-02 14:21:42,907:INFO:          matplotlib: 3.7.5
2025-12-02 14:21:42,907:INFO:          scikitplot: 0.3.7
2025-12-02 14:21:42,907:INFO:         yellowbrick: 1.5
2025-12-02 14:21:42,907:INFO:              plotly: 5.24.1
2025-12-02 14:21:42,907:INFO:    plotly-resampler: Not installed
2025-12-02 14:21:42,907:INFO:             kaleido: 1.2.0
2025-12-02 14:21:42,907:INFO:           schemdraw: 0.15
2025-12-02 14:21:42,907:INFO:         statsmodels: 0.14.5
2025-12-02 14:21:42,907:INFO:              sktime: 0.26.0
2025-12-02 14:21:42,907:INFO:               tbats: 1.1.3
2025-12-02 14:21:42,907:INFO:            pmdarima: 2.0.4
2025-12-02 14:21:42,907:INFO:              psutil: 7.1.3
2025-12-02 14:21:42,907:INFO:          markupsafe: 3.0.3
2025-12-02 14:21:42,907:INFO:             pickle5: Not installed
2025-12-02 14:21:42,907:INFO:         cloudpickle: 3.1.2
2025-12-02 14:21:42,907:INFO:         deprecation: 2.1.0
2025-12-02 14:21:42,907:INFO:              xxhash: 3.6.0
2025-12-02 14:21:42,907:INFO:           wurlitzer: Not installed
2025-12-02 14:21:42,907:INFO:PyCaret optional dependencies:
2025-12-02 14:21:45,607:INFO:                shap: 0.49.1
2025-12-02 14:21:45,607:INFO:           interpret: 0.7.3
2025-12-02 14:21:45,607:INFO:                umap: 0.5.7
2025-12-02 14:21:45,607:INFO:     ydata_profiling: 4.18.0
2025-12-02 14:21:45,607:INFO:  explainerdashboard: 0.5.1
2025-12-02 14:21:45,607:INFO:             autoviz: Not installed
2025-12-02 14:21:45,607:INFO:           fairlearn: 0.7.0
2025-12-02 14:21:45,607:INFO:          deepchecks: Not installed
2025-12-02 14:21:45,607:INFO:             xgboost: 2.1.3
2025-12-02 14:21:45,607:INFO:            catboost: 1.2.8
2025-12-02 14:21:45,607:INFO:              kmodes: 0.12.2
2025-12-02 14:21:45,607:INFO:             mlxtend: 0.23.4
2025-12-02 14:21:45,607:INFO:       statsforecast: 1.5.0
2025-12-02 14:21:45,607:INFO:        tune_sklearn: Not installed
2025-12-02 14:21:45,607:INFO:                 ray: Not installed
2025-12-02 14:21:45,607:INFO:            hyperopt: 0.2.7
2025-12-02 14:21:45,607:INFO:              optuna: 4.6.0
2025-12-02 14:21:45,607:INFO:               skopt: 0.10.2
2025-12-02 14:21:45,607:INFO:              mlflow: 3.6.0
2025-12-02 14:21:45,607:INFO:              gradio: 6.0.1
2025-12-02 14:21:45,607:INFO:             fastapi: 0.123.0
2025-12-02 14:21:45,607:INFO:             uvicorn: 0.38.0
2025-12-02 14:21:45,607:INFO:              m2cgen: 0.10.0
2025-12-02 14:21:45,607:INFO:           evidently: 0.4.40
2025-12-02 14:21:45,607:INFO:               fugue: 0.8.7
2025-12-02 14:21:45,607:INFO:           streamlit: 1.51.0
2025-12-02 14:21:45,607:INFO:             prophet: Not installed
2025-12-02 14:21:45,607:INFO:None
2025-12-02 14:21:45,607:INFO:Set up data.
2025-12-02 14:21:45,613:INFO:Set up folding strategy.
2025-12-02 14:21:45,613:INFO:Set up train/test split.
2025-12-02 14:21:45,618:INFO:Set up index.
2025-12-02 14:21:45,618:INFO:Assigning column types.
2025-12-02 14:21:45,621:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-12-02 14:21:45,650:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-12-02 14:21:45,652:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-02 14:21:45,673:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-02 14:21:45,675:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-02 14:21:45,890:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-12-02 14:21:45,890:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-02 14:21:45,906:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-02 14:21:45,908:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-02 14:21:45,908:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-12-02 14:21:45,934:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-02 14:21:45,951:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-02 14:21:45,951:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-02 14:21:45,974:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-02 14:21:45,990:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-02 14:21:45,994:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-02 14:21:45,994:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-12-02 14:21:46,035:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-02 14:21:46,038:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-02 14:21:46,079:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-02 14:21:46,080:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-02 14:21:46,082:INFO:Preparing preprocessing pipeline...
2025-12-02 14:21:46,082:INFO:Set up simple imputation.
2025-12-02 14:21:46,085:INFO:Set up encoding of ordinal features.
2025-12-02 14:21:46,089:INFO:Set up encoding of categorical features.
2025-12-02 14:21:46,089:INFO:Set up imbalanced handling.
2025-12-02 14:21:46,089:INFO:Set up feature normalization.
2025-12-02 14:21:46,162:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\joblib\externals\loky\backend\context.py:136: UserWarning: Could not find the number of physical cores for the following reason:
[WinError 2] El sistema no puede encontrar el archivo especificado
Returning the number of logical cores instead. You can silence this warning by setting LOKY_MAX_CPU_COUNT to the number of cores you want to use.

2025-12-02 14:21:46,189:INFO:Finished creating preprocessing pipeline.
2025-12-02 14:21:46,206:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\OMAR\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'IncomeRatio', 'SystolicBP',
                                             'BMI', 'WaistCircumference',
                                             'Height', 'TotalCholesterol',
                                             'Triglycerides', 'LDL', 'HDL',
                                             'HbA1c', 'Glucose', 'Creatinine',
                                             'UricAcid', 'ALT_Enzyme',
                                             'Albumin', 'Potassium', 'Sodium',
                                             'G...
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              random_state=42,
                                                                              sampling_strategy='auto')))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=RobustScaler(copy=True,
                                                             quantile_range=(25.0,
                                                                             75.0),
                                                             unit_variance=False,
                                                             with_centering=True,
                                                             with_scaling=True)))],
         verbose=False)
2025-12-02 14:21:46,206:INFO:Creating final display dataframe.
2025-12-02 14:21:46,441:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target      HeartDisease
2                   Target type            Binary
3           Original data shape        (4370, 28)
4        Transformed data shape        (7253, 41)
5   Transformed train set shape        (5942, 41)
6    Transformed test set shape        (1311, 41)
7              Numeric features                20
8          Categorical features                 7
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15                Fix imbalance              True
16         Fix imbalance method             SMOTE
17                    Normalize              True
18             Normalize method            robust
19               Fold Generator   StratifiedKFold
20                  Fold Number                10
21                     CPU Jobs                 1
22                      Use GPU             False
23               Log Experiment             False
24              Experiment Name  clf-default-name
25                          USI              447b
2025-12-02 14:21:46,491:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-02 14:21:46,494:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-02 14:21:46,540:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-02 14:21:46,542:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-02 14:21:46,542:INFO:setup() successfully completed in 4.22s...............
2025-12-02 14:21:51,135:INFO:Initializing compare_models()
2025-12-02 14:21:51,135:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025D27710AF0>, include=['xgboost', 'lightgbm'], fold=None, round=4, cross_validation=True, sort=Recall, n_select=3, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000025D27710AF0>, 'include': ['xgboost', 'lightgbm'], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Recall', 'n_select': 3, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2025-12-02 14:21:51,135:INFO:Checking exceptions
2025-12-02 14:21:51,139:INFO:Preparing display monitor
2025-12-02 14:21:51,158:INFO:Initializing Extreme Gradient Boosting
2025-12-02 14:21:51,158:INFO:Total runtime is 0.0 minutes
2025-12-02 14:21:51,160:INFO:SubProcess create_model() called ==================================
2025-12-02 14:21:51,160:INFO:Initializing create_model()
2025-12-02 14:21:51,160:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025D27710AF0>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025D27711570>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-02 14:21:51,160:INFO:Checking exceptions
2025-12-02 14:21:51,160:INFO:Importing libraries
2025-12-02 14:21:51,160:INFO:Copying training dataset
2025-12-02 14:21:51,166:INFO:Defining folds
2025-12-02 14:21:51,166:INFO:Declaring metric variables
2025-12-02 14:21:51,170:INFO:Importing untrained model
2025-12-02 14:21:51,172:INFO:Extreme Gradient Boosting Imported successfully
2025-12-02 14:21:51,177:INFO:Starting cross validation
2025-12-02 14:21:51,179:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-12-02 14:21:54,145:INFO:Calculating mean and std
2025-12-02 14:21:54,146:INFO:Creating metrics dataframe
2025-12-02 14:21:54,148:INFO:Uploading results into container
2025-12-02 14:21:54,148:INFO:Uploading model into container now
2025-12-02 14:21:54,148:INFO:_master_model_container: 1
2025-12-02 14:21:54,148:INFO:_display_container: 2
2025-12-02 14:21:54,148:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2025-12-02 14:21:54,148:INFO:create_model() successfully completed......................................
2025-12-02 14:21:54,313:INFO:SubProcess create_model() end ==================================
2025-12-02 14:21:54,313:INFO:Creating metrics dataframe
2025-12-02 14:21:54,318:INFO:Initializing Light Gradient Boosting Machine
2025-12-02 14:21:54,318:INFO:Total runtime is 0.05267279942830404 minutes
2025-12-02 14:21:54,321:INFO:SubProcess create_model() called ==================================
2025-12-02 14:21:54,321:INFO:Initializing create_model()
2025-12-02 14:21:54,321:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025D27710AF0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025D27711570>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-02 14:21:54,321:INFO:Checking exceptions
2025-12-02 14:21:54,321:INFO:Importing libraries
2025-12-02 14:21:54,321:INFO:Copying training dataset
2025-12-02 14:21:54,327:INFO:Defining folds
2025-12-02 14:21:54,327:INFO:Declaring metric variables
2025-12-02 14:21:54,331:INFO:Importing untrained model
2025-12-02 14:21:54,332:INFO:Light Gradient Boosting Machine Imported successfully
2025-12-02 14:21:54,339:INFO:Starting cross validation
2025-12-02 14:21:54,341:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-12-02 14:21:54,436:INFO:[LightGBM] [Info] Number of positive: 2673, number of negative: 2673
2025-12-02 14:21:54,439:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000491 seconds.
2025-12-02 14:21:54,439:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-02 14:21:54,439:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-02 14:21:54,439:INFO:[LightGBM] [Info] Total Bins 8133
2025-12-02 14:21:54,439:INFO:[LightGBM] [Info] Number of data points in the train set: 5346, number of used features: 32
2025-12-02 14:21:54,439:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-02 14:21:54,740:INFO:[LightGBM] [Info] Number of positive: 2674, number of negative: 2674
2025-12-02 14:21:54,740:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000805 seconds.
2025-12-02 14:21:54,740:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-02 14:21:54,740:INFO:[LightGBM] [Info] Total Bins 8153
2025-12-02 14:21:54,740:INFO:[LightGBM] [Info] Number of data points in the train set: 5348, number of used features: 32
2025-12-02 14:21:54,740:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-02 14:21:55,058:INFO:[LightGBM] [Info] Number of positive: 2674, number of negative: 2674
2025-12-02 14:21:55,059:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000467 seconds.
2025-12-02 14:21:55,059:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-02 14:21:55,059:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-02 14:21:55,059:INFO:[LightGBM] [Info] Total Bins 7980
2025-12-02 14:21:55,059:INFO:[LightGBM] [Info] Number of data points in the train set: 5348, number of used features: 32
2025-12-02 14:21:55,060:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-02 14:21:55,359:INFO:[LightGBM] [Info] Number of positive: 2674, number of negative: 2674
2025-12-02 14:21:55,361:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000972 seconds.
2025-12-02 14:21:55,361:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-02 14:21:55,361:INFO:[LightGBM] [Info] Total Bins 8160
2025-12-02 14:21:55,361:INFO:[LightGBM] [Info] Number of data points in the train set: 5348, number of used features: 32
2025-12-02 14:21:55,362:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-02 14:21:55,680:INFO:[LightGBM] [Info] Number of positive: 2674, number of negative: 2674
2025-12-02 14:21:55,680:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000808 seconds.
2025-12-02 14:21:55,680:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-02 14:21:55,680:INFO:[LightGBM] [Info] Total Bins 8160
2025-12-02 14:21:55,680:INFO:[LightGBM] [Info] Number of data points in the train set: 5348, number of used features: 32
2025-12-02 14:21:55,680:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-02 14:21:55,918:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-12-02 14:21:56,003:INFO:[LightGBM] [Info] Number of positive: 2674, number of negative: 2674
2025-12-02 14:21:56,003:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000812 seconds.
2025-12-02 14:21:56,003:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-02 14:21:56,003:INFO:[LightGBM] [Info] Total Bins 8148
2025-12-02 14:21:56,006:INFO:[LightGBM] [Info] Number of data points in the train set: 5348, number of used features: 32
2025-12-02 14:21:56,006:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-02 14:21:56,318:INFO:[LightGBM] [Info] Number of positive: 2674, number of negative: 2674
2025-12-02 14:21:56,320:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000825 seconds.
2025-12-02 14:21:56,320:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-02 14:21:56,320:INFO:[LightGBM] [Info] Total Bins 8151
2025-12-02 14:21:56,320:INFO:[LightGBM] [Info] Number of data points in the train set: 5348, number of used features: 32
2025-12-02 14:21:56,320:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-02 14:21:56,669:INFO:[LightGBM] [Info] Number of positive: 2674, number of negative: 2674
2025-12-02 14:21:56,669:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000839 seconds.
2025-12-02 14:21:56,669:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-02 14:21:56,671:INFO:[LightGBM] [Info] Total Bins 7762
2025-12-02 14:21:56,671:INFO:[LightGBM] [Info] Number of data points in the train set: 5348, number of used features: 32
2025-12-02 14:21:56,671:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-02 14:21:57,003:INFO:[LightGBM] [Info] Number of positive: 2674, number of negative: 2674
2025-12-02 14:21:57,004:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000801 seconds.
2025-12-02 14:21:57,004:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-02 14:21:57,004:INFO:[LightGBM] [Info] Total Bins 8160
2025-12-02 14:21:57,005:INFO:[LightGBM] [Info] Number of data points in the train set: 5348, number of used features: 32
2025-12-02 14:21:57,005:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-02 14:21:57,321:INFO:[LightGBM] [Info] Number of positive: 2674, number of negative: 2674
2025-12-02 14:21:57,322:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000817 seconds.
2025-12-02 14:21:57,322:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-02 14:21:57,322:INFO:[LightGBM] [Info] Total Bins 8148
2025-12-02 14:21:57,322:INFO:[LightGBM] [Info] Number of data points in the train set: 5348, number of used features: 32
2025-12-02 14:21:57,322:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-02 14:21:57,567:INFO:Calculating mean and std
2025-12-02 14:21:57,568:INFO:Creating metrics dataframe
2025-12-02 14:21:57,569:INFO:Uploading results into container
2025-12-02 14:21:57,569:INFO:Uploading model into container now
2025-12-02 14:21:57,569:INFO:_master_model_container: 2
2025-12-02 14:21:57,569:INFO:_display_container: 2
2025-12-02 14:21:57,571:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-12-02 14:21:57,571:INFO:create_model() successfully completed......................................
2025-12-02 14:21:57,733:INFO:SubProcess create_model() end ==================================
2025-12-02 14:21:57,733:INFO:Creating metrics dataframe
2025-12-02 14:21:57,737:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.

2025-12-02 14:21:57,748:INFO:Initializing create_model()
2025-12-02 14:21:57,748:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025D27710AF0>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-02 14:21:57,748:INFO:Checking exceptions
2025-12-02 14:21:57,750:INFO:Importing libraries
2025-12-02 14:21:57,750:INFO:Copying training dataset
2025-12-02 14:21:57,758:INFO:Defining folds
2025-12-02 14:21:57,758:INFO:Declaring metric variables
2025-12-02 14:21:57,758:INFO:Importing untrained model
2025-12-02 14:21:57,758:INFO:Declaring custom model
2025-12-02 14:21:57,758:INFO:Extreme Gradient Boosting Imported successfully
2025-12-02 14:21:57,759:INFO:Cross validation set to False
2025-12-02 14:21:57,759:INFO:Fitting Model
2025-12-02 14:21:57,796:INFO:Warning: No categorical columns found. Calling 'transform' will only return input data.
2025-12-02 14:21:58,040:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2025-12-02 14:21:58,040:INFO:create_model() successfully completed......................................
2025-12-02 14:21:58,221:INFO:Initializing create_model()
2025-12-02 14:21:58,223:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025D27710AF0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-02 14:21:58,223:INFO:Checking exceptions
2025-12-02 14:21:58,224:INFO:Importing libraries
2025-12-02 14:21:58,224:INFO:Copying training dataset
2025-12-02 14:21:58,232:INFO:Defining folds
2025-12-02 14:21:58,232:INFO:Declaring metric variables
2025-12-02 14:21:58,232:INFO:Importing untrained model
2025-12-02 14:21:58,232:INFO:Declaring custom model
2025-12-02 14:21:58,233:INFO:Light Gradient Boosting Machine Imported successfully
2025-12-02 14:21:58,234:INFO:Cross validation set to False
2025-12-02 14:21:58,234:INFO:Fitting Model
2025-12-02 14:21:58,267:INFO:Warning: No categorical columns found. Calling 'transform' will only return input data.
2025-12-02 14:21:58,314:INFO:[LightGBM] [Info] Number of positive: 2971, number of negative: 2971
2025-12-02 14:21:58,316:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001020 seconds.
2025-12-02 14:21:58,316:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-02 14:21:58,316:INFO:[LightGBM] [Info] Total Bins 8160
2025-12-02 14:21:58,316:INFO:[LightGBM] [Info] Number of data points in the train set: 5942, number of used features: 32
2025-12-02 14:21:58,316:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-12-02 14:21:58,543:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-12-02 14:21:58,543:INFO:create_model() successfully completed......................................
2025-12-02 14:21:58,721:INFO:_master_model_container: 2
2025-12-02 14:21:58,721:INFO:_display_container: 2
2025-12-02 14:21:58,721:INFO:[XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...), LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)]
2025-12-02 14:21:58,723:INFO:compare_models() successfully completed......................................
2025-12-02 14:22:11,390:INFO:Initializing tune_model()
2025-12-02 14:22:11,390:INFO:tune_model(estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...), fold=None, round=4, n_iter=5, custom_grid=None, optimize=Recall, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=False, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025D27710AF0>)
2025-12-02 14:22:11,390:INFO:Checking exceptions
2025-12-02 14:22:11,396:INFO:Copying training dataset
2025-12-02 14:22:11,400:INFO:Checking base model
2025-12-02 14:22:11,400:INFO:Base model : Extreme Gradient Boosting
2025-12-02 14:22:11,401:INFO:Declaring metric variables
2025-12-02 14:22:11,401:INFO:Defining Hyperparameters
2025-12-02 14:22:11,562:INFO:Tuning with n_jobs=1
2025-12-02 14:22:11,562:INFO:Initializing RandomizedSearchCV
2025-12-02 14:22:28,423:INFO:best_params: {'actual_estimator__subsample': 1, 'actual_estimator__scale_pos_weight': 8.5, 'actual_estimator__reg_lambda': 0.0005, 'actual_estimator__reg_alpha': 0.001, 'actual_estimator__n_estimators': 10, 'actual_estimator__min_child_weight': 3, 'actual_estimator__max_depth': 8, 'actual_estimator__learning_rate': 0.0001, 'actual_estimator__colsample_bytree': 0.7}
2025-12-02 14:22:28,423:INFO:Hyperparameter search completed
2025-12-02 14:22:28,423:INFO:SubProcess create_model() called ==================================
2025-12-02 14:22:28,423:INFO:Initializing create_model()
2025-12-02 14:22:28,423:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025D27710AF0>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025D2772C490>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'subsample': 1, 'scale_pos_weight': 8.5, 'reg_lambda': 0.0005, 'reg_alpha': 0.001, 'n_estimators': 10, 'min_child_weight': 3, 'max_depth': 8, 'learning_rate': 0.0001, 'colsample_bytree': 0.7})
2025-12-02 14:22:28,423:INFO:Checking exceptions
2025-12-02 14:22:28,423:INFO:Importing libraries
2025-12-02 14:22:28,423:INFO:Copying training dataset
2025-12-02 14:22:28,430:INFO:Defining folds
2025-12-02 14:22:28,430:INFO:Declaring metric variables
2025-12-02 14:22:28,430:INFO:Importing untrained model
2025-12-02 14:22:28,430:INFO:Declaring custom model
2025-12-02 14:22:28,430:INFO:Extreme Gradient Boosting Imported successfully
2025-12-02 14:22:28,430:INFO:Starting cross validation
2025-12-02 14:22:28,432:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-12-02 14:22:29,923:INFO:Calculating mean and std
2025-12-02 14:22:29,923:INFO:Creating metrics dataframe
2025-12-02 14:22:29,923:INFO:Finalizing model
2025-12-02 14:22:29,953:INFO:Warning: No categorical columns found. Calling 'transform' will only return input data.
2025-12-02 14:22:30,042:INFO:Uploading results into container
2025-12-02 14:22:30,042:INFO:Uploading model into container now
2025-12-02 14:22:30,044:INFO:_master_model_container: 3
2025-12-02 14:22:30,044:INFO:_display_container: 3
2025-12-02 14:22:30,044:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=0.7, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=0.0001, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=8, max_leaves=None,
              min_child_weight=3, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=10, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2025-12-02 14:22:30,044:INFO:create_model() successfully completed......................................
2025-12-02 14:22:30,221:INFO:SubProcess create_model() end ==================================
2025-12-02 14:22:30,221:INFO:choose_better activated
2025-12-02 14:22:30,221:INFO:SubProcess create_model() called ==================================
2025-12-02 14:22:30,221:INFO:Initializing create_model()
2025-12-02 14:22:30,221:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025D27710AF0>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-02 14:22:30,221:INFO:Checking exceptions
2025-12-02 14:22:30,223:INFO:Importing libraries
2025-12-02 14:22:30,223:INFO:Copying training dataset
2025-12-02 14:22:30,229:INFO:Defining folds
2025-12-02 14:22:30,229:INFO:Declaring metric variables
2025-12-02 14:22:30,229:INFO:Importing untrained model
2025-12-02 14:22:30,229:INFO:Declaring custom model
2025-12-02 14:22:30,229:INFO:Extreme Gradient Boosting Imported successfully
2025-12-02 14:22:30,229:INFO:Starting cross validation
2025-12-02 14:22:30,230:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-12-02 14:22:33,209:INFO:Calculating mean and std
2025-12-02 14:22:33,209:INFO:Creating metrics dataframe
2025-12-02 14:22:33,210:INFO:Finalizing model
2025-12-02 14:22:33,246:INFO:Warning: No categorical columns found. Calling 'transform' will only return input data.
2025-12-02 14:22:33,524:INFO:Uploading results into container
2025-12-02 14:22:33,524:INFO:Uploading model into container now
2025-12-02 14:22:33,524:INFO:_master_model_container: 4
2025-12-02 14:22:33,524:INFO:_display_container: 4
2025-12-02 14:22:33,526:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2025-12-02 14:22:33,526:INFO:create_model() successfully completed......................................
2025-12-02 14:22:33,716:INFO:SubProcess create_model() end ==================================
2025-12-02 14:22:33,716:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...) result for Recall is 0.0806
2025-12-02 14:22:33,716:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=0.7, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=0.0001, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=8, max_leaves=None,
              min_child_weight=3, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=10, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...) result for Recall is 1.0
2025-12-02 14:22:33,716:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=0.7, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=0.0001, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=8, max_leaves=None,
              min_child_weight=3, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=10, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...) is best model
2025-12-02 14:22:33,718:INFO:choose_better completed
2025-12-02 14:22:33,718:INFO:_master_model_container: 4
2025-12-02 14:22:33,718:INFO:_display_container: 3
2025-12-02 14:22:33,718:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=0.7, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=0.0001, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=8, max_leaves=None,
              min_child_weight=3, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=10, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2025-12-02 14:22:33,718:INFO:tune_model() successfully completed......................................
2025-12-02 14:22:40,303:INFO:Initializing predict_model()
2025-12-02 14:22:40,303:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025D27710AF0>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=0.7, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=0.0001, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=8, max_leaves=None,
              min_child_weight=3, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=10, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...), probability_threshold=None, encoded_labels=False, raw_score=True, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000025D23A5F760>)
2025-12-02 14:22:40,303:INFO:Checking exceptions
2025-12-02 14:22:40,303:INFO:Preloading libraries
2025-12-02 14:22:40,583:INFO:Initializing get_config()
2025-12-02 14:22:40,583:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025D27710AF0>, variable=target_param)
2025-12-02 14:22:40,589:INFO:Variable:  returned as HeartDisease
2025-12-02 14:22:40,589:INFO:get_config() successfully completed......................................
2025-12-02 14:22:46,780:INFO:Initializing interpret_model()
2025-12-02 14:22:46,780:INFO:interpret_model(estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=0.7, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=0.0001, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=8, max_leaves=None,
              min_child_weight=3, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=10, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...), use_train_data=False, X_new_sample=None, y_new_sample=None, feature=None, kwargs={}, observation=None, plot=summary, save=False, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025D27710AF0>)
2025-12-02 14:22:46,780:INFO:Checking exceptions
2025-12-02 14:22:46,781:INFO:Soft dependency imported: shap: 0.49.1
2025-12-02 14:22:46,831:INFO:plot type: summary
2025-12-02 14:22:46,831:INFO:Creating TreeExplainer
2025-12-02 14:22:46,832:INFO:Compiling shap values
2025-12-02 14:22:46,890:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:4145: FutureWarning: The NumPy global RNG was seeded by calling `np.random.seed`. In a future version this function will no longer use the global RNG. Pass `rng` explicitly to opt-in to the new behaviour and silence this warning.

2025-12-02 14:22:47,266:INFO:Visual Rendered Successfully
2025-12-02 14:22:47,266:INFO:interpret_model() successfully completed......................................
2025-12-02 14:22:50,988:INFO:Initializing finalize_model()
2025-12-02 14:22:50,988:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025D27710AF0>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=0.7, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=0.0001, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=8, max_leaves=None,
              min_child_weight=3, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=10, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2025-12-02 14:22:50,989:INFO:Finalizing XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=0.7, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=0.0001, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=8, max_leaves=None,
              min_child_weight=3, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=10, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2025-12-02 14:22:50,994:INFO:Initializing create_model()
2025-12-02 14:22:50,994:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025D27710AF0>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=0.7, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=0.0001, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=8, max_leaves=None,
              min_child_weight=3, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=10, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2025-12-02 14:22:50,994:INFO:Checking exceptions
2025-12-02 14:22:50,994:INFO:Importing libraries
2025-12-02 14:22:50,994:INFO:Copying training dataset
2025-12-02 14:22:50,994:INFO:Defining folds
2025-12-02 14:22:50,994:INFO:Declaring metric variables
2025-12-02 14:22:50,994:INFO:Importing untrained model
2025-12-02 14:22:50,994:INFO:Declaring custom model
2025-12-02 14:22:50,994:INFO:Extreme Gradient Boosting Imported successfully
2025-12-02 14:22:50,994:INFO:Cross validation set to False
2025-12-02 14:22:50,994:INFO:Fitting Model
2025-12-02 14:22:51,033:INFO:Warning: No categorical columns found. Calling 'transform' will only return input data.
2025-12-02 14:28:22,720:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-12-02 14:28:22,720:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-12-02 14:28:22,720:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-12-02 14:28:22,720:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-12-02 14:28:36,421:INFO:PyCaret ClassificationExperiment
2025-12-02 14:28:36,421:INFO:Logging name: clf-default-name
2025-12-02 14:28:36,421:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-12-02 14:28:36,421:INFO:version 3.3.2
2025-12-02 14:28:36,421:INFO:Initializing setup()
2025-12-02 14:28:36,421:INFO:self.USI: 1a5a
2025-12-02 14:28:36,421:INFO:self._variable_keys: {'log_plots_param', 'gpu_param', 'USI', 'y_test', 'fold_shuffle_param', 'seed', 'X_train', 'data', 'html_param', 'fix_imbalance', 'X', 'pipeline', 'n_jobs_param', 'logging_param', 'idx', '_ml_usecase', 'memory', 'X_test', 'fold_groups_param', 'fold_generator', 'y_train', 'exp_id', '_available_plots', 'y', 'exp_name_log', 'is_multiclass', 'target_param', 'gpu_n_jobs_param'}
2025-12-02 14:28:36,421:INFO:Checking environment
2025-12-02 14:28:36,421:INFO:python_version: 3.10.19
2025-12-02 14:28:36,421:INFO:python_build: ('main', 'Oct 21 2025 16:41:31')
2025-12-02 14:28:36,421:INFO:machine: AMD64
2025-12-02 14:28:36,421:INFO:platform: Windows-10-10.0.26100-SP0
2025-12-02 14:28:36,421:INFO:Memory: svmem(total=16282144768, available=4900978688, percent=69.9, used=11381166080, free=4900978688)
2025-12-02 14:28:36,421:INFO:Physical Core: 6
2025-12-02 14:28:36,421:INFO:Logical Core: 12
2025-12-02 14:28:36,421:INFO:Checking libraries
2025-12-02 14:28:36,421:INFO:System:
2025-12-02 14:28:36,421:INFO:    python: 3.10.19 | packaged by Anaconda, Inc. | (main, Oct 21 2025, 16:41:31) [MSC v.1929 64 bit (AMD64)]
2025-12-02 14:28:36,421:INFO:executable: c:\Users\OMAR\miniconda3\envs\xgb_env\python.exe
2025-12-02 14:28:36,421:INFO:   machine: Windows-10-10.0.26100-SP0
2025-12-02 14:28:36,422:INFO:PyCaret required dependencies:
2025-12-02 14:28:36,422:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-02 14:28:36,973:INFO:                 pip: 25.3
2025-12-02 14:28:36,973:INFO:          setuptools: 80.9.0
2025-12-02 14:28:36,973:INFO:             pycaret: 3.3.2
2025-12-02 14:28:36,973:INFO:             IPython: 8.37.0
2025-12-02 14:28:36,973:INFO:          ipywidgets: 8.1.8
2025-12-02 14:28:36,973:INFO:                tqdm: 4.67.1
2025-12-02 14:28:36,973:INFO:               numpy: 1.26.4
2025-12-02 14:28:36,973:INFO:              pandas: 2.1.4
2025-12-02 14:28:36,973:INFO:              jinja2: 3.1.6
2025-12-02 14:28:36,973:INFO:               scipy: 1.11.4
2025-12-02 14:28:36,973:INFO:              joblib: 1.3.2
2025-12-02 14:28:36,973:INFO:             sklearn: 1.4.2
2025-12-02 14:28:36,973:INFO:                pyod: 2.0.5
2025-12-02 14:28:36,973:INFO:            imblearn: 0.14.0
2025-12-02 14:28:36,973:INFO:   category_encoders: 2.7.0
2025-12-02 14:28:36,976:INFO:            lightgbm: 4.6.0
2025-12-02 14:28:36,976:INFO:               numba: 0.62.1
2025-12-02 14:28:36,976:INFO:            requests: 2.32.5
2025-12-02 14:28:36,976:INFO:          matplotlib: 3.7.5
2025-12-02 14:28:36,976:INFO:          scikitplot: 0.3.7
2025-12-02 14:28:36,976:INFO:         yellowbrick: 1.5
2025-12-02 14:28:36,976:INFO:              plotly: 5.24.1
2025-12-02 14:28:36,976:INFO:    plotly-resampler: Not installed
2025-12-02 14:28:36,976:INFO:             kaleido: 1.2.0
2025-12-02 14:28:36,976:INFO:           schemdraw: 0.15
2025-12-02 14:28:36,976:INFO:         statsmodels: 0.14.5
2025-12-02 14:28:36,976:INFO:              sktime: 0.26.0
2025-12-02 14:28:36,976:INFO:               tbats: 1.1.3
2025-12-02 14:28:36,976:INFO:            pmdarima: 2.0.4
2025-12-02 14:28:36,976:INFO:              psutil: 7.1.3
2025-12-02 14:28:36,976:INFO:          markupsafe: 3.0.3
2025-12-02 14:28:36,976:INFO:             pickle5: Not installed
2025-12-02 14:28:36,976:INFO:         cloudpickle: 3.1.2
2025-12-02 14:28:36,976:INFO:         deprecation: 2.1.0
2025-12-02 14:28:36,976:INFO:              xxhash: 3.6.0
2025-12-02 14:28:36,976:INFO:           wurlitzer: Not installed
2025-12-02 14:28:36,976:INFO:PyCaret optional dependencies:
2025-12-02 14:28:39,632:INFO:                shap: 0.49.1
2025-12-02 14:28:39,632:INFO:           interpret: 0.7.3
2025-12-02 14:28:39,632:INFO:                umap: 0.5.7
2025-12-02 14:28:39,632:INFO:     ydata_profiling: 4.18.0
2025-12-02 14:28:39,632:INFO:  explainerdashboard: 0.5.1
2025-12-02 14:28:39,632:INFO:             autoviz: Not installed
2025-12-02 14:28:39,632:INFO:           fairlearn: 0.7.0
2025-12-02 14:28:39,632:INFO:          deepchecks: Not installed
2025-12-02 14:28:39,632:INFO:             xgboost: 2.1.3
2025-12-02 14:28:39,632:INFO:            catboost: 1.2.8
2025-12-02 14:28:39,632:INFO:              kmodes: 0.12.2
2025-12-02 14:28:39,632:INFO:             mlxtend: 0.23.4
2025-12-02 14:28:39,632:INFO:       statsforecast: 1.5.0
2025-12-02 14:28:39,632:INFO:        tune_sklearn: Not installed
2025-12-02 14:28:39,632:INFO:                 ray: Not installed
2025-12-02 14:28:39,632:INFO:            hyperopt: 0.2.7
2025-12-02 14:28:39,632:INFO:              optuna: 4.6.0
2025-12-02 14:28:39,632:INFO:               skopt: 0.10.2
2025-12-02 14:28:39,632:INFO:              mlflow: 3.6.0
2025-12-02 14:28:39,632:INFO:              gradio: 6.0.1
2025-12-02 14:28:39,632:INFO:             fastapi: 0.123.0
2025-12-02 14:28:39,632:INFO:             uvicorn: 0.38.0
2025-12-02 14:28:39,632:INFO:              m2cgen: 0.10.0
2025-12-02 14:28:39,632:INFO:           evidently: 0.4.40
2025-12-02 14:28:39,632:INFO:               fugue: 0.8.7
2025-12-02 14:28:39,632:INFO:           streamlit: 1.51.0
2025-12-02 14:28:39,632:INFO:             prophet: Not installed
2025-12-02 14:28:39,632:INFO:None
2025-12-02 14:28:39,632:INFO:Set up data.
2025-12-02 14:28:39,640:INFO:Set up folding strategy.
2025-12-02 14:28:39,640:INFO:Set up train/test split.
2025-12-02 14:28:39,644:INFO:Set up index.
2025-12-02 14:28:39,644:INFO:Assigning column types.
2025-12-02 14:28:39,649:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-12-02 14:28:39,673:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-12-02 14:28:39,673:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-02 14:28:39,694:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-02 14:28:39,698:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-02 14:28:39,899:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-12-02 14:28:39,900:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-02 14:28:39,915:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-02 14:28:39,916:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-02 14:28:39,916:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-12-02 14:28:39,940:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-02 14:28:39,956:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-02 14:28:39,958:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-02 14:28:39,982:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-02 14:28:39,998:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-02 14:28:40,001:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-02 14:28:40,001:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-12-02 14:28:40,040:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-02 14:28:40,040:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-02 14:28:40,082:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-02 14:28:40,082:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-02 14:28:40,082:INFO:Preparing preprocessing pipeline...
2025-12-02 14:28:40,088:INFO:Set up simple imputation.
2025-12-02 14:28:40,090:INFO:Set up encoding of ordinal features.
2025-12-02 14:28:40,094:INFO:Set up encoding of categorical features.
2025-12-02 14:28:40,094:INFO:Set up feature normalization.
2025-12-02 14:28:40,162:INFO:Finished creating preprocessing pipeline.
2025-12-02 14:28:40,179:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\OMAR\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'IncomeRatio', 'SystolicBP',
                                             'BMI', 'WaistCircumference',
                                             'Height', 'TotalCholesterol',
                                             'Triglycerides', 'LDL', 'HDL',
                                             'HbA1c', 'Glucose', 'Creatinine',
                                             'UricAcid', 'ALT_Enzyme',
                                             'Albumin', 'Potassium', 'Sodium',
                                             'G...
                                    transformer=TargetEncoder(cols=[],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=RobustScaler(copy=True,
                                                             quantile_range=(25.0,
                                                                             75.0),
                                                             unit_variance=False,
                                                             with_centering=True,
                                                             with_scaling=True)))],
         verbose=False)
2025-12-02 14:28:40,179:INFO:Creating final display dataframe.
2025-12-02 14:28:40,353:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target      HeartDisease
2                   Target type            Binary
3           Original data shape        (4370, 28)
4        Transformed data shape        (4370, 41)
5   Transformed train set shape        (3059, 41)
6    Transformed test set shape        (1311, 41)
7              Numeric features                20
8          Categorical features                 7
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15                    Normalize              True
16             Normalize method            robust
17               Fold Generator   StratifiedKFold
18                  Fold Number                10
19                     CPU Jobs                 1
20                      Use GPU             False
21               Log Experiment             False
22              Experiment Name  clf-default-name
23                          USI              1a5a
2025-12-02 14:28:40,407:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-02 14:28:40,408:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-02 14:28:40,450:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-02 14:28:40,451:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-02 14:28:40,453:INFO:setup() successfully completed in 4.04s...............
2025-12-02 14:28:46,004:INFO:Initializing compare_models()
2025-12-02 14:28:46,004:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000223F92755D0>, include=['xgboost', 'lightgbm'], fold=None, round=4, cross_validation=True, sort=Recall, n_select=3, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x00000223F92755D0>, 'include': ['xgboost', 'lightgbm'], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Recall', 'n_select': 3, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2025-12-02 14:28:46,004:INFO:Checking exceptions
2025-12-02 14:28:46,008:INFO:Preparing display monitor
2025-12-02 14:28:46,027:INFO:Initializing Extreme Gradient Boosting
2025-12-02 14:28:46,027:INFO:Total runtime is 0.0 minutes
2025-12-02 14:28:46,030:INFO:SubProcess create_model() called ==================================
2025-12-02 14:28:46,031:INFO:Initializing create_model()
2025-12-02 14:28:46,031:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000223F92755D0>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000223F905EEF0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-02 14:28:46,031:INFO:Checking exceptions
2025-12-02 14:28:46,031:INFO:Importing libraries
2025-12-02 14:28:46,031:INFO:Copying training dataset
2025-12-02 14:28:46,037:INFO:Defining folds
2025-12-02 14:28:46,037:INFO:Declaring metric variables
2025-12-02 14:28:46,040:INFO:Importing untrained model
2025-12-02 14:28:46,043:INFO:Extreme Gradient Boosting Imported successfully
2025-12-02 14:28:46,047:INFO:Starting cross validation
2025-12-02 14:28:46,048:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-12-02 14:28:46,260:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-12-02 14:28:47,173:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-12-02 14:28:47,348:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-12-02 14:28:47,862:INFO:Calculating mean and std
2025-12-02 14:28:47,864:INFO:Creating metrics dataframe
2025-12-02 14:28:47,865:INFO:Uploading results into container
2025-12-02 14:28:47,865:INFO:Uploading model into container now
2025-12-02 14:28:47,865:INFO:_master_model_container: 1
2025-12-02 14:28:47,865:INFO:_display_container: 2
2025-12-02 14:28:47,866:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2025-12-02 14:28:47,866:INFO:create_model() successfully completed......................................
2025-12-02 14:28:48,036:INFO:SubProcess create_model() end ==================================
2025-12-02 14:28:48,036:INFO:Creating metrics dataframe
2025-12-02 14:28:48,040:INFO:Initializing Light Gradient Boosting Machine
2025-12-02 14:28:48,040:INFO:Total runtime is 0.03354540268580119 minutes
2025-12-02 14:28:48,044:INFO:SubProcess create_model() called ==================================
2025-12-02 14:28:48,044:INFO:Initializing create_model()
2025-12-02 14:28:48,044:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000223F92755D0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000223F905EEF0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-02 14:28:48,044:INFO:Checking exceptions
2025-12-02 14:28:48,044:INFO:Importing libraries
2025-12-02 14:28:48,044:INFO:Copying training dataset
2025-12-02 14:28:48,052:INFO:Defining folds
2025-12-02 14:28:48,052:INFO:Declaring metric variables
2025-12-02 14:28:48,053:INFO:Importing untrained model
2025-12-02 14:28:48,056:INFO:Light Gradient Boosting Machine Imported successfully
2025-12-02 14:28:48,060:INFO:Starting cross validation
2025-12-02 14:28:48,062:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-12-02 14:28:48,119:INFO:[LightGBM] [Info] Number of positive: 80, number of negative: 2673
2025-12-02 14:28:48,120:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000176 seconds.
2025-12-02 14:28:48,120:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-02 14:28:48,120:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-02 14:28:48,120:INFO:[LightGBM] [Info] Total Bins 5948
2025-12-02 14:28:48,121:INFO:[LightGBM] [Info] Number of data points in the train set: 2753, number of used features: 32
2025-12-02 14:28:48,121:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.029059 -> initscore=-3.508930
2025-12-02 14:28:48,121:INFO:[LightGBM] [Info] Start training from score -3.508930
2025-12-02 14:28:48,319:INFO:[LightGBM] [Info] Number of positive: 79, number of negative: 2674
2025-12-02 14:28:48,319:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000150 seconds.
2025-12-02 14:28:48,319:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-02 14:28:48,319:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-02 14:28:48,319:INFO:[LightGBM] [Info] Total Bins 5953
2025-12-02 14:28:48,319:INFO:[LightGBM] [Info] Number of data points in the train set: 2753, number of used features: 32
2025-12-02 14:28:48,321:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.028696 -> initscore=-3.521883
2025-12-02 14:28:48,321:INFO:[LightGBM] [Info] Start training from score -3.521883
2025-12-02 14:28:48,471:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-12-02 14:28:48,518:INFO:[LightGBM] [Info] Number of positive: 79, number of negative: 2674
2025-12-02 14:28:48,518:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000150 seconds.
2025-12-02 14:28:48,518:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-02 14:28:48,518:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-02 14:28:48,518:INFO:[LightGBM] [Info] Total Bins 5951
2025-12-02 14:28:48,518:INFO:[LightGBM] [Info] Number of data points in the train set: 2753, number of used features: 32
2025-12-02 14:28:48,518:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.028696 -> initscore=-3.521883
2025-12-02 14:28:48,518:INFO:[LightGBM] [Info] Start training from score -3.521883
2025-12-02 14:28:48,716:INFO:[LightGBM] [Info] Number of positive: 79, number of negative: 2674
2025-12-02 14:28:48,717:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000151 seconds.
2025-12-02 14:28:48,717:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-02 14:28:48,717:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-02 14:28:48,717:INFO:[LightGBM] [Info] Total Bins 5948
2025-12-02 14:28:48,717:INFO:[LightGBM] [Info] Number of data points in the train set: 2753, number of used features: 32
2025-12-02 14:28:48,717:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.028696 -> initscore=-3.521883
2025-12-02 14:28:48,717:INFO:[LightGBM] [Info] Start training from score -3.521883
2025-12-02 14:28:48,915:INFO:[LightGBM] [Info] Number of positive: 79, number of negative: 2674
2025-12-02 14:28:48,915:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000153 seconds.
2025-12-02 14:28:48,915:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-02 14:28:48,915:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-02 14:28:48,915:INFO:[LightGBM] [Info] Total Bins 5949
2025-12-02 14:28:48,915:INFO:[LightGBM] [Info] Number of data points in the train set: 2753, number of used features: 32
2025-12-02 14:28:48,916:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.028696 -> initscore=-3.521883
2025-12-02 14:28:48,916:INFO:[LightGBM] [Info] Start training from score -3.521883
2025-12-02 14:28:49,118:INFO:[LightGBM] [Info] Number of positive: 79, number of negative: 2674
2025-12-02 14:28:49,118:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000162 seconds.
2025-12-02 14:28:49,118:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-02 14:28:49,118:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-02 14:28:49,118:INFO:[LightGBM] [Info] Total Bins 5952
2025-12-02 14:28:49,118:INFO:[LightGBM] [Info] Number of data points in the train set: 2753, number of used features: 32
2025-12-02 14:28:49,118:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.028696 -> initscore=-3.521883
2025-12-02 14:28:49,118:INFO:[LightGBM] [Info] Start training from score -3.521883
2025-12-02 14:28:49,273:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-12-02 14:28:49,321:INFO:[LightGBM] [Info] Number of positive: 79, number of negative: 2674
2025-12-02 14:28:49,321:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000148 seconds.
2025-12-02 14:28:49,321:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-02 14:28:49,321:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-02 14:28:49,321:INFO:[LightGBM] [Info] Total Bins 5951
2025-12-02 14:28:49,321:INFO:[LightGBM] [Info] Number of data points in the train set: 2753, number of used features: 32
2025-12-02 14:28:49,321:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.028696 -> initscore=-3.521883
2025-12-02 14:28:49,321:INFO:[LightGBM] [Info] Start training from score -3.521883
2025-12-02 14:28:49,469:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-12-02 14:28:49,516:INFO:[LightGBM] [Info] Number of positive: 79, number of negative: 2674
2025-12-02 14:28:49,516:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000381 seconds.
2025-12-02 14:28:49,518:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-02 14:28:49,518:INFO:[LightGBM] [Info] Total Bins 5951
2025-12-02 14:28:49,518:INFO:[LightGBM] [Info] Number of data points in the train set: 2753, number of used features: 32
2025-12-02 14:28:49,518:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.028696 -> initscore=-3.521883
2025-12-02 14:28:49,518:INFO:[LightGBM] [Info] Start training from score -3.521883
2025-12-02 14:28:49,718:INFO:[LightGBM] [Info] Number of positive: 79, number of negative: 2674
2025-12-02 14:28:49,721:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000146 seconds.
2025-12-02 14:28:49,721:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-02 14:28:49,721:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-02 14:28:49,721:INFO:[LightGBM] [Info] Total Bins 5950
2025-12-02 14:28:49,721:INFO:[LightGBM] [Info] Number of data points in the train set: 2753, number of used features: 32
2025-12-02 14:28:49,721:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.028696 -> initscore=-3.521883
2025-12-02 14:28:49,721:INFO:[LightGBM] [Info] Start training from score -3.521883
2025-12-02 14:28:49,920:INFO:[LightGBM] [Info] Number of positive: 80, number of negative: 2674
2025-12-02 14:28:49,920:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000391 seconds.
2025-12-02 14:28:49,920:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-12-02 14:28:49,920:INFO:[LightGBM] [Info] Total Bins 5946
2025-12-02 14:28:49,920:INFO:[LightGBM] [Info] Number of data points in the train set: 2754, number of used features: 32
2025-12-02 14:28:49,920:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.029049 -> initscore=-3.509304
2025-12-02 14:28:49,920:INFO:[LightGBM] [Info] Start training from score -3.509304
2025-12-02 14:28:50,073:INFO:Calculating mean and std
2025-12-02 14:28:50,073:INFO:Creating metrics dataframe
2025-12-02 14:28:50,079:INFO:Uploading results into container
2025-12-02 14:28:50,079:INFO:Uploading model into container now
2025-12-02 14:28:50,079:INFO:_master_model_container: 2
2025-12-02 14:28:50,079:INFO:_display_container: 2
2025-12-02 14:28:50,079:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-12-02 14:28:50,079:INFO:create_model() successfully completed......................................
2025-12-02 14:28:50,243:INFO:SubProcess create_model() end ==================================
2025-12-02 14:28:50,243:INFO:Creating metrics dataframe
2025-12-02 14:28:50,248:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.

2025-12-02 14:28:50,254:INFO:Initializing create_model()
2025-12-02 14:28:50,255:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000223F92755D0>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-02 14:28:50,255:INFO:Checking exceptions
2025-12-02 14:28:50,256:INFO:Importing libraries
2025-12-02 14:28:50,256:INFO:Copying training dataset
2025-12-02 14:28:50,261:INFO:Defining folds
2025-12-02 14:28:50,261:INFO:Declaring metric variables
2025-12-02 14:28:50,261:INFO:Importing untrained model
2025-12-02 14:28:50,261:INFO:Declaring custom model
2025-12-02 14:28:50,262:INFO:Extreme Gradient Boosting Imported successfully
2025-12-02 14:28:50,263:INFO:Cross validation set to False
2025-12-02 14:28:50,263:INFO:Fitting Model
2025-12-02 14:28:50,312:INFO:Warning: No categorical columns found. Calling 'transform' will only return input data.
2025-12-02 14:28:50,430:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2025-12-02 14:28:50,430:INFO:create_model() successfully completed......................................
2025-12-02 14:28:50,609:INFO:Initializing create_model()
2025-12-02 14:28:50,609:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000223F92755D0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-02 14:28:50,609:INFO:Checking exceptions
2025-12-02 14:28:50,611:INFO:Importing libraries
2025-12-02 14:28:50,611:INFO:Copying training dataset
2025-12-02 14:28:50,618:INFO:Defining folds
2025-12-02 14:28:50,618:INFO:Declaring metric variables
2025-12-02 14:28:50,618:INFO:Importing untrained model
2025-12-02 14:28:50,618:INFO:Declaring custom model
2025-12-02 14:28:50,619:INFO:Light Gradient Boosting Machine Imported successfully
2025-12-02 14:28:50,620:INFO:Cross validation set to False
2025-12-02 14:28:50,620:INFO:Fitting Model
2025-12-02 14:28:50,651:INFO:Warning: No categorical columns found. Calling 'transform' will only return input data.
2025-12-02 14:28:50,667:INFO:[LightGBM] [Info] Number of positive: 88, number of negative: 2971
2025-12-02 14:28:50,668:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000162 seconds.
2025-12-02 14:28:50,668:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-12-02 14:28:50,668:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-12-02 14:28:50,668:INFO:[LightGBM] [Info] Total Bins 5953
2025-12-02 14:28:50,668:INFO:[LightGBM] [Info] Number of data points in the train set: 3059, number of used features: 32
2025-12-02 14:28:50,669:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.028768 -> initscore=-3.519317
2025-12-02 14:28:50,669:INFO:[LightGBM] [Info] Start training from score -3.519317
2025-12-02 14:28:50,803:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-12-02 14:28:50,803:INFO:create_model() successfully completed......................................
2025-12-02 14:28:50,974:INFO:_master_model_container: 2
2025-12-02 14:28:50,974:INFO:_display_container: 2
2025-12-02 14:28:50,974:INFO:[XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...), LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)]
2025-12-02 14:28:50,974:INFO:compare_models() successfully completed......................................
2025-12-02 14:28:57,953:INFO:Initializing tune_model()
2025-12-02 14:28:57,953:INFO:tune_model(estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...), fold=None, round=4, n_iter=5, custom_grid=None, optimize=Recall, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=False, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000223F92755D0>)
2025-12-02 14:28:57,953:INFO:Checking exceptions
2025-12-02 14:28:57,956:INFO:Copying training dataset
2025-12-02 14:28:57,960:INFO:Checking base model
2025-12-02 14:28:57,960:INFO:Base model : Extreme Gradient Boosting
2025-12-02 14:28:57,962:INFO:Declaring metric variables
2025-12-02 14:28:57,962:INFO:Defining Hyperparameters
2025-12-02 14:28:58,122:INFO:Tuning with n_jobs=1
2025-12-02 14:28:58,122:INFO:Initializing RandomizedSearchCV
2025-12-02 14:29:07,249:INFO:best_params: {'actual_estimator__subsample': 0.9, 'actual_estimator__scale_pos_weight': 33.0, 'actual_estimator__reg_lambda': 0.15, 'actual_estimator__reg_alpha': 10, 'actual_estimator__n_estimators': 170, 'actual_estimator__min_child_weight': 2, 'actual_estimator__max_depth': 8, 'actual_estimator__learning_rate': 0.3, 'actual_estimator__colsample_bytree': 0.7}
2025-12-02 14:29:07,249:INFO:Hyperparameter search completed
2025-12-02 14:29:07,249:INFO:SubProcess create_model() called ==================================
2025-12-02 14:29:07,251:INFO:Initializing create_model()
2025-12-02 14:29:07,251:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000223F92755D0>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000223F92D0AF0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'subsample': 0.9, 'scale_pos_weight': 33.0, 'reg_lambda': 0.15, 'reg_alpha': 10, 'n_estimators': 170, 'min_child_weight': 2, 'max_depth': 8, 'learning_rate': 0.3, 'colsample_bytree': 0.7})
2025-12-02 14:29:07,251:INFO:Checking exceptions
2025-12-02 14:29:07,251:INFO:Importing libraries
2025-12-02 14:29:07,251:INFO:Copying training dataset
2025-12-02 14:29:07,253:INFO:Defining folds
2025-12-02 14:29:07,253:INFO:Declaring metric variables
2025-12-02 14:29:07,253:INFO:Importing untrained model
2025-12-02 14:29:07,253:INFO:Declaring custom model
2025-12-02 14:29:07,256:INFO:Extreme Gradient Boosting Imported successfully
2025-12-02 14:29:07,256:INFO:Starting cross validation
2025-12-02 14:29:07,256:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-12-02 14:29:09,233:INFO:Calculating mean and std
2025-12-02 14:29:09,233:INFO:Creating metrics dataframe
2025-12-02 14:29:09,235:INFO:Finalizing model
2025-12-02 14:29:09,265:INFO:Warning: No categorical columns found. Calling 'transform' will only return input data.
2025-12-02 14:29:09,403:INFO:Uploading results into container
2025-12-02 14:29:09,403:INFO:Uploading model into container now
2025-12-02 14:29:09,403:INFO:_master_model_container: 3
2025-12-02 14:29:09,403:INFO:_display_container: 3
2025-12-02 14:29:09,406:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=0.7, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=0.3, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=8, max_leaves=None,
              min_child_weight=2, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=170, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2025-12-02 14:29:09,406:INFO:create_model() successfully completed......................................
2025-12-02 14:29:09,583:INFO:SubProcess create_model() end ==================================
2025-12-02 14:29:09,583:INFO:choose_better activated
2025-12-02 14:29:09,583:INFO:SubProcess create_model() called ==================================
2025-12-02 14:29:09,584:INFO:Initializing create_model()
2025-12-02 14:29:09,584:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000223F92755D0>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-02 14:29:09,584:INFO:Checking exceptions
2025-12-02 14:29:09,585:INFO:Importing libraries
2025-12-02 14:29:09,586:INFO:Copying training dataset
2025-12-02 14:29:09,590:INFO:Defining folds
2025-12-02 14:29:09,590:INFO:Declaring metric variables
2025-12-02 14:29:09,590:INFO:Importing untrained model
2025-12-02 14:29:09,590:INFO:Declaring custom model
2025-12-02 14:29:09,590:INFO:Extreme Gradient Boosting Imported successfully
2025-12-02 14:29:09,590:INFO:Starting cross validation
2025-12-02 14:29:09,590:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-12-02 14:29:09,762:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-12-02 14:29:10,601:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-12-02 14:29:10,781:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-12-02 14:29:11,300:INFO:Calculating mean and std
2025-12-02 14:29:11,300:INFO:Creating metrics dataframe
2025-12-02 14:29:11,301:INFO:Finalizing model
2025-12-02 14:29:11,329:INFO:Warning: No categorical columns found. Calling 'transform' will only return input data.
2025-12-02 14:29:11,442:INFO:Uploading results into container
2025-12-02 14:29:11,442:INFO:Uploading model into container now
2025-12-02 14:29:11,442:INFO:_master_model_container: 4
2025-12-02 14:29:11,442:INFO:_display_container: 4
2025-12-02 14:29:11,444:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2025-12-02 14:29:11,444:INFO:create_model() successfully completed......................................
2025-12-02 14:29:11,616:INFO:SubProcess create_model() end ==================================
2025-12-02 14:29:11,618:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...) result for Recall is 0.0236
2025-12-02 14:29:11,618:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=0.7, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=0.3, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=8, max_leaves=None,
              min_child_weight=2, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=170, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...) result for Recall is 0.2278
2025-12-02 14:29:11,618:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=0.7, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=0.3, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=8, max_leaves=None,
              min_child_weight=2, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=170, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...) is best model
2025-12-02 14:29:11,618:INFO:choose_better completed
2025-12-02 14:29:11,618:INFO:_master_model_container: 4
2025-12-02 14:29:11,618:INFO:_display_container: 3
2025-12-02 14:29:11,618:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=0.7, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=0.3, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=8, max_leaves=None,
              min_child_weight=2, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=170, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2025-12-02 14:29:11,618:INFO:tune_model() successfully completed......................................
2025-12-02 14:29:17,644:INFO:Initializing predict_model()
2025-12-02 14:29:17,644:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000223F92755D0>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=0.7, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=0.3, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=8, max_leaves=None,
              min_child_weight=2, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=170, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...), probability_threshold=None, encoded_labels=False, raw_score=True, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000223F55DC9D0>)
2025-12-02 14:29:17,645:INFO:Checking exceptions
2025-12-02 14:29:17,645:INFO:Preloading libraries
2025-12-02 14:29:17,932:INFO:Initializing get_config()
2025-12-02 14:29:17,932:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000223F92755D0>, variable=target_param)
2025-12-02 14:29:17,932:INFO:Variable:  returned as HeartDisease
2025-12-02 14:29:17,932:INFO:get_config() successfully completed......................................
2025-12-02 14:29:33,835:INFO:Initializing interpret_model()
2025-12-02 14:29:33,835:INFO:interpret_model(estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=0.7, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=0.3, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=8, max_leaves=None,
              min_child_weight=2, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=170, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...), use_train_data=False, X_new_sample=None, y_new_sample=None, feature=None, kwargs={}, observation=None, plot=summary, save=False, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000223F92755D0>)
2025-12-02 14:29:33,835:INFO:Checking exceptions
2025-12-02 14:29:33,835:INFO:Soft dependency imported: shap: 0.49.1
2025-12-02 14:29:33,890:INFO:plot type: summary
2025-12-02 14:29:33,890:INFO:Creating TreeExplainer
2025-12-02 14:29:33,909:INFO:Compiling shap values
2025-12-02 14:29:34,106:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:4145: FutureWarning: The NumPy global RNG was seeded by calling `np.random.seed`. In a future version this function will no longer use the global RNG. Pass `rng` explicitly to opt-in to the new behaviour and silence this warning.

2025-12-02 14:29:34,462:INFO:Visual Rendered Successfully
2025-12-02 14:29:34,462:INFO:interpret_model() successfully completed......................................
2025-12-02 14:29:40,312:INFO:Initializing finalize_model()
2025-12-02 14:29:40,312:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000223F92755D0>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=0.7, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=0.3, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=8, max_leaves=None,
              min_child_weight=2, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=170, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2025-12-02 14:29:40,312:INFO:Finalizing XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=0.7, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=0.3, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=8, max_leaves=None,
              min_child_weight=2, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=170, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2025-12-02 14:29:40,316:INFO:Initializing create_model()
2025-12-02 14:29:40,316:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000223F92755D0>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=0.7, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=0.3, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=8, max_leaves=None,
              min_child_weight=2, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=170, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2025-12-02 14:29:40,316:INFO:Checking exceptions
2025-12-02 14:29:40,318:INFO:Importing libraries
2025-12-02 14:29:40,318:INFO:Copying training dataset
2025-12-02 14:29:40,319:INFO:Defining folds
2025-12-02 14:29:40,319:INFO:Declaring metric variables
2025-12-02 14:29:40,319:INFO:Importing untrained model
2025-12-02 14:29:40,319:INFO:Declaring custom model
2025-12-02 14:29:40,321:INFO:Extreme Gradient Boosting Imported successfully
2025-12-02 14:29:40,322:INFO:Cross validation set to False
2025-12-02 14:29:40,322:INFO:Fitting Model
2025-12-02 14:29:40,354:INFO:Warning: No categorical columns found. Calling 'transform' will only return input data.
2025-12-02 14:29:40,569:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'IncomeRatio', 'SystolicBP',
                                             'BMI', 'WaistCircumference',
                                             'Height', 'TotalCholesterol',
                                             'Triglycerides', 'LDL', 'HDL',
                                             'HbA1c', 'Glucose', 'Creatinine',
                                             'UricAcid', 'ALT_Enzyme',
                                             'Albumin', 'Potassium', 'Sodium',
                                             'GGT_Enzyme', 'AST_Enzyme'],
                                    transformer=Si...
                               importance_type=None,
                               interaction_constraints=None, learning_rate=0.3,
                               max_bin=None, max_cat_threshold=None,
                               max_cat_to_onehot=None, max_delta_step=None,
                               max_depth=8, max_leaves=None, min_child_weight=2,
                               missing=nan, monotone_constraints=None,
                               multi_strategy=None, n_estimators=170, n_jobs=1,
                               num_parallel_tree=None,
                               objective='binary:logistic', ...))],
         verbose=False)
2025-12-02 14:29:40,569:INFO:create_model() successfully completed......................................
2025-12-02 14:29:40,742:INFO:_master_model_container: 4
2025-12-02 14:29:40,742:INFO:_display_container: 4
2025-12-02 14:29:40,758:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'IncomeRatio', 'SystolicBP',
                                             'BMI', 'WaistCircumference',
                                             'Height', 'TotalCholesterol',
                                             'Triglycerides', 'LDL', 'HDL',
                                             'HbA1c', 'Glucose', 'Creatinine',
                                             'UricAcid', 'ALT_Enzyme',
                                             'Albumin', 'Potassium', 'Sodium',
                                             'GGT_Enzyme', 'AST_Enzyme'],
                                    transformer=Si...
                               importance_type=None,
                               interaction_constraints=None, learning_rate=0.3,
                               max_bin=None, max_cat_threshold=None,
                               max_cat_to_onehot=None, max_delta_step=None,
                               max_depth=8, max_leaves=None, min_child_weight=2,
                               missing=nan, monotone_constraints=None,
                               multi_strategy=None, n_estimators=170, n_jobs=1,
                               num_parallel_tree=None,
                               objective='binary:logistic', ...))],
         verbose=False)
2025-12-02 14:29:40,758:INFO:finalize_model() successfully completed......................................
2025-12-02 14:29:40,943:INFO:Initializing save_model()
2025-12-02 14:29:40,943:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'IncomeRatio', 'SystolicBP',
                                             'BMI', 'WaistCircumference',
                                             'Height', 'TotalCholesterol',
                                             'Triglycerides', 'LDL', 'HDL',
                                             'HbA1c', 'Glucose', 'Creatinine',
                                             'UricAcid', 'ALT_Enzyme',
                                             'Albumin', 'Potassium', 'Sodium',
                                             'GGT_Enzyme', 'AST_Enzyme'],
                                    transformer=Si...
                               importance_type=None,
                               interaction_constraints=None, learning_rate=0.3,
                               max_bin=None, max_cat_threshold=None,
                               max_cat_to_onehot=None, max_delta_step=None,
                               max_depth=8, max_leaves=None, min_child_weight=2,
                               missing=nan, monotone_constraints=None,
                               multi_strategy=None, n_estimators=170, n_jobs=1,
                               num_parallel_tree=None,
                               objective='binary:logistic', ...))],
         verbose=False), model_name=../models\best_pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\OMAR\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'IncomeRatio', 'SystolicBP',
                                             'BMI', 'WaistCircumference',
                                             'Height', 'TotalCholesterol',
                                             'Triglycerides', 'LDL', 'HDL',
                                             'HbA1c', 'Glucose', 'Creatinine',
                                             'UricAcid', 'ALT_Enzyme',
                                             'Albumin', 'Potassium', 'Sodium',
                                             'G...
                                    transformer=TargetEncoder(cols=[],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=RobustScaler(copy=True,
                                                             quantile_range=(25.0,
                                                                             75.0),
                                                             unit_variance=False,
                                                             with_centering=True,
                                                             with_scaling=True)))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2025-12-02 14:29:40,943:INFO:Adding model into prep_pipe
2025-12-02 14:29:40,943:WARNING:Only Model saved as it was a pipeline.
2025-12-02 14:29:40,954:INFO:../models\best_pipeline.pkl saved in current working directory
2025-12-02 14:29:40,970:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'IncomeRatio', 'SystolicBP',
                                             'BMI', 'WaistCircumference',
                                             'Height', 'TotalCholesterol',
                                             'Triglycerides', 'LDL', 'HDL',
                                             'HbA1c', 'Glucose', 'Creatinine',
                                             'UricAcid', 'ALT_Enzyme',
                                             'Albumin', 'Potassium', 'Sodium',
                                             'GGT_Enzyme', 'AST_Enzyme'],
                                    transformer=Si...
                               importance_type=None,
                               interaction_constraints=None, learning_rate=0.3,
                               max_bin=None, max_cat_threshold=None,
                               max_cat_to_onehot=None, max_delta_step=None,
                               max_depth=8, max_leaves=None, min_child_weight=2,
                               missing=nan, monotone_constraints=None,
                               multi_strategy=None, n_estimators=170, n_jobs=1,
                               num_parallel_tree=None,
                               objective='binary:logistic', ...))],
         verbose=False)
2025-12-02 14:29:40,970:INFO:save_model() successfully completed......................................
2025-12-02 14:30:04,719:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-12-02 14:30:04,721:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-12-02 14:30:04,721:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-12-02 14:30:04,721:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-12-02 14:30:08,505:INFO:Initializing load_model()
2025-12-02 14:30:08,505:INFO:load_model(model_name=../models/best_pipeline, platform=None, authentication=None, verbose=True)
2025-12-02 14:30:08,536:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-02 14:30:12,390:INFO:Initializing predict_model()
2025-12-02 14:30:12,390:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EFD537EC80>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Age', 'IncomeRatio', 'SystolicBP',
                                             'BMI', 'WaistCircumference',
                                             'Height', 'TotalCholesterol',
                                             'Triglycerides', 'LDL', 'HDL',
                                             'HbA1c', 'Glucose', 'Creatinine',
                                             'UricAcid', 'ALT_Enzyme',
                                             'Albumin', 'Potassium', 'Sodium',
                                             'GGT_Enzyme', 'AST_Enzyme'],
                                    transformer=SimpleImputer()...
                               feature_types=None, gamma=None, grow_policy=None,
                               importance_type=None,
                               interaction_constraints=None, learning_rate=0.3,
                               max_bin=None, max_cat_threshold=None,
                               max_cat_to_onehot=None, max_delta_step=None,
                               max_depth=8, max_leaves=None, min_child_weight=2,
                               missing=nan, monotone_constraints=None,
                               multi_strategy=None, n_estimators=170, n_jobs=1,
                               num_parallel_tree=None, random_state=42, ...))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001EFD422D120>)
2025-12-02 14:30:12,390:INFO:Checking exceptions
2025-12-02 14:30:12,390:INFO:Preloading libraries
2025-12-02 14:30:12,390:INFO:Set up data.
2025-12-02 14:30:12,401:INFO:Set up index.
2025-12-02 14:30:43,674:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-12-02 14:30:43,674:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-12-02 14:30:43,674:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-12-02 14:30:43,674:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-12-02 14:30:52,536:INFO:Initializing load_model()
2025-12-02 14:30:52,536:INFO:load_model(model_name=../models/best_pipeline, platform=None, authentication=None, verbose=True)
2025-12-02 14:30:52,663:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-02 14:31:03,203:INFO:Initializing predict_model()
2025-12-02 14:31:03,203:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000019B19906B00>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Age', 'IncomeRatio', 'SystolicBP',
                                             'BMI', 'WaistCircumference',
                                             'Height', 'TotalCholesterol',
                                             'Triglycerides', 'LDL', 'HDL',
                                             'HbA1c', 'Glucose', 'Creatinine',
                                             'UricAcid', 'ALT_Enzyme',
                                             'Albumin', 'Potassium', 'Sodium',
                                             'GGT_Enzyme', 'AST_Enzyme'],
                                    transformer=SimpleImputer()...
                               feature_types=None, gamma=None, grow_policy=None,
                               importance_type=None,
                               interaction_constraints=None, learning_rate=0.3,
                               max_bin=None, max_cat_threshold=None,
                               max_cat_to_onehot=None, max_delta_step=None,
                               max_depth=8, max_leaves=None, min_child_weight=2,
                               missing=nan, monotone_constraints=None,
                               multi_strategy=None, n_estimators=170, n_jobs=1,
                               num_parallel_tree=None, random_state=42, ...))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000019B17942320>)
2025-12-02 14:31:03,203:INFO:Checking exceptions
2025-12-02 14:31:03,203:INFO:Preloading libraries
2025-12-02 14:31:03,203:INFO:Set up data.
2025-12-02 14:31:03,207:INFO:Set up index.
2025-12-02 14:48:26,987:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-12-02 14:48:26,987:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-12-02 14:48:26,987:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-12-02 14:48:26,987:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-12-02 14:48:50,844:INFO:PyCaret ClassificationExperiment
2025-12-02 14:48:50,844:INFO:Logging name: clf-default-name
2025-12-02 14:48:50,845:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-12-02 14:48:50,845:INFO:version 3.3.2
2025-12-02 14:48:50,845:INFO:Initializing setup()
2025-12-02 14:48:50,845:INFO:self.USI: f58f
2025-12-02 14:48:50,845:INFO:self._variable_keys: {'X', '_ml_usecase', 'y', 'fix_imbalance', 'USI', 'y_test', 'logging_param', 'n_jobs_param', 'exp_id', 'gpu_n_jobs_param', 'idx', 'y_train', 'data', 'X_train', '_available_plots', 'fold_shuffle_param', 'target_param', 'fold_groups_param', 'seed', 'is_multiclass', 'memory', 'html_param', 'exp_name_log', 'fold_generator', 'gpu_param', 'pipeline', 'log_plots_param', 'X_test'}
2025-12-02 14:48:50,845:INFO:Checking environment
2025-12-02 14:48:50,845:INFO:python_version: 3.10.19
2025-12-02 14:48:50,845:INFO:python_build: ('main', 'Oct 21 2025 16:41:31')
2025-12-02 14:48:50,845:INFO:machine: AMD64
2025-12-02 14:48:50,845:INFO:platform: Windows-10-10.0.26100-SP0
2025-12-02 14:48:50,845:INFO:Memory: svmem(total=16282144768, available=4368936960, percent=73.2, used=11913207808, free=4368936960)
2025-12-02 14:48:50,845:INFO:Physical Core: 6
2025-12-02 14:48:50,845:INFO:Logical Core: 12
2025-12-02 14:48:50,845:INFO:Checking libraries
2025-12-02 14:48:50,845:INFO:System:
2025-12-02 14:48:50,846:INFO:    python: 3.10.19 | packaged by Anaconda, Inc. | (main, Oct 21 2025, 16:41:31) [MSC v.1929 64 bit (AMD64)]
2025-12-02 14:48:50,846:INFO:executable: c:\Users\OMAR\miniconda3\envs\xgb_env\python.exe
2025-12-02 14:48:50,846:INFO:   machine: Windows-10-10.0.26100-SP0
2025-12-02 14:48:50,846:INFO:PyCaret required dependencies:
2025-12-02 14:48:50,847:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-02 14:48:51,413:INFO:                 pip: 25.3
2025-12-02 14:48:51,413:INFO:          setuptools: 80.9.0
2025-12-02 14:48:51,413:INFO:             pycaret: 3.3.2
2025-12-02 14:48:51,413:INFO:             IPython: 8.37.0
2025-12-02 14:48:51,413:INFO:          ipywidgets: 8.1.8
2025-12-02 14:48:51,413:INFO:                tqdm: 4.67.1
2025-12-02 14:48:51,413:INFO:               numpy: 1.26.4
2025-12-02 14:48:51,413:INFO:              pandas: 2.1.4
2025-12-02 14:48:51,413:INFO:              jinja2: 3.1.6
2025-12-02 14:48:51,413:INFO:               scipy: 1.11.4
2025-12-02 14:48:51,413:INFO:              joblib: 1.3.2
2025-12-02 14:48:51,413:INFO:             sklearn: 1.4.2
2025-12-02 14:48:51,413:INFO:                pyod: 2.0.5
2025-12-02 14:48:51,413:INFO:            imblearn: 0.14.0
2025-12-02 14:48:51,413:INFO:   category_encoders: 2.7.0
2025-12-02 14:48:51,413:INFO:            lightgbm: 4.6.0
2025-12-02 14:48:51,413:INFO:               numba: 0.62.1
2025-12-02 14:48:51,413:INFO:            requests: 2.32.5
2025-12-02 14:48:51,414:INFO:          matplotlib: 3.7.5
2025-12-02 14:48:51,414:INFO:          scikitplot: 0.3.7
2025-12-02 14:48:51,414:INFO:         yellowbrick: 1.5
2025-12-02 14:48:51,414:INFO:              plotly: 5.24.1
2025-12-02 14:48:51,414:INFO:    plotly-resampler: Not installed
2025-12-02 14:48:51,414:INFO:             kaleido: 1.2.0
2025-12-02 14:48:51,414:INFO:           schemdraw: 0.15
2025-12-02 14:48:51,414:INFO:         statsmodels: 0.14.5
2025-12-02 14:48:51,414:INFO:              sktime: 0.26.0
2025-12-02 14:48:51,414:INFO:               tbats: 1.1.3
2025-12-02 14:48:51,414:INFO:            pmdarima: 2.0.4
2025-12-02 14:48:51,414:INFO:              psutil: 7.1.3
2025-12-02 14:48:51,414:INFO:          markupsafe: 3.0.3
2025-12-02 14:48:51,414:INFO:             pickle5: Not installed
2025-12-02 14:48:51,414:INFO:         cloudpickle: 3.1.2
2025-12-02 14:48:51,414:INFO:         deprecation: 2.1.0
2025-12-02 14:48:51,414:INFO:              xxhash: 3.6.0
2025-12-02 14:48:51,414:INFO:           wurlitzer: Not installed
2025-12-02 14:48:51,414:INFO:PyCaret optional dependencies:
2025-12-02 14:48:54,240:INFO:                shap: 0.49.1
2025-12-02 14:48:54,240:INFO:           interpret: 0.7.3
2025-12-02 14:48:54,240:INFO:                umap: 0.5.7
2025-12-02 14:48:54,240:INFO:     ydata_profiling: 4.18.0
2025-12-02 14:48:54,240:INFO:  explainerdashboard: 0.5.1
2025-12-02 14:48:54,240:INFO:             autoviz: Not installed
2025-12-02 14:48:54,240:INFO:           fairlearn: 0.7.0
2025-12-02 14:48:54,240:INFO:          deepchecks: Not installed
2025-12-02 14:48:54,240:INFO:             xgboost: 2.1.3
2025-12-02 14:48:54,240:INFO:            catboost: 1.2.8
2025-12-02 14:48:54,240:INFO:              kmodes: 0.12.2
2025-12-02 14:48:54,240:INFO:             mlxtend: 0.23.4
2025-12-02 14:48:54,240:INFO:       statsforecast: 1.5.0
2025-12-02 14:48:54,240:INFO:        tune_sklearn: Not installed
2025-12-02 14:48:54,240:INFO:                 ray: Not installed
2025-12-02 14:48:54,240:INFO:            hyperopt: 0.2.7
2025-12-02 14:48:54,240:INFO:              optuna: 4.6.0
2025-12-02 14:48:54,240:INFO:               skopt: 0.10.2
2025-12-02 14:48:54,240:INFO:              mlflow: 3.6.0
2025-12-02 14:48:54,240:INFO:              gradio: 6.0.1
2025-12-02 14:48:54,240:INFO:             fastapi: 0.123.0
2025-12-02 14:48:54,241:INFO:             uvicorn: 0.38.0
2025-12-02 14:48:54,241:INFO:              m2cgen: 0.10.0
2025-12-02 14:48:54,241:INFO:           evidently: 0.4.40
2025-12-02 14:48:54,241:INFO:               fugue: 0.8.7
2025-12-02 14:48:54,241:INFO:           streamlit: 1.51.0
2025-12-02 14:48:54,241:INFO:             prophet: Not installed
2025-12-02 14:48:54,241:INFO:None
2025-12-02 14:48:54,241:INFO:Set up data.
2025-12-02 14:48:54,262:INFO:Set up folding strategy.
2025-12-02 14:48:54,262:INFO:Set up train/test split.
2025-12-02 14:48:54,284:INFO:Set up index.
2025-12-02 14:48:54,285:INFO:Assigning column types.
2025-12-02 14:48:54,305:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-12-02 14:48:54,330:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-12-02 14:48:54,332:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-02 14:48:54,353:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-02 14:48:54,354:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-02 14:48:54,399:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-12-02 14:48:54,400:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-02 14:48:54,416:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-02 14:48:54,417:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-02 14:48:54,418:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-12-02 14:48:54,442:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-02 14:48:54,458:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-02 14:48:54,459:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-02 14:48:54,485:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-02 14:48:54,500:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-02 14:48:54,501:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-02 14:48:54,503:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-12-02 14:48:54,543:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-02 14:48:54,545:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-02 14:48:54,587:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-02 14:48:54,588:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-02 14:48:54,591:INFO:Preparing preprocessing pipeline...
2025-12-02 14:48:54,595:INFO:Set up simple imputation.
2025-12-02 14:48:54,606:INFO:Set up encoding of ordinal features.
2025-12-02 14:48:54,613:INFO:Set up encoding of categorical features.
2025-12-02 14:48:54,614:INFO:Set up feature normalization.
2025-12-02 14:48:54,778:INFO:Finished creating preprocessing pipeline.
2025-12-02 14:48:54,794:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\OMAR\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'IncomeRatio', 'SystolicBP',
                                             'BMI', 'WaistCircumference',
                                             'Height', 'TotalCholesterol',
                                             'Triglycerides', 'LDL', 'HDL',
                                             'HbA1c', 'Glucose', 'Creatinine',
                                             'UricAcid', 'ALT_Enzyme',
                                             'Albumin', 'Potassium', 'Sodium',
                                             'G...
                                    transformer=TargetEncoder(cols=[],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=RobustScaler(copy=True,
                                                             quantile_range=(25.0,
                                                                             75.0),
                                                             unit_variance=False,
                                                             with_centering=True,
                                                             with_scaling=True)))],
         verbose=False)
2025-12-02 14:48:54,794:INFO:Creating final display dataframe.
2025-12-02 14:48:55,195:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target      HeartDisease
2                   Target type            Binary
3           Original data shape       (43695, 28)
4        Transformed data shape       (43695, 32)
5   Transformed train set shape       (30586, 32)
6    Transformed test set shape       (13109, 32)
7              Numeric features                20
8          Categorical features                 7
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15                    Normalize              True
16             Normalize method            robust
17               Fold Generator   StratifiedKFold
18                  Fold Number                10
19                     CPU Jobs                 1
20                      Use GPU             False
21               Log Experiment             False
22              Experiment Name  clf-default-name
23                          USI              f58f
2025-12-02 14:48:55,246:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-02 14:48:55,248:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-02 14:48:55,291:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-02 14:48:55,294:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-02 14:48:55,296:INFO:setup() successfully completed in 4.46s...............
2025-12-02 14:49:15,575:INFO:Initializing get_config()
2025-12-02 14:49:15,576:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C0817B2E60>, variable=y_train)
2025-12-02 14:49:15,576:INFO:Variable: 'y_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_train_transformed' instead.
2025-12-02 14:49:15,576:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_train_transformed' instead.

2025-12-02 14:49:15,584:INFO:Variable:  returned as 15208    0.0
25325    0.0
5132     0.0
17217    0.0
6382     0.0
        ... 
6265     0.0
42694    0.0
13399    0.0
39959    0.0
6616     0.0
Name: HeartDisease, Length: 30586, dtype: float32
2025-12-02 14:49:15,585:INFO:get_config() successfully completed......................................
2025-12-02 14:49:15,585:INFO:Initializing create_model()
2025-12-02 14:49:15,585:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C0817B2E60>, estimator=xgboost, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={'scale_pos_weight': 38.162612035851474})
2025-12-02 14:49:15,586:INFO:Checking exceptions
2025-12-02 14:49:15,599:INFO:Importing libraries
2025-12-02 14:49:15,599:INFO:Copying training dataset
2025-12-02 14:49:15,629:INFO:Defining folds
2025-12-02 14:49:15,629:INFO:Declaring metric variables
2025-12-02 14:49:15,633:INFO:Importing untrained model
2025-12-02 14:49:15,636:INFO:Extreme Gradient Boosting Imported successfully
2025-12-02 14:49:15,640:INFO:Starting cross validation
2025-12-02 14:49:15,641:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-12-02 14:49:21,821:INFO:Calculating mean and std
2025-12-02 14:49:21,821:INFO:Creating metrics dataframe
2025-12-02 14:49:21,825:INFO:Finalizing model
2025-12-02 14:49:21,904:INFO:Warning: No categorical columns found. Calling 'transform' will only return input data.
2025-12-02 14:49:22,420:INFO:Uploading results into container
2025-12-02 14:49:22,420:INFO:Uploading model into container now
2025-12-02 14:49:22,429:INFO:_master_model_container: 1
2025-12-02 14:49:22,429:INFO:_display_container: 2
2025-12-02 14:49:22,429:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2025-12-02 14:49:22,430:INFO:create_model() successfully completed......................................
2025-12-02 14:54:02,206:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-12-02 14:54:02,206:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-12-02 14:54:02,206:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-12-02 14:54:02,206:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-12-02 14:54:29,647:INFO:PyCaret ClassificationExperiment
2025-12-02 14:54:29,647:INFO:Logging name: clf-default-name
2025-12-02 14:54:29,647:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-12-02 14:54:29,647:INFO:version 3.3.2
2025-12-02 14:54:29,647:INFO:Initializing setup()
2025-12-02 14:54:29,647:INFO:self.USI: 30d0
2025-12-02 14:54:29,647:INFO:self._variable_keys: {'fold_shuffle_param', 'y_train', 'fold_generator', 'html_param', 'memory', 'data', 'target_param', 'logging_param', 'exp_id', 'y', 'X', 'gpu_n_jobs_param', 'pipeline', 'is_multiclass', 'fix_imbalance', '_ml_usecase', 'n_jobs_param', 'seed', 'log_plots_param', 'X_train', 'exp_name_log', 'USI', 'y_test', 'fold_groups_param', 'X_test', 'idx', '_available_plots', 'gpu_param'}
2025-12-02 14:54:29,648:INFO:Checking environment
2025-12-02 14:54:29,648:INFO:python_version: 3.10.19
2025-12-02 14:54:29,648:INFO:python_build: ('main', 'Oct 21 2025 16:41:31')
2025-12-02 14:54:29,648:INFO:machine: AMD64
2025-12-02 14:54:29,648:INFO:platform: Windows-10-10.0.26100-SP0
2025-12-02 14:54:29,648:INFO:Memory: svmem(total=16282144768, available=4519849984, percent=72.2, used=11762294784, free=4519849984)
2025-12-02 14:54:29,648:INFO:Physical Core: 6
2025-12-02 14:54:29,648:INFO:Logical Core: 12
2025-12-02 14:54:29,648:INFO:Checking libraries
2025-12-02 14:54:29,648:INFO:System:
2025-12-02 14:54:29,648:INFO:    python: 3.10.19 | packaged by Anaconda, Inc. | (main, Oct 21 2025, 16:41:31) [MSC v.1929 64 bit (AMD64)]
2025-12-02 14:54:29,648:INFO:executable: c:\Users\OMAR\miniconda3\envs\xgb_env\python.exe
2025-12-02 14:54:29,648:INFO:   machine: Windows-10-10.0.26100-SP0
2025-12-02 14:54:29,648:INFO:PyCaret required dependencies:
2025-12-02 14:54:29,650:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-02 14:54:30,198:INFO:                 pip: 25.3
2025-12-02 14:54:30,198:INFO:          setuptools: 80.9.0
2025-12-02 14:54:30,198:INFO:             pycaret: 3.3.2
2025-12-02 14:54:30,198:INFO:             IPython: 8.37.0
2025-12-02 14:54:30,200:INFO:          ipywidgets: 8.1.8
2025-12-02 14:54:30,200:INFO:                tqdm: 4.67.1
2025-12-02 14:54:30,200:INFO:               numpy: 1.26.4
2025-12-02 14:54:30,200:INFO:              pandas: 2.1.4
2025-12-02 14:54:30,200:INFO:              jinja2: 3.1.6
2025-12-02 14:54:30,200:INFO:               scipy: 1.11.4
2025-12-02 14:54:30,200:INFO:              joblib: 1.3.2
2025-12-02 14:54:30,200:INFO:             sklearn: 1.4.2
2025-12-02 14:54:30,200:INFO:                pyod: 2.0.5
2025-12-02 14:54:30,200:INFO:            imblearn: 0.14.0
2025-12-02 14:54:30,200:INFO:   category_encoders: 2.7.0
2025-12-02 14:54:30,200:INFO:            lightgbm: 4.6.0
2025-12-02 14:54:30,200:INFO:               numba: 0.62.1
2025-12-02 14:54:30,200:INFO:            requests: 2.32.5
2025-12-02 14:54:30,200:INFO:          matplotlib: 3.7.5
2025-12-02 14:54:30,200:INFO:          scikitplot: 0.3.7
2025-12-02 14:54:30,200:INFO:         yellowbrick: 1.5
2025-12-02 14:54:30,200:INFO:              plotly: 5.24.1
2025-12-02 14:54:30,200:INFO:    plotly-resampler: Not installed
2025-12-02 14:54:30,200:INFO:             kaleido: 1.2.0
2025-12-02 14:54:30,200:INFO:           schemdraw: 0.15
2025-12-02 14:54:30,200:INFO:         statsmodels: 0.14.5
2025-12-02 14:54:30,200:INFO:              sktime: 0.26.0
2025-12-02 14:54:30,200:INFO:               tbats: 1.1.3
2025-12-02 14:54:30,200:INFO:            pmdarima: 2.0.4
2025-12-02 14:54:30,200:INFO:              psutil: 7.1.3
2025-12-02 14:54:30,200:INFO:          markupsafe: 3.0.3
2025-12-02 14:54:30,200:INFO:             pickle5: Not installed
2025-12-02 14:54:30,200:INFO:         cloudpickle: 3.1.2
2025-12-02 14:54:30,200:INFO:         deprecation: 2.1.0
2025-12-02 14:54:30,200:INFO:              xxhash: 3.6.0
2025-12-02 14:54:30,200:INFO:           wurlitzer: Not installed
2025-12-02 14:54:30,200:INFO:PyCaret optional dependencies:
2025-12-02 14:54:32,940:INFO:                shap: 0.49.1
2025-12-02 14:54:32,940:INFO:           interpret: 0.7.3
2025-12-02 14:54:32,940:INFO:                umap: 0.5.7
2025-12-02 14:54:32,940:INFO:     ydata_profiling: 4.18.0
2025-12-02 14:54:32,940:INFO:  explainerdashboard: 0.5.1
2025-12-02 14:54:32,940:INFO:             autoviz: Not installed
2025-12-02 14:54:32,940:INFO:           fairlearn: 0.7.0
2025-12-02 14:54:32,940:INFO:          deepchecks: Not installed
2025-12-02 14:54:32,940:INFO:             xgboost: 2.1.3
2025-12-02 14:54:32,940:INFO:            catboost: 1.2.8
2025-12-02 14:54:32,940:INFO:              kmodes: 0.12.2
2025-12-02 14:54:32,940:INFO:             mlxtend: 0.23.4
2025-12-02 14:54:32,940:INFO:       statsforecast: 1.5.0
2025-12-02 14:54:32,940:INFO:        tune_sklearn: Not installed
2025-12-02 14:54:32,940:INFO:                 ray: Not installed
2025-12-02 14:54:32,940:INFO:            hyperopt: 0.2.7
2025-12-02 14:54:32,940:INFO:              optuna: 4.6.0
2025-12-02 14:54:32,940:INFO:               skopt: 0.10.2
2025-12-02 14:54:32,940:INFO:              mlflow: 3.6.0
2025-12-02 14:54:32,940:INFO:              gradio: 6.0.1
2025-12-02 14:54:32,940:INFO:             fastapi: 0.123.0
2025-12-02 14:54:32,940:INFO:             uvicorn: 0.38.0
2025-12-02 14:54:32,940:INFO:              m2cgen: 0.10.0
2025-12-02 14:54:32,940:INFO:           evidently: 0.4.40
2025-12-02 14:54:32,940:INFO:               fugue: 0.8.7
2025-12-02 14:54:32,940:INFO:           streamlit: 1.51.0
2025-12-02 14:54:32,940:INFO:             prophet: Not installed
2025-12-02 14:54:32,940:INFO:None
2025-12-02 14:54:32,940:INFO:Set up data.
2025-12-02 14:54:32,960:INFO:Set up folding strategy.
2025-12-02 14:54:32,961:INFO:Set up train/test split.
2025-12-02 14:54:32,982:INFO:Set up index.
2025-12-02 14:54:32,982:INFO:Assigning column types.
2025-12-02 14:54:33,006:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-12-02 14:54:33,032:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-12-02 14:54:33,032:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-02 14:54:33,053:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-02 14:54:33,056:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-02 14:54:33,101:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-12-02 14:54:33,101:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-02 14:54:33,116:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-02 14:54:33,117:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-02 14:54:33,118:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-12-02 14:54:33,144:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-02 14:54:33,159:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-02 14:54:33,160:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-02 14:54:33,184:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-02 14:54:33,202:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-02 14:54:33,203:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-02 14:54:33,203:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-12-02 14:54:33,244:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-02 14:54:33,248:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-02 14:54:33,289:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-02 14:54:33,290:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-02 14:54:33,290:INFO:Preparing preprocessing pipeline...
2025-12-02 14:54:33,296:INFO:Set up simple imputation.
2025-12-02 14:54:33,310:INFO:Set up encoding of ordinal features.
2025-12-02 14:54:33,316:INFO:Set up encoding of categorical features.
2025-12-02 14:54:33,316:INFO:Set up feature normalization.
2025-12-02 14:54:33,653:INFO:Finished creating preprocessing pipeline.
2025-12-02 14:54:33,671:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\OMAR\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'IncomeRatio', 'SystolicBP',
                                             'BMI', 'WaistCircumference',
                                             'Height', 'TotalCholesterol',
                                             'Triglycerides', 'LDL', 'HDL',
                                             'HbA1c', 'Glucose', 'Creatinine',
                                             'UricAcid', 'ALT_Enzyme',
                                             'Albumin', 'Potassium', 'Sodium',
                                             'G...
                                    transformer=TargetEncoder(cols=[],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=RobustScaler(copy=True,
                                                             quantile_range=(25.0,
                                                                             75.0),
                                                             unit_variance=False,
                                                             with_centering=True,
                                                             with_scaling=True)))],
         verbose=False)
2025-12-02 14:54:33,671:INFO:Creating final display dataframe.
2025-12-02 14:54:34,050:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target      HeartDisease
2                   Target type            Binary
3           Original data shape       (43695, 28)
4        Transformed data shape       (43695, 32)
5   Transformed train set shape       (30586, 32)
6    Transformed test set shape       (13109, 32)
7              Numeric features                20
8          Categorical features                 7
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15                    Normalize              True
16             Normalize method            robust
17               Fold Generator   StratifiedKFold
18                  Fold Number                10
19                     CPU Jobs                 1
20                      Use GPU             False
21               Log Experiment             False
22              Experiment Name  clf-default-name
23                          USI              30d0
2025-12-02 14:54:34,121:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-02 14:54:34,123:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-02 14:54:34,170:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-02 14:54:34,172:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-02 14:54:34,173:INFO:setup() successfully completed in 4.53s...............
2025-12-02 14:54:50,746:INFO:Initializing get_config()
2025-12-02 14:54:50,746:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016C4FEC0AC0>, variable=y_train)
2025-12-02 14:54:50,746:INFO:Variable: 'y_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_train_transformed' instead.
2025-12-02 14:54:50,747:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_train_transformed' instead.

2025-12-02 14:54:50,756:INFO:Variable:  returned as 15208    0.0
25325    0.0
5132     0.0
17217    0.0
6382     0.0
        ... 
6265     0.0
42694    0.0
13399    0.0
39959    0.0
6616     0.0
Name: HeartDisease, Length: 30586, dtype: float32
2025-12-02 14:54:50,756:INFO:get_config() successfully completed......................................
2025-12-02 14:54:50,758:INFO:Initializing create_model()
2025-12-02 14:54:50,758:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016C4FEC0AC0>, estimator=xgboost, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={'scale_pos_weight': 38.162612035851474})
2025-12-02 14:54:50,758:INFO:Checking exceptions
2025-12-02 14:54:50,772:INFO:Importing libraries
2025-12-02 14:54:50,772:INFO:Copying training dataset
2025-12-02 14:54:50,801:INFO:Defining folds
2025-12-02 14:54:50,801:INFO:Declaring metric variables
2025-12-02 14:54:50,805:INFO:Importing untrained model
2025-12-02 14:54:50,807:INFO:Extreme Gradient Boosting Imported successfully
2025-12-02 14:54:50,812:INFO:Starting cross validation
2025-12-02 14:54:50,813:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-12-02 14:54:56,973:INFO:Calculating mean and std
2025-12-02 14:54:56,973:INFO:Creating metrics dataframe
2025-12-02 14:54:56,980:INFO:Finalizing model
2025-12-02 14:54:57,069:INFO:Warning: No categorical columns found. Calling 'transform' will only return input data.
2025-12-02 14:54:57,579:INFO:Uploading results into container
2025-12-02 14:54:57,580:INFO:Uploading model into container now
2025-12-02 14:54:57,588:INFO:_master_model_container: 1
2025-12-02 14:54:57,588:INFO:_display_container: 2
2025-12-02 14:54:57,589:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2025-12-02 14:54:57,590:INFO:create_model() successfully completed......................................
2025-12-02 14:55:30,024:INFO:Initializing tune_model()
2025-12-02 14:55:30,024:INFO:tune_model(estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...), fold=None, round=4, n_iter=5, custom_grid=None, optimize=Recall, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=False, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016C4FEC0AC0>)
2025-12-02 14:55:30,024:INFO:Checking exceptions
2025-12-02 14:55:30,044:INFO:Copying training dataset
2025-12-02 14:55:30,060:INFO:Checking base model
2025-12-02 14:55:30,060:INFO:Base model : Extreme Gradient Boosting
2025-12-02 14:55:30,060:INFO:Declaring metric variables
2025-12-02 14:55:30,060:INFO:Defining Hyperparameters
2025-12-02 14:55:30,218:INFO:Tuning with n_jobs=1
2025-12-02 14:55:30,218:INFO:Initializing RandomizedSearchCV
2025-12-02 14:56:04,740:INFO:best_params: {'actual_estimator__subsample': 0.7, 'actual_estimator__scale_pos_weight': 38.0, 'actual_estimator__reg_lambda': 0.7, 'actual_estimator__reg_alpha': 0.001, 'actual_estimator__n_estimators': 60, 'actual_estimator__min_child_weight': 1, 'actual_estimator__max_depth': 6, 'actual_estimator__learning_rate': 0.4, 'actual_estimator__colsample_bytree': 0.7}
2025-12-02 14:56:04,740:INFO:Hyperparameter search completed
2025-12-02 14:56:04,740:INFO:SubProcess create_model() called ==================================
2025-12-02 14:56:04,740:INFO:Initializing create_model()
2025-12-02 14:56:04,740:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016C4FEC0AC0>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016C4FF0A290>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'subsample': 0.7, 'scale_pos_weight': 38.0, 'reg_lambda': 0.7, 'reg_alpha': 0.001, 'n_estimators': 60, 'min_child_weight': 1, 'max_depth': 6, 'learning_rate': 0.4, 'colsample_bytree': 0.7})
2025-12-02 14:56:04,740:INFO:Checking exceptions
2025-12-02 14:56:04,740:INFO:Importing libraries
2025-12-02 14:56:04,740:INFO:Copying training dataset
2025-12-02 14:56:04,764:INFO:Defining folds
2025-12-02 14:56:04,764:INFO:Declaring metric variables
2025-12-02 14:56:04,764:INFO:Importing untrained model
2025-12-02 14:56:04,764:INFO:Declaring custom model
2025-12-02 14:56:04,766:INFO:Extreme Gradient Boosting Imported successfully
2025-12-02 14:56:04,766:INFO:Starting cross validation
2025-12-02 14:56:04,766:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-12-02 14:56:09,569:INFO:Calculating mean and std
2025-12-02 14:56:09,569:INFO:Creating metrics dataframe
2025-12-02 14:56:09,571:INFO:Finalizing model
2025-12-02 14:56:09,640:INFO:Warning: No categorical columns found. Calling 'transform' will only return input data.
2025-12-02 14:56:10,040:INFO:Uploading results into container
2025-12-02 14:56:10,040:INFO:Uploading model into container now
2025-12-02 14:56:10,040:INFO:_master_model_container: 2
2025-12-02 14:56:10,040:INFO:_display_container: 3
2025-12-02 14:56:10,042:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=0.7, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=0.4, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=6, max_leaves=None,
              min_child_weight=1, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=60, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2025-12-02 14:56:10,042:INFO:create_model() successfully completed......................................
2025-12-02 14:56:10,224:INFO:SubProcess create_model() end ==================================
2025-12-02 14:56:10,224:INFO:choose_better activated
2025-12-02 14:56:10,224:INFO:SubProcess create_model() called ==================================
2025-12-02 14:56:10,224:INFO:Initializing create_model()
2025-12-02 14:56:10,224:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016C4FEC0AC0>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-02 14:56:10,224:INFO:Checking exceptions
2025-12-02 14:56:10,224:INFO:Importing libraries
2025-12-02 14:56:10,224:INFO:Copying training dataset
2025-12-02 14:56:10,251:INFO:Defining folds
2025-12-02 14:56:10,251:INFO:Declaring metric variables
2025-12-02 14:56:10,251:INFO:Importing untrained model
2025-12-02 14:56:10,251:INFO:Declaring custom model
2025-12-02 14:56:10,253:INFO:Extreme Gradient Boosting Imported successfully
2025-12-02 14:56:10,253:INFO:Starting cross validation
2025-12-02 14:56:10,253:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-12-02 14:56:16,139:INFO:Calculating mean and std
2025-12-02 14:56:16,140:INFO:Creating metrics dataframe
2025-12-02 14:56:16,142:INFO:Finalizing model
2025-12-02 14:56:16,210:INFO:Warning: No categorical columns found. Calling 'transform' will only return input data.
2025-12-02 14:56:16,710:INFO:Uploading results into container
2025-12-02 14:56:16,712:INFO:Uploading model into container now
2025-12-02 14:56:16,712:INFO:_master_model_container: 3
2025-12-02 14:56:16,712:INFO:_display_container: 4
2025-12-02 14:56:16,712:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2025-12-02 14:56:16,712:INFO:create_model() successfully completed......................................
2025-12-02 14:56:16,896:INFO:SubProcess create_model() end ==================================
2025-12-02 14:56:16,896:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...) result for Recall is 0.2882
2025-12-02 14:56:16,896:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=0.7, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=0.4, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=6, max_leaves=None,
              min_child_weight=1, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=60, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...) result for Recall is 0.3316
2025-12-02 14:56:16,896:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=0.7, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=0.4, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=6, max_leaves=None,
              min_child_weight=1, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=60, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...) is best model
2025-12-02 14:56:16,896:INFO:choose_better completed
2025-12-02 14:56:16,896:INFO:_master_model_container: 3
2025-12-02 14:56:16,896:INFO:_display_container: 3
2025-12-02 14:56:16,896:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=0.7, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=0.4, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=6, max_leaves=None,
              min_child_weight=1, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=60, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2025-12-02 14:56:16,896:INFO:tune_model() successfully completed......................................
2025-12-02 14:56:23,047:INFO:Initializing predict_model()
2025-12-02 14:56:23,047:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016C4FEC0AC0>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=0.7, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=0.4, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=6, max_leaves=None,
              min_child_weight=1, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=60, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...), probability_threshold=None, encoded_labels=False, raw_score=True, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000016C4C208550>)
2025-12-02 14:56:23,047:INFO:Checking exceptions
2025-12-02 14:56:23,047:INFO:Preloading libraries
2025-12-02 14:56:23,460:INFO:Initializing get_config()
2025-12-02 14:56:23,460:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016C4FEC0AC0>, variable=target_param)
2025-12-02 14:56:23,460:INFO:Variable:  returned as HeartDisease
2025-12-02 14:56:23,460:INFO:get_config() successfully completed......................................
2025-12-02 14:56:34,856:INFO:Initializing interpret_model()
2025-12-02 14:56:34,856:INFO:interpret_model(estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=0.7, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=0.4, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=6, max_leaves=None,
              min_child_weight=1, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=60, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...), use_train_data=False, X_new_sample=None, y_new_sample=None, feature=None, kwargs={}, observation=None, plot=summary, save=False, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016C4FEC0AC0>)
2025-12-02 14:56:34,856:INFO:Checking exceptions
2025-12-02 14:56:34,856:INFO:Soft dependency imported: shap: 0.49.1
2025-12-02 14:56:34,932:INFO:plot type: summary
2025-12-02 14:56:34,932:INFO:Creating TreeExplainer
2025-12-02 14:56:34,941:INFO:Compiling shap values
2025-12-02 14:56:38,251:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:4145: FutureWarning: The NumPy global RNG was seeded by calling `np.random.seed`. In a future version this function will no longer use the global RNG. Pass `rng` explicitly to opt-in to the new behaviour and silence this warning.

2025-12-02 14:56:39,403:INFO:Visual Rendered Successfully
2025-12-02 14:56:39,403:INFO:interpret_model() successfully completed......................................
2025-12-02 14:56:49,623:INFO:Initializing finalize_model()
2025-12-02 14:56:49,623:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016C4FEC0AC0>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=0.7, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=0.4, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=6, max_leaves=None,
              min_child_weight=1, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=60, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2025-12-02 14:56:49,623:INFO:Finalizing XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=0.7, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=0.4, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=6, max_leaves=None,
              min_child_weight=1, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=60, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2025-12-02 14:56:49,643:INFO:Initializing create_model()
2025-12-02 14:56:49,643:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016C4FEC0AC0>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=0.7, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=0.4, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=6, max_leaves=None,
              min_child_weight=1, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=60, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2025-12-02 14:56:49,643:INFO:Checking exceptions
2025-12-02 14:56:49,644:INFO:Importing libraries
2025-12-02 14:56:49,644:INFO:Copying training dataset
2025-12-02 14:56:49,649:INFO:Defining folds
2025-12-02 14:56:49,649:INFO:Declaring metric variables
2025-12-02 14:56:49,650:INFO:Importing untrained model
2025-12-02 14:56:49,650:INFO:Declaring custom model
2025-12-02 14:56:49,651:INFO:Extreme Gradient Boosting Imported successfully
2025-12-02 14:56:49,652:INFO:Cross validation set to False
2025-12-02 14:56:49,653:INFO:Fitting Model
2025-12-02 14:56:49,762:INFO:Warning: No categorical columns found. Calling 'transform' will only return input data.
2025-12-02 14:56:50,326:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'IncomeRatio', 'SystolicBP',
                                             'BMI', 'WaistCircumference',
                                             'Height', 'TotalCholesterol',
                                             'Triglycerides', 'LDL', 'HDL',
                                             'HbA1c', 'Glucose', 'Creatinine',
                                             'UricAcid', 'ALT_Enzyme',
                                             'Albumin', 'Potassium', 'Sodium',
                                             'GGT_Enzyme', 'AST_Enzyme'],
                                    transformer=Si...
                               feature_types=None, gamma=None, grow_policy=None,
                               importance_type=None,
                               interaction_constraints=None, learning_rate=0.4,
                               max_bin=None, max_cat_threshold=None,
                               max_cat_to_onehot=None, max_delta_step=None,
                               max_depth=6, max_leaves=None, min_child_weight=1,
                               missing=nan, monotone_constraints=None,
                               multi_strategy=None, n_estimators=60, n_jobs=1,
                               num_parallel_tree=None,
                               objective='binary:logistic', ...))],
         verbose=False)
2025-12-02 14:56:50,326:INFO:create_model() successfully completed......................................
2025-12-02 14:56:50,499:INFO:_master_model_container: 3
2025-12-02 14:56:50,500:INFO:_display_container: 4
2025-12-02 14:56:50,516:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'IncomeRatio', 'SystolicBP',
                                             'BMI', 'WaistCircumference',
                                             'Height', 'TotalCholesterol',
                                             'Triglycerides', 'LDL', 'HDL',
                                             'HbA1c', 'Glucose', 'Creatinine',
                                             'UricAcid', 'ALT_Enzyme',
                                             'Albumin', 'Potassium', 'Sodium',
                                             'GGT_Enzyme', 'AST_Enzyme'],
                                    transformer=Si...
                               feature_types=None, gamma=None, grow_policy=None,
                               importance_type=None,
                               interaction_constraints=None, learning_rate=0.4,
                               max_bin=None, max_cat_threshold=None,
                               max_cat_to_onehot=None, max_delta_step=None,
                               max_depth=6, max_leaves=None, min_child_weight=1,
                               missing=nan, monotone_constraints=None,
                               multi_strategy=None, n_estimators=60, n_jobs=1,
                               num_parallel_tree=None,
                               objective='binary:logistic', ...))],
         verbose=False)
2025-12-02 14:56:50,516:INFO:finalize_model() successfully completed......................................
2025-12-02 14:56:50,710:INFO:Initializing save_model()
2025-12-02 14:56:50,710:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'IncomeRatio', 'SystolicBP',
                                             'BMI', 'WaistCircumference',
                                             'Height', 'TotalCholesterol',
                                             'Triglycerides', 'LDL', 'HDL',
                                             'HbA1c', 'Glucose', 'Creatinine',
                                             'UricAcid', 'ALT_Enzyme',
                                             'Albumin', 'Potassium', 'Sodium',
                                             'GGT_Enzyme', 'AST_Enzyme'],
                                    transformer=Si...
                               feature_types=None, gamma=None, grow_policy=None,
                               importance_type=None,
                               interaction_constraints=None, learning_rate=0.4,
                               max_bin=None, max_cat_threshold=None,
                               max_cat_to_onehot=None, max_delta_step=None,
                               max_depth=6, max_leaves=None, min_child_weight=1,
                               missing=nan, monotone_constraints=None,
                               multi_strategy=None, n_estimators=60, n_jobs=1,
                               num_parallel_tree=None,
                               objective='binary:logistic', ...))],
         verbose=False), model_name=../models\best_pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\OMAR\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'IncomeRatio', 'SystolicBP',
                                             'BMI', 'WaistCircumference',
                                             'Height', 'TotalCholesterol',
                                             'Triglycerides', 'LDL', 'HDL',
                                             'HbA1c', 'Glucose', 'Creatinine',
                                             'UricAcid', 'ALT_Enzyme',
                                             'Albumin', 'Potassium', 'Sodium',
                                             'G...
                                    transformer=TargetEncoder(cols=[],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=RobustScaler(copy=True,
                                                             quantile_range=(25.0,
                                                                             75.0),
                                                             unit_variance=False,
                                                             with_centering=True,
                                                             with_scaling=True)))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2025-12-02 14:56:50,710:INFO:Adding model into prep_pipe
2025-12-02 14:56:50,710:WARNING:Only Model saved as it was a pipeline.
2025-12-02 14:56:50,716:INFO:../models\best_pipeline.pkl saved in current working directory
2025-12-02 14:56:50,732:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'IncomeRatio', 'SystolicBP',
                                             'BMI', 'WaistCircumference',
                                             'Height', 'TotalCholesterol',
                                             'Triglycerides', 'LDL', 'HDL',
                                             'HbA1c', 'Glucose', 'Creatinine',
                                             'UricAcid', 'ALT_Enzyme',
                                             'Albumin', 'Potassium', 'Sodium',
                                             'GGT_Enzyme', 'AST_Enzyme'],
                                    transformer=Si...
                               feature_types=None, gamma=None, grow_policy=None,
                               importance_type=None,
                               interaction_constraints=None, learning_rate=0.4,
                               max_bin=None, max_cat_threshold=None,
                               max_cat_to_onehot=None, max_delta_step=None,
                               max_depth=6, max_leaves=None, min_child_weight=1,
                               missing=nan, monotone_constraints=None,
                               multi_strategy=None, n_estimators=60, n_jobs=1,
                               num_parallel_tree=None,
                               objective='binary:logistic', ...))],
         verbose=False)
2025-12-02 14:56:50,732:INFO:save_model() successfully completed......................................
2025-12-02 14:57:11,460:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-12-02 14:57:11,460:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-12-02 14:57:11,460:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-12-02 14:57:11,460:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-12-02 14:57:15,190:INFO:Initializing load_model()
2025-12-02 14:57:15,191:INFO:load_model(model_name=../models/best_pipeline, platform=None, authentication=None, verbose=True)
2025-12-02 14:57:15,224:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-02 14:57:28,243:INFO:Initializing predict_model()
2025-12-02 14:57:28,243:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001CCB1D1F370>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Age', 'IncomeRatio', 'SystolicBP',
                                             'BMI', 'WaistCircumference',
                                             'Height', 'TotalCholesterol',
                                             'Triglycerides', 'LDL', 'HDL',
                                             'HbA1c', 'Glucose', 'Creatinine',
                                             'UricAcid', 'ALT_Enzyme',
                                             'Albumin', 'Potassium', 'Sodium',
                                             'GGT_Enzyme', 'AST_Enzyme'],
                                    transformer=SimpleImputer()...
                               feature_types=None, gamma=None, grow_policy=None,
                               importance_type=None,
                               interaction_constraints=None, learning_rate=0.4,
                               max_bin=None, max_cat_threshold=None,
                               max_cat_to_onehot=None, max_delta_step=None,
                               max_depth=6, max_leaves=None, min_child_weight=1,
                               missing=nan, monotone_constraints=None,
                               multi_strategy=None, n_estimators=60, n_jobs=1,
                               num_parallel_tree=None, random_state=42, ...))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001CCB0BCD5A0>)
2025-12-02 14:57:28,243:INFO:Checking exceptions
2025-12-02 14:57:28,243:INFO:Preloading libraries
2025-12-02 14:57:28,243:INFO:Set up data.
2025-12-02 14:57:28,252:INFO:Set up index.
2025-12-02 14:58:17,319:INFO:Initializing load_model()
2025-12-02 14:58:17,319:INFO:load_model(model_name=../models/best_pipeline, platform=None, authentication=None, verbose=True)
2025-12-02 14:58:30,493:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-12-02 14:58:30,494:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-12-02 14:58:30,494:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-12-02 14:58:30,494:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-12-02 14:58:34,726:INFO:Initializing load_model()
2025-12-02 14:58:34,726:INFO:load_model(model_name=../models/best_pipeline, platform=None, authentication=None, verbose=True)
2025-12-02 14:58:34,859:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-02 14:58:46,040:INFO:Initializing predict_model()
2025-12-02 14:58:46,040:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000026DDFC57130>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Age', 'IncomeRatio', 'SystolicBP',
                                             'BMI', 'WaistCircumference',
                                             'Height', 'TotalCholesterol',
                                             'Triglycerides', 'LDL', 'HDL',
                                             'HbA1c', 'Glucose', 'Creatinine',
                                             'UricAcid', 'ALT_Enzyme',
                                             'Albumin', 'Potassium', 'Sodium',
                                             'GGT_Enzyme', 'AST_Enzyme'],
                                    transformer=SimpleImputer()...
                               feature_types=None, gamma=None, grow_policy=None,
                               importance_type=None,
                               interaction_constraints=None, learning_rate=0.4,
                               max_bin=None, max_cat_threshold=None,
                               max_cat_to_onehot=None, max_delta_step=None,
                               max_depth=6, max_leaves=None, min_child_weight=1,
                               missing=nan, monotone_constraints=None,
                               multi_strategy=None, n_estimators=60, n_jobs=1,
                               num_parallel_tree=None, random_state=42, ...))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000026DDFC5A440>)
2025-12-02 14:58:46,040:INFO:Checking exceptions
2025-12-02 14:58:46,040:INFO:Preloading libraries
2025-12-02 14:58:46,040:INFO:Set up data.
2025-12-02 14:58:46,044:INFO:Set up index.
2025-12-02 15:15:45,769:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-12-02 15:15:45,769:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-12-02 15:15:45,769:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-12-02 15:15:45,769:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-12-02 15:18:46,360:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-12-02 15:18:46,360:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-12-02 15:18:46,360:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-12-02 15:18:46,360:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-12-02 15:18:51,624:INFO:Initializing load_model()
2025-12-02 15:18:51,624:INFO:load_model(model_name=../models/best_pipeline, platform=None, authentication=None, verbose=True)
2025-12-02 15:18:51,657:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-02 15:20:34,238:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-12-02 15:20:34,238:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-12-02 15:20:34,238:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-12-02 15:20:34,238:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-12-02 15:20:37,908:INFO:Initializing load_model()
2025-12-02 15:20:37,908:INFO:load_model(model_name=../models/best_pipeline, platform=None, authentication=None, verbose=True)
2025-12-02 15:20:37,940:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-02 17:20:55,714:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-12-02 17:20:55,714:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-12-02 17:20:55,714:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-12-02 17:20:55,714:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-12-02 17:21:39,025:INFO:PyCaret ClassificationExperiment
2025-12-02 17:21:39,025:INFO:Logging name: clf-default-name
2025-12-02 17:21:39,025:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-12-02 17:21:39,025:INFO:version 3.3.2
2025-12-02 17:21:39,025:INFO:Initializing setup()
2025-12-02 17:21:39,025:INFO:self.USI: b045
2025-12-02 17:21:39,025:INFO:self._variable_keys: {'X_train', 'exp_id', 'fold_shuffle_param', 'is_multiclass', 'y_train', '_available_plots', '_ml_usecase', 'y', 'html_param', 'fix_imbalance', 'X', 'idx', 'fold_groups_param', 'log_plots_param', 'X_test', 'seed', 'USI', 'memory', 'n_jobs_param', 'data', 'gpu_param', 'exp_name_log', 'gpu_n_jobs_param', 'pipeline', 'y_test', 'fold_generator', 'target_param', 'logging_param'}
2025-12-02 17:21:39,025:INFO:Checking environment
2025-12-02 17:21:39,025:INFO:python_version: 3.10.19
2025-12-02 17:21:39,025:INFO:python_build: ('main', 'Oct 21 2025 16:41:31')
2025-12-02 17:21:39,025:INFO:machine: AMD64
2025-12-02 17:21:39,025:INFO:platform: Windows-10-10.0.26100-SP0
2025-12-02 17:21:39,025:INFO:Memory: svmem(total=16282144768, available=4228182016, percent=74.0, used=12053962752, free=4228182016)
2025-12-02 17:21:39,026:INFO:Physical Core: 6
2025-12-02 17:21:39,026:INFO:Logical Core: 12
2025-12-02 17:21:39,026:INFO:Checking libraries
2025-12-02 17:21:39,026:INFO:System:
2025-12-02 17:21:39,026:INFO:    python: 3.10.19 | packaged by Anaconda, Inc. | (main, Oct 21 2025, 16:41:31) [MSC v.1929 64 bit (AMD64)]
2025-12-02 17:21:39,026:INFO:executable: c:\Users\OMAR\miniconda3\envs\xgb_env\python.exe
2025-12-02 17:21:39,026:INFO:   machine: Windows-10-10.0.26100-SP0
2025-12-02 17:21:39,026:INFO:PyCaret required dependencies:
2025-12-02 17:21:39,027:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-02 17:21:39,716:INFO:                 pip: 25.3
2025-12-02 17:21:39,716:INFO:          setuptools: 80.9.0
2025-12-02 17:21:39,716:INFO:             pycaret: 3.3.2
2025-12-02 17:21:39,716:INFO:             IPython: 8.37.0
2025-12-02 17:21:39,716:INFO:          ipywidgets: 8.1.8
2025-12-02 17:21:39,716:INFO:                tqdm: 4.67.1
2025-12-02 17:21:39,716:INFO:               numpy: 1.26.4
2025-12-02 17:21:39,716:INFO:              pandas: 2.1.4
2025-12-02 17:21:39,716:INFO:              jinja2: 3.1.6
2025-12-02 17:21:39,716:INFO:               scipy: 1.11.4
2025-12-02 17:21:39,716:INFO:              joblib: 1.3.2
2025-12-02 17:21:39,716:INFO:             sklearn: 1.4.2
2025-12-02 17:21:39,716:INFO:                pyod: 2.0.5
2025-12-02 17:21:39,716:INFO:            imblearn: 0.14.0
2025-12-02 17:21:39,716:INFO:   category_encoders: 2.7.0
2025-12-02 17:21:39,716:INFO:            lightgbm: 4.6.0
2025-12-02 17:21:39,716:INFO:               numba: 0.62.1
2025-12-02 17:21:39,716:INFO:            requests: 2.32.5
2025-12-02 17:21:39,716:INFO:          matplotlib: 3.7.5
2025-12-02 17:21:39,719:INFO:          scikitplot: 0.3.7
2025-12-02 17:21:39,719:INFO:         yellowbrick: 1.5
2025-12-02 17:21:39,719:INFO:              plotly: 5.24.1
2025-12-02 17:21:39,719:INFO:    plotly-resampler: Not installed
2025-12-02 17:21:39,719:INFO:             kaleido: 1.2.0
2025-12-02 17:21:39,719:INFO:           schemdraw: 0.15
2025-12-02 17:21:39,719:INFO:         statsmodels: 0.14.5
2025-12-02 17:21:39,719:INFO:              sktime: 0.26.0
2025-12-02 17:21:39,719:INFO:               tbats: 1.1.3
2025-12-02 17:21:39,719:INFO:            pmdarima: 2.0.4
2025-12-02 17:21:39,719:INFO:              psutil: 7.1.3
2025-12-02 17:21:39,719:INFO:          markupsafe: 3.0.3
2025-12-02 17:21:39,719:INFO:             pickle5: Not installed
2025-12-02 17:21:39,719:INFO:         cloudpickle: 3.1.2
2025-12-02 17:21:39,719:INFO:         deprecation: 2.1.0
2025-12-02 17:21:39,719:INFO:              xxhash: 3.6.0
2025-12-02 17:21:39,719:INFO:           wurlitzer: Not installed
2025-12-02 17:21:39,719:INFO:PyCaret optional dependencies:
2025-12-02 17:21:43,106:INFO:                shap: 0.49.1
2025-12-02 17:21:43,106:INFO:           interpret: 0.7.3
2025-12-02 17:21:43,106:INFO:                umap: 0.5.7
2025-12-02 17:21:43,106:INFO:     ydata_profiling: 4.18.0
2025-12-02 17:21:43,106:INFO:  explainerdashboard: 0.5.1
2025-12-02 17:21:43,106:INFO:             autoviz: Not installed
2025-12-02 17:21:43,106:INFO:           fairlearn: 0.7.0
2025-12-02 17:21:43,106:INFO:          deepchecks: Not installed
2025-12-02 17:21:43,106:INFO:             xgboost: 2.1.3
2025-12-02 17:21:43,106:INFO:            catboost: 1.2.8
2025-12-02 17:21:43,106:INFO:              kmodes: 0.12.2
2025-12-02 17:21:43,106:INFO:             mlxtend: 0.23.4
2025-12-02 17:21:43,106:INFO:       statsforecast: 1.5.0
2025-12-02 17:21:43,106:INFO:        tune_sklearn: Not installed
2025-12-02 17:21:43,106:INFO:                 ray: Not installed
2025-12-02 17:21:43,106:INFO:            hyperopt: 0.2.7
2025-12-02 17:21:43,106:INFO:              optuna: 4.6.0
2025-12-02 17:21:43,106:INFO:               skopt: 0.10.2
2025-12-02 17:21:43,106:INFO:              mlflow: 3.6.0
2025-12-02 17:21:43,106:INFO:              gradio: 6.0.1
2025-12-02 17:21:43,106:INFO:             fastapi: 0.123.0
2025-12-02 17:21:43,106:INFO:             uvicorn: 0.38.0
2025-12-02 17:21:43,106:INFO:              m2cgen: 0.10.0
2025-12-02 17:21:43,106:INFO:           evidently: 0.4.40
2025-12-02 17:21:43,106:INFO:               fugue: 0.8.7
2025-12-02 17:21:43,106:INFO:           streamlit: 1.51.0
2025-12-02 17:21:43,106:INFO:             prophet: Not installed
2025-12-02 17:21:43,106:INFO:None
2025-12-02 17:21:43,106:INFO:Set up data.
2025-12-02 17:21:43,123:INFO:Set up folding strategy.
2025-12-02 17:21:43,123:INFO:Set up train/test split.
2025-12-02 17:21:43,151:INFO:Set up index.
2025-12-02 17:21:43,154:INFO:Assigning column types.
2025-12-02 17:21:43,180:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-12-02 17:21:43,206:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-12-02 17:21:43,210:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-02 17:21:43,237:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-02 17:21:43,239:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-02 17:21:43,531:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-12-02 17:21:43,531:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-02 17:21:43,547:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-02 17:21:43,550:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-02 17:21:43,551:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-12-02 17:21:43,573:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-02 17:21:43,592:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-02 17:21:43,592:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-02 17:21:43,621:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-02 17:21:43,636:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-02 17:21:43,636:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-02 17:21:43,636:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-12-02 17:21:43,676:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-02 17:21:43,681:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-02 17:21:43,723:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-02 17:21:43,724:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-02 17:21:43,726:INFO:Preparing preprocessing pipeline...
2025-12-02 17:21:43,731:INFO:Set up simple imputation.
2025-12-02 17:21:43,746:INFO:Set up encoding of ordinal features.
2025-12-02 17:21:43,753:INFO:Set up encoding of categorical features.
2025-12-02 17:21:43,753:INFO:Set up feature normalization.
2025-12-02 17:21:43,931:INFO:Finished creating preprocessing pipeline.
2025-12-02 17:21:43,946:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\OMAR\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'IncomeRatio', 'SystolicBP',
                                             'BMI', 'WaistCircumference',
                                             'Height', 'TotalCholesterol',
                                             'Triglycerides', 'LDL', 'HDL',
                                             'HbA1c', 'Glucose', 'Creatinine',
                                             'UricAcid', 'ALT_Enzyme',
                                             'Albumin', 'Potassium', 'Sodium',
                                             'G...
                                    transformer=TargetEncoder(cols=[],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=RobustScaler(copy=True,
                                                             quantile_range=(25.0,
                                                                             75.0),
                                                             unit_variance=False,
                                                             with_centering=True,
                                                             with_scaling=True)))],
         verbose=False)
2025-12-02 17:21:43,946:INFO:Creating final display dataframe.
2025-12-02 17:21:44,171:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target      HeartDisease
2                   Target type            Binary
3           Original data shape       (43695, 28)
4        Transformed data shape       (43695, 32)
5   Transformed train set shape       (30586, 32)
6    Transformed test set shape       (13109, 32)
7              Numeric features                20
8          Categorical features                 7
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15                    Normalize              True
16             Normalize method            robust
17               Fold Generator   StratifiedKFold
18                  Fold Number                10
19                     CPU Jobs                 1
20                      Use GPU             False
21               Log Experiment             False
22              Experiment Name  clf-default-name
23                          USI              b045
2025-12-02 17:21:44,222:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-02 17:21:44,225:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-02 17:21:44,267:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-02 17:21:44,268:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-02 17:21:44,271:INFO:setup() successfully completed in 5.26s...............
2025-12-02 17:21:54,219:INFO:Initializing get_config()
2025-12-02 17:21:54,219:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000019D68AAC430>, variable=y_train)
2025-12-02 17:21:54,219:INFO:Variable: 'y_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_train_transformed' instead.
2025-12-02 17:21:54,219:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_train_transformed' instead.

2025-12-02 17:21:54,226:INFO:Variable:  returned as 15208    0.0
25325    0.0
5132     0.0
17217    0.0
6382     0.0
        ... 
6265     0.0
42694    0.0
13399    0.0
39959    0.0
6616     0.0
Name: HeartDisease, Length: 30586, dtype: float32
2025-12-02 17:21:54,226:INFO:get_config() successfully completed......................................
2025-12-02 17:21:54,228:INFO:Initializing create_model()
2025-12-02 17:21:54,228:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000019D68AAC430>, estimator=xgboost, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={'scale_pos_weight': 38.162612035851474})
2025-12-02 17:21:54,228:INFO:Checking exceptions
2025-12-02 17:21:54,241:INFO:Importing libraries
2025-12-02 17:21:54,241:INFO:Copying training dataset
2025-12-02 17:21:54,270:INFO:Defining folds
2025-12-02 17:21:54,270:INFO:Declaring metric variables
2025-12-02 17:21:54,278:INFO:Importing untrained model
2025-12-02 17:21:54,285:INFO:Extreme Gradient Boosting Imported successfully
2025-12-02 17:21:54,293:INFO:Starting cross validation
2025-12-02 17:21:54,295:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-12-02 17:22:00,486:INFO:Calculating mean and std
2025-12-02 17:22:00,486:INFO:Creating metrics dataframe
2025-12-02 17:22:00,499:INFO:Finalizing model
2025-12-02 17:22:00,586:INFO:Warning: No categorical columns found. Calling 'transform' will only return input data.
2025-12-02 17:22:01,137:INFO:Uploading results into container
2025-12-02 17:22:01,138:INFO:Uploading model into container now
2025-12-02 17:22:01,146:INFO:_master_model_container: 1
2025-12-02 17:22:01,146:INFO:_display_container: 2
2025-12-02 17:22:01,146:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2025-12-02 17:22:01,148:INFO:create_model() successfully completed......................................
2025-12-02 17:22:07,692:INFO:Initializing create_model()
2025-12-02 17:22:07,692:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000019D68AAC430>, estimator=lr, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-02 17:22:07,692:INFO:Checking exceptions
2025-12-02 17:22:07,693:INFO:Importing libraries
2025-12-02 17:22:07,693:INFO:Copying training dataset
2025-12-02 17:22:07,721:INFO:Defining folds
2025-12-02 17:22:07,721:INFO:Declaring metric variables
2025-12-02 17:22:07,721:INFO:Importing untrained model
2025-12-02 17:22:07,721:INFO:Logistic Regression Imported successfully
2025-12-02 17:22:07,722:INFO:Starting cross validation
2025-12-02 17:22:07,723:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-12-02 17:22:08,641:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-12-02 17:22:09,186:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-12-02 17:22:09,547:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-12-02 17:22:09,550:INFO:Calculating mean and std
2025-12-02 17:22:09,550:INFO:Creating metrics dataframe
2025-12-02 17:22:09,550:INFO:Finalizing model
2025-12-02 17:22:09,624:INFO:Warning: No categorical columns found. Calling 'transform' will only return input data.
2025-12-02 17:22:09,711:INFO:Uploading results into container
2025-12-02 17:22:09,713:INFO:Uploading model into container now
2025-12-02 17:22:09,713:INFO:_master_model_container: 2
2025-12-02 17:22:09,713:INFO:_display_container: 3
2025-12-02 17:22:09,714:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-12-02 17:22:09,714:INFO:create_model() successfully completed......................................
2025-12-02 17:22:09,873:INFO:Initializing create_model()
2025-12-02 17:22:09,873:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000019D68AAC430>, estimator=rf, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-02 17:22:09,873:INFO:Checking exceptions
2025-12-02 17:22:09,873:INFO:Importing libraries
2025-12-02 17:22:09,875:INFO:Copying training dataset
2025-12-02 17:22:09,896:INFO:Defining folds
2025-12-02 17:22:09,896:INFO:Declaring metric variables
2025-12-02 17:22:09,896:INFO:Importing untrained model
2025-12-02 17:22:09,896:INFO:Random Forest Classifier Imported successfully
2025-12-02 17:22:09,896:INFO:Starting cross validation
2025-12-02 17:22:09,900:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-12-02 17:22:51,201:INFO:Calculating mean and std
2025-12-02 17:22:51,201:INFO:Creating metrics dataframe
2025-12-02 17:22:51,202:INFO:Finalizing model
2025-12-02 17:22:51,276:INFO:Warning: No categorical columns found. Calling 'transform' will only return input data.
2025-12-02 17:22:55,726:INFO:Uploading results into container
2025-12-02 17:22:55,726:INFO:Uploading model into container now
2025-12-02 17:22:55,726:INFO:_master_model_container: 3
2025-12-02 17:22:55,726:INFO:_display_container: 4
2025-12-02 17:22:55,726:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2025-12-02 17:22:55,726:INFO:create_model() successfully completed......................................
2025-12-02 17:23:04,359:INFO:Initializing get_config()
2025-12-02 17:23:04,359:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000019D68AAC430>, variable=X_train)
2025-12-02 17:23:04,359:INFO:Variable: 'X_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_train_transformed' instead.
2025-12-02 17:23:04,359:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'X_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_train_transformed' instead.

2025-12-02 17:23:04,375:INFO:Variable:  returned as         Age  IncomeRatio  SystolicBP        BMI  WaistCircumference  \
15208  72.0     4.060000  121.333336  30.000000           94.000000   
25325  18.0     2.540000   92.000000  15.900000           64.699997   
5132   38.0     0.870000  103.000000  25.600000           97.300003   
17217  52.0     0.000000  112.666664  22.600000           96.099998   
6382   55.0     2.037726  140.666672  50.500000          143.000000   
...     ...          ...         ...        ...                 ...   
6265    6.0     0.810000   97.519173  26.900000           77.000000   
42694  29.0     1.340000   90.000000  22.600000           86.599998   
13399  50.0     2.881760  121.796486  27.657665           93.338409   
39959  72.0     1.410000  128.000000  34.500000          121.800003   
6616   57.0     0.770000  128.666672  16.799999           73.000000   

           Height  TotalCholesterol  Triglycerides         LDL        HDL  \
15208  149.399994        194.488342     145.337372  106.569115  58.927979   
25325  153.800003        171.174011      28.993015  106.506821  58.757504   
5132   179.000000        177.000000     131.000000  118.000000  33.000000   
17217  178.500000        178.807617     112.662071  106.533295  49.698704   
6382   166.500000        204.000000     152.522919  106.537094  67.000000   
...           ...               ...            ...         ...        ...   
6265   119.900002        115.000000       0.133738   59.959660  55.000000   
42694  160.899994        171.000000      46.859886  106.514542  55.000000   
13399  157.421341        188.051712     117.379623  106.551285  58.025379   
39959  169.600006        230.000000     331.343445  106.646034  57.000000   
6616   160.399994        161.000000      59.000000   87.000000  62.000000   

       ...      Sodium  GGT_Enzyme  AST_Enzyme  Sex  Race  Education  Smoking  \
15208  ...  140.134155   19.427843   20.704529  2.0   5.0   2.000000      0.0   
25325  ...  139.276627   12.077684   20.956255  2.0   1.0   3.399943      0.0   
5132   ...  143.000000   15.000000   27.000000  1.0   1.0   2.000000      1.0   
17217  ...  139.376740   38.195724   26.162401  1.0   4.0   3.000000      1.0   
6382   ...  139.000000  501.000000   14.000000  2.0   4.0   4.000000      1.0   
...    ...         ...         ...         ...  ...   ...        ...      ...   
6265   ...  139.272446   11.077256   21.572195  2.0   1.0   1.818816      0.0   
42694  ...  135.000000    9.000000   16.000000  2.0   1.0   4.000000      0.0   
13399  ...  139.551743   21.783148   21.532890  2.0   4.0   4.000000      0.0   
39959  ...  139.000000   25.000000   25.000000  1.0   3.0   4.000000      0.0   
6616   ...  144.000000   31.000000   20.000000  2.0   3.0   4.000000      1.0   

       PhysicalActivity  HealthInsurance   Alcohol  
15208          0.000000              1.0  0.000000  
25325          0.000000              1.0  1.000000  
5132           0.000000              0.0  0.811142  
17217          0.000000              1.0  1.000000  
6382           0.000000              1.0  1.003436  
...                 ...              ...       ...  
6265           0.414518              1.0  0.260271  
42694          0.000000              0.0  1.000000  
13399          0.000000              1.0  0.447658  
39959          0.000000              1.0  1.000000  
6616           0.000000              1.0  0.795789  

[30586 rows x 27 columns]
2025-12-02 17:23:04,375:INFO:get_config() successfully completed......................................
2025-12-02 17:23:04,375:INFO:Initializing get_config()
2025-12-02 17:23:04,375:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000019D68AAC430>, variable=y_train)
2025-12-02 17:23:04,375:INFO:Variable: 'y_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_train_transformed' instead.
2025-12-02 17:23:04,375:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_train_transformed' instead.

2025-12-02 17:23:04,383:INFO:Variable:  returned as 15208    0.0
25325    0.0
5132     0.0
17217    0.0
6382     0.0
        ... 
6265     0.0
42694    0.0
13399    0.0
39959    0.0
6616     0.0
Name: HeartDisease, Length: 30586, dtype: float32
2025-12-02 17:23:04,383:INFO:get_config() successfully completed......................................
2025-12-02 17:23:04,383:INFO:Initializing get_config()
2025-12-02 17:23:04,383:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000019D68AAC430>, variable=X_test)
2025-12-02 17:23:04,383:INFO:Variable: 'X_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_test_transformed' instead.
2025-12-02 17:23:04,383:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'X_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_test_transformed' instead.

2025-12-02 17:23:04,397:INFO:Variable:  returned as         Age  IncomeRatio  SystolicBP        BMI  WaistCircumference  \
28456   9.0     1.130000   99.333336  15.700000           61.099998   
8993   66.0     2.540000  166.333328  32.400002          114.800003   
34312  61.0     2.040000  125.333336  30.000000          107.300003   
4802    6.0     2.541160  104.023125  22.902746           75.281982   
25895  61.0     5.000000  110.000000  22.930634           88.350540   
...     ...          ...         ...        ...                 ...   
18045   5.0     1.690000   98.095139  13.900000           49.000000   
5425   56.0     2.816601  167.666672  26.400000           96.500000   
12819  70.0     1.850000  134.841583  29.400000          116.300003   
33659   7.0     4.580000   99.172447  19.500000           61.599998   
19531   4.0     1.030000   99.557884  16.100000           52.599998   

           Height  TotalCholesterol  Triglycerides         LDL        HDL  \
28456  135.399994        166.760483       0.173547  106.177483  60.548538   
8993   154.300003        200.000000     162.087509  106.576744  61.000000   
34312  174.100006        165.000000     193.000000   94.000000  32.000000   
4802   148.985626        162.438828      20.569315  106.503899  51.826447   
25895  166.014694        205.000000     242.794479  106.603226  50.000000   
...           ...               ...            ...         ...        ...   
18045  111.800003        156.431137       0.197693   96.216103  60.169205   
5425   164.600006        187.000000      56.000000  120.000000  56.000000   
12819  189.100006        141.000000       0.274363  103.940323  37.000000   
33659  131.300003        128.000000       0.145901   71.974304  56.000000   
19531  105.699997        155.803253       0.195925   95.590103  60.170795   

       ...      Sodium  GGT_Enzyme  AST_Enzyme  Sex  Race  Education  \
28456  ...  139.097183   11.915139   20.541420  2.0   5.0   3.071737   
8993   ...  144.000000   27.000000   19.000000  2.0   4.0   4.000000   
34312  ...  138.000000   20.000000   24.000000  1.0   3.0   2.000000   
4802   ...  139.436310   19.514387   24.333504  1.0   5.0   3.528540   
25895  ...  139.000000   27.000000   22.000000  1.0   3.0   5.000000   
...    ...         ...         ...         ...  ...   ...        ...   
18045  ...  139.290634   17.000010   25.400091  1.0   3.0   1.778809   
5425   ...  144.000000   24.000000   17.000000  2.0   4.0   4.000000   
12819  ...  141.000000   24.000000   32.000000  1.0   3.0   5.000000   
33659  ...  139.546265   12.943172   24.146975  1.0   4.0   3.521028   
19531  ...  139.166153   19.742857   25.262833  1.0   5.0   1.732558   

        Smoking  PhysicalActivity  HealthInsurance   Alcohol  
28456  0.000000          0.413342              1.0  0.248789  
8993   1.000000          0.000000              1.0  0.677497  
34312  0.000000          0.000000              1.0  1.000000  
4802   0.073612          0.633515              1.0  0.529613  
25895  0.000000          0.000000              1.0  0.000000  
...         ...               ...              ...       ...  
18045  0.000000          0.565897              1.0  0.273056  
5425   1.000000          1.000000              1.0  0.665636  
12819  1.000000          1.000000              1.0  1.014022  
33659  0.000000          0.727392              1.0  0.495082  
19531  0.000000          0.495139              1.0  0.137422  

[13109 rows x 27 columns]
2025-12-02 17:23:04,398:INFO:get_config() successfully completed......................................
2025-12-02 17:23:04,398:INFO:Initializing get_config()
2025-12-02 17:23:04,398:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000019D68AAC430>, variable=y_test)
2025-12-02 17:23:04,398:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-12-02 17:23:04,398:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-12-02 17:23:04,402:INFO:Variable:  returned as 28456    0.0
8993     0.0
34312    0.0
4802     0.0
25895    0.0
        ... 
18045    0.0
5425     0.0
12819    0.0
33659    0.0
19531    0.0
Name: HeartDisease, Length: 13109, dtype: float32
2025-12-02 17:23:04,402:INFO:get_config() successfully completed......................................
2025-12-02 17:26:16,176:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-12-02 17:26:16,176:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-12-02 17:26:16,176:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-12-02 17:26:16,176:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-12-02 17:26:26,564:INFO:PyCaret ClassificationExperiment
2025-12-02 17:26:26,564:INFO:Logging name: clf-default-name
2025-12-02 17:26:26,564:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-12-02 17:26:26,564:INFO:version 3.3.2
2025-12-02 17:26:26,564:INFO:Initializing setup()
2025-12-02 17:26:26,564:INFO:self.USI: 6f21
2025-12-02 17:26:26,564:INFO:self._variable_keys: {'_ml_usecase', '_available_plots', 'USI', 'y_test', 'X', 'exp_id', 'target_param', 'idx', 'n_jobs_param', 'memory', 'log_plots_param', 'fix_imbalance', 'is_multiclass', 'data', 'exp_name_log', 'fold_groups_param', 'X_test', 'y', 'fold_shuffle_param', 'y_train', 'html_param', 'gpu_n_jobs_param', 'logging_param', 'fold_generator', 'pipeline', 'gpu_param', 'seed', 'X_train'}
2025-12-02 17:26:26,564:INFO:Checking environment
2025-12-02 17:26:26,564:INFO:python_version: 3.10.19
2025-12-02 17:26:26,564:INFO:python_build: ('main', 'Oct 21 2025 16:41:31')
2025-12-02 17:26:26,564:INFO:machine: AMD64
2025-12-02 17:26:26,564:INFO:platform: Windows-10-10.0.26100-SP0
2025-12-02 17:26:26,564:INFO:Memory: svmem(total=16282144768, available=3913494528, percent=76.0, used=12368650240, free=3913494528)
2025-12-02 17:26:26,564:INFO:Physical Core: 6
2025-12-02 17:26:26,565:INFO:Logical Core: 12
2025-12-02 17:26:26,565:INFO:Checking libraries
2025-12-02 17:26:26,565:INFO:System:
2025-12-02 17:26:26,565:INFO:    python: 3.10.19 | packaged by Anaconda, Inc. | (main, Oct 21 2025, 16:41:31) [MSC v.1929 64 bit (AMD64)]
2025-12-02 17:26:26,565:INFO:executable: c:\Users\OMAR\miniconda3\envs\xgb_env\python.exe
2025-12-02 17:26:26,565:INFO:   machine: Windows-10-10.0.26100-SP0
2025-12-02 17:26:26,565:INFO:PyCaret required dependencies:
2025-12-02 17:26:26,565:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-02 17:26:27,120:INFO:                 pip: 25.3
2025-12-02 17:26:27,120:INFO:          setuptools: 80.9.0
2025-12-02 17:26:27,120:INFO:             pycaret: 3.3.2
2025-12-02 17:26:27,120:INFO:             IPython: 8.37.0
2025-12-02 17:26:27,120:INFO:          ipywidgets: 8.1.8
2025-12-02 17:26:27,120:INFO:                tqdm: 4.67.1
2025-12-02 17:26:27,120:INFO:               numpy: 1.26.4
2025-12-02 17:26:27,120:INFO:              pandas: 2.1.4
2025-12-02 17:26:27,120:INFO:              jinja2: 3.1.6
2025-12-02 17:26:27,120:INFO:               scipy: 1.11.4
2025-12-02 17:26:27,120:INFO:              joblib: 1.3.2
2025-12-02 17:26:27,120:INFO:             sklearn: 1.4.2
2025-12-02 17:26:27,121:INFO:                pyod: 2.0.5
2025-12-02 17:26:27,121:INFO:            imblearn: 0.14.0
2025-12-02 17:26:27,121:INFO:   category_encoders: 2.7.0
2025-12-02 17:26:27,121:INFO:            lightgbm: 4.6.0
2025-12-02 17:26:27,121:INFO:               numba: 0.62.1
2025-12-02 17:26:27,121:INFO:            requests: 2.32.5
2025-12-02 17:26:27,121:INFO:          matplotlib: 3.7.5
2025-12-02 17:26:27,121:INFO:          scikitplot: 0.3.7
2025-12-02 17:26:27,121:INFO:         yellowbrick: 1.5
2025-12-02 17:26:27,121:INFO:              plotly: 5.24.1
2025-12-02 17:26:27,121:INFO:    plotly-resampler: Not installed
2025-12-02 17:26:27,121:INFO:             kaleido: 1.2.0
2025-12-02 17:26:27,121:INFO:           schemdraw: 0.15
2025-12-02 17:26:27,121:INFO:         statsmodels: 0.14.5
2025-12-02 17:26:27,121:INFO:              sktime: 0.26.0
2025-12-02 17:26:27,121:INFO:               tbats: 1.1.3
2025-12-02 17:26:27,121:INFO:            pmdarima: 2.0.4
2025-12-02 17:26:27,121:INFO:              psutil: 7.1.3
2025-12-02 17:26:27,121:INFO:          markupsafe: 3.0.3
2025-12-02 17:26:27,121:INFO:             pickle5: Not installed
2025-12-02 17:26:27,121:INFO:         cloudpickle: 3.1.2
2025-12-02 17:26:27,121:INFO:         deprecation: 2.1.0
2025-12-02 17:26:27,121:INFO:              xxhash: 3.6.0
2025-12-02 17:26:27,121:INFO:           wurlitzer: Not installed
2025-12-02 17:26:27,121:INFO:PyCaret optional dependencies:
2025-12-02 17:26:29,784:INFO:                shap: 0.49.1
2025-12-02 17:26:29,784:INFO:           interpret: 0.7.3
2025-12-02 17:26:29,784:INFO:                umap: 0.5.7
2025-12-02 17:26:29,784:INFO:     ydata_profiling: 4.18.0
2025-12-02 17:26:29,784:INFO:  explainerdashboard: 0.5.1
2025-12-02 17:26:29,784:INFO:             autoviz: Not installed
2025-12-02 17:26:29,784:INFO:           fairlearn: 0.7.0
2025-12-02 17:26:29,784:INFO:          deepchecks: Not installed
2025-12-02 17:26:29,784:INFO:             xgboost: 2.1.3
2025-12-02 17:26:29,784:INFO:            catboost: 1.2.8
2025-12-02 17:26:29,784:INFO:              kmodes: 0.12.2
2025-12-02 17:26:29,784:INFO:             mlxtend: 0.23.4
2025-12-02 17:26:29,784:INFO:       statsforecast: 1.5.0
2025-12-02 17:26:29,784:INFO:        tune_sklearn: Not installed
2025-12-02 17:26:29,784:INFO:                 ray: Not installed
2025-12-02 17:26:29,784:INFO:            hyperopt: 0.2.7
2025-12-02 17:26:29,784:INFO:              optuna: 4.6.0
2025-12-02 17:26:29,784:INFO:               skopt: 0.10.2
2025-12-02 17:26:29,784:INFO:              mlflow: 3.6.0
2025-12-02 17:26:29,784:INFO:              gradio: 6.0.1
2025-12-02 17:26:29,784:INFO:             fastapi: 0.123.0
2025-12-02 17:26:29,784:INFO:             uvicorn: 0.38.0
2025-12-02 17:26:29,784:INFO:              m2cgen: 0.10.0
2025-12-02 17:26:29,784:INFO:           evidently: 0.4.40
2025-12-02 17:26:29,784:INFO:               fugue: 0.8.7
2025-12-02 17:26:29,784:INFO:           streamlit: 1.51.0
2025-12-02 17:26:29,784:INFO:             prophet: Not installed
2025-12-02 17:26:29,784:INFO:None
2025-12-02 17:26:29,784:INFO:Set up data.
2025-12-02 17:26:29,806:INFO:Set up folding strategy.
2025-12-02 17:26:29,806:INFO:Set up train/test split.
2025-12-02 17:26:29,826:INFO:Set up index.
2025-12-02 17:26:29,832:INFO:Assigning column types.
2025-12-02 17:26:29,853:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-12-02 17:26:29,876:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-12-02 17:26:29,876:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-02 17:26:29,900:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-02 17:26:29,900:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-02 17:26:29,948:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-12-02 17:26:29,949:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-02 17:26:29,966:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-02 17:26:29,966:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-02 17:26:29,966:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-12-02 17:26:29,992:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-02 17:26:30,009:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-02 17:26:30,011:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-02 17:26:30,037:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-02 17:26:30,052:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-02 17:26:30,054:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-02 17:26:30,054:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-12-02 17:26:30,092:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-02 17:26:30,097:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-02 17:26:30,138:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-02 17:26:30,138:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-02 17:26:30,142:INFO:Preparing preprocessing pipeline...
2025-12-02 17:26:30,146:INFO:Set up simple imputation.
2025-12-02 17:26:30,160:INFO:Set up encoding of ordinal features.
2025-12-02 17:26:30,168:INFO:Set up encoding of categorical features.
2025-12-02 17:26:30,169:INFO:Set up feature normalization.
2025-12-02 17:26:30,342:INFO:Finished creating preprocessing pipeline.
2025-12-02 17:26:30,356:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\OMAR\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'IncomeRatio', 'SystolicBP',
                                             'BMI', 'WaistCircumference',
                                             'Height', 'TotalCholesterol',
                                             'Triglycerides', 'LDL', 'HDL',
                                             'HbA1c', 'Glucose', 'Creatinine',
                                             'UricAcid', 'ALT_Enzyme',
                                             'Albumin', 'Potassium', 'Sodium',
                                             'G...
                                    transformer=TargetEncoder(cols=[],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=RobustScaler(copy=True,
                                                             quantile_range=(25.0,
                                                                             75.0),
                                                             unit_variance=False,
                                                             with_centering=True,
                                                             with_scaling=True)))],
         verbose=False)
2025-12-02 17:26:30,356:INFO:Creating final display dataframe.
2025-12-02 17:26:30,606:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target      HeartDisease
2                   Target type            Binary
3           Original data shape       (43695, 28)
4        Transformed data shape       (43695, 32)
5   Transformed train set shape       (30586, 32)
6    Transformed test set shape       (13109, 32)
7              Numeric features                20
8          Categorical features                 7
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15                    Normalize              True
16             Normalize method            robust
17               Fold Generator   StratifiedKFold
18                  Fold Number                10
19                     CPU Jobs                 1
20                      Use GPU             False
21               Log Experiment             False
22              Experiment Name  clf-default-name
23                          USI              6f21
2025-12-02 17:26:30,654:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-02 17:26:30,657:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-02 17:26:30,702:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-02 17:26:30,704:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-02 17:26:30,706:INFO:setup() successfully completed in 4.15s...............
2025-12-02 17:26:35,251:INFO:Initializing get_config()
2025-12-02 17:26:35,251:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017153B431F0>, variable=y_train)
2025-12-02 17:26:35,251:INFO:Variable: 'y_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_train_transformed' instead.
2025-12-02 17:26:35,251:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_train_transformed' instead.

2025-12-02 17:26:35,259:INFO:Variable:  returned as 15208    0.0
25325    0.0
5132     0.0
17217    0.0
6382     0.0
        ... 
6265     0.0
42694    0.0
13399    0.0
39959    0.0
6616     0.0
Name: HeartDisease, Length: 30586, dtype: float32
2025-12-02 17:26:35,260:INFO:get_config() successfully completed......................................
2025-12-02 17:26:35,261:INFO:Initializing create_model()
2025-12-02 17:26:35,261:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017153B431F0>, estimator=xgboost, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={'scale_pos_weight': 38.162612035851474})
2025-12-02 17:26:35,261:INFO:Checking exceptions
2025-12-02 17:26:35,274:INFO:Importing libraries
2025-12-02 17:26:35,274:INFO:Copying training dataset
2025-12-02 17:26:35,303:INFO:Defining folds
2025-12-02 17:26:35,303:INFO:Declaring metric variables
2025-12-02 17:26:35,306:INFO:Importing untrained model
2025-12-02 17:26:35,309:INFO:Extreme Gradient Boosting Imported successfully
2025-12-02 17:26:35,314:INFO:Starting cross validation
2025-12-02 17:26:35,316:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-12-02 17:26:41,432:INFO:Calculating mean and std
2025-12-02 17:26:41,432:INFO:Creating metrics dataframe
2025-12-02 17:26:41,439:INFO:Finalizing model
2025-12-02 17:26:41,523:INFO:Warning: No categorical columns found. Calling 'transform' will only return input data.
2025-12-02 17:26:42,047:INFO:Uploading results into container
2025-12-02 17:26:42,047:INFO:Uploading model into container now
2025-12-02 17:26:42,055:INFO:_master_model_container: 1
2025-12-02 17:26:42,055:INFO:_display_container: 2
2025-12-02 17:26:42,056:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2025-12-02 17:26:42,056:INFO:create_model() successfully completed......................................
2025-12-02 17:26:54,031:INFO:Initializing create_model()
2025-12-02 17:26:54,031:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017153B431F0>, estimator=lr, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-02 17:26:54,031:INFO:Checking exceptions
2025-12-02 17:26:54,046:INFO:Importing libraries
2025-12-02 17:26:54,047:INFO:Copying training dataset
2025-12-02 17:26:54,074:INFO:Defining folds
2025-12-02 17:26:54,075:INFO:Declaring metric variables
2025-12-02 17:26:54,077:INFO:Importing untrained model
2025-12-02 17:26:54,080:INFO:Logistic Regression Imported successfully
2025-12-02 17:26:54,084:INFO:Starting cross validation
2025-12-02 17:26:54,086:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-12-02 17:26:55,047:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-12-02 17:26:55,607:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-12-02 17:26:56,001:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-12-02 17:26:56,006:INFO:Calculating mean and std
2025-12-02 17:26:56,006:INFO:Creating metrics dataframe
2025-12-02 17:26:56,014:INFO:Finalizing model
2025-12-02 17:26:56,096:INFO:Warning: No categorical columns found. Calling 'transform' will only return input data.
2025-12-02 17:26:56,191:INFO:Uploading results into container
2025-12-02 17:26:56,192:INFO:Uploading model into container now
2025-12-02 17:26:56,201:INFO:_master_model_container: 2
2025-12-02 17:26:56,201:INFO:_display_container: 3
2025-12-02 17:26:56,201:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-12-02 17:26:56,201:INFO:create_model() successfully completed......................................
2025-12-02 17:26:56,360:INFO:Initializing create_model()
2025-12-02 17:26:56,361:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017153B431F0>, estimator=rf, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-02 17:26:56,361:INFO:Checking exceptions
2025-12-02 17:26:56,372:INFO:Importing libraries
2025-12-02 17:26:56,372:INFO:Copying training dataset
2025-12-02 17:26:56,402:INFO:Defining folds
2025-12-02 17:26:56,403:INFO:Declaring metric variables
2025-12-02 17:26:56,404:INFO:Importing untrained model
2025-12-02 17:26:56,407:INFO:Random Forest Classifier Imported successfully
2025-12-02 17:26:56,411:INFO:Starting cross validation
2025-12-02 17:26:56,413:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-12-02 17:27:36,731:INFO:Calculating mean and std
2025-12-02 17:27:36,731:INFO:Creating metrics dataframe
2025-12-02 17:27:36,735:INFO:Finalizing model
2025-12-02 17:27:36,813:INFO:Warning: No categorical columns found. Calling 'transform' will only return input data.
2025-12-02 17:27:41,242:INFO:Uploading results into container
2025-12-02 17:27:41,242:INFO:Uploading model into container now
2025-12-02 17:27:41,250:INFO:_master_model_container: 3
2025-12-02 17:27:41,251:INFO:_display_container: 4
2025-12-02 17:27:41,251:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2025-12-02 17:27:41,251:INFO:create_model() successfully completed......................................
2025-12-02 17:28:04,872:INFO:Initializing get_config()
2025-12-02 17:28:04,872:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017153B431F0>, variable=X_train_transformed)
2025-12-02 17:28:04,909:INFO:Variable: X_train returned as             Age  IncomeRatio  SystolicBP       BMI  WaistCircumference  \
15208  0.954545     0.854789    0.359485  0.518044            0.206281   
25325 -0.272727     0.253271   -0.812170 -0.966167           -0.799656   
5132   0.181818    -0.407608   -0.372799  0.054886            0.319578   
17217  0.500000    -0.751898    0.013314 -0.260904            0.278379   
6382   0.568182     0.054503    1.131712  2.675938            1.888566   
...         ...          ...         ...       ...                 ...   
6265  -0.545455    -0.431352   -0.591719  0.191728           -0.377368   
42694 -0.022727    -0.221612   -0.892056 -0.260904           -0.047778   
13399  0.454545     0.388518    0.377985  0.271482            0.183567   
39959  0.954545    -0.193911    0.625770  0.991728            1.160720   
6616   0.613636    -0.447182    0.652399 -0.871430           -0.514698   

         Height  TotalCholesterol  Triglycerides       LDL       HDL  ...  \
15208 -0.487303          0.625876       0.583394  0.005397  0.314564  ...   
25325 -0.300856          0.033588      -0.261476  0.000256  0.303682  ...   
5132   0.766972          0.181594       0.479279  0.948690 -1.340476  ...   
17217  0.745785          0.227516       0.346113  0.002441 -0.274561  ...   
6382   0.237295          0.867515       0.635574  0.002754  0.829819  ...   
...         ...               ...            ...       ...       ...  ...   
6265  -1.737339         -1.393483      -0.471046 -3.840886  0.063832  ...   
42694  0.000000          0.029167      -0.131730  0.000893  0.063832  ...   
13399 -0.147405          0.462357       0.380371  0.003925  0.256949  ...   
39959  0.368655          1.528031       1.934134  0.011744  0.191497  ...   
6616  -0.021187         -0.224877      -0.043571 -1.609476  0.510658  ...   

       Race_5.0  Race_1.0  Race_4.0  Race_3.0  Race_2.0  Education  Smoking  \
15208       1.0       0.0       0.0       0.0       0.0  -0.659696      0.0   
25325       0.0       1.0       0.0       0.0       0.0   0.185278      0.0   
5132        0.0       1.0       0.0       0.0       0.0  -0.659696      1.0   
17217       0.0       0.0       1.0       0.0       0.0  -0.056119      1.0   
6382        0.0       0.0       1.0       0.0       0.0   0.547458      1.0   
...         ...       ...       ...       ...       ...        ...      ...   
6265        0.0       1.0       0.0       0.0       0.0  -0.769055      0.0   
42694       0.0       1.0       0.0       0.0       0.0   0.547458      0.0   
13399       0.0       0.0       1.0       0.0       0.0   0.547458      0.0   
39959       0.0       0.0       0.0       1.0       0.0   0.547458      0.0   
6616        0.0       0.0       0.0       1.0       0.0   0.547458      1.0   

       PhysicalActivity  HealthInsurance   Alcohol  
15208          0.000000              0.0 -0.886483  
25325          0.000000              0.0  0.592213  
5132           0.000000             -1.0  0.312949  
17217          0.000000              0.0  0.592213  
6382           0.000000              0.0  0.597293  
...                 ...              ...       ...  
6265           0.662459              0.0 -0.501621  
42694          0.000000             -1.0  0.592213  
13399          0.000000              0.0 -0.224534  
39959          0.000000              0.0  0.592213  
6616           0.000000              0.0  0.290247  

[30586 rows x 31 columns]
2025-12-02 17:28:04,909:INFO:get_config() successfully completed......................................
2025-12-02 17:28:04,909:INFO:Initializing get_config()
2025-12-02 17:28:04,909:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017153B431F0>, variable=y_train)
2025-12-02 17:28:04,909:INFO:Variable: 'y_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_train_transformed' instead.
2025-12-02 17:28:04,909:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_train_transformed' instead.

2025-12-02 17:28:04,916:INFO:Variable:  returned as 15208    0.0
25325    0.0
5132     0.0
17217    0.0
6382     0.0
        ... 
6265     0.0
42694    0.0
13399    0.0
39959    0.0
6616     0.0
Name: HeartDisease, Length: 30586, dtype: float32
2025-12-02 17:28:04,916:INFO:get_config() successfully completed......................................
2025-12-02 17:28:04,919:INFO:Initializing get_config()
2025-12-02 17:28:04,919:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017153B431F0>, variable=X_test_transformed)
2025-12-02 17:28:05,002:INFO:Variable: X_test returned as             Age  IncomeRatio  SystolicBP       BMI  WaistCircumference  \
28456 -0.477273    -0.304717   -0.519256 -0.987220           -0.923253   
8993   0.818182     0.253271    2.156910  0.770675            0.920394   
34312  0.704545     0.055403    0.519256  0.518044            0.662901   
4802  -0.545455     0.253730   -0.331933 -0.229036           -0.436352   
25895  0.704545     1.226781   -0.093200 -0.226100            0.012322   
...         ...          ...         ...       ...                 ...   
18045 -0.568182    -0.083104   -0.568713 -1.176693           -1.338674   
5425   0.590909     0.362732    2.210168  0.139096            0.292112   
12819  0.909091    -0.019787    0.899042  0.454886            0.971892   
33659 -0.522727     1.060572   -0.525683 -0.587220           -0.906087   
19531 -0.590909    -0.344290   -0.510287 -0.945114           -1.215078   

         Height  TotalCholesterol  Triglycerides       LDL       HDL  ...  \
28456 -1.080540         -0.078535      -0.470757 -0.026922  0.418008  ...   
8993  -0.279669          0.765897       0.705031  0.006026  0.446825  ...   
34312  0.559339         -0.123259       0.929511 -1.031826 -1.404309  ...   
4802  -0.504861         -0.188325      -0.322647  0.000015 -0.138743  ...   
25895  0.216731          0.892919       1.291109  0.008211 -0.255329  ...   
...         ...               ...            ...       ...       ...  ...   
18045 -2.080569         -0.340947      -0.470582 -0.848950  0.393794  ...   
5425   0.156785          0.435639      -0.065356  1.113733  0.127664  ...   
12819  1.194951         -0.732967      -0.470025 -0.211535 -1.085148  ...   
33659 -1.254274         -1.063225      -0.470958 -2.849419  0.127664  ...   
19531 -2.339052         -0.356898      -0.470595 -0.900608  0.393896  ...   

       Race_5.0  Race_1.0  Race_4.0  Race_3.0  Race_2.0  Education   Smoking  \
28456       1.0       0.0       0.0       0.0       0.0  -0.012820  0.000000   
8993        0.0       0.0       1.0       0.0       0.0   0.547458  1.000000   
34312       0.0       0.0       0.0       1.0       0.0  -0.659696  0.000000   
4802        1.0       0.0       0.0       0.0       0.0   0.262895  0.073612   
25895       0.0       0.0       0.0       1.0       0.0   1.151035  0.000000   
...         ...       ...       ...       ...       ...        ...       ...   
18045       0.0       0.0       0.0       1.0       0.0  -0.793202  0.000000   
5425        0.0       0.0       1.0       0.0       0.0   0.547458  1.000000   
12819       0.0       0.0       0.0       1.0       0.0   1.151035  1.000000   
33659       0.0       0.0       1.0       0.0       0.0   0.258362  0.000000   
19531       1.0       0.0       0.0       0.0       0.0  -0.821118  0.000000   

       PhysicalActivity  HealthInsurance   Alcohol  
28456          0.660578              0.0 -0.518600  
8993           0.000000              0.0  0.115329  
34312          0.000000              0.0  0.592213  
4802           1.012447              0.0 -0.103347  
25895          0.000000              0.0 -0.886483  
...                 ...              ...       ...  
18045          0.904383              0.0 -0.482716  
5425           1.598141              0.0  0.097790  
12819          1.598141              0.0  0.612947  
33659          1.162475              0.0 -0.154408  
19531          0.791302              0.0 -0.683278  

[13109 rows x 31 columns]
2025-12-02 17:28:05,002:INFO:get_config() successfully completed......................................
2025-12-02 17:28:05,003:INFO:Initializing get_config()
2025-12-02 17:28:05,003:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017153B431F0>, variable=y_test)
2025-12-02 17:28:05,003:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-12-02 17:28:05,003:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-12-02 17:28:05,010:INFO:Variable:  returned as 28456    0.0
8993     0.0
34312    0.0
4802     0.0
25895    0.0
        ... 
18045    0.0
5425     0.0
12819    0.0
33659    0.0
19531    0.0
Name: HeartDisease, Length: 13109, dtype: float32
2025-12-02 17:28:05,010:INFO:get_config() successfully completed......................................
2025-12-02 17:28:05,175:INFO:Initializing get_config()
2025-12-02 17:28:05,176:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017153B431F0>, variable=X_train_transformed)
2025-12-02 17:28:05,217:INFO:Variable: X_train returned as             Age  IncomeRatio  SystolicBP       BMI  WaistCircumference  \
15208  0.954545     0.854789    0.359485  0.518044            0.206281   
25325 -0.272727     0.253271   -0.812170 -0.966167           -0.799656   
5132   0.181818    -0.407608   -0.372799  0.054886            0.319578   
17217  0.500000    -0.751898    0.013314 -0.260904            0.278379   
6382   0.568182     0.054503    1.131712  2.675938            1.888566   
...         ...          ...         ...       ...                 ...   
6265  -0.545455    -0.431352   -0.591719  0.191728           -0.377368   
42694 -0.022727    -0.221612   -0.892056 -0.260904           -0.047778   
13399  0.454545     0.388518    0.377985  0.271482            0.183567   
39959  0.954545    -0.193911    0.625770  0.991728            1.160720   
6616   0.613636    -0.447182    0.652399 -0.871430           -0.514698   

         Height  TotalCholesterol  Triglycerides       LDL       HDL  ...  \
15208 -0.487303          0.625876       0.583394  0.005397  0.314564  ...   
25325 -0.300856          0.033588      -0.261476  0.000256  0.303682  ...   
5132   0.766972          0.181594       0.479279  0.948690 -1.340476  ...   
17217  0.745785          0.227516       0.346113  0.002441 -0.274561  ...   
6382   0.237295          0.867515       0.635574  0.002754  0.829819  ...   
...         ...               ...            ...       ...       ...  ...   
6265  -1.737339         -1.393483      -0.471046 -3.840886  0.063832  ...   
42694  0.000000          0.029167      -0.131730  0.000893  0.063832  ...   
13399 -0.147405          0.462357       0.380371  0.003925  0.256949  ...   
39959  0.368655          1.528031       1.934134  0.011744  0.191497  ...   
6616  -0.021187         -0.224877      -0.043571 -1.609476  0.510658  ...   

       Race_5.0  Race_1.0  Race_4.0  Race_3.0  Race_2.0  Education  Smoking  \
15208       1.0       0.0       0.0       0.0       0.0  -0.659696      0.0   
25325       0.0       1.0       0.0       0.0       0.0   0.185278      0.0   
5132        0.0       1.0       0.0       0.0       0.0  -0.659696      1.0   
17217       0.0       0.0       1.0       0.0       0.0  -0.056119      1.0   
6382        0.0       0.0       1.0       0.0       0.0   0.547458      1.0   
...         ...       ...       ...       ...       ...        ...      ...   
6265        0.0       1.0       0.0       0.0       0.0  -0.769055      0.0   
42694       0.0       1.0       0.0       0.0       0.0   0.547458      0.0   
13399       0.0       0.0       1.0       0.0       0.0   0.547458      0.0   
39959       0.0       0.0       0.0       1.0       0.0   0.547458      0.0   
6616        0.0       0.0       0.0       1.0       0.0   0.547458      1.0   

       PhysicalActivity  HealthInsurance   Alcohol  
15208          0.000000              0.0 -0.886483  
25325          0.000000              0.0  0.592213  
5132           0.000000             -1.0  0.312949  
17217          0.000000              0.0  0.592213  
6382           0.000000              0.0  0.597293  
...                 ...              ...       ...  
6265           0.662459              0.0 -0.501621  
42694          0.000000             -1.0  0.592213  
13399          0.000000              0.0 -0.224534  
39959          0.000000              0.0  0.592213  
6616           0.000000              0.0  0.290247  

[30586 rows x 31 columns]
2025-12-02 17:28:05,217:INFO:get_config() successfully completed......................................
2025-12-02 17:28:05,219:INFO:Initializing get_config()
2025-12-02 17:28:05,219:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017153B431F0>, variable=y_train)
2025-12-02 17:28:05,219:INFO:Variable: 'y_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_train_transformed' instead.
2025-12-02 17:28:05,219:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_train_transformed' instead.

2025-12-02 17:28:05,226:INFO:Variable:  returned as 15208    0.0
25325    0.0
5132     0.0
17217    0.0
6382     0.0
        ... 
6265     0.0
42694    0.0
13399    0.0
39959    0.0
6616     0.0
Name: HeartDisease, Length: 30586, dtype: float32
2025-12-02 17:28:05,227:INFO:get_config() successfully completed......................................
2025-12-02 17:28:05,229:INFO:Initializing get_config()
2025-12-02 17:28:05,229:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017153B431F0>, variable=X_test_transformed)
2025-12-02 17:28:05,310:INFO:Variable: X_test returned as             Age  IncomeRatio  SystolicBP       BMI  WaistCircumference  \
28456 -0.477273    -0.304717   -0.519256 -0.987220           -0.923253   
8993   0.818182     0.253271    2.156910  0.770675            0.920394   
34312  0.704545     0.055403    0.519256  0.518044            0.662901   
4802  -0.545455     0.253730   -0.331933 -0.229036           -0.436352   
25895  0.704545     1.226781   -0.093200 -0.226100            0.012322   
...         ...          ...         ...       ...                 ...   
18045 -0.568182    -0.083104   -0.568713 -1.176693           -1.338674   
5425   0.590909     0.362732    2.210168  0.139096            0.292112   
12819  0.909091    -0.019787    0.899042  0.454886            0.971892   
33659 -0.522727     1.060572   -0.525683 -0.587220           -0.906087   
19531 -0.590909    -0.344290   -0.510287 -0.945114           -1.215078   

         Height  TotalCholesterol  Triglycerides       LDL       HDL  ...  \
28456 -1.080540         -0.078535      -0.470757 -0.026922  0.418008  ...   
8993  -0.279669          0.765897       0.705031  0.006026  0.446825  ...   
34312  0.559339         -0.123259       0.929511 -1.031826 -1.404309  ...   
4802  -0.504861         -0.188325      -0.322647  0.000015 -0.138743  ...   
25895  0.216731          0.892919       1.291109  0.008211 -0.255329  ...   
...         ...               ...            ...       ...       ...  ...   
18045 -2.080569         -0.340947      -0.470582 -0.848950  0.393794  ...   
5425   0.156785          0.435639      -0.065356  1.113733  0.127664  ...   
12819  1.194951         -0.732967      -0.470025 -0.211535 -1.085148  ...   
33659 -1.254274         -1.063225      -0.470958 -2.849419  0.127664  ...   
19531 -2.339052         -0.356898      -0.470595 -0.900608  0.393896  ...   

       Race_5.0  Race_1.0  Race_4.0  Race_3.0  Race_2.0  Education   Smoking  \
28456       1.0       0.0       0.0       0.0       0.0  -0.012820  0.000000   
8993        0.0       0.0       1.0       0.0       0.0   0.547458  1.000000   
34312       0.0       0.0       0.0       1.0       0.0  -0.659696  0.000000   
4802        1.0       0.0       0.0       0.0       0.0   0.262895  0.073612   
25895       0.0       0.0       0.0       1.0       0.0   1.151035  0.000000   
...         ...       ...       ...       ...       ...        ...       ...   
18045       0.0       0.0       0.0       1.0       0.0  -0.793202  0.000000   
5425        0.0       0.0       1.0       0.0       0.0   0.547458  1.000000   
12819       0.0       0.0       0.0       1.0       0.0   1.151035  1.000000   
33659       0.0       0.0       1.0       0.0       0.0   0.258362  0.000000   
19531       1.0       0.0       0.0       0.0       0.0  -0.821118  0.000000   

       PhysicalActivity  HealthInsurance   Alcohol  
28456          0.660578              0.0 -0.518600  
8993           0.000000              0.0  0.115329  
34312          0.000000              0.0  0.592213  
4802           1.012447              0.0 -0.103347  
25895          0.000000              0.0 -0.886483  
...                 ...              ...       ...  
18045          0.904383              0.0 -0.482716  
5425           1.598141              0.0  0.097790  
12819          1.598141              0.0  0.612947  
33659          1.162475              0.0 -0.154408  
19531          0.791302              0.0 -0.683278  

[13109 rows x 31 columns]
2025-12-02 17:28:05,310:INFO:get_config() successfully completed......................................
2025-12-02 17:28:05,310:INFO:Initializing get_config()
2025-12-02 17:28:05,310:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017153B431F0>, variable=y_test)
2025-12-02 17:28:05,310:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-12-02 17:28:05,310:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-12-02 17:28:05,318:INFO:Variable:  returned as 28456    0.0
8993     0.0
34312    0.0
4802     0.0
25895    0.0
        ... 
18045    0.0
5425     0.0
12819    0.0
33659    0.0
19531    0.0
Name: HeartDisease, Length: 13109, dtype: float32
2025-12-02 17:28:05,318:INFO:get_config() successfully completed......................................
2025-12-02 17:28:23,833:INFO:Initializing plot_model()
2025-12-02 17:28:23,833:INFO:plot_model(plot=error, fold=None, verbose=True, display=None, display_format=None, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017153B431F0>, system=True)
2025-12-02 17:28:23,833:INFO:Checking exceptions
2025-12-02 17:28:23,851:INFO:Preloading libraries
2025-12-02 17:28:23,858:INFO:Copying training dataset
2025-12-02 17:28:23,858:INFO:Plot type: error
2025-12-02 17:28:24,070:INFO:Fitting Model
2025-12-02 17:28:24,071:INFO:Scoring test/hold-out set
2025-12-02 17:28:24,239:INFO:Visual Rendered Successfully
2025-12-02 17:28:24,407:INFO:plot_model() successfully completed......................................
2025-12-02 17:28:34,137:INFO:Initializing get_config()
2025-12-02 17:28:34,137:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017153B431F0>, variable=X_test_transformed)
2025-12-02 17:28:34,216:INFO:Variable: X_test returned as             Age  IncomeRatio  SystolicBP       BMI  WaistCircumference  \
28456 -0.477273    -0.304717   -0.519256 -0.987220           -0.923253   
8993   0.818182     0.253271    2.156910  0.770675            0.920394   
34312  0.704545     0.055403    0.519256  0.518044            0.662901   
4802  -0.545455     0.253730   -0.331933 -0.229036           -0.436352   
25895  0.704545     1.226781   -0.093200 -0.226100            0.012322   
...         ...          ...         ...       ...                 ...   
18045 -0.568182    -0.083104   -0.568713 -1.176693           -1.338674   
5425   0.590909     0.362732    2.210168  0.139096            0.292112   
12819  0.909091    -0.019787    0.899042  0.454886            0.971892   
33659 -0.522727     1.060572   -0.525683 -0.587220           -0.906087   
19531 -0.590909    -0.344290   -0.510287 -0.945114           -1.215078   

         Height  TotalCholesterol  Triglycerides       LDL       HDL  ...  \
28456 -1.080540         -0.078535      -0.470757 -0.026922  0.418008  ...   
8993  -0.279669          0.765897       0.705031  0.006026  0.446825  ...   
34312  0.559339         -0.123259       0.929511 -1.031826 -1.404309  ...   
4802  -0.504861         -0.188325      -0.322647  0.000015 -0.138743  ...   
25895  0.216731          0.892919       1.291109  0.008211 -0.255329  ...   
...         ...               ...            ...       ...       ...  ...   
18045 -2.080569         -0.340947      -0.470582 -0.848950  0.393794  ...   
5425   0.156785          0.435639      -0.065356  1.113733  0.127664  ...   
12819  1.194951         -0.732967      -0.470025 -0.211535 -1.085148  ...   
33659 -1.254274         -1.063225      -0.470958 -2.849419  0.127664  ...   
19531 -2.339052         -0.356898      -0.470595 -0.900608  0.393896  ...   

       Race_5.0  Race_1.0  Race_4.0  Race_3.0  Race_2.0  Education   Smoking  \
28456       1.0       0.0       0.0       0.0       0.0  -0.012820  0.000000   
8993        0.0       0.0       1.0       0.0       0.0   0.547458  1.000000   
34312       0.0       0.0       0.0       1.0       0.0  -0.659696  0.000000   
4802        1.0       0.0       0.0       0.0       0.0   0.262895  0.073612   
25895       0.0       0.0       0.0       1.0       0.0   1.151035  0.000000   
...         ...       ...       ...       ...       ...        ...       ...   
18045       0.0       0.0       0.0       1.0       0.0  -0.793202  0.000000   
5425        0.0       0.0       1.0       0.0       0.0   0.547458  1.000000   
12819       0.0       0.0       0.0       1.0       0.0   1.151035  1.000000   
33659       0.0       0.0       1.0       0.0       0.0   0.258362  0.000000   
19531       1.0       0.0       0.0       0.0       0.0  -0.821118  0.000000   

       PhysicalActivity  HealthInsurance   Alcohol  
28456          0.660578              0.0 -0.518600  
8993           0.000000              0.0  0.115329  
34312          0.000000              0.0  0.592213  
4802           1.012447              0.0 -0.103347  
25895          0.000000              0.0 -0.886483  
...                 ...              ...       ...  
18045          0.904383              0.0 -0.482716  
5425           1.598141              0.0  0.097790  
12819          1.598141              0.0  0.612947  
33659          1.162475              0.0 -0.154408  
19531          0.791302              0.0 -0.683278  

[13109 rows x 31 columns]
2025-12-02 17:28:34,216:INFO:get_config() successfully completed......................................
2025-12-02 17:28:34,242:INFO:Initializing get_config()
2025-12-02 17:28:34,242:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017153B431F0>, variable=y_test)
2025-12-02 17:28:34,242:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-12-02 17:28:34,242:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-12-02 17:28:34,247:INFO:Variable:  returned as 28456    0.0
8993     0.0
34312    0.0
4802     0.0
25895    0.0
        ... 
18045    0.0
5425     0.0
12819    0.0
33659    0.0
19531    0.0
Name: HeartDisease, Length: 13109, dtype: float32
2025-12-02 17:28:34,247:INFO:get_config() successfully completed......................................
2025-12-02 17:28:34,248:INFO:Initializing get_config()
2025-12-02 17:28:34,248:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017153B431F0>, variable=y_test)
2025-12-02 17:28:34,248:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-12-02 17:28:34,248:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-12-02 17:28:34,251:INFO:Variable:  returned as 28456    0.0
8993     0.0
34312    0.0
4802     0.0
25895    0.0
        ... 
18045    0.0
5425     0.0
12819    0.0
33659    0.0
19531    0.0
Name: HeartDisease, Length: 13109, dtype: float32
2025-12-02 17:28:34,251:INFO:get_config() successfully completed......................................
2025-12-02 17:28:34,255:INFO:Initializing get_config()
2025-12-02 17:28:34,255:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017153B431F0>, variable=X_test_transformed)
2025-12-02 17:28:34,323:INFO:Variable: X_test returned as             Age  IncomeRatio  SystolicBP       BMI  WaistCircumference  \
28456 -0.477273    -0.304717   -0.519256 -0.987220           -0.923253   
8993   0.818182     0.253271    2.156910  0.770675            0.920394   
34312  0.704545     0.055403    0.519256  0.518044            0.662901   
4802  -0.545455     0.253730   -0.331933 -0.229036           -0.436352   
25895  0.704545     1.226781   -0.093200 -0.226100            0.012322   
...         ...          ...         ...       ...                 ...   
18045 -0.568182    -0.083104   -0.568713 -1.176693           -1.338674   
5425   0.590909     0.362732    2.210168  0.139096            0.292112   
12819  0.909091    -0.019787    0.899042  0.454886            0.971892   
33659 -0.522727     1.060572   -0.525683 -0.587220           -0.906087   
19531 -0.590909    -0.344290   -0.510287 -0.945114           -1.215078   

         Height  TotalCholesterol  Triglycerides       LDL       HDL  ...  \
28456 -1.080540         -0.078535      -0.470757 -0.026922  0.418008  ...   
8993  -0.279669          0.765897       0.705031  0.006026  0.446825  ...   
34312  0.559339         -0.123259       0.929511 -1.031826 -1.404309  ...   
4802  -0.504861         -0.188325      -0.322647  0.000015 -0.138743  ...   
25895  0.216731          0.892919       1.291109  0.008211 -0.255329  ...   
...         ...               ...            ...       ...       ...  ...   
18045 -2.080569         -0.340947      -0.470582 -0.848950  0.393794  ...   
5425   0.156785          0.435639      -0.065356  1.113733  0.127664  ...   
12819  1.194951         -0.732967      -0.470025 -0.211535 -1.085148  ...   
33659 -1.254274         -1.063225      -0.470958 -2.849419  0.127664  ...   
19531 -2.339052         -0.356898      -0.470595 -0.900608  0.393896  ...   

       Race_5.0  Race_1.0  Race_4.0  Race_3.0  Race_2.0  Education   Smoking  \
28456       1.0       0.0       0.0       0.0       0.0  -0.012820  0.000000   
8993        0.0       0.0       1.0       0.0       0.0   0.547458  1.000000   
34312       0.0       0.0       0.0       1.0       0.0  -0.659696  0.000000   
4802        1.0       0.0       0.0       0.0       0.0   0.262895  0.073612   
25895       0.0       0.0       0.0       1.0       0.0   1.151035  0.000000   
...         ...       ...       ...       ...       ...        ...       ...   
18045       0.0       0.0       0.0       1.0       0.0  -0.793202  0.000000   
5425        0.0       0.0       1.0       0.0       0.0   0.547458  1.000000   
12819       0.0       0.0       0.0       1.0       0.0   1.151035  1.000000   
33659       0.0       0.0       1.0       0.0       0.0   0.258362  0.000000   
19531       1.0       0.0       0.0       0.0       0.0  -0.821118  0.000000   

       PhysicalActivity  HealthInsurance   Alcohol  
28456          0.660578              0.0 -0.518600  
8993           0.000000              0.0  0.115329  
34312          0.000000              0.0  0.592213  
4802           1.012447              0.0 -0.103347  
25895          0.000000              0.0 -0.886483  
...                 ...              ...       ...  
18045          0.904383              0.0 -0.482716  
5425           1.598141              0.0  0.097790  
12819          1.598141              0.0  0.612947  
33659          1.162475              0.0 -0.154408  
19531          0.791302              0.0 -0.683278  

[13109 rows x 31 columns]
2025-12-02 17:28:34,323:INFO:get_config() successfully completed......................................
2025-12-02 17:28:34,326:INFO:Initializing get_config()
2025-12-02 17:28:34,326:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017153B431F0>, variable=y_test)
2025-12-02 17:28:34,326:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-12-02 17:28:34,326:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-12-02 17:28:34,331:INFO:Variable:  returned as 28456    0.0
8993     0.0
34312    0.0
4802     0.0
25895    0.0
        ... 
18045    0.0
5425     0.0
12819    0.0
33659    0.0
19531    0.0
Name: HeartDisease, Length: 13109, dtype: float32
2025-12-02 17:28:34,331:INFO:get_config() successfully completed......................................
2025-12-02 17:28:34,332:INFO:Initializing get_config()
2025-12-02 17:28:34,332:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017153B431F0>, variable=y_test)
2025-12-02 17:28:34,332:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-12-02 17:28:34,332:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-12-02 17:28:34,337:INFO:Variable:  returned as 28456    0.0
8993     0.0
34312    0.0
4802     0.0
25895    0.0
        ... 
18045    0.0
5425     0.0
12819    0.0
33659    0.0
19531    0.0
Name: HeartDisease, Length: 13109, dtype: float32
2025-12-02 17:28:34,337:INFO:get_config() successfully completed......................................
2025-12-02 17:28:34,337:INFO:Initializing get_config()
2025-12-02 17:28:34,337:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017153B431F0>, variable=X_test_transformed)
2025-12-02 17:28:34,407:INFO:Variable: X_test returned as             Age  IncomeRatio  SystolicBP       BMI  WaistCircumference  \
28456 -0.477273    -0.304717   -0.519256 -0.987220           -0.923253   
8993   0.818182     0.253271    2.156910  0.770675            0.920394   
34312  0.704545     0.055403    0.519256  0.518044            0.662901   
4802  -0.545455     0.253730   -0.331933 -0.229036           -0.436352   
25895  0.704545     1.226781   -0.093200 -0.226100            0.012322   
...         ...          ...         ...       ...                 ...   
18045 -0.568182    -0.083104   -0.568713 -1.176693           -1.338674   
5425   0.590909     0.362732    2.210168  0.139096            0.292112   
12819  0.909091    -0.019787    0.899042  0.454886            0.971892   
33659 -0.522727     1.060572   -0.525683 -0.587220           -0.906087   
19531 -0.590909    -0.344290   -0.510287 -0.945114           -1.215078   

         Height  TotalCholesterol  Triglycerides       LDL       HDL  ...  \
28456 -1.080540         -0.078535      -0.470757 -0.026922  0.418008  ...   
8993  -0.279669          0.765897       0.705031  0.006026  0.446825  ...   
34312  0.559339         -0.123259       0.929511 -1.031826 -1.404309  ...   
4802  -0.504861         -0.188325      -0.322647  0.000015 -0.138743  ...   
25895  0.216731          0.892919       1.291109  0.008211 -0.255329  ...   
...         ...               ...            ...       ...       ...  ...   
18045 -2.080569         -0.340947      -0.470582 -0.848950  0.393794  ...   
5425   0.156785          0.435639      -0.065356  1.113733  0.127664  ...   
12819  1.194951         -0.732967      -0.470025 -0.211535 -1.085148  ...   
33659 -1.254274         -1.063225      -0.470958 -2.849419  0.127664  ...   
19531 -2.339052         -0.356898      -0.470595 -0.900608  0.393896  ...   

       Race_5.0  Race_1.0  Race_4.0  Race_3.0  Race_2.0  Education   Smoking  \
28456       1.0       0.0       0.0       0.0       0.0  -0.012820  0.000000   
8993        0.0       0.0       1.0       0.0       0.0   0.547458  1.000000   
34312       0.0       0.0       0.0       1.0       0.0  -0.659696  0.000000   
4802        1.0       0.0       0.0       0.0       0.0   0.262895  0.073612   
25895       0.0       0.0       0.0       1.0       0.0   1.151035  0.000000   
...         ...       ...       ...       ...       ...        ...       ...   
18045       0.0       0.0       0.0       1.0       0.0  -0.793202  0.000000   
5425        0.0       0.0       1.0       0.0       0.0   0.547458  1.000000   
12819       0.0       0.0       0.0       1.0       0.0   1.151035  1.000000   
33659       0.0       0.0       1.0       0.0       0.0   0.258362  0.000000   
19531       1.0       0.0       0.0       0.0       0.0  -0.821118  0.000000   

       PhysicalActivity  HealthInsurance   Alcohol  
28456          0.660578              0.0 -0.518600  
8993           0.000000              0.0  0.115329  
34312          0.000000              0.0  0.592213  
4802           1.012447              0.0 -0.103347  
25895          0.000000              0.0 -0.886483  
...                 ...              ...       ...  
18045          0.904383              0.0 -0.482716  
5425           1.598141              0.0  0.097790  
12819          1.598141              0.0  0.612947  
33659          1.162475              0.0 -0.154408  
19531          0.791302              0.0 -0.683278  

[13109 rows x 31 columns]
2025-12-02 17:28:34,407:INFO:get_config() successfully completed......................................
2025-12-02 17:28:34,466:INFO:Initializing get_config()
2025-12-02 17:28:34,466:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017153B431F0>, variable=y_test)
2025-12-02 17:28:34,466:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-12-02 17:28:34,467:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-12-02 17:28:34,473:INFO:Variable:  returned as 28456    0.0
8993     0.0
34312    0.0
4802     0.0
25895    0.0
        ... 
18045    0.0
5425     0.0
12819    0.0
33659    0.0
19531    0.0
Name: HeartDisease, Length: 13109, dtype: float32
2025-12-02 17:28:34,473:INFO:get_config() successfully completed......................................
2025-12-02 17:28:34,473:INFO:Initializing get_config()
2025-12-02 17:28:34,473:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017153B431F0>, variable=y_test)
2025-12-02 17:28:34,473:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-12-02 17:28:34,473:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-12-02 17:28:34,476:INFO:Variable:  returned as 28456    0.0
8993     0.0
34312    0.0
4802     0.0
25895    0.0
        ... 
18045    0.0
5425     0.0
12819    0.0
33659    0.0
19531    0.0
Name: HeartDisease, Length: 13109, dtype: float32
2025-12-02 17:28:34,476:INFO:get_config() successfully completed......................................
2025-12-02 17:28:41,119:INFO:Initializing interpret_model()
2025-12-02 17:28:41,119:INFO:interpret_model(estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...), use_train_data=False, X_new_sample=None, y_new_sample=None, feature=None, kwargs={}, observation=None, plot=summary, save=False, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017153B431F0>)
2025-12-02 17:28:41,119:INFO:Checking exceptions
2025-12-02 17:28:41,119:INFO:Soft dependency imported: shap: 0.49.1
2025-12-02 17:28:41,189:INFO:plot type: summary
2025-12-02 17:28:41,189:INFO:Creating TreeExplainer
2025-12-02 17:28:41,205:INFO:Compiling shap values
2025-12-02 17:28:45,966:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:4145: FutureWarning: The NumPy global RNG was seeded by calling `np.random.seed`. In a future version this function will no longer use the global RNG. Pass `rng` explicitly to opt-in to the new behaviour and silence this warning.

2025-12-02 17:28:47,126:INFO:Visual Rendered Successfully
2025-12-02 17:28:47,126:INFO:interpret_model() successfully completed......................................
2025-12-02 17:28:51,394:INFO:Initializing interpret_model()
2025-12-02 17:28:51,394:INFO:interpret_model(estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...), use_train_data=False, X_new_sample=None, y_new_sample=None, feature=None, kwargs={}, observation=0, plot=reason, save=False, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017153B431F0>)
2025-12-02 17:28:51,394:INFO:Checking exceptions
2025-12-02 17:28:51,394:INFO:Soft dependency imported: shap: 0.49.1
2025-12-02 17:28:51,463:INFO:plot type: reason
2025-12-02 17:28:51,463:INFO:model type detected: type 2
2025-12-02 17:28:51,463:INFO:Creating TreeExplainer
2025-12-02 17:28:51,476:INFO:Compiling shap values
2025-12-02 17:28:56,204:INFO:Visual Rendered Successfully
2025-12-02 17:28:56,205:INFO:interpret_model() successfully completed......................................
2025-12-02 17:29:01,571:INFO:Initializing get_config()
2025-12-02 17:29:01,571:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017153B431F0>, variable=X_test_transformed)
2025-12-02 17:29:01,647:INFO:Variable: X_test returned as             Age  IncomeRatio  SystolicBP       BMI  WaistCircumference  \
28456 -0.477273    -0.304717   -0.519256 -0.987220           -0.923253   
8993   0.818182     0.253271    2.156910  0.770675            0.920394   
34312  0.704545     0.055403    0.519256  0.518044            0.662901   
4802  -0.545455     0.253730   -0.331933 -0.229036           -0.436352   
25895  0.704545     1.226781   -0.093200 -0.226100            0.012322   
...         ...          ...         ...       ...                 ...   
18045 -0.568182    -0.083104   -0.568713 -1.176693           -1.338674   
5425   0.590909     0.362732    2.210168  0.139096            0.292112   
12819  0.909091    -0.019787    0.899042  0.454886            0.971892   
33659 -0.522727     1.060572   -0.525683 -0.587220           -0.906087   
19531 -0.590909    -0.344290   -0.510287 -0.945114           -1.215078   

         Height  TotalCholesterol  Triglycerides       LDL       HDL  ...  \
28456 -1.080540         -0.078535      -0.470757 -0.026922  0.418008  ...   
8993  -0.279669          0.765897       0.705031  0.006026  0.446825  ...   
34312  0.559339         -0.123259       0.929511 -1.031826 -1.404309  ...   
4802  -0.504861         -0.188325      -0.322647  0.000015 -0.138743  ...   
25895  0.216731          0.892919       1.291109  0.008211 -0.255329  ...   
...         ...               ...            ...       ...       ...  ...   
18045 -2.080569         -0.340947      -0.470582 -0.848950  0.393794  ...   
5425   0.156785          0.435639      -0.065356  1.113733  0.127664  ...   
12819  1.194951         -0.732967      -0.470025 -0.211535 -1.085148  ...   
33659 -1.254274         -1.063225      -0.470958 -2.849419  0.127664  ...   
19531 -2.339052         -0.356898      -0.470595 -0.900608  0.393896  ...   

       Race_5.0  Race_1.0  Race_4.0  Race_3.0  Race_2.0  Education   Smoking  \
28456       1.0       0.0       0.0       0.0       0.0  -0.012820  0.000000   
8993        0.0       0.0       1.0       0.0       0.0   0.547458  1.000000   
34312       0.0       0.0       0.0       1.0       0.0  -0.659696  0.000000   
4802        1.0       0.0       0.0       0.0       0.0   0.262895  0.073612   
25895       0.0       0.0       0.0       1.0       0.0   1.151035  0.000000   
...         ...       ...       ...       ...       ...        ...       ...   
18045       0.0       0.0       0.0       1.0       0.0  -0.793202  0.000000   
5425        0.0       0.0       1.0       0.0       0.0   0.547458  1.000000   
12819       0.0       0.0       0.0       1.0       0.0   1.151035  1.000000   
33659       0.0       0.0       1.0       0.0       0.0   0.258362  0.000000   
19531       1.0       0.0       0.0       0.0       0.0  -0.821118  0.000000   

       PhysicalActivity  HealthInsurance   Alcohol  
28456          0.660578              0.0 -0.518600  
8993           0.000000              0.0  0.115329  
34312          0.000000              0.0  0.592213  
4802           1.012447              0.0 -0.103347  
25895          0.000000              0.0 -0.886483  
...                 ...              ...       ...  
18045          0.904383              0.0 -0.482716  
5425           1.598141              0.0  0.097790  
12819          1.598141              0.0  0.612947  
33659          1.162475              0.0 -0.154408  
19531          0.791302              0.0 -0.683278  

[13109 rows x 31 columns]
2025-12-02 17:29:01,647:INFO:get_config() successfully completed......................................
2025-12-02 17:29:01,675:INFO:Initializing get_config()
2025-12-02 17:29:01,675:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017153B431F0>, variable=y_test)
2025-12-02 17:29:01,675:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-12-02 17:29:01,675:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-12-02 17:29:01,680:INFO:Variable:  returned as 28456    0.0
8993     0.0
34312    0.0
4802     0.0
25895    0.0
        ... 
18045    0.0
5425     0.0
12819    0.0
33659    0.0
19531    0.0
Name: HeartDisease, Length: 13109, dtype: float32
2025-12-02 17:29:01,680:INFO:get_config() successfully completed......................................
2025-12-02 17:29:21,410:INFO:Initializing tune_model()
2025-12-02 17:29:21,410:INFO:tune_model(estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...), fold=None, round=4, n_iter=5, custom_grid=None, optimize=Recall, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=False, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017153B431F0>)
2025-12-02 17:29:21,410:INFO:Checking exceptions
2025-12-02 17:29:21,421:INFO:Copying training dataset
2025-12-02 17:29:21,436:INFO:Checking base model
2025-12-02 17:29:21,436:INFO:Base model : Extreme Gradient Boosting
2025-12-02 17:29:21,436:INFO:Declaring metric variables
2025-12-02 17:29:21,436:INFO:Defining Hyperparameters
2025-12-02 17:29:21,604:INFO:Tuning with n_jobs=1
2025-12-02 17:29:21,604:INFO:Initializing RandomizedSearchCV
2025-12-02 17:29:57,252:INFO:best_params: {'actual_estimator__subsample': 0.7, 'actual_estimator__scale_pos_weight': 38.0, 'actual_estimator__reg_lambda': 0.7, 'actual_estimator__reg_alpha': 0.001, 'actual_estimator__n_estimators': 60, 'actual_estimator__min_child_weight': 1, 'actual_estimator__max_depth': 6, 'actual_estimator__learning_rate': 0.4, 'actual_estimator__colsample_bytree': 0.7}
2025-12-02 17:29:57,252:INFO:Hyperparameter search completed
2025-12-02 17:29:57,252:INFO:SubProcess create_model() called ==================================
2025-12-02 17:29:57,252:INFO:Initializing create_model()
2025-12-02 17:29:57,252:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017153B431F0>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001715BD3B9D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'subsample': 0.7, 'scale_pos_weight': 38.0, 'reg_lambda': 0.7, 'reg_alpha': 0.001, 'n_estimators': 60, 'min_child_weight': 1, 'max_depth': 6, 'learning_rate': 0.4, 'colsample_bytree': 0.7})
2025-12-02 17:29:57,252:INFO:Checking exceptions
2025-12-02 17:29:57,252:INFO:Importing libraries
2025-12-02 17:29:57,252:INFO:Copying training dataset
2025-12-02 17:29:57,276:INFO:Defining folds
2025-12-02 17:29:57,276:INFO:Declaring metric variables
2025-12-02 17:29:57,276:INFO:Importing untrained model
2025-12-02 17:29:57,276:INFO:Declaring custom model
2025-12-02 17:29:57,276:INFO:Extreme Gradient Boosting Imported successfully
2025-12-02 17:29:57,276:INFO:Starting cross validation
2025-12-02 17:29:57,276:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-12-02 17:30:02,054:INFO:Calculating mean and std
2025-12-02 17:30:02,056:INFO:Creating metrics dataframe
2025-12-02 17:30:02,056:INFO:Finalizing model
2025-12-02 17:30:02,124:INFO:Warning: No categorical columns found. Calling 'transform' will only return input data.
2025-12-02 17:30:02,517:INFO:Uploading results into container
2025-12-02 17:30:02,519:INFO:Uploading model into container now
2025-12-02 17:30:02,519:INFO:_master_model_container: 4
2025-12-02 17:30:02,519:INFO:_display_container: 5
2025-12-02 17:30:02,520:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=0.7, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=0.4, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=6, max_leaves=None,
              min_child_weight=1, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=60, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2025-12-02 17:30:02,520:INFO:create_model() successfully completed......................................
2025-12-02 17:30:02,702:INFO:SubProcess create_model() end ==================================
2025-12-02 17:30:02,702:INFO:choose_better activated
2025-12-02 17:30:02,704:INFO:SubProcess create_model() called ==================================
2025-12-02 17:30:02,704:INFO:Initializing create_model()
2025-12-02 17:30:02,704:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017153B431F0>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-02 17:30:02,704:INFO:Checking exceptions
2025-12-02 17:30:02,704:INFO:Importing libraries
2025-12-02 17:30:02,704:INFO:Copying training dataset
2025-12-02 17:30:02,726:INFO:Defining folds
2025-12-02 17:30:02,726:INFO:Declaring metric variables
2025-12-02 17:30:02,726:INFO:Importing untrained model
2025-12-02 17:30:02,726:INFO:Declaring custom model
2025-12-02 17:30:02,726:INFO:Extreme Gradient Boosting Imported successfully
2025-12-02 17:30:02,726:INFO:Starting cross validation
2025-12-02 17:30:02,726:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-12-02 17:30:08,647:INFO:Calculating mean and std
2025-12-02 17:30:08,647:INFO:Creating metrics dataframe
2025-12-02 17:30:08,651:INFO:Finalizing model
2025-12-02 17:30:08,714:INFO:Warning: No categorical columns found. Calling 'transform' will only return input data.
2025-12-02 17:30:09,221:INFO:Uploading results into container
2025-12-02 17:30:09,221:INFO:Uploading model into container now
2025-12-02 17:30:09,221:INFO:_master_model_container: 5
2025-12-02 17:30:09,221:INFO:_display_container: 6
2025-12-02 17:30:09,222:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2025-12-02 17:30:09,222:INFO:create_model() successfully completed......................................
2025-12-02 17:30:09,401:INFO:SubProcess create_model() end ==================================
2025-12-02 17:30:09,401:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...) result for Recall is 0.2882
2025-12-02 17:30:09,401:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=0.7, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=0.4, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=6, max_leaves=None,
              min_child_weight=1, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=60, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...) result for Recall is 0.3316
2025-12-02 17:30:09,404:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=0.7, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=0.4, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=6, max_leaves=None,
              min_child_weight=1, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=60, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...) is best model
2025-12-02 17:30:09,404:INFO:choose_better completed
2025-12-02 17:30:09,404:INFO:_master_model_container: 5
2025-12-02 17:30:09,404:INFO:_display_container: 5
2025-12-02 17:30:09,404:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=0.7, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=0.4, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=6, max_leaves=None,
              min_child_weight=1, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=60, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2025-12-02 17:30:09,404:INFO:tune_model() successfully completed......................................
2025-12-02 17:30:14,821:INFO:Initializing predict_model()
2025-12-02 17:30:14,821:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017153B431F0>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=0.7, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=0.4, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=6, max_leaves=None,
              min_child_weight=1, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=60, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...), probability_threshold=None, encoded_labels=False, raw_score=True, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001715D91B0A0>)
2025-12-02 17:30:14,821:INFO:Checking exceptions
2025-12-02 17:30:14,822:INFO:Preloading libraries
2025-12-02 17:30:15,216:INFO:Initializing get_config()
2025-12-02 17:30:15,216:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017153B431F0>, variable=target_param)
2025-12-02 17:30:15,216:INFO:Variable:  returned as HeartDisease
2025-12-02 17:30:15,216:INFO:get_config() successfully completed......................................
2025-12-02 17:30:22,124:INFO:Initializing interpret_model()
2025-12-02 17:30:22,124:INFO:interpret_model(estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=0.7, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=0.4, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=6, max_leaves=None,
              min_child_weight=1, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=60, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...), use_train_data=False, X_new_sample=None, y_new_sample=None, feature=None, kwargs={}, observation=None, plot=summary, save=False, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017153B431F0>)
2025-12-02 17:30:22,124:INFO:Checking exceptions
2025-12-02 17:30:22,125:INFO:Soft dependency imported: shap: 0.49.1
2025-12-02 17:30:22,196:INFO:plot type: summary
2025-12-02 17:30:22,196:INFO:Creating TreeExplainer
2025-12-02 17:30:22,206:INFO:Compiling shap values
2025-12-02 17:30:25,521:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:4145: FutureWarning: The NumPy global RNG was seeded by calling `np.random.seed`. In a future version this function will no longer use the global RNG. Pass `rng` explicitly to opt-in to the new behaviour and silence this warning.

2025-12-02 17:30:26,656:INFO:Visual Rendered Successfully
2025-12-02 17:30:26,656:INFO:interpret_model() successfully completed......................................
2025-12-02 17:31:47,247:INFO:Initializing finalize_model()
2025-12-02 17:31:47,250:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017153B431F0>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=0.7, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=0.4, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=6, max_leaves=None,
              min_child_weight=1, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=60, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2025-12-02 17:31:47,250:INFO:Finalizing XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=0.7, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=0.4, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=6, max_leaves=None,
              min_child_weight=1, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=60, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2025-12-02 17:31:47,264:INFO:Initializing create_model()
2025-12-02 17:31:47,264:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017153B431F0>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=0.7, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=0.4, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=6, max_leaves=None,
              min_child_weight=1, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=60, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2025-12-02 17:31:47,267:INFO:Checking exceptions
2025-12-02 17:31:47,268:INFO:Importing libraries
2025-12-02 17:31:47,268:INFO:Copying training dataset
2025-12-02 17:31:47,272:INFO:Defining folds
2025-12-02 17:31:47,272:INFO:Declaring metric variables
2025-12-02 17:31:47,272:INFO:Importing untrained model
2025-12-02 17:31:47,273:INFO:Declaring custom model
2025-12-02 17:31:47,274:INFO:Extreme Gradient Boosting Imported successfully
2025-12-02 17:31:47,275:INFO:Cross validation set to False
2025-12-02 17:31:47,275:INFO:Fitting Model
2025-12-02 17:31:47,382:INFO:Warning: No categorical columns found. Calling 'transform' will only return input data.
2025-12-02 17:31:47,959:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'IncomeRatio', 'SystolicBP',
                                             'BMI', 'WaistCircumference',
                                             'Height', 'TotalCholesterol',
                                             'Triglycerides', 'LDL', 'HDL',
                                             'HbA1c', 'Glucose', 'Creatinine',
                                             'UricAcid', 'ALT_Enzyme',
                                             'Albumin', 'Potassium', 'Sodium',
                                             'GGT_Enzyme', 'AST_Enzyme'],
                                    transformer=Si...
                               feature_types=None, gamma=None, grow_policy=None,
                               importance_type=None,
                               interaction_constraints=None, learning_rate=0.4,
                               max_bin=None, max_cat_threshold=None,
                               max_cat_to_onehot=None, max_delta_step=None,
                               max_depth=6, max_leaves=None, min_child_weight=1,
                               missing=nan, monotone_constraints=None,
                               multi_strategy=None, n_estimators=60, n_jobs=1,
                               num_parallel_tree=None,
                               objective='binary:logistic', ...))],
         verbose=False)
2025-12-02 17:31:47,959:INFO:create_model() successfully completed......................................
2025-12-02 17:31:48,132:INFO:_master_model_container: 5
2025-12-02 17:31:48,132:INFO:_display_container: 6
2025-12-02 17:31:48,147:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'IncomeRatio', 'SystolicBP',
                                             'BMI', 'WaistCircumference',
                                             'Height', 'TotalCholesterol',
                                             'Triglycerides', 'LDL', 'HDL',
                                             'HbA1c', 'Glucose', 'Creatinine',
                                             'UricAcid', 'ALT_Enzyme',
                                             'Albumin', 'Potassium', 'Sodium',
                                             'GGT_Enzyme', 'AST_Enzyme'],
                                    transformer=Si...
                               feature_types=None, gamma=None, grow_policy=None,
                               importance_type=None,
                               interaction_constraints=None, learning_rate=0.4,
                               max_bin=None, max_cat_threshold=None,
                               max_cat_to_onehot=None, max_delta_step=None,
                               max_depth=6, max_leaves=None, min_child_weight=1,
                               missing=nan, monotone_constraints=None,
                               multi_strategy=None, n_estimators=60, n_jobs=1,
                               num_parallel_tree=None,
                               objective='binary:logistic', ...))],
         verbose=False)
2025-12-02 17:31:48,147:INFO:finalize_model() successfully completed......................................
2025-12-02 17:31:48,342:INFO:Initializing save_model()
2025-12-02 17:31:48,342:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'IncomeRatio', 'SystolicBP',
                                             'BMI', 'WaistCircumference',
                                             'Height', 'TotalCholesterol',
                                             'Triglycerides', 'LDL', 'HDL',
                                             'HbA1c', 'Glucose', 'Creatinine',
                                             'UricAcid', 'ALT_Enzyme',
                                             'Albumin', 'Potassium', 'Sodium',
                                             'GGT_Enzyme', 'AST_Enzyme'],
                                    transformer=Si...
                               feature_types=None, gamma=None, grow_policy=None,
                               importance_type=None,
                               interaction_constraints=None, learning_rate=0.4,
                               max_bin=None, max_cat_threshold=None,
                               max_cat_to_onehot=None, max_delta_step=None,
                               max_depth=6, max_leaves=None, min_child_weight=1,
                               missing=nan, monotone_constraints=None,
                               multi_strategy=None, n_estimators=60, n_jobs=1,
                               num_parallel_tree=None,
                               objective='binary:logistic', ...))],
         verbose=False), model_name=../models\best_pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\OMAR\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'IncomeRatio', 'SystolicBP',
                                             'BMI', 'WaistCircumference',
                                             'Height', 'TotalCholesterol',
                                             'Triglycerides', 'LDL', 'HDL',
                                             'HbA1c', 'Glucose', 'Creatinine',
                                             'UricAcid', 'ALT_Enzyme',
                                             'Albumin', 'Potassium', 'Sodium',
                                             'G...
                                    transformer=TargetEncoder(cols=[],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=RobustScaler(copy=True,
                                                             quantile_range=(25.0,
                                                                             75.0),
                                                             unit_variance=False,
                                                             with_centering=True,
                                                             with_scaling=True)))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2025-12-02 17:31:48,342:INFO:Adding model into prep_pipe
2025-12-02 17:31:48,342:WARNING:Only Model saved as it was a pipeline.
2025-12-02 17:31:48,350:INFO:../models\best_pipeline.pkl saved in current working directory
2025-12-02 17:31:48,364:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'IncomeRatio', 'SystolicBP',
                                             'BMI', 'WaistCircumference',
                                             'Height', 'TotalCholesterol',
                                             'Triglycerides', 'LDL', 'HDL',
                                             'HbA1c', 'Glucose', 'Creatinine',
                                             'UricAcid', 'ALT_Enzyme',
                                             'Albumin', 'Potassium', 'Sodium',
                                             'GGT_Enzyme', 'AST_Enzyme'],
                                    transformer=Si...
                               feature_types=None, gamma=None, grow_policy=None,
                               importance_type=None,
                               interaction_constraints=None, learning_rate=0.4,
                               max_bin=None, max_cat_threshold=None,
                               max_cat_to_onehot=None, max_delta_step=None,
                               max_depth=6, max_leaves=None, min_child_weight=1,
                               missing=nan, monotone_constraints=None,
                               multi_strategy=None, n_estimators=60, n_jobs=1,
                               num_parallel_tree=None,
                               objective='binary:logistic', ...))],
         verbose=False)
2025-12-02 17:31:48,364:INFO:save_model() successfully completed......................................
2025-12-02 17:34:22,196:INFO:Initializing get_config()
2025-12-02 17:34:22,196:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017153B431F0>, variable=X_train_transformed)
2025-12-02 17:34:22,236:INFO:Variable: X_train returned as             Age  IncomeRatio  SystolicBP       BMI  WaistCircumference  \
15208  0.954545     0.854789    0.359485  0.518044            0.206281   
25325 -0.272727     0.253271   -0.812170 -0.966167           -0.799656   
5132   0.181818    -0.407608   -0.372799  0.054886            0.319578   
17217  0.500000    -0.751898    0.013314 -0.260904            0.278379   
6382   0.568182     0.054503    1.131712  2.675938            1.888566   
...         ...          ...         ...       ...                 ...   
6265  -0.545455    -0.431352   -0.591719  0.191728           -0.377368   
42694 -0.022727    -0.221612   -0.892056 -0.260904           -0.047778   
13399  0.454545     0.388518    0.377985  0.271482            0.183567   
39959  0.954545    -0.193911    0.625770  0.991728            1.160720   
6616   0.613636    -0.447182    0.652399 -0.871430           -0.514698   

         Height  TotalCholesterol  Triglycerides       LDL       HDL  ...  \
15208 -0.487303          0.625876       0.583394  0.005397  0.314564  ...   
25325 -0.300856          0.033588      -0.261476  0.000256  0.303682  ...   
5132   0.766972          0.181594       0.479279  0.948690 -1.340476  ...   
17217  0.745785          0.227516       0.346113  0.002441 -0.274561  ...   
6382   0.237295          0.867515       0.635574  0.002754  0.829819  ...   
...         ...               ...            ...       ...       ...  ...   
6265  -1.737339         -1.393483      -0.471046 -3.840886  0.063832  ...   
42694  0.000000          0.029167      -0.131730  0.000893  0.063832  ...   
13399 -0.147405          0.462357       0.380371  0.003925  0.256949  ...   
39959  0.368655          1.528031       1.934134  0.011744  0.191497  ...   
6616  -0.021187         -0.224877      -0.043571 -1.609476  0.510658  ...   

       Race_5.0  Race_1.0  Race_4.0  Race_3.0  Race_2.0  Education  Smoking  \
15208       1.0       0.0       0.0       0.0       0.0  -0.659696      0.0   
25325       0.0       1.0       0.0       0.0       0.0   0.185278      0.0   
5132        0.0       1.0       0.0       0.0       0.0  -0.659696      1.0   
17217       0.0       0.0       1.0       0.0       0.0  -0.056119      1.0   
6382        0.0       0.0       1.0       0.0       0.0   0.547458      1.0   
...         ...       ...       ...       ...       ...        ...      ...   
6265        0.0       1.0       0.0       0.0       0.0  -0.769055      0.0   
42694       0.0       1.0       0.0       0.0       0.0   0.547458      0.0   
13399       0.0       0.0       1.0       0.0       0.0   0.547458      0.0   
39959       0.0       0.0       0.0       1.0       0.0   0.547458      0.0   
6616        0.0       0.0       0.0       1.0       0.0   0.547458      1.0   

       PhysicalActivity  HealthInsurance   Alcohol  
15208          0.000000              0.0 -0.886483  
25325          0.000000              0.0  0.592213  
5132           0.000000             -1.0  0.312949  
17217          0.000000              0.0  0.592213  
6382           0.000000              0.0  0.597293  
...                 ...              ...       ...  
6265           0.662459              0.0 -0.501621  
42694          0.000000             -1.0  0.592213  
13399          0.000000              0.0 -0.224534  
39959          0.000000              0.0  0.592213  
6616           0.000000              0.0  0.290247  

[30586 rows x 31 columns]
2025-12-02 17:34:22,237:INFO:get_config() successfully completed......................................
2025-12-02 17:34:22,237:INFO:Initializing get_config()
2025-12-02 17:34:22,237:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017153B431F0>, variable=y_train)
2025-12-02 17:34:22,237:INFO:Variable: 'y_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_train_transformed' instead.
2025-12-02 17:34:22,237:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_train_transformed' instead.

2025-12-02 17:34:22,245:INFO:Variable:  returned as 15208    0.0
25325    0.0
5132     0.0
17217    0.0
6382     0.0
        ... 
6265     0.0
42694    0.0
13399    0.0
39959    0.0
6616     0.0
Name: HeartDisease, Length: 30586, dtype: float32
2025-12-02 17:34:22,246:INFO:get_config() successfully completed......................................
2025-12-02 17:34:22,248:INFO:Initializing get_config()
2025-12-02 17:34:22,248:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017153B431F0>, variable=X_test_transformed)
2025-12-02 17:34:22,333:INFO:Variable: X_test returned as             Age  IncomeRatio  SystolicBP       BMI  WaistCircumference  \
28456 -0.477273    -0.304717   -0.519256 -0.987220           -0.923253   
8993   0.818182     0.253271    2.156910  0.770675            0.920394   
34312  0.704545     0.055403    0.519256  0.518044            0.662901   
4802  -0.545455     0.253730   -0.331933 -0.229036           -0.436352   
25895  0.704545     1.226781   -0.093200 -0.226100            0.012322   
...         ...          ...         ...       ...                 ...   
18045 -0.568182    -0.083104   -0.568713 -1.176693           -1.338674   
5425   0.590909     0.362732    2.210168  0.139096            0.292112   
12819  0.909091    -0.019787    0.899042  0.454886            0.971892   
33659 -0.522727     1.060572   -0.525683 -0.587220           -0.906087   
19531 -0.590909    -0.344290   -0.510287 -0.945114           -1.215078   

         Height  TotalCholesterol  Triglycerides       LDL       HDL  ...  \
28456 -1.080540         -0.078535      -0.470757 -0.026922  0.418008  ...   
8993  -0.279669          0.765897       0.705031  0.006026  0.446825  ...   
34312  0.559339         -0.123259       0.929511 -1.031826 -1.404309  ...   
4802  -0.504861         -0.188325      -0.322647  0.000015 -0.138743  ...   
25895  0.216731          0.892919       1.291109  0.008211 -0.255329  ...   
...         ...               ...            ...       ...       ...  ...   
18045 -2.080569         -0.340947      -0.470582 -0.848950  0.393794  ...   
5425   0.156785          0.435639      -0.065356  1.113733  0.127664  ...   
12819  1.194951         -0.732967      -0.470025 -0.211535 -1.085148  ...   
33659 -1.254274         -1.063225      -0.470958 -2.849419  0.127664  ...   
19531 -2.339052         -0.356898      -0.470595 -0.900608  0.393896  ...   

       Race_5.0  Race_1.0  Race_4.0  Race_3.0  Race_2.0  Education   Smoking  \
28456       1.0       0.0       0.0       0.0       0.0  -0.012820  0.000000   
8993        0.0       0.0       1.0       0.0       0.0   0.547458  1.000000   
34312       0.0       0.0       0.0       1.0       0.0  -0.659696  0.000000   
4802        1.0       0.0       0.0       0.0       0.0   0.262895  0.073612   
25895       0.0       0.0       0.0       1.0       0.0   1.151035  0.000000   
...         ...       ...       ...       ...       ...        ...       ...   
18045       0.0       0.0       0.0       1.0       0.0  -0.793202  0.000000   
5425        0.0       0.0       1.0       0.0       0.0   0.547458  1.000000   
12819       0.0       0.0       0.0       1.0       0.0   1.151035  1.000000   
33659       0.0       0.0       1.0       0.0       0.0   0.258362  0.000000   
19531       1.0       0.0       0.0       0.0       0.0  -0.821118  0.000000   

       PhysicalActivity  HealthInsurance   Alcohol  
28456          0.660578              0.0 -0.518600  
8993           0.000000              0.0  0.115329  
34312          0.000000              0.0  0.592213  
4802           1.012447              0.0 -0.103347  
25895          0.000000              0.0 -0.886483  
...                 ...              ...       ...  
18045          0.904383              0.0 -0.482716  
5425           1.598141              0.0  0.097790  
12819          1.598141              0.0  0.612947  
33659          1.162475              0.0 -0.154408  
19531          0.791302              0.0 -0.683278  

[13109 rows x 31 columns]
2025-12-02 17:34:22,333:INFO:get_config() successfully completed......................................
2025-12-02 17:34:22,333:INFO:Initializing get_config()
2025-12-02 17:34:22,333:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017153B431F0>, variable=y_test)
2025-12-02 17:34:22,333:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-12-02 17:34:22,333:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-12-02 17:34:22,336:INFO:Variable:  returned as 28456    0.0
8993     0.0
34312    0.0
4802     0.0
25895    0.0
        ... 
18045    0.0
5425     0.0
12819    0.0
33659    0.0
19531    0.0
Name: HeartDisease, Length: 13109, dtype: float32
2025-12-02 17:34:22,336:INFO:get_config() successfully completed......................................
2025-12-02 17:34:22,492:INFO:Initializing get_config()
2025-12-02 17:34:22,492:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017153B431F0>, variable=X_train_transformed)
2025-12-02 17:34:22,537:INFO:Variable: X_train returned as             Age  IncomeRatio  SystolicBP       BMI  WaistCircumference  \
15208  0.954545     0.854789    0.359485  0.518044            0.206281   
25325 -0.272727     0.253271   -0.812170 -0.966167           -0.799656   
5132   0.181818    -0.407608   -0.372799  0.054886            0.319578   
17217  0.500000    -0.751898    0.013314 -0.260904            0.278379   
6382   0.568182     0.054503    1.131712  2.675938            1.888566   
...         ...          ...         ...       ...                 ...   
6265  -0.545455    -0.431352   -0.591719  0.191728           -0.377368   
42694 -0.022727    -0.221612   -0.892056 -0.260904           -0.047778   
13399  0.454545     0.388518    0.377985  0.271482            0.183567   
39959  0.954545    -0.193911    0.625770  0.991728            1.160720   
6616   0.613636    -0.447182    0.652399 -0.871430           -0.514698   

         Height  TotalCholesterol  Triglycerides       LDL       HDL  ...  \
15208 -0.487303          0.625876       0.583394  0.005397  0.314564  ...   
25325 -0.300856          0.033588      -0.261476  0.000256  0.303682  ...   
5132   0.766972          0.181594       0.479279  0.948690 -1.340476  ...   
17217  0.745785          0.227516       0.346113  0.002441 -0.274561  ...   
6382   0.237295          0.867515       0.635574  0.002754  0.829819  ...   
...         ...               ...            ...       ...       ...  ...   
6265  -1.737339         -1.393483      -0.471046 -3.840886  0.063832  ...   
42694  0.000000          0.029167      -0.131730  0.000893  0.063832  ...   
13399 -0.147405          0.462357       0.380371  0.003925  0.256949  ...   
39959  0.368655          1.528031       1.934134  0.011744  0.191497  ...   
6616  -0.021187         -0.224877      -0.043571 -1.609476  0.510658  ...   

       Race_5.0  Race_1.0  Race_4.0  Race_3.0  Race_2.0  Education  Smoking  \
15208       1.0       0.0       0.0       0.0       0.0  -0.659696      0.0   
25325       0.0       1.0       0.0       0.0       0.0   0.185278      0.0   
5132        0.0       1.0       0.0       0.0       0.0  -0.659696      1.0   
17217       0.0       0.0       1.0       0.0       0.0  -0.056119      1.0   
6382        0.0       0.0       1.0       0.0       0.0   0.547458      1.0   
...         ...       ...       ...       ...       ...        ...      ...   
6265        0.0       1.0       0.0       0.0       0.0  -0.769055      0.0   
42694       0.0       1.0       0.0       0.0       0.0   0.547458      0.0   
13399       0.0       0.0       1.0       0.0       0.0   0.547458      0.0   
39959       0.0       0.0       0.0       1.0       0.0   0.547458      0.0   
6616        0.0       0.0       0.0       1.0       0.0   0.547458      1.0   

       PhysicalActivity  HealthInsurance   Alcohol  
15208          0.000000              0.0 -0.886483  
25325          0.000000              0.0  0.592213  
5132           0.000000             -1.0  0.312949  
17217          0.000000              0.0  0.592213  
6382           0.000000              0.0  0.597293  
...                 ...              ...       ...  
6265           0.662459              0.0 -0.501621  
42694          0.000000             -1.0  0.592213  
13399          0.000000              0.0 -0.224534  
39959          0.000000              0.0  0.592213  
6616           0.000000              0.0  0.290247  

[30586 rows x 31 columns]
2025-12-02 17:34:22,537:INFO:get_config() successfully completed......................................
2025-12-02 17:34:22,537:INFO:Initializing get_config()
2025-12-02 17:34:22,537:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017153B431F0>, variable=y_train)
2025-12-02 17:34:22,537:INFO:Variable: 'y_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_train_transformed' instead.
2025-12-02 17:34:22,537:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_train_transformed' instead.

2025-12-02 17:34:22,546:INFO:Variable:  returned as 15208    0.0
25325    0.0
5132     0.0
17217    0.0
6382     0.0
        ... 
6265     0.0
42694    0.0
13399    0.0
39959    0.0
6616     0.0
Name: HeartDisease, Length: 30586, dtype: float32
2025-12-02 17:34:22,546:INFO:get_config() successfully completed......................................
2025-12-02 17:34:22,547:INFO:Initializing get_config()
2025-12-02 17:34:22,547:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017153B431F0>, variable=X_test_transformed)
2025-12-02 17:34:22,634:INFO:Variable: X_test returned as             Age  IncomeRatio  SystolicBP       BMI  WaistCircumference  \
28456 -0.477273    -0.304717   -0.519256 -0.987220           -0.923253   
8993   0.818182     0.253271    2.156910  0.770675            0.920394   
34312  0.704545     0.055403    0.519256  0.518044            0.662901   
4802  -0.545455     0.253730   -0.331933 -0.229036           -0.436352   
25895  0.704545     1.226781   -0.093200 -0.226100            0.012322   
...         ...          ...         ...       ...                 ...   
18045 -0.568182    -0.083104   -0.568713 -1.176693           -1.338674   
5425   0.590909     0.362732    2.210168  0.139096            0.292112   
12819  0.909091    -0.019787    0.899042  0.454886            0.971892   
33659 -0.522727     1.060572   -0.525683 -0.587220           -0.906087   
19531 -0.590909    -0.344290   -0.510287 -0.945114           -1.215078   

         Height  TotalCholesterol  Triglycerides       LDL       HDL  ...  \
28456 -1.080540         -0.078535      -0.470757 -0.026922  0.418008  ...   
8993  -0.279669          0.765897       0.705031  0.006026  0.446825  ...   
34312  0.559339         -0.123259       0.929511 -1.031826 -1.404309  ...   
4802  -0.504861         -0.188325      -0.322647  0.000015 -0.138743  ...   
25895  0.216731          0.892919       1.291109  0.008211 -0.255329  ...   
...         ...               ...            ...       ...       ...  ...   
18045 -2.080569         -0.340947      -0.470582 -0.848950  0.393794  ...   
5425   0.156785          0.435639      -0.065356  1.113733  0.127664  ...   
12819  1.194951         -0.732967      -0.470025 -0.211535 -1.085148  ...   
33659 -1.254274         -1.063225      -0.470958 -2.849419  0.127664  ...   
19531 -2.339052         -0.356898      -0.470595 -0.900608  0.393896  ...   

       Race_5.0  Race_1.0  Race_4.0  Race_3.0  Race_2.0  Education   Smoking  \
28456       1.0       0.0       0.0       0.0       0.0  -0.012820  0.000000   
8993        0.0       0.0       1.0       0.0       0.0   0.547458  1.000000   
34312       0.0       0.0       0.0       1.0       0.0  -0.659696  0.000000   
4802        1.0       0.0       0.0       0.0       0.0   0.262895  0.073612   
25895       0.0       0.0       0.0       1.0       0.0   1.151035  0.000000   
...         ...       ...       ...       ...       ...        ...       ...   
18045       0.0       0.0       0.0       1.0       0.0  -0.793202  0.000000   
5425        0.0       0.0       1.0       0.0       0.0   0.547458  1.000000   
12819       0.0       0.0       0.0       1.0       0.0   1.151035  1.000000   
33659       0.0       0.0       1.0       0.0       0.0   0.258362  0.000000   
19531       1.0       0.0       0.0       0.0       0.0  -0.821118  0.000000   

       PhysicalActivity  HealthInsurance   Alcohol  
28456          0.660578              0.0 -0.518600  
8993           0.000000              0.0  0.115329  
34312          0.000000              0.0  0.592213  
4802           1.012447              0.0 -0.103347  
25895          0.000000              0.0 -0.886483  
...                 ...              ...       ...  
18045          0.904383              0.0 -0.482716  
5425           1.598141              0.0  0.097790  
12819          1.598141              0.0  0.612947  
33659          1.162475              0.0 -0.154408  
19531          0.791302              0.0 -0.683278  

[13109 rows x 31 columns]
2025-12-02 17:34:22,634:INFO:get_config() successfully completed......................................
2025-12-02 17:34:22,634:INFO:Initializing get_config()
2025-12-02 17:34:22,634:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017153B431F0>, variable=y_test)
2025-12-02 17:34:22,634:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-12-02 17:34:22,634:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-12-02 17:34:22,638:INFO:Variable:  returned as 28456    0.0
8993     0.0
34312    0.0
4802     0.0
25895    0.0
        ... 
18045    0.0
5425     0.0
12819    0.0
33659    0.0
19531    0.0
Name: HeartDisease, Length: 13109, dtype: float32
2025-12-02 17:34:22,638:INFO:get_config() successfully completed......................................
2025-12-02 17:34:58,955:INFO:Initializing get_config()
2025-12-02 17:34:58,955:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017153B431F0>, variable=y_test)
2025-12-02 17:34:58,955:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-12-02 17:34:58,956:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-12-02 17:34:58,960:INFO:Variable:  returned as 28456    0.0
8993     0.0
34312    0.0
4802     0.0
25895    0.0
        ... 
18045    0.0
5425     0.0
12819    0.0
33659    0.0
19531    0.0
Name: HeartDisease, Length: 13109, dtype: float32
2025-12-02 17:34:58,960:INFO:get_config() successfully completed......................................
2025-12-02 17:34:58,963:INFO:Initializing get_config()
2025-12-02 17:34:58,963:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017153B431F0>, variable=X_test_transformed)
2025-12-02 17:34:59,050:INFO:Variable: X_test returned as             Age  IncomeRatio  SystolicBP       BMI  WaistCircumference  \
28456 -0.477273    -0.304717   -0.519256 -0.987220           -0.923253   
8993   0.818182     0.253271    2.156910  0.770675            0.920394   
34312  0.704545     0.055403    0.519256  0.518044            0.662901   
4802  -0.545455     0.253730   -0.331933 -0.229036           -0.436352   
25895  0.704545     1.226781   -0.093200 -0.226100            0.012322   
...         ...          ...         ...       ...                 ...   
18045 -0.568182    -0.083104   -0.568713 -1.176693           -1.338674   
5425   0.590909     0.362732    2.210168  0.139096            0.292112   
12819  0.909091    -0.019787    0.899042  0.454886            0.971892   
33659 -0.522727     1.060572   -0.525683 -0.587220           -0.906087   
19531 -0.590909    -0.344290   -0.510287 -0.945114           -1.215078   

         Height  TotalCholesterol  Triglycerides       LDL       HDL  ...  \
28456 -1.080540         -0.078535      -0.470757 -0.026922  0.418008  ...   
8993  -0.279669          0.765897       0.705031  0.006026  0.446825  ...   
34312  0.559339         -0.123259       0.929511 -1.031826 -1.404309  ...   
4802  -0.504861         -0.188325      -0.322647  0.000015 -0.138743  ...   
25895  0.216731          0.892919       1.291109  0.008211 -0.255329  ...   
...         ...               ...            ...       ...       ...  ...   
18045 -2.080569         -0.340947      -0.470582 -0.848950  0.393794  ...   
5425   0.156785          0.435639      -0.065356  1.113733  0.127664  ...   
12819  1.194951         -0.732967      -0.470025 -0.211535 -1.085148  ...   
33659 -1.254274         -1.063225      -0.470958 -2.849419  0.127664  ...   
19531 -2.339052         -0.356898      -0.470595 -0.900608  0.393896  ...   

       Race_5.0  Race_1.0  Race_4.0  Race_3.0  Race_2.0  Education   Smoking  \
28456       1.0       0.0       0.0       0.0       0.0  -0.012820  0.000000   
8993        0.0       0.0       1.0       0.0       0.0   0.547458  1.000000   
34312       0.0       0.0       0.0       1.0       0.0  -0.659696  0.000000   
4802        1.0       0.0       0.0       0.0       0.0   0.262895  0.073612   
25895       0.0       0.0       0.0       1.0       0.0   1.151035  0.000000   
...         ...       ...       ...       ...       ...        ...       ...   
18045       0.0       0.0       0.0       1.0       0.0  -0.793202  0.000000   
5425        0.0       0.0       1.0       0.0       0.0   0.547458  1.000000   
12819       0.0       0.0       0.0       1.0       0.0   1.151035  1.000000   
33659       0.0       0.0       1.0       0.0       0.0   0.258362  0.000000   
19531       1.0       0.0       0.0       0.0       0.0  -0.821118  0.000000   

       PhysicalActivity  HealthInsurance   Alcohol  
28456          0.660578              0.0 -0.518600  
8993           0.000000              0.0  0.115329  
34312          0.000000              0.0  0.592213  
4802           1.012447              0.0 -0.103347  
25895          0.000000              0.0 -0.886483  
...                 ...              ...       ...  
18045          0.904383              0.0 -0.482716  
5425           1.598141              0.0  0.097790  
12819          1.598141              0.0  0.612947  
33659          1.162475              0.0 -0.154408  
19531          0.791302              0.0 -0.683278  

[13109 rows x 31 columns]
2025-12-02 17:34:59,050:INFO:get_config() successfully completed......................................
2025-12-02 17:34:59,143:INFO:Initializing get_config()
2025-12-02 17:34:59,143:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017153B431F0>, variable=X_train_transformed)
2025-12-02 17:34:59,184:INFO:Variable: X_train returned as             Age  IncomeRatio  SystolicBP       BMI  WaistCircumference  \
15208  0.954545     0.854789    0.359485  0.518044            0.206281   
25325 -0.272727     0.253271   -0.812170 -0.966167           -0.799656   
5132   0.181818    -0.407608   -0.372799  0.054886            0.319578   
17217  0.500000    -0.751898    0.013314 -0.260904            0.278379   
6382   0.568182     0.054503    1.131712  2.675938            1.888566   
...         ...          ...         ...       ...                 ...   
6265  -0.545455    -0.431352   -0.591719  0.191728           -0.377368   
42694 -0.022727    -0.221612   -0.892056 -0.260904           -0.047778   
13399  0.454545     0.388518    0.377985  0.271482            0.183567   
39959  0.954545    -0.193911    0.625770  0.991728            1.160720   
6616   0.613636    -0.447182    0.652399 -0.871430           -0.514698   

         Height  TotalCholesterol  Triglycerides       LDL       HDL  ...  \
15208 -0.487303          0.625876       0.583394  0.005397  0.314564  ...   
25325 -0.300856          0.033588      -0.261476  0.000256  0.303682  ...   
5132   0.766972          0.181594       0.479279  0.948690 -1.340476  ...   
17217  0.745785          0.227516       0.346113  0.002441 -0.274561  ...   
6382   0.237295          0.867515       0.635574  0.002754  0.829819  ...   
...         ...               ...            ...       ...       ...  ...   
6265  -1.737339         -1.393483      -0.471046 -3.840886  0.063832  ...   
42694  0.000000          0.029167      -0.131730  0.000893  0.063832  ...   
13399 -0.147405          0.462357       0.380371  0.003925  0.256949  ...   
39959  0.368655          1.528031       1.934134  0.011744  0.191497  ...   
6616  -0.021187         -0.224877      -0.043571 -1.609476  0.510658  ...   

       Race_5.0  Race_1.0  Race_4.0  Race_3.0  Race_2.0  Education  Smoking  \
15208       1.0       0.0       0.0       0.0       0.0  -0.659696      0.0   
25325       0.0       1.0       0.0       0.0       0.0   0.185278      0.0   
5132        0.0       1.0       0.0       0.0       0.0  -0.659696      1.0   
17217       0.0       0.0       1.0       0.0       0.0  -0.056119      1.0   
6382        0.0       0.0       1.0       0.0       0.0   0.547458      1.0   
...         ...       ...       ...       ...       ...        ...      ...   
6265        0.0       1.0       0.0       0.0       0.0  -0.769055      0.0   
42694       0.0       1.0       0.0       0.0       0.0   0.547458      0.0   
13399       0.0       0.0       1.0       0.0       0.0   0.547458      0.0   
39959       0.0       0.0       0.0       1.0       0.0   0.547458      0.0   
6616        0.0       0.0       0.0       1.0       0.0   0.547458      1.0   

       PhysicalActivity  HealthInsurance   Alcohol  
15208          0.000000              0.0 -0.886483  
25325          0.000000              0.0  0.592213  
5132           0.000000             -1.0  0.312949  
17217          0.000000              0.0  0.592213  
6382           0.000000              0.0  0.597293  
...                 ...              ...       ...  
6265           0.662459              0.0 -0.501621  
42694          0.000000             -1.0  0.592213  
13399          0.000000              0.0 -0.224534  
39959          0.000000              0.0  0.592213  
6616           0.000000              0.0  0.290247  

[30586 rows x 31 columns]
2025-12-02 17:34:59,184:INFO:get_config() successfully completed......................................
2025-12-02 17:37:27,942:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-12-02 17:37:27,942:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-12-02 17:37:27,942:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-12-02 17:37:27,942:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-12-02 17:37:37,931:INFO:PyCaret ClassificationExperiment
2025-12-02 17:37:37,931:INFO:Logging name: clf-default-name
2025-12-02 17:37:37,931:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-12-02 17:37:37,931:INFO:version 3.3.2
2025-12-02 17:37:37,931:INFO:Initializing setup()
2025-12-02 17:37:37,931:INFO:self.USI: 6f1f
2025-12-02 17:37:37,931:INFO:self._variable_keys: {'idx', 'X', 'html_param', '_ml_usecase', 'X_test', 'pipeline', 'y_test', 'X_train', 'exp_id', 'data', 'y', 'n_jobs_param', 'memory', 'log_plots_param', 'logging_param', 'gpu_param', 'fold_groups_param', 'is_multiclass', 'fold_generator', 'seed', 'y_train', 'fix_imbalance', 'fold_shuffle_param', '_available_plots', 'target_param', 'USI', 'gpu_n_jobs_param', 'exp_name_log'}
2025-12-02 17:37:37,931:INFO:Checking environment
2025-12-02 17:37:37,931:INFO:python_version: 3.10.19
2025-12-02 17:37:37,931:INFO:python_build: ('main', 'Oct 21 2025 16:41:31')
2025-12-02 17:37:37,931:INFO:machine: AMD64
2025-12-02 17:37:37,931:INFO:platform: Windows-10-10.0.26100-SP0
2025-12-02 17:37:37,931:INFO:Memory: svmem(total=16282144768, available=3884724224, percent=76.1, used=12397420544, free=3884724224)
2025-12-02 17:37:37,931:INFO:Physical Core: 6
2025-12-02 17:37:37,931:INFO:Logical Core: 12
2025-12-02 17:37:37,931:INFO:Checking libraries
2025-12-02 17:37:37,931:INFO:System:
2025-12-02 17:37:37,931:INFO:    python: 3.10.19 | packaged by Anaconda, Inc. | (main, Oct 21 2025, 16:41:31) [MSC v.1929 64 bit (AMD64)]
2025-12-02 17:37:37,931:INFO:executable: c:\Users\OMAR\miniconda3\envs\xgb_env\python.exe
2025-12-02 17:37:37,931:INFO:   machine: Windows-10-10.0.26100-SP0
2025-12-02 17:37:37,931:INFO:PyCaret required dependencies:
2025-12-02 17:37:37,931:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-02 17:37:38,500:INFO:                 pip: 25.3
2025-12-02 17:37:38,500:INFO:          setuptools: 80.9.0
2025-12-02 17:37:38,500:INFO:             pycaret: 3.3.2
2025-12-02 17:37:38,500:INFO:             IPython: 8.37.0
2025-12-02 17:37:38,500:INFO:          ipywidgets: 8.1.8
2025-12-02 17:37:38,500:INFO:                tqdm: 4.67.1
2025-12-02 17:37:38,500:INFO:               numpy: 1.26.4
2025-12-02 17:37:38,500:INFO:              pandas: 2.1.4
2025-12-02 17:37:38,500:INFO:              jinja2: 3.1.6
2025-12-02 17:37:38,500:INFO:               scipy: 1.11.4
2025-12-02 17:37:38,500:INFO:              joblib: 1.3.2
2025-12-02 17:37:38,500:INFO:             sklearn: 1.4.2
2025-12-02 17:37:38,500:INFO:                pyod: 2.0.5
2025-12-02 17:37:38,500:INFO:            imblearn: 0.14.0
2025-12-02 17:37:38,500:INFO:   category_encoders: 2.7.0
2025-12-02 17:37:38,500:INFO:            lightgbm: 4.6.0
2025-12-02 17:37:38,500:INFO:               numba: 0.62.1
2025-12-02 17:37:38,500:INFO:            requests: 2.32.5
2025-12-02 17:37:38,500:INFO:          matplotlib: 3.7.5
2025-12-02 17:37:38,500:INFO:          scikitplot: 0.3.7
2025-12-02 17:37:38,500:INFO:         yellowbrick: 1.5
2025-12-02 17:37:38,500:INFO:              plotly: 5.24.1
2025-12-02 17:37:38,500:INFO:    plotly-resampler: Not installed
2025-12-02 17:37:38,500:INFO:             kaleido: 1.2.0
2025-12-02 17:37:38,500:INFO:           schemdraw: 0.15
2025-12-02 17:37:38,500:INFO:         statsmodels: 0.14.5
2025-12-02 17:37:38,500:INFO:              sktime: 0.26.0
2025-12-02 17:37:38,500:INFO:               tbats: 1.1.3
2025-12-02 17:37:38,500:INFO:            pmdarima: 2.0.4
2025-12-02 17:37:38,500:INFO:              psutil: 7.1.3
2025-12-02 17:37:38,500:INFO:          markupsafe: 3.0.3
2025-12-02 17:37:38,500:INFO:             pickle5: Not installed
2025-12-02 17:37:38,500:INFO:         cloudpickle: 3.1.2
2025-12-02 17:37:38,500:INFO:         deprecation: 2.1.0
2025-12-02 17:37:38,500:INFO:              xxhash: 3.6.0
2025-12-02 17:37:38,500:INFO:           wurlitzer: Not installed
2025-12-02 17:37:38,500:INFO:PyCaret optional dependencies:
2025-12-02 17:37:41,314:INFO:                shap: 0.49.1
2025-12-02 17:37:41,314:INFO:           interpret: 0.7.3
2025-12-02 17:37:41,314:INFO:                umap: 0.5.7
2025-12-02 17:37:41,314:INFO:     ydata_profiling: 4.18.0
2025-12-02 17:37:41,314:INFO:  explainerdashboard: 0.5.1
2025-12-02 17:37:41,314:INFO:             autoviz: Not installed
2025-12-02 17:37:41,314:INFO:           fairlearn: 0.7.0
2025-12-02 17:37:41,314:INFO:          deepchecks: Not installed
2025-12-02 17:37:41,314:INFO:             xgboost: 2.1.3
2025-12-02 17:37:41,314:INFO:            catboost: 1.2.8
2025-12-02 17:37:41,314:INFO:              kmodes: 0.12.2
2025-12-02 17:37:41,314:INFO:             mlxtend: 0.23.4
2025-12-02 17:37:41,314:INFO:       statsforecast: 1.5.0
2025-12-02 17:37:41,314:INFO:        tune_sklearn: Not installed
2025-12-02 17:37:41,314:INFO:                 ray: Not installed
2025-12-02 17:37:41,314:INFO:            hyperopt: 0.2.7
2025-12-02 17:37:41,314:INFO:              optuna: 4.6.0
2025-12-02 17:37:41,314:INFO:               skopt: 0.10.2
2025-12-02 17:37:41,314:INFO:              mlflow: 3.6.0
2025-12-02 17:37:41,314:INFO:              gradio: 6.0.1
2025-12-02 17:37:41,314:INFO:             fastapi: 0.123.0
2025-12-02 17:37:41,314:INFO:             uvicorn: 0.38.0
2025-12-02 17:37:41,314:INFO:              m2cgen: 0.10.0
2025-12-02 17:37:41,314:INFO:           evidently: 0.4.40
2025-12-02 17:37:41,314:INFO:               fugue: 0.8.7
2025-12-02 17:37:41,314:INFO:           streamlit: 1.51.0
2025-12-02 17:37:41,314:INFO:             prophet: Not installed
2025-12-02 17:37:41,314:INFO:None
2025-12-02 17:37:41,314:INFO:Set up data.
2025-12-02 17:37:41,343:INFO:Set up folding strategy.
2025-12-02 17:37:41,343:INFO:Set up train/test split.
2025-12-02 17:37:41,364:INFO:Set up index.
2025-12-02 17:37:41,370:INFO:Assigning column types.
2025-12-02 17:37:41,388:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-12-02 17:37:41,414:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-12-02 17:37:41,417:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-02 17:37:41,440:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-02 17:37:41,442:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-02 17:37:41,491:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-12-02 17:37:41,492:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-02 17:37:41,507:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-02 17:37:41,509:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-02 17:37:41,509:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-12-02 17:37:41,533:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-02 17:37:41,550:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-02 17:37:41,552:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-02 17:37:41,576:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-02 17:37:41,594:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-02 17:37:41,596:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-02 17:37:41,597:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-12-02 17:37:41,636:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-02 17:37:41,636:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-02 17:37:41,681:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-02 17:37:41,681:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-02 17:37:41,681:INFO:Preparing preprocessing pipeline...
2025-12-02 17:37:41,687:INFO:Set up simple imputation.
2025-12-02 17:37:41,700:INFO:Set up encoding of ordinal features.
2025-12-02 17:37:41,706:INFO:Set up encoding of categorical features.
2025-12-02 17:37:41,706:INFO:Set up feature normalization.
2025-12-02 17:37:41,871:INFO:Finished creating preprocessing pipeline.
2025-12-02 17:37:41,887:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\OMAR\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'IncomeRatio', 'SystolicBP',
                                             'BMI', 'WaistCircumference',
                                             'Height', 'TotalCholesterol',
                                             'Triglycerides', 'LDL', 'HDL',
                                             'HbA1c', 'Glucose', 'Creatinine',
                                             'UricAcid', 'ALT_Enzyme',
                                             'Albumin', 'Potassium', 'Sodium',
                                             'G...
                                    transformer=TargetEncoder(cols=[],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=RobustScaler(copy=True,
                                                             quantile_range=(25.0,
                                                                             75.0),
                                                             unit_variance=False,
                                                             with_centering=True,
                                                             with_scaling=True)))],
         verbose=False)
2025-12-02 17:37:41,887:INFO:Creating final display dataframe.
2025-12-02 17:37:42,106:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target      HeartDisease
2                   Target type            Binary
3           Original data shape       (43695, 28)
4        Transformed data shape       (43695, 32)
5   Transformed train set shape       (30586, 32)
6    Transformed test set shape       (13109, 32)
7              Numeric features                20
8          Categorical features                 7
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15                    Normalize              True
16             Normalize method            robust
17               Fold Generator   StratifiedKFold
18                  Fold Number                10
19                     CPU Jobs                 1
20                      Use GPU             False
21               Log Experiment             False
22              Experiment Name  clf-default-name
23                          USI              6f1f
2025-12-02 17:37:42,154:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-02 17:37:42,156:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-02 17:37:42,201:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-02 17:37:42,204:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-02 17:37:42,206:INFO:setup() successfully completed in 4.28s...............
2025-12-02 17:37:47,276:INFO:Initializing get_config()
2025-12-02 17:37:47,277:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F0B344EB30>, variable=y_train)
2025-12-02 17:37:47,277:INFO:Variable: 'y_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_train_transformed' instead.
2025-12-02 17:37:47,277:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_train_transformed' instead.

2025-12-02 17:37:47,288:INFO:Variable:  returned as 15208    0.0
25325    0.0
5132     0.0
17217    0.0
6382     0.0
        ... 
6265     0.0
42694    0.0
13399    0.0
39959    0.0
6616     0.0
Name: HeartDisease, Length: 30586, dtype: float32
2025-12-02 17:37:47,288:INFO:get_config() successfully completed......................................
2025-12-02 17:37:47,288:INFO:Initializing create_model()
2025-12-02 17:37:47,289:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F0B344EB30>, estimator=xgboost, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={'scale_pos_weight': 38.162612035851474})
2025-12-02 17:37:47,289:INFO:Checking exceptions
2025-12-02 17:37:47,303:INFO:Importing libraries
2025-12-02 17:37:47,303:INFO:Copying training dataset
2025-12-02 17:37:47,332:INFO:Defining folds
2025-12-02 17:37:47,332:INFO:Declaring metric variables
2025-12-02 17:37:47,335:INFO:Importing untrained model
2025-12-02 17:37:47,338:INFO:Extreme Gradient Boosting Imported successfully
2025-12-02 17:37:47,343:INFO:Starting cross validation
2025-12-02 17:37:47,344:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-12-02 17:37:53,644:INFO:Calculating mean and std
2025-12-02 17:37:53,644:INFO:Creating metrics dataframe
2025-12-02 17:37:53,646:INFO:Finalizing model
2025-12-02 17:37:53,725:INFO:Warning: No categorical columns found. Calling 'transform' will only return input data.
2025-12-02 17:37:54,231:INFO:Uploading results into container
2025-12-02 17:37:54,232:INFO:Uploading model into container now
2025-12-02 17:37:54,242:INFO:_master_model_container: 1
2025-12-02 17:37:54,242:INFO:_display_container: 2
2025-12-02 17:37:54,243:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2025-12-02 17:37:54,243:INFO:create_model() successfully completed......................................
2025-12-02 17:37:57,789:INFO:Initializing create_model()
2025-12-02 17:37:57,789:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F0B344EB30>, estimator=lr, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-02 17:37:57,789:INFO:Checking exceptions
2025-12-02 17:37:57,800:INFO:Importing libraries
2025-12-02 17:37:57,800:INFO:Copying training dataset
2025-12-02 17:37:57,828:INFO:Defining folds
2025-12-02 17:37:57,828:INFO:Declaring metric variables
2025-12-02 17:37:57,831:INFO:Importing untrained model
2025-12-02 17:37:57,833:INFO:Logistic Regression Imported successfully
2025-12-02 17:37:57,838:INFO:Starting cross validation
2025-12-02 17:37:57,839:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-12-02 17:37:58,800:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-12-02 17:37:59,373:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-12-02 17:37:59,756:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-12-02 17:37:59,762:INFO:Calculating mean and std
2025-12-02 17:37:59,762:INFO:Creating metrics dataframe
2025-12-02 17:37:59,767:INFO:Finalizing model
2025-12-02 17:37:59,862:INFO:Warning: No categorical columns found. Calling 'transform' will only return input data.
2025-12-02 17:37:59,954:INFO:Uploading results into container
2025-12-02 17:37:59,955:INFO:Uploading model into container now
2025-12-02 17:37:59,963:INFO:_master_model_container: 2
2025-12-02 17:37:59,963:INFO:_display_container: 3
2025-12-02 17:37:59,963:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-12-02 17:37:59,963:INFO:create_model() successfully completed......................................
2025-12-02 17:38:00,123:INFO:Initializing create_model()
2025-12-02 17:38:00,123:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F0B344EB30>, estimator=rf, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-02 17:38:00,123:INFO:Checking exceptions
2025-12-02 17:38:00,135:INFO:Importing libraries
2025-12-02 17:38:00,135:INFO:Copying training dataset
2025-12-02 17:38:00,164:INFO:Defining folds
2025-12-02 17:38:00,164:INFO:Declaring metric variables
2025-12-02 17:38:00,167:INFO:Importing untrained model
2025-12-02 17:38:00,174:INFO:Random Forest Classifier Imported successfully
2025-12-02 17:38:00,182:INFO:Starting cross validation
2025-12-02 17:38:00,183:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-12-02 17:38:40,281:INFO:Calculating mean and std
2025-12-02 17:38:40,281:INFO:Creating metrics dataframe
2025-12-02 17:38:40,286:INFO:Finalizing model
2025-12-02 17:38:40,363:INFO:Warning: No categorical columns found. Calling 'transform' will only return input data.
2025-12-02 17:38:44,782:INFO:Uploading results into container
2025-12-02 17:38:44,783:INFO:Uploading model into container now
2025-12-02 17:38:44,786:INFO:_master_model_container: 3
2025-12-02 17:38:44,786:INFO:_display_container: 4
2025-12-02 17:38:44,786:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2025-12-02 17:38:44,786:INFO:create_model() successfully completed......................................
2025-12-02 17:38:49,742:INFO:Initializing get_config()
2025-12-02 17:38:49,742:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F0B344EB30>, variable=X_train_transformed)
2025-12-02 17:38:49,780:INFO:Variable: X_train returned as             Age  IncomeRatio  SystolicBP       BMI  WaistCircumference  \
15208  0.954545     0.854789    0.359485  0.518044            0.206281   
25325 -0.272727     0.253271   -0.812170 -0.966167           -0.799656   
5132   0.181818    -0.407608   -0.372799  0.054886            0.319578   
17217  0.500000    -0.751898    0.013314 -0.260904            0.278379   
6382   0.568182     0.054503    1.131712  2.675938            1.888566   
...         ...          ...         ...       ...                 ...   
6265  -0.545455    -0.431352   -0.591719  0.191728           -0.377368   
42694 -0.022727    -0.221612   -0.892056 -0.260904           -0.047778   
13399  0.454545     0.388518    0.377985  0.271482            0.183567   
39959  0.954545    -0.193911    0.625770  0.991728            1.160720   
6616   0.613636    -0.447182    0.652399 -0.871430           -0.514698   

         Height  TotalCholesterol  Triglycerides       LDL       HDL  ...  \
15208 -0.487303          0.625876       0.583394  0.005397  0.314564  ...   
25325 -0.300856          0.033588      -0.261476  0.000256  0.303682  ...   
5132   0.766972          0.181594       0.479279  0.948690 -1.340476  ...   
17217  0.745785          0.227516       0.346113  0.002441 -0.274561  ...   
6382   0.237295          0.867515       0.635574  0.002754  0.829819  ...   
...         ...               ...            ...       ...       ...  ...   
6265  -1.737339         -1.393483      -0.471046 -3.840886  0.063832  ...   
42694  0.000000          0.029167      -0.131730  0.000893  0.063832  ...   
13399 -0.147405          0.462357       0.380371  0.003925  0.256949  ...   
39959  0.368655          1.528031       1.934134  0.011744  0.191497  ...   
6616  -0.021187         -0.224877      -0.043571 -1.609476  0.510658  ...   

       Race_5.0  Race_1.0  Race_4.0  Race_3.0  Race_2.0  Education  Smoking  \
15208       1.0       0.0       0.0       0.0       0.0  -0.659696      0.0   
25325       0.0       1.0       0.0       0.0       0.0   0.185278      0.0   
5132        0.0       1.0       0.0       0.0       0.0  -0.659696      1.0   
17217       0.0       0.0       1.0       0.0       0.0  -0.056119      1.0   
6382        0.0       0.0       1.0       0.0       0.0   0.547458      1.0   
...         ...       ...       ...       ...       ...        ...      ...   
6265        0.0       1.0       0.0       0.0       0.0  -0.769055      0.0   
42694       0.0       1.0       0.0       0.0       0.0   0.547458      0.0   
13399       0.0       0.0       1.0       0.0       0.0   0.547458      0.0   
39959       0.0       0.0       0.0       1.0       0.0   0.547458      0.0   
6616        0.0       0.0       0.0       1.0       0.0   0.547458      1.0   

       PhysicalActivity  HealthInsurance   Alcohol  
15208          0.000000              0.0 -0.886483  
25325          0.000000              0.0  0.592213  
5132           0.000000             -1.0  0.312949  
17217          0.000000              0.0  0.592213  
6382           0.000000              0.0  0.597293  
...                 ...              ...       ...  
6265           0.662459              0.0 -0.501621  
42694          0.000000             -1.0  0.592213  
13399          0.000000              0.0 -0.224534  
39959          0.000000              0.0  0.592213  
6616           0.000000              0.0  0.290247  

[30586 rows x 31 columns]
2025-12-02 17:38:49,780:INFO:get_config() successfully completed......................................
2025-12-02 17:38:49,780:INFO:Initializing get_config()
2025-12-02 17:38:49,780:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F0B344EB30>, variable=y_train)
2025-12-02 17:38:49,780:INFO:Variable: 'y_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_train_transformed' instead.
2025-12-02 17:38:49,780:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_train_transformed' instead.

2025-12-02 17:38:49,787:INFO:Variable:  returned as 15208    0.0
25325    0.0
5132     0.0
17217    0.0
6382     0.0
        ... 
6265     0.0
42694    0.0
13399    0.0
39959    0.0
6616     0.0
Name: HeartDisease, Length: 30586, dtype: float32
2025-12-02 17:38:49,787:INFO:get_config() successfully completed......................................
2025-12-02 17:38:49,787:INFO:Initializing get_config()
2025-12-02 17:38:49,792:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F0B344EB30>, variable=X_test_transformed)
2025-12-02 17:38:49,868:INFO:Variable: X_test returned as             Age  IncomeRatio  SystolicBP       BMI  WaistCircumference  \
28456 -0.477273    -0.304717   -0.519256 -0.987220           -0.923253   
8993   0.818182     0.253271    2.156910  0.770675            0.920394   
34312  0.704545     0.055403    0.519256  0.518044            0.662901   
4802  -0.545455     0.253730   -0.331933 -0.229036           -0.436352   
25895  0.704545     1.226781   -0.093200 -0.226100            0.012322   
...         ...          ...         ...       ...                 ...   
18045 -0.568182    -0.083104   -0.568713 -1.176693           -1.338674   
5425   0.590909     0.362732    2.210168  0.139096            0.292112   
12819  0.909091    -0.019787    0.899042  0.454886            0.971892   
33659 -0.522727     1.060572   -0.525683 -0.587220           -0.906087   
19531 -0.590909    -0.344290   -0.510287 -0.945114           -1.215078   

         Height  TotalCholesterol  Triglycerides       LDL       HDL  ...  \
28456 -1.080540         -0.078535      -0.470757 -0.026922  0.418008  ...   
8993  -0.279669          0.765897       0.705031  0.006026  0.446825  ...   
34312  0.559339         -0.123259       0.929511 -1.031826 -1.404309  ...   
4802  -0.504861         -0.188325      -0.322647  0.000015 -0.138743  ...   
25895  0.216731          0.892919       1.291109  0.008211 -0.255329  ...   
...         ...               ...            ...       ...       ...  ...   
18045 -2.080569         -0.340947      -0.470582 -0.848950  0.393794  ...   
5425   0.156785          0.435639      -0.065356  1.113733  0.127664  ...   
12819  1.194951         -0.732967      -0.470025 -0.211535 -1.085148  ...   
33659 -1.254274         -1.063225      -0.470958 -2.849419  0.127664  ...   
19531 -2.339052         -0.356898      -0.470595 -0.900608  0.393896  ...   

       Race_5.0  Race_1.0  Race_4.0  Race_3.0  Race_2.0  Education   Smoking  \
28456       1.0       0.0       0.0       0.0       0.0  -0.012820  0.000000   
8993        0.0       0.0       1.0       0.0       0.0   0.547458  1.000000   
34312       0.0       0.0       0.0       1.0       0.0  -0.659696  0.000000   
4802        1.0       0.0       0.0       0.0       0.0   0.262895  0.073612   
25895       0.0       0.0       0.0       1.0       0.0   1.151035  0.000000   
...         ...       ...       ...       ...       ...        ...       ...   
18045       0.0       0.0       0.0       1.0       0.0  -0.793202  0.000000   
5425        0.0       0.0       1.0       0.0       0.0   0.547458  1.000000   
12819       0.0       0.0       0.0       1.0       0.0   1.151035  1.000000   
33659       0.0       0.0       1.0       0.0       0.0   0.258362  0.000000   
19531       1.0       0.0       0.0       0.0       0.0  -0.821118  0.000000   

       PhysicalActivity  HealthInsurance   Alcohol  
28456          0.660578              0.0 -0.518600  
8993           0.000000              0.0  0.115329  
34312          0.000000              0.0  0.592213  
4802           1.012447              0.0 -0.103347  
25895          0.000000              0.0 -0.886483  
...                 ...              ...       ...  
18045          0.904383              0.0 -0.482716  
5425           1.598141              0.0  0.097790  
12819          1.598141              0.0  0.612947  
33659          1.162475              0.0 -0.154408  
19531          0.791302              0.0 -0.683278  

[13109 rows x 31 columns]
2025-12-02 17:38:49,868:INFO:get_config() successfully completed......................................
2025-12-02 17:38:49,868:INFO:Initializing get_config()
2025-12-02 17:38:49,868:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F0B344EB30>, variable=y_test)
2025-12-02 17:38:49,868:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-12-02 17:38:49,868:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-12-02 17:38:49,873:INFO:Variable:  returned as 28456    0.0
8993     0.0
34312    0.0
4802     0.0
25895    0.0
        ... 
18045    0.0
5425     0.0
12819    0.0
33659    0.0
19531    0.0
Name: HeartDisease, Length: 13109, dtype: float32
2025-12-02 17:38:49,873:INFO:get_config() successfully completed......................................
2025-12-02 17:38:50,036:INFO:Initializing get_config()
2025-12-02 17:38:50,037:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F0B344EB30>, variable=X_train_transformed)
2025-12-02 17:38:50,086:INFO:Variable: X_train returned as             Age  IncomeRatio  SystolicBP       BMI  WaistCircumference  \
15208  0.954545     0.854789    0.359485  0.518044            0.206281   
25325 -0.272727     0.253271   -0.812170 -0.966167           -0.799656   
5132   0.181818    -0.407608   -0.372799  0.054886            0.319578   
17217  0.500000    -0.751898    0.013314 -0.260904            0.278379   
6382   0.568182     0.054503    1.131712  2.675938            1.888566   
...         ...          ...         ...       ...                 ...   
6265  -0.545455    -0.431352   -0.591719  0.191728           -0.377368   
42694 -0.022727    -0.221612   -0.892056 -0.260904           -0.047778   
13399  0.454545     0.388518    0.377985  0.271482            0.183567   
39959  0.954545    -0.193911    0.625770  0.991728            1.160720   
6616   0.613636    -0.447182    0.652399 -0.871430           -0.514698   

         Height  TotalCholesterol  Triglycerides       LDL       HDL  ...  \
15208 -0.487303          0.625876       0.583394  0.005397  0.314564  ...   
25325 -0.300856          0.033588      -0.261476  0.000256  0.303682  ...   
5132   0.766972          0.181594       0.479279  0.948690 -1.340476  ...   
17217  0.745785          0.227516       0.346113  0.002441 -0.274561  ...   
6382   0.237295          0.867515       0.635574  0.002754  0.829819  ...   
...         ...               ...            ...       ...       ...  ...   
6265  -1.737339         -1.393483      -0.471046 -3.840886  0.063832  ...   
42694  0.000000          0.029167      -0.131730  0.000893  0.063832  ...   
13399 -0.147405          0.462357       0.380371  0.003925  0.256949  ...   
39959  0.368655          1.528031       1.934134  0.011744  0.191497  ...   
6616  -0.021187         -0.224877      -0.043571 -1.609476  0.510658  ...   

       Race_5.0  Race_1.0  Race_4.0  Race_3.0  Race_2.0  Education  Smoking  \
15208       1.0       0.0       0.0       0.0       0.0  -0.659696      0.0   
25325       0.0       1.0       0.0       0.0       0.0   0.185278      0.0   
5132        0.0       1.0       0.0       0.0       0.0  -0.659696      1.0   
17217       0.0       0.0       1.0       0.0       0.0  -0.056119      1.0   
6382        0.0       0.0       1.0       0.0       0.0   0.547458      1.0   
...         ...       ...       ...       ...       ...        ...      ...   
6265        0.0       1.0       0.0       0.0       0.0  -0.769055      0.0   
42694       0.0       1.0       0.0       0.0       0.0   0.547458      0.0   
13399       0.0       0.0       1.0       0.0       0.0   0.547458      0.0   
39959       0.0       0.0       0.0       1.0       0.0   0.547458      0.0   
6616        0.0       0.0       0.0       1.0       0.0   0.547458      1.0   

       PhysicalActivity  HealthInsurance   Alcohol  
15208          0.000000              0.0 -0.886483  
25325          0.000000              0.0  0.592213  
5132           0.000000             -1.0  0.312949  
17217          0.000000              0.0  0.592213  
6382           0.000000              0.0  0.597293  
...                 ...              ...       ...  
6265           0.662459              0.0 -0.501621  
42694          0.000000             -1.0  0.592213  
13399          0.000000              0.0 -0.224534  
39959          0.000000              0.0  0.592213  
6616           0.000000              0.0  0.290247  

[30586 rows x 31 columns]
2025-12-02 17:38:50,086:INFO:get_config() successfully completed......................................
2025-12-02 17:38:50,086:INFO:Initializing get_config()
2025-12-02 17:38:50,086:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F0B344EB30>, variable=y_train)
2025-12-02 17:38:50,086:INFO:Variable: 'y_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_train_transformed' instead.
2025-12-02 17:38:50,086:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_train_transformed' instead.

2025-12-02 17:38:50,095:INFO:Variable:  returned as 15208    0.0
25325    0.0
5132     0.0
17217    0.0
6382     0.0
        ... 
6265     0.0
42694    0.0
13399    0.0
39959    0.0
6616     0.0
Name: HeartDisease, Length: 30586, dtype: float32
2025-12-02 17:38:50,096:INFO:get_config() successfully completed......................................
2025-12-02 17:38:50,098:INFO:Initializing get_config()
2025-12-02 17:38:50,098:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F0B344EB30>, variable=X_test_transformed)
2025-12-02 17:38:50,186:INFO:Variable: X_test returned as             Age  IncomeRatio  SystolicBP       BMI  WaistCircumference  \
28456 -0.477273    -0.304717   -0.519256 -0.987220           -0.923253   
8993   0.818182     0.253271    2.156910  0.770675            0.920394   
34312  0.704545     0.055403    0.519256  0.518044            0.662901   
4802  -0.545455     0.253730   -0.331933 -0.229036           -0.436352   
25895  0.704545     1.226781   -0.093200 -0.226100            0.012322   
...         ...          ...         ...       ...                 ...   
18045 -0.568182    -0.083104   -0.568713 -1.176693           -1.338674   
5425   0.590909     0.362732    2.210168  0.139096            0.292112   
12819  0.909091    -0.019787    0.899042  0.454886            0.971892   
33659 -0.522727     1.060572   -0.525683 -0.587220           -0.906087   
19531 -0.590909    -0.344290   -0.510287 -0.945114           -1.215078   

         Height  TotalCholesterol  Triglycerides       LDL       HDL  ...  \
28456 -1.080540         -0.078535      -0.470757 -0.026922  0.418008  ...   
8993  -0.279669          0.765897       0.705031  0.006026  0.446825  ...   
34312  0.559339         -0.123259       0.929511 -1.031826 -1.404309  ...   
4802  -0.504861         -0.188325      -0.322647  0.000015 -0.138743  ...   
25895  0.216731          0.892919       1.291109  0.008211 -0.255329  ...   
...         ...               ...            ...       ...       ...  ...   
18045 -2.080569         -0.340947      -0.470582 -0.848950  0.393794  ...   
5425   0.156785          0.435639      -0.065356  1.113733  0.127664  ...   
12819  1.194951         -0.732967      -0.470025 -0.211535 -1.085148  ...   
33659 -1.254274         -1.063225      -0.470958 -2.849419  0.127664  ...   
19531 -2.339052         -0.356898      -0.470595 -0.900608  0.393896  ...   

       Race_5.0  Race_1.0  Race_4.0  Race_3.0  Race_2.0  Education   Smoking  \
28456       1.0       0.0       0.0       0.0       0.0  -0.012820  0.000000   
8993        0.0       0.0       1.0       0.0       0.0   0.547458  1.000000   
34312       0.0       0.0       0.0       1.0       0.0  -0.659696  0.000000   
4802        1.0       0.0       0.0       0.0       0.0   0.262895  0.073612   
25895       0.0       0.0       0.0       1.0       0.0   1.151035  0.000000   
...         ...       ...       ...       ...       ...        ...       ...   
18045       0.0       0.0       0.0       1.0       0.0  -0.793202  0.000000   
5425        0.0       0.0       1.0       0.0       0.0   0.547458  1.000000   
12819       0.0       0.0       0.0       1.0       0.0   1.151035  1.000000   
33659       0.0       0.0       1.0       0.0       0.0   0.258362  0.000000   
19531       1.0       0.0       0.0       0.0       0.0  -0.821118  0.000000   

       PhysicalActivity  HealthInsurance   Alcohol  
28456          0.660578              0.0 -0.518600  
8993           0.000000              0.0  0.115329  
34312          0.000000              0.0  0.592213  
4802           1.012447              0.0 -0.103347  
25895          0.000000              0.0 -0.886483  
...                 ...              ...       ...  
18045          0.904383              0.0 -0.482716  
5425           1.598141              0.0  0.097790  
12819          1.598141              0.0  0.612947  
33659          1.162475              0.0 -0.154408  
19531          0.791302              0.0 -0.683278  

[13109 rows x 31 columns]
2025-12-02 17:38:50,186:INFO:get_config() successfully completed......................................
2025-12-02 17:38:50,186:INFO:Initializing get_config()
2025-12-02 17:38:50,186:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F0B344EB30>, variable=y_test)
2025-12-02 17:38:50,186:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-12-02 17:38:50,186:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-12-02 17:38:50,192:INFO:Variable:  returned as 28456    0.0
8993     0.0
34312    0.0
4802     0.0
25895    0.0
        ... 
18045    0.0
5425     0.0
12819    0.0
33659    0.0
19531    0.0
Name: HeartDisease, Length: 13109, dtype: float32
2025-12-02 17:38:50,192:INFO:get_config() successfully completed......................................
2025-12-02 17:38:50,326:INFO:Initializing get_config()
2025-12-02 17:38:50,326:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F0B344EB30>, variable=X_test_transformed)
2025-12-02 17:38:50,403:INFO:Variable: X_test returned as             Age  IncomeRatio  SystolicBP       BMI  WaistCircumference  \
28456 -0.477273    -0.304717   -0.519256 -0.987220           -0.923253   
8993   0.818182     0.253271    2.156910  0.770675            0.920394   
34312  0.704545     0.055403    0.519256  0.518044            0.662901   
4802  -0.545455     0.253730   -0.331933 -0.229036           -0.436352   
25895  0.704545     1.226781   -0.093200 -0.226100            0.012322   
...         ...          ...         ...       ...                 ...   
18045 -0.568182    -0.083104   -0.568713 -1.176693           -1.338674   
5425   0.590909     0.362732    2.210168  0.139096            0.292112   
12819  0.909091    -0.019787    0.899042  0.454886            0.971892   
33659 -0.522727     1.060572   -0.525683 -0.587220           -0.906087   
19531 -0.590909    -0.344290   -0.510287 -0.945114           -1.215078   

         Height  TotalCholesterol  Triglycerides       LDL       HDL  ...  \
28456 -1.080540         -0.078535      -0.470757 -0.026922  0.418008  ...   
8993  -0.279669          0.765897       0.705031  0.006026  0.446825  ...   
34312  0.559339         -0.123259       0.929511 -1.031826 -1.404309  ...   
4802  -0.504861         -0.188325      -0.322647  0.000015 -0.138743  ...   
25895  0.216731          0.892919       1.291109  0.008211 -0.255329  ...   
...         ...               ...            ...       ...       ...  ...   
18045 -2.080569         -0.340947      -0.470582 -0.848950  0.393794  ...   
5425   0.156785          0.435639      -0.065356  1.113733  0.127664  ...   
12819  1.194951         -0.732967      -0.470025 -0.211535 -1.085148  ...   
33659 -1.254274         -1.063225      -0.470958 -2.849419  0.127664  ...   
19531 -2.339052         -0.356898      -0.470595 -0.900608  0.393896  ...   

       Race_5.0  Race_1.0  Race_4.0  Race_3.0  Race_2.0  Education   Smoking  \
28456       1.0       0.0       0.0       0.0       0.0  -0.012820  0.000000   
8993        0.0       0.0       1.0       0.0       0.0   0.547458  1.000000   
34312       0.0       0.0       0.0       1.0       0.0  -0.659696  0.000000   
4802        1.0       0.0       0.0       0.0       0.0   0.262895  0.073612   
25895       0.0       0.0       0.0       1.0       0.0   1.151035  0.000000   
...         ...       ...       ...       ...       ...        ...       ...   
18045       0.0       0.0       0.0       1.0       0.0  -0.793202  0.000000   
5425        0.0       0.0       1.0       0.0       0.0   0.547458  1.000000   
12819       0.0       0.0       0.0       1.0       0.0   1.151035  1.000000   
33659       0.0       0.0       1.0       0.0       0.0   0.258362  0.000000   
19531       1.0       0.0       0.0       0.0       0.0  -0.821118  0.000000   

       PhysicalActivity  HealthInsurance   Alcohol  
28456          0.660578              0.0 -0.518600  
8993           0.000000              0.0  0.115329  
34312          0.000000              0.0  0.592213  
4802           1.012447              0.0 -0.103347  
25895          0.000000              0.0 -0.886483  
...                 ...              ...       ...  
18045          0.904383              0.0 -0.482716  
5425           1.598141              0.0  0.097790  
12819          1.598141              0.0  0.612947  
33659          1.162475              0.0 -0.154408  
19531          0.791302              0.0 -0.683278  

[13109 rows x 31 columns]
2025-12-02 17:38:50,403:INFO:get_config() successfully completed......................................
2025-12-02 17:38:50,431:INFO:Initializing get_config()
2025-12-02 17:38:50,431:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F0B344EB30>, variable=y_test)
2025-12-02 17:38:50,431:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-12-02 17:38:50,432:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-12-02 17:38:50,437:INFO:Variable:  returned as 28456    0.0
8993     0.0
34312    0.0
4802     0.0
25895    0.0
        ... 
18045    0.0
5425     0.0
12819    0.0
33659    0.0
19531    0.0
Name: HeartDisease, Length: 13109, dtype: float32
2025-12-02 17:38:50,437:INFO:get_config() successfully completed......................................
2025-12-02 17:38:50,440:INFO:Initializing get_config()
2025-12-02 17:38:50,440:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F0B344EB30>, variable=y_test)
2025-12-02 17:38:50,440:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-12-02 17:38:50,440:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-12-02 17:38:50,445:INFO:Variable:  returned as 28456    0.0
8993     0.0
34312    0.0
4802     0.0
25895    0.0
        ... 
18045    0.0
5425     0.0
12819    0.0
33659    0.0
19531    0.0
Name: HeartDisease, Length: 13109, dtype: float32
2025-12-02 17:38:50,445:INFO:get_config() successfully completed......................................
2025-12-02 17:38:50,448:INFO:Initializing get_config()
2025-12-02 17:38:50,448:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F0B344EB30>, variable=X_test_transformed)
2025-12-02 17:38:50,523:INFO:Variable: X_test returned as             Age  IncomeRatio  SystolicBP       BMI  WaistCircumference  \
28456 -0.477273    -0.304717   -0.519256 -0.987220           -0.923253   
8993   0.818182     0.253271    2.156910  0.770675            0.920394   
34312  0.704545     0.055403    0.519256  0.518044            0.662901   
4802  -0.545455     0.253730   -0.331933 -0.229036           -0.436352   
25895  0.704545     1.226781   -0.093200 -0.226100            0.012322   
...         ...          ...         ...       ...                 ...   
18045 -0.568182    -0.083104   -0.568713 -1.176693           -1.338674   
5425   0.590909     0.362732    2.210168  0.139096            0.292112   
12819  0.909091    -0.019787    0.899042  0.454886            0.971892   
33659 -0.522727     1.060572   -0.525683 -0.587220           -0.906087   
19531 -0.590909    -0.344290   -0.510287 -0.945114           -1.215078   

         Height  TotalCholesterol  Triglycerides       LDL       HDL  ...  \
28456 -1.080540         -0.078535      -0.470757 -0.026922  0.418008  ...   
8993  -0.279669          0.765897       0.705031  0.006026  0.446825  ...   
34312  0.559339         -0.123259       0.929511 -1.031826 -1.404309  ...   
4802  -0.504861         -0.188325      -0.322647  0.000015 -0.138743  ...   
25895  0.216731          0.892919       1.291109  0.008211 -0.255329  ...   
...         ...               ...            ...       ...       ...  ...   
18045 -2.080569         -0.340947      -0.470582 -0.848950  0.393794  ...   
5425   0.156785          0.435639      -0.065356  1.113733  0.127664  ...   
12819  1.194951         -0.732967      -0.470025 -0.211535 -1.085148  ...   
33659 -1.254274         -1.063225      -0.470958 -2.849419  0.127664  ...   
19531 -2.339052         -0.356898      -0.470595 -0.900608  0.393896  ...   

       Race_5.0  Race_1.0  Race_4.0  Race_3.0  Race_2.0  Education   Smoking  \
28456       1.0       0.0       0.0       0.0       0.0  -0.012820  0.000000   
8993        0.0       0.0       1.0       0.0       0.0   0.547458  1.000000   
34312       0.0       0.0       0.0       1.0       0.0  -0.659696  0.000000   
4802        1.0       0.0       0.0       0.0       0.0   0.262895  0.073612   
25895       0.0       0.0       0.0       1.0       0.0   1.151035  0.000000   
...         ...       ...       ...       ...       ...        ...       ...   
18045       0.0       0.0       0.0       1.0       0.0  -0.793202  0.000000   
5425        0.0       0.0       1.0       0.0       0.0   0.547458  1.000000   
12819       0.0       0.0       0.0       1.0       0.0   1.151035  1.000000   
33659       0.0       0.0       1.0       0.0       0.0   0.258362  0.000000   
19531       1.0       0.0       0.0       0.0       0.0  -0.821118  0.000000   

       PhysicalActivity  HealthInsurance   Alcohol  
28456          0.660578              0.0 -0.518600  
8993           0.000000              0.0  0.115329  
34312          0.000000              0.0  0.592213  
4802           1.012447              0.0 -0.103347  
25895          0.000000              0.0 -0.886483  
...                 ...              ...       ...  
18045          0.904383              0.0 -0.482716  
5425           1.598141              0.0  0.097790  
12819          1.598141              0.0  0.612947  
33659          1.162475              0.0 -0.154408  
19531          0.791302              0.0 -0.683278  

[13109 rows x 31 columns]
2025-12-02 17:38:50,523:INFO:get_config() successfully completed......................................
2025-12-02 17:38:50,523:INFO:Initializing get_config()
2025-12-02 17:38:50,523:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F0B344EB30>, variable=y_test)
2025-12-02 17:38:50,523:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-12-02 17:38:50,523:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-12-02 17:38:50,526:INFO:Variable:  returned as 28456    0.0
8993     0.0
34312    0.0
4802     0.0
25895    0.0
        ... 
18045    0.0
5425     0.0
12819    0.0
33659    0.0
19531    0.0
Name: HeartDisease, Length: 13109, dtype: float32
2025-12-02 17:38:50,526:INFO:get_config() successfully completed......................................
2025-12-02 17:38:50,533:INFO:Initializing get_config()
2025-12-02 17:38:50,533:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F0B344EB30>, variable=y_test)
2025-12-02 17:38:50,533:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-12-02 17:38:50,533:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-12-02 17:38:50,538:INFO:Variable:  returned as 28456    0.0
8993     0.0
34312    0.0
4802     0.0
25895    0.0
        ... 
18045    0.0
5425     0.0
12819    0.0
33659    0.0
19531    0.0
Name: HeartDisease, Length: 13109, dtype: float32
2025-12-02 17:38:50,538:INFO:get_config() successfully completed......................................
2025-12-02 17:38:50,542:INFO:Initializing get_config()
2025-12-02 17:38:50,542:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F0B344EB30>, variable=X_test_transformed)
2025-12-02 17:38:50,621:INFO:Variable: X_test returned as             Age  IncomeRatio  SystolicBP       BMI  WaistCircumference  \
28456 -0.477273    -0.304717   -0.519256 -0.987220           -0.923253   
8993   0.818182     0.253271    2.156910  0.770675            0.920394   
34312  0.704545     0.055403    0.519256  0.518044            0.662901   
4802  -0.545455     0.253730   -0.331933 -0.229036           -0.436352   
25895  0.704545     1.226781   -0.093200 -0.226100            0.012322   
...         ...          ...         ...       ...                 ...   
18045 -0.568182    -0.083104   -0.568713 -1.176693           -1.338674   
5425   0.590909     0.362732    2.210168  0.139096            0.292112   
12819  0.909091    -0.019787    0.899042  0.454886            0.971892   
33659 -0.522727     1.060572   -0.525683 -0.587220           -0.906087   
19531 -0.590909    -0.344290   -0.510287 -0.945114           -1.215078   

         Height  TotalCholesterol  Triglycerides       LDL       HDL  ...  \
28456 -1.080540         -0.078535      -0.470757 -0.026922  0.418008  ...   
8993  -0.279669          0.765897       0.705031  0.006026  0.446825  ...   
34312  0.559339         -0.123259       0.929511 -1.031826 -1.404309  ...   
4802  -0.504861         -0.188325      -0.322647  0.000015 -0.138743  ...   
25895  0.216731          0.892919       1.291109  0.008211 -0.255329  ...   
...         ...               ...            ...       ...       ...  ...   
18045 -2.080569         -0.340947      -0.470582 -0.848950  0.393794  ...   
5425   0.156785          0.435639      -0.065356  1.113733  0.127664  ...   
12819  1.194951         -0.732967      -0.470025 -0.211535 -1.085148  ...   
33659 -1.254274         -1.063225      -0.470958 -2.849419  0.127664  ...   
19531 -2.339052         -0.356898      -0.470595 -0.900608  0.393896  ...   

       Race_5.0  Race_1.0  Race_4.0  Race_3.0  Race_2.0  Education   Smoking  \
28456       1.0       0.0       0.0       0.0       0.0  -0.012820  0.000000   
8993        0.0       0.0       1.0       0.0       0.0   0.547458  1.000000   
34312       0.0       0.0       0.0       1.0       0.0  -0.659696  0.000000   
4802        1.0       0.0       0.0       0.0       0.0   0.262895  0.073612   
25895       0.0       0.0       0.0       1.0       0.0   1.151035  0.000000   
...         ...       ...       ...       ...       ...        ...       ...   
18045       0.0       0.0       0.0       1.0       0.0  -0.793202  0.000000   
5425        0.0       0.0       1.0       0.0       0.0   0.547458  1.000000   
12819       0.0       0.0       0.0       1.0       0.0   1.151035  1.000000   
33659       0.0       0.0       1.0       0.0       0.0   0.258362  0.000000   
19531       1.0       0.0       0.0       0.0       0.0  -0.821118  0.000000   

       PhysicalActivity  HealthInsurance   Alcohol  
28456          0.660578              0.0 -0.518600  
8993           0.000000              0.0  0.115329  
34312          0.000000              0.0  0.592213  
4802           1.012447              0.0 -0.103347  
25895          0.000000              0.0 -0.886483  
...                 ...              ...       ...  
18045          0.904383              0.0 -0.482716  
5425           1.598141              0.0  0.097790  
12819          1.598141              0.0  0.612947  
33659          1.162475              0.0 -0.154408  
19531          0.791302              0.0 -0.683278  

[13109 rows x 31 columns]
2025-12-02 17:38:50,623:INFO:get_config() successfully completed......................................
2025-12-02 17:38:50,676:INFO:Initializing get_config()
2025-12-02 17:38:50,676:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F0B344EB30>, variable=y_test)
2025-12-02 17:38:50,676:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-12-02 17:38:50,676:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-12-02 17:38:50,685:INFO:Variable:  returned as 28456    0.0
8993     0.0
34312    0.0
4802     0.0
25895    0.0
        ... 
18045    0.0
5425     0.0
12819    0.0
33659    0.0
19531    0.0
Name: HeartDisease, Length: 13109, dtype: float32
2025-12-02 17:38:50,685:INFO:get_config() successfully completed......................................
2025-12-02 17:38:50,686:INFO:Initializing get_config()
2025-12-02 17:38:50,686:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F0B344EB30>, variable=y_test)
2025-12-02 17:38:50,686:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-12-02 17:38:50,686:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-12-02 17:38:50,692:INFO:Variable:  returned as 28456    0.0
8993     0.0
34312    0.0
4802     0.0
25895    0.0
        ... 
18045    0.0
5425     0.0
12819    0.0
33659    0.0
19531    0.0
Name: HeartDisease, Length: 13109, dtype: float32
2025-12-02 17:38:50,692:INFO:get_config() successfully completed......................................
2025-12-02 17:38:58,410:INFO:Initializing plot_model()
2025-12-02 17:38:58,410:INFO:plot_model(plot=error, fold=None, verbose=True, display=None, display_format=None, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F0B344EB30>, system=True)
2025-12-02 17:38:58,410:INFO:Checking exceptions
2025-12-02 17:38:58,429:INFO:Preloading libraries
2025-12-02 17:38:58,433:INFO:Copying training dataset
2025-12-02 17:38:58,433:INFO:Plot type: error
2025-12-02 17:38:58,651:INFO:Fitting Model
2025-12-02 17:38:58,651:INFO:Scoring test/hold-out set
2025-12-02 17:38:58,814:INFO:Visual Rendered Successfully
2025-12-02 17:38:58,987:INFO:plot_model() successfully completed......................................
2025-12-02 17:39:03,252:INFO:Initializing get_config()
2025-12-02 17:39:03,253:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F0B344EB30>, variable=X_test_transformed)
2025-12-02 17:39:03,330:INFO:Variable: X_test returned as             Age  IncomeRatio  SystolicBP       BMI  WaistCircumference  \
28456 -0.477273    -0.304717   -0.519256 -0.987220           -0.923253   
8993   0.818182     0.253271    2.156910  0.770675            0.920394   
34312  0.704545     0.055403    0.519256  0.518044            0.662901   
4802  -0.545455     0.253730   -0.331933 -0.229036           -0.436352   
25895  0.704545     1.226781   -0.093200 -0.226100            0.012322   
...         ...          ...         ...       ...                 ...   
18045 -0.568182    -0.083104   -0.568713 -1.176693           -1.338674   
5425   0.590909     0.362732    2.210168  0.139096            0.292112   
12819  0.909091    -0.019787    0.899042  0.454886            0.971892   
33659 -0.522727     1.060572   -0.525683 -0.587220           -0.906087   
19531 -0.590909    -0.344290   -0.510287 -0.945114           -1.215078   

         Height  TotalCholesterol  Triglycerides       LDL       HDL  ...  \
28456 -1.080540         -0.078535      -0.470757 -0.026922  0.418008  ...   
8993  -0.279669          0.765897       0.705031  0.006026  0.446825  ...   
34312  0.559339         -0.123259       0.929511 -1.031826 -1.404309  ...   
4802  -0.504861         -0.188325      -0.322647  0.000015 -0.138743  ...   
25895  0.216731          0.892919       1.291109  0.008211 -0.255329  ...   
...         ...               ...            ...       ...       ...  ...   
18045 -2.080569         -0.340947      -0.470582 -0.848950  0.393794  ...   
5425   0.156785          0.435639      -0.065356  1.113733  0.127664  ...   
12819  1.194951         -0.732967      -0.470025 -0.211535 -1.085148  ...   
33659 -1.254274         -1.063225      -0.470958 -2.849419  0.127664  ...   
19531 -2.339052         -0.356898      -0.470595 -0.900608  0.393896  ...   

       Race_5.0  Race_1.0  Race_4.0  Race_3.0  Race_2.0  Education   Smoking  \
28456       1.0       0.0       0.0       0.0       0.0  -0.012820  0.000000   
8993        0.0       0.0       1.0       0.0       0.0   0.547458  1.000000   
34312       0.0       0.0       0.0       1.0       0.0  -0.659696  0.000000   
4802        1.0       0.0       0.0       0.0       0.0   0.262895  0.073612   
25895       0.0       0.0       0.0       1.0       0.0   1.151035  0.000000   
...         ...       ...       ...       ...       ...        ...       ...   
18045       0.0       0.0       0.0       1.0       0.0  -0.793202  0.000000   
5425        0.0       0.0       1.0       0.0       0.0   0.547458  1.000000   
12819       0.0       0.0       0.0       1.0       0.0   1.151035  1.000000   
33659       0.0       0.0       1.0       0.0       0.0   0.258362  0.000000   
19531       1.0       0.0       0.0       0.0       0.0  -0.821118  0.000000   

       PhysicalActivity  HealthInsurance   Alcohol  
28456          0.660578              0.0 -0.518600  
8993           0.000000              0.0  0.115329  
34312          0.000000              0.0  0.592213  
4802           1.012447              0.0 -0.103347  
25895          0.000000              0.0 -0.886483  
...                 ...              ...       ...  
18045          0.904383              0.0 -0.482716  
5425           1.598141              0.0  0.097790  
12819          1.598141              0.0  0.612947  
33659          1.162475              0.0 -0.154408  
19531          0.791302              0.0 -0.683278  

[13109 rows x 31 columns]
2025-12-02 17:39:03,330:INFO:get_config() successfully completed......................................
2025-12-02 17:39:03,356:INFO:Initializing get_config()
2025-12-02 17:39:03,359:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F0B344EB30>, variable=y_test)
2025-12-02 17:39:03,359:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-12-02 17:39:03,359:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-12-02 17:39:03,364:INFO:Variable:  returned as 28456    0.0
8993     0.0
34312    0.0
4802     0.0
25895    0.0
        ... 
18045    0.0
5425     0.0
12819    0.0
33659    0.0
19531    0.0
Name: HeartDisease, Length: 13109, dtype: float32
2025-12-02 17:39:03,364:INFO:get_config() successfully completed......................................
2025-12-02 17:39:03,365:INFO:Initializing get_config()
2025-12-02 17:39:03,365:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F0B344EB30>, variable=y_test)
2025-12-02 17:39:03,365:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-12-02 17:39:03,365:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-12-02 17:39:03,371:INFO:Variable:  returned as 28456    0.0
8993     0.0
34312    0.0
4802     0.0
25895    0.0
        ... 
18045    0.0
5425     0.0
12819    0.0
33659    0.0
19531    0.0
Name: HeartDisease, Length: 13109, dtype: float32
2025-12-02 17:39:03,371:INFO:get_config() successfully completed......................................
2025-12-02 17:39:03,373:INFO:Initializing get_config()
2025-12-02 17:39:03,373:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F0B344EB30>, variable=X_test_transformed)
2025-12-02 17:39:03,449:INFO:Variable: X_test returned as             Age  IncomeRatio  SystolicBP       BMI  WaistCircumference  \
28456 -0.477273    -0.304717   -0.519256 -0.987220           -0.923253   
8993   0.818182     0.253271    2.156910  0.770675            0.920394   
34312  0.704545     0.055403    0.519256  0.518044            0.662901   
4802  -0.545455     0.253730   -0.331933 -0.229036           -0.436352   
25895  0.704545     1.226781   -0.093200 -0.226100            0.012322   
...         ...          ...         ...       ...                 ...   
18045 -0.568182    -0.083104   -0.568713 -1.176693           -1.338674   
5425   0.590909     0.362732    2.210168  0.139096            0.292112   
12819  0.909091    -0.019787    0.899042  0.454886            0.971892   
33659 -0.522727     1.060572   -0.525683 -0.587220           -0.906087   
19531 -0.590909    -0.344290   -0.510287 -0.945114           -1.215078   

         Height  TotalCholesterol  Triglycerides       LDL       HDL  ...  \
28456 -1.080540         -0.078535      -0.470757 -0.026922  0.418008  ...   
8993  -0.279669          0.765897       0.705031  0.006026  0.446825  ...   
34312  0.559339         -0.123259       0.929511 -1.031826 -1.404309  ...   
4802  -0.504861         -0.188325      -0.322647  0.000015 -0.138743  ...   
25895  0.216731          0.892919       1.291109  0.008211 -0.255329  ...   
...         ...               ...            ...       ...       ...  ...   
18045 -2.080569         -0.340947      -0.470582 -0.848950  0.393794  ...   
5425   0.156785          0.435639      -0.065356  1.113733  0.127664  ...   
12819  1.194951         -0.732967      -0.470025 -0.211535 -1.085148  ...   
33659 -1.254274         -1.063225      -0.470958 -2.849419  0.127664  ...   
19531 -2.339052         -0.356898      -0.470595 -0.900608  0.393896  ...   

       Race_5.0  Race_1.0  Race_4.0  Race_3.0  Race_2.0  Education   Smoking  \
28456       1.0       0.0       0.0       0.0       0.0  -0.012820  0.000000   
8993        0.0       0.0       1.0       0.0       0.0   0.547458  1.000000   
34312       0.0       0.0       0.0       1.0       0.0  -0.659696  0.000000   
4802        1.0       0.0       0.0       0.0       0.0   0.262895  0.073612   
25895       0.0       0.0       0.0       1.0       0.0   1.151035  0.000000   
...         ...       ...       ...       ...       ...        ...       ...   
18045       0.0       0.0       0.0       1.0       0.0  -0.793202  0.000000   
5425        0.0       0.0       1.0       0.0       0.0   0.547458  1.000000   
12819       0.0       0.0       0.0       1.0       0.0   1.151035  1.000000   
33659       0.0       0.0       1.0       0.0       0.0   0.258362  0.000000   
19531       1.0       0.0       0.0       0.0       0.0  -0.821118  0.000000   

       PhysicalActivity  HealthInsurance   Alcohol  
28456          0.660578              0.0 -0.518600  
8993           0.000000              0.0  0.115329  
34312          0.000000              0.0  0.592213  
4802           1.012447              0.0 -0.103347  
25895          0.000000              0.0 -0.886483  
...                 ...              ...       ...  
18045          0.904383              0.0 -0.482716  
5425           1.598141              0.0  0.097790  
12819          1.598141              0.0  0.612947  
33659          1.162475              0.0 -0.154408  
19531          0.791302              0.0 -0.683278  

[13109 rows x 31 columns]
2025-12-02 17:39:03,449:INFO:get_config() successfully completed......................................
2025-12-02 17:39:03,451:INFO:Initializing get_config()
2025-12-02 17:39:03,451:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F0B344EB30>, variable=y_test)
2025-12-02 17:39:03,451:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-12-02 17:39:03,451:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-12-02 17:39:03,455:INFO:Variable:  returned as 28456    0.0
8993     0.0
34312    0.0
4802     0.0
25895    0.0
        ... 
18045    0.0
5425     0.0
12819    0.0
33659    0.0
19531    0.0
Name: HeartDisease, Length: 13109, dtype: float32
2025-12-02 17:39:03,456:INFO:get_config() successfully completed......................................
2025-12-02 17:39:03,456:INFO:Initializing get_config()
2025-12-02 17:39:03,456:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F0B344EB30>, variable=y_test)
2025-12-02 17:39:03,456:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-12-02 17:39:03,456:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-12-02 17:39:03,460:INFO:Variable:  returned as 28456    0.0
8993     0.0
34312    0.0
4802     0.0
25895    0.0
        ... 
18045    0.0
5425     0.0
12819    0.0
33659    0.0
19531    0.0
Name: HeartDisease, Length: 13109, dtype: float32
2025-12-02 17:39:03,460:INFO:get_config() successfully completed......................................
2025-12-02 17:39:03,463:INFO:Initializing get_config()
2025-12-02 17:39:03,463:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F0B344EB30>, variable=X_test_transformed)
2025-12-02 17:39:03,535:INFO:Variable: X_test returned as             Age  IncomeRatio  SystolicBP       BMI  WaistCircumference  \
28456 -0.477273    -0.304717   -0.519256 -0.987220           -0.923253   
8993   0.818182     0.253271    2.156910  0.770675            0.920394   
34312  0.704545     0.055403    0.519256  0.518044            0.662901   
4802  -0.545455     0.253730   -0.331933 -0.229036           -0.436352   
25895  0.704545     1.226781   -0.093200 -0.226100            0.012322   
...         ...          ...         ...       ...                 ...   
18045 -0.568182    -0.083104   -0.568713 -1.176693           -1.338674   
5425   0.590909     0.362732    2.210168  0.139096            0.292112   
12819  0.909091    -0.019787    0.899042  0.454886            0.971892   
33659 -0.522727     1.060572   -0.525683 -0.587220           -0.906087   
19531 -0.590909    -0.344290   -0.510287 -0.945114           -1.215078   

         Height  TotalCholesterol  Triglycerides       LDL       HDL  ...  \
28456 -1.080540         -0.078535      -0.470757 -0.026922  0.418008  ...   
8993  -0.279669          0.765897       0.705031  0.006026  0.446825  ...   
34312  0.559339         -0.123259       0.929511 -1.031826 -1.404309  ...   
4802  -0.504861         -0.188325      -0.322647  0.000015 -0.138743  ...   
25895  0.216731          0.892919       1.291109  0.008211 -0.255329  ...   
...         ...               ...            ...       ...       ...  ...   
18045 -2.080569         -0.340947      -0.470582 -0.848950  0.393794  ...   
5425   0.156785          0.435639      -0.065356  1.113733  0.127664  ...   
12819  1.194951         -0.732967      -0.470025 -0.211535 -1.085148  ...   
33659 -1.254274         -1.063225      -0.470958 -2.849419  0.127664  ...   
19531 -2.339052         -0.356898      -0.470595 -0.900608  0.393896  ...   

       Race_5.0  Race_1.0  Race_4.0  Race_3.0  Race_2.0  Education   Smoking  \
28456       1.0       0.0       0.0       0.0       0.0  -0.012820  0.000000   
8993        0.0       0.0       1.0       0.0       0.0   0.547458  1.000000   
34312       0.0       0.0       0.0       1.0       0.0  -0.659696  0.000000   
4802        1.0       0.0       0.0       0.0       0.0   0.262895  0.073612   
25895       0.0       0.0       0.0       1.0       0.0   1.151035  0.000000   
...         ...       ...       ...       ...       ...        ...       ...   
18045       0.0       0.0       0.0       1.0       0.0  -0.793202  0.000000   
5425        0.0       0.0       1.0       0.0       0.0   0.547458  1.000000   
12819       0.0       0.0       0.0       1.0       0.0   1.151035  1.000000   
33659       0.0       0.0       1.0       0.0       0.0   0.258362  0.000000   
19531       1.0       0.0       0.0       0.0       0.0  -0.821118  0.000000   

       PhysicalActivity  HealthInsurance   Alcohol  
28456          0.660578              0.0 -0.518600  
8993           0.000000              0.0  0.115329  
34312          0.000000              0.0  0.592213  
4802           1.012447              0.0 -0.103347  
25895          0.000000              0.0 -0.886483  
...                 ...              ...       ...  
18045          0.904383              0.0 -0.482716  
5425           1.598141              0.0  0.097790  
12819          1.598141              0.0  0.612947  
33659          1.162475              0.0 -0.154408  
19531          0.791302              0.0 -0.683278  

[13109 rows x 31 columns]
2025-12-02 17:39:03,536:INFO:get_config() successfully completed......................................
2025-12-02 17:39:03,596:INFO:Initializing get_config()
2025-12-02 17:39:03,596:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F0B344EB30>, variable=y_test)
2025-12-02 17:39:03,596:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-12-02 17:39:03,596:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-12-02 17:39:03,601:INFO:Variable:  returned as 28456    0.0
8993     0.0
34312    0.0
4802     0.0
25895    0.0
        ... 
18045    0.0
5425     0.0
12819    0.0
33659    0.0
19531    0.0
Name: HeartDisease, Length: 13109, dtype: float32
2025-12-02 17:39:03,601:INFO:get_config() successfully completed......................................
2025-12-02 17:39:03,601:INFO:Initializing get_config()
2025-12-02 17:39:03,601:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F0B344EB30>, variable=y_test)
2025-12-02 17:39:03,601:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-12-02 17:39:03,601:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-12-02 17:39:03,607:INFO:Variable:  returned as 28456    0.0
8993     0.0
34312    0.0
4802     0.0
25895    0.0
        ... 
18045    0.0
5425     0.0
12819    0.0
33659    0.0
19531    0.0
Name: HeartDisease, Length: 13109, dtype: float32
2025-12-02 17:39:03,607:INFO:get_config() successfully completed......................................
2025-12-02 17:39:03,710:INFO:Initializing get_config()
2025-12-02 17:39:03,710:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F0B344EB30>, variable=X_test_transformed)
2025-12-02 17:39:03,793:INFO:Variable: X_test returned as             Age  IncomeRatio  SystolicBP       BMI  WaistCircumference  \
28456 -0.477273    -0.304717   -0.519256 -0.987220           -0.923253   
8993   0.818182     0.253271    2.156910  0.770675            0.920394   
34312  0.704545     0.055403    0.519256  0.518044            0.662901   
4802  -0.545455     0.253730   -0.331933 -0.229036           -0.436352   
25895  0.704545     1.226781   -0.093200 -0.226100            0.012322   
...         ...          ...         ...       ...                 ...   
18045 -0.568182    -0.083104   -0.568713 -1.176693           -1.338674   
5425   0.590909     0.362732    2.210168  0.139096            0.292112   
12819  0.909091    -0.019787    0.899042  0.454886            0.971892   
33659 -0.522727     1.060572   -0.525683 -0.587220           -0.906087   
19531 -0.590909    -0.344290   -0.510287 -0.945114           -1.215078   

         Height  TotalCholesterol  Triglycerides       LDL       HDL  ...  \
28456 -1.080540         -0.078535      -0.470757 -0.026922  0.418008  ...   
8993  -0.279669          0.765897       0.705031  0.006026  0.446825  ...   
34312  0.559339         -0.123259       0.929511 -1.031826 -1.404309  ...   
4802  -0.504861         -0.188325      -0.322647  0.000015 -0.138743  ...   
25895  0.216731          0.892919       1.291109  0.008211 -0.255329  ...   
...         ...               ...            ...       ...       ...  ...   
18045 -2.080569         -0.340947      -0.470582 -0.848950  0.393794  ...   
5425   0.156785          0.435639      -0.065356  1.113733  0.127664  ...   
12819  1.194951         -0.732967      -0.470025 -0.211535 -1.085148  ...   
33659 -1.254274         -1.063225      -0.470958 -2.849419  0.127664  ...   
19531 -2.339052         -0.356898      -0.470595 -0.900608  0.393896  ...   

       Race_5.0  Race_1.0  Race_4.0  Race_3.0  Race_2.0  Education   Smoking  \
28456       1.0       0.0       0.0       0.0       0.0  -0.012820  0.000000   
8993        0.0       0.0       1.0       0.0       0.0   0.547458  1.000000   
34312       0.0       0.0       0.0       1.0       0.0  -0.659696  0.000000   
4802        1.0       0.0       0.0       0.0       0.0   0.262895  0.073612   
25895       0.0       0.0       0.0       1.0       0.0   1.151035  0.000000   
...         ...       ...       ...       ...       ...        ...       ...   
18045       0.0       0.0       0.0       1.0       0.0  -0.793202  0.000000   
5425        0.0       0.0       1.0       0.0       0.0   0.547458  1.000000   
12819       0.0       0.0       0.0       1.0       0.0   1.151035  1.000000   
33659       0.0       0.0       1.0       0.0       0.0   0.258362  0.000000   
19531       1.0       0.0       0.0       0.0       0.0  -0.821118  0.000000   

       PhysicalActivity  HealthInsurance   Alcohol  
28456          0.660578              0.0 -0.518600  
8993           0.000000              0.0  0.115329  
34312          0.000000              0.0  0.592213  
4802           1.012447              0.0 -0.103347  
25895          0.000000              0.0 -0.886483  
...                 ...              ...       ...  
18045          0.904383              0.0 -0.482716  
5425           1.598141              0.0  0.097790  
12819          1.598141              0.0  0.612947  
33659          1.162475              0.0 -0.154408  
19531          0.791302              0.0 -0.683278  

[13109 rows x 31 columns]
2025-12-02 17:39:03,793:INFO:get_config() successfully completed......................................
2025-12-02 17:39:03,821:INFO:Initializing get_config()
2025-12-02 17:39:03,821:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F0B344EB30>, variable=y_test)
2025-12-02 17:39:03,821:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-12-02 17:39:03,821:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-12-02 17:39:03,826:INFO:Variable:  returned as 28456    0.0
8993     0.0
34312    0.0
4802     0.0
25895    0.0
        ... 
18045    0.0
5425     0.0
12819    0.0
33659    0.0
19531    0.0
Name: HeartDisease, Length: 13109, dtype: float32
2025-12-02 17:39:03,826:INFO:get_config() successfully completed......................................
2025-12-02 17:39:03,826:INFO:Initializing get_config()
2025-12-02 17:39:03,826:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F0B344EB30>, variable=X_test_transformed)
2025-12-02 17:39:03,898:INFO:Variable: X_test returned as             Age  IncomeRatio  SystolicBP       BMI  WaistCircumference  \
28456 -0.477273    -0.304717   -0.519256 -0.987220           -0.923253   
8993   0.818182     0.253271    2.156910  0.770675            0.920394   
34312  0.704545     0.055403    0.519256  0.518044            0.662901   
4802  -0.545455     0.253730   -0.331933 -0.229036           -0.436352   
25895  0.704545     1.226781   -0.093200 -0.226100            0.012322   
...         ...          ...         ...       ...                 ...   
18045 -0.568182    -0.083104   -0.568713 -1.176693           -1.338674   
5425   0.590909     0.362732    2.210168  0.139096            0.292112   
12819  0.909091    -0.019787    0.899042  0.454886            0.971892   
33659 -0.522727     1.060572   -0.525683 -0.587220           -0.906087   
19531 -0.590909    -0.344290   -0.510287 -0.945114           -1.215078   

         Height  TotalCholesterol  Triglycerides       LDL       HDL  ...  \
28456 -1.080540         -0.078535      -0.470757 -0.026922  0.418008  ...   
8993  -0.279669          0.765897       0.705031  0.006026  0.446825  ...   
34312  0.559339         -0.123259       0.929511 -1.031826 -1.404309  ...   
4802  -0.504861         -0.188325      -0.322647  0.000015 -0.138743  ...   
25895  0.216731          0.892919       1.291109  0.008211 -0.255329  ...   
...         ...               ...            ...       ...       ...  ...   
18045 -2.080569         -0.340947      -0.470582 -0.848950  0.393794  ...   
5425   0.156785          0.435639      -0.065356  1.113733  0.127664  ...   
12819  1.194951         -0.732967      -0.470025 -0.211535 -1.085148  ...   
33659 -1.254274         -1.063225      -0.470958 -2.849419  0.127664  ...   
19531 -2.339052         -0.356898      -0.470595 -0.900608  0.393896  ...   

       Race_5.0  Race_1.0  Race_4.0  Race_3.0  Race_2.0  Education   Smoking  \
28456       1.0       0.0       0.0       0.0       0.0  -0.012820  0.000000   
8993        0.0       0.0       1.0       0.0       0.0   0.547458  1.000000   
34312       0.0       0.0       0.0       1.0       0.0  -0.659696  0.000000   
4802        1.0       0.0       0.0       0.0       0.0   0.262895  0.073612   
25895       0.0       0.0       0.0       1.0       0.0   1.151035  0.000000   
...         ...       ...       ...       ...       ...        ...       ...   
18045       0.0       0.0       0.0       1.0       0.0  -0.793202  0.000000   
5425        0.0       0.0       1.0       0.0       0.0   0.547458  1.000000   
12819       0.0       0.0       0.0       1.0       0.0   1.151035  1.000000   
33659       0.0       0.0       1.0       0.0       0.0   0.258362  0.000000   
19531       1.0       0.0       0.0       0.0       0.0  -0.821118  0.000000   

       PhysicalActivity  HealthInsurance   Alcohol  
28456          0.660578              0.0 -0.518600  
8993           0.000000              0.0  0.115329  
34312          0.000000              0.0  0.592213  
4802           1.012447              0.0 -0.103347  
25895          0.000000              0.0 -0.886483  
...                 ...              ...       ...  
18045          0.904383              0.0 -0.482716  
5425           1.598141              0.0  0.097790  
12819          1.598141              0.0  0.612947  
33659          1.162475              0.0 -0.154408  
19531          0.791302              0.0 -0.683278  

[13109 rows x 31 columns]
2025-12-02 17:39:03,898:INFO:get_config() successfully completed......................................
2025-12-02 17:39:03,900:INFO:Initializing get_config()
2025-12-02 17:39:03,901:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F0B344EB30>, variable=y_test)
2025-12-02 17:39:03,901:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-12-02 17:39:03,901:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-12-02 17:39:03,906:INFO:Variable:  returned as 28456    0.0
8993     0.0
34312    0.0
4802     0.0
25895    0.0
        ... 
18045    0.0
5425     0.0
12819    0.0
33659    0.0
19531    0.0
Name: HeartDisease, Length: 13109, dtype: float32
2025-12-02 17:39:03,906:INFO:get_config() successfully completed......................................
2025-12-02 17:39:03,906:INFO:Initializing get_config()
2025-12-02 17:39:03,906:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F0B344EB30>, variable=X_test_transformed)
2025-12-02 17:39:03,982:INFO:Variable: X_test returned as             Age  IncomeRatio  SystolicBP       BMI  WaistCircumference  \
28456 -0.477273    -0.304717   -0.519256 -0.987220           -0.923253   
8993   0.818182     0.253271    2.156910  0.770675            0.920394   
34312  0.704545     0.055403    0.519256  0.518044            0.662901   
4802  -0.545455     0.253730   -0.331933 -0.229036           -0.436352   
25895  0.704545     1.226781   -0.093200 -0.226100            0.012322   
...         ...          ...         ...       ...                 ...   
18045 -0.568182    -0.083104   -0.568713 -1.176693           -1.338674   
5425   0.590909     0.362732    2.210168  0.139096            0.292112   
12819  0.909091    -0.019787    0.899042  0.454886            0.971892   
33659 -0.522727     1.060572   -0.525683 -0.587220           -0.906087   
19531 -0.590909    -0.344290   -0.510287 -0.945114           -1.215078   

         Height  TotalCholesterol  Triglycerides       LDL       HDL  ...  \
28456 -1.080540         -0.078535      -0.470757 -0.026922  0.418008  ...   
8993  -0.279669          0.765897       0.705031  0.006026  0.446825  ...   
34312  0.559339         -0.123259       0.929511 -1.031826 -1.404309  ...   
4802  -0.504861         -0.188325      -0.322647  0.000015 -0.138743  ...   
25895  0.216731          0.892919       1.291109  0.008211 -0.255329  ...   
...         ...               ...            ...       ...       ...  ...   
18045 -2.080569         -0.340947      -0.470582 -0.848950  0.393794  ...   
5425   0.156785          0.435639      -0.065356  1.113733  0.127664  ...   
12819  1.194951         -0.732967      -0.470025 -0.211535 -1.085148  ...   
33659 -1.254274         -1.063225      -0.470958 -2.849419  0.127664  ...   
19531 -2.339052         -0.356898      -0.470595 -0.900608  0.393896  ...   

       Race_5.0  Race_1.0  Race_4.0  Race_3.0  Race_2.0  Education   Smoking  \
28456       1.0       0.0       0.0       0.0       0.0  -0.012820  0.000000   
8993        0.0       0.0       1.0       0.0       0.0   0.547458  1.000000   
34312       0.0       0.0       0.0       1.0       0.0  -0.659696  0.000000   
4802        1.0       0.0       0.0       0.0       0.0   0.262895  0.073612   
25895       0.0       0.0       0.0       1.0       0.0   1.151035  0.000000   
...         ...       ...       ...       ...       ...        ...       ...   
18045       0.0       0.0       0.0       1.0       0.0  -0.793202  0.000000   
5425        0.0       0.0       1.0       0.0       0.0   0.547458  1.000000   
12819       0.0       0.0       0.0       1.0       0.0   1.151035  1.000000   
33659       0.0       0.0       1.0       0.0       0.0   0.258362  0.000000   
19531       1.0       0.0       0.0       0.0       0.0  -0.821118  0.000000   

       PhysicalActivity  HealthInsurance   Alcohol  
28456          0.660578              0.0 -0.518600  
8993           0.000000              0.0  0.115329  
34312          0.000000              0.0  0.592213  
4802           1.012447              0.0 -0.103347  
25895          0.000000              0.0 -0.886483  
...                 ...              ...       ...  
18045          0.904383              0.0 -0.482716  
5425           1.598141              0.0  0.097790  
12819          1.598141              0.0  0.612947  
33659          1.162475              0.0 -0.154408  
19531          0.791302              0.0 -0.683278  

[13109 rows x 31 columns]
2025-12-02 17:39:03,982:INFO:get_config() successfully completed......................................
2025-12-02 17:39:04,038:INFO:Initializing get_config()
2025-12-02 17:39:04,038:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F0B344EB30>, variable=y_test)
2025-12-02 17:39:04,038:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-12-02 17:39:04,038:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-12-02 17:39:04,045:INFO:Variable:  returned as 28456    0.0
8993     0.0
34312    0.0
4802     0.0
25895    0.0
        ... 
18045    0.0
5425     0.0
12819    0.0
33659    0.0
19531    0.0
Name: HeartDisease, Length: 13109, dtype: float32
2025-12-02 17:39:04,045:INFO:get_config() successfully completed......................................
2025-12-02 17:39:10,267:INFO:Initializing get_config()
2025-12-02 17:39:10,267:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F0B344EB30>, variable=X_test_transformed)
2025-12-02 17:39:10,342:INFO:Variable: X_test returned as             Age  IncomeRatio  SystolicBP       BMI  WaistCircumference  \
28456 -0.477273    -0.304717   -0.519256 -0.987220           -0.923253   
8993   0.818182     0.253271    2.156910  0.770675            0.920394   
34312  0.704545     0.055403    0.519256  0.518044            0.662901   
4802  -0.545455     0.253730   -0.331933 -0.229036           -0.436352   
25895  0.704545     1.226781   -0.093200 -0.226100            0.012322   
...         ...          ...         ...       ...                 ...   
18045 -0.568182    -0.083104   -0.568713 -1.176693           -1.338674   
5425   0.590909     0.362732    2.210168  0.139096            0.292112   
12819  0.909091    -0.019787    0.899042  0.454886            0.971892   
33659 -0.522727     1.060572   -0.525683 -0.587220           -0.906087   
19531 -0.590909    -0.344290   -0.510287 -0.945114           -1.215078   

         Height  TotalCholesterol  Triglycerides       LDL       HDL  ...  \
28456 -1.080540         -0.078535      -0.470757 -0.026922  0.418008  ...   
8993  -0.279669          0.765897       0.705031  0.006026  0.446825  ...   
34312  0.559339         -0.123259       0.929511 -1.031826 -1.404309  ...   
4802  -0.504861         -0.188325      -0.322647  0.000015 -0.138743  ...   
25895  0.216731          0.892919       1.291109  0.008211 -0.255329  ...   
...         ...               ...            ...       ...       ...  ...   
18045 -2.080569         -0.340947      -0.470582 -0.848950  0.393794  ...   
5425   0.156785          0.435639      -0.065356  1.113733  0.127664  ...   
12819  1.194951         -0.732967      -0.470025 -0.211535 -1.085148  ...   
33659 -1.254274         -1.063225      -0.470958 -2.849419  0.127664  ...   
19531 -2.339052         -0.356898      -0.470595 -0.900608  0.393896  ...   

       Race_5.0  Race_1.0  Race_4.0  Race_3.0  Race_2.0  Education   Smoking  \
28456       1.0       0.0       0.0       0.0       0.0  -0.012820  0.000000   
8993        0.0       0.0       1.0       0.0       0.0   0.547458  1.000000   
34312       0.0       0.0       0.0       1.0       0.0  -0.659696  0.000000   
4802        1.0       0.0       0.0       0.0       0.0   0.262895  0.073612   
25895       0.0       0.0       0.0       1.0       0.0   1.151035  0.000000   
...         ...       ...       ...       ...       ...        ...       ...   
18045       0.0       0.0       0.0       1.0       0.0  -0.793202  0.000000   
5425        0.0       0.0       1.0       0.0       0.0   0.547458  1.000000   
12819       0.0       0.0       0.0       1.0       0.0   1.151035  1.000000   
33659       0.0       0.0       1.0       0.0       0.0   0.258362  0.000000   
19531       1.0       0.0       0.0       0.0       0.0  -0.821118  0.000000   

       PhysicalActivity  HealthInsurance   Alcohol  
28456          0.660578              0.0 -0.518600  
8993           0.000000              0.0  0.115329  
34312          0.000000              0.0  0.592213  
4802           1.012447              0.0 -0.103347  
25895          0.000000              0.0 -0.886483  
...                 ...              ...       ...  
18045          0.904383              0.0 -0.482716  
5425           1.598141              0.0  0.097790  
12819          1.598141              0.0  0.612947  
33659          1.162475              0.0 -0.154408  
19531          0.791302              0.0 -0.683278  

[13109 rows x 31 columns]
2025-12-02 17:39:10,342:INFO:get_config() successfully completed......................................
2025-12-02 17:39:10,370:INFO:Initializing get_config()
2025-12-02 17:39:10,370:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F0B344EB30>, variable=y_test)
2025-12-02 17:39:10,370:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-12-02 17:39:10,370:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-12-02 17:39:10,376:INFO:Variable:  returned as 28456    0.0
8993     0.0
34312    0.0
4802     0.0
25895    0.0
        ... 
18045    0.0
5425     0.0
12819    0.0
33659    0.0
19531    0.0
Name: HeartDisease, Length: 13109, dtype: float32
2025-12-02 17:39:10,376:INFO:get_config() successfully completed......................................
2025-12-02 17:39:18,445:INFO:Initializing tune_model()
2025-12-02 17:39:18,445:INFO:tune_model(estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...), fold=None, round=4, n_iter=5, custom_grid=None, optimize=Recall, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=False, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F0B344EB30>)
2025-12-02 17:39:18,445:INFO:Checking exceptions
2025-12-02 17:39:18,456:INFO:Copying training dataset
2025-12-02 17:39:18,473:INFO:Checking base model
2025-12-02 17:39:18,474:INFO:Base model : Extreme Gradient Boosting
2025-12-02 17:39:18,474:INFO:Declaring metric variables
2025-12-02 17:39:18,474:INFO:Defining Hyperparameters
2025-12-02 17:39:18,636:INFO:Tuning with n_jobs=1
2025-12-02 17:39:18,636:INFO:Initializing RandomizedSearchCV
2025-12-02 17:39:54,076:INFO:best_params: {'actual_estimator__subsample': 0.7, 'actual_estimator__scale_pos_weight': 38.0, 'actual_estimator__reg_lambda': 0.7, 'actual_estimator__reg_alpha': 0.001, 'actual_estimator__n_estimators': 60, 'actual_estimator__min_child_weight': 1, 'actual_estimator__max_depth': 6, 'actual_estimator__learning_rate': 0.4, 'actual_estimator__colsample_bytree': 0.7}
2025-12-02 17:39:54,076:INFO:Hyperparameter search completed
2025-12-02 17:39:54,076:INFO:SubProcess create_model() called ==================================
2025-12-02 17:39:54,076:INFO:Initializing create_model()
2025-12-02 17:39:54,076:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F0B344EB30>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F0B2316B30>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'subsample': 0.7, 'scale_pos_weight': 38.0, 'reg_lambda': 0.7, 'reg_alpha': 0.001, 'n_estimators': 60, 'min_child_weight': 1, 'max_depth': 6, 'learning_rate': 0.4, 'colsample_bytree': 0.7})
2025-12-02 17:39:54,076:INFO:Checking exceptions
2025-12-02 17:39:54,076:INFO:Importing libraries
2025-12-02 17:39:54,076:INFO:Copying training dataset
2025-12-02 17:39:54,097:INFO:Defining folds
2025-12-02 17:39:54,097:INFO:Declaring metric variables
2025-12-02 17:39:54,097:INFO:Importing untrained model
2025-12-02 17:39:54,097:INFO:Declaring custom model
2025-12-02 17:39:54,098:INFO:Extreme Gradient Boosting Imported successfully
2025-12-02 17:39:54,098:INFO:Starting cross validation
2025-12-02 17:39:54,100:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-12-02 17:39:59,014:INFO:Calculating mean and std
2025-12-02 17:39:59,014:INFO:Creating metrics dataframe
2025-12-02 17:39:59,014:INFO:Finalizing model
2025-12-02 17:39:59,115:INFO:Warning: No categorical columns found. Calling 'transform' will only return input data.
2025-12-02 17:39:59,580:INFO:Uploading results into container
2025-12-02 17:39:59,581:INFO:Uploading model into container now
2025-12-02 17:39:59,581:INFO:_master_model_container: 4
2025-12-02 17:39:59,581:INFO:_display_container: 5
2025-12-02 17:39:59,581:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=0.7, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=0.4, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=6, max_leaves=None,
              min_child_weight=1, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=60, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2025-12-02 17:39:59,581:INFO:create_model() successfully completed......................................
2025-12-02 17:39:59,771:INFO:SubProcess create_model() end ==================================
2025-12-02 17:39:59,771:INFO:choose_better activated
2025-12-02 17:39:59,772:INFO:SubProcess create_model() called ==================================
2025-12-02 17:39:59,773:INFO:Initializing create_model()
2025-12-02 17:39:59,773:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F0B344EB30>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-02 17:39:59,773:INFO:Checking exceptions
2025-12-02 17:39:59,774:INFO:Importing libraries
2025-12-02 17:39:59,774:INFO:Copying training dataset
2025-12-02 17:39:59,797:INFO:Defining folds
2025-12-02 17:39:59,797:INFO:Declaring metric variables
2025-12-02 17:39:59,797:INFO:Importing untrained model
2025-12-02 17:39:59,797:INFO:Declaring custom model
2025-12-02 17:39:59,797:INFO:Extreme Gradient Boosting Imported successfully
2025-12-02 17:39:59,797:INFO:Starting cross validation
2025-12-02 17:39:59,797:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-12-02 17:40:05,947:INFO:Calculating mean and std
2025-12-02 17:40:05,947:INFO:Creating metrics dataframe
2025-12-02 17:40:05,947:INFO:Finalizing model
2025-12-02 17:40:06,016:INFO:Warning: No categorical columns found. Calling 'transform' will only return input data.
2025-12-02 17:40:06,526:INFO:Uploading results into container
2025-12-02 17:40:06,529:INFO:Uploading model into container now
2025-12-02 17:40:06,529:INFO:_master_model_container: 5
2025-12-02 17:40:06,529:INFO:_display_container: 6
2025-12-02 17:40:06,529:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2025-12-02 17:40:06,529:INFO:create_model() successfully completed......................................
2025-12-02 17:40:06,714:INFO:SubProcess create_model() end ==================================
2025-12-02 17:40:06,719:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...) result for Recall is 0.2882
2025-12-02 17:40:06,719:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=0.7, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=0.4, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=6, max_leaves=None,
              min_child_weight=1, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=60, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...) result for Recall is 0.3316
2025-12-02 17:40:06,720:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=0.7, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=0.4, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=6, max_leaves=None,
              min_child_weight=1, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=60, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...) is best model
2025-12-02 17:40:06,720:INFO:choose_better completed
2025-12-02 17:40:06,720:INFO:_master_model_container: 5
2025-12-02 17:40:06,720:INFO:_display_container: 5
2025-12-02 17:40:06,720:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=0.7, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=0.4, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=6, max_leaves=None,
              min_child_weight=1, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=60, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2025-12-02 17:40:06,720:INFO:tune_model() successfully completed......................................
2025-12-02 17:40:09,650:INFO:Initializing predict_model()
2025-12-02 17:40:09,650:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F0B344EB30>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=0.7, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=0.4, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=6, max_leaves=None,
              min_child_weight=1, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=60, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...), probability_threshold=None, encoded_labels=False, raw_score=True, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001F0DC548E50>)
2025-12-02 17:40:09,650:INFO:Checking exceptions
2025-12-02 17:40:09,650:INFO:Preloading libraries
2025-12-02 17:40:10,050:INFO:Initializing get_config()
2025-12-02 17:40:10,050:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F0B344EB30>, variable=target_param)
2025-12-02 17:40:10,050:INFO:Variable:  returned as HeartDisease
2025-12-02 17:40:10,050:INFO:get_config() successfully completed......................................
2025-12-02 17:40:17,656:INFO:Initializing interpret_model()
2025-12-02 17:40:17,656:INFO:interpret_model(estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=0.7, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=0.4, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=6, max_leaves=None,
              min_child_weight=1, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=60, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...), use_train_data=False, X_new_sample=None, y_new_sample=None, feature=None, kwargs={}, observation=None, plot=summary, save=False, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F0B344EB30>)
2025-12-02 17:40:17,656:INFO:Checking exceptions
2025-12-02 17:40:17,656:INFO:Soft dependency imported: shap: 0.49.1
2025-12-02 17:40:17,729:INFO:plot type: summary
2025-12-02 17:40:17,730:INFO:Creating TreeExplainer
2025-12-02 17:40:17,736:INFO:Compiling shap values
2025-12-02 17:40:21,071:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:4145: FutureWarning: The NumPy global RNG was seeded by calling `np.random.seed`. In a future version this function will no longer use the global RNG. Pass `rng` explicitly to opt-in to the new behaviour and silence this warning.

2025-12-02 17:40:22,221:INFO:Visual Rendered Successfully
2025-12-02 17:40:22,221:INFO:interpret_model() successfully completed......................................
2025-12-02 17:40:31,277:INFO:Initializing finalize_model()
2025-12-02 17:40:31,277:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F0B344EB30>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=0.7, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=0.4, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=6, max_leaves=None,
              min_child_weight=1, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=60, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2025-12-02 17:40:31,281:INFO:Finalizing XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=0.7, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=0.4, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=6, max_leaves=None,
              min_child_weight=1, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=60, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2025-12-02 17:40:31,297:INFO:Initializing create_model()
2025-12-02 17:40:31,297:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F0B344EB30>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=0.7, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=0.4, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=6, max_leaves=None,
              min_child_weight=1, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=60, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2025-12-02 17:40:31,297:INFO:Checking exceptions
2025-12-02 17:40:31,297:INFO:Importing libraries
2025-12-02 17:40:31,297:INFO:Copying training dataset
2025-12-02 17:40:31,301:INFO:Defining folds
2025-12-02 17:40:31,301:INFO:Declaring metric variables
2025-12-02 17:40:31,301:INFO:Importing untrained model
2025-12-02 17:40:31,301:INFO:Declaring custom model
2025-12-02 17:40:31,302:INFO:Extreme Gradient Boosting Imported successfully
2025-12-02 17:40:31,302:INFO:Cross validation set to False
2025-12-02 17:40:31,302:INFO:Fitting Model
2025-12-02 17:40:31,397:INFO:Warning: No categorical columns found. Calling 'transform' will only return input data.
2025-12-02 17:40:31,955:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'IncomeRatio', 'SystolicBP',
                                             'BMI', 'WaistCircumference',
                                             'Height', 'TotalCholesterol',
                                             'Triglycerides', 'LDL', 'HDL',
                                             'HbA1c', 'Glucose', 'Creatinine',
                                             'UricAcid', 'ALT_Enzyme',
                                             'Albumin', 'Potassium', 'Sodium',
                                             'GGT_Enzyme', 'AST_Enzyme'],
                                    transformer=Si...
                               feature_types=None, gamma=None, grow_policy=None,
                               importance_type=None,
                               interaction_constraints=None, learning_rate=0.4,
                               max_bin=None, max_cat_threshold=None,
                               max_cat_to_onehot=None, max_delta_step=None,
                               max_depth=6, max_leaves=None, min_child_weight=1,
                               missing=nan, monotone_constraints=None,
                               multi_strategy=None, n_estimators=60, n_jobs=1,
                               num_parallel_tree=None,
                               objective='binary:logistic', ...))],
         verbose=False)
2025-12-02 17:40:31,956:INFO:create_model() successfully completed......................................
2025-12-02 17:40:32,126:INFO:_master_model_container: 5
2025-12-02 17:40:32,126:INFO:_display_container: 6
2025-12-02 17:40:32,144:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'IncomeRatio', 'SystolicBP',
                                             'BMI', 'WaistCircumference',
                                             'Height', 'TotalCholesterol',
                                             'Triglycerides', 'LDL', 'HDL',
                                             'HbA1c', 'Glucose', 'Creatinine',
                                             'UricAcid', 'ALT_Enzyme',
                                             'Albumin', 'Potassium', 'Sodium',
                                             'GGT_Enzyme', 'AST_Enzyme'],
                                    transformer=Si...
                               feature_types=None, gamma=None, grow_policy=None,
                               importance_type=None,
                               interaction_constraints=None, learning_rate=0.4,
                               max_bin=None, max_cat_threshold=None,
                               max_cat_to_onehot=None, max_delta_step=None,
                               max_depth=6, max_leaves=None, min_child_weight=1,
                               missing=nan, monotone_constraints=None,
                               multi_strategy=None, n_estimators=60, n_jobs=1,
                               num_parallel_tree=None,
                               objective='binary:logistic', ...))],
         verbose=False)
2025-12-02 17:40:32,144:INFO:finalize_model() successfully completed......................................
2025-12-02 17:40:32,337:INFO:Initializing save_model()
2025-12-02 17:40:32,337:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'IncomeRatio', 'SystolicBP',
                                             'BMI', 'WaistCircumference',
                                             'Height', 'TotalCholesterol',
                                             'Triglycerides', 'LDL', 'HDL',
                                             'HbA1c', 'Glucose', 'Creatinine',
                                             'UricAcid', 'ALT_Enzyme',
                                             'Albumin', 'Potassium', 'Sodium',
                                             'GGT_Enzyme', 'AST_Enzyme'],
                                    transformer=Si...
                               feature_types=None, gamma=None, grow_policy=None,
                               importance_type=None,
                               interaction_constraints=None, learning_rate=0.4,
                               max_bin=None, max_cat_threshold=None,
                               max_cat_to_onehot=None, max_delta_step=None,
                               max_depth=6, max_leaves=None, min_child_weight=1,
                               missing=nan, monotone_constraints=None,
                               multi_strategy=None, n_estimators=60, n_jobs=1,
                               num_parallel_tree=None,
                               objective='binary:logistic', ...))],
         verbose=False), model_name=../models\best_pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\OMAR\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'IncomeRatio', 'SystolicBP',
                                             'BMI', 'WaistCircumference',
                                             'Height', 'TotalCholesterol',
                                             'Triglycerides', 'LDL', 'HDL',
                                             'HbA1c', 'Glucose', 'Creatinine',
                                             'UricAcid', 'ALT_Enzyme',
                                             'Albumin', 'Potassium', 'Sodium',
                                             'G...
                                    transformer=TargetEncoder(cols=[],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=RobustScaler(copy=True,
                                                             quantile_range=(25.0,
                                                                             75.0),
                                                             unit_variance=False,
                                                             with_centering=True,
                                                             with_scaling=True)))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2025-12-02 17:40:32,337:INFO:Adding model into prep_pipe
2025-12-02 17:40:32,337:WARNING:Only Model saved as it was a pipeline.
2025-12-02 17:40:32,343:INFO:../models\best_pipeline.pkl saved in current working directory
2025-12-02 17:40:32,358:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'IncomeRatio', 'SystolicBP',
                                             'BMI', 'WaistCircumference',
                                             'Height', 'TotalCholesterol',
                                             'Triglycerides', 'LDL', 'HDL',
                                             'HbA1c', 'Glucose', 'Creatinine',
                                             'UricAcid', 'ALT_Enzyme',
                                             'Albumin', 'Potassium', 'Sodium',
                                             'GGT_Enzyme', 'AST_Enzyme'],
                                    transformer=Si...
                               feature_types=None, gamma=None, grow_policy=None,
                               importance_type=None,
                               interaction_constraints=None, learning_rate=0.4,
                               max_bin=None, max_cat_threshold=None,
                               max_cat_to_onehot=None, max_delta_step=None,
                               max_depth=6, max_leaves=None, min_child_weight=1,
                               missing=nan, monotone_constraints=None,
                               multi_strategy=None, n_estimators=60, n_jobs=1,
                               num_parallel_tree=None,
                               objective='binary:logistic', ...))],
         verbose=False)
2025-12-02 17:40:32,358:INFO:save_model() successfully completed......................................
2025-12-02 18:41:08,129:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-12-02 18:41:08,129:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-12-02 18:41:08,129:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-12-02 18:41:08,129:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-12-02 18:41:25,757:INFO:PyCaret ClassificationExperiment
2025-12-02 18:41:25,758:INFO:Logging name: clf-default-name
2025-12-02 18:41:25,758:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-12-02 18:41:25,758:INFO:version 3.3.2
2025-12-02 18:41:25,758:INFO:Initializing setup()
2025-12-02 18:41:25,758:INFO:self.USI: 9a99
2025-12-02 18:41:25,758:INFO:self._variable_keys: {'fix_imbalance', 'fold_generator', 'idx', 'X_test', '_available_plots', 'gpu_n_jobs_param', 'is_multiclass', 'html_param', 'exp_name_log', 'log_plots_param', 'data', 'y_test', 'logging_param', 'y_train', 'n_jobs_param', 'fold_shuffle_param', 'pipeline', 'seed', 'y', 'fold_groups_param', 'target_param', 'X_train', 'memory', 'USI', 'exp_id', 'X', 'gpu_param', '_ml_usecase'}
2025-12-02 18:41:25,758:INFO:Checking environment
2025-12-02 18:41:25,758:INFO:python_version: 3.10.19
2025-12-02 18:41:25,758:INFO:python_build: ('main', 'Oct 21 2025 16:41:31')
2025-12-02 18:41:25,758:INFO:machine: AMD64
2025-12-02 18:41:25,758:INFO:platform: Windows-10-10.0.26100-SP0
2025-12-02 18:41:25,758:INFO:Memory: svmem(total=16282144768, available=4598784000, percent=71.8, used=11683360768, free=4598784000)
2025-12-02 18:41:25,758:INFO:Physical Core: 6
2025-12-02 18:41:25,758:INFO:Logical Core: 12
2025-12-02 18:41:25,758:INFO:Checking libraries
2025-12-02 18:41:25,758:INFO:System:
2025-12-02 18:41:25,759:INFO:    python: 3.10.19 | packaged by Anaconda, Inc. | (main, Oct 21 2025, 16:41:31) [MSC v.1929 64 bit (AMD64)]
2025-12-02 18:41:25,759:INFO:executable: c:\Users\OMAR\miniconda3\envs\xgb_env\python.exe
2025-12-02 18:41:25,759:INFO:   machine: Windows-10-10.0.26100-SP0
2025-12-02 18:41:25,759:INFO:PyCaret required dependencies:
2025-12-02 18:41:25,759:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-02 18:41:26,326:INFO:                 pip: 25.3
2025-12-02 18:41:26,326:INFO:          setuptools: 80.9.0
2025-12-02 18:41:26,326:INFO:             pycaret: 3.3.2
2025-12-02 18:41:26,326:INFO:             IPython: 8.37.0
2025-12-02 18:41:26,326:INFO:          ipywidgets: 8.1.8
2025-12-02 18:41:26,326:INFO:                tqdm: 4.67.1
2025-12-02 18:41:26,326:INFO:               numpy: 1.26.4
2025-12-02 18:41:26,326:INFO:              pandas: 2.1.4
2025-12-02 18:41:26,326:INFO:              jinja2: 3.1.6
2025-12-02 18:41:26,326:INFO:               scipy: 1.11.4
2025-12-02 18:41:26,326:INFO:              joblib: 1.3.2
2025-12-02 18:41:26,326:INFO:             sklearn: 1.4.2
2025-12-02 18:41:26,326:INFO:                pyod: 2.0.5
2025-12-02 18:41:26,326:INFO:            imblearn: 0.14.0
2025-12-02 18:41:26,326:INFO:   category_encoders: 2.7.0
2025-12-02 18:41:26,326:INFO:            lightgbm: 4.6.0
2025-12-02 18:41:26,326:INFO:               numba: 0.62.1
2025-12-02 18:41:26,326:INFO:            requests: 2.32.5
2025-12-02 18:41:26,326:INFO:          matplotlib: 3.7.5
2025-12-02 18:41:26,326:INFO:          scikitplot: 0.3.7
2025-12-02 18:41:26,326:INFO:         yellowbrick: 1.5
2025-12-02 18:41:26,326:INFO:              plotly: 5.24.1
2025-12-02 18:41:26,326:INFO:    plotly-resampler: Not installed
2025-12-02 18:41:26,326:INFO:             kaleido: 1.2.0
2025-12-02 18:41:26,326:INFO:           schemdraw: 0.15
2025-12-02 18:41:26,326:INFO:         statsmodels: 0.14.5
2025-12-02 18:41:26,326:INFO:              sktime: 0.26.0
2025-12-02 18:41:26,326:INFO:               tbats: 1.1.3
2025-12-02 18:41:26,326:INFO:            pmdarima: 2.0.4
2025-12-02 18:41:26,326:INFO:              psutil: 7.1.3
2025-12-02 18:41:26,326:INFO:          markupsafe: 3.0.3
2025-12-02 18:41:26,326:INFO:             pickle5: Not installed
2025-12-02 18:41:26,326:INFO:         cloudpickle: 3.1.2
2025-12-02 18:41:26,326:INFO:         deprecation: 2.1.0
2025-12-02 18:41:26,326:INFO:              xxhash: 3.6.0
2025-12-02 18:41:26,326:INFO:           wurlitzer: Not installed
2025-12-02 18:41:26,326:INFO:PyCaret optional dependencies:
2025-12-02 18:41:29,120:INFO:                shap: 0.49.1
2025-12-02 18:41:29,120:INFO:           interpret: 0.7.3
2025-12-02 18:41:29,120:INFO:                umap: 0.5.7
2025-12-02 18:41:29,120:INFO:     ydata_profiling: 4.18.0
2025-12-02 18:41:29,120:INFO:  explainerdashboard: 0.5.1
2025-12-02 18:41:29,120:INFO:             autoviz: Not installed
2025-12-02 18:41:29,120:INFO:           fairlearn: 0.7.0
2025-12-02 18:41:29,120:INFO:          deepchecks: Not installed
2025-12-02 18:41:29,120:INFO:             xgboost: 2.1.3
2025-12-02 18:41:29,120:INFO:            catboost: 1.2.8
2025-12-02 18:41:29,120:INFO:              kmodes: 0.12.2
2025-12-02 18:41:29,120:INFO:             mlxtend: 0.23.4
2025-12-02 18:41:29,120:INFO:       statsforecast: 1.5.0
2025-12-02 18:41:29,120:INFO:        tune_sklearn: Not installed
2025-12-02 18:41:29,120:INFO:                 ray: Not installed
2025-12-02 18:41:29,120:INFO:            hyperopt: 0.2.7
2025-12-02 18:41:29,120:INFO:              optuna: 4.6.0
2025-12-02 18:41:29,120:INFO:               skopt: 0.10.2
2025-12-02 18:41:29,120:INFO:              mlflow: 3.6.0
2025-12-02 18:41:29,120:INFO:              gradio: 6.0.1
2025-12-02 18:41:29,120:INFO:             fastapi: 0.123.0
2025-12-02 18:41:29,120:INFO:             uvicorn: 0.38.0
2025-12-02 18:41:29,120:INFO:              m2cgen: 0.10.0
2025-12-02 18:41:29,120:INFO:           evidently: 0.4.40
2025-12-02 18:41:29,120:INFO:               fugue: 0.8.7
2025-12-02 18:41:29,120:INFO:           streamlit: 1.51.0
2025-12-02 18:41:29,120:INFO:             prophet: Not installed
2025-12-02 18:41:29,120:INFO:None
2025-12-02 18:41:29,120:INFO:Set up data.
2025-12-02 18:41:29,136:INFO:Set up folding strategy.
2025-12-02 18:41:29,136:INFO:Set up train/test split.
2025-12-02 18:41:29,160:INFO:Set up index.
2025-12-02 18:41:29,160:INFO:Assigning column types.
2025-12-02 18:41:29,182:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-12-02 18:41:29,206:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-12-02 18:41:29,209:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-02 18:41:29,227:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-02 18:41:29,231:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-02 18:41:29,278:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-12-02 18:41:29,278:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-02 18:41:29,292:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-02 18:41:29,297:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-02 18:41:29,297:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-12-02 18:41:29,322:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-02 18:41:29,337:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-02 18:41:29,340:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-02 18:41:29,366:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-02 18:41:29,381:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-02 18:41:29,381:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-02 18:41:29,381:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-12-02 18:41:29,423:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-02 18:41:29,426:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-02 18:41:29,465:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-02 18:41:29,470:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-02 18:41:29,472:INFO:Preparing preprocessing pipeline...
2025-12-02 18:41:29,476:INFO:Set up simple imputation.
2025-12-02 18:41:29,486:INFO:Set up encoding of ordinal features.
2025-12-02 18:41:29,492:INFO:Set up encoding of categorical features.
2025-12-02 18:41:29,492:INFO:Set up feature normalization.
2025-12-02 18:41:29,651:INFO:Finished creating preprocessing pipeline.
2025-12-02 18:41:29,664:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\OMAR\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'IncomeRatio', 'SystolicBP',
                                             'BMI', 'WaistCircumference',
                                             'Height', 'TotalCholesterol',
                                             'Triglycerides', 'LDL', 'HDL',
                                             'HbA1c', 'Glucose', 'Creatinine',
                                             'UricAcid', 'ALT_Enzyme',
                                             'Albumin', 'Potassium', 'Sodium',
                                             'G...
                                    transformer=TargetEncoder(cols=[],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=RobustScaler(copy=True,
                                                             quantile_range=(25.0,
                                                                             75.0),
                                                             unit_variance=False,
                                                             with_centering=True,
                                                             with_scaling=True)))],
         verbose=False)
2025-12-02 18:41:29,664:INFO:Creating final display dataframe.
2025-12-02 18:41:29,880:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target      HeartDisease
2                   Target type            Binary
3           Original data shape       (43695, 28)
4        Transformed data shape       (43695, 32)
5   Transformed train set shape       (30586, 32)
6    Transformed test set shape       (13109, 32)
7              Numeric features                20
8          Categorical features                 7
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15                    Normalize              True
16             Normalize method            robust
17               Fold Generator   StratifiedKFold
18                  Fold Number                10
19                     CPU Jobs                 1
20                      Use GPU             False
21               Log Experiment             False
22              Experiment Name  clf-default-name
23                          USI              9a99
2025-12-02 18:41:29,929:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-02 18:41:29,932:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-02 18:41:29,976:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-02 18:41:29,977:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-02 18:41:29,980:INFO:setup() successfully completed in 4.23s...............
2025-12-02 18:41:35,508:INFO:Initializing get_config()
2025-12-02 18:41:35,510:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E1DA10EB30>, variable=y_train)
2025-12-02 18:41:35,510:INFO:Variable: 'y_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_train_transformed' instead.
2025-12-02 18:41:35,510:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_train_transformed' instead.

2025-12-02 18:41:35,520:INFO:Variable:  returned as 15208    0.0
25325    0.0
5132     0.0
17217    0.0
6382     0.0
        ... 
6265     0.0
42694    0.0
13399    0.0
39959    0.0
6616     0.0
Name: HeartDisease, Length: 30586, dtype: float32
2025-12-02 18:41:35,520:INFO:get_config() successfully completed......................................
2025-12-02 18:41:35,521:INFO:Initializing create_model()
2025-12-02 18:41:35,521:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E1DA10EB30>, estimator=xgboost, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={'scale_pos_weight': 76.32522407170295})
2025-12-02 18:41:35,521:INFO:Checking exceptions
2025-12-02 18:41:35,533:INFO:Importing libraries
2025-12-02 18:41:35,533:INFO:Copying training dataset
2025-12-02 18:41:35,562:INFO:Defining folds
2025-12-02 18:41:35,562:INFO:Declaring metric variables
2025-12-02 18:41:35,564:INFO:Importing untrained model
2025-12-02 18:41:35,567:INFO:Extreme Gradient Boosting Imported successfully
2025-12-02 18:41:35,571:INFO:Starting cross validation
2025-12-02 18:41:35,573:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-12-02 18:41:41,721:INFO:Calculating mean and std
2025-12-02 18:41:41,722:INFO:Creating metrics dataframe
2025-12-02 18:41:41,726:INFO:Finalizing model
2025-12-02 18:41:41,803:INFO:Warning: No categorical columns found. Calling 'transform' will only return input data.
2025-12-02 18:41:42,322:INFO:Uploading results into container
2025-12-02 18:41:42,323:INFO:Uploading model into container now
2025-12-02 18:41:42,331:INFO:_master_model_container: 1
2025-12-02 18:41:42,331:INFO:_display_container: 2
2025-12-02 18:41:42,331:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2025-12-02 18:41:42,331:INFO:create_model() successfully completed......................................
2025-12-02 18:41:49,545:INFO:Initializing create_model()
2025-12-02 18:41:49,545:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E1DA10EB30>, estimator=lr, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-02 18:41:49,545:INFO:Checking exceptions
2025-12-02 18:41:49,558:INFO:Importing libraries
2025-12-02 18:41:49,558:INFO:Copying training dataset
2025-12-02 18:41:49,585:INFO:Defining folds
2025-12-02 18:41:49,585:INFO:Declaring metric variables
2025-12-02 18:41:49,588:INFO:Importing untrained model
2025-12-02 18:41:49,590:INFO:Logistic Regression Imported successfully
2025-12-02 18:41:49,596:INFO:Starting cross validation
2025-12-02 18:41:49,599:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-12-02 18:41:50,580:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-12-02 18:41:51,164:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-12-02 18:41:51,551:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-12-02 18:41:51,556:INFO:Calculating mean and std
2025-12-02 18:41:51,559:INFO:Creating metrics dataframe
2025-12-02 18:41:51,562:INFO:Finalizing model
2025-12-02 18:41:51,642:INFO:Warning: No categorical columns found. Calling 'transform' will only return input data.
2025-12-02 18:41:51,748:INFO:Uploading results into container
2025-12-02 18:41:51,749:INFO:Uploading model into container now
2025-12-02 18:41:51,756:INFO:_master_model_container: 2
2025-12-02 18:41:51,756:INFO:_display_container: 3
2025-12-02 18:41:51,756:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-12-02 18:41:51,756:INFO:create_model() successfully completed......................................
2025-12-02 18:41:51,933:INFO:Initializing create_model()
2025-12-02 18:41:51,933:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E1DA10EB30>, estimator=rf, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-02 18:41:51,933:INFO:Checking exceptions
2025-12-02 18:41:51,947:INFO:Importing libraries
2025-12-02 18:41:51,948:INFO:Copying training dataset
2025-12-02 18:41:51,978:INFO:Defining folds
2025-12-02 18:41:51,978:INFO:Declaring metric variables
2025-12-02 18:41:51,981:INFO:Importing untrained model
2025-12-02 18:41:51,984:INFO:Random Forest Classifier Imported successfully
2025-12-02 18:41:51,988:INFO:Starting cross validation
2025-12-02 18:41:51,991:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-12-02 18:42:31,976:INFO:Calculating mean and std
2025-12-02 18:42:31,976:INFO:Creating metrics dataframe
2025-12-02 18:42:31,981:INFO:Finalizing model
2025-12-02 18:42:32,064:INFO:Warning: No categorical columns found. Calling 'transform' will only return input data.
2025-12-02 18:42:36,485:INFO:Uploading results into container
2025-12-02 18:42:36,485:INFO:Uploading model into container now
2025-12-02 18:42:36,492:INFO:_master_model_container: 3
2025-12-02 18:42:36,493:INFO:_display_container: 4
2025-12-02 18:42:36,493:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2025-12-02 18:42:36,493:INFO:create_model() successfully completed......................................
2025-12-02 18:43:00,535:INFO:Initializing get_config()
2025-12-02 18:43:00,535:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E1DA10EB30>, variable=X_train_transformed)
2025-12-02 18:43:00,571:INFO:Variable: X_train returned as             Age  IncomeRatio  SystolicBP       BMI  WaistCircumference  \
15208  0.954545     0.854789    0.359485  0.518044            0.206281   
25325 -0.272727     0.253271   -0.812170 -0.966167           -0.799656   
5132   0.181818    -0.407608   -0.372799  0.054886            0.319578   
17217  0.500000    -0.751898    0.013314 -0.260904            0.278379   
6382   0.568182     0.054503    1.131712  2.675938            1.888566   
...         ...          ...         ...       ...                 ...   
6265  -0.545455    -0.431352   -0.591719  0.191728           -0.377368   
42694 -0.022727    -0.221612   -0.892056 -0.260904           -0.047778   
13399  0.454545     0.388518    0.377985  0.271482            0.183567   
39959  0.954545    -0.193911    0.625770  0.991728            1.160720   
6616   0.613636    -0.447182    0.652399 -0.871430           -0.514698   

         Height  TotalCholesterol  Triglycerides       LDL       HDL  ...  \
15208 -0.487303          0.625876       0.583394  0.005397  0.314564  ...   
25325 -0.300856          0.033588      -0.261476  0.000256  0.303682  ...   
5132   0.766972          0.181594       0.479279  0.948690 -1.340476  ...   
17217  0.745785          0.227516       0.346113  0.002441 -0.274561  ...   
6382   0.237295          0.867515       0.635574  0.002754  0.829819  ...   
...         ...               ...            ...       ...       ...  ...   
6265  -1.737339         -1.393483      -0.471046 -3.840886  0.063832  ...   
42694  0.000000          0.029167      -0.131730  0.000893  0.063832  ...   
13399 -0.147405          0.462357       0.380371  0.003925  0.256949  ...   
39959  0.368655          1.528031       1.934134  0.011744  0.191497  ...   
6616  -0.021187         -0.224877      -0.043571 -1.609476  0.510658  ...   

       Race_5.0  Race_1.0  Race_4.0  Race_3.0  Race_2.0  Education  Smoking  \
15208       1.0       0.0       0.0       0.0       0.0  -0.659696      0.0   
25325       0.0       1.0       0.0       0.0       0.0   0.185278      0.0   
5132        0.0       1.0       0.0       0.0       0.0  -0.659696      1.0   
17217       0.0       0.0       1.0       0.0       0.0  -0.056119      1.0   
6382        0.0       0.0       1.0       0.0       0.0   0.547458      1.0   
...         ...       ...       ...       ...       ...        ...      ...   
6265        0.0       1.0       0.0       0.0       0.0  -0.769055      0.0   
42694       0.0       1.0       0.0       0.0       0.0   0.547458      0.0   
13399       0.0       0.0       1.0       0.0       0.0   0.547458      0.0   
39959       0.0       0.0       0.0       1.0       0.0   0.547458      0.0   
6616        0.0       0.0       0.0       1.0       0.0   0.547458      1.0   

       PhysicalActivity  HealthInsurance   Alcohol  
15208          0.000000              0.0 -0.886483  
25325          0.000000              0.0  0.592213  
5132           0.000000             -1.0  0.312949  
17217          0.000000              0.0  0.592213  
6382           0.000000              0.0  0.597293  
...                 ...              ...       ...  
6265           0.662459              0.0 -0.501621  
42694          0.000000             -1.0  0.592213  
13399          0.000000              0.0 -0.224534  
39959          0.000000              0.0  0.592213  
6616           0.000000              0.0  0.290247  

[30586 rows x 31 columns]
2025-12-02 18:43:00,571:INFO:get_config() successfully completed......................................
2025-12-02 18:43:00,571:INFO:Initializing get_config()
2025-12-02 18:43:00,571:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E1DA10EB30>, variable=y_train)
2025-12-02 18:43:00,572:INFO:Variable: 'y_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_train_transformed' instead.
2025-12-02 18:43:00,572:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_train_transformed' instead.

2025-12-02 18:43:00,579:INFO:Variable:  returned as 15208    0.0
25325    0.0
5132     0.0
17217    0.0
6382     0.0
        ... 
6265     0.0
42694    0.0
13399    0.0
39959    0.0
6616     0.0
Name: HeartDisease, Length: 30586, dtype: float32
2025-12-02 18:43:00,579:INFO:get_config() successfully completed......................................
2025-12-02 18:43:00,582:INFO:Initializing get_config()
2025-12-02 18:43:00,582:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E1DA10EB30>, variable=X_test_transformed)
2025-12-02 18:43:00,654:INFO:Variable: X_test returned as             Age  IncomeRatio  SystolicBP       BMI  WaistCircumference  \
28456 -0.477273    -0.304717   -0.519256 -0.987220           -0.923253   
8993   0.818182     0.253271    2.156910  0.770675            0.920394   
34312  0.704545     0.055403    0.519256  0.518044            0.662901   
4802  -0.545455     0.253730   -0.331933 -0.229036           -0.436352   
25895  0.704545     1.226781   -0.093200 -0.226100            0.012322   
...         ...          ...         ...       ...                 ...   
18045 -0.568182    -0.083104   -0.568713 -1.176693           -1.338674   
5425   0.590909     0.362732    2.210168  0.139096            0.292112   
12819  0.909091    -0.019787    0.899042  0.454886            0.971892   
33659 -0.522727     1.060572   -0.525683 -0.587220           -0.906087   
19531 -0.590909    -0.344290   -0.510287 -0.945114           -1.215078   

         Height  TotalCholesterol  Triglycerides       LDL       HDL  ...  \
28456 -1.080540         -0.078535      -0.470757 -0.026922  0.418008  ...   
8993  -0.279669          0.765897       0.705031  0.006026  0.446825  ...   
34312  0.559339         -0.123259       0.929511 -1.031826 -1.404309  ...   
4802  -0.504861         -0.188325      -0.322647  0.000015 -0.138743  ...   
25895  0.216731          0.892919       1.291109  0.008211 -0.255329  ...   
...         ...               ...            ...       ...       ...  ...   
18045 -2.080569         -0.340947      -0.470582 -0.848950  0.393794  ...   
5425   0.156785          0.435639      -0.065356  1.113733  0.127664  ...   
12819  1.194951         -0.732967      -0.470025 -0.211535 -1.085148  ...   
33659 -1.254274         -1.063225      -0.470958 -2.849419  0.127664  ...   
19531 -2.339052         -0.356898      -0.470595 -0.900608  0.393896  ...   

       Race_5.0  Race_1.0  Race_4.0  Race_3.0  Race_2.0  Education   Smoking  \
28456       1.0       0.0       0.0       0.0       0.0  -0.012820  0.000000   
8993        0.0       0.0       1.0       0.0       0.0   0.547458  1.000000   
34312       0.0       0.0       0.0       1.0       0.0  -0.659696  0.000000   
4802        1.0       0.0       0.0       0.0       0.0   0.262895  0.073612   
25895       0.0       0.0       0.0       1.0       0.0   1.151035  0.000000   
...         ...       ...       ...       ...       ...        ...       ...   
18045       0.0       0.0       0.0       1.0       0.0  -0.793202  0.000000   
5425        0.0       0.0       1.0       0.0       0.0   0.547458  1.000000   
12819       0.0       0.0       0.0       1.0       0.0   1.151035  1.000000   
33659       0.0       0.0       1.0       0.0       0.0   0.258362  0.000000   
19531       1.0       0.0       0.0       0.0       0.0  -0.821118  0.000000   

       PhysicalActivity  HealthInsurance   Alcohol  
28456          0.660578              0.0 -0.518600  
8993           0.000000              0.0  0.115329  
34312          0.000000              0.0  0.592213  
4802           1.012447              0.0 -0.103347  
25895          0.000000              0.0 -0.886483  
...                 ...              ...       ...  
18045          0.904383              0.0 -0.482716  
5425           1.598141              0.0  0.097790  
12819          1.598141              0.0  0.612947  
33659          1.162475              0.0 -0.154408  
19531          0.791302              0.0 -0.683278  

[13109 rows x 31 columns]
2025-12-02 18:43:00,654:INFO:get_config() successfully completed......................................
2025-12-02 18:43:00,654:INFO:Initializing get_config()
2025-12-02 18:43:00,654:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E1DA10EB30>, variable=y_test)
2025-12-02 18:43:00,654:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-12-02 18:43:00,654:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-12-02 18:43:00,660:INFO:Variable:  returned as 28456    0.0
8993     0.0
34312    0.0
4802     0.0
25895    0.0
        ... 
18045    0.0
5425     0.0
12819    0.0
33659    0.0
19531    0.0
Name: HeartDisease, Length: 13109, dtype: float32
2025-12-02 18:43:00,660:INFO:get_config() successfully completed......................................
2025-12-02 18:43:00,822:INFO:Initializing get_config()
2025-12-02 18:43:00,823:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E1DA10EB30>, variable=X_train_transformed)
2025-12-02 18:43:00,869:INFO:Variable: X_train returned as             Age  IncomeRatio  SystolicBP       BMI  WaistCircumference  \
15208  0.954545     0.854789    0.359485  0.518044            0.206281   
25325 -0.272727     0.253271   -0.812170 -0.966167           -0.799656   
5132   0.181818    -0.407608   -0.372799  0.054886            0.319578   
17217  0.500000    -0.751898    0.013314 -0.260904            0.278379   
6382   0.568182     0.054503    1.131712  2.675938            1.888566   
...         ...          ...         ...       ...                 ...   
6265  -0.545455    -0.431352   -0.591719  0.191728           -0.377368   
42694 -0.022727    -0.221612   -0.892056 -0.260904           -0.047778   
13399  0.454545     0.388518    0.377985  0.271482            0.183567   
39959  0.954545    -0.193911    0.625770  0.991728            1.160720   
6616   0.613636    -0.447182    0.652399 -0.871430           -0.514698   

         Height  TotalCholesterol  Triglycerides       LDL       HDL  ...  \
15208 -0.487303          0.625876       0.583394  0.005397  0.314564  ...   
25325 -0.300856          0.033588      -0.261476  0.000256  0.303682  ...   
5132   0.766972          0.181594       0.479279  0.948690 -1.340476  ...   
17217  0.745785          0.227516       0.346113  0.002441 -0.274561  ...   
6382   0.237295          0.867515       0.635574  0.002754  0.829819  ...   
...         ...               ...            ...       ...       ...  ...   
6265  -1.737339         -1.393483      -0.471046 -3.840886  0.063832  ...   
42694  0.000000          0.029167      -0.131730  0.000893  0.063832  ...   
13399 -0.147405          0.462357       0.380371  0.003925  0.256949  ...   
39959  0.368655          1.528031       1.934134  0.011744  0.191497  ...   
6616  -0.021187         -0.224877      -0.043571 -1.609476  0.510658  ...   

       Race_5.0  Race_1.0  Race_4.0  Race_3.0  Race_2.0  Education  Smoking  \
15208       1.0       0.0       0.0       0.0       0.0  -0.659696      0.0   
25325       0.0       1.0       0.0       0.0       0.0   0.185278      0.0   
5132        0.0       1.0       0.0       0.0       0.0  -0.659696      1.0   
17217       0.0       0.0       1.0       0.0       0.0  -0.056119      1.0   
6382        0.0       0.0       1.0       0.0       0.0   0.547458      1.0   
...         ...       ...       ...       ...       ...        ...      ...   
6265        0.0       1.0       0.0       0.0       0.0  -0.769055      0.0   
42694       0.0       1.0       0.0       0.0       0.0   0.547458      0.0   
13399       0.0       0.0       1.0       0.0       0.0   0.547458      0.0   
39959       0.0       0.0       0.0       1.0       0.0   0.547458      0.0   
6616        0.0       0.0       0.0       1.0       0.0   0.547458      1.0   

       PhysicalActivity  HealthInsurance   Alcohol  
15208          0.000000              0.0 -0.886483  
25325          0.000000              0.0  0.592213  
5132           0.000000             -1.0  0.312949  
17217          0.000000              0.0  0.592213  
6382           0.000000              0.0  0.597293  
...                 ...              ...       ...  
6265           0.662459              0.0 -0.501621  
42694          0.000000             -1.0  0.592213  
13399          0.000000              0.0 -0.224534  
39959          0.000000              0.0  0.592213  
6616           0.000000              0.0  0.290247  

[30586 rows x 31 columns]
2025-12-02 18:43:00,869:INFO:get_config() successfully completed......................................
2025-12-02 18:43:00,869:INFO:Initializing get_config()
2025-12-02 18:43:00,869:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E1DA10EB30>, variable=y_train)
2025-12-02 18:43:00,869:INFO:Variable: 'y_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_train_transformed' instead.
2025-12-02 18:43:00,869:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_train_transformed' instead.

2025-12-02 18:43:00,876:INFO:Variable:  returned as 15208    0.0
25325    0.0
5132     0.0
17217    0.0
6382     0.0
        ... 
6265     0.0
42694    0.0
13399    0.0
39959    0.0
6616     0.0
Name: HeartDisease, Length: 30586, dtype: float32
2025-12-02 18:43:00,876:INFO:get_config() successfully completed......................................
2025-12-02 18:43:00,877:INFO:Initializing get_config()
2025-12-02 18:43:00,877:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E1DA10EB30>, variable=X_test_transformed)
2025-12-02 18:43:00,951:INFO:Variable: X_test returned as             Age  IncomeRatio  SystolicBP       BMI  WaistCircumference  \
28456 -0.477273    -0.304717   -0.519256 -0.987220           -0.923253   
8993   0.818182     0.253271    2.156910  0.770675            0.920394   
34312  0.704545     0.055403    0.519256  0.518044            0.662901   
4802  -0.545455     0.253730   -0.331933 -0.229036           -0.436352   
25895  0.704545     1.226781   -0.093200 -0.226100            0.012322   
...         ...          ...         ...       ...                 ...   
18045 -0.568182    -0.083104   -0.568713 -1.176693           -1.338674   
5425   0.590909     0.362732    2.210168  0.139096            0.292112   
12819  0.909091    -0.019787    0.899042  0.454886            0.971892   
33659 -0.522727     1.060572   -0.525683 -0.587220           -0.906087   
19531 -0.590909    -0.344290   -0.510287 -0.945114           -1.215078   

         Height  TotalCholesterol  Triglycerides       LDL       HDL  ...  \
28456 -1.080540         -0.078535      -0.470757 -0.026922  0.418008  ...   
8993  -0.279669          0.765897       0.705031  0.006026  0.446825  ...   
34312  0.559339         -0.123259       0.929511 -1.031826 -1.404309  ...   
4802  -0.504861         -0.188325      -0.322647  0.000015 -0.138743  ...   
25895  0.216731          0.892919       1.291109  0.008211 -0.255329  ...   
...         ...               ...            ...       ...       ...  ...   
18045 -2.080569         -0.340947      -0.470582 -0.848950  0.393794  ...   
5425   0.156785          0.435639      -0.065356  1.113733  0.127664  ...   
12819  1.194951         -0.732967      -0.470025 -0.211535 -1.085148  ...   
33659 -1.254274         -1.063225      -0.470958 -2.849419  0.127664  ...   
19531 -2.339052         -0.356898      -0.470595 -0.900608  0.393896  ...   

       Race_5.0  Race_1.0  Race_4.0  Race_3.0  Race_2.0  Education   Smoking  \
28456       1.0       0.0       0.0       0.0       0.0  -0.012820  0.000000   
8993        0.0       0.0       1.0       0.0       0.0   0.547458  1.000000   
34312       0.0       0.0       0.0       1.0       0.0  -0.659696  0.000000   
4802        1.0       0.0       0.0       0.0       0.0   0.262895  0.073612   
25895       0.0       0.0       0.0       1.0       0.0   1.151035  0.000000   
...         ...       ...       ...       ...       ...        ...       ...   
18045       0.0       0.0       0.0       1.0       0.0  -0.793202  0.000000   
5425        0.0       0.0       1.0       0.0       0.0   0.547458  1.000000   
12819       0.0       0.0       0.0       1.0       0.0   1.151035  1.000000   
33659       0.0       0.0       1.0       0.0       0.0   0.258362  0.000000   
19531       1.0       0.0       0.0       0.0       0.0  -0.821118  0.000000   

       PhysicalActivity  HealthInsurance   Alcohol  
28456          0.660578              0.0 -0.518600  
8993           0.000000              0.0  0.115329  
34312          0.000000              0.0  0.592213  
4802           1.012447              0.0 -0.103347  
25895          0.000000              0.0 -0.886483  
...                 ...              ...       ...  
18045          0.904383              0.0 -0.482716  
5425           1.598141              0.0  0.097790  
12819          1.598141              0.0  0.612947  
33659          1.162475              0.0 -0.154408  
19531          0.791302              0.0 -0.683278  

[13109 rows x 31 columns]
2025-12-02 18:43:00,952:INFO:get_config() successfully completed......................................
2025-12-02 18:43:00,952:INFO:Initializing get_config()
2025-12-02 18:43:00,952:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E1DA10EB30>, variable=y_test)
2025-12-02 18:43:00,952:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-12-02 18:43:00,952:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-12-02 18:43:00,957:INFO:Variable:  returned as 28456    0.0
8993     0.0
34312    0.0
4802     0.0
25895    0.0
        ... 
18045    0.0
5425     0.0
12819    0.0
33659    0.0
19531    0.0
Name: HeartDisease, Length: 13109, dtype: float32
2025-12-02 18:43:00,957:INFO:get_config() successfully completed......................................
2025-12-02 18:43:01,092:INFO:Initializing get_config()
2025-12-02 18:43:01,092:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E1DA10EB30>, variable=X_test_transformed)
2025-12-02 18:43:01,173:INFO:Variable: X_test returned as             Age  IncomeRatio  SystolicBP       BMI  WaistCircumference  \
28456 -0.477273    -0.304717   -0.519256 -0.987220           -0.923253   
8993   0.818182     0.253271    2.156910  0.770675            0.920394   
34312  0.704545     0.055403    0.519256  0.518044            0.662901   
4802  -0.545455     0.253730   -0.331933 -0.229036           -0.436352   
25895  0.704545     1.226781   -0.093200 -0.226100            0.012322   
...         ...          ...         ...       ...                 ...   
18045 -0.568182    -0.083104   -0.568713 -1.176693           -1.338674   
5425   0.590909     0.362732    2.210168  0.139096            0.292112   
12819  0.909091    -0.019787    0.899042  0.454886            0.971892   
33659 -0.522727     1.060572   -0.525683 -0.587220           -0.906087   
19531 -0.590909    -0.344290   -0.510287 -0.945114           -1.215078   

         Height  TotalCholesterol  Triglycerides       LDL       HDL  ...  \
28456 -1.080540         -0.078535      -0.470757 -0.026922  0.418008  ...   
8993  -0.279669          0.765897       0.705031  0.006026  0.446825  ...   
34312  0.559339         -0.123259       0.929511 -1.031826 -1.404309  ...   
4802  -0.504861         -0.188325      -0.322647  0.000015 -0.138743  ...   
25895  0.216731          0.892919       1.291109  0.008211 -0.255329  ...   
...         ...               ...            ...       ...       ...  ...   
18045 -2.080569         -0.340947      -0.470582 -0.848950  0.393794  ...   
5425   0.156785          0.435639      -0.065356  1.113733  0.127664  ...   
12819  1.194951         -0.732967      -0.470025 -0.211535 -1.085148  ...   
33659 -1.254274         -1.063225      -0.470958 -2.849419  0.127664  ...   
19531 -2.339052         -0.356898      -0.470595 -0.900608  0.393896  ...   

       Race_5.0  Race_1.0  Race_4.0  Race_3.0  Race_2.0  Education   Smoking  \
28456       1.0       0.0       0.0       0.0       0.0  -0.012820  0.000000   
8993        0.0       0.0       1.0       0.0       0.0   0.547458  1.000000   
34312       0.0       0.0       0.0       1.0       0.0  -0.659696  0.000000   
4802        1.0       0.0       0.0       0.0       0.0   0.262895  0.073612   
25895       0.0       0.0       0.0       1.0       0.0   1.151035  0.000000   
...         ...       ...       ...       ...       ...        ...       ...   
18045       0.0       0.0       0.0       1.0       0.0  -0.793202  0.000000   
5425        0.0       0.0       1.0       0.0       0.0   0.547458  1.000000   
12819       0.0       0.0       0.0       1.0       0.0   1.151035  1.000000   
33659       0.0       0.0       1.0       0.0       0.0   0.258362  0.000000   
19531       1.0       0.0       0.0       0.0       0.0  -0.821118  0.000000   

       PhysicalActivity  HealthInsurance   Alcohol  
28456          0.660578              0.0 -0.518600  
8993           0.000000              0.0  0.115329  
34312          0.000000              0.0  0.592213  
4802           1.012447              0.0 -0.103347  
25895          0.000000              0.0 -0.886483  
...                 ...              ...       ...  
18045          0.904383              0.0 -0.482716  
5425           1.598141              0.0  0.097790  
12819          1.598141              0.0  0.612947  
33659          1.162475              0.0 -0.154408  
19531          0.791302              0.0 -0.683278  

[13109 rows x 31 columns]
2025-12-02 18:43:01,174:INFO:get_config() successfully completed......................................
2025-12-02 18:43:01,201:INFO:Initializing get_config()
2025-12-02 18:43:01,201:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E1DA10EB30>, variable=y_test)
2025-12-02 18:43:01,201:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-12-02 18:43:01,201:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-12-02 18:43:01,207:INFO:Variable:  returned as 28456    0.0
8993     0.0
34312    0.0
4802     0.0
25895    0.0
        ... 
18045    0.0
5425     0.0
12819    0.0
33659    0.0
19531    0.0
Name: HeartDisease, Length: 13109, dtype: float32
2025-12-02 18:43:01,207:INFO:get_config() successfully completed......................................
2025-12-02 18:43:01,210:INFO:Initializing get_config()
2025-12-02 18:43:01,210:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E1DA10EB30>, variable=y_test)
2025-12-02 18:43:01,210:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-12-02 18:43:01,210:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-12-02 18:43:01,215:INFO:Variable:  returned as 28456    0.0
8993     0.0
34312    0.0
4802     0.0
25895    0.0
        ... 
18045    0.0
5425     0.0
12819    0.0
33659    0.0
19531    0.0
Name: HeartDisease, Length: 13109, dtype: float32
2025-12-02 18:43:01,215:INFO:get_config() successfully completed......................................
2025-12-02 18:43:01,217:INFO:Initializing get_config()
2025-12-02 18:43:01,217:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E1DA10EB30>, variable=X_test_transformed)
2025-12-02 18:43:01,287:INFO:Variable: X_test returned as             Age  IncomeRatio  SystolicBP       BMI  WaistCircumference  \
28456 -0.477273    -0.304717   -0.519256 -0.987220           -0.923253   
8993   0.818182     0.253271    2.156910  0.770675            0.920394   
34312  0.704545     0.055403    0.519256  0.518044            0.662901   
4802  -0.545455     0.253730   -0.331933 -0.229036           -0.436352   
25895  0.704545     1.226781   -0.093200 -0.226100            0.012322   
...         ...          ...         ...       ...                 ...   
18045 -0.568182    -0.083104   -0.568713 -1.176693           -1.338674   
5425   0.590909     0.362732    2.210168  0.139096            0.292112   
12819  0.909091    -0.019787    0.899042  0.454886            0.971892   
33659 -0.522727     1.060572   -0.525683 -0.587220           -0.906087   
19531 -0.590909    -0.344290   -0.510287 -0.945114           -1.215078   

         Height  TotalCholesterol  Triglycerides       LDL       HDL  ...  \
28456 -1.080540         -0.078535      -0.470757 -0.026922  0.418008  ...   
8993  -0.279669          0.765897       0.705031  0.006026  0.446825  ...   
34312  0.559339         -0.123259       0.929511 -1.031826 -1.404309  ...   
4802  -0.504861         -0.188325      -0.322647  0.000015 -0.138743  ...   
25895  0.216731          0.892919       1.291109  0.008211 -0.255329  ...   
...         ...               ...            ...       ...       ...  ...   
18045 -2.080569         -0.340947      -0.470582 -0.848950  0.393794  ...   
5425   0.156785          0.435639      -0.065356  1.113733  0.127664  ...   
12819  1.194951         -0.732967      -0.470025 -0.211535 -1.085148  ...   
33659 -1.254274         -1.063225      -0.470958 -2.849419  0.127664  ...   
19531 -2.339052         -0.356898      -0.470595 -0.900608  0.393896  ...   

       Race_5.0  Race_1.0  Race_4.0  Race_3.0  Race_2.0  Education   Smoking  \
28456       1.0       0.0       0.0       0.0       0.0  -0.012820  0.000000   
8993        0.0       0.0       1.0       0.0       0.0   0.547458  1.000000   
34312       0.0       0.0       0.0       1.0       0.0  -0.659696  0.000000   
4802        1.0       0.0       0.0       0.0       0.0   0.262895  0.073612   
25895       0.0       0.0       0.0       1.0       0.0   1.151035  0.000000   
...         ...       ...       ...       ...       ...        ...       ...   
18045       0.0       0.0       0.0       1.0       0.0  -0.793202  0.000000   
5425        0.0       0.0       1.0       0.0       0.0   0.547458  1.000000   
12819       0.0       0.0       0.0       1.0       0.0   1.151035  1.000000   
33659       0.0       0.0       1.0       0.0       0.0   0.258362  0.000000   
19531       1.0       0.0       0.0       0.0       0.0  -0.821118  0.000000   

       PhysicalActivity  HealthInsurance   Alcohol  
28456          0.660578              0.0 -0.518600  
8993           0.000000              0.0  0.115329  
34312          0.000000              0.0  0.592213  
4802           1.012447              0.0 -0.103347  
25895          0.000000              0.0 -0.886483  
...                 ...              ...       ...  
18045          0.904383              0.0 -0.482716  
5425           1.598141              0.0  0.097790  
12819          1.598141              0.0  0.612947  
33659          1.162475              0.0 -0.154408  
19531          0.791302              0.0 -0.683278  

[13109 rows x 31 columns]
2025-12-02 18:43:01,287:INFO:get_config() successfully completed......................................
2025-12-02 18:43:01,292:INFO:Initializing get_config()
2025-12-02 18:43:01,292:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E1DA10EB30>, variable=y_test)
2025-12-02 18:43:01,292:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-12-02 18:43:01,292:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-12-02 18:43:01,297:INFO:Variable:  returned as 28456    0.0
8993     0.0
34312    0.0
4802     0.0
25895    0.0
        ... 
18045    0.0
5425     0.0
12819    0.0
33659    0.0
19531    0.0
Name: HeartDisease, Length: 13109, dtype: float32
2025-12-02 18:43:01,297:INFO:get_config() successfully completed......................................
2025-12-02 18:43:01,300:INFO:Initializing get_config()
2025-12-02 18:43:01,300:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E1DA10EB30>, variable=y_test)
2025-12-02 18:43:01,300:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-12-02 18:43:01,300:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-12-02 18:43:01,305:INFO:Variable:  returned as 28456    0.0
8993     0.0
34312    0.0
4802     0.0
25895    0.0
        ... 
18045    0.0
5425     0.0
12819    0.0
33659    0.0
19531    0.0
Name: HeartDisease, Length: 13109, dtype: float32
2025-12-02 18:43:01,306:INFO:get_config() successfully completed......................................
2025-12-02 18:43:01,308:INFO:Initializing get_config()
2025-12-02 18:43:01,308:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E1DA10EB30>, variable=X_test_transformed)
2025-12-02 18:43:01,410:INFO:Variable: X_test returned as             Age  IncomeRatio  SystolicBP       BMI  WaistCircumference  \
28456 -0.477273    -0.304717   -0.519256 -0.987220           -0.923253   
8993   0.818182     0.253271    2.156910  0.770675            0.920394   
34312  0.704545     0.055403    0.519256  0.518044            0.662901   
4802  -0.545455     0.253730   -0.331933 -0.229036           -0.436352   
25895  0.704545     1.226781   -0.093200 -0.226100            0.012322   
...         ...          ...         ...       ...                 ...   
18045 -0.568182    -0.083104   -0.568713 -1.176693           -1.338674   
5425   0.590909     0.362732    2.210168  0.139096            0.292112   
12819  0.909091    -0.019787    0.899042  0.454886            0.971892   
33659 -0.522727     1.060572   -0.525683 -0.587220           -0.906087   
19531 -0.590909    -0.344290   -0.510287 -0.945114           -1.215078   

         Height  TotalCholesterol  Triglycerides       LDL       HDL  ...  \
28456 -1.080540         -0.078535      -0.470757 -0.026922  0.418008  ...   
8993  -0.279669          0.765897       0.705031  0.006026  0.446825  ...   
34312  0.559339         -0.123259       0.929511 -1.031826 -1.404309  ...   
4802  -0.504861         -0.188325      -0.322647  0.000015 -0.138743  ...   
25895  0.216731          0.892919       1.291109  0.008211 -0.255329  ...   
...         ...               ...            ...       ...       ...  ...   
18045 -2.080569         -0.340947      -0.470582 -0.848950  0.393794  ...   
5425   0.156785          0.435639      -0.065356  1.113733  0.127664  ...   
12819  1.194951         -0.732967      -0.470025 -0.211535 -1.085148  ...   
33659 -1.254274         -1.063225      -0.470958 -2.849419  0.127664  ...   
19531 -2.339052         -0.356898      -0.470595 -0.900608  0.393896  ...   

       Race_5.0  Race_1.0  Race_4.0  Race_3.0  Race_2.0  Education   Smoking  \
28456       1.0       0.0       0.0       0.0       0.0  -0.012820  0.000000   
8993        0.0       0.0       1.0       0.0       0.0   0.547458  1.000000   
34312       0.0       0.0       0.0       1.0       0.0  -0.659696  0.000000   
4802        1.0       0.0       0.0       0.0       0.0   0.262895  0.073612   
25895       0.0       0.0       0.0       1.0       0.0   1.151035  0.000000   
...         ...       ...       ...       ...       ...        ...       ...   
18045       0.0       0.0       0.0       1.0       0.0  -0.793202  0.000000   
5425        0.0       0.0       1.0       0.0       0.0   0.547458  1.000000   
12819       0.0       0.0       0.0       1.0       0.0   1.151035  1.000000   
33659       0.0       0.0       1.0       0.0       0.0   0.258362  0.000000   
19531       1.0       0.0       0.0       0.0       0.0  -0.821118  0.000000   

       PhysicalActivity  HealthInsurance   Alcohol  
28456          0.660578              0.0 -0.518600  
8993           0.000000              0.0  0.115329  
34312          0.000000              0.0  0.592213  
4802           1.012447              0.0 -0.103347  
25895          0.000000              0.0 -0.886483  
...                 ...              ...       ...  
18045          0.904383              0.0 -0.482716  
5425           1.598141              0.0  0.097790  
12819          1.598141              0.0  0.612947  
33659          1.162475              0.0 -0.154408  
19531          0.791302              0.0 -0.683278  

[13109 rows x 31 columns]
2025-12-02 18:43:01,410:INFO:get_config() successfully completed......................................
2025-12-02 18:43:01,464:INFO:Initializing get_config()
2025-12-02 18:43:01,464:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E1DA10EB30>, variable=y_test)
2025-12-02 18:43:01,464:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-12-02 18:43:01,464:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-12-02 18:43:01,472:INFO:Variable:  returned as 28456    0.0
8993     0.0
34312    0.0
4802     0.0
25895    0.0
        ... 
18045    0.0
5425     0.0
12819    0.0
33659    0.0
19531    0.0
Name: HeartDisease, Length: 13109, dtype: float32
2025-12-02 18:43:01,472:INFO:get_config() successfully completed......................................
2025-12-02 18:43:01,475:INFO:Initializing get_config()
2025-12-02 18:43:01,475:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E1DA10EB30>, variable=y_test)
2025-12-02 18:43:01,475:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-12-02 18:43:01,475:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-12-02 18:43:01,479:INFO:Variable:  returned as 28456    0.0
8993     0.0
34312    0.0
4802     0.0
25895    0.0
        ... 
18045    0.0
5425     0.0
12819    0.0
33659    0.0
19531    0.0
Name: HeartDisease, Length: 13109, dtype: float32
2025-12-02 18:43:01,479:INFO:get_config() successfully completed......................................
2025-12-02 18:43:05,251:INFO:Initializing plot_model()
2025-12-02 18:43:05,251:INFO:plot_model(plot=error, fold=None, verbose=True, display=None, display_format=None, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E1DA10EB30>, system=True)
2025-12-02 18:43:05,251:INFO:Checking exceptions
2025-12-02 18:43:05,271:INFO:Preloading libraries
2025-12-02 18:43:05,276:INFO:Copying training dataset
2025-12-02 18:43:05,276:INFO:Plot type: error
2025-12-02 18:43:05,491:INFO:Fitting Model
2025-12-02 18:43:05,492:INFO:Scoring test/hold-out set
2025-12-02 18:43:05,665:INFO:Visual Rendered Successfully
2025-12-02 18:43:05,831:INFO:plot_model() successfully completed......................................
2025-12-02 18:43:10,135:INFO:Initializing get_config()
2025-12-02 18:43:10,135:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E1DA10EB30>, variable=X_test_transformed)
2025-12-02 18:43:10,215:INFO:Variable: X_test returned as             Age  IncomeRatio  SystolicBP       BMI  WaistCircumference  \
28456 -0.477273    -0.304717   -0.519256 -0.987220           -0.923253   
8993   0.818182     0.253271    2.156910  0.770675            0.920394   
34312  0.704545     0.055403    0.519256  0.518044            0.662901   
4802  -0.545455     0.253730   -0.331933 -0.229036           -0.436352   
25895  0.704545     1.226781   -0.093200 -0.226100            0.012322   
...         ...          ...         ...       ...                 ...   
18045 -0.568182    -0.083104   -0.568713 -1.176693           -1.338674   
5425   0.590909     0.362732    2.210168  0.139096            0.292112   
12819  0.909091    -0.019787    0.899042  0.454886            0.971892   
33659 -0.522727     1.060572   -0.525683 -0.587220           -0.906087   
19531 -0.590909    -0.344290   -0.510287 -0.945114           -1.215078   

         Height  TotalCholesterol  Triglycerides       LDL       HDL  ...  \
28456 -1.080540         -0.078535      -0.470757 -0.026922  0.418008  ...   
8993  -0.279669          0.765897       0.705031  0.006026  0.446825  ...   
34312  0.559339         -0.123259       0.929511 -1.031826 -1.404309  ...   
4802  -0.504861         -0.188325      -0.322647  0.000015 -0.138743  ...   
25895  0.216731          0.892919       1.291109  0.008211 -0.255329  ...   
...         ...               ...            ...       ...       ...  ...   
18045 -2.080569         -0.340947      -0.470582 -0.848950  0.393794  ...   
5425   0.156785          0.435639      -0.065356  1.113733  0.127664  ...   
12819  1.194951         -0.732967      -0.470025 -0.211535 -1.085148  ...   
33659 -1.254274         -1.063225      -0.470958 -2.849419  0.127664  ...   
19531 -2.339052         -0.356898      -0.470595 -0.900608  0.393896  ...   

       Race_5.0  Race_1.0  Race_4.0  Race_3.0  Race_2.0  Education   Smoking  \
28456       1.0       0.0       0.0       0.0       0.0  -0.012820  0.000000   
8993        0.0       0.0       1.0       0.0       0.0   0.547458  1.000000   
34312       0.0       0.0       0.0       1.0       0.0  -0.659696  0.000000   
4802        1.0       0.0       0.0       0.0       0.0   0.262895  0.073612   
25895       0.0       0.0       0.0       1.0       0.0   1.151035  0.000000   
...         ...       ...       ...       ...       ...        ...       ...   
18045       0.0       0.0       0.0       1.0       0.0  -0.793202  0.000000   
5425        0.0       0.0       1.0       0.0       0.0   0.547458  1.000000   
12819       0.0       0.0       0.0       1.0       0.0   1.151035  1.000000   
33659       0.0       0.0       1.0       0.0       0.0   0.258362  0.000000   
19531       1.0       0.0       0.0       0.0       0.0  -0.821118  0.000000   

       PhysicalActivity  HealthInsurance   Alcohol  
28456          0.660578              0.0 -0.518600  
8993           0.000000              0.0  0.115329  
34312          0.000000              0.0  0.592213  
4802           1.012447              0.0 -0.103347  
25895          0.000000              0.0 -0.886483  
...                 ...              ...       ...  
18045          0.904383              0.0 -0.482716  
5425           1.598141              0.0  0.097790  
12819          1.598141              0.0  0.612947  
33659          1.162475              0.0 -0.154408  
19531          0.791302              0.0 -0.683278  

[13109 rows x 31 columns]
2025-12-02 18:43:10,215:INFO:get_config() successfully completed......................................
2025-12-02 18:43:10,242:INFO:Initializing get_config()
2025-12-02 18:43:10,242:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E1DA10EB30>, variable=y_test)
2025-12-02 18:43:10,243:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-12-02 18:43:10,243:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-12-02 18:43:10,247:INFO:Variable:  returned as 28456    0.0
8993     0.0
34312    0.0
4802     0.0
25895    0.0
        ... 
18045    0.0
5425     0.0
12819    0.0
33659    0.0
19531    0.0
Name: HeartDisease, Length: 13109, dtype: float32
2025-12-02 18:43:10,247:INFO:get_config() successfully completed......................................
2025-12-02 18:43:10,248:INFO:Initializing get_config()
2025-12-02 18:43:10,248:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E1DA10EB30>, variable=y_test)
2025-12-02 18:43:10,248:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-12-02 18:43:10,248:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-12-02 18:43:10,252:INFO:Variable:  returned as 28456    0.0
8993     0.0
34312    0.0
4802     0.0
25895    0.0
        ... 
18045    0.0
5425     0.0
12819    0.0
33659    0.0
19531    0.0
Name: HeartDisease, Length: 13109, dtype: float32
2025-12-02 18:43:10,252:INFO:get_config() successfully completed......................................
2025-12-02 18:43:10,254:INFO:Initializing get_config()
2025-12-02 18:43:10,254:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E1DA10EB30>, variable=X_test_transformed)
2025-12-02 18:43:10,321:INFO:Variable: X_test returned as             Age  IncomeRatio  SystolicBP       BMI  WaistCircumference  \
28456 -0.477273    -0.304717   -0.519256 -0.987220           -0.923253   
8993   0.818182     0.253271    2.156910  0.770675            0.920394   
34312  0.704545     0.055403    0.519256  0.518044            0.662901   
4802  -0.545455     0.253730   -0.331933 -0.229036           -0.436352   
25895  0.704545     1.226781   -0.093200 -0.226100            0.012322   
...         ...          ...         ...       ...                 ...   
18045 -0.568182    -0.083104   -0.568713 -1.176693           -1.338674   
5425   0.590909     0.362732    2.210168  0.139096            0.292112   
12819  0.909091    -0.019787    0.899042  0.454886            0.971892   
33659 -0.522727     1.060572   -0.525683 -0.587220           -0.906087   
19531 -0.590909    -0.344290   -0.510287 -0.945114           -1.215078   

         Height  TotalCholesterol  Triglycerides       LDL       HDL  ...  \
28456 -1.080540         -0.078535      -0.470757 -0.026922  0.418008  ...   
8993  -0.279669          0.765897       0.705031  0.006026  0.446825  ...   
34312  0.559339         -0.123259       0.929511 -1.031826 -1.404309  ...   
4802  -0.504861         -0.188325      -0.322647  0.000015 -0.138743  ...   
25895  0.216731          0.892919       1.291109  0.008211 -0.255329  ...   
...         ...               ...            ...       ...       ...  ...   
18045 -2.080569         -0.340947      -0.470582 -0.848950  0.393794  ...   
5425   0.156785          0.435639      -0.065356  1.113733  0.127664  ...   
12819  1.194951         -0.732967      -0.470025 -0.211535 -1.085148  ...   
33659 -1.254274         -1.063225      -0.470958 -2.849419  0.127664  ...   
19531 -2.339052         -0.356898      -0.470595 -0.900608  0.393896  ...   

       Race_5.0  Race_1.0  Race_4.0  Race_3.0  Race_2.0  Education   Smoking  \
28456       1.0       0.0       0.0       0.0       0.0  -0.012820  0.000000   
8993        0.0       0.0       1.0       0.0       0.0   0.547458  1.000000   
34312       0.0       0.0       0.0       1.0       0.0  -0.659696  0.000000   
4802        1.0       0.0       0.0       0.0       0.0   0.262895  0.073612   
25895       0.0       0.0       0.0       1.0       0.0   1.151035  0.000000   
...         ...       ...       ...       ...       ...        ...       ...   
18045       0.0       0.0       0.0       1.0       0.0  -0.793202  0.000000   
5425        0.0       0.0       1.0       0.0       0.0   0.547458  1.000000   
12819       0.0       0.0       0.0       1.0       0.0   1.151035  1.000000   
33659       0.0       0.0       1.0       0.0       0.0   0.258362  0.000000   
19531       1.0       0.0       0.0       0.0       0.0  -0.821118  0.000000   

       PhysicalActivity  HealthInsurance   Alcohol  
28456          0.660578              0.0 -0.518600  
8993           0.000000              0.0  0.115329  
34312          0.000000              0.0  0.592213  
4802           1.012447              0.0 -0.103347  
25895          0.000000              0.0 -0.886483  
...                 ...              ...       ...  
18045          0.904383              0.0 -0.482716  
5425           1.598141              0.0  0.097790  
12819          1.598141              0.0  0.612947  
33659          1.162475              0.0 -0.154408  
19531          0.791302              0.0 -0.683278  

[13109 rows x 31 columns]
2025-12-02 18:43:10,321:INFO:get_config() successfully completed......................................
2025-12-02 18:43:10,323:INFO:Initializing get_config()
2025-12-02 18:43:10,323:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E1DA10EB30>, variable=y_test)
2025-12-02 18:43:10,323:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-12-02 18:43:10,323:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-12-02 18:43:10,329:INFO:Variable:  returned as 28456    0.0
8993     0.0
34312    0.0
4802     0.0
25895    0.0
        ... 
18045    0.0
5425     0.0
12819    0.0
33659    0.0
19531    0.0
Name: HeartDisease, Length: 13109, dtype: float32
2025-12-02 18:43:10,329:INFO:get_config() successfully completed......................................
2025-12-02 18:43:10,330:INFO:Initializing get_config()
2025-12-02 18:43:10,330:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E1DA10EB30>, variable=y_test)
2025-12-02 18:43:10,330:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-12-02 18:43:10,330:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-12-02 18:43:10,334:INFO:Variable:  returned as 28456    0.0
8993     0.0
34312    0.0
4802     0.0
25895    0.0
        ... 
18045    0.0
5425     0.0
12819    0.0
33659    0.0
19531    0.0
Name: HeartDisease, Length: 13109, dtype: float32
2025-12-02 18:43:10,334:INFO:get_config() successfully completed......................................
2025-12-02 18:43:10,336:INFO:Initializing get_config()
2025-12-02 18:43:10,336:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E1DA10EB30>, variable=X_test_transformed)
2025-12-02 18:43:10,411:INFO:Variable: X_test returned as             Age  IncomeRatio  SystolicBP       BMI  WaistCircumference  \
28456 -0.477273    -0.304717   -0.519256 -0.987220           -0.923253   
8993   0.818182     0.253271    2.156910  0.770675            0.920394   
34312  0.704545     0.055403    0.519256  0.518044            0.662901   
4802  -0.545455     0.253730   -0.331933 -0.229036           -0.436352   
25895  0.704545     1.226781   -0.093200 -0.226100            0.012322   
...         ...          ...         ...       ...                 ...   
18045 -0.568182    -0.083104   -0.568713 -1.176693           -1.338674   
5425   0.590909     0.362732    2.210168  0.139096            0.292112   
12819  0.909091    -0.019787    0.899042  0.454886            0.971892   
33659 -0.522727     1.060572   -0.525683 -0.587220           -0.906087   
19531 -0.590909    -0.344290   -0.510287 -0.945114           -1.215078   

         Height  TotalCholesterol  Triglycerides       LDL       HDL  ...  \
28456 -1.080540         -0.078535      -0.470757 -0.026922  0.418008  ...   
8993  -0.279669          0.765897       0.705031  0.006026  0.446825  ...   
34312  0.559339         -0.123259       0.929511 -1.031826 -1.404309  ...   
4802  -0.504861         -0.188325      -0.322647  0.000015 -0.138743  ...   
25895  0.216731          0.892919       1.291109  0.008211 -0.255329  ...   
...         ...               ...            ...       ...       ...  ...   
18045 -2.080569         -0.340947      -0.470582 -0.848950  0.393794  ...   
5425   0.156785          0.435639      -0.065356  1.113733  0.127664  ...   
12819  1.194951         -0.732967      -0.470025 -0.211535 -1.085148  ...   
33659 -1.254274         -1.063225      -0.470958 -2.849419  0.127664  ...   
19531 -2.339052         -0.356898      -0.470595 -0.900608  0.393896  ...   

       Race_5.0  Race_1.0  Race_4.0  Race_3.0  Race_2.0  Education   Smoking  \
28456       1.0       0.0       0.0       0.0       0.0  -0.012820  0.000000   
8993        0.0       0.0       1.0       0.0       0.0   0.547458  1.000000   
34312       0.0       0.0       0.0       1.0       0.0  -0.659696  0.000000   
4802        1.0       0.0       0.0       0.0       0.0   0.262895  0.073612   
25895       0.0       0.0       0.0       1.0       0.0   1.151035  0.000000   
...         ...       ...       ...       ...       ...        ...       ...   
18045       0.0       0.0       0.0       1.0       0.0  -0.793202  0.000000   
5425        0.0       0.0       1.0       0.0       0.0   0.547458  1.000000   
12819       0.0       0.0       0.0       1.0       0.0   1.151035  1.000000   
33659       0.0       0.0       1.0       0.0       0.0   0.258362  0.000000   
19531       1.0       0.0       0.0       0.0       0.0  -0.821118  0.000000   

       PhysicalActivity  HealthInsurance   Alcohol  
28456          0.660578              0.0 -0.518600  
8993           0.000000              0.0  0.115329  
34312          0.000000              0.0  0.592213  
4802           1.012447              0.0 -0.103347  
25895          0.000000              0.0 -0.886483  
...                 ...              ...       ...  
18045          0.904383              0.0 -0.482716  
5425           1.598141              0.0  0.097790  
12819          1.598141              0.0  0.612947  
33659          1.162475              0.0 -0.154408  
19531          0.791302              0.0 -0.683278  

[13109 rows x 31 columns]
2025-12-02 18:43:10,411:INFO:get_config() successfully completed......................................
2025-12-02 18:43:10,468:INFO:Initializing get_config()
2025-12-02 18:43:10,470:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E1DA10EB30>, variable=y_test)
2025-12-02 18:43:10,470:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-12-02 18:43:10,470:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-12-02 18:43:10,473:INFO:Variable:  returned as 28456    0.0
8993     0.0
34312    0.0
4802     0.0
25895    0.0
        ... 
18045    0.0
5425     0.0
12819    0.0
33659    0.0
19531    0.0
Name: HeartDisease, Length: 13109, dtype: float32
2025-12-02 18:43:10,473:INFO:get_config() successfully completed......................................
2025-12-02 18:43:10,476:INFO:Initializing get_config()
2025-12-02 18:43:10,476:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E1DA10EB30>, variable=y_test)
2025-12-02 18:43:10,476:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-12-02 18:43:10,476:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-12-02 18:43:10,482:INFO:Variable:  returned as 28456    0.0
8993     0.0
34312    0.0
4802     0.0
25895    0.0
        ... 
18045    0.0
5425     0.0
12819    0.0
33659    0.0
19531    0.0
Name: HeartDisease, Length: 13109, dtype: float32
2025-12-02 18:43:10,482:INFO:get_config() successfully completed......................................
2025-12-02 18:43:10,576:INFO:Initializing get_config()
2025-12-02 18:43:10,576:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E1DA10EB30>, variable=X_test_transformed)
2025-12-02 18:43:10,681:INFO:Variable: X_test returned as             Age  IncomeRatio  SystolicBP       BMI  WaistCircumference  \
28456 -0.477273    -0.304717   -0.519256 -0.987220           -0.923253   
8993   0.818182     0.253271    2.156910  0.770675            0.920394   
34312  0.704545     0.055403    0.519256  0.518044            0.662901   
4802  -0.545455     0.253730   -0.331933 -0.229036           -0.436352   
25895  0.704545     1.226781   -0.093200 -0.226100            0.012322   
...         ...          ...         ...       ...                 ...   
18045 -0.568182    -0.083104   -0.568713 -1.176693           -1.338674   
5425   0.590909     0.362732    2.210168  0.139096            0.292112   
12819  0.909091    -0.019787    0.899042  0.454886            0.971892   
33659 -0.522727     1.060572   -0.525683 -0.587220           -0.906087   
19531 -0.590909    -0.344290   -0.510287 -0.945114           -1.215078   

         Height  TotalCholesterol  Triglycerides       LDL       HDL  ...  \
28456 -1.080540         -0.078535      -0.470757 -0.026922  0.418008  ...   
8993  -0.279669          0.765897       0.705031  0.006026  0.446825  ...   
34312  0.559339         -0.123259       0.929511 -1.031826 -1.404309  ...   
4802  -0.504861         -0.188325      -0.322647  0.000015 -0.138743  ...   
25895  0.216731          0.892919       1.291109  0.008211 -0.255329  ...   
...         ...               ...            ...       ...       ...  ...   
18045 -2.080569         -0.340947      -0.470582 -0.848950  0.393794  ...   
5425   0.156785          0.435639      -0.065356  1.113733  0.127664  ...   
12819  1.194951         -0.732967      -0.470025 -0.211535 -1.085148  ...   
33659 -1.254274         -1.063225      -0.470958 -2.849419  0.127664  ...   
19531 -2.339052         -0.356898      -0.470595 -0.900608  0.393896  ...   

       Race_5.0  Race_1.0  Race_4.0  Race_3.0  Race_2.0  Education   Smoking  \
28456       1.0       0.0       0.0       0.0       0.0  -0.012820  0.000000   
8993        0.0       0.0       1.0       0.0       0.0   0.547458  1.000000   
34312       0.0       0.0       0.0       1.0       0.0  -0.659696  0.000000   
4802        1.0       0.0       0.0       0.0       0.0   0.262895  0.073612   
25895       0.0       0.0       0.0       1.0       0.0   1.151035  0.000000   
...         ...       ...       ...       ...       ...        ...       ...   
18045       0.0       0.0       0.0       1.0       0.0  -0.793202  0.000000   
5425        0.0       0.0       1.0       0.0       0.0   0.547458  1.000000   
12819       0.0       0.0       0.0       1.0       0.0   1.151035  1.000000   
33659       0.0       0.0       1.0       0.0       0.0   0.258362  0.000000   
19531       1.0       0.0       0.0       0.0       0.0  -0.821118  0.000000   

       PhysicalActivity  HealthInsurance   Alcohol  
28456          0.660578              0.0 -0.518600  
8993           0.000000              0.0  0.115329  
34312          0.000000              0.0  0.592213  
4802           1.012447              0.0 -0.103347  
25895          0.000000              0.0 -0.886483  
...                 ...              ...       ...  
18045          0.904383              0.0 -0.482716  
5425           1.598141              0.0  0.097790  
12819          1.598141              0.0  0.612947  
33659          1.162475              0.0 -0.154408  
19531          0.791302              0.0 -0.683278  

[13109 rows x 31 columns]
2025-12-02 18:43:10,681:INFO:get_config() successfully completed......................................
2025-12-02 18:43:10,706:INFO:Initializing get_config()
2025-12-02 18:43:10,706:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E1DA10EB30>, variable=y_test)
2025-12-02 18:43:10,706:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-12-02 18:43:10,706:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-12-02 18:43:10,714:INFO:Variable:  returned as 28456    0.0
8993     0.0
34312    0.0
4802     0.0
25895    0.0
        ... 
18045    0.0
5425     0.0
12819    0.0
33659    0.0
19531    0.0
Name: HeartDisease, Length: 13109, dtype: float32
2025-12-02 18:43:10,714:INFO:get_config() successfully completed......................................
2025-12-02 18:43:10,715:INFO:Initializing get_config()
2025-12-02 18:43:10,715:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E1DA10EB30>, variable=X_test_transformed)
2025-12-02 18:43:10,787:INFO:Variable: X_test returned as             Age  IncomeRatio  SystolicBP       BMI  WaistCircumference  \
28456 -0.477273    -0.304717   -0.519256 -0.987220           -0.923253   
8993   0.818182     0.253271    2.156910  0.770675            0.920394   
34312  0.704545     0.055403    0.519256  0.518044            0.662901   
4802  -0.545455     0.253730   -0.331933 -0.229036           -0.436352   
25895  0.704545     1.226781   -0.093200 -0.226100            0.012322   
...         ...          ...         ...       ...                 ...   
18045 -0.568182    -0.083104   -0.568713 -1.176693           -1.338674   
5425   0.590909     0.362732    2.210168  0.139096            0.292112   
12819  0.909091    -0.019787    0.899042  0.454886            0.971892   
33659 -0.522727     1.060572   -0.525683 -0.587220           -0.906087   
19531 -0.590909    -0.344290   -0.510287 -0.945114           -1.215078   

         Height  TotalCholesterol  Triglycerides       LDL       HDL  ...  \
28456 -1.080540         -0.078535      -0.470757 -0.026922  0.418008  ...   
8993  -0.279669          0.765897       0.705031  0.006026  0.446825  ...   
34312  0.559339         -0.123259       0.929511 -1.031826 -1.404309  ...   
4802  -0.504861         -0.188325      -0.322647  0.000015 -0.138743  ...   
25895  0.216731          0.892919       1.291109  0.008211 -0.255329  ...   
...         ...               ...            ...       ...       ...  ...   
18045 -2.080569         -0.340947      -0.470582 -0.848950  0.393794  ...   
5425   0.156785          0.435639      -0.065356  1.113733  0.127664  ...   
12819  1.194951         -0.732967      -0.470025 -0.211535 -1.085148  ...   
33659 -1.254274         -1.063225      -0.470958 -2.849419  0.127664  ...   
19531 -2.339052         -0.356898      -0.470595 -0.900608  0.393896  ...   

       Race_5.0  Race_1.0  Race_4.0  Race_3.0  Race_2.0  Education   Smoking  \
28456       1.0       0.0       0.0       0.0       0.0  -0.012820  0.000000   
8993        0.0       0.0       1.0       0.0       0.0   0.547458  1.000000   
34312       0.0       0.0       0.0       1.0       0.0  -0.659696  0.000000   
4802        1.0       0.0       0.0       0.0       0.0   0.262895  0.073612   
25895       0.0       0.0       0.0       1.0       0.0   1.151035  0.000000   
...         ...       ...       ...       ...       ...        ...       ...   
18045       0.0       0.0       0.0       1.0       0.0  -0.793202  0.000000   
5425        0.0       0.0       1.0       0.0       0.0   0.547458  1.000000   
12819       0.0       0.0       0.0       1.0       0.0   1.151035  1.000000   
33659       0.0       0.0       1.0       0.0       0.0   0.258362  0.000000   
19531       1.0       0.0       0.0       0.0       0.0  -0.821118  0.000000   

       PhysicalActivity  HealthInsurance   Alcohol  
28456          0.660578              0.0 -0.518600  
8993           0.000000              0.0  0.115329  
34312          0.000000              0.0  0.592213  
4802           1.012447              0.0 -0.103347  
25895          0.000000              0.0 -0.886483  
...                 ...              ...       ...  
18045          0.904383              0.0 -0.482716  
5425           1.598141              0.0  0.097790  
12819          1.598141              0.0  0.612947  
33659          1.162475              0.0 -0.154408  
19531          0.791302              0.0 -0.683278  

[13109 rows x 31 columns]
2025-12-02 18:43:10,787:INFO:get_config() successfully completed......................................
2025-12-02 18:43:10,792:INFO:Initializing get_config()
2025-12-02 18:43:10,792:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E1DA10EB30>, variable=y_test)
2025-12-02 18:43:10,792:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-12-02 18:43:10,792:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-12-02 18:43:10,798:INFO:Variable:  returned as 28456    0.0
8993     0.0
34312    0.0
4802     0.0
25895    0.0
        ... 
18045    0.0
5425     0.0
12819    0.0
33659    0.0
19531    0.0
Name: HeartDisease, Length: 13109, dtype: float32
2025-12-02 18:43:10,798:INFO:get_config() successfully completed......................................
2025-12-02 18:43:10,799:INFO:Initializing get_config()
2025-12-02 18:43:10,799:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E1DA10EB30>, variable=X_test_transformed)
2025-12-02 18:43:10,878:INFO:Variable: X_test returned as             Age  IncomeRatio  SystolicBP       BMI  WaistCircumference  \
28456 -0.477273    -0.304717   -0.519256 -0.987220           -0.923253   
8993   0.818182     0.253271    2.156910  0.770675            0.920394   
34312  0.704545     0.055403    0.519256  0.518044            0.662901   
4802  -0.545455     0.253730   -0.331933 -0.229036           -0.436352   
25895  0.704545     1.226781   -0.093200 -0.226100            0.012322   
...         ...          ...         ...       ...                 ...   
18045 -0.568182    -0.083104   -0.568713 -1.176693           -1.338674   
5425   0.590909     0.362732    2.210168  0.139096            0.292112   
12819  0.909091    -0.019787    0.899042  0.454886            0.971892   
33659 -0.522727     1.060572   -0.525683 -0.587220           -0.906087   
19531 -0.590909    -0.344290   -0.510287 -0.945114           -1.215078   

         Height  TotalCholesterol  Triglycerides       LDL       HDL  ...  \
28456 -1.080540         -0.078535      -0.470757 -0.026922  0.418008  ...   
8993  -0.279669          0.765897       0.705031  0.006026  0.446825  ...   
34312  0.559339         -0.123259       0.929511 -1.031826 -1.404309  ...   
4802  -0.504861         -0.188325      -0.322647  0.000015 -0.138743  ...   
25895  0.216731          0.892919       1.291109  0.008211 -0.255329  ...   
...         ...               ...            ...       ...       ...  ...   
18045 -2.080569         -0.340947      -0.470582 -0.848950  0.393794  ...   
5425   0.156785          0.435639      -0.065356  1.113733  0.127664  ...   
12819  1.194951         -0.732967      -0.470025 -0.211535 -1.085148  ...   
33659 -1.254274         -1.063225      -0.470958 -2.849419  0.127664  ...   
19531 -2.339052         -0.356898      -0.470595 -0.900608  0.393896  ...   

       Race_5.0  Race_1.0  Race_4.0  Race_3.0  Race_2.0  Education   Smoking  \
28456       1.0       0.0       0.0       0.0       0.0  -0.012820  0.000000   
8993        0.0       0.0       1.0       0.0       0.0   0.547458  1.000000   
34312       0.0       0.0       0.0       1.0       0.0  -0.659696  0.000000   
4802        1.0       0.0       0.0       0.0       0.0   0.262895  0.073612   
25895       0.0       0.0       0.0       1.0       0.0   1.151035  0.000000   
...         ...       ...       ...       ...       ...        ...       ...   
18045       0.0       0.0       0.0       1.0       0.0  -0.793202  0.000000   
5425        0.0       0.0       1.0       0.0       0.0   0.547458  1.000000   
12819       0.0       0.0       0.0       1.0       0.0   1.151035  1.000000   
33659       0.0       0.0       1.0       0.0       0.0   0.258362  0.000000   
19531       1.0       0.0       0.0       0.0       0.0  -0.821118  0.000000   

       PhysicalActivity  HealthInsurance   Alcohol  
28456          0.660578              0.0 -0.518600  
8993           0.000000              0.0  0.115329  
34312          0.000000              0.0  0.592213  
4802           1.012447              0.0 -0.103347  
25895          0.000000              0.0 -0.886483  
...                 ...              ...       ...  
18045          0.904383              0.0 -0.482716  
5425           1.598141              0.0  0.097790  
12819          1.598141              0.0  0.612947  
33659          1.162475              0.0 -0.154408  
19531          0.791302              0.0 -0.683278  

[13109 rows x 31 columns]
2025-12-02 18:43:10,878:INFO:get_config() successfully completed......................................
2025-12-02 18:43:10,934:INFO:Initializing get_config()
2025-12-02 18:43:10,934:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E1DA10EB30>, variable=y_test)
2025-12-02 18:43:10,934:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-12-02 18:43:10,934:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-12-02 18:43:10,936:INFO:Variable:  returned as 28456    0.0
8993     0.0
34312    0.0
4802     0.0
25895    0.0
        ... 
18045    0.0
5425     0.0
12819    0.0
33659    0.0
19531    0.0
Name: HeartDisease, Length: 13109, dtype: float32
2025-12-02 18:43:10,936:INFO:get_config() successfully completed......................................
2025-12-02 18:43:24,945:INFO:Initializing get_config()
2025-12-02 18:43:24,945:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E1DA10EB30>, variable=X_test_transformed)
2025-12-02 18:43:25,019:INFO:Variable: X_test returned as             Age  IncomeRatio  SystolicBP       BMI  WaistCircumference  \
28456 -0.477273    -0.304717   -0.519256 -0.987220           -0.923253   
8993   0.818182     0.253271    2.156910  0.770675            0.920394   
34312  0.704545     0.055403    0.519256  0.518044            0.662901   
4802  -0.545455     0.253730   -0.331933 -0.229036           -0.436352   
25895  0.704545     1.226781   -0.093200 -0.226100            0.012322   
...         ...          ...         ...       ...                 ...   
18045 -0.568182    -0.083104   -0.568713 -1.176693           -1.338674   
5425   0.590909     0.362732    2.210168  0.139096            0.292112   
12819  0.909091    -0.019787    0.899042  0.454886            0.971892   
33659 -0.522727     1.060572   -0.525683 -0.587220           -0.906087   
19531 -0.590909    -0.344290   -0.510287 -0.945114           -1.215078   

         Height  TotalCholesterol  Triglycerides       LDL       HDL  ...  \
28456 -1.080540         -0.078535      -0.470757 -0.026922  0.418008  ...   
8993  -0.279669          0.765897       0.705031  0.006026  0.446825  ...   
34312  0.559339         -0.123259       0.929511 -1.031826 -1.404309  ...   
4802  -0.504861         -0.188325      -0.322647  0.000015 -0.138743  ...   
25895  0.216731          0.892919       1.291109  0.008211 -0.255329  ...   
...         ...               ...            ...       ...       ...  ...   
18045 -2.080569         -0.340947      -0.470582 -0.848950  0.393794  ...   
5425   0.156785          0.435639      -0.065356  1.113733  0.127664  ...   
12819  1.194951         -0.732967      -0.470025 -0.211535 -1.085148  ...   
33659 -1.254274         -1.063225      -0.470958 -2.849419  0.127664  ...   
19531 -2.339052         -0.356898      -0.470595 -0.900608  0.393896  ...   

       Race_5.0  Race_1.0  Race_4.0  Race_3.0  Race_2.0  Education   Smoking  \
28456       1.0       0.0       0.0       0.0       0.0  -0.012820  0.000000   
8993        0.0       0.0       1.0       0.0       0.0   0.547458  1.000000   
34312       0.0       0.0       0.0       1.0       0.0  -0.659696  0.000000   
4802        1.0       0.0       0.0       0.0       0.0   0.262895  0.073612   
25895       0.0       0.0       0.0       1.0       0.0   1.151035  0.000000   
...         ...       ...       ...       ...       ...        ...       ...   
18045       0.0       0.0       0.0       1.0       0.0  -0.793202  0.000000   
5425        0.0       0.0       1.0       0.0       0.0   0.547458  1.000000   
12819       0.0       0.0       0.0       1.0       0.0   1.151035  1.000000   
33659       0.0       0.0       1.0       0.0       0.0   0.258362  0.000000   
19531       1.0       0.0       0.0       0.0       0.0  -0.821118  0.000000   

       PhysicalActivity  HealthInsurance   Alcohol  
28456          0.660578              0.0 -0.518600  
8993           0.000000              0.0  0.115329  
34312          0.000000              0.0  0.592213  
4802           1.012447              0.0 -0.103347  
25895          0.000000              0.0 -0.886483  
...                 ...              ...       ...  
18045          0.904383              0.0 -0.482716  
5425           1.598141              0.0  0.097790  
12819          1.598141              0.0  0.612947  
33659          1.162475              0.0 -0.154408  
19531          0.791302              0.0 -0.683278  

[13109 rows x 31 columns]
2025-12-02 18:43:25,019:INFO:get_config() successfully completed......................................
2025-12-02 18:43:25,048:INFO:Initializing get_config()
2025-12-02 18:43:25,049:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E1DA10EB30>, variable=y_test)
2025-12-02 18:43:25,049:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-12-02 18:43:25,049:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-12-02 18:43:25,056:INFO:Variable:  returned as 28456    0.0
8993     0.0
34312    0.0
4802     0.0
25895    0.0
        ... 
18045    0.0
5425     0.0
12819    0.0
33659    0.0
19531    0.0
Name: HeartDisease, Length: 13109, dtype: float32
2025-12-02 18:43:25,056:INFO:get_config() successfully completed......................................
2025-12-02 18:43:30,053:INFO:Initializing get_config()
2025-12-02 18:43:30,053:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E1DA10EB30>, variable=y_test)
2025-12-02 18:43:30,053:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-12-02 18:43:30,053:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-12-02 18:43:30,060:INFO:Variable:  returned as 28456    0.0
8993     0.0
34312    0.0
4802     0.0
25895    0.0
        ... 
18045    0.0
5425     0.0
12819    0.0
33659    0.0
19531    0.0
Name: HeartDisease, Length: 13109, dtype: float32
2025-12-02 18:43:30,061:INFO:get_config() successfully completed......................................
2025-12-02 18:43:30,061:INFO:Initializing get_config()
2025-12-02 18:43:30,061:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E1DA10EB30>, variable=X_test_transformed)
2025-12-02 18:43:30,132:INFO:Variable: X_test returned as             Age  IncomeRatio  SystolicBP       BMI  WaistCircumference  \
28456 -0.477273    -0.304717   -0.519256 -0.987220           -0.923253   
8993   0.818182     0.253271    2.156910  0.770675            0.920394   
34312  0.704545     0.055403    0.519256  0.518044            0.662901   
4802  -0.545455     0.253730   -0.331933 -0.229036           -0.436352   
25895  0.704545     1.226781   -0.093200 -0.226100            0.012322   
...         ...          ...         ...       ...                 ...   
18045 -0.568182    -0.083104   -0.568713 -1.176693           -1.338674   
5425   0.590909     0.362732    2.210168  0.139096            0.292112   
12819  0.909091    -0.019787    0.899042  0.454886            0.971892   
33659 -0.522727     1.060572   -0.525683 -0.587220           -0.906087   
19531 -0.590909    -0.344290   -0.510287 -0.945114           -1.215078   

         Height  TotalCholesterol  Triglycerides       LDL       HDL  ...  \
28456 -1.080540         -0.078535      -0.470757 -0.026922  0.418008  ...   
8993  -0.279669          0.765897       0.705031  0.006026  0.446825  ...   
34312  0.559339         -0.123259       0.929511 -1.031826 -1.404309  ...   
4802  -0.504861         -0.188325      -0.322647  0.000015 -0.138743  ...   
25895  0.216731          0.892919       1.291109  0.008211 -0.255329  ...   
...         ...               ...            ...       ...       ...  ...   
18045 -2.080569         -0.340947      -0.470582 -0.848950  0.393794  ...   
5425   0.156785          0.435639      -0.065356  1.113733  0.127664  ...   
12819  1.194951         -0.732967      -0.470025 -0.211535 -1.085148  ...   
33659 -1.254274         -1.063225      -0.470958 -2.849419  0.127664  ...   
19531 -2.339052         -0.356898      -0.470595 -0.900608  0.393896  ...   

       Race_5.0  Race_1.0  Race_4.0  Race_3.0  Race_2.0  Education   Smoking  \
28456       1.0       0.0       0.0       0.0       0.0  -0.012820  0.000000   
8993        0.0       0.0       1.0       0.0       0.0   0.547458  1.000000   
34312       0.0       0.0       0.0       1.0       0.0  -0.659696  0.000000   
4802        1.0       0.0       0.0       0.0       0.0   0.262895  0.073612   
25895       0.0       0.0       0.0       1.0       0.0   1.151035  0.000000   
...         ...       ...       ...       ...       ...        ...       ...   
18045       0.0       0.0       0.0       1.0       0.0  -0.793202  0.000000   
5425        0.0       0.0       1.0       0.0       0.0   0.547458  1.000000   
12819       0.0       0.0       0.0       1.0       0.0   1.151035  1.000000   
33659       0.0       0.0       1.0       0.0       0.0   0.258362  0.000000   
19531       1.0       0.0       0.0       0.0       0.0  -0.821118  0.000000   

       PhysicalActivity  HealthInsurance   Alcohol  
28456          0.660578              0.0 -0.518600  
8993           0.000000              0.0  0.115329  
34312          0.000000              0.0  0.592213  
4802           1.012447              0.0 -0.103347  
25895          0.000000              0.0 -0.886483  
...                 ...              ...       ...  
18045          0.904383              0.0 -0.482716  
5425           1.598141              0.0  0.097790  
12819          1.598141              0.0  0.612947  
33659          1.162475              0.0 -0.154408  
19531          0.791302              0.0 -0.683278  

[13109 rows x 31 columns]
2025-12-02 18:43:30,132:INFO:get_config() successfully completed......................................
2025-12-02 18:43:30,222:INFO:Initializing get_config()
2025-12-02 18:43:30,224:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E1DA10EB30>, variable=X_train_transformed)
2025-12-02 18:43:30,256:INFO:Variable: X_train returned as             Age  IncomeRatio  SystolicBP       BMI  WaistCircumference  \
15208  0.954545     0.854789    0.359485  0.518044            0.206281   
25325 -0.272727     0.253271   -0.812170 -0.966167           -0.799656   
5132   0.181818    -0.407608   -0.372799  0.054886            0.319578   
17217  0.500000    -0.751898    0.013314 -0.260904            0.278379   
6382   0.568182     0.054503    1.131712  2.675938            1.888566   
...         ...          ...         ...       ...                 ...   
6265  -0.545455    -0.431352   -0.591719  0.191728           -0.377368   
42694 -0.022727    -0.221612   -0.892056 -0.260904           -0.047778   
13399  0.454545     0.388518    0.377985  0.271482            0.183567   
39959  0.954545    -0.193911    0.625770  0.991728            1.160720   
6616   0.613636    -0.447182    0.652399 -0.871430           -0.514698   

         Height  TotalCholesterol  Triglycerides       LDL       HDL  ...  \
15208 -0.487303          0.625876       0.583394  0.005397  0.314564  ...   
25325 -0.300856          0.033588      -0.261476  0.000256  0.303682  ...   
5132   0.766972          0.181594       0.479279  0.948690 -1.340476  ...   
17217  0.745785          0.227516       0.346113  0.002441 -0.274561  ...   
6382   0.237295          0.867515       0.635574  0.002754  0.829819  ...   
...         ...               ...            ...       ...       ...  ...   
6265  -1.737339         -1.393483      -0.471046 -3.840886  0.063832  ...   
42694  0.000000          0.029167      -0.131730  0.000893  0.063832  ...   
13399 -0.147405          0.462357       0.380371  0.003925  0.256949  ...   
39959  0.368655          1.528031       1.934134  0.011744  0.191497  ...   
6616  -0.021187         -0.224877      -0.043571 -1.609476  0.510658  ...   

       Race_5.0  Race_1.0  Race_4.0  Race_3.0  Race_2.0  Education  Smoking  \
15208       1.0       0.0       0.0       0.0       0.0  -0.659696      0.0   
25325       0.0       1.0       0.0       0.0       0.0   0.185278      0.0   
5132        0.0       1.0       0.0       0.0       0.0  -0.659696      1.0   
17217       0.0       0.0       1.0       0.0       0.0  -0.056119      1.0   
6382        0.0       0.0       1.0       0.0       0.0   0.547458      1.0   
...         ...       ...       ...       ...       ...        ...      ...   
6265        0.0       1.0       0.0       0.0       0.0  -0.769055      0.0   
42694       0.0       1.0       0.0       0.0       0.0   0.547458      0.0   
13399       0.0       0.0       1.0       0.0       0.0   0.547458      0.0   
39959       0.0       0.0       0.0       1.0       0.0   0.547458      0.0   
6616        0.0       0.0       0.0       1.0       0.0   0.547458      1.0   

       PhysicalActivity  HealthInsurance   Alcohol  
15208          0.000000              0.0 -0.886483  
25325          0.000000              0.0  0.592213  
5132           0.000000             -1.0  0.312949  
17217          0.000000              0.0  0.592213  
6382           0.000000              0.0  0.597293  
...                 ...              ...       ...  
6265           0.662459              0.0 -0.501621  
42694          0.000000             -1.0  0.592213  
13399          0.000000              0.0 -0.224534  
39959          0.000000              0.0  0.592213  
6616           0.000000              0.0  0.290247  

[30586 rows x 31 columns]
2025-12-02 18:43:30,256:INFO:get_config() successfully completed......................................
2025-12-02 18:43:39,630:INFO:Initializing tune_model()
2025-12-02 18:43:39,631:INFO:tune_model(estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...), fold=None, round=4, n_iter=5, custom_grid=None, optimize=Recall, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=False, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E1DA10EB30>)
2025-12-02 18:43:39,631:INFO:Checking exceptions
2025-12-02 18:43:39,642:INFO:Copying training dataset
2025-12-02 18:43:39,656:INFO:Checking base model
2025-12-02 18:43:39,656:INFO:Base model : Extreme Gradient Boosting
2025-12-02 18:43:39,656:INFO:Declaring metric variables
2025-12-02 18:43:39,656:INFO:Defining Hyperparameters
2025-12-02 18:43:39,823:INFO:Tuning with n_jobs=1
2025-12-02 18:43:39,823:INFO:Initializing RandomizedSearchCV
2025-12-02 18:44:14,354:INFO:best_params: {'actual_estimator__subsample': 0.7, 'actual_estimator__scale_pos_weight': 38.0, 'actual_estimator__reg_lambda': 0.7, 'actual_estimator__reg_alpha': 0.001, 'actual_estimator__n_estimators': 60, 'actual_estimator__min_child_weight': 1, 'actual_estimator__max_depth': 6, 'actual_estimator__learning_rate': 0.4, 'actual_estimator__colsample_bytree': 0.7}
2025-12-02 18:44:14,354:INFO:Hyperparameter search completed
2025-12-02 18:44:14,354:INFO:SubProcess create_model() called ==================================
2025-12-02 18:44:14,356:INFO:Initializing create_model()
2025-12-02 18:44:14,356:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E1DA10EB30>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E18377AC50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'subsample': 0.7, 'scale_pos_weight': 38.0, 'reg_lambda': 0.7, 'reg_alpha': 0.001, 'n_estimators': 60, 'min_child_weight': 1, 'max_depth': 6, 'learning_rate': 0.4, 'colsample_bytree': 0.7})
2025-12-02 18:44:14,356:INFO:Checking exceptions
2025-12-02 18:44:14,356:INFO:Importing libraries
2025-12-02 18:44:14,356:INFO:Copying training dataset
2025-12-02 18:44:14,376:INFO:Defining folds
2025-12-02 18:44:14,376:INFO:Declaring metric variables
2025-12-02 18:44:14,376:INFO:Importing untrained model
2025-12-02 18:44:14,376:INFO:Declaring custom model
2025-12-02 18:44:14,376:INFO:Extreme Gradient Boosting Imported successfully
2025-12-02 18:44:14,376:INFO:Starting cross validation
2025-12-02 18:44:14,376:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-12-02 18:44:19,254:INFO:Calculating mean and std
2025-12-02 18:44:19,256:INFO:Creating metrics dataframe
2025-12-02 18:44:19,256:INFO:Finalizing model
2025-12-02 18:44:19,323:INFO:Warning: No categorical columns found. Calling 'transform' will only return input data.
2025-12-02 18:44:19,723:INFO:Uploading results into container
2025-12-02 18:44:19,726:INFO:Uploading model into container now
2025-12-02 18:44:19,726:INFO:_master_model_container: 4
2025-12-02 18:44:19,726:INFO:_display_container: 5
2025-12-02 18:44:19,726:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=0.7, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=0.4, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=6, max_leaves=None,
              min_child_weight=1, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=60, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2025-12-02 18:44:19,726:INFO:create_model() successfully completed......................................
2025-12-02 18:44:19,914:INFO:SubProcess create_model() end ==================================
2025-12-02 18:44:19,914:INFO:choose_better activated
2025-12-02 18:44:19,914:INFO:SubProcess create_model() called ==================================
2025-12-02 18:44:19,914:INFO:Initializing create_model()
2025-12-02 18:44:19,914:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E1DA10EB30>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-02 18:44:19,914:INFO:Checking exceptions
2025-12-02 18:44:19,914:INFO:Importing libraries
2025-12-02 18:44:19,914:INFO:Copying training dataset
2025-12-02 18:44:19,937:INFO:Defining folds
2025-12-02 18:44:19,937:INFO:Declaring metric variables
2025-12-02 18:44:19,937:INFO:Importing untrained model
2025-12-02 18:44:19,937:INFO:Declaring custom model
2025-12-02 18:44:19,937:INFO:Extreme Gradient Boosting Imported successfully
2025-12-02 18:44:19,937:INFO:Starting cross validation
2025-12-02 18:44:19,937:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-12-02 18:44:25,979:INFO:Calculating mean and std
2025-12-02 18:44:25,979:INFO:Creating metrics dataframe
2025-12-02 18:44:25,981:INFO:Finalizing model
2025-12-02 18:44:26,051:INFO:Warning: No categorical columns found. Calling 'transform' will only return input data.
2025-12-02 18:44:26,567:INFO:Uploading results into container
2025-12-02 18:44:26,567:INFO:Uploading model into container now
2025-12-02 18:44:26,568:INFO:_master_model_container: 5
2025-12-02 18:44:26,568:INFO:_display_container: 6
2025-12-02 18:44:26,568:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2025-12-02 18:44:26,568:INFO:create_model() successfully completed......................................
2025-12-02 18:44:26,751:INFO:SubProcess create_model() end ==================================
2025-12-02 18:44:26,751:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...) result for Recall is 0.3112
2025-12-02 18:44:26,751:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=0.7, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=0.4, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=6, max_leaves=None,
              min_child_weight=1, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=60, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...) result for Recall is 0.3316
2025-12-02 18:44:26,751:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=0.7, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=0.4, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=6, max_leaves=None,
              min_child_weight=1, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=60, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...) is best model
2025-12-02 18:44:26,751:INFO:choose_better completed
2025-12-02 18:44:26,751:INFO:_master_model_container: 5
2025-12-02 18:44:26,751:INFO:_display_container: 5
2025-12-02 18:44:26,751:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=0.7, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=0.4, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=6, max_leaves=None,
              min_child_weight=1, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=60, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2025-12-02 18:44:26,751:INFO:tune_model() successfully completed......................................
2025-12-02 18:44:32,049:INFO:Initializing predict_model()
2025-12-02 18:44:32,049:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E1DA10EB30>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=0.7, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=0.4, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=6, max_leaves=None,
              min_child_weight=1, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=60, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...), probability_threshold=None, encoded_labels=False, raw_score=True, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001E1836F0550>)
2025-12-02 18:44:32,049:INFO:Checking exceptions
2025-12-02 18:44:32,049:INFO:Preloading libraries
2025-12-02 18:44:32,442:INFO:Initializing get_config()
2025-12-02 18:44:32,442:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E1DA10EB30>, variable=target_param)
2025-12-02 18:44:32,442:INFO:Variable:  returned as HeartDisease
2025-12-02 18:44:32,442:INFO:get_config() successfully completed......................................
2025-12-02 18:44:48,692:INFO:Initializing interpret_model()
2025-12-02 18:44:48,692:INFO:interpret_model(estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=0.7, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=0.4, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=6, max_leaves=None,
              min_child_weight=1, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=60, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...), use_train_data=False, X_new_sample=None, y_new_sample=None, feature=None, kwargs={}, observation=None, plot=summary, save=False, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E1DA10EB30>)
2025-12-02 18:44:48,692:INFO:Checking exceptions
2025-12-02 18:44:48,692:INFO:Soft dependency imported: shap: 0.49.1
2025-12-02 18:44:48,771:INFO:plot type: summary
2025-12-02 18:44:48,771:INFO:Creating TreeExplainer
2025-12-02 18:44:48,781:INFO:Compiling shap values
2025-12-02 18:44:52,076:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:4145: FutureWarning: The NumPy global RNG was seeded by calling `np.random.seed`. In a future version this function will no longer use the global RNG. Pass `rng` explicitly to opt-in to the new behaviour and silence this warning.

2025-12-02 18:44:53,222:INFO:Visual Rendered Successfully
2025-12-02 18:44:53,223:INFO:interpret_model() successfully completed......................................
2025-12-02 18:44:56,321:INFO:Initializing predict_model()
2025-12-02 18:44:56,321:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E1DA10EB30>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...), probability_threshold=None, encoded_labels=False, raw_score=True, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001E183773D90>)
2025-12-02 18:44:56,322:INFO:Checking exceptions
2025-12-02 18:44:56,322:INFO:Preloading libraries
2025-12-02 18:44:56,743:INFO:Initializing get_config()
2025-12-02 18:44:56,743:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E1DA10EB30>, variable=target)
2025-12-02 18:47:18,046:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-12-02 18:47:18,046:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-12-02 18:47:18,046:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-12-02 18:47:18,046:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-12-02 18:47:19,878:INFO:PyCaret ClassificationExperiment
2025-12-02 18:47:19,878:INFO:Logging name: clf-default-name
2025-12-02 18:47:19,878:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-12-02 18:47:19,878:INFO:version 3.3.2
2025-12-02 18:47:19,878:INFO:Initializing setup()
2025-12-02 18:47:19,878:INFO:self.USI: a00d
2025-12-02 18:47:19,878:INFO:self._variable_keys: {'logging_param', 'X_test', 'fold_generator', 'gpu_param', 'y', '_available_plots', 'y_train', 'data', 'USI', 'gpu_n_jobs_param', 'exp_name_log', '_ml_usecase', 'X', 'y_test', 'html_param', 'memory', 'fold_shuffle_param', 'idx', 'n_jobs_param', 'is_multiclass', 'target_param', 'X_train', 'log_plots_param', 'pipeline', 'fix_imbalance', 'fold_groups_param', 'exp_id', 'seed'}
2025-12-02 18:47:19,878:INFO:Checking environment
2025-12-02 18:47:19,878:INFO:python_version: 3.10.19
2025-12-02 18:47:19,878:INFO:python_build: ('main', 'Oct 21 2025 16:41:31')
2025-12-02 18:47:19,878:INFO:machine: AMD64
2025-12-02 18:47:19,878:INFO:platform: Windows-10-10.0.26100-SP0
2025-12-02 18:47:19,878:INFO:Memory: svmem(total=16282144768, available=4437057536, percent=72.7, used=11845087232, free=4437057536)
2025-12-02 18:47:19,878:INFO:Physical Core: 6
2025-12-02 18:47:19,881:INFO:Logical Core: 12
2025-12-02 18:47:19,881:INFO:Checking libraries
2025-12-02 18:47:19,881:INFO:System:
2025-12-02 18:47:19,881:INFO:    python: 3.10.19 | packaged by Anaconda, Inc. | (main, Oct 21 2025, 16:41:31) [MSC v.1929 64 bit (AMD64)]
2025-12-02 18:47:19,881:INFO:executable: c:\Users\OMAR\miniconda3\envs\xgb_env\python.exe
2025-12-02 18:47:19,881:INFO:   machine: Windows-10-10.0.26100-SP0
2025-12-02 18:47:19,881:INFO:PyCaret required dependencies:
2025-12-02 18:47:19,881:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-02 18:47:20,577:INFO:                 pip: 25.3
2025-12-02 18:47:20,577:INFO:          setuptools: 80.9.0
2025-12-02 18:47:20,577:INFO:             pycaret: 3.3.2
2025-12-02 18:47:20,577:INFO:             IPython: 8.37.0
2025-12-02 18:47:20,577:INFO:          ipywidgets: 8.1.8
2025-12-02 18:47:20,577:INFO:                tqdm: 4.67.1
2025-12-02 18:47:20,577:INFO:               numpy: 1.26.4
2025-12-02 18:47:20,577:INFO:              pandas: 2.1.4
2025-12-02 18:47:20,577:INFO:              jinja2: 3.1.6
2025-12-02 18:47:20,577:INFO:               scipy: 1.11.4
2025-12-02 18:47:20,577:INFO:              joblib: 1.3.2
2025-12-02 18:47:20,577:INFO:             sklearn: 1.4.2
2025-12-02 18:47:20,577:INFO:                pyod: 2.0.5
2025-12-02 18:47:20,577:INFO:            imblearn: 0.14.0
2025-12-02 18:47:20,577:INFO:   category_encoders: 2.7.0
2025-12-02 18:47:20,580:INFO:            lightgbm: 4.6.0
2025-12-02 18:47:20,580:INFO:               numba: 0.62.1
2025-12-02 18:47:20,580:INFO:            requests: 2.32.5
2025-12-02 18:47:20,580:INFO:          matplotlib: 3.7.5
2025-12-02 18:47:20,580:INFO:          scikitplot: 0.3.7
2025-12-02 18:47:20,580:INFO:         yellowbrick: 1.5
2025-12-02 18:47:20,580:INFO:              plotly: 5.24.1
2025-12-02 18:47:20,580:INFO:    plotly-resampler: Not installed
2025-12-02 18:47:20,580:INFO:             kaleido: 1.2.0
2025-12-02 18:47:20,580:INFO:           schemdraw: 0.15
2025-12-02 18:47:20,580:INFO:         statsmodels: 0.14.5
2025-12-02 18:47:20,580:INFO:              sktime: 0.26.0
2025-12-02 18:47:20,580:INFO:               tbats: 1.1.3
2025-12-02 18:47:20,580:INFO:            pmdarima: 2.0.4
2025-12-02 18:47:20,580:INFO:              psutil: 7.1.3
2025-12-02 18:47:20,580:INFO:          markupsafe: 3.0.3
2025-12-02 18:47:20,580:INFO:             pickle5: Not installed
2025-12-02 18:47:20,580:INFO:         cloudpickle: 3.1.2
2025-12-02 18:47:20,580:INFO:         deprecation: 2.1.0
2025-12-02 18:47:20,580:INFO:              xxhash: 3.6.0
2025-12-02 18:47:20,580:INFO:           wurlitzer: Not installed
2025-12-02 18:47:20,580:INFO:PyCaret optional dependencies:
2025-12-02 18:47:23,681:INFO:                shap: 0.49.1
2025-12-02 18:47:23,681:INFO:           interpret: 0.7.3
2025-12-02 18:47:23,681:INFO:                umap: 0.5.7
2025-12-02 18:47:23,681:INFO:     ydata_profiling: 4.18.0
2025-12-02 18:47:23,681:INFO:  explainerdashboard: 0.5.1
2025-12-02 18:47:23,681:INFO:             autoviz: Not installed
2025-12-02 18:47:23,681:INFO:           fairlearn: 0.7.0
2025-12-02 18:47:23,681:INFO:          deepchecks: Not installed
2025-12-02 18:47:23,681:INFO:             xgboost: 2.1.3
2025-12-02 18:47:23,681:INFO:            catboost: 1.2.8
2025-12-02 18:47:23,681:INFO:              kmodes: 0.12.2
2025-12-02 18:47:23,681:INFO:             mlxtend: 0.23.4
2025-12-02 18:47:23,681:INFO:       statsforecast: 1.5.0
2025-12-02 18:47:23,681:INFO:        tune_sklearn: Not installed
2025-12-02 18:47:23,681:INFO:                 ray: Not installed
2025-12-02 18:47:23,681:INFO:            hyperopt: 0.2.7
2025-12-02 18:47:23,681:INFO:              optuna: 4.6.0
2025-12-02 18:47:23,681:INFO:               skopt: 0.10.2
2025-12-02 18:47:23,681:INFO:              mlflow: 3.6.0
2025-12-02 18:47:23,681:INFO:              gradio: 6.0.1
2025-12-02 18:47:23,681:INFO:             fastapi: 0.123.0
2025-12-02 18:47:23,681:INFO:             uvicorn: 0.38.0
2025-12-02 18:47:23,681:INFO:              m2cgen: 0.10.0
2025-12-02 18:47:23,681:INFO:           evidently: 0.4.40
2025-12-02 18:47:23,681:INFO:               fugue: 0.8.7
2025-12-02 18:47:23,681:INFO:           streamlit: 1.51.0
2025-12-02 18:47:23,681:INFO:             prophet: Not installed
2025-12-02 18:47:23,681:INFO:None
2025-12-02 18:47:23,681:INFO:Set up data.
2025-12-02 18:47:23,700:INFO:Set up folding strategy.
2025-12-02 18:47:23,700:INFO:Set up train/test split.
2025-12-02 18:47:23,723:INFO:Set up index.
2025-12-02 18:47:23,723:INFO:Assigning column types.
2025-12-02 18:47:23,742:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-12-02 18:47:23,770:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-12-02 18:47:23,773:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-02 18:47:23,792:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-02 18:47:23,792:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-02 18:47:23,842:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-12-02 18:47:23,842:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-02 18:47:23,860:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-02 18:47:23,861:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-02 18:47:23,861:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-12-02 18:47:23,886:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-02 18:47:23,904:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-02 18:47:23,906:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-02 18:47:23,933:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-02 18:47:23,961:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-02 18:47:23,963:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-02 18:47:23,963:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-12-02 18:47:24,006:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-02 18:47:24,007:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-02 18:47:24,051:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-02 18:47:24,052:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-02 18:47:24,054:INFO:Preparing preprocessing pipeline...
2025-12-02 18:47:24,059:INFO:Set up simple imputation.
2025-12-02 18:47:24,071:INFO:Set up encoding of ordinal features.
2025-12-02 18:47:24,076:INFO:Set up encoding of categorical features.
2025-12-02 18:47:24,076:INFO:Set up feature normalization.
2025-12-02 18:47:24,259:INFO:Finished creating preprocessing pipeline.
2025-12-02 18:47:24,276:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\OMAR\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'IncomeRatio', 'SystolicBP',
                                             'BMI', 'WaistCircumference',
                                             'Height', 'TotalCholesterol',
                                             'Triglycerides', 'LDL', 'HDL',
                                             'HbA1c', 'Glucose', 'Creatinine',
                                             'UricAcid', 'ALT_Enzyme',
                                             'Albumin', 'Potassium', 'Sodium',
                                             'G...
                                    transformer=TargetEncoder(cols=[],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=RobustScaler(copy=True,
                                                             quantile_range=(25.0,
                                                                             75.0),
                                                             unit_variance=False,
                                                             with_centering=True,
                                                             with_scaling=True)))],
         verbose=False)
2025-12-02 18:47:24,276:INFO:Creating final display dataframe.
2025-12-02 18:47:24,515:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target      HeartDisease
2                   Target type            Binary
3           Original data shape       (43695, 28)
4        Transformed data shape       (43695, 32)
5   Transformed train set shape       (30586, 32)
6    Transformed test set shape       (13109, 32)
7              Numeric features                20
8          Categorical features                 7
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15                    Normalize              True
16             Normalize method            robust
17               Fold Generator   StratifiedKFold
18                  Fold Number                10
19                     CPU Jobs                 1
20                      Use GPU             False
21               Log Experiment             False
22              Experiment Name  clf-default-name
23                          USI              a00d
2025-12-02 18:47:24,567:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-02 18:47:24,570:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-02 18:47:24,616:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-02 18:47:24,620:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-02 18:47:24,621:INFO:setup() successfully completed in 4.75s...............
2025-12-02 18:47:24,954:INFO:Initializing get_config()
2025-12-02 18:47:24,954:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265C4AAF0D0>, variable=y_train)
2025-12-02 18:47:24,957:INFO:Variable: 'y_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_train_transformed' instead.
2025-12-02 18:47:24,957:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_train_transformed' instead.

2025-12-02 18:47:24,971:INFO:Variable:  returned as 15208    0.0
25325    0.0
5132     0.0
17217    0.0
6382     0.0
        ... 
6265     0.0
42694    0.0
13399    0.0
39959    0.0
6616     0.0
Name: HeartDisease, Length: 30586, dtype: float32
2025-12-02 18:47:24,971:INFO:get_config() successfully completed......................................
2025-12-02 18:47:24,971:INFO:Initializing create_model()
2025-12-02 18:47:24,971:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265C4AAF0D0>, estimator=xgboost, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={'scale_pos_weight': 76.32522407170295})
2025-12-02 18:47:24,971:INFO:Checking exceptions
2025-12-02 18:47:24,986:INFO:Importing libraries
2025-12-02 18:47:24,987:INFO:Copying training dataset
2025-12-02 18:47:25,023:INFO:Defining folds
2025-12-02 18:47:25,023:INFO:Declaring metric variables
2025-12-02 18:47:25,026:INFO:Importing untrained model
2025-12-02 18:47:25,032:INFO:Extreme Gradient Boosting Imported successfully
2025-12-02 18:47:25,038:INFO:Starting cross validation
2025-12-02 18:47:25,038:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-12-02 18:47:32,042:INFO:Calculating mean and std
2025-12-02 18:47:32,046:INFO:Creating metrics dataframe
2025-12-02 18:47:32,051:INFO:Finalizing model
2025-12-02 18:47:32,140:INFO:Warning: No categorical columns found. Calling 'transform' will only return input data.
2025-12-02 18:47:32,757:INFO:Uploading results into container
2025-12-02 18:47:32,757:INFO:Uploading model into container now
2025-12-02 18:47:32,766:INFO:_master_model_container: 1
2025-12-02 18:47:32,766:INFO:_display_container: 2
2025-12-02 18:47:32,766:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2025-12-02 18:47:32,768:INFO:create_model() successfully completed......................................
2025-12-02 18:47:33,001:INFO:Initializing create_model()
2025-12-02 18:47:33,001:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265C4AAF0D0>, estimator=lr, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-02 18:47:33,001:INFO:Checking exceptions
2025-12-02 18:47:33,014:INFO:Importing libraries
2025-12-02 18:47:33,014:INFO:Copying training dataset
2025-12-02 18:47:33,056:INFO:Defining folds
2025-12-02 18:47:33,057:INFO:Declaring metric variables
2025-12-02 18:47:33,061:INFO:Importing untrained model
2025-12-02 18:47:33,064:INFO:Logistic Regression Imported successfully
2025-12-02 18:47:33,070:INFO:Starting cross validation
2025-12-02 18:47:33,072:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-12-02 18:47:34,276:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-12-02 18:47:34,964:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-12-02 18:47:35,393:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-12-02 18:47:35,401:INFO:Calculating mean and std
2025-12-02 18:47:35,402:INFO:Creating metrics dataframe
2025-12-02 18:47:35,406:INFO:Finalizing model
2025-12-02 18:47:35,504:INFO:Warning: No categorical columns found. Calling 'transform' will only return input data.
2025-12-02 18:47:35,611:INFO:Uploading results into container
2025-12-02 18:47:35,611:INFO:Uploading model into container now
2025-12-02 18:47:35,622:INFO:_master_model_container: 2
2025-12-02 18:47:35,622:INFO:_display_container: 3
2025-12-02 18:47:35,623:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-12-02 18:47:35,623:INFO:create_model() successfully completed......................................
2025-12-02 18:47:35,802:INFO:Initializing create_model()
2025-12-02 18:47:35,802:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265C4AAF0D0>, estimator=rf, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-02 18:47:35,802:INFO:Checking exceptions
2025-12-02 18:47:35,814:INFO:Importing libraries
2025-12-02 18:47:35,814:INFO:Copying training dataset
2025-12-02 18:47:35,854:INFO:Defining folds
2025-12-02 18:47:35,854:INFO:Declaring metric variables
2025-12-02 18:47:35,859:INFO:Importing untrained model
2025-12-02 18:47:35,862:INFO:Random Forest Classifier Imported successfully
2025-12-02 18:47:35,870:INFO:Starting cross validation
2025-12-02 18:47:35,871:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-12-02 18:48:16,736:INFO:Calculating mean and std
2025-12-02 18:48:16,736:INFO:Creating metrics dataframe
2025-12-02 18:48:16,742:INFO:Finalizing model
2025-12-02 18:48:16,813:INFO:Warning: No categorical columns found. Calling 'transform' will only return input data.
2025-12-02 18:48:21,209:INFO:Uploading results into container
2025-12-02 18:48:21,209:INFO:Uploading model into container now
2025-12-02 18:48:21,218:INFO:_master_model_container: 3
2025-12-02 18:48:21,219:INFO:_display_container: 4
2025-12-02 18:48:21,219:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2025-12-02 18:48:21,219:INFO:create_model() successfully completed......................................
2025-12-02 18:48:21,406:INFO:Initializing get_config()
2025-12-02 18:48:21,406:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265C4AAF0D0>, variable=X_train_transformed)
2025-12-02 18:48:21,440:INFO:Variable: X_train returned as             Age  IncomeRatio  SystolicBP       BMI  WaistCircumference  \
15208  0.954545     0.854789    0.359485  0.518044            0.206281   
25325 -0.272727     0.253271   -0.812170 -0.966167           -0.799656   
5132   0.181818    -0.407608   -0.372799  0.054886            0.319578   
17217  0.500000    -0.751898    0.013314 -0.260904            0.278379   
6382   0.568182     0.054503    1.131712  2.675938            1.888566   
...         ...          ...         ...       ...                 ...   
6265  -0.545455    -0.431352   -0.591719  0.191728           -0.377368   
42694 -0.022727    -0.221612   -0.892056 -0.260904           -0.047778   
13399  0.454545     0.388518    0.377985  0.271482            0.183567   
39959  0.954545    -0.193911    0.625770  0.991728            1.160720   
6616   0.613636    -0.447182    0.652399 -0.871430           -0.514698   

         Height  TotalCholesterol  Triglycerides       LDL       HDL  ...  \
15208 -0.487303          0.625876       0.583394  0.005397  0.314564  ...   
25325 -0.300856          0.033588      -0.261476  0.000256  0.303682  ...   
5132   0.766972          0.181594       0.479279  0.948690 -1.340476  ...   
17217  0.745785          0.227516       0.346113  0.002441 -0.274561  ...   
6382   0.237295          0.867515       0.635574  0.002754  0.829819  ...   
...         ...               ...            ...       ...       ...  ...   
6265  -1.737339         -1.393483      -0.471046 -3.840886  0.063832  ...   
42694  0.000000          0.029167      -0.131730  0.000893  0.063832  ...   
13399 -0.147405          0.462357       0.380371  0.003925  0.256949  ...   
39959  0.368655          1.528031       1.934134  0.011744  0.191497  ...   
6616  -0.021187         -0.224877      -0.043571 -1.609476  0.510658  ...   

       Race_5.0  Race_1.0  Race_4.0  Race_3.0  Race_2.0  Education  Smoking  \
15208       1.0       0.0       0.0       0.0       0.0  -0.659696      0.0   
25325       0.0       1.0       0.0       0.0       0.0   0.185278      0.0   
5132        0.0       1.0       0.0       0.0       0.0  -0.659696      1.0   
17217       0.0       0.0       1.0       0.0       0.0  -0.056119      1.0   
6382        0.0       0.0       1.0       0.0       0.0   0.547458      1.0   
...         ...       ...       ...       ...       ...        ...      ...   
6265        0.0       1.0       0.0       0.0       0.0  -0.769055      0.0   
42694       0.0       1.0       0.0       0.0       0.0   0.547458      0.0   
13399       0.0       0.0       1.0       0.0       0.0   0.547458      0.0   
39959       0.0       0.0       0.0       1.0       0.0   0.547458      0.0   
6616        0.0       0.0       0.0       1.0       0.0   0.547458      1.0   

       PhysicalActivity  HealthInsurance   Alcohol  
15208          0.000000              0.0 -0.886483  
25325          0.000000              0.0  0.592213  
5132           0.000000             -1.0  0.312949  
17217          0.000000              0.0  0.592213  
6382           0.000000              0.0  0.597293  
...                 ...              ...       ...  
6265           0.662459              0.0 -0.501621  
42694          0.000000             -1.0  0.592213  
13399          0.000000              0.0 -0.224534  
39959          0.000000              0.0  0.592213  
6616           0.000000              0.0  0.290247  

[30586 rows x 31 columns]
2025-12-02 18:48:21,442:INFO:get_config() successfully completed......................................
2025-12-02 18:48:21,442:INFO:Initializing get_config()
2025-12-02 18:48:21,442:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265C4AAF0D0>, variable=y_train)
2025-12-02 18:48:21,442:INFO:Variable: 'y_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_train_transformed' instead.
2025-12-02 18:48:21,442:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_train_transformed' instead.

2025-12-02 18:48:21,446:INFO:Variable:  returned as 15208    0.0
25325    0.0
5132     0.0
17217    0.0
6382     0.0
        ... 
6265     0.0
42694    0.0
13399    0.0
39959    0.0
6616     0.0
Name: HeartDisease, Length: 30586, dtype: float32
2025-12-02 18:48:21,446:INFO:get_config() successfully completed......................................
2025-12-02 18:48:21,450:INFO:Initializing get_config()
2025-12-02 18:48:21,450:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265C4AAF0D0>, variable=X_test_transformed)
2025-12-02 18:48:21,514:INFO:Variable: X_test returned as             Age  IncomeRatio  SystolicBP       BMI  WaistCircumference  \
28456 -0.477273    -0.304717   -0.519256 -0.987220           -0.923253   
8993   0.818182     0.253271    2.156910  0.770675            0.920394   
34312  0.704545     0.055403    0.519256  0.518044            0.662901   
4802  -0.545455     0.253730   -0.331933 -0.229036           -0.436352   
25895  0.704545     1.226781   -0.093200 -0.226100            0.012322   
...         ...          ...         ...       ...                 ...   
18045 -0.568182    -0.083104   -0.568713 -1.176693           -1.338674   
5425   0.590909     0.362732    2.210168  0.139096            0.292112   
12819  0.909091    -0.019787    0.899042  0.454886            0.971892   
33659 -0.522727     1.060572   -0.525683 -0.587220           -0.906087   
19531 -0.590909    -0.344290   -0.510287 -0.945114           -1.215078   

         Height  TotalCholesterol  Triglycerides       LDL       HDL  ...  \
28456 -1.080540         -0.078535      -0.470757 -0.026922  0.418008  ...   
8993  -0.279669          0.765897       0.705031  0.006026  0.446825  ...   
34312  0.559339         -0.123259       0.929511 -1.031826 -1.404309  ...   
4802  -0.504861         -0.188325      -0.322647  0.000015 -0.138743  ...   
25895  0.216731          0.892919       1.291109  0.008211 -0.255329  ...   
...         ...               ...            ...       ...       ...  ...   
18045 -2.080569         -0.340947      -0.470582 -0.848950  0.393794  ...   
5425   0.156785          0.435639      -0.065356  1.113733  0.127664  ...   
12819  1.194951         -0.732967      -0.470025 -0.211535 -1.085148  ...   
33659 -1.254274         -1.063225      -0.470958 -2.849419  0.127664  ...   
19531 -2.339052         -0.356898      -0.470595 -0.900608  0.393896  ...   

       Race_5.0  Race_1.0  Race_4.0  Race_3.0  Race_2.0  Education   Smoking  \
28456       1.0       0.0       0.0       0.0       0.0  -0.012820  0.000000   
8993        0.0       0.0       1.0       0.0       0.0   0.547458  1.000000   
34312       0.0       0.0       0.0       1.0       0.0  -0.659696  0.000000   
4802        1.0       0.0       0.0       0.0       0.0   0.262895  0.073612   
25895       0.0       0.0       0.0       1.0       0.0   1.151035  0.000000   
...         ...       ...       ...       ...       ...        ...       ...   
18045       0.0       0.0       0.0       1.0       0.0  -0.793202  0.000000   
5425        0.0       0.0       1.0       0.0       0.0   0.547458  1.000000   
12819       0.0       0.0       0.0       1.0       0.0   1.151035  1.000000   
33659       0.0       0.0       1.0       0.0       0.0   0.258362  0.000000   
19531       1.0       0.0       0.0       0.0       0.0  -0.821118  0.000000   

       PhysicalActivity  HealthInsurance   Alcohol  
28456          0.660578              0.0 -0.518600  
8993           0.000000              0.0  0.115329  
34312          0.000000              0.0  0.592213  
4802           1.012447              0.0 -0.103347  
25895          0.000000              0.0 -0.886483  
...                 ...              ...       ...  
18045          0.904383              0.0 -0.482716  
5425           1.598141              0.0  0.097790  
12819          1.598141              0.0  0.612947  
33659          1.162475              0.0 -0.154408  
19531          0.791302              0.0 -0.683278  

[13109 rows x 31 columns]
2025-12-02 18:48:21,517:INFO:get_config() successfully completed......................................
2025-12-02 18:48:21,517:INFO:Initializing get_config()
2025-12-02 18:48:21,517:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265C4AAF0D0>, variable=y_test)
2025-12-02 18:48:21,517:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-12-02 18:48:21,517:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-12-02 18:48:21,522:INFO:Variable:  returned as 28456    0.0
8993     0.0
34312    0.0
4802     0.0
25895    0.0
        ... 
18045    0.0
5425     0.0
12819    0.0
33659    0.0
19531    0.0
Name: HeartDisease, Length: 13109, dtype: float32
2025-12-02 18:48:21,522:INFO:get_config() successfully completed......................................
2025-12-02 18:48:21,677:INFO:Initializing get_config()
2025-12-02 18:48:21,677:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265C4AAF0D0>, variable=X_train_transformed)
2025-12-02 18:48:21,726:INFO:Variable: X_train returned as             Age  IncomeRatio  SystolicBP       BMI  WaistCircumference  \
15208  0.954545     0.854789    0.359485  0.518044            0.206281   
25325 -0.272727     0.253271   -0.812170 -0.966167           -0.799656   
5132   0.181818    -0.407608   -0.372799  0.054886            0.319578   
17217  0.500000    -0.751898    0.013314 -0.260904            0.278379   
6382   0.568182     0.054503    1.131712  2.675938            1.888566   
...         ...          ...         ...       ...                 ...   
6265  -0.545455    -0.431352   -0.591719  0.191728           -0.377368   
42694 -0.022727    -0.221612   -0.892056 -0.260904           -0.047778   
13399  0.454545     0.388518    0.377985  0.271482            0.183567   
39959  0.954545    -0.193911    0.625770  0.991728            1.160720   
6616   0.613636    -0.447182    0.652399 -0.871430           -0.514698   

         Height  TotalCholesterol  Triglycerides       LDL       HDL  ...  \
15208 -0.487303          0.625876       0.583394  0.005397  0.314564  ...   
25325 -0.300856          0.033588      -0.261476  0.000256  0.303682  ...   
5132   0.766972          0.181594       0.479279  0.948690 -1.340476  ...   
17217  0.745785          0.227516       0.346113  0.002441 -0.274561  ...   
6382   0.237295          0.867515       0.635574  0.002754  0.829819  ...   
...         ...               ...            ...       ...       ...  ...   
6265  -1.737339         -1.393483      -0.471046 -3.840886  0.063832  ...   
42694  0.000000          0.029167      -0.131730  0.000893  0.063832  ...   
13399 -0.147405          0.462357       0.380371  0.003925  0.256949  ...   
39959  0.368655          1.528031       1.934134  0.011744  0.191497  ...   
6616  -0.021187         -0.224877      -0.043571 -1.609476  0.510658  ...   

       Race_5.0  Race_1.0  Race_4.0  Race_3.0  Race_2.0  Education  Smoking  \
15208       1.0       0.0       0.0       0.0       0.0  -0.659696      0.0   
25325       0.0       1.0       0.0       0.0       0.0   0.185278      0.0   
5132        0.0       1.0       0.0       0.0       0.0  -0.659696      1.0   
17217       0.0       0.0       1.0       0.0       0.0  -0.056119      1.0   
6382        0.0       0.0       1.0       0.0       0.0   0.547458      1.0   
...         ...       ...       ...       ...       ...        ...      ...   
6265        0.0       1.0       0.0       0.0       0.0  -0.769055      0.0   
42694       0.0       1.0       0.0       0.0       0.0   0.547458      0.0   
13399       0.0       0.0       1.0       0.0       0.0   0.547458      0.0   
39959       0.0       0.0       0.0       1.0       0.0   0.547458      0.0   
6616        0.0       0.0       0.0       1.0       0.0   0.547458      1.0   

       PhysicalActivity  HealthInsurance   Alcohol  
15208          0.000000              0.0 -0.886483  
25325          0.000000              0.0  0.592213  
5132           0.000000             -1.0  0.312949  
17217          0.000000              0.0  0.592213  
6382           0.000000              0.0  0.597293  
...                 ...              ...       ...  
6265           0.662459              0.0 -0.501621  
42694          0.000000             -1.0  0.592213  
13399          0.000000              0.0 -0.224534  
39959          0.000000              0.0  0.592213  
6616           0.000000              0.0  0.290247  

[30586 rows x 31 columns]
2025-12-02 18:48:21,726:INFO:get_config() successfully completed......................................
2025-12-02 18:48:21,726:INFO:Initializing get_config()
2025-12-02 18:48:21,726:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265C4AAF0D0>, variable=y_train)
2025-12-02 18:48:21,726:INFO:Variable: 'y_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_train_transformed' instead.
2025-12-02 18:48:21,726:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_train_transformed' instead.

2025-12-02 18:48:21,736:INFO:Variable:  returned as 15208    0.0
25325    0.0
5132     0.0
17217    0.0
6382     0.0
        ... 
6265     0.0
42694    0.0
13399    0.0
39959    0.0
6616     0.0
Name: HeartDisease, Length: 30586, dtype: float32
2025-12-02 18:48:21,736:INFO:get_config() successfully completed......................................
2025-12-02 18:48:21,736:INFO:Initializing get_config()
2025-12-02 18:48:21,736:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265C4AAF0D0>, variable=X_test_transformed)
2025-12-02 18:48:21,804:INFO:Variable: X_test returned as             Age  IncomeRatio  SystolicBP       BMI  WaistCircumference  \
28456 -0.477273    -0.304717   -0.519256 -0.987220           -0.923253   
8993   0.818182     0.253271    2.156910  0.770675            0.920394   
34312  0.704545     0.055403    0.519256  0.518044            0.662901   
4802  -0.545455     0.253730   -0.331933 -0.229036           -0.436352   
25895  0.704545     1.226781   -0.093200 -0.226100            0.012322   
...         ...          ...         ...       ...                 ...   
18045 -0.568182    -0.083104   -0.568713 -1.176693           -1.338674   
5425   0.590909     0.362732    2.210168  0.139096            0.292112   
12819  0.909091    -0.019787    0.899042  0.454886            0.971892   
33659 -0.522727     1.060572   -0.525683 -0.587220           -0.906087   
19531 -0.590909    -0.344290   -0.510287 -0.945114           -1.215078   

         Height  TotalCholesterol  Triglycerides       LDL       HDL  ...  \
28456 -1.080540         -0.078535      -0.470757 -0.026922  0.418008  ...   
8993  -0.279669          0.765897       0.705031  0.006026  0.446825  ...   
34312  0.559339         -0.123259       0.929511 -1.031826 -1.404309  ...   
4802  -0.504861         -0.188325      -0.322647  0.000015 -0.138743  ...   
25895  0.216731          0.892919       1.291109  0.008211 -0.255329  ...   
...         ...               ...            ...       ...       ...  ...   
18045 -2.080569         -0.340947      -0.470582 -0.848950  0.393794  ...   
5425   0.156785          0.435639      -0.065356  1.113733  0.127664  ...   
12819  1.194951         -0.732967      -0.470025 -0.211535 -1.085148  ...   
33659 -1.254274         -1.063225      -0.470958 -2.849419  0.127664  ...   
19531 -2.339052         -0.356898      -0.470595 -0.900608  0.393896  ...   

       Race_5.0  Race_1.0  Race_4.0  Race_3.0  Race_2.0  Education   Smoking  \
28456       1.0       0.0       0.0       0.0       0.0  -0.012820  0.000000   
8993        0.0       0.0       1.0       0.0       0.0   0.547458  1.000000   
34312       0.0       0.0       0.0       1.0       0.0  -0.659696  0.000000   
4802        1.0       0.0       0.0       0.0       0.0   0.262895  0.073612   
25895       0.0       0.0       0.0       1.0       0.0   1.151035  0.000000   
...         ...       ...       ...       ...       ...        ...       ...   
18045       0.0       0.0       0.0       1.0       0.0  -0.793202  0.000000   
5425        0.0       0.0       1.0       0.0       0.0   0.547458  1.000000   
12819       0.0       0.0       0.0       1.0       0.0   1.151035  1.000000   
33659       0.0       0.0       1.0       0.0       0.0   0.258362  0.000000   
19531       1.0       0.0       0.0       0.0       0.0  -0.821118  0.000000   

       PhysicalActivity  HealthInsurance   Alcohol  
28456          0.660578              0.0 -0.518600  
8993           0.000000              0.0  0.115329  
34312          0.000000              0.0  0.592213  
4802           1.012447              0.0 -0.103347  
25895          0.000000              0.0 -0.886483  
...                 ...              ...       ...  
18045          0.904383              0.0 -0.482716  
5425           1.598141              0.0  0.097790  
12819          1.598141              0.0  0.612947  
33659          1.162475              0.0 -0.154408  
19531          0.791302              0.0 -0.683278  

[13109 rows x 31 columns]
2025-12-02 18:48:21,804:INFO:get_config() successfully completed......................................
2025-12-02 18:48:21,804:INFO:Initializing get_config()
2025-12-02 18:48:21,804:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265C4AAF0D0>, variable=y_test)
2025-12-02 18:48:21,804:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-12-02 18:48:21,804:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-12-02 18:48:21,809:INFO:Variable:  returned as 28456    0.0
8993     0.0
34312    0.0
4802     0.0
25895    0.0
        ... 
18045    0.0
5425     0.0
12819    0.0
33659    0.0
19531    0.0
Name: HeartDisease, Length: 13109, dtype: float32
2025-12-02 18:48:21,809:INFO:get_config() successfully completed......................................
2025-12-02 18:48:21,932:INFO:Initializing get_config()
2025-12-02 18:48:21,932:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265C4AAF0D0>, variable=X_test_transformed)
2025-12-02 18:48:22,000:INFO:Variable: X_test returned as             Age  IncomeRatio  SystolicBP       BMI  WaistCircumference  \
28456 -0.477273    -0.304717   -0.519256 -0.987220           -0.923253   
8993   0.818182     0.253271    2.156910  0.770675            0.920394   
34312  0.704545     0.055403    0.519256  0.518044            0.662901   
4802  -0.545455     0.253730   -0.331933 -0.229036           -0.436352   
25895  0.704545     1.226781   -0.093200 -0.226100            0.012322   
...         ...          ...         ...       ...                 ...   
18045 -0.568182    -0.083104   -0.568713 -1.176693           -1.338674   
5425   0.590909     0.362732    2.210168  0.139096            0.292112   
12819  0.909091    -0.019787    0.899042  0.454886            0.971892   
33659 -0.522727     1.060572   -0.525683 -0.587220           -0.906087   
19531 -0.590909    -0.344290   -0.510287 -0.945114           -1.215078   

         Height  TotalCholesterol  Triglycerides       LDL       HDL  ...  \
28456 -1.080540         -0.078535      -0.470757 -0.026922  0.418008  ...   
8993  -0.279669          0.765897       0.705031  0.006026  0.446825  ...   
34312  0.559339         -0.123259       0.929511 -1.031826 -1.404309  ...   
4802  -0.504861         -0.188325      -0.322647  0.000015 -0.138743  ...   
25895  0.216731          0.892919       1.291109  0.008211 -0.255329  ...   
...         ...               ...            ...       ...       ...  ...   
18045 -2.080569         -0.340947      -0.470582 -0.848950  0.393794  ...   
5425   0.156785          0.435639      -0.065356  1.113733  0.127664  ...   
12819  1.194951         -0.732967      -0.470025 -0.211535 -1.085148  ...   
33659 -1.254274         -1.063225      -0.470958 -2.849419  0.127664  ...   
19531 -2.339052         -0.356898      -0.470595 -0.900608  0.393896  ...   

       Race_5.0  Race_1.0  Race_4.0  Race_3.0  Race_2.0  Education   Smoking  \
28456       1.0       0.0       0.0       0.0       0.0  -0.012820  0.000000   
8993        0.0       0.0       1.0       0.0       0.0   0.547458  1.000000   
34312       0.0       0.0       0.0       1.0       0.0  -0.659696  0.000000   
4802        1.0       0.0       0.0       0.0       0.0   0.262895  0.073612   
25895       0.0       0.0       0.0       1.0       0.0   1.151035  0.000000   
...         ...       ...       ...       ...       ...        ...       ...   
18045       0.0       0.0       0.0       1.0       0.0  -0.793202  0.000000   
5425        0.0       0.0       1.0       0.0       0.0   0.547458  1.000000   
12819       0.0       0.0       0.0       1.0       0.0   1.151035  1.000000   
33659       0.0       0.0       1.0       0.0       0.0   0.258362  0.000000   
19531       1.0       0.0       0.0       0.0       0.0  -0.821118  0.000000   

       PhysicalActivity  HealthInsurance   Alcohol  
28456          0.660578              0.0 -0.518600  
8993           0.000000              0.0  0.115329  
34312          0.000000              0.0  0.592213  
4802           1.012447              0.0 -0.103347  
25895          0.000000              0.0 -0.886483  
...                 ...              ...       ...  
18045          0.904383              0.0 -0.482716  
5425           1.598141              0.0  0.097790  
12819          1.598141              0.0  0.612947  
33659          1.162475              0.0 -0.154408  
19531          0.791302              0.0 -0.683278  

[13109 rows x 31 columns]
2025-12-02 18:48:22,001:INFO:get_config() successfully completed......................................
2025-12-02 18:48:22,026:INFO:Initializing get_config()
2025-12-02 18:48:22,026:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265C4AAF0D0>, variable=y_test)
2025-12-02 18:48:22,026:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-12-02 18:48:22,026:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-12-02 18:48:22,032:INFO:Variable:  returned as 28456    0.0
8993     0.0
34312    0.0
4802     0.0
25895    0.0
        ... 
18045    0.0
5425     0.0
12819    0.0
33659    0.0
19531    0.0
Name: HeartDisease, Length: 13109, dtype: float32
2025-12-02 18:48:22,032:INFO:get_config() successfully completed......................................
2025-12-02 18:48:22,032:INFO:Initializing get_config()
2025-12-02 18:48:22,035:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265C4AAF0D0>, variable=y_test)
2025-12-02 18:48:22,035:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-12-02 18:48:22,035:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-12-02 18:48:22,037:INFO:Variable:  returned as 28456    0.0
8993     0.0
34312    0.0
4802     0.0
25895    0.0
        ... 
18045    0.0
5425     0.0
12819    0.0
33659    0.0
19531    0.0
Name: HeartDisease, Length: 13109, dtype: float32
2025-12-02 18:48:22,037:INFO:get_config() successfully completed......................................
2025-12-02 18:48:22,041:INFO:Initializing get_config()
2025-12-02 18:48:22,041:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265C4AAF0D0>, variable=X_test_transformed)
2025-12-02 18:48:22,106:INFO:Variable: X_test returned as             Age  IncomeRatio  SystolicBP       BMI  WaistCircumference  \
28456 -0.477273    -0.304717   -0.519256 -0.987220           -0.923253   
8993   0.818182     0.253271    2.156910  0.770675            0.920394   
34312  0.704545     0.055403    0.519256  0.518044            0.662901   
4802  -0.545455     0.253730   -0.331933 -0.229036           -0.436352   
25895  0.704545     1.226781   -0.093200 -0.226100            0.012322   
...         ...          ...         ...       ...                 ...   
18045 -0.568182    -0.083104   -0.568713 -1.176693           -1.338674   
5425   0.590909     0.362732    2.210168  0.139096            0.292112   
12819  0.909091    -0.019787    0.899042  0.454886            0.971892   
33659 -0.522727     1.060572   -0.525683 -0.587220           -0.906087   
19531 -0.590909    -0.344290   -0.510287 -0.945114           -1.215078   

         Height  TotalCholesterol  Triglycerides       LDL       HDL  ...  \
28456 -1.080540         -0.078535      -0.470757 -0.026922  0.418008  ...   
8993  -0.279669          0.765897       0.705031  0.006026  0.446825  ...   
34312  0.559339         -0.123259       0.929511 -1.031826 -1.404309  ...   
4802  -0.504861         -0.188325      -0.322647  0.000015 -0.138743  ...   
25895  0.216731          0.892919       1.291109  0.008211 -0.255329  ...   
...         ...               ...            ...       ...       ...  ...   
18045 -2.080569         -0.340947      -0.470582 -0.848950  0.393794  ...   
5425   0.156785          0.435639      -0.065356  1.113733  0.127664  ...   
12819  1.194951         -0.732967      -0.470025 -0.211535 -1.085148  ...   
33659 -1.254274         -1.063225      -0.470958 -2.849419  0.127664  ...   
19531 -2.339052         -0.356898      -0.470595 -0.900608  0.393896  ...   

       Race_5.0  Race_1.0  Race_4.0  Race_3.0  Race_2.0  Education   Smoking  \
28456       1.0       0.0       0.0       0.0       0.0  -0.012820  0.000000   
8993        0.0       0.0       1.0       0.0       0.0   0.547458  1.000000   
34312       0.0       0.0       0.0       1.0       0.0  -0.659696  0.000000   
4802        1.0       0.0       0.0       0.0       0.0   0.262895  0.073612   
25895       0.0       0.0       0.0       1.0       0.0   1.151035  0.000000   
...         ...       ...       ...       ...       ...        ...       ...   
18045       0.0       0.0       0.0       1.0       0.0  -0.793202  0.000000   
5425        0.0       0.0       1.0       0.0       0.0   0.547458  1.000000   
12819       0.0       0.0       0.0       1.0       0.0   1.151035  1.000000   
33659       0.0       0.0       1.0       0.0       0.0   0.258362  0.000000   
19531       1.0       0.0       0.0       0.0       0.0  -0.821118  0.000000   

       PhysicalActivity  HealthInsurance   Alcohol  
28456          0.660578              0.0 -0.518600  
8993           0.000000              0.0  0.115329  
34312          0.000000              0.0  0.592213  
4802           1.012447              0.0 -0.103347  
25895          0.000000              0.0 -0.886483  
...                 ...              ...       ...  
18045          0.904383              0.0 -0.482716  
5425           1.598141              0.0  0.097790  
12819          1.598141              0.0  0.612947  
33659          1.162475              0.0 -0.154408  
19531          0.791302              0.0 -0.683278  

[13109 rows x 31 columns]
2025-12-02 18:48:22,106:INFO:get_config() successfully completed......................................
2025-12-02 18:48:22,106:INFO:Initializing get_config()
2025-12-02 18:48:22,106:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265C4AAF0D0>, variable=y_test)
2025-12-02 18:48:22,109:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-12-02 18:48:22,109:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-12-02 18:48:22,113:INFO:Variable:  returned as 28456    0.0
8993     0.0
34312    0.0
4802     0.0
25895    0.0
        ... 
18045    0.0
5425     0.0
12819    0.0
33659    0.0
19531    0.0
Name: HeartDisease, Length: 13109, dtype: float32
2025-12-02 18:48:22,113:INFO:get_config() successfully completed......................................
2025-12-02 18:48:22,115:INFO:Initializing get_config()
2025-12-02 18:48:22,115:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265C4AAF0D0>, variable=y_test)
2025-12-02 18:48:22,115:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-12-02 18:48:22,115:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-12-02 18:48:22,120:INFO:Variable:  returned as 28456    0.0
8993     0.0
34312    0.0
4802     0.0
25895    0.0
        ... 
18045    0.0
5425     0.0
12819    0.0
33659    0.0
19531    0.0
Name: HeartDisease, Length: 13109, dtype: float32
2025-12-02 18:48:22,120:INFO:get_config() successfully completed......................................
2025-12-02 18:48:22,122:INFO:Initializing get_config()
2025-12-02 18:48:22,122:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265C4AAF0D0>, variable=X_test_transformed)
2025-12-02 18:48:22,186:INFO:Variable: X_test returned as             Age  IncomeRatio  SystolicBP       BMI  WaistCircumference  \
28456 -0.477273    -0.304717   -0.519256 -0.987220           -0.923253   
8993   0.818182     0.253271    2.156910  0.770675            0.920394   
34312  0.704545     0.055403    0.519256  0.518044            0.662901   
4802  -0.545455     0.253730   -0.331933 -0.229036           -0.436352   
25895  0.704545     1.226781   -0.093200 -0.226100            0.012322   
...         ...          ...         ...       ...                 ...   
18045 -0.568182    -0.083104   -0.568713 -1.176693           -1.338674   
5425   0.590909     0.362732    2.210168  0.139096            0.292112   
12819  0.909091    -0.019787    0.899042  0.454886            0.971892   
33659 -0.522727     1.060572   -0.525683 -0.587220           -0.906087   
19531 -0.590909    -0.344290   -0.510287 -0.945114           -1.215078   

         Height  TotalCholesterol  Triglycerides       LDL       HDL  ...  \
28456 -1.080540         -0.078535      -0.470757 -0.026922  0.418008  ...   
8993  -0.279669          0.765897       0.705031  0.006026  0.446825  ...   
34312  0.559339         -0.123259       0.929511 -1.031826 -1.404309  ...   
4802  -0.504861         -0.188325      -0.322647  0.000015 -0.138743  ...   
25895  0.216731          0.892919       1.291109  0.008211 -0.255329  ...   
...         ...               ...            ...       ...       ...  ...   
18045 -2.080569         -0.340947      -0.470582 -0.848950  0.393794  ...   
5425   0.156785          0.435639      -0.065356  1.113733  0.127664  ...   
12819  1.194951         -0.732967      -0.470025 -0.211535 -1.085148  ...   
33659 -1.254274         -1.063225      -0.470958 -2.849419  0.127664  ...   
19531 -2.339052         -0.356898      -0.470595 -0.900608  0.393896  ...   

       Race_5.0  Race_1.0  Race_4.0  Race_3.0  Race_2.0  Education   Smoking  \
28456       1.0       0.0       0.0       0.0       0.0  -0.012820  0.000000   
8993        0.0       0.0       1.0       0.0       0.0   0.547458  1.000000   
34312       0.0       0.0       0.0       1.0       0.0  -0.659696  0.000000   
4802        1.0       0.0       0.0       0.0       0.0   0.262895  0.073612   
25895       0.0       0.0       0.0       1.0       0.0   1.151035  0.000000   
...         ...       ...       ...       ...       ...        ...       ...   
18045       0.0       0.0       0.0       1.0       0.0  -0.793202  0.000000   
5425        0.0       0.0       1.0       0.0       0.0   0.547458  1.000000   
12819       0.0       0.0       0.0       1.0       0.0   1.151035  1.000000   
33659       0.0       0.0       1.0       0.0       0.0   0.258362  0.000000   
19531       1.0       0.0       0.0       0.0       0.0  -0.821118  0.000000   

       PhysicalActivity  HealthInsurance   Alcohol  
28456          0.660578              0.0 -0.518600  
8993           0.000000              0.0  0.115329  
34312          0.000000              0.0  0.592213  
4802           1.012447              0.0 -0.103347  
25895          0.000000              0.0 -0.886483  
...                 ...              ...       ...  
18045          0.904383              0.0 -0.482716  
5425           1.598141              0.0  0.097790  
12819          1.598141              0.0  0.612947  
33659          1.162475              0.0 -0.154408  
19531          0.791302              0.0 -0.683278  

[13109 rows x 31 columns]
2025-12-02 18:48:22,186:INFO:get_config() successfully completed......................................
2025-12-02 18:48:22,242:INFO:Initializing get_config()
2025-12-02 18:48:22,242:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265C4AAF0D0>, variable=y_test)
2025-12-02 18:48:22,242:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-12-02 18:48:22,242:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-12-02 18:48:22,246:INFO:Variable:  returned as 28456    0.0
8993     0.0
34312    0.0
4802     0.0
25895    0.0
        ... 
18045    0.0
5425     0.0
12819    0.0
33659    0.0
19531    0.0
Name: HeartDisease, Length: 13109, dtype: float32
2025-12-02 18:48:22,248:INFO:get_config() successfully completed......................................
2025-12-02 18:48:22,250:INFO:Initializing get_config()
2025-12-02 18:48:22,250:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265C4AAF0D0>, variable=y_test)
2025-12-02 18:48:22,250:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-12-02 18:48:22,250:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-12-02 18:48:22,254:INFO:Variable:  returned as 28456    0.0
8993     0.0
34312    0.0
4802     0.0
25895    0.0
        ... 
18045    0.0
5425     0.0
12819    0.0
33659    0.0
19531    0.0
Name: HeartDisease, Length: 13109, dtype: float32
2025-12-02 18:48:22,254:INFO:get_config() successfully completed......................................
2025-12-02 18:48:22,276:INFO:Initializing plot_model()
2025-12-02 18:48:22,276:INFO:plot_model(plot=error, fold=None, verbose=True, display=None, display_format=None, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265C4AAF0D0>, system=True)
2025-12-02 18:48:22,276:INFO:Checking exceptions
2025-12-02 18:48:22,292:INFO:Preloading libraries
2025-12-02 18:48:22,301:INFO:Copying training dataset
2025-12-02 18:48:22,301:INFO:Plot type: error
2025-12-02 18:48:22,509:INFO:Fitting Model
2025-12-02 18:48:22,510:INFO:Scoring test/hold-out set
2025-12-02 18:48:22,681:INFO:Visual Rendered Successfully
2025-12-02 18:48:22,836:INFO:plot_model() successfully completed......................................
2025-12-02 18:48:22,876:INFO:Initializing get_config()
2025-12-02 18:48:22,876:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265C4AAF0D0>, variable=X_test_transformed)
2025-12-02 18:48:22,944:INFO:Variable: X_test returned as             Age  IncomeRatio  SystolicBP       BMI  WaistCircumference  \
28456 -0.477273    -0.304717   -0.519256 -0.987220           -0.923253   
8993   0.818182     0.253271    2.156910  0.770675            0.920394   
34312  0.704545     0.055403    0.519256  0.518044            0.662901   
4802  -0.545455     0.253730   -0.331933 -0.229036           -0.436352   
25895  0.704545     1.226781   -0.093200 -0.226100            0.012322   
...         ...          ...         ...       ...                 ...   
18045 -0.568182    -0.083104   -0.568713 -1.176693           -1.338674   
5425   0.590909     0.362732    2.210168  0.139096            0.292112   
12819  0.909091    -0.019787    0.899042  0.454886            0.971892   
33659 -0.522727     1.060572   -0.525683 -0.587220           -0.906087   
19531 -0.590909    -0.344290   -0.510287 -0.945114           -1.215078   

         Height  TotalCholesterol  Triglycerides       LDL       HDL  ...  \
28456 -1.080540         -0.078535      -0.470757 -0.026922  0.418008  ...   
8993  -0.279669          0.765897       0.705031  0.006026  0.446825  ...   
34312  0.559339         -0.123259       0.929511 -1.031826 -1.404309  ...   
4802  -0.504861         -0.188325      -0.322647  0.000015 -0.138743  ...   
25895  0.216731          0.892919       1.291109  0.008211 -0.255329  ...   
...         ...               ...            ...       ...       ...  ...   
18045 -2.080569         -0.340947      -0.470582 -0.848950  0.393794  ...   
5425   0.156785          0.435639      -0.065356  1.113733  0.127664  ...   
12819  1.194951         -0.732967      -0.470025 -0.211535 -1.085148  ...   
33659 -1.254274         -1.063225      -0.470958 -2.849419  0.127664  ...   
19531 -2.339052         -0.356898      -0.470595 -0.900608  0.393896  ...   

       Race_5.0  Race_1.0  Race_4.0  Race_3.0  Race_2.0  Education   Smoking  \
28456       1.0       0.0       0.0       0.0       0.0  -0.012820  0.000000   
8993        0.0       0.0       1.0       0.0       0.0   0.547458  1.000000   
34312       0.0       0.0       0.0       1.0       0.0  -0.659696  0.000000   
4802        1.0       0.0       0.0       0.0       0.0   0.262895  0.073612   
25895       0.0       0.0       0.0       1.0       0.0   1.151035  0.000000   
...         ...       ...       ...       ...       ...        ...       ...   
18045       0.0       0.0       0.0       1.0       0.0  -0.793202  0.000000   
5425        0.0       0.0       1.0       0.0       0.0   0.547458  1.000000   
12819       0.0       0.0       0.0       1.0       0.0   1.151035  1.000000   
33659       0.0       0.0       1.0       0.0       0.0   0.258362  0.000000   
19531       1.0       0.0       0.0       0.0       0.0  -0.821118  0.000000   

       PhysicalActivity  HealthInsurance   Alcohol  
28456          0.660578              0.0 -0.518600  
8993           0.000000              0.0  0.115329  
34312          0.000000              0.0  0.592213  
4802           1.012447              0.0 -0.103347  
25895          0.000000              0.0 -0.886483  
...                 ...              ...       ...  
18045          0.904383              0.0 -0.482716  
5425           1.598141              0.0  0.097790  
12819          1.598141              0.0  0.612947  
33659          1.162475              0.0 -0.154408  
19531          0.791302              0.0 -0.683278  

[13109 rows x 31 columns]
2025-12-02 18:48:22,944:INFO:get_config() successfully completed......................................
2025-12-02 18:48:22,970:INFO:Initializing get_config()
2025-12-02 18:48:22,970:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265C4AAF0D0>, variable=y_test)
2025-12-02 18:48:22,970:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-12-02 18:48:22,971:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-12-02 18:48:22,973:INFO:Variable:  returned as 28456    0.0
8993     0.0
34312    0.0
4802     0.0
25895    0.0
        ... 
18045    0.0
5425     0.0
12819    0.0
33659    0.0
19531    0.0
Name: HeartDisease, Length: 13109, dtype: float32
2025-12-02 18:48:22,973:INFO:get_config() successfully completed......................................
2025-12-02 18:48:22,976:INFO:Initializing get_config()
2025-12-02 18:48:22,976:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265C4AAF0D0>, variable=y_test)
2025-12-02 18:48:22,976:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-12-02 18:48:22,976:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-12-02 18:48:22,976:INFO:Variable:  returned as 28456    0.0
8993     0.0
34312    0.0
4802     0.0
25895    0.0
        ... 
18045    0.0
5425     0.0
12819    0.0
33659    0.0
19531    0.0
Name: HeartDisease, Length: 13109, dtype: float32
2025-12-02 18:48:22,976:INFO:get_config() successfully completed......................................
2025-12-02 18:48:22,982:INFO:Initializing get_config()
2025-12-02 18:48:22,982:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265C4AAF0D0>, variable=X_test_transformed)
2025-12-02 18:48:23,042:INFO:Variable: X_test returned as             Age  IncomeRatio  SystolicBP       BMI  WaistCircumference  \
28456 -0.477273    -0.304717   -0.519256 -0.987220           -0.923253   
8993   0.818182     0.253271    2.156910  0.770675            0.920394   
34312  0.704545     0.055403    0.519256  0.518044            0.662901   
4802  -0.545455     0.253730   -0.331933 -0.229036           -0.436352   
25895  0.704545     1.226781   -0.093200 -0.226100            0.012322   
...         ...          ...         ...       ...                 ...   
18045 -0.568182    -0.083104   -0.568713 -1.176693           -1.338674   
5425   0.590909     0.362732    2.210168  0.139096            0.292112   
12819  0.909091    -0.019787    0.899042  0.454886            0.971892   
33659 -0.522727     1.060572   -0.525683 -0.587220           -0.906087   
19531 -0.590909    -0.344290   -0.510287 -0.945114           -1.215078   

         Height  TotalCholesterol  Triglycerides       LDL       HDL  ...  \
28456 -1.080540         -0.078535      -0.470757 -0.026922  0.418008  ...   
8993  -0.279669          0.765897       0.705031  0.006026  0.446825  ...   
34312  0.559339         -0.123259       0.929511 -1.031826 -1.404309  ...   
4802  -0.504861         -0.188325      -0.322647  0.000015 -0.138743  ...   
25895  0.216731          0.892919       1.291109  0.008211 -0.255329  ...   
...         ...               ...            ...       ...       ...  ...   
18045 -2.080569         -0.340947      -0.470582 -0.848950  0.393794  ...   
5425   0.156785          0.435639      -0.065356  1.113733  0.127664  ...   
12819  1.194951         -0.732967      -0.470025 -0.211535 -1.085148  ...   
33659 -1.254274         -1.063225      -0.470958 -2.849419  0.127664  ...   
19531 -2.339052         -0.356898      -0.470595 -0.900608  0.393896  ...   

       Race_5.0  Race_1.0  Race_4.0  Race_3.0  Race_2.0  Education   Smoking  \
28456       1.0       0.0       0.0       0.0       0.0  -0.012820  0.000000   
8993        0.0       0.0       1.0       0.0       0.0   0.547458  1.000000   
34312       0.0       0.0       0.0       1.0       0.0  -0.659696  0.000000   
4802        1.0       0.0       0.0       0.0       0.0   0.262895  0.073612   
25895       0.0       0.0       0.0       1.0       0.0   1.151035  0.000000   
...         ...       ...       ...       ...       ...        ...       ...   
18045       0.0       0.0       0.0       1.0       0.0  -0.793202  0.000000   
5425        0.0       0.0       1.0       0.0       0.0   0.547458  1.000000   
12819       0.0       0.0       0.0       1.0       0.0   1.151035  1.000000   
33659       0.0       0.0       1.0       0.0       0.0   0.258362  0.000000   
19531       1.0       0.0       0.0       0.0       0.0  -0.821118  0.000000   

       PhysicalActivity  HealthInsurance   Alcohol  
28456          0.660578              0.0 -0.518600  
8993           0.000000              0.0  0.115329  
34312          0.000000              0.0  0.592213  
4802           1.012447              0.0 -0.103347  
25895          0.000000              0.0 -0.886483  
...                 ...              ...       ...  
18045          0.904383              0.0 -0.482716  
5425           1.598141              0.0  0.097790  
12819          1.598141              0.0  0.612947  
33659          1.162475              0.0 -0.154408  
19531          0.791302              0.0 -0.683278  

[13109 rows x 31 columns]
2025-12-02 18:48:23,042:INFO:get_config() successfully completed......................................
2025-12-02 18:48:23,047:INFO:Initializing get_config()
2025-12-02 18:48:23,047:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265C4AAF0D0>, variable=y_test)
2025-12-02 18:48:23,047:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-12-02 18:48:23,047:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-12-02 18:48:23,051:INFO:Variable:  returned as 28456    0.0
8993     0.0
34312    0.0
4802     0.0
25895    0.0
        ... 
18045    0.0
5425     0.0
12819    0.0
33659    0.0
19531    0.0
Name: HeartDisease, Length: 13109, dtype: float32
2025-12-02 18:48:23,051:INFO:get_config() successfully completed......................................
2025-12-02 18:48:23,051:INFO:Initializing get_config()
2025-12-02 18:48:23,051:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265C4AAF0D0>, variable=y_test)
2025-12-02 18:48:23,051:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-12-02 18:48:23,051:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-12-02 18:48:23,056:INFO:Variable:  returned as 28456    0.0
8993     0.0
34312    0.0
4802     0.0
25895    0.0
        ... 
18045    0.0
5425     0.0
12819    0.0
33659    0.0
19531    0.0
Name: HeartDisease, Length: 13109, dtype: float32
2025-12-02 18:48:23,056:INFO:get_config() successfully completed......................................
2025-12-02 18:48:23,059:INFO:Initializing get_config()
2025-12-02 18:48:23,059:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265C4AAF0D0>, variable=X_test_transformed)
2025-12-02 18:48:23,123:INFO:Variable: X_test returned as             Age  IncomeRatio  SystolicBP       BMI  WaistCircumference  \
28456 -0.477273    -0.304717   -0.519256 -0.987220           -0.923253   
8993   0.818182     0.253271    2.156910  0.770675            0.920394   
34312  0.704545     0.055403    0.519256  0.518044            0.662901   
4802  -0.545455     0.253730   -0.331933 -0.229036           -0.436352   
25895  0.704545     1.226781   -0.093200 -0.226100            0.012322   
...         ...          ...         ...       ...                 ...   
18045 -0.568182    -0.083104   -0.568713 -1.176693           -1.338674   
5425   0.590909     0.362732    2.210168  0.139096            0.292112   
12819  0.909091    -0.019787    0.899042  0.454886            0.971892   
33659 -0.522727     1.060572   -0.525683 -0.587220           -0.906087   
19531 -0.590909    -0.344290   -0.510287 -0.945114           -1.215078   

         Height  TotalCholesterol  Triglycerides       LDL       HDL  ...  \
28456 -1.080540         -0.078535      -0.470757 -0.026922  0.418008  ...   
8993  -0.279669          0.765897       0.705031  0.006026  0.446825  ...   
34312  0.559339         -0.123259       0.929511 -1.031826 -1.404309  ...   
4802  -0.504861         -0.188325      -0.322647  0.000015 -0.138743  ...   
25895  0.216731          0.892919       1.291109  0.008211 -0.255329  ...   
...         ...               ...            ...       ...       ...  ...   
18045 -2.080569         -0.340947      -0.470582 -0.848950  0.393794  ...   
5425   0.156785          0.435639      -0.065356  1.113733  0.127664  ...   
12819  1.194951         -0.732967      -0.470025 -0.211535 -1.085148  ...   
33659 -1.254274         -1.063225      -0.470958 -2.849419  0.127664  ...   
19531 -2.339052         -0.356898      -0.470595 -0.900608  0.393896  ...   

       Race_5.0  Race_1.0  Race_4.0  Race_3.0  Race_2.0  Education   Smoking  \
28456       1.0       0.0       0.0       0.0       0.0  -0.012820  0.000000   
8993        0.0       0.0       1.0       0.0       0.0   0.547458  1.000000   
34312       0.0       0.0       0.0       1.0       0.0  -0.659696  0.000000   
4802        1.0       0.0       0.0       0.0       0.0   0.262895  0.073612   
25895       0.0       0.0       0.0       1.0       0.0   1.151035  0.000000   
...         ...       ...       ...       ...       ...        ...       ...   
18045       0.0       0.0       0.0       1.0       0.0  -0.793202  0.000000   
5425        0.0       0.0       1.0       0.0       0.0   0.547458  1.000000   
12819       0.0       0.0       0.0       1.0       0.0   1.151035  1.000000   
33659       0.0       0.0       1.0       0.0       0.0   0.258362  0.000000   
19531       1.0       0.0       0.0       0.0       0.0  -0.821118  0.000000   

       PhysicalActivity  HealthInsurance   Alcohol  
28456          0.660578              0.0 -0.518600  
8993           0.000000              0.0  0.115329  
34312          0.000000              0.0  0.592213  
4802           1.012447              0.0 -0.103347  
25895          0.000000              0.0 -0.886483  
...                 ...              ...       ...  
18045          0.904383              0.0 -0.482716  
5425           1.598141              0.0  0.097790  
12819          1.598141              0.0  0.612947  
33659          1.162475              0.0 -0.154408  
19531          0.791302              0.0 -0.683278  

[13109 rows x 31 columns]
2025-12-02 18:48:23,123:INFO:get_config() successfully completed......................................
2025-12-02 18:48:23,176:INFO:Initializing get_config()
2025-12-02 18:48:23,176:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265C4AAF0D0>, variable=y_test)
2025-12-02 18:48:23,176:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-12-02 18:48:23,176:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-12-02 18:48:23,182:INFO:Variable:  returned as 28456    0.0
8993     0.0
34312    0.0
4802     0.0
25895    0.0
        ... 
18045    0.0
5425     0.0
12819    0.0
33659    0.0
19531    0.0
Name: HeartDisease, Length: 13109, dtype: float32
2025-12-02 18:48:23,182:INFO:get_config() successfully completed......................................
2025-12-02 18:48:23,182:INFO:Initializing get_config()
2025-12-02 18:48:23,182:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265C4AAF0D0>, variable=y_test)
2025-12-02 18:48:23,182:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-12-02 18:48:23,182:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-12-02 18:48:23,186:INFO:Variable:  returned as 28456    0.0
8993     0.0
34312    0.0
4802     0.0
25895    0.0
        ... 
18045    0.0
5425     0.0
12819    0.0
33659    0.0
19531    0.0
Name: HeartDisease, Length: 13109, dtype: float32
2025-12-02 18:48:23,186:INFO:get_config() successfully completed......................................
2025-12-02 18:48:23,277:INFO:Initializing get_config()
2025-12-02 18:48:23,277:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265C4AAF0D0>, variable=X_test_transformed)
2025-12-02 18:48:23,347:INFO:Variable: X_test returned as             Age  IncomeRatio  SystolicBP       BMI  WaistCircumference  \
28456 -0.477273    -0.304717   -0.519256 -0.987220           -0.923253   
8993   0.818182     0.253271    2.156910  0.770675            0.920394   
34312  0.704545     0.055403    0.519256  0.518044            0.662901   
4802  -0.545455     0.253730   -0.331933 -0.229036           -0.436352   
25895  0.704545     1.226781   -0.093200 -0.226100            0.012322   
...         ...          ...         ...       ...                 ...   
18045 -0.568182    -0.083104   -0.568713 -1.176693           -1.338674   
5425   0.590909     0.362732    2.210168  0.139096            0.292112   
12819  0.909091    -0.019787    0.899042  0.454886            0.971892   
33659 -0.522727     1.060572   -0.525683 -0.587220           -0.906087   
19531 -0.590909    -0.344290   -0.510287 -0.945114           -1.215078   

         Height  TotalCholesterol  Triglycerides       LDL       HDL  ...  \
28456 -1.080540         -0.078535      -0.470757 -0.026922  0.418008  ...   
8993  -0.279669          0.765897       0.705031  0.006026  0.446825  ...   
34312  0.559339         -0.123259       0.929511 -1.031826 -1.404309  ...   
4802  -0.504861         -0.188325      -0.322647  0.000015 -0.138743  ...   
25895  0.216731          0.892919       1.291109  0.008211 -0.255329  ...   
...         ...               ...            ...       ...       ...  ...   
18045 -2.080569         -0.340947      -0.470582 -0.848950  0.393794  ...   
5425   0.156785          0.435639      -0.065356  1.113733  0.127664  ...   
12819  1.194951         -0.732967      -0.470025 -0.211535 -1.085148  ...   
33659 -1.254274         -1.063225      -0.470958 -2.849419  0.127664  ...   
19531 -2.339052         -0.356898      -0.470595 -0.900608  0.393896  ...   

       Race_5.0  Race_1.0  Race_4.0  Race_3.0  Race_2.0  Education   Smoking  \
28456       1.0       0.0       0.0       0.0       0.0  -0.012820  0.000000   
8993        0.0       0.0       1.0       0.0       0.0   0.547458  1.000000   
34312       0.0       0.0       0.0       1.0       0.0  -0.659696  0.000000   
4802        1.0       0.0       0.0       0.0       0.0   0.262895  0.073612   
25895       0.0       0.0       0.0       1.0       0.0   1.151035  0.000000   
...         ...       ...       ...       ...       ...        ...       ...   
18045       0.0       0.0       0.0       1.0       0.0  -0.793202  0.000000   
5425        0.0       0.0       1.0       0.0       0.0   0.547458  1.000000   
12819       0.0       0.0       0.0       1.0       0.0   1.151035  1.000000   
33659       0.0       0.0       1.0       0.0       0.0   0.258362  0.000000   
19531       1.0       0.0       0.0       0.0       0.0  -0.821118  0.000000   

       PhysicalActivity  HealthInsurance   Alcohol  
28456          0.660578              0.0 -0.518600  
8993           0.000000              0.0  0.115329  
34312          0.000000              0.0  0.592213  
4802           1.012447              0.0 -0.103347  
25895          0.000000              0.0 -0.886483  
...                 ...              ...       ...  
18045          0.904383              0.0 -0.482716  
5425           1.598141              0.0  0.097790  
12819          1.598141              0.0  0.612947  
33659          1.162475              0.0 -0.154408  
19531          0.791302              0.0 -0.683278  

[13109 rows x 31 columns]
2025-12-02 18:48:23,347:INFO:get_config() successfully completed......................................
2025-12-02 18:48:23,373:INFO:Initializing get_config()
2025-12-02 18:48:23,373:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265C4AAF0D0>, variable=y_test)
2025-12-02 18:48:23,373:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-12-02 18:48:23,373:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-12-02 18:48:23,376:INFO:Variable:  returned as 28456    0.0
8993     0.0
34312    0.0
4802     0.0
25895    0.0
        ... 
18045    0.0
5425     0.0
12819    0.0
33659    0.0
19531    0.0
Name: HeartDisease, Length: 13109, dtype: float32
2025-12-02 18:48:23,376:INFO:get_config() successfully completed......................................
2025-12-02 18:48:23,376:INFO:Initializing get_config()
2025-12-02 18:48:23,376:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265C4AAF0D0>, variable=X_test_transformed)
2025-12-02 18:48:23,442:INFO:Variable: X_test returned as             Age  IncomeRatio  SystolicBP       BMI  WaistCircumference  \
28456 -0.477273    -0.304717   -0.519256 -0.987220           -0.923253   
8993   0.818182     0.253271    2.156910  0.770675            0.920394   
34312  0.704545     0.055403    0.519256  0.518044            0.662901   
4802  -0.545455     0.253730   -0.331933 -0.229036           -0.436352   
25895  0.704545     1.226781   -0.093200 -0.226100            0.012322   
...         ...          ...         ...       ...                 ...   
18045 -0.568182    -0.083104   -0.568713 -1.176693           -1.338674   
5425   0.590909     0.362732    2.210168  0.139096            0.292112   
12819  0.909091    -0.019787    0.899042  0.454886            0.971892   
33659 -0.522727     1.060572   -0.525683 -0.587220           -0.906087   
19531 -0.590909    -0.344290   -0.510287 -0.945114           -1.215078   

         Height  TotalCholesterol  Triglycerides       LDL       HDL  ...  \
28456 -1.080540         -0.078535      -0.470757 -0.026922  0.418008  ...   
8993  -0.279669          0.765897       0.705031  0.006026  0.446825  ...   
34312  0.559339         -0.123259       0.929511 -1.031826 -1.404309  ...   
4802  -0.504861         -0.188325      -0.322647  0.000015 -0.138743  ...   
25895  0.216731          0.892919       1.291109  0.008211 -0.255329  ...   
...         ...               ...            ...       ...       ...  ...   
18045 -2.080569         -0.340947      -0.470582 -0.848950  0.393794  ...   
5425   0.156785          0.435639      -0.065356  1.113733  0.127664  ...   
12819  1.194951         -0.732967      -0.470025 -0.211535 -1.085148  ...   
33659 -1.254274         -1.063225      -0.470958 -2.849419  0.127664  ...   
19531 -2.339052         -0.356898      -0.470595 -0.900608  0.393896  ...   

       Race_5.0  Race_1.0  Race_4.0  Race_3.0  Race_2.0  Education   Smoking  \
28456       1.0       0.0       0.0       0.0       0.0  -0.012820  0.000000   
8993        0.0       0.0       1.0       0.0       0.0   0.547458  1.000000   
34312       0.0       0.0       0.0       1.0       0.0  -0.659696  0.000000   
4802        1.0       0.0       0.0       0.0       0.0   0.262895  0.073612   
25895       0.0       0.0       0.0       1.0       0.0   1.151035  0.000000   
...         ...       ...       ...       ...       ...        ...       ...   
18045       0.0       0.0       0.0       1.0       0.0  -0.793202  0.000000   
5425        0.0       0.0       1.0       0.0       0.0   0.547458  1.000000   
12819       0.0       0.0       0.0       1.0       0.0   1.151035  1.000000   
33659       0.0       0.0       1.0       0.0       0.0   0.258362  0.000000   
19531       1.0       0.0       0.0       0.0       0.0  -0.821118  0.000000   

       PhysicalActivity  HealthInsurance   Alcohol  
28456          0.660578              0.0 -0.518600  
8993           0.000000              0.0  0.115329  
34312          0.000000              0.0  0.592213  
4802           1.012447              0.0 -0.103347  
25895          0.000000              0.0 -0.886483  
...                 ...              ...       ...  
18045          0.904383              0.0 -0.482716  
5425           1.598141              0.0  0.097790  
12819          1.598141              0.0  0.612947  
33659          1.162475              0.0 -0.154408  
19531          0.791302              0.0 -0.683278  

[13109 rows x 31 columns]
2025-12-02 18:48:23,442:INFO:get_config() successfully completed......................................
2025-12-02 18:48:23,442:INFO:Initializing get_config()
2025-12-02 18:48:23,442:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265C4AAF0D0>, variable=y_test)
2025-12-02 18:48:23,442:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-12-02 18:48:23,442:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-12-02 18:48:23,451:INFO:Variable:  returned as 28456    0.0
8993     0.0
34312    0.0
4802     0.0
25895    0.0
        ... 
18045    0.0
5425     0.0
12819    0.0
33659    0.0
19531    0.0
Name: HeartDisease, Length: 13109, dtype: float32
2025-12-02 18:48:23,451:INFO:get_config() successfully completed......................................
2025-12-02 18:48:23,451:INFO:Initializing get_config()
2025-12-02 18:48:23,451:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265C4AAF0D0>, variable=X_test_transformed)
2025-12-02 18:48:23,516:INFO:Variable: X_test returned as             Age  IncomeRatio  SystolicBP       BMI  WaistCircumference  \
28456 -0.477273    -0.304717   -0.519256 -0.987220           -0.923253   
8993   0.818182     0.253271    2.156910  0.770675            0.920394   
34312  0.704545     0.055403    0.519256  0.518044            0.662901   
4802  -0.545455     0.253730   -0.331933 -0.229036           -0.436352   
25895  0.704545     1.226781   -0.093200 -0.226100            0.012322   
...         ...          ...         ...       ...                 ...   
18045 -0.568182    -0.083104   -0.568713 -1.176693           -1.338674   
5425   0.590909     0.362732    2.210168  0.139096            0.292112   
12819  0.909091    -0.019787    0.899042  0.454886            0.971892   
33659 -0.522727     1.060572   -0.525683 -0.587220           -0.906087   
19531 -0.590909    -0.344290   -0.510287 -0.945114           -1.215078   

         Height  TotalCholesterol  Triglycerides       LDL       HDL  ...  \
28456 -1.080540         -0.078535      -0.470757 -0.026922  0.418008  ...   
8993  -0.279669          0.765897       0.705031  0.006026  0.446825  ...   
34312  0.559339         -0.123259       0.929511 -1.031826 -1.404309  ...   
4802  -0.504861         -0.188325      -0.322647  0.000015 -0.138743  ...   
25895  0.216731          0.892919       1.291109  0.008211 -0.255329  ...   
...         ...               ...            ...       ...       ...  ...   
18045 -2.080569         -0.340947      -0.470582 -0.848950  0.393794  ...   
5425   0.156785          0.435639      -0.065356  1.113733  0.127664  ...   
12819  1.194951         -0.732967      -0.470025 -0.211535 -1.085148  ...   
33659 -1.254274         -1.063225      -0.470958 -2.849419  0.127664  ...   
19531 -2.339052         -0.356898      -0.470595 -0.900608  0.393896  ...   

       Race_5.0  Race_1.0  Race_4.0  Race_3.0  Race_2.0  Education   Smoking  \
28456       1.0       0.0       0.0       0.0       0.0  -0.012820  0.000000   
8993        0.0       0.0       1.0       0.0       0.0   0.547458  1.000000   
34312       0.0       0.0       0.0       1.0       0.0  -0.659696  0.000000   
4802        1.0       0.0       0.0       0.0       0.0   0.262895  0.073612   
25895       0.0       0.0       0.0       1.0       0.0   1.151035  0.000000   
...         ...       ...       ...       ...       ...        ...       ...   
18045       0.0       0.0       0.0       1.0       0.0  -0.793202  0.000000   
5425        0.0       0.0       1.0       0.0       0.0   0.547458  1.000000   
12819       0.0       0.0       0.0       1.0       0.0   1.151035  1.000000   
33659       0.0       0.0       1.0       0.0       0.0   0.258362  0.000000   
19531       1.0       0.0       0.0       0.0       0.0  -0.821118  0.000000   

       PhysicalActivity  HealthInsurance   Alcohol  
28456          0.660578              0.0 -0.518600  
8993           0.000000              0.0  0.115329  
34312          0.000000              0.0  0.592213  
4802           1.012447              0.0 -0.103347  
25895          0.000000              0.0 -0.886483  
...                 ...              ...       ...  
18045          0.904383              0.0 -0.482716  
5425           1.598141              0.0  0.097790  
12819          1.598141              0.0  0.612947  
33659          1.162475              0.0 -0.154408  
19531          0.791302              0.0 -0.683278  

[13109 rows x 31 columns]
2025-12-02 18:48:23,516:INFO:get_config() successfully completed......................................
2025-12-02 18:48:23,573:INFO:Initializing get_config()
2025-12-02 18:48:23,573:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265C4AAF0D0>, variable=y_test)
2025-12-02 18:48:23,573:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-12-02 18:48:23,573:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-12-02 18:48:23,576:INFO:Variable:  returned as 28456    0.0
8993     0.0
34312    0.0
4802     0.0
25895    0.0
        ... 
18045    0.0
5425     0.0
12819    0.0
33659    0.0
19531    0.0
Name: HeartDisease, Length: 13109, dtype: float32
2025-12-02 18:48:23,576:INFO:get_config() successfully completed......................................
2025-12-02 18:48:23,636:INFO:Initializing get_config()
2025-12-02 18:48:23,636:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265C4AAF0D0>, variable=X_test_transformed)
2025-12-02 18:48:23,704:INFO:Variable: X_test returned as             Age  IncomeRatio  SystolicBP       BMI  WaistCircumference  \
28456 -0.477273    -0.304717   -0.519256 -0.987220           -0.923253   
8993   0.818182     0.253271    2.156910  0.770675            0.920394   
34312  0.704545     0.055403    0.519256  0.518044            0.662901   
4802  -0.545455     0.253730   -0.331933 -0.229036           -0.436352   
25895  0.704545     1.226781   -0.093200 -0.226100            0.012322   
...         ...          ...         ...       ...                 ...   
18045 -0.568182    -0.083104   -0.568713 -1.176693           -1.338674   
5425   0.590909     0.362732    2.210168  0.139096            0.292112   
12819  0.909091    -0.019787    0.899042  0.454886            0.971892   
33659 -0.522727     1.060572   -0.525683 -0.587220           -0.906087   
19531 -0.590909    -0.344290   -0.510287 -0.945114           -1.215078   

         Height  TotalCholesterol  Triglycerides       LDL       HDL  ...  \
28456 -1.080540         -0.078535      -0.470757 -0.026922  0.418008  ...   
8993  -0.279669          0.765897       0.705031  0.006026  0.446825  ...   
34312  0.559339         -0.123259       0.929511 -1.031826 -1.404309  ...   
4802  -0.504861         -0.188325      -0.322647  0.000015 -0.138743  ...   
25895  0.216731          0.892919       1.291109  0.008211 -0.255329  ...   
...         ...               ...            ...       ...       ...  ...   
18045 -2.080569         -0.340947      -0.470582 -0.848950  0.393794  ...   
5425   0.156785          0.435639      -0.065356  1.113733  0.127664  ...   
12819  1.194951         -0.732967      -0.470025 -0.211535 -1.085148  ...   
33659 -1.254274         -1.063225      -0.470958 -2.849419  0.127664  ...   
19531 -2.339052         -0.356898      -0.470595 -0.900608  0.393896  ...   

       Race_5.0  Race_1.0  Race_4.0  Race_3.0  Race_2.0  Education   Smoking  \
28456       1.0       0.0       0.0       0.0       0.0  -0.012820  0.000000   
8993        0.0       0.0       1.0       0.0       0.0   0.547458  1.000000   
34312       0.0       0.0       0.0       1.0       0.0  -0.659696  0.000000   
4802        1.0       0.0       0.0       0.0       0.0   0.262895  0.073612   
25895       0.0       0.0       0.0       1.0       0.0   1.151035  0.000000   
...         ...       ...       ...       ...       ...        ...       ...   
18045       0.0       0.0       0.0       1.0       0.0  -0.793202  0.000000   
5425        0.0       0.0       1.0       0.0       0.0   0.547458  1.000000   
12819       0.0       0.0       0.0       1.0       0.0   1.151035  1.000000   
33659       0.0       0.0       1.0       0.0       0.0   0.258362  0.000000   
19531       1.0       0.0       0.0       0.0       0.0  -0.821118  0.000000   

       PhysicalActivity  HealthInsurance   Alcohol  
28456          0.660578              0.0 -0.518600  
8993           0.000000              0.0  0.115329  
34312          0.000000              0.0  0.592213  
4802           1.012447              0.0 -0.103347  
25895          0.000000              0.0 -0.886483  
...                 ...              ...       ...  
18045          0.904383              0.0 -0.482716  
5425           1.598141              0.0  0.097790  
12819          1.598141              0.0  0.612947  
33659          1.162475              0.0 -0.154408  
19531          0.791302              0.0 -0.683278  

[13109 rows x 31 columns]
2025-12-02 18:48:23,704:INFO:get_config() successfully completed......................................
2025-12-02 18:48:23,730:INFO:Initializing get_config()
2025-12-02 18:48:23,730:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265C4AAF0D0>, variable=y_test)
2025-12-02 18:48:23,731:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-12-02 18:48:23,731:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-12-02 18:48:23,736:INFO:Variable:  returned as 28456    0.0
8993     0.0
34312    0.0
4802     0.0
25895    0.0
        ... 
18045    0.0
5425     0.0
12819    0.0
33659    0.0
19531    0.0
Name: HeartDisease, Length: 13109, dtype: float32
2025-12-02 18:48:23,736:INFO:get_config() successfully completed......................................
2025-12-02 18:48:23,964:INFO:Initializing get_config()
2025-12-02 18:48:23,964:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265C4AAF0D0>, variable=y_test)
2025-12-02 18:48:23,964:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-12-02 18:48:23,964:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-12-02 18:48:23,971:INFO:Variable:  returned as 28456    0.0
8993     0.0
34312    0.0
4802     0.0
25895    0.0
        ... 
18045    0.0
5425     0.0
12819    0.0
33659    0.0
19531    0.0
Name: HeartDisease, Length: 13109, dtype: float32
2025-12-02 18:48:23,971:INFO:get_config() successfully completed......................................
2025-12-02 18:48:23,971:INFO:Initializing get_config()
2025-12-02 18:48:23,971:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265C4AAF0D0>, variable=X_test_transformed)
2025-12-02 18:48:24,065:INFO:Variable: X_test returned as             Age  IncomeRatio  SystolicBP       BMI  WaistCircumference  \
28456 -0.477273    -0.304717   -0.519256 -0.987220           -0.923253   
8993   0.818182     0.253271    2.156910  0.770675            0.920394   
34312  0.704545     0.055403    0.519256  0.518044            0.662901   
4802  -0.545455     0.253730   -0.331933 -0.229036           -0.436352   
25895  0.704545     1.226781   -0.093200 -0.226100            0.012322   
...         ...          ...         ...       ...                 ...   
18045 -0.568182    -0.083104   -0.568713 -1.176693           -1.338674   
5425   0.590909     0.362732    2.210168  0.139096            0.292112   
12819  0.909091    -0.019787    0.899042  0.454886            0.971892   
33659 -0.522727     1.060572   -0.525683 -0.587220           -0.906087   
19531 -0.590909    -0.344290   -0.510287 -0.945114           -1.215078   

         Height  TotalCholesterol  Triglycerides       LDL       HDL  ...  \
28456 -1.080540         -0.078535      -0.470757 -0.026922  0.418008  ...   
8993  -0.279669          0.765897       0.705031  0.006026  0.446825  ...   
34312  0.559339         -0.123259       0.929511 -1.031826 -1.404309  ...   
4802  -0.504861         -0.188325      -0.322647  0.000015 -0.138743  ...   
25895  0.216731          0.892919       1.291109  0.008211 -0.255329  ...   
...         ...               ...            ...       ...       ...  ...   
18045 -2.080569         -0.340947      -0.470582 -0.848950  0.393794  ...   
5425   0.156785          0.435639      -0.065356  1.113733  0.127664  ...   
12819  1.194951         -0.732967      -0.470025 -0.211535 -1.085148  ...   
33659 -1.254274         -1.063225      -0.470958 -2.849419  0.127664  ...   
19531 -2.339052         -0.356898      -0.470595 -0.900608  0.393896  ...   

       Race_5.0  Race_1.0  Race_4.0  Race_3.0  Race_2.0  Education   Smoking  \
28456       1.0       0.0       0.0       0.0       0.0  -0.012820  0.000000   
8993        0.0       0.0       1.0       0.0       0.0   0.547458  1.000000   
34312       0.0       0.0       0.0       1.0       0.0  -0.659696  0.000000   
4802        1.0       0.0       0.0       0.0       0.0   0.262895  0.073612   
25895       0.0       0.0       0.0       1.0       0.0   1.151035  0.000000   
...         ...       ...       ...       ...       ...        ...       ...   
18045       0.0       0.0       0.0       1.0       0.0  -0.793202  0.000000   
5425        0.0       0.0       1.0       0.0       0.0   0.547458  1.000000   
12819       0.0       0.0       0.0       1.0       0.0   1.151035  1.000000   
33659       0.0       0.0       1.0       0.0       0.0   0.258362  0.000000   
19531       1.0       0.0       0.0       0.0       0.0  -0.821118  0.000000   

       PhysicalActivity  HealthInsurance   Alcohol  
28456          0.660578              0.0 -0.518600  
8993           0.000000              0.0  0.115329  
34312          0.000000              0.0  0.592213  
4802           1.012447              0.0 -0.103347  
25895          0.000000              0.0 -0.886483  
...                 ...              ...       ...  
18045          0.904383              0.0 -0.482716  
5425           1.598141              0.0  0.097790  
12819          1.598141              0.0  0.612947  
33659          1.162475              0.0 -0.154408  
19531          0.791302              0.0 -0.683278  

[13109 rows x 31 columns]
2025-12-02 18:48:24,065:INFO:get_config() successfully completed......................................
2025-12-02 18:48:24,197:INFO:Initializing get_config()
2025-12-02 18:48:24,197:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265C4AAF0D0>, variable=X_train_transformed)
2025-12-02 18:48:24,242:INFO:Variable: X_train returned as             Age  IncomeRatio  SystolicBP       BMI  WaistCircumference  \
15208  0.954545     0.854789    0.359485  0.518044            0.206281   
25325 -0.272727     0.253271   -0.812170 -0.966167           -0.799656   
5132   0.181818    -0.407608   -0.372799  0.054886            0.319578   
17217  0.500000    -0.751898    0.013314 -0.260904            0.278379   
6382   0.568182     0.054503    1.131712  2.675938            1.888566   
...         ...          ...         ...       ...                 ...   
6265  -0.545455    -0.431352   -0.591719  0.191728           -0.377368   
42694 -0.022727    -0.221612   -0.892056 -0.260904           -0.047778   
13399  0.454545     0.388518    0.377985  0.271482            0.183567   
39959  0.954545    -0.193911    0.625770  0.991728            1.160720   
6616   0.613636    -0.447182    0.652399 -0.871430           -0.514698   

         Height  TotalCholesterol  Triglycerides       LDL       HDL  ...  \
15208 -0.487303          0.625876       0.583394  0.005397  0.314564  ...   
25325 -0.300856          0.033588      -0.261476  0.000256  0.303682  ...   
5132   0.766972          0.181594       0.479279  0.948690 -1.340476  ...   
17217  0.745785          0.227516       0.346113  0.002441 -0.274561  ...   
6382   0.237295          0.867515       0.635574  0.002754  0.829819  ...   
...         ...               ...            ...       ...       ...  ...   
6265  -1.737339         -1.393483      -0.471046 -3.840886  0.063832  ...   
42694  0.000000          0.029167      -0.131730  0.000893  0.063832  ...   
13399 -0.147405          0.462357       0.380371  0.003925  0.256949  ...   
39959  0.368655          1.528031       1.934134  0.011744  0.191497  ...   
6616  -0.021187         -0.224877      -0.043571 -1.609476  0.510658  ...   

       Race_5.0  Race_1.0  Race_4.0  Race_3.0  Race_2.0  Education  Smoking  \
15208       1.0       0.0       0.0       0.0       0.0  -0.659696      0.0   
25325       0.0       1.0       0.0       0.0       0.0   0.185278      0.0   
5132        0.0       1.0       0.0       0.0       0.0  -0.659696      1.0   
17217       0.0       0.0       1.0       0.0       0.0  -0.056119      1.0   
6382        0.0       0.0       1.0       0.0       0.0   0.547458      1.0   
...         ...       ...       ...       ...       ...        ...      ...   
6265        0.0       1.0       0.0       0.0       0.0  -0.769055      0.0   
42694       0.0       1.0       0.0       0.0       0.0   0.547458      0.0   
13399       0.0       0.0       1.0       0.0       0.0   0.547458      0.0   
39959       0.0       0.0       0.0       1.0       0.0   0.547458      0.0   
6616        0.0       0.0       0.0       1.0       0.0   0.547458      1.0   

       PhysicalActivity  HealthInsurance   Alcohol  
15208          0.000000              0.0 -0.886483  
25325          0.000000              0.0  0.592213  
5132           0.000000             -1.0  0.312949  
17217          0.000000              0.0  0.592213  
6382           0.000000              0.0  0.597293  
...                 ...              ...       ...  
6265           0.662459              0.0 -0.501621  
42694          0.000000             -1.0  0.592213  
13399          0.000000              0.0 -0.224534  
39959          0.000000              0.0  0.592213  
6616           0.000000              0.0  0.290247  

[30586 rows x 31 columns]
2025-12-02 18:48:24,242:INFO:get_config() successfully completed......................................
2025-12-02 18:48:24,276:INFO:Initializing tune_model()
2025-12-02 18:48:24,276:INFO:tune_model(estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...), fold=None, round=4, n_iter=5, custom_grid=None, optimize=Recall, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=False, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265C4AAF0D0>)
2025-12-02 18:48:24,276:INFO:Checking exceptions
2025-12-02 18:48:24,289:INFO:Copying training dataset
2025-12-02 18:48:24,306:INFO:Checking base model
2025-12-02 18:48:24,306:INFO:Base model : Extreme Gradient Boosting
2025-12-02 18:48:24,306:INFO:Declaring metric variables
2025-12-02 18:48:24,306:INFO:Defining Hyperparameters
2025-12-02 18:48:24,484:INFO:Tuning with n_jobs=1
2025-12-02 18:48:24,484:INFO:Initializing RandomizedSearchCV
2025-12-02 18:48:57,681:INFO:best_params: {'actual_estimator__subsample': 0.7, 'actual_estimator__scale_pos_weight': 38.0, 'actual_estimator__reg_lambda': 0.7, 'actual_estimator__reg_alpha': 0.001, 'actual_estimator__n_estimators': 60, 'actual_estimator__min_child_weight': 1, 'actual_estimator__max_depth': 6, 'actual_estimator__learning_rate': 0.4, 'actual_estimator__colsample_bytree': 0.7}
2025-12-02 18:48:57,681:INFO:Hyperparameter search completed
2025-12-02 18:48:57,681:INFO:SubProcess create_model() called ==================================
2025-12-02 18:48:57,681:INFO:Initializing create_model()
2025-12-02 18:48:57,681:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265C4AAF0D0>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000265E01B2DD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'subsample': 0.7, 'scale_pos_weight': 38.0, 'reg_lambda': 0.7, 'reg_alpha': 0.001, 'n_estimators': 60, 'min_child_weight': 1, 'max_depth': 6, 'learning_rate': 0.4, 'colsample_bytree': 0.7})
2025-12-02 18:48:57,681:INFO:Checking exceptions
2025-12-02 18:48:57,681:INFO:Importing libraries
2025-12-02 18:48:57,681:INFO:Copying training dataset
2025-12-02 18:48:57,706:INFO:Defining folds
2025-12-02 18:48:57,706:INFO:Declaring metric variables
2025-12-02 18:48:57,706:INFO:Importing untrained model
2025-12-02 18:48:57,706:INFO:Declaring custom model
2025-12-02 18:48:57,706:INFO:Extreme Gradient Boosting Imported successfully
2025-12-02 18:48:57,706:INFO:Starting cross validation
2025-12-02 18:48:57,709:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-12-02 18:49:02,387:INFO:Calculating mean and std
2025-12-02 18:49:02,387:INFO:Creating metrics dataframe
2025-12-02 18:49:02,387:INFO:Finalizing model
2025-12-02 18:49:02,454:INFO:Warning: No categorical columns found. Calling 'transform' will only return input data.
2025-12-02 18:49:02,865:INFO:Uploading results into container
2025-12-02 18:49:02,865:INFO:Uploading model into container now
2025-12-02 18:49:02,867:INFO:_master_model_container: 4
2025-12-02 18:49:02,867:INFO:_display_container: 5
2025-12-02 18:49:02,867:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=0.7, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=0.4, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=6, max_leaves=None,
              min_child_weight=1, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=60, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2025-12-02 18:49:02,867:INFO:create_model() successfully completed......................................
2025-12-02 18:49:03,060:INFO:SubProcess create_model() end ==================================
2025-12-02 18:49:03,060:INFO:choose_better activated
2025-12-02 18:49:03,060:INFO:SubProcess create_model() called ==================================
2025-12-02 18:49:03,064:INFO:Initializing create_model()
2025-12-02 18:49:03,064:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265C4AAF0D0>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-02 18:49:03,064:INFO:Checking exceptions
2025-12-02 18:49:03,064:INFO:Importing libraries
2025-12-02 18:49:03,064:INFO:Copying training dataset
2025-12-02 18:49:03,092:INFO:Defining folds
2025-12-02 18:49:03,092:INFO:Declaring metric variables
2025-12-02 18:49:03,092:INFO:Importing untrained model
2025-12-02 18:49:03,092:INFO:Declaring custom model
2025-12-02 18:49:03,094:INFO:Extreme Gradient Boosting Imported successfully
2025-12-02 18:49:03,094:INFO:Starting cross validation
2025-12-02 18:49:03,095:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-12-02 18:49:09,036:INFO:Calculating mean and std
2025-12-02 18:49:09,036:INFO:Creating metrics dataframe
2025-12-02 18:49:09,036:INFO:Finalizing model
2025-12-02 18:49:09,104:INFO:Warning: No categorical columns found. Calling 'transform' will only return input data.
2025-12-02 18:49:09,609:INFO:Uploading results into container
2025-12-02 18:49:09,611:INFO:Uploading model into container now
2025-12-02 18:49:09,611:INFO:_master_model_container: 5
2025-12-02 18:49:09,611:INFO:_display_container: 6
2025-12-02 18:49:09,611:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2025-12-02 18:49:09,611:INFO:create_model() successfully completed......................................
2025-12-02 18:49:09,792:INFO:SubProcess create_model() end ==================================
2025-12-02 18:49:09,794:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...) result for Recall is 0.3112
2025-12-02 18:49:09,794:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=0.7, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=0.4, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=6, max_leaves=None,
              min_child_weight=1, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=60, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...) result for Recall is 0.3316
2025-12-02 18:49:09,794:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=0.7, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=0.4, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=6, max_leaves=None,
              min_child_weight=1, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=60, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...) is best model
2025-12-02 18:49:09,794:INFO:choose_better completed
2025-12-02 18:49:09,796:INFO:_master_model_container: 5
2025-12-02 18:49:09,796:INFO:_display_container: 5
2025-12-02 18:49:09,796:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=0.7, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=0.4, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=6, max_leaves=None,
              min_child_weight=1, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=60, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2025-12-02 18:49:09,796:INFO:tune_model() successfully completed......................................
2025-12-02 18:49:09,989:INFO:Initializing predict_model()
2025-12-02 18:49:09,989:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265C4AAF0D0>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=0.7, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=0.4, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=6, max_leaves=None,
              min_child_weight=1, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=60, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...), probability_threshold=None, encoded_labels=False, raw_score=True, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000265EDBD8E50>)
2025-12-02 18:49:09,989:INFO:Checking exceptions
2025-12-02 18:49:09,989:INFO:Preloading libraries
2025-12-02 18:49:10,360:INFO:Initializing get_config()
2025-12-02 18:49:10,360:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265C4AAF0D0>, variable=target_param)
2025-12-02 18:49:10,360:INFO:Variable:  returned as HeartDisease
2025-12-02 18:49:10,360:INFO:get_config() successfully completed......................................
2025-12-02 18:49:11,092:INFO:Initializing interpret_model()
2025-12-02 18:49:11,092:INFO:interpret_model(estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=0.7, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=0.4, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=6, max_leaves=None,
              min_child_weight=1, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=60, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...), use_train_data=False, X_new_sample=None, y_new_sample=None, feature=None, kwargs={}, observation=None, plot=summary, save=False, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265C4AAF0D0>)
2025-12-02 18:49:11,092:INFO:Checking exceptions
2025-12-02 18:49:11,092:INFO:Soft dependency imported: shap: 0.49.1
2025-12-02 18:49:11,173:INFO:plot type: summary
2025-12-02 18:49:11,173:INFO:Creating TreeExplainer
2025-12-02 18:49:11,190:INFO:Compiling shap values
2025-12-02 18:49:14,546:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:4145: FutureWarning: The NumPy global RNG was seeded by calling `np.random.seed`. In a future version this function will no longer use the global RNG. Pass `rng` explicitly to opt-in to the new behaviour and silence this warning.

2025-12-02 18:49:15,696:INFO:Visual Rendered Successfully
2025-12-02 18:49:15,696:INFO:interpret_model() successfully completed......................................
2025-12-02 18:49:15,915:INFO:Initializing predict_model()
2025-12-02 18:49:15,915:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265C4AAF0D0>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...), probability_threshold=None, encoded_labels=False, raw_score=True, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000265DFE97880>)
2025-12-02 18:49:15,915:INFO:Checking exceptions
2025-12-02 18:49:15,915:INFO:Preloading libraries
2025-12-02 18:49:16,314:INFO:Initializing get_config()
2025-12-02 18:49:16,314:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265C4AAF0D0>, variable=target_param)
2025-12-02 18:49:16,314:INFO:Variable:  returned as HeartDisease
2025-12-02 18:49:16,314:INFO:get_config() successfully completed......................................
2025-12-02 18:49:16,451:INFO:Initializing finalize_model()
2025-12-02 18:49:16,451:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265C4AAF0D0>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=0.7, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=0.4, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=6, max_leaves=None,
              min_child_weight=1, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=60, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2025-12-02 18:49:16,451:INFO:Finalizing XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=0.7, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=0.4, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=6, max_leaves=None,
              min_child_weight=1, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=60, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2025-12-02 18:49:16,465:INFO:Initializing create_model()
2025-12-02 18:49:16,465:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265C4AAF0D0>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=0.7, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=0.4, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=6, max_leaves=None,
              min_child_weight=1, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=60, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2025-12-02 18:49:16,465:INFO:Checking exceptions
2025-12-02 18:49:16,465:INFO:Importing libraries
2025-12-02 18:49:16,465:INFO:Copying training dataset
2025-12-02 18:49:16,471:INFO:Defining folds
2025-12-02 18:49:16,471:INFO:Declaring metric variables
2025-12-02 18:49:16,471:INFO:Importing untrained model
2025-12-02 18:49:16,471:INFO:Declaring custom model
2025-12-02 18:49:16,473:INFO:Extreme Gradient Boosting Imported successfully
2025-12-02 18:49:16,474:INFO:Cross validation set to False
2025-12-02 18:49:16,474:INFO:Fitting Model
2025-12-02 18:49:16,556:INFO:Warning: No categorical columns found. Calling 'transform' will only return input data.
2025-12-02 18:49:17,063:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'IncomeRatio', 'SystolicBP',
                                             'BMI', 'WaistCircumference',
                                             'Height', 'TotalCholesterol',
                                             'Triglycerides', 'LDL', 'HDL',
                                             'HbA1c', 'Glucose', 'Creatinine',
                                             'UricAcid', 'ALT_Enzyme',
                                             'Albumin', 'Potassium', 'Sodium',
                                             'GGT_Enzyme', 'AST_Enzyme'],
                                    transformer=Si...
                               feature_types=None, gamma=None, grow_policy=None,
                               importance_type=None,
                               interaction_constraints=None, learning_rate=0.4,
                               max_bin=None, max_cat_threshold=None,
                               max_cat_to_onehot=None, max_delta_step=None,
                               max_depth=6, max_leaves=None, min_child_weight=1,
                               missing=nan, monotone_constraints=None,
                               multi_strategy=None, n_estimators=60, n_jobs=1,
                               num_parallel_tree=None,
                               objective='binary:logistic', ...))],
         verbose=False)
2025-12-02 18:49:17,063:INFO:create_model() successfully completed......................................
2025-12-02 18:49:17,231:INFO:_master_model_container: 5
2025-12-02 18:49:17,231:INFO:_display_container: 7
2025-12-02 18:49:17,247:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'IncomeRatio', 'SystolicBP',
                                             'BMI', 'WaistCircumference',
                                             'Height', 'TotalCholesterol',
                                             'Triglycerides', 'LDL', 'HDL',
                                             'HbA1c', 'Glucose', 'Creatinine',
                                             'UricAcid', 'ALT_Enzyme',
                                             'Albumin', 'Potassium', 'Sodium',
                                             'GGT_Enzyme', 'AST_Enzyme'],
                                    transformer=Si...
                               feature_types=None, gamma=None, grow_policy=None,
                               importance_type=None,
                               interaction_constraints=None, learning_rate=0.4,
                               max_bin=None, max_cat_threshold=None,
                               max_cat_to_onehot=None, max_delta_step=None,
                               max_depth=6, max_leaves=None, min_child_weight=1,
                               missing=nan, monotone_constraints=None,
                               multi_strategy=None, n_estimators=60, n_jobs=1,
                               num_parallel_tree=None,
                               objective='binary:logistic', ...))],
         verbose=False)
2025-12-02 18:49:17,247:INFO:finalize_model() successfully completed......................................
2025-12-02 18:49:17,426:INFO:Initializing save_model()
2025-12-02 18:49:17,426:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'IncomeRatio', 'SystolicBP',
                                             'BMI', 'WaistCircumference',
                                             'Height', 'TotalCholesterol',
                                             'Triglycerides', 'LDL', 'HDL',
                                             'HbA1c', 'Glucose', 'Creatinine',
                                             'UricAcid', 'ALT_Enzyme',
                                             'Albumin', 'Potassium', 'Sodium',
                                             'GGT_Enzyme', 'AST_Enzyme'],
                                    transformer=Si...
                               feature_types=None, gamma=None, grow_policy=None,
                               importance_type=None,
                               interaction_constraints=None, learning_rate=0.4,
                               max_bin=None, max_cat_threshold=None,
                               max_cat_to_onehot=None, max_delta_step=None,
                               max_depth=6, max_leaves=None, min_child_weight=1,
                               missing=nan, monotone_constraints=None,
                               multi_strategy=None, n_estimators=60, n_jobs=1,
                               num_parallel_tree=None,
                               objective='binary:logistic', ...))],
         verbose=False), model_name=../models\best_pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\OMAR\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'IncomeRatio', 'SystolicBP',
                                             'BMI', 'WaistCircumference',
                                             'Height', 'TotalCholesterol',
                                             'Triglycerides', 'LDL', 'HDL',
                                             'HbA1c', 'Glucose', 'Creatinine',
                                             'UricAcid', 'ALT_Enzyme',
                                             'Albumin', 'Potassium', 'Sodium',
                                             'G...
                                    transformer=TargetEncoder(cols=[],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=RobustScaler(copy=True,
                                                             quantile_range=(25.0,
                                                                             75.0),
                                                             unit_variance=False,
                                                             with_centering=True,
                                                             with_scaling=True)))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2025-12-02 18:49:17,426:INFO:Adding model into prep_pipe
2025-12-02 18:49:17,426:WARNING:Only Model saved as it was a pipeline.
2025-12-02 18:49:17,436:INFO:../models\best_pipeline.pkl saved in current working directory
2025-12-02 18:49:17,452:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'IncomeRatio', 'SystolicBP',
                                             'BMI', 'WaistCircumference',
                                             'Height', 'TotalCholesterol',
                                             'Triglycerides', 'LDL', 'HDL',
                                             'HbA1c', 'Glucose', 'Creatinine',
                                             'UricAcid', 'ALT_Enzyme',
                                             'Albumin', 'Potassium', 'Sodium',
                                             'GGT_Enzyme', 'AST_Enzyme'],
                                    transformer=Si...
                               feature_types=None, gamma=None, grow_policy=None,
                               importance_type=None,
                               interaction_constraints=None, learning_rate=0.4,
                               max_bin=None, max_cat_threshold=None,
                               max_cat_to_onehot=None, max_delta_step=None,
                               max_depth=6, max_leaves=None, min_child_weight=1,
                               missing=nan, monotone_constraints=None,
                               multi_strategy=None, n_estimators=60, n_jobs=1,
                               num_parallel_tree=None,
                               objective='binary:logistic', ...))],
         verbose=False)
2025-12-02 18:49:17,452:INFO:save_model() successfully completed......................................
2025-12-02 18:51:56,292:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-12-02 18:51:56,292:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-12-02 18:51:56,292:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-12-02 18:51:56,292:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-12-02 18:51:57,944:INFO:Initializing load_model()
2025-12-02 18:51:57,944:INFO:load_model(model_name=../models/best_pipeline, platform=None, authentication=None, verbose=True)
2025-12-02 18:51:57,981:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-02 18:51:58,615:INFO:Initializing predict_model()
2025-12-02 18:51:58,615:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023184362C50>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Age', 'IncomeRatio', 'SystolicBP',
                                             'BMI', 'WaistCircumference',
                                             'Height', 'TotalCholesterol',
                                             'Triglycerides', 'LDL', 'HDL',
                                             'HbA1c', 'Glucose', 'Creatinine',
                                             'UricAcid', 'ALT_Enzyme',
                                             'Albumin', 'Potassium', 'Sodium',
                                             'GGT_Enzyme', 'AST_Enzyme'],
                                    transformer=SimpleImputer()...
                               feature_types=None, gamma=None, grow_policy=None,
                               importance_type=None,
                               interaction_constraints=None, learning_rate=0.4,
                               max_bin=None, max_cat_threshold=None,
                               max_cat_to_onehot=None, max_delta_step=None,
                               max_depth=6, max_leaves=None, min_child_weight=1,
                               missing=nan, monotone_constraints=None,
                               multi_strategy=None, n_estimators=60, n_jobs=1,
                               num_parallel_tree=None, random_state=42, ...))]), probability_threshold=None, encoded_labels=False, raw_score=True, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000231A38857E0>)
2025-12-02 18:51:58,615:INFO:Checking exceptions
2025-12-02 18:51:58,615:INFO:Preloading libraries
2025-12-02 18:51:58,615:INFO:Set up data.
2025-12-02 18:51:58,626:INFO:Set up index.
2025-12-02 18:51:58,992:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-02 18:51:59,000:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-02 18:51:59,001:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-02 19:31:50,051:INFO:Initializing load_model()
2025-12-02 19:31:50,052:INFO:load_model(model_name=../models/best_pipeline, platform=None, authentication=None, verbose=True)
2025-12-02 19:31:50,126:INFO:Initializing predict_model()
2025-12-02 19:31:50,126:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000231A5F5BC70>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Age', 'IncomeRatio', 'SystolicBP',
                                             'BMI', 'WaistCircumference',
                                             'Height', 'TotalCholesterol',
                                             'Triglycerides', 'LDL', 'HDL',
                                             'HbA1c', 'Glucose', 'Creatinine',
                                             'UricAcid', 'ALT_Enzyme',
                                             'Albumin', 'Potassium', 'Sodium',
                                             'GGT_Enzyme', 'AST_Enzyme'],
                                    transformer=SimpleImputer()...
                               feature_types=None, gamma=None, grow_policy=None,
                               importance_type=None,
                               interaction_constraints=None, learning_rate=0.4,
                               max_bin=None, max_cat_threshold=None,
                               max_cat_to_onehot=None, max_delta_step=None,
                               max_depth=6, max_leaves=None, min_child_weight=1,
                               missing=nan, monotone_constraints=None,
                               multi_strategy=None, n_estimators=60, n_jobs=1,
                               num_parallel_tree=None, random_state=42, ...))]), probability_threshold=None, encoded_labels=False, raw_score=True, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002318320D5A0>)
2025-12-02 19:31:50,126:INFO:Checking exceptions
2025-12-02 19:31:50,126:INFO:Preloading libraries
2025-12-02 19:31:50,126:INFO:Set up data.
2025-12-02 19:31:50,136:INFO:Set up index.
2025-12-02 19:31:50,513:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-02 19:31:50,518:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-02 19:31:50,520:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-02 19:33:22,614:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-12-02 19:33:22,614:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-12-02 19:33:22,614:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-12-02 19:33:22,614:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-12-02 19:33:24,286:INFO:Initializing load_model()
2025-12-02 19:33:24,286:INFO:load_model(model_name=../models/best_pipeline, platform=None, authentication=None, verbose=True)
2025-12-02 19:33:24,319:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-02 19:33:24,960:INFO:Initializing predict_model()
2025-12-02 19:33:24,963:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002357FF3DF00>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Age', 'IncomeRatio', 'SystolicBP',
                                             'BMI', 'WaistCircumference',
                                             'Height', 'TotalCholesterol',
                                             'Triglycerides', 'LDL', 'HDL',
                                             'HbA1c', 'Glucose', 'Creatinine',
                                             'UricAcid', 'ALT_Enzyme',
                                             'Albumin', 'Potassium', 'Sodium',
                                             'GGT_Enzyme', 'AST_Enzyme'],
                                    transformer=SimpleImputer()...
                               feature_types=None, gamma=None, grow_policy=None,
                               importance_type=None,
                               interaction_constraints=None, learning_rate=0.4,
                               max_bin=None, max_cat_threshold=None,
                               max_cat_to_onehot=None, max_delta_step=None,
                               max_depth=6, max_leaves=None, min_child_weight=1,
                               missing=nan, monotone_constraints=None,
                               multi_strategy=None, n_estimators=60, n_jobs=1,
                               num_parallel_tree=None, random_state=42, ...))]), probability_threshold=None, encoded_labels=False, raw_score=True, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002351F585990>)
2025-12-02 19:33:24,963:INFO:Checking exceptions
2025-12-02 19:33:24,963:INFO:Preloading libraries
2025-12-02 19:33:24,963:INFO:Set up data.
2025-12-02 19:33:24,971:INFO:Set up index.
2025-12-02 19:33:25,302:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-02 19:33:25,307:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-02 19:33:25,307:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-02 19:46:03,238:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-12-02 19:46:03,242:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-12-02 19:46:03,242:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-12-02 19:46:03,242:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-12-02 19:46:04,810:INFO:Initializing load_model()
2025-12-02 19:46:04,810:INFO:load_model(model_name=../models/best_pipeline, platform=None, authentication=None, verbose=True)
2025-12-02 19:46:04,850:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-02 19:46:05,495:INFO:Initializing predict_model()
2025-12-02 19:46:05,495:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001710ADD5FC0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Age', 'IncomeRatio', 'SystolicBP',
                                             'BMI', 'WaistCircumference',
                                             'Height', 'TotalCholesterol',
                                             'Triglycerides', 'LDL', 'HDL',
                                             'HbA1c', 'Glucose', 'Creatinine',
                                             'UricAcid', 'ALT_Enzyme',
                                             'Albumin', 'Potassium', 'Sodium',
                                             'GGT_Enzyme', 'AST_Enzyme'],
                                    transformer=SimpleImputer()...
                               feature_types=None, gamma=None, grow_policy=None,
                               importance_type=None,
                               interaction_constraints=None, learning_rate=0.4,
                               max_bin=None, max_cat_threshold=None,
                               max_cat_to_onehot=None, max_delta_step=None,
                               max_depth=6, max_leaves=None, min_child_weight=1,
                               missing=nan, monotone_constraints=None,
                               multi_strategy=None, n_estimators=60, n_jobs=1,
                               num_parallel_tree=None, random_state=42, ...))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001710AE08280>)
2025-12-02 19:46:05,495:INFO:Checking exceptions
2025-12-02 19:46:05,495:INFO:Preloading libraries
2025-12-02 19:46:05,495:INFO:Set up data.
2025-12-02 19:46:05,497:INFO:Set up index.
2025-12-03 08:26:54,119:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-12-03 08:26:54,119:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-12-03 08:26:54,119:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-12-03 08:26:54,119:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-12-03 08:26:56,469:INFO:Initializing load_model()
2025-12-03 08:26:56,469:INFO:load_model(model_name=../models/best_pipeline, platform=None, authentication=None, verbose=True)
2025-12-03 08:26:56,554:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-03 08:26:57,519:INFO:Initializing predict_model()
2025-12-03 08:26:57,519:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022360B7AD40>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Age', 'IncomeRatio', 'SystolicBP',
                                             'BMI', 'WaistCircumference',
                                             'Height', 'TotalCholesterol',
                                             'Triglycerides', 'LDL', 'HDL',
                                             'HbA1c', 'Glucose', 'Creatinine',
                                             'UricAcid', 'ALT_Enzyme',
                                             'Albumin', 'Potassium', 'Sodium',
                                             'GGT_Enzyme', 'AST_Enzyme'],
                                    transformer=SimpleImputer()...
                               feature_types=None, gamma=None, grow_policy=None,
                               importance_type=None,
                               interaction_constraints=None, learning_rate=0.4,
                               max_bin=None, max_cat_threshold=None,
                               max_cat_to_onehot=None, max_delta_step=None,
                               max_depth=6, max_leaves=None, min_child_weight=1,
                               missing=nan, monotone_constraints=None,
                               multi_strategy=None, n_estimators=60, n_jobs=1,
                               num_parallel_tree=None, random_state=42, ...))]), probability_threshold=None, encoded_labels=False, raw_score=True, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000022300219A20>)
2025-12-03 08:26:57,519:INFO:Checking exceptions
2025-12-03 08:26:57,519:INFO:Preloading libraries
2025-12-03 08:26:57,522:INFO:Set up data.
2025-12-03 08:26:57,549:INFO:Set up index.
2025-12-03 09:45:35,688:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-12-03 09:45:35,688:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-12-03 09:45:35,688:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-12-03 09:45:35,688:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-12-03 09:45:37,494:INFO:PyCaret ClassificationExperiment
2025-12-03 09:45:37,494:INFO:Logging name: clf-default-name
2025-12-03 09:45:37,494:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-12-03 09:45:37,494:INFO:version 3.3.2
2025-12-03 09:45:37,494:INFO:Initializing setup()
2025-12-03 09:45:37,494:INFO:self.USI: b645
2025-12-03 09:45:37,494:INFO:self._variable_keys: {'idx', 'html_param', '_available_plots', 'y_test', 'USI', 'target_param', 'memory', 'pipeline', 'n_jobs_param', 'X_test', 'seed', 'is_multiclass', 'gpu_param', 'logging_param', 'y_train', 'log_plots_param', 'X_train', 'gpu_n_jobs_param', 'fix_imbalance', 'exp_name_log', 'fold_shuffle_param', 'fold_groups_param', 'X', 'data', 'fold_generator', 'y', 'exp_id', '_ml_usecase'}
2025-12-03 09:45:37,494:INFO:Checking environment
2025-12-03 09:45:37,494:INFO:python_version: 3.10.19
2025-12-03 09:45:37,494:INFO:python_build: ('main', 'Oct 21 2025 16:41:31')
2025-12-03 09:45:37,494:INFO:machine: AMD64
2025-12-03 09:45:37,494:INFO:platform: Windows-10-10.0.26100-SP0
2025-12-03 09:45:37,494:INFO:Memory: svmem(total=16282144768, available=5583261696, percent=65.7, used=10698883072, free=5583261696)
2025-12-03 09:45:37,494:INFO:Physical Core: 6
2025-12-03 09:45:37,494:INFO:Logical Core: 12
2025-12-03 09:45:37,494:INFO:Checking libraries
2025-12-03 09:45:37,494:INFO:System:
2025-12-03 09:45:37,494:INFO:    python: 3.10.19 | packaged by Anaconda, Inc. | (main, Oct 21 2025, 16:41:31) [MSC v.1929 64 bit (AMD64)]
2025-12-03 09:45:37,494:INFO:executable: c:\Users\OMAR\miniconda3\envs\xgb_env\python.exe
2025-12-03 09:45:37,494:INFO:   machine: Windows-10-10.0.26100-SP0
2025-12-03 09:45:37,494:INFO:PyCaret required dependencies:
2025-12-03 09:45:37,494:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-03 09:45:38,073:INFO:                 pip: 25.3
2025-12-03 09:45:38,073:INFO:          setuptools: 80.9.0
2025-12-03 09:45:38,073:INFO:             pycaret: 3.3.2
2025-12-03 09:45:38,073:INFO:             IPython: 8.37.0
2025-12-03 09:45:38,073:INFO:          ipywidgets: 8.1.8
2025-12-03 09:45:38,073:INFO:                tqdm: 4.67.1
2025-12-03 09:45:38,073:INFO:               numpy: 1.26.4
2025-12-03 09:45:38,073:INFO:              pandas: 2.1.4
2025-12-03 09:45:38,073:INFO:              jinja2: 3.1.6
2025-12-03 09:45:38,073:INFO:               scipy: 1.11.4
2025-12-03 09:45:38,073:INFO:              joblib: 1.3.2
2025-12-03 09:45:38,073:INFO:             sklearn: 1.4.2
2025-12-03 09:45:38,073:INFO:                pyod: 2.0.5
2025-12-03 09:45:38,073:INFO:            imblearn: 0.14.0
2025-12-03 09:45:38,073:INFO:   category_encoders: 2.7.0
2025-12-03 09:45:38,073:INFO:            lightgbm: 4.6.0
2025-12-03 09:45:38,073:INFO:               numba: 0.62.1
2025-12-03 09:45:38,073:INFO:            requests: 2.32.5
2025-12-03 09:45:38,073:INFO:          matplotlib: 3.7.5
2025-12-03 09:45:38,073:INFO:          scikitplot: 0.3.7
2025-12-03 09:45:38,073:INFO:         yellowbrick: 1.5
2025-12-03 09:45:38,073:INFO:              plotly: 5.24.1
2025-12-03 09:45:38,073:INFO:    plotly-resampler: Not installed
2025-12-03 09:45:38,073:INFO:             kaleido: 1.2.0
2025-12-03 09:45:38,073:INFO:           schemdraw: 0.15
2025-12-03 09:45:38,073:INFO:         statsmodels: 0.14.5
2025-12-03 09:45:38,073:INFO:              sktime: 0.26.0
2025-12-03 09:45:38,073:INFO:               tbats: 1.1.3
2025-12-03 09:45:38,073:INFO:            pmdarima: 2.0.4
2025-12-03 09:45:38,073:INFO:              psutil: 7.1.3
2025-12-03 09:45:38,073:INFO:          markupsafe: 3.0.3
2025-12-03 09:45:38,073:INFO:             pickle5: Not installed
2025-12-03 09:45:38,073:INFO:         cloudpickle: 3.1.2
2025-12-03 09:45:38,073:INFO:         deprecation: 2.1.0
2025-12-03 09:45:38,073:INFO:              xxhash: 3.6.0
2025-12-03 09:45:38,073:INFO:           wurlitzer: Not installed
2025-12-03 09:45:38,073:INFO:PyCaret optional dependencies:
2025-12-03 09:45:41,511:INFO:                shap: 0.49.1
2025-12-03 09:45:41,511:INFO:           interpret: 0.7.3
2025-12-03 09:45:41,511:INFO:                umap: 0.5.7
2025-12-03 09:45:41,511:INFO:     ydata_profiling: 4.18.0
2025-12-03 09:45:41,511:INFO:  explainerdashboard: 0.5.1
2025-12-03 09:45:41,511:INFO:             autoviz: Not installed
2025-12-03 09:45:41,511:INFO:           fairlearn: 0.7.0
2025-12-03 09:45:41,511:INFO:          deepchecks: Not installed
2025-12-03 09:45:41,511:INFO:             xgboost: 2.1.3
2025-12-03 09:45:41,511:INFO:            catboost: 1.2.8
2025-12-03 09:45:41,511:INFO:              kmodes: 0.12.2
2025-12-03 09:45:41,511:INFO:             mlxtend: 0.23.4
2025-12-03 09:45:41,511:INFO:       statsforecast: 1.5.0
2025-12-03 09:45:41,511:INFO:        tune_sklearn: Not installed
2025-12-03 09:45:41,511:INFO:                 ray: Not installed
2025-12-03 09:45:41,511:INFO:            hyperopt: 0.2.7
2025-12-03 09:45:41,511:INFO:              optuna: 4.6.0
2025-12-03 09:45:41,511:INFO:               skopt: 0.10.2
2025-12-03 09:45:41,511:INFO:              mlflow: 3.6.0
2025-12-03 09:45:41,511:INFO:              gradio: 6.0.1
2025-12-03 09:45:41,511:INFO:             fastapi: 0.123.0
2025-12-03 09:45:41,511:INFO:             uvicorn: 0.38.0
2025-12-03 09:45:41,511:INFO:              m2cgen: 0.10.0
2025-12-03 09:45:41,511:INFO:           evidently: 0.4.40
2025-12-03 09:45:41,511:INFO:               fugue: 0.8.7
2025-12-03 09:45:41,511:INFO:           streamlit: 1.51.0
2025-12-03 09:45:41,511:INFO:             prophet: Not installed
2025-12-03 09:45:41,511:INFO:None
2025-12-03 09:45:41,511:INFO:Set up data.
2025-12-03 09:45:41,534:INFO:Set up folding strategy.
2025-12-03 09:45:41,536:INFO:Set up train/test split.
2025-12-03 09:45:41,559:INFO:Set up index.
2025-12-03 09:45:41,561:INFO:Assigning column types.
2025-12-03 09:45:41,582:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-12-03 09:45:41,609:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-12-03 09:45:41,609:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-03 09:45:41,634:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-03 09:45:41,634:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-03 09:45:41,770:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-12-03 09:45:41,770:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-03 09:45:41,785:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-03 09:45:41,785:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-03 09:45:41,785:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-12-03 09:45:41,815:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-03 09:45:41,831:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-03 09:45:41,834:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-03 09:45:41,858:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-03 09:45:41,876:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-03 09:45:41,876:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-03 09:45:41,878:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-12-03 09:45:41,918:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-03 09:45:41,919:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-03 09:45:41,961:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-03 09:45:41,963:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-03 09:45:41,965:INFO:Preparing preprocessing pipeline...
2025-12-03 09:45:41,970:INFO:Set up simple imputation.
2025-12-03 09:45:41,985:INFO:Set up encoding of ordinal features.
2025-12-03 09:45:41,993:INFO:Set up encoding of categorical features.
2025-12-03 09:45:41,993:INFO:Set up feature normalization.
2025-12-03 09:45:42,173:INFO:Finished creating preprocessing pipeline.
2025-12-03 09:45:42,188:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\OMAR\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'IncomeRatio', 'SystolicBP',
                                             'BMI', 'WaistCircumference',
                                             'Height', 'TotalCholesterol',
                                             'Triglycerides', 'LDL', 'HDL',
                                             'HbA1c', 'Glucose', 'Creatinine',
                                             'UricAcid', 'ALT_Enzyme',
                                             'Albumin', 'Potassium', 'Sodium',
                                             'G...
                                    transformer=TargetEncoder(cols=[],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=RobustScaler(copy=True,
                                                             quantile_range=(25.0,
                                                                             75.0),
                                                             unit_variance=False,
                                                             with_centering=True,
                                                             with_scaling=True)))],
         verbose=False)
2025-12-03 09:45:42,188:INFO:Creating final display dataframe.
2025-12-03 09:45:42,420:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target      HeartDisease
2                   Target type            Binary
3           Original data shape       (43695, 28)
4        Transformed data shape       (43695, 32)
5   Transformed train set shape       (30586, 32)
6    Transformed test set shape       (13109, 32)
7              Numeric features                20
8          Categorical features                 7
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15                    Normalize              True
16             Normalize method            robust
17               Fold Generator   StratifiedKFold
18                  Fold Number                10
19                     CPU Jobs                 1
20                      Use GPU             False
21               Log Experiment             False
22              Experiment Name  clf-default-name
23                          USI              b645
2025-12-03 09:45:42,470:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-03 09:45:42,473:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-03 09:45:42,514:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-03 09:45:42,518:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-03 09:45:42,519:INFO:setup() successfully completed in 5.04s...............
2025-12-03 09:45:42,561:INFO:Initializing get_config()
2025-12-03 09:45:42,561:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018F86ECEB30>, variable=y_train)
2025-12-03 09:45:42,561:INFO:Variable: 'y_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_train_transformed' instead.
2025-12-03 09:45:42,561:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_train_transformed' instead.

2025-12-03 09:45:42,573:INFO:Variable:  returned as 15208    0.0
25325    0.0
5132     0.0
17217    0.0
6382     0.0
        ... 
6265     0.0
42694    0.0
13399    0.0
39959    0.0
6616     0.0
Name: HeartDisease, Length: 30586, dtype: float32
2025-12-03 09:45:42,573:INFO:get_config() successfully completed......................................
2025-12-03 09:45:42,575:INFO:Initializing create_model()
2025-12-03 09:45:42,576:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018F86ECEB30>, estimator=xgboost, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={'scale_pos_weight': 76.32522407170295})
2025-12-03 09:45:42,576:INFO:Checking exceptions
2025-12-03 09:45:42,588:INFO:Importing libraries
2025-12-03 09:45:42,588:INFO:Copying training dataset
2025-12-03 09:45:42,616:INFO:Defining folds
2025-12-03 09:45:42,616:INFO:Declaring metric variables
2025-12-03 09:45:42,620:INFO:Importing untrained model
2025-12-03 09:45:42,625:INFO:Extreme Gradient Boosting Imported successfully
2025-12-03 09:45:42,632:INFO:Starting cross validation
2025-12-03 09:45:42,635:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-12-03 09:45:48,882:INFO:Calculating mean and std
2025-12-03 09:45:48,884:INFO:Creating metrics dataframe
2025-12-03 09:45:48,888:INFO:Finalizing model
2025-12-03 09:45:48,976:INFO:Warning: No categorical columns found. Calling 'transform' will only return input data.
2025-12-03 09:45:49,554:INFO:Uploading results into container
2025-12-03 09:45:49,555:INFO:Uploading model into container now
2025-12-03 09:45:49,564:INFO:_master_model_container: 1
2025-12-03 09:45:49,564:INFO:_display_container: 2
2025-12-03 09:45:49,564:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2025-12-03 09:45:49,564:INFO:create_model() successfully completed......................................
2025-12-03 09:45:49,767:INFO:Initializing create_model()
2025-12-03 09:45:49,767:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018F86ECEB30>, estimator=lr, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-03 09:45:49,768:INFO:Checking exceptions
2025-12-03 09:45:49,777:INFO:Importing libraries
2025-12-03 09:45:49,778:INFO:Copying training dataset
2025-12-03 09:45:49,807:INFO:Defining folds
2025-12-03 09:45:49,807:INFO:Declaring metric variables
2025-12-03 09:45:49,811:INFO:Importing untrained model
2025-12-03 09:45:49,815:INFO:Logistic Regression Imported successfully
2025-12-03 09:45:49,822:INFO:Starting cross validation
2025-12-03 09:45:49,824:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-12-03 09:45:50,820:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-12-03 09:45:51,420:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-12-03 09:45:51,800:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-12-03 09:45:51,806:INFO:Calculating mean and std
2025-12-03 09:45:51,808:INFO:Creating metrics dataframe
2025-12-03 09:45:51,810:INFO:Finalizing model
2025-12-03 09:45:51,894:INFO:Warning: No categorical columns found. Calling 'transform' will only return input data.
2025-12-03 09:45:51,984:INFO:Uploading results into container
2025-12-03 09:45:51,988:INFO:Uploading model into container now
2025-12-03 09:45:51,994:INFO:_master_model_container: 2
2025-12-03 09:45:51,994:INFO:_display_container: 3
2025-12-03 09:45:51,994:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-12-03 09:45:51,994:INFO:create_model() successfully completed......................................
2025-12-03 09:45:52,152:INFO:Initializing create_model()
2025-12-03 09:45:52,154:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018F86ECEB30>, estimator=rf, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-03 09:45:52,154:INFO:Checking exceptions
2025-12-03 09:45:52,160:INFO:Importing libraries
2025-12-03 09:45:52,165:INFO:Copying training dataset
2025-12-03 09:45:52,193:INFO:Defining folds
2025-12-03 09:45:52,193:INFO:Declaring metric variables
2025-12-03 09:45:52,196:INFO:Importing untrained model
2025-12-03 09:45:52,199:INFO:Random Forest Classifier Imported successfully
2025-12-03 09:45:52,204:INFO:Starting cross validation
2025-12-03 09:45:52,205:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-12-03 09:46:31,549:INFO:Calculating mean and std
2025-12-03 09:46:31,550:INFO:Creating metrics dataframe
2025-12-03 09:46:31,554:INFO:Finalizing model
2025-12-03 09:46:31,625:INFO:Warning: No categorical columns found. Calling 'transform' will only return input data.
2025-12-03 09:46:36,035:INFO:Uploading results into container
2025-12-03 09:46:36,035:INFO:Uploading model into container now
2025-12-03 09:46:36,044:INFO:_master_model_container: 3
2025-12-03 09:46:36,044:INFO:_display_container: 4
2025-12-03 09:46:36,044:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2025-12-03 09:46:36,044:INFO:create_model() successfully completed......................................
2025-12-03 09:46:36,220:INFO:Initializing get_config()
2025-12-03 09:46:36,220:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018F86ECEB30>, variable=X_train_transformed)
2025-12-03 09:46:36,255:INFO:Variable: X_train returned as             Age  IncomeRatio  SystolicBP       BMI  WaistCircumference  \
15208  0.954545     0.854789    0.359485  0.518044            0.206281   
25325 -0.272727     0.253271   -0.812170 -0.966167           -0.799656   
5132   0.181818    -0.407608   -0.372799  0.054886            0.319578   
17217  0.500000    -0.751898    0.013314 -0.260904            0.278379   
6382   0.568182     0.054503    1.131712  2.675938            1.888566   
...         ...          ...         ...       ...                 ...   
6265  -0.545455    -0.431352   -0.591719  0.191728           -0.377368   
42694 -0.022727    -0.221612   -0.892056 -0.260904           -0.047778   
13399  0.454545     0.388518    0.377985  0.271482            0.183567   
39959  0.954545    -0.193911    0.625770  0.991728            1.160720   
6616   0.613636    -0.447182    0.652399 -0.871430           -0.514698   

         Height  TotalCholesterol  Triglycerides       LDL       HDL  ...  \
15208 -0.487303          0.625876       0.583394  0.005397  0.314564  ...   
25325 -0.300856          0.033588      -0.261476  0.000256  0.303682  ...   
5132   0.766972          0.181594       0.479279  0.948690 -1.340476  ...   
17217  0.745785          0.227516       0.346113  0.002441 -0.274561  ...   
6382   0.237295          0.867515       0.635574  0.002754  0.829819  ...   
...         ...               ...            ...       ...       ...  ...   
6265  -1.737339         -1.393483      -0.471046 -3.840886  0.063832  ...   
42694  0.000000          0.029167      -0.131730  0.000893  0.063832  ...   
13399 -0.147405          0.462357       0.380371  0.003925  0.256949  ...   
39959  0.368655          1.528031       1.934134  0.011744  0.191497  ...   
6616  -0.021187         -0.224877      -0.043571 -1.609476  0.510658  ...   

       Race_5.0  Race_1.0  Race_4.0  Race_3.0  Race_2.0  Education  Smoking  \
15208       1.0       0.0       0.0       0.0       0.0  -0.659696      0.0   
25325       0.0       1.0       0.0       0.0       0.0   0.185278      0.0   
5132        0.0       1.0       0.0       0.0       0.0  -0.659696      1.0   
17217       0.0       0.0       1.0       0.0       0.0  -0.056119      1.0   
6382        0.0       0.0       1.0       0.0       0.0   0.547458      1.0   
...         ...       ...       ...       ...       ...        ...      ...   
6265        0.0       1.0       0.0       0.0       0.0  -0.769055      0.0   
42694       0.0       1.0       0.0       0.0       0.0   0.547458      0.0   
13399       0.0       0.0       1.0       0.0       0.0   0.547458      0.0   
39959       0.0       0.0       0.0       1.0       0.0   0.547458      0.0   
6616        0.0       0.0       0.0       1.0       0.0   0.547458      1.0   

       PhysicalActivity  HealthInsurance   Alcohol  
15208          0.000000              0.0 -0.886483  
25325          0.000000              0.0  0.592213  
5132           0.000000             -1.0  0.312949  
17217          0.000000              0.0  0.592213  
6382           0.000000              0.0  0.597293  
...                 ...              ...       ...  
6265           0.662459              0.0 -0.501621  
42694          0.000000             -1.0  0.592213  
13399          0.000000              0.0 -0.224534  
39959          0.000000              0.0  0.592213  
6616           0.000000              0.0  0.290247  

[30586 rows x 31 columns]
2025-12-03 09:46:36,255:INFO:get_config() successfully completed......................................
2025-12-03 09:46:36,255:INFO:Initializing get_config()
2025-12-03 09:46:36,255:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018F86ECEB30>, variable=y_train)
2025-12-03 09:46:36,255:INFO:Variable: 'y_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_train_transformed' instead.
2025-12-03 09:46:36,256:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_train_transformed' instead.

2025-12-03 09:46:36,263:INFO:Variable:  returned as 15208    0.0
25325    0.0
5132     0.0
17217    0.0
6382     0.0
        ... 
6265     0.0
42694    0.0
13399    0.0
39959    0.0
6616     0.0
Name: HeartDisease, Length: 30586, dtype: float32
2025-12-03 09:46:36,263:INFO:get_config() successfully completed......................................
2025-12-03 09:46:36,263:INFO:Initializing get_config()
2025-12-03 09:46:36,263:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018F86ECEB30>, variable=X_test_transformed)
2025-12-03 09:46:36,332:INFO:Variable: X_test returned as             Age  IncomeRatio  SystolicBP       BMI  WaistCircumference  \
28456 -0.477273    -0.304717   -0.519256 -0.987220           -0.923253   
8993   0.818182     0.253271    2.156910  0.770675            0.920394   
34312  0.704545     0.055403    0.519256  0.518044            0.662901   
4802  -0.545455     0.253730   -0.331933 -0.229036           -0.436352   
25895  0.704545     1.226781   -0.093200 -0.226100            0.012322   
...         ...          ...         ...       ...                 ...   
18045 -0.568182    -0.083104   -0.568713 -1.176693           -1.338674   
5425   0.590909     0.362732    2.210168  0.139096            0.292112   
12819  0.909091    -0.019787    0.899042  0.454886            0.971892   
33659 -0.522727     1.060572   -0.525683 -0.587220           -0.906087   
19531 -0.590909    -0.344290   -0.510287 -0.945114           -1.215078   

         Height  TotalCholesterol  Triglycerides       LDL       HDL  ...  \
28456 -1.080540         -0.078535      -0.470757 -0.026922  0.418008  ...   
8993  -0.279669          0.765897       0.705031  0.006026  0.446825  ...   
34312  0.559339         -0.123259       0.929511 -1.031826 -1.404309  ...   
4802  -0.504861         -0.188325      -0.322647  0.000015 -0.138743  ...   
25895  0.216731          0.892919       1.291109  0.008211 -0.255329  ...   
...         ...               ...            ...       ...       ...  ...   
18045 -2.080569         -0.340947      -0.470582 -0.848950  0.393794  ...   
5425   0.156785          0.435639      -0.065356  1.113733  0.127664  ...   
12819  1.194951         -0.732967      -0.470025 -0.211535 -1.085148  ...   
33659 -1.254274         -1.063225      -0.470958 -2.849419  0.127664  ...   
19531 -2.339052         -0.356898      -0.470595 -0.900608  0.393896  ...   

       Race_5.0  Race_1.0  Race_4.0  Race_3.0  Race_2.0  Education   Smoking  \
28456       1.0       0.0       0.0       0.0       0.0  -0.012820  0.000000   
8993        0.0       0.0       1.0       0.0       0.0   0.547458  1.000000   
34312       0.0       0.0       0.0       1.0       0.0  -0.659696  0.000000   
4802        1.0       0.0       0.0       0.0       0.0   0.262895  0.073612   
25895       0.0       0.0       0.0       1.0       0.0   1.151035  0.000000   
...         ...       ...       ...       ...       ...        ...       ...   
18045       0.0       0.0       0.0       1.0       0.0  -0.793202  0.000000   
5425        0.0       0.0       1.0       0.0       0.0   0.547458  1.000000   
12819       0.0       0.0       0.0       1.0       0.0   1.151035  1.000000   
33659       0.0       0.0       1.0       0.0       0.0   0.258362  0.000000   
19531       1.0       0.0       0.0       0.0       0.0  -0.821118  0.000000   

       PhysicalActivity  HealthInsurance   Alcohol  
28456          0.660578              0.0 -0.518600  
8993           0.000000              0.0  0.115329  
34312          0.000000              0.0  0.592213  
4802           1.012447              0.0 -0.103347  
25895          0.000000              0.0 -0.886483  
...                 ...              ...       ...  
18045          0.904383              0.0 -0.482716  
5425           1.598141              0.0  0.097790  
12819          1.598141              0.0  0.612947  
33659          1.162475              0.0 -0.154408  
19531          0.791302              0.0 -0.683278  

[13109 rows x 31 columns]
2025-12-03 09:46:36,332:INFO:get_config() successfully completed......................................
2025-12-03 09:46:36,332:INFO:Initializing get_config()
2025-12-03 09:46:36,332:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018F86ECEB30>, variable=y_test)
2025-12-03 09:46:36,332:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-12-03 09:46:36,332:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-12-03 09:46:36,338:INFO:Variable:  returned as 28456    0.0
8993     0.0
34312    0.0
4802     0.0
25895    0.0
        ... 
18045    0.0
5425     0.0
12819    0.0
33659    0.0
19531    0.0
Name: HeartDisease, Length: 13109, dtype: float32
2025-12-03 09:46:36,338:INFO:get_config() successfully completed......................................
2025-12-03 09:46:36,494:INFO:Initializing get_config()
2025-12-03 09:46:36,495:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018F86ECEB30>, variable=X_train_transformed)
2025-12-03 09:46:36,538:INFO:Variable: X_train returned as             Age  IncomeRatio  SystolicBP       BMI  WaistCircumference  \
15208  0.954545     0.854789    0.359485  0.518044            0.206281   
25325 -0.272727     0.253271   -0.812170 -0.966167           -0.799656   
5132   0.181818    -0.407608   -0.372799  0.054886            0.319578   
17217  0.500000    -0.751898    0.013314 -0.260904            0.278379   
6382   0.568182     0.054503    1.131712  2.675938            1.888566   
...         ...          ...         ...       ...                 ...   
6265  -0.545455    -0.431352   -0.591719  0.191728           -0.377368   
42694 -0.022727    -0.221612   -0.892056 -0.260904           -0.047778   
13399  0.454545     0.388518    0.377985  0.271482            0.183567   
39959  0.954545    -0.193911    0.625770  0.991728            1.160720   
6616   0.613636    -0.447182    0.652399 -0.871430           -0.514698   

         Height  TotalCholesterol  Triglycerides       LDL       HDL  ...  \
15208 -0.487303          0.625876       0.583394  0.005397  0.314564  ...   
25325 -0.300856          0.033588      -0.261476  0.000256  0.303682  ...   
5132   0.766972          0.181594       0.479279  0.948690 -1.340476  ...   
17217  0.745785          0.227516       0.346113  0.002441 -0.274561  ...   
6382   0.237295          0.867515       0.635574  0.002754  0.829819  ...   
...         ...               ...            ...       ...       ...  ...   
6265  -1.737339         -1.393483      -0.471046 -3.840886  0.063832  ...   
42694  0.000000          0.029167      -0.131730  0.000893  0.063832  ...   
13399 -0.147405          0.462357       0.380371  0.003925  0.256949  ...   
39959  0.368655          1.528031       1.934134  0.011744  0.191497  ...   
6616  -0.021187         -0.224877      -0.043571 -1.609476  0.510658  ...   

       Race_5.0  Race_1.0  Race_4.0  Race_3.0  Race_2.0  Education  Smoking  \
15208       1.0       0.0       0.0       0.0       0.0  -0.659696      0.0   
25325       0.0       1.0       0.0       0.0       0.0   0.185278      0.0   
5132        0.0       1.0       0.0       0.0       0.0  -0.659696      1.0   
17217       0.0       0.0       1.0       0.0       0.0  -0.056119      1.0   
6382        0.0       0.0       1.0       0.0       0.0   0.547458      1.0   
...         ...       ...       ...       ...       ...        ...      ...   
6265        0.0       1.0       0.0       0.0       0.0  -0.769055      0.0   
42694       0.0       1.0       0.0       0.0       0.0   0.547458      0.0   
13399       0.0       0.0       1.0       0.0       0.0   0.547458      0.0   
39959       0.0       0.0       0.0       1.0       0.0   0.547458      0.0   
6616        0.0       0.0       0.0       1.0       0.0   0.547458      1.0   

       PhysicalActivity  HealthInsurance   Alcohol  
15208          0.000000              0.0 -0.886483  
25325          0.000000              0.0  0.592213  
5132           0.000000             -1.0  0.312949  
17217          0.000000              0.0  0.592213  
6382           0.000000              0.0  0.597293  
...                 ...              ...       ...  
6265           0.662459              0.0 -0.501621  
42694          0.000000             -1.0  0.592213  
13399          0.000000              0.0 -0.224534  
39959          0.000000              0.0  0.592213  
6616           0.000000              0.0  0.290247  

[30586 rows x 31 columns]
2025-12-03 09:46:36,538:INFO:get_config() successfully completed......................................
2025-12-03 09:46:36,538:INFO:Initializing get_config()
2025-12-03 09:46:36,538:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018F86ECEB30>, variable=y_train)
2025-12-03 09:46:36,538:INFO:Variable: 'y_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_train_transformed' instead.
2025-12-03 09:46:36,538:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_train_transformed' instead.

2025-12-03 09:46:36,547:INFO:Variable:  returned as 15208    0.0
25325    0.0
5132     0.0
17217    0.0
6382     0.0
        ... 
6265     0.0
42694    0.0
13399    0.0
39959    0.0
6616     0.0
Name: HeartDisease, Length: 30586, dtype: float32
2025-12-03 09:46:36,547:INFO:get_config() successfully completed......................................
2025-12-03 09:46:36,549:INFO:Initializing get_config()
2025-12-03 09:46:36,549:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018F86ECEB30>, variable=X_test_transformed)
2025-12-03 09:46:36,617:INFO:Variable: X_test returned as             Age  IncomeRatio  SystolicBP       BMI  WaistCircumference  \
28456 -0.477273    -0.304717   -0.519256 -0.987220           -0.923253   
8993   0.818182     0.253271    2.156910  0.770675            0.920394   
34312  0.704545     0.055403    0.519256  0.518044            0.662901   
4802  -0.545455     0.253730   -0.331933 -0.229036           -0.436352   
25895  0.704545     1.226781   -0.093200 -0.226100            0.012322   
...         ...          ...         ...       ...                 ...   
18045 -0.568182    -0.083104   -0.568713 -1.176693           -1.338674   
5425   0.590909     0.362732    2.210168  0.139096            0.292112   
12819  0.909091    -0.019787    0.899042  0.454886            0.971892   
33659 -0.522727     1.060572   -0.525683 -0.587220           -0.906087   
19531 -0.590909    -0.344290   -0.510287 -0.945114           -1.215078   

         Height  TotalCholesterol  Triglycerides       LDL       HDL  ...  \
28456 -1.080540         -0.078535      -0.470757 -0.026922  0.418008  ...   
8993  -0.279669          0.765897       0.705031  0.006026  0.446825  ...   
34312  0.559339         -0.123259       0.929511 -1.031826 -1.404309  ...   
4802  -0.504861         -0.188325      -0.322647  0.000015 -0.138743  ...   
25895  0.216731          0.892919       1.291109  0.008211 -0.255329  ...   
...         ...               ...            ...       ...       ...  ...   
18045 -2.080569         -0.340947      -0.470582 -0.848950  0.393794  ...   
5425   0.156785          0.435639      -0.065356  1.113733  0.127664  ...   
12819  1.194951         -0.732967      -0.470025 -0.211535 -1.085148  ...   
33659 -1.254274         -1.063225      -0.470958 -2.849419  0.127664  ...   
19531 -2.339052         -0.356898      -0.470595 -0.900608  0.393896  ...   

       Race_5.0  Race_1.0  Race_4.0  Race_3.0  Race_2.0  Education   Smoking  \
28456       1.0       0.0       0.0       0.0       0.0  -0.012820  0.000000   
8993        0.0       0.0       1.0       0.0       0.0   0.547458  1.000000   
34312       0.0       0.0       0.0       1.0       0.0  -0.659696  0.000000   
4802        1.0       0.0       0.0       0.0       0.0   0.262895  0.073612   
25895       0.0       0.0       0.0       1.0       0.0   1.151035  0.000000   
...         ...       ...       ...       ...       ...        ...       ...   
18045       0.0       0.0       0.0       1.0       0.0  -0.793202  0.000000   
5425        0.0       0.0       1.0       0.0       0.0   0.547458  1.000000   
12819       0.0       0.0       0.0       1.0       0.0   1.151035  1.000000   
33659       0.0       0.0       1.0       0.0       0.0   0.258362  0.000000   
19531       1.0       0.0       0.0       0.0       0.0  -0.821118  0.000000   

       PhysicalActivity  HealthInsurance   Alcohol  
28456          0.660578              0.0 -0.518600  
8993           0.000000              0.0  0.115329  
34312          0.000000              0.0  0.592213  
4802           1.012447              0.0 -0.103347  
25895          0.000000              0.0 -0.886483  
...                 ...              ...       ...  
18045          0.904383              0.0 -0.482716  
5425           1.598141              0.0  0.097790  
12819          1.598141              0.0  0.612947  
33659          1.162475              0.0 -0.154408  
19531          0.791302              0.0 -0.683278  

[13109 rows x 31 columns]
2025-12-03 09:46:36,617:INFO:get_config() successfully completed......................................
2025-12-03 09:46:36,617:INFO:Initializing get_config()
2025-12-03 09:46:36,617:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018F86ECEB30>, variable=y_test)
2025-12-03 09:46:36,618:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-12-03 09:46:36,618:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-12-03 09:46:36,623:INFO:Variable:  returned as 28456    0.0
8993     0.0
34312    0.0
4802     0.0
25895    0.0
        ... 
18045    0.0
5425     0.0
12819    0.0
33659    0.0
19531    0.0
Name: HeartDisease, Length: 13109, dtype: float32
2025-12-03 09:46:36,623:INFO:get_config() successfully completed......................................
2025-12-03 09:46:36,749:INFO:Initializing get_config()
2025-12-03 09:46:36,749:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018F86ECEB30>, variable=X_test_transformed)
2025-12-03 09:46:36,819:INFO:Variable: X_test returned as             Age  IncomeRatio  SystolicBP       BMI  WaistCircumference  \
28456 -0.477273    -0.304717   -0.519256 -0.987220           -0.923253   
8993   0.818182     0.253271    2.156910  0.770675            0.920394   
34312  0.704545     0.055403    0.519256  0.518044            0.662901   
4802  -0.545455     0.253730   -0.331933 -0.229036           -0.436352   
25895  0.704545     1.226781   -0.093200 -0.226100            0.012322   
...         ...          ...         ...       ...                 ...   
18045 -0.568182    -0.083104   -0.568713 -1.176693           -1.338674   
5425   0.590909     0.362732    2.210168  0.139096            0.292112   
12819  0.909091    -0.019787    0.899042  0.454886            0.971892   
33659 -0.522727     1.060572   -0.525683 -0.587220           -0.906087   
19531 -0.590909    -0.344290   -0.510287 -0.945114           -1.215078   

         Height  TotalCholesterol  Triglycerides       LDL       HDL  ...  \
28456 -1.080540         -0.078535      -0.470757 -0.026922  0.418008  ...   
8993  -0.279669          0.765897       0.705031  0.006026  0.446825  ...   
34312  0.559339         -0.123259       0.929511 -1.031826 -1.404309  ...   
4802  -0.504861         -0.188325      -0.322647  0.000015 -0.138743  ...   
25895  0.216731          0.892919       1.291109  0.008211 -0.255329  ...   
...         ...               ...            ...       ...       ...  ...   
18045 -2.080569         -0.340947      -0.470582 -0.848950  0.393794  ...   
5425   0.156785          0.435639      -0.065356  1.113733  0.127664  ...   
12819  1.194951         -0.732967      -0.470025 -0.211535 -1.085148  ...   
33659 -1.254274         -1.063225      -0.470958 -2.849419  0.127664  ...   
19531 -2.339052         -0.356898      -0.470595 -0.900608  0.393896  ...   

       Race_5.0  Race_1.0  Race_4.0  Race_3.0  Race_2.0  Education   Smoking  \
28456       1.0       0.0       0.0       0.0       0.0  -0.012820  0.000000   
8993        0.0       0.0       1.0       0.0       0.0   0.547458  1.000000   
34312       0.0       0.0       0.0       1.0       0.0  -0.659696  0.000000   
4802        1.0       0.0       0.0       0.0       0.0   0.262895  0.073612   
25895       0.0       0.0       0.0       1.0       0.0   1.151035  0.000000   
...         ...       ...       ...       ...       ...        ...       ...   
18045       0.0       0.0       0.0       1.0       0.0  -0.793202  0.000000   
5425        0.0       0.0       1.0       0.0       0.0   0.547458  1.000000   
12819       0.0       0.0       0.0       1.0       0.0   1.151035  1.000000   
33659       0.0       0.0       1.0       0.0       0.0   0.258362  0.000000   
19531       1.0       0.0       0.0       0.0       0.0  -0.821118  0.000000   

       PhysicalActivity  HealthInsurance   Alcohol  
28456          0.660578              0.0 -0.518600  
8993           0.000000              0.0  0.115329  
34312          0.000000              0.0  0.592213  
4802           1.012447              0.0 -0.103347  
25895          0.000000              0.0 -0.886483  
...                 ...              ...       ...  
18045          0.904383              0.0 -0.482716  
5425           1.598141              0.0  0.097790  
12819          1.598141              0.0  0.612947  
33659          1.162475              0.0 -0.154408  
19531          0.791302              0.0 -0.683278  

[13109 rows x 31 columns]
2025-12-03 09:46:36,819:INFO:get_config() successfully completed......................................
2025-12-03 09:46:36,844:INFO:Initializing get_config()
2025-12-03 09:46:36,844:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018F86ECEB30>, variable=y_test)
2025-12-03 09:46:36,846:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-12-03 09:46:36,846:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-12-03 09:46:36,850:INFO:Variable:  returned as 28456    0.0
8993     0.0
34312    0.0
4802     0.0
25895    0.0
        ... 
18045    0.0
5425     0.0
12819    0.0
33659    0.0
19531    0.0
Name: HeartDisease, Length: 13109, dtype: float32
2025-12-03 09:46:36,850:INFO:get_config() successfully completed......................................
2025-12-03 09:46:36,853:INFO:Initializing get_config()
2025-12-03 09:46:36,853:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018F86ECEB30>, variable=y_test)
2025-12-03 09:46:36,853:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-12-03 09:46:36,853:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-12-03 09:46:36,858:INFO:Variable:  returned as 28456    0.0
8993     0.0
34312    0.0
4802     0.0
25895    0.0
        ... 
18045    0.0
5425     0.0
12819    0.0
33659    0.0
19531    0.0
Name: HeartDisease, Length: 13109, dtype: float32
2025-12-03 09:46:36,858:INFO:get_config() successfully completed......................................
2025-12-03 09:46:36,859:INFO:Initializing get_config()
2025-12-03 09:46:36,859:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018F86ECEB30>, variable=X_test_transformed)
2025-12-03 09:46:36,926:INFO:Variable: X_test returned as             Age  IncomeRatio  SystolicBP       BMI  WaistCircumference  \
28456 -0.477273    -0.304717   -0.519256 -0.987220           -0.923253   
8993   0.818182     0.253271    2.156910  0.770675            0.920394   
34312  0.704545     0.055403    0.519256  0.518044            0.662901   
4802  -0.545455     0.253730   -0.331933 -0.229036           -0.436352   
25895  0.704545     1.226781   -0.093200 -0.226100            0.012322   
...         ...          ...         ...       ...                 ...   
18045 -0.568182    -0.083104   -0.568713 -1.176693           -1.338674   
5425   0.590909     0.362732    2.210168  0.139096            0.292112   
12819  0.909091    -0.019787    0.899042  0.454886            0.971892   
33659 -0.522727     1.060572   -0.525683 -0.587220           -0.906087   
19531 -0.590909    -0.344290   -0.510287 -0.945114           -1.215078   

         Height  TotalCholesterol  Triglycerides       LDL       HDL  ...  \
28456 -1.080540         -0.078535      -0.470757 -0.026922  0.418008  ...   
8993  -0.279669          0.765897       0.705031  0.006026  0.446825  ...   
34312  0.559339         -0.123259       0.929511 -1.031826 -1.404309  ...   
4802  -0.504861         -0.188325      -0.322647  0.000015 -0.138743  ...   
25895  0.216731          0.892919       1.291109  0.008211 -0.255329  ...   
...         ...               ...            ...       ...       ...  ...   
18045 -2.080569         -0.340947      -0.470582 -0.848950  0.393794  ...   
5425   0.156785          0.435639      -0.065356  1.113733  0.127664  ...   
12819  1.194951         -0.732967      -0.470025 -0.211535 -1.085148  ...   
33659 -1.254274         -1.063225      -0.470958 -2.849419  0.127664  ...   
19531 -2.339052         -0.356898      -0.470595 -0.900608  0.393896  ...   

       Race_5.0  Race_1.0  Race_4.0  Race_3.0  Race_2.0  Education   Smoking  \
28456       1.0       0.0       0.0       0.0       0.0  -0.012820  0.000000   
8993        0.0       0.0       1.0       0.0       0.0   0.547458  1.000000   
34312       0.0       0.0       0.0       1.0       0.0  -0.659696  0.000000   
4802        1.0       0.0       0.0       0.0       0.0   0.262895  0.073612   
25895       0.0       0.0       0.0       1.0       0.0   1.151035  0.000000   
...         ...       ...       ...       ...       ...        ...       ...   
18045       0.0       0.0       0.0       1.0       0.0  -0.793202  0.000000   
5425        0.0       0.0       1.0       0.0       0.0   0.547458  1.000000   
12819       0.0       0.0       0.0       1.0       0.0   1.151035  1.000000   
33659       0.0       0.0       1.0       0.0       0.0   0.258362  0.000000   
19531       1.0       0.0       0.0       0.0       0.0  -0.821118  0.000000   

       PhysicalActivity  HealthInsurance   Alcohol  
28456          0.660578              0.0 -0.518600  
8993           0.000000              0.0  0.115329  
34312          0.000000              0.0  0.592213  
4802           1.012447              0.0 -0.103347  
25895          0.000000              0.0 -0.886483  
...                 ...              ...       ...  
18045          0.904383              0.0 -0.482716  
5425           1.598141              0.0  0.097790  
12819          1.598141              0.0  0.612947  
33659          1.162475              0.0 -0.154408  
19531          0.791302              0.0 -0.683278  

[13109 rows x 31 columns]
2025-12-03 09:46:36,926:INFO:get_config() successfully completed......................................
2025-12-03 09:46:36,928:INFO:Initializing get_config()
2025-12-03 09:46:36,928:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018F86ECEB30>, variable=y_test)
2025-12-03 09:46:36,928:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-12-03 09:46:36,928:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-12-03 09:46:36,931:INFO:Variable:  returned as 28456    0.0
8993     0.0
34312    0.0
4802     0.0
25895    0.0
        ... 
18045    0.0
5425     0.0
12819    0.0
33659    0.0
19531    0.0
Name: HeartDisease, Length: 13109, dtype: float32
2025-12-03 09:46:36,931:INFO:get_config() successfully completed......................................
2025-12-03 09:46:36,934:INFO:Initializing get_config()
2025-12-03 09:46:36,934:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018F86ECEB30>, variable=y_test)
2025-12-03 09:46:36,934:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-12-03 09:46:36,934:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-12-03 09:46:36,941:INFO:Variable:  returned as 28456    0.0
8993     0.0
34312    0.0
4802     0.0
25895    0.0
        ... 
18045    0.0
5425     0.0
12819    0.0
33659    0.0
19531    0.0
Name: HeartDisease, Length: 13109, dtype: float32
2025-12-03 09:46:36,941:INFO:get_config() successfully completed......................................
2025-12-03 09:46:36,942:INFO:Initializing get_config()
2025-12-03 09:46:36,942:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018F86ECEB30>, variable=X_test_transformed)
2025-12-03 09:46:37,009:INFO:Variable: X_test returned as             Age  IncomeRatio  SystolicBP       BMI  WaistCircumference  \
28456 -0.477273    -0.304717   -0.519256 -0.987220           -0.923253   
8993   0.818182     0.253271    2.156910  0.770675            0.920394   
34312  0.704545     0.055403    0.519256  0.518044            0.662901   
4802  -0.545455     0.253730   -0.331933 -0.229036           -0.436352   
25895  0.704545     1.226781   -0.093200 -0.226100            0.012322   
...         ...          ...         ...       ...                 ...   
18045 -0.568182    -0.083104   -0.568713 -1.176693           -1.338674   
5425   0.590909     0.362732    2.210168  0.139096            0.292112   
12819  0.909091    -0.019787    0.899042  0.454886            0.971892   
33659 -0.522727     1.060572   -0.525683 -0.587220           -0.906087   
19531 -0.590909    -0.344290   -0.510287 -0.945114           -1.215078   

         Height  TotalCholesterol  Triglycerides       LDL       HDL  ...  \
28456 -1.080540         -0.078535      -0.470757 -0.026922  0.418008  ...   
8993  -0.279669          0.765897       0.705031  0.006026  0.446825  ...   
34312  0.559339         -0.123259       0.929511 -1.031826 -1.404309  ...   
4802  -0.504861         -0.188325      -0.322647  0.000015 -0.138743  ...   
25895  0.216731          0.892919       1.291109  0.008211 -0.255329  ...   
...         ...               ...            ...       ...       ...  ...   
18045 -2.080569         -0.340947      -0.470582 -0.848950  0.393794  ...   
5425   0.156785          0.435639      -0.065356  1.113733  0.127664  ...   
12819  1.194951         -0.732967      -0.470025 -0.211535 -1.085148  ...   
33659 -1.254274         -1.063225      -0.470958 -2.849419  0.127664  ...   
19531 -2.339052         -0.356898      -0.470595 -0.900608  0.393896  ...   

       Race_5.0  Race_1.0  Race_4.0  Race_3.0  Race_2.0  Education   Smoking  \
28456       1.0       0.0       0.0       0.0       0.0  -0.012820  0.000000   
8993        0.0       0.0       1.0       0.0       0.0   0.547458  1.000000   
34312       0.0       0.0       0.0       1.0       0.0  -0.659696  0.000000   
4802        1.0       0.0       0.0       0.0       0.0   0.262895  0.073612   
25895       0.0       0.0       0.0       1.0       0.0   1.151035  0.000000   
...         ...       ...       ...       ...       ...        ...       ...   
18045       0.0       0.0       0.0       1.0       0.0  -0.793202  0.000000   
5425        0.0       0.0       1.0       0.0       0.0   0.547458  1.000000   
12819       0.0       0.0       0.0       1.0       0.0   1.151035  1.000000   
33659       0.0       0.0       1.0       0.0       0.0   0.258362  0.000000   
19531       1.0       0.0       0.0       0.0       0.0  -0.821118  0.000000   

       PhysicalActivity  HealthInsurance   Alcohol  
28456          0.660578              0.0 -0.518600  
8993           0.000000              0.0  0.115329  
34312          0.000000              0.0  0.592213  
4802           1.012447              0.0 -0.103347  
25895          0.000000              0.0 -0.886483  
...                 ...              ...       ...  
18045          0.904383              0.0 -0.482716  
5425           1.598141              0.0  0.097790  
12819          1.598141              0.0  0.612947  
33659          1.162475              0.0 -0.154408  
19531          0.791302              0.0 -0.683278  

[13109 rows x 31 columns]
2025-12-03 09:46:37,009:INFO:get_config() successfully completed......................................
2025-12-03 09:46:37,064:INFO:Initializing get_config()
2025-12-03 09:46:37,064:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018F86ECEB30>, variable=y_test)
2025-12-03 09:46:37,064:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-12-03 09:46:37,064:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-12-03 09:46:37,069:INFO:Variable:  returned as 28456    0.0
8993     0.0
34312    0.0
4802     0.0
25895    0.0
        ... 
18045    0.0
5425     0.0
12819    0.0
33659    0.0
19531    0.0
Name: HeartDisease, Length: 13109, dtype: float32
2025-12-03 09:46:37,069:INFO:get_config() successfully completed......................................
2025-12-03 09:46:37,070:INFO:Initializing get_config()
2025-12-03 09:46:37,070:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018F86ECEB30>, variable=y_test)
2025-12-03 09:46:37,070:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-12-03 09:46:37,070:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-12-03 09:46:37,076:INFO:Variable:  returned as 28456    0.0
8993     0.0
34312    0.0
4802     0.0
25895    0.0
        ... 
18045    0.0
5425     0.0
12819    0.0
33659    0.0
19531    0.0
Name: HeartDisease, Length: 13109, dtype: float32
2025-12-03 09:46:37,076:INFO:get_config() successfully completed......................................
2025-12-03 09:46:37,096:INFO:Initializing plot_model()
2025-12-03 09:46:37,096:INFO:plot_model(plot=error, fold=None, verbose=True, display=None, display_format=None, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018F86ECEB30>, system=True)
2025-12-03 09:46:37,096:INFO:Checking exceptions
2025-12-03 09:46:37,119:INFO:Preloading libraries
2025-12-03 09:46:37,134:INFO:Copying training dataset
2025-12-03 09:46:37,134:INFO:Plot type: error
2025-12-03 09:46:37,341:INFO:Fitting Model
2025-12-03 09:46:37,341:INFO:Scoring test/hold-out set
2025-12-03 09:46:37,499:INFO:Visual Rendered Successfully
2025-12-03 09:46:37,663:INFO:plot_model() successfully completed......................................
2025-12-03 09:46:37,685:INFO:Initializing get_config()
2025-12-03 09:46:37,685:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018F86ECEB30>, variable=X_test_transformed)
2025-12-03 09:46:37,760:INFO:Variable: X_test returned as             Age  IncomeRatio  SystolicBP       BMI  WaistCircumference  \
28456 -0.477273    -0.304717   -0.519256 -0.987220           -0.923253   
8993   0.818182     0.253271    2.156910  0.770675            0.920394   
34312  0.704545     0.055403    0.519256  0.518044            0.662901   
4802  -0.545455     0.253730   -0.331933 -0.229036           -0.436352   
25895  0.704545     1.226781   -0.093200 -0.226100            0.012322   
...         ...          ...         ...       ...                 ...   
18045 -0.568182    -0.083104   -0.568713 -1.176693           -1.338674   
5425   0.590909     0.362732    2.210168  0.139096            0.292112   
12819  0.909091    -0.019787    0.899042  0.454886            0.971892   
33659 -0.522727     1.060572   -0.525683 -0.587220           -0.906087   
19531 -0.590909    -0.344290   -0.510287 -0.945114           -1.215078   

         Height  TotalCholesterol  Triglycerides       LDL       HDL  ...  \
28456 -1.080540         -0.078535      -0.470757 -0.026922  0.418008  ...   
8993  -0.279669          0.765897       0.705031  0.006026  0.446825  ...   
34312  0.559339         -0.123259       0.929511 -1.031826 -1.404309  ...   
4802  -0.504861         -0.188325      -0.322647  0.000015 -0.138743  ...   
25895  0.216731          0.892919       1.291109  0.008211 -0.255329  ...   
...         ...               ...            ...       ...       ...  ...   
18045 -2.080569         -0.340947      -0.470582 -0.848950  0.393794  ...   
5425   0.156785          0.435639      -0.065356  1.113733  0.127664  ...   
12819  1.194951         -0.732967      -0.470025 -0.211535 -1.085148  ...   
33659 -1.254274         -1.063225      -0.470958 -2.849419  0.127664  ...   
19531 -2.339052         -0.356898      -0.470595 -0.900608  0.393896  ...   

       Race_5.0  Race_1.0  Race_4.0  Race_3.0  Race_2.0  Education   Smoking  \
28456       1.0       0.0       0.0       0.0       0.0  -0.012820  0.000000   
8993        0.0       0.0       1.0       0.0       0.0   0.547458  1.000000   
34312       0.0       0.0       0.0       1.0       0.0  -0.659696  0.000000   
4802        1.0       0.0       0.0       0.0       0.0   0.262895  0.073612   
25895       0.0       0.0       0.0       1.0       0.0   1.151035  0.000000   
...         ...       ...       ...       ...       ...        ...       ...   
18045       0.0       0.0       0.0       1.0       0.0  -0.793202  0.000000   
5425        0.0       0.0       1.0       0.0       0.0   0.547458  1.000000   
12819       0.0       0.0       0.0       1.0       0.0   1.151035  1.000000   
33659       0.0       0.0       1.0       0.0       0.0   0.258362  0.000000   
19531       1.0       0.0       0.0       0.0       0.0  -0.821118  0.000000   

       PhysicalActivity  HealthInsurance   Alcohol  
28456          0.660578              0.0 -0.518600  
8993           0.000000              0.0  0.115329  
34312          0.000000              0.0  0.592213  
4802           1.012447              0.0 -0.103347  
25895          0.000000              0.0 -0.886483  
...                 ...              ...       ...  
18045          0.904383              0.0 -0.482716  
5425           1.598141              0.0  0.097790  
12819          1.598141              0.0  0.612947  
33659          1.162475              0.0 -0.154408  
19531          0.791302              0.0 -0.683278  

[13109 rows x 31 columns]
2025-12-03 09:46:37,760:INFO:get_config() successfully completed......................................
2025-12-03 09:46:37,785:INFO:Initializing get_config()
2025-12-03 09:46:37,785:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018F86ECEB30>, variable=y_test)
2025-12-03 09:46:37,785:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-12-03 09:46:37,785:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-12-03 09:46:37,791:INFO:Variable:  returned as 28456    0.0
8993     0.0
34312    0.0
4802     0.0
25895    0.0
        ... 
18045    0.0
5425     0.0
12819    0.0
33659    0.0
19531    0.0
Name: HeartDisease, Length: 13109, dtype: float32
2025-12-03 09:46:37,791:INFO:get_config() successfully completed......................................
2025-12-03 09:46:37,791:INFO:Initializing get_config()
2025-12-03 09:46:37,791:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018F86ECEB30>, variable=y_test)
2025-12-03 09:46:37,791:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-12-03 09:46:37,791:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-12-03 09:46:37,794:INFO:Variable:  returned as 28456    0.0
8993     0.0
34312    0.0
4802     0.0
25895    0.0
        ... 
18045    0.0
5425     0.0
12819    0.0
33659    0.0
19531    0.0
Name: HeartDisease, Length: 13109, dtype: float32
2025-12-03 09:46:37,794:INFO:get_config() successfully completed......................................
2025-12-03 09:46:37,794:INFO:Initializing get_config()
2025-12-03 09:46:37,794:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018F86ECEB30>, variable=X_test_transformed)
2025-12-03 09:46:37,863:INFO:Variable: X_test returned as             Age  IncomeRatio  SystolicBP       BMI  WaistCircumference  \
28456 -0.477273    -0.304717   -0.519256 -0.987220           -0.923253   
8993   0.818182     0.253271    2.156910  0.770675            0.920394   
34312  0.704545     0.055403    0.519256  0.518044            0.662901   
4802  -0.545455     0.253730   -0.331933 -0.229036           -0.436352   
25895  0.704545     1.226781   -0.093200 -0.226100            0.012322   
...         ...          ...         ...       ...                 ...   
18045 -0.568182    -0.083104   -0.568713 -1.176693           -1.338674   
5425   0.590909     0.362732    2.210168  0.139096            0.292112   
12819  0.909091    -0.019787    0.899042  0.454886            0.971892   
33659 -0.522727     1.060572   -0.525683 -0.587220           -0.906087   
19531 -0.590909    -0.344290   -0.510287 -0.945114           -1.215078   

         Height  TotalCholesterol  Triglycerides       LDL       HDL  ...  \
28456 -1.080540         -0.078535      -0.470757 -0.026922  0.418008  ...   
8993  -0.279669          0.765897       0.705031  0.006026  0.446825  ...   
34312  0.559339         -0.123259       0.929511 -1.031826 -1.404309  ...   
4802  -0.504861         -0.188325      -0.322647  0.000015 -0.138743  ...   
25895  0.216731          0.892919       1.291109  0.008211 -0.255329  ...   
...         ...               ...            ...       ...       ...  ...   
18045 -2.080569         -0.340947      -0.470582 -0.848950  0.393794  ...   
5425   0.156785          0.435639      -0.065356  1.113733  0.127664  ...   
12819  1.194951         -0.732967      -0.470025 -0.211535 -1.085148  ...   
33659 -1.254274         -1.063225      -0.470958 -2.849419  0.127664  ...   
19531 -2.339052         -0.356898      -0.470595 -0.900608  0.393896  ...   

       Race_5.0  Race_1.0  Race_4.0  Race_3.0  Race_2.0  Education   Smoking  \
28456       1.0       0.0       0.0       0.0       0.0  -0.012820  0.000000   
8993        0.0       0.0       1.0       0.0       0.0   0.547458  1.000000   
34312       0.0       0.0       0.0       1.0       0.0  -0.659696  0.000000   
4802        1.0       0.0       0.0       0.0       0.0   0.262895  0.073612   
25895       0.0       0.0       0.0       1.0       0.0   1.151035  0.000000   
...         ...       ...       ...       ...       ...        ...       ...   
18045       0.0       0.0       0.0       1.0       0.0  -0.793202  0.000000   
5425        0.0       0.0       1.0       0.0       0.0   0.547458  1.000000   
12819       0.0       0.0       0.0       1.0       0.0   1.151035  1.000000   
33659       0.0       0.0       1.0       0.0       0.0   0.258362  0.000000   
19531       1.0       0.0       0.0       0.0       0.0  -0.821118  0.000000   

       PhysicalActivity  HealthInsurance   Alcohol  
28456          0.660578              0.0 -0.518600  
8993           0.000000              0.0  0.115329  
34312          0.000000              0.0  0.592213  
4802           1.012447              0.0 -0.103347  
25895          0.000000              0.0 -0.886483  
...                 ...              ...       ...  
18045          0.904383              0.0 -0.482716  
5425           1.598141              0.0  0.097790  
12819          1.598141              0.0  0.612947  
33659          1.162475              0.0 -0.154408  
19531          0.791302              0.0 -0.683278  

[13109 rows x 31 columns]
2025-12-03 09:46:37,863:INFO:get_config() successfully completed......................................
2025-12-03 09:46:37,863:INFO:Initializing get_config()
2025-12-03 09:46:37,863:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018F86ECEB30>, variable=y_test)
2025-12-03 09:46:37,863:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-12-03 09:46:37,863:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-12-03 09:46:37,870:INFO:Variable:  returned as 28456    0.0
8993     0.0
34312    0.0
4802     0.0
25895    0.0
        ... 
18045    0.0
5425     0.0
12819    0.0
33659    0.0
19531    0.0
Name: HeartDisease, Length: 13109, dtype: float32
2025-12-03 09:46:37,870:INFO:get_config() successfully completed......................................
2025-12-03 09:46:37,870:INFO:Initializing get_config()
2025-12-03 09:46:37,870:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018F86ECEB30>, variable=y_test)
2025-12-03 09:46:37,870:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-12-03 09:46:37,870:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-12-03 09:46:37,877:INFO:Variable:  returned as 28456    0.0
8993     0.0
34312    0.0
4802     0.0
25895    0.0
        ... 
18045    0.0
5425     0.0
12819    0.0
33659    0.0
19531    0.0
Name: HeartDisease, Length: 13109, dtype: float32
2025-12-03 09:46:37,877:INFO:get_config() successfully completed......................................
2025-12-03 09:46:37,877:INFO:Initializing get_config()
2025-12-03 09:46:37,877:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018F86ECEB30>, variable=X_test_transformed)
2025-12-03 09:46:37,945:INFO:Variable: X_test returned as             Age  IncomeRatio  SystolicBP       BMI  WaistCircumference  \
28456 -0.477273    -0.304717   -0.519256 -0.987220           -0.923253   
8993   0.818182     0.253271    2.156910  0.770675            0.920394   
34312  0.704545     0.055403    0.519256  0.518044            0.662901   
4802  -0.545455     0.253730   -0.331933 -0.229036           -0.436352   
25895  0.704545     1.226781   -0.093200 -0.226100            0.012322   
...         ...          ...         ...       ...                 ...   
18045 -0.568182    -0.083104   -0.568713 -1.176693           -1.338674   
5425   0.590909     0.362732    2.210168  0.139096            0.292112   
12819  0.909091    -0.019787    0.899042  0.454886            0.971892   
33659 -0.522727     1.060572   -0.525683 -0.587220           -0.906087   
19531 -0.590909    -0.344290   -0.510287 -0.945114           -1.215078   

         Height  TotalCholesterol  Triglycerides       LDL       HDL  ...  \
28456 -1.080540         -0.078535      -0.470757 -0.026922  0.418008  ...   
8993  -0.279669          0.765897       0.705031  0.006026  0.446825  ...   
34312  0.559339         -0.123259       0.929511 -1.031826 -1.404309  ...   
4802  -0.504861         -0.188325      -0.322647  0.000015 -0.138743  ...   
25895  0.216731          0.892919       1.291109  0.008211 -0.255329  ...   
...         ...               ...            ...       ...       ...  ...   
18045 -2.080569         -0.340947      -0.470582 -0.848950  0.393794  ...   
5425   0.156785          0.435639      -0.065356  1.113733  0.127664  ...   
12819  1.194951         -0.732967      -0.470025 -0.211535 -1.085148  ...   
33659 -1.254274         -1.063225      -0.470958 -2.849419  0.127664  ...   
19531 -2.339052         -0.356898      -0.470595 -0.900608  0.393896  ...   

       Race_5.0  Race_1.0  Race_4.0  Race_3.0  Race_2.0  Education   Smoking  \
28456       1.0       0.0       0.0       0.0       0.0  -0.012820  0.000000   
8993        0.0       0.0       1.0       0.0       0.0   0.547458  1.000000   
34312       0.0       0.0       0.0       1.0       0.0  -0.659696  0.000000   
4802        1.0       0.0       0.0       0.0       0.0   0.262895  0.073612   
25895       0.0       0.0       0.0       1.0       0.0   1.151035  0.000000   
...         ...       ...       ...       ...       ...        ...       ...   
18045       0.0       0.0       0.0       1.0       0.0  -0.793202  0.000000   
5425        0.0       0.0       1.0       0.0       0.0   0.547458  1.000000   
12819       0.0       0.0       0.0       1.0       0.0   1.151035  1.000000   
33659       0.0       0.0       1.0       0.0       0.0   0.258362  0.000000   
19531       1.0       0.0       0.0       0.0       0.0  -0.821118  0.000000   

       PhysicalActivity  HealthInsurance   Alcohol  
28456          0.660578              0.0 -0.518600  
8993           0.000000              0.0  0.115329  
34312          0.000000              0.0  0.592213  
4802           1.012447              0.0 -0.103347  
25895          0.000000              0.0 -0.886483  
...                 ...              ...       ...  
18045          0.904383              0.0 -0.482716  
5425           1.598141              0.0  0.097790  
12819          1.598141              0.0  0.612947  
33659          1.162475              0.0 -0.154408  
19531          0.791302              0.0 -0.683278  

[13109 rows x 31 columns]
2025-12-03 09:46:37,945:INFO:get_config() successfully completed......................................
2025-12-03 09:46:37,999:INFO:Initializing get_config()
2025-12-03 09:46:37,999:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018F86ECEB30>, variable=y_test)
2025-12-03 09:46:37,999:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-12-03 09:46:37,999:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-12-03 09:46:38,006:INFO:Variable:  returned as 28456    0.0
8993     0.0
34312    0.0
4802     0.0
25895    0.0
        ... 
18045    0.0
5425     0.0
12819    0.0
33659    0.0
19531    0.0
Name: HeartDisease, Length: 13109, dtype: float32
2025-12-03 09:46:38,006:INFO:get_config() successfully completed......................................
2025-12-03 09:46:38,007:INFO:Initializing get_config()
2025-12-03 09:46:38,007:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018F86ECEB30>, variable=y_test)
2025-12-03 09:46:38,007:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-12-03 09:46:38,007:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-12-03 09:46:38,012:INFO:Variable:  returned as 28456    0.0
8993     0.0
34312    0.0
4802     0.0
25895    0.0
        ... 
18045    0.0
5425     0.0
12819    0.0
33659    0.0
19531    0.0
Name: HeartDisease, Length: 13109, dtype: float32
2025-12-03 09:46:38,012:INFO:get_config() successfully completed......................................
2025-12-03 09:46:38,105:INFO:Initializing get_config()
2025-12-03 09:46:38,105:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018F86ECEB30>, variable=X_test_transformed)
2025-12-03 09:46:38,176:INFO:Variable: X_test returned as             Age  IncomeRatio  SystolicBP       BMI  WaistCircumference  \
28456 -0.477273    -0.304717   -0.519256 -0.987220           -0.923253   
8993   0.818182     0.253271    2.156910  0.770675            0.920394   
34312  0.704545     0.055403    0.519256  0.518044            0.662901   
4802  -0.545455     0.253730   -0.331933 -0.229036           -0.436352   
25895  0.704545     1.226781   -0.093200 -0.226100            0.012322   
...         ...          ...         ...       ...                 ...   
18045 -0.568182    -0.083104   -0.568713 -1.176693           -1.338674   
5425   0.590909     0.362732    2.210168  0.139096            0.292112   
12819  0.909091    -0.019787    0.899042  0.454886            0.971892   
33659 -0.522727     1.060572   -0.525683 -0.587220           -0.906087   
19531 -0.590909    -0.344290   -0.510287 -0.945114           -1.215078   

         Height  TotalCholesterol  Triglycerides       LDL       HDL  ...  \
28456 -1.080540         -0.078535      -0.470757 -0.026922  0.418008  ...   
8993  -0.279669          0.765897       0.705031  0.006026  0.446825  ...   
34312  0.559339         -0.123259       0.929511 -1.031826 -1.404309  ...   
4802  -0.504861         -0.188325      -0.322647  0.000015 -0.138743  ...   
25895  0.216731          0.892919       1.291109  0.008211 -0.255329  ...   
...         ...               ...            ...       ...       ...  ...   
18045 -2.080569         -0.340947      -0.470582 -0.848950  0.393794  ...   
5425   0.156785          0.435639      -0.065356  1.113733  0.127664  ...   
12819  1.194951         -0.732967      -0.470025 -0.211535 -1.085148  ...   
33659 -1.254274         -1.063225      -0.470958 -2.849419  0.127664  ...   
19531 -2.339052         -0.356898      -0.470595 -0.900608  0.393896  ...   

       Race_5.0  Race_1.0  Race_4.0  Race_3.0  Race_2.0  Education   Smoking  \
28456       1.0       0.0       0.0       0.0       0.0  -0.012820  0.000000   
8993        0.0       0.0       1.0       0.0       0.0   0.547458  1.000000   
34312       0.0       0.0       0.0       1.0       0.0  -0.659696  0.000000   
4802        1.0       0.0       0.0       0.0       0.0   0.262895  0.073612   
25895       0.0       0.0       0.0       1.0       0.0   1.151035  0.000000   
...         ...       ...       ...       ...       ...        ...       ...   
18045       0.0       0.0       0.0       1.0       0.0  -0.793202  0.000000   
5425        0.0       0.0       1.0       0.0       0.0   0.547458  1.000000   
12819       0.0       0.0       0.0       1.0       0.0   1.151035  1.000000   
33659       0.0       0.0       1.0       0.0       0.0   0.258362  0.000000   
19531       1.0       0.0       0.0       0.0       0.0  -0.821118  0.000000   

       PhysicalActivity  HealthInsurance   Alcohol  
28456          0.660578              0.0 -0.518600  
8993           0.000000              0.0  0.115329  
34312          0.000000              0.0  0.592213  
4802           1.012447              0.0 -0.103347  
25895          0.000000              0.0 -0.886483  
...                 ...              ...       ...  
18045          0.904383              0.0 -0.482716  
5425           1.598141              0.0  0.097790  
12819          1.598141              0.0  0.612947  
33659          1.162475              0.0 -0.154408  
19531          0.791302              0.0 -0.683278  

[13109 rows x 31 columns]
2025-12-03 09:46:38,176:INFO:get_config() successfully completed......................................
2025-12-03 09:46:38,202:INFO:Initializing get_config()
2025-12-03 09:46:38,202:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018F86ECEB30>, variable=y_test)
2025-12-03 09:46:38,202:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-12-03 09:46:38,204:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-12-03 09:46:38,209:INFO:Variable:  returned as 28456    0.0
8993     0.0
34312    0.0
4802     0.0
25895    0.0
        ... 
18045    0.0
5425     0.0
12819    0.0
33659    0.0
19531    0.0
Name: HeartDisease, Length: 13109, dtype: float32
2025-12-03 09:46:38,209:INFO:get_config() successfully completed......................................
2025-12-03 09:46:38,209:INFO:Initializing get_config()
2025-12-03 09:46:38,209:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018F86ECEB30>, variable=X_test_transformed)
2025-12-03 09:46:38,278:INFO:Variable: X_test returned as             Age  IncomeRatio  SystolicBP       BMI  WaistCircumference  \
28456 -0.477273    -0.304717   -0.519256 -0.987220           -0.923253   
8993   0.818182     0.253271    2.156910  0.770675            0.920394   
34312  0.704545     0.055403    0.519256  0.518044            0.662901   
4802  -0.545455     0.253730   -0.331933 -0.229036           -0.436352   
25895  0.704545     1.226781   -0.093200 -0.226100            0.012322   
...         ...          ...         ...       ...                 ...   
18045 -0.568182    -0.083104   -0.568713 -1.176693           -1.338674   
5425   0.590909     0.362732    2.210168  0.139096            0.292112   
12819  0.909091    -0.019787    0.899042  0.454886            0.971892   
33659 -0.522727     1.060572   -0.525683 -0.587220           -0.906087   
19531 -0.590909    -0.344290   -0.510287 -0.945114           -1.215078   

         Height  TotalCholesterol  Triglycerides       LDL       HDL  ...  \
28456 -1.080540         -0.078535      -0.470757 -0.026922  0.418008  ...   
8993  -0.279669          0.765897       0.705031  0.006026  0.446825  ...   
34312  0.559339         -0.123259       0.929511 -1.031826 -1.404309  ...   
4802  -0.504861         -0.188325      -0.322647  0.000015 -0.138743  ...   
25895  0.216731          0.892919       1.291109  0.008211 -0.255329  ...   
...         ...               ...            ...       ...       ...  ...   
18045 -2.080569         -0.340947      -0.470582 -0.848950  0.393794  ...   
5425   0.156785          0.435639      -0.065356  1.113733  0.127664  ...   
12819  1.194951         -0.732967      -0.470025 -0.211535 -1.085148  ...   
33659 -1.254274         -1.063225      -0.470958 -2.849419  0.127664  ...   
19531 -2.339052         -0.356898      -0.470595 -0.900608  0.393896  ...   

       Race_5.0  Race_1.0  Race_4.0  Race_3.0  Race_2.0  Education   Smoking  \
28456       1.0       0.0       0.0       0.0       0.0  -0.012820  0.000000   
8993        0.0       0.0       1.0       0.0       0.0   0.547458  1.000000   
34312       0.0       0.0       0.0       1.0       0.0  -0.659696  0.000000   
4802        1.0       0.0       0.0       0.0       0.0   0.262895  0.073612   
25895       0.0       0.0       0.0       1.0       0.0   1.151035  0.000000   
...         ...       ...       ...       ...       ...        ...       ...   
18045       0.0       0.0       0.0       1.0       0.0  -0.793202  0.000000   
5425        0.0       0.0       1.0       0.0       0.0   0.547458  1.000000   
12819       0.0       0.0       0.0       1.0       0.0   1.151035  1.000000   
33659       0.0       0.0       1.0       0.0       0.0   0.258362  0.000000   
19531       1.0       0.0       0.0       0.0       0.0  -0.821118  0.000000   

       PhysicalActivity  HealthInsurance   Alcohol  
28456          0.660578              0.0 -0.518600  
8993           0.000000              0.0  0.115329  
34312          0.000000              0.0  0.592213  
4802           1.012447              0.0 -0.103347  
25895          0.000000              0.0 -0.886483  
...                 ...              ...       ...  
18045          0.904383              0.0 -0.482716  
5425           1.598141              0.0  0.097790  
12819          1.598141              0.0  0.612947  
33659          1.162475              0.0 -0.154408  
19531          0.791302              0.0 -0.683278  

[13109 rows x 31 columns]
2025-12-03 09:46:38,280:INFO:get_config() successfully completed......................................
2025-12-03 09:46:38,281:INFO:Initializing get_config()
2025-12-03 09:46:38,281:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018F86ECEB30>, variable=y_test)
2025-12-03 09:46:38,281:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-12-03 09:46:38,281:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-12-03 09:46:38,284:INFO:Variable:  returned as 28456    0.0
8993     0.0
34312    0.0
4802     0.0
25895    0.0
        ... 
18045    0.0
5425     0.0
12819    0.0
33659    0.0
19531    0.0
Name: HeartDisease, Length: 13109, dtype: float32
2025-12-03 09:46:38,284:INFO:get_config() successfully completed......................................
2025-12-03 09:46:38,284:INFO:Initializing get_config()
2025-12-03 09:46:38,284:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018F86ECEB30>, variable=X_test_transformed)
2025-12-03 09:46:38,356:INFO:Variable: X_test returned as             Age  IncomeRatio  SystolicBP       BMI  WaistCircumference  \
28456 -0.477273    -0.304717   -0.519256 -0.987220           -0.923253   
8993   0.818182     0.253271    2.156910  0.770675            0.920394   
34312  0.704545     0.055403    0.519256  0.518044            0.662901   
4802  -0.545455     0.253730   -0.331933 -0.229036           -0.436352   
25895  0.704545     1.226781   -0.093200 -0.226100            0.012322   
...         ...          ...         ...       ...                 ...   
18045 -0.568182    -0.083104   -0.568713 -1.176693           -1.338674   
5425   0.590909     0.362732    2.210168  0.139096            0.292112   
12819  0.909091    -0.019787    0.899042  0.454886            0.971892   
33659 -0.522727     1.060572   -0.525683 -0.587220           -0.906087   
19531 -0.590909    -0.344290   -0.510287 -0.945114           -1.215078   

         Height  TotalCholesterol  Triglycerides       LDL       HDL  ...  \
28456 -1.080540         -0.078535      -0.470757 -0.026922  0.418008  ...   
8993  -0.279669          0.765897       0.705031  0.006026  0.446825  ...   
34312  0.559339         -0.123259       0.929511 -1.031826 -1.404309  ...   
4802  -0.504861         -0.188325      -0.322647  0.000015 -0.138743  ...   
25895  0.216731          0.892919       1.291109  0.008211 -0.255329  ...   
...         ...               ...            ...       ...       ...  ...   
18045 -2.080569         -0.340947      -0.470582 -0.848950  0.393794  ...   
5425   0.156785          0.435639      -0.065356  1.113733  0.127664  ...   
12819  1.194951         -0.732967      -0.470025 -0.211535 -1.085148  ...   
33659 -1.254274         -1.063225      -0.470958 -2.849419  0.127664  ...   
19531 -2.339052         -0.356898      -0.470595 -0.900608  0.393896  ...   

       Race_5.0  Race_1.0  Race_4.0  Race_3.0  Race_2.0  Education   Smoking  \
28456       1.0       0.0       0.0       0.0       0.0  -0.012820  0.000000   
8993        0.0       0.0       1.0       0.0       0.0   0.547458  1.000000   
34312       0.0       0.0       0.0       1.0       0.0  -0.659696  0.000000   
4802        1.0       0.0       0.0       0.0       0.0   0.262895  0.073612   
25895       0.0       0.0       0.0       1.0       0.0   1.151035  0.000000   
...         ...       ...       ...       ...       ...        ...       ...   
18045       0.0       0.0       0.0       1.0       0.0  -0.793202  0.000000   
5425        0.0       0.0       1.0       0.0       0.0   0.547458  1.000000   
12819       0.0       0.0       0.0       1.0       0.0   1.151035  1.000000   
33659       0.0       0.0       1.0       0.0       0.0   0.258362  0.000000   
19531       1.0       0.0       0.0       0.0       0.0  -0.821118  0.000000   

       PhysicalActivity  HealthInsurance   Alcohol  
28456          0.660578              0.0 -0.518600  
8993           0.000000              0.0  0.115329  
34312          0.000000              0.0  0.592213  
4802           1.012447              0.0 -0.103347  
25895          0.000000              0.0 -0.886483  
...                 ...              ...       ...  
18045          0.904383              0.0 -0.482716  
5425           1.598141              0.0  0.097790  
12819          1.598141              0.0  0.612947  
33659          1.162475              0.0 -0.154408  
19531          0.791302              0.0 -0.683278  

[13109 rows x 31 columns]
2025-12-03 09:46:38,356:INFO:get_config() successfully completed......................................
2025-12-03 09:46:38,409:INFO:Initializing get_config()
2025-12-03 09:46:38,409:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018F86ECEB30>, variable=y_test)
2025-12-03 09:46:38,409:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-12-03 09:46:38,409:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-12-03 09:46:38,415:INFO:Variable:  returned as 28456    0.0
8993     0.0
34312    0.0
4802     0.0
25895    0.0
        ... 
18045    0.0
5425     0.0
12819    0.0
33659    0.0
19531    0.0
Name: HeartDisease, Length: 13109, dtype: float32
2025-12-03 09:46:38,415:INFO:get_config() successfully completed......................................
2025-12-03 09:46:38,476:INFO:Initializing get_config()
2025-12-03 09:46:38,476:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018F86ECEB30>, variable=X_test_transformed)
2025-12-03 09:46:38,550:INFO:Variable: X_test returned as             Age  IncomeRatio  SystolicBP       BMI  WaistCircumference  \
28456 -0.477273    -0.304717   -0.519256 -0.987220           -0.923253   
8993   0.818182     0.253271    2.156910  0.770675            0.920394   
34312  0.704545     0.055403    0.519256  0.518044            0.662901   
4802  -0.545455     0.253730   -0.331933 -0.229036           -0.436352   
25895  0.704545     1.226781   -0.093200 -0.226100            0.012322   
...         ...          ...         ...       ...                 ...   
18045 -0.568182    -0.083104   -0.568713 -1.176693           -1.338674   
5425   0.590909     0.362732    2.210168  0.139096            0.292112   
12819  0.909091    -0.019787    0.899042  0.454886            0.971892   
33659 -0.522727     1.060572   -0.525683 -0.587220           -0.906087   
19531 -0.590909    -0.344290   -0.510287 -0.945114           -1.215078   

         Height  TotalCholesterol  Triglycerides       LDL       HDL  ...  \
28456 -1.080540         -0.078535      -0.470757 -0.026922  0.418008  ...   
8993  -0.279669          0.765897       0.705031  0.006026  0.446825  ...   
34312  0.559339         -0.123259       0.929511 -1.031826 -1.404309  ...   
4802  -0.504861         -0.188325      -0.322647  0.000015 -0.138743  ...   
25895  0.216731          0.892919       1.291109  0.008211 -0.255329  ...   
...         ...               ...            ...       ...       ...  ...   
18045 -2.080569         -0.340947      -0.470582 -0.848950  0.393794  ...   
5425   0.156785          0.435639      -0.065356  1.113733  0.127664  ...   
12819  1.194951         -0.732967      -0.470025 -0.211535 -1.085148  ...   
33659 -1.254274         -1.063225      -0.470958 -2.849419  0.127664  ...   
19531 -2.339052         -0.356898      -0.470595 -0.900608  0.393896  ...   

       Race_5.0  Race_1.0  Race_4.0  Race_3.0  Race_2.0  Education   Smoking  \
28456       1.0       0.0       0.0       0.0       0.0  -0.012820  0.000000   
8993        0.0       0.0       1.0       0.0       0.0   0.547458  1.000000   
34312       0.0       0.0       0.0       1.0       0.0  -0.659696  0.000000   
4802        1.0       0.0       0.0       0.0       0.0   0.262895  0.073612   
25895       0.0       0.0       0.0       1.0       0.0   1.151035  0.000000   
...         ...       ...       ...       ...       ...        ...       ...   
18045       0.0       0.0       0.0       1.0       0.0  -0.793202  0.000000   
5425        0.0       0.0       1.0       0.0       0.0   0.547458  1.000000   
12819       0.0       0.0       0.0       1.0       0.0   1.151035  1.000000   
33659       0.0       0.0       1.0       0.0       0.0   0.258362  0.000000   
19531       1.0       0.0       0.0       0.0       0.0  -0.821118  0.000000   

       PhysicalActivity  HealthInsurance   Alcohol  
28456          0.660578              0.0 -0.518600  
8993           0.000000              0.0  0.115329  
34312          0.000000              0.0  0.592213  
4802           1.012447              0.0 -0.103347  
25895          0.000000              0.0 -0.886483  
...                 ...              ...       ...  
18045          0.904383              0.0 -0.482716  
5425           1.598141              0.0  0.097790  
12819          1.598141              0.0  0.612947  
33659          1.162475              0.0 -0.154408  
19531          0.791302              0.0 -0.683278  

[13109 rows x 31 columns]
2025-12-03 09:46:38,550:INFO:get_config() successfully completed......................................
2025-12-03 09:46:38,578:INFO:Initializing get_config()
2025-12-03 09:46:38,578:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018F86ECEB30>, variable=y_test)
2025-12-03 09:46:38,578:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-12-03 09:46:38,578:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-12-03 09:46:38,582:INFO:Variable:  returned as 28456    0.0
8993     0.0
34312    0.0
4802     0.0
25895    0.0
        ... 
18045    0.0
5425     0.0
12819    0.0
33659    0.0
19531    0.0
Name: HeartDisease, Length: 13109, dtype: float32
2025-12-03 09:46:38,582:INFO:get_config() successfully completed......................................
2025-12-03 09:46:38,796:INFO:Initializing get_config()
2025-12-03 09:46:38,796:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018F86ECEB30>, variable=y_test)
2025-12-03 09:46:38,799:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-12-03 09:46:38,799:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-12-03 09:46:38,806:INFO:Variable:  returned as 28456    0.0
8993     0.0
34312    0.0
4802     0.0
25895    0.0
        ... 
18045    0.0
5425     0.0
12819    0.0
33659    0.0
19531    0.0
Name: HeartDisease, Length: 13109, dtype: float32
2025-12-03 09:46:38,806:INFO:get_config() successfully completed......................................
2025-12-03 09:46:38,806:INFO:Initializing get_config()
2025-12-03 09:46:38,806:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018F86ECEB30>, variable=X_test_transformed)
2025-12-03 09:46:38,878:INFO:Variable: X_test returned as             Age  IncomeRatio  SystolicBP       BMI  WaistCircumference  \
28456 -0.477273    -0.304717   -0.519256 -0.987220           -0.923253   
8993   0.818182     0.253271    2.156910  0.770675            0.920394   
34312  0.704545     0.055403    0.519256  0.518044            0.662901   
4802  -0.545455     0.253730   -0.331933 -0.229036           -0.436352   
25895  0.704545     1.226781   -0.093200 -0.226100            0.012322   
...         ...          ...         ...       ...                 ...   
18045 -0.568182    -0.083104   -0.568713 -1.176693           -1.338674   
5425   0.590909     0.362732    2.210168  0.139096            0.292112   
12819  0.909091    -0.019787    0.899042  0.454886            0.971892   
33659 -0.522727     1.060572   -0.525683 -0.587220           -0.906087   
19531 -0.590909    -0.344290   -0.510287 -0.945114           -1.215078   

         Height  TotalCholesterol  Triglycerides       LDL       HDL  ...  \
28456 -1.080540         -0.078535      -0.470757 -0.026922  0.418008  ...   
8993  -0.279669          0.765897       0.705031  0.006026  0.446825  ...   
34312  0.559339         -0.123259       0.929511 -1.031826 -1.404309  ...   
4802  -0.504861         -0.188325      -0.322647  0.000015 -0.138743  ...   
25895  0.216731          0.892919       1.291109  0.008211 -0.255329  ...   
...         ...               ...            ...       ...       ...  ...   
18045 -2.080569         -0.340947      -0.470582 -0.848950  0.393794  ...   
5425   0.156785          0.435639      -0.065356  1.113733  0.127664  ...   
12819  1.194951         -0.732967      -0.470025 -0.211535 -1.085148  ...   
33659 -1.254274         -1.063225      -0.470958 -2.849419  0.127664  ...   
19531 -2.339052         -0.356898      -0.470595 -0.900608  0.393896  ...   

       Race_5.0  Race_1.0  Race_4.0  Race_3.0  Race_2.0  Education   Smoking  \
28456       1.0       0.0       0.0       0.0       0.0  -0.012820  0.000000   
8993        0.0       0.0       1.0       0.0       0.0   0.547458  1.000000   
34312       0.0       0.0       0.0       1.0       0.0  -0.659696  0.000000   
4802        1.0       0.0       0.0       0.0       0.0   0.262895  0.073612   
25895       0.0       0.0       0.0       1.0       0.0   1.151035  0.000000   
...         ...       ...       ...       ...       ...        ...       ...   
18045       0.0       0.0       0.0       1.0       0.0  -0.793202  0.000000   
5425        0.0       0.0       1.0       0.0       0.0   0.547458  1.000000   
12819       0.0       0.0       0.0       1.0       0.0   1.151035  1.000000   
33659       0.0       0.0       1.0       0.0       0.0   0.258362  0.000000   
19531       1.0       0.0       0.0       0.0       0.0  -0.821118  0.000000   

       PhysicalActivity  HealthInsurance   Alcohol  
28456          0.660578              0.0 -0.518600  
8993           0.000000              0.0  0.115329  
34312          0.000000              0.0  0.592213  
4802           1.012447              0.0 -0.103347  
25895          0.000000              0.0 -0.886483  
...                 ...              ...       ...  
18045          0.904383              0.0 -0.482716  
5425           1.598141              0.0  0.097790  
12819          1.598141              0.0  0.612947  
33659          1.162475              0.0 -0.154408  
19531          0.791302              0.0 -0.683278  

[13109 rows x 31 columns]
2025-12-03 09:46:38,878:INFO:get_config() successfully completed......................................
2025-12-03 09:46:38,960:INFO:Initializing get_config()
2025-12-03 09:46:38,960:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018F86ECEB30>, variable=X_train_transformed)
2025-12-03 09:46:39,000:INFO:Variable: X_train returned as             Age  IncomeRatio  SystolicBP       BMI  WaistCircumference  \
15208  0.954545     0.854789    0.359485  0.518044            0.206281   
25325 -0.272727     0.253271   -0.812170 -0.966167           -0.799656   
5132   0.181818    -0.407608   -0.372799  0.054886            0.319578   
17217  0.500000    -0.751898    0.013314 -0.260904            0.278379   
6382   0.568182     0.054503    1.131712  2.675938            1.888566   
...         ...          ...         ...       ...                 ...   
6265  -0.545455    -0.431352   -0.591719  0.191728           -0.377368   
42694 -0.022727    -0.221612   -0.892056 -0.260904           -0.047778   
13399  0.454545     0.388518    0.377985  0.271482            0.183567   
39959  0.954545    -0.193911    0.625770  0.991728            1.160720   
6616   0.613636    -0.447182    0.652399 -0.871430           -0.514698   

         Height  TotalCholesterol  Triglycerides       LDL       HDL  ...  \
15208 -0.487303          0.625876       0.583394  0.005397  0.314564  ...   
25325 -0.300856          0.033588      -0.261476  0.000256  0.303682  ...   
5132   0.766972          0.181594       0.479279  0.948690 -1.340476  ...   
17217  0.745785          0.227516       0.346113  0.002441 -0.274561  ...   
6382   0.237295          0.867515       0.635574  0.002754  0.829819  ...   
...         ...               ...            ...       ...       ...  ...   
6265  -1.737339         -1.393483      -0.471046 -3.840886  0.063832  ...   
42694  0.000000          0.029167      -0.131730  0.000893  0.063832  ...   
13399 -0.147405          0.462357       0.380371  0.003925  0.256949  ...   
39959  0.368655          1.528031       1.934134  0.011744  0.191497  ...   
6616  -0.021187         -0.224877      -0.043571 -1.609476  0.510658  ...   

       Race_5.0  Race_1.0  Race_4.0  Race_3.0  Race_2.0  Education  Smoking  \
15208       1.0       0.0       0.0       0.0       0.0  -0.659696      0.0   
25325       0.0       1.0       0.0       0.0       0.0   0.185278      0.0   
5132        0.0       1.0       0.0       0.0       0.0  -0.659696      1.0   
17217       0.0       0.0       1.0       0.0       0.0  -0.056119      1.0   
6382        0.0       0.0       1.0       0.0       0.0   0.547458      1.0   
...         ...       ...       ...       ...       ...        ...      ...   
6265        0.0       1.0       0.0       0.0       0.0  -0.769055      0.0   
42694       0.0       1.0       0.0       0.0       0.0   0.547458      0.0   
13399       0.0       0.0       1.0       0.0       0.0   0.547458      0.0   
39959       0.0       0.0       0.0       1.0       0.0   0.547458      0.0   
6616        0.0       0.0       0.0       1.0       0.0   0.547458      1.0   

       PhysicalActivity  HealthInsurance   Alcohol  
15208          0.000000              0.0 -0.886483  
25325          0.000000              0.0  0.592213  
5132           0.000000             -1.0  0.312949  
17217          0.000000              0.0  0.592213  
6382           0.000000              0.0  0.597293  
...                 ...              ...       ...  
6265           0.662459              0.0 -0.501621  
42694          0.000000             -1.0  0.592213  
13399          0.000000              0.0 -0.224534  
39959          0.000000              0.0  0.592213  
6616           0.000000              0.0  0.290247  

[30586 rows x 31 columns]
2025-12-03 09:46:39,000:INFO:get_config() successfully completed......................................
2025-12-03 09:46:39,018:INFO:Initializing tune_model()
2025-12-03 09:46:39,019:INFO:tune_model(estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...), fold=None, round=4, n_iter=5, custom_grid=None, optimize=Recall, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=False, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018F86ECEB30>)
2025-12-03 09:46:39,019:INFO:Checking exceptions
2025-12-03 09:46:39,032:INFO:Copying training dataset
2025-12-03 09:46:39,044:INFO:Checking base model
2025-12-03 09:46:39,049:INFO:Base model : Extreme Gradient Boosting
2025-12-03 09:46:39,049:INFO:Declaring metric variables
2025-12-03 09:46:39,049:INFO:Defining Hyperparameters
2025-12-03 09:46:39,209:INFO:Tuning with n_jobs=1
2025-12-03 09:46:39,209:INFO:Initializing RandomizedSearchCV
2025-12-03 09:47:12,584:INFO:best_params: {'actual_estimator__subsample': 0.7, 'actual_estimator__scale_pos_weight': 38.0, 'actual_estimator__reg_lambda': 0.7, 'actual_estimator__reg_alpha': 0.001, 'actual_estimator__n_estimators': 60, 'actual_estimator__min_child_weight': 1, 'actual_estimator__max_depth': 6, 'actual_estimator__learning_rate': 0.4, 'actual_estimator__colsample_bytree': 0.7}
2025-12-03 09:47:12,584:INFO:Hyperparameter search completed
2025-12-03 09:47:12,584:INFO:SubProcess create_model() called ==================================
2025-12-03 09:47:12,584:INFO:Initializing create_model()
2025-12-03 09:47:12,584:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018F86ECEB30>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000018FB0061A80>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'subsample': 0.7, 'scale_pos_weight': 38.0, 'reg_lambda': 0.7, 'reg_alpha': 0.001, 'n_estimators': 60, 'min_child_weight': 1, 'max_depth': 6, 'learning_rate': 0.4, 'colsample_bytree': 0.7})
2025-12-03 09:47:12,584:INFO:Checking exceptions
2025-12-03 09:47:12,584:INFO:Importing libraries
2025-12-03 09:47:12,584:INFO:Copying training dataset
2025-12-03 09:47:12,606:INFO:Defining folds
2025-12-03 09:47:12,606:INFO:Declaring metric variables
2025-12-03 09:47:12,606:INFO:Importing untrained model
2025-12-03 09:47:12,606:INFO:Declaring custom model
2025-12-03 09:47:12,606:INFO:Extreme Gradient Boosting Imported successfully
2025-12-03 09:47:12,606:INFO:Starting cross validation
2025-12-03 09:47:12,608:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-12-03 09:47:17,220:INFO:Calculating mean and std
2025-12-03 09:47:17,220:INFO:Creating metrics dataframe
2025-12-03 09:47:17,223:INFO:Finalizing model
2025-12-03 09:47:17,288:INFO:Warning: No categorical columns found. Calling 'transform' will only return input data.
2025-12-03 09:47:17,670:INFO:Uploading results into container
2025-12-03 09:47:17,673:INFO:Uploading model into container now
2025-12-03 09:47:17,673:INFO:_master_model_container: 4
2025-12-03 09:47:17,673:INFO:_display_container: 5
2025-12-03 09:47:17,673:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=0.7, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=0.4, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=6, max_leaves=None,
              min_child_weight=1, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=60, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2025-12-03 09:47:17,673:INFO:create_model() successfully completed......................................
2025-12-03 09:47:17,850:INFO:SubProcess create_model() end ==================================
2025-12-03 09:47:17,850:INFO:choose_better activated
2025-12-03 09:47:17,852:INFO:SubProcess create_model() called ==================================
2025-12-03 09:47:17,852:INFO:Initializing create_model()
2025-12-03 09:47:17,852:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018F86ECEB30>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-03 09:47:17,852:INFO:Checking exceptions
2025-12-03 09:47:17,853:INFO:Importing libraries
2025-12-03 09:47:17,853:INFO:Copying training dataset
2025-12-03 09:47:17,873:INFO:Defining folds
2025-12-03 09:47:17,873:INFO:Declaring metric variables
2025-12-03 09:47:17,873:INFO:Importing untrained model
2025-12-03 09:47:17,873:INFO:Declaring custom model
2025-12-03 09:47:17,873:INFO:Extreme Gradient Boosting Imported successfully
2025-12-03 09:47:17,873:INFO:Starting cross validation
2025-12-03 09:47:17,875:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-12-03 09:47:23,686:INFO:Calculating mean and std
2025-12-03 09:47:23,686:INFO:Creating metrics dataframe
2025-12-03 09:47:23,687:INFO:Finalizing model
2025-12-03 09:47:23,752:INFO:Warning: No categorical columns found. Calling 'transform' will only return input data.
2025-12-03 09:47:24,256:INFO:Uploading results into container
2025-12-03 09:47:24,258:INFO:Uploading model into container now
2025-12-03 09:47:24,258:INFO:_master_model_container: 5
2025-12-03 09:47:24,258:INFO:_display_container: 6
2025-12-03 09:47:24,258:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2025-12-03 09:47:24,258:INFO:create_model() successfully completed......................................
2025-12-03 09:47:24,438:INFO:SubProcess create_model() end ==================================
2025-12-03 09:47:24,438:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...) result for Recall is 0.3112
2025-12-03 09:47:24,438:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=0.7, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=0.4, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=6, max_leaves=None,
              min_child_weight=1, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=60, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...) result for Recall is 0.3316
2025-12-03 09:47:24,441:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=0.7, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=0.4, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=6, max_leaves=None,
              min_child_weight=1, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=60, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...) is best model
2025-12-03 09:47:24,441:INFO:choose_better completed
2025-12-03 09:47:24,441:INFO:_master_model_container: 5
2025-12-03 09:47:24,441:INFO:_display_container: 5
2025-12-03 09:47:24,441:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=0.7, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=0.4, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=6, max_leaves=None,
              min_child_weight=1, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=60, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2025-12-03 09:47:24,441:INFO:tune_model() successfully completed......................................
2025-12-03 09:47:24,631:INFO:Initializing predict_model()
2025-12-03 09:47:24,631:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018F86ECEB30>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=0.7, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=0.4, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=6, max_leaves=None,
              min_child_weight=1, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=60, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...), probability_threshold=None, encoded_labels=False, raw_score=True, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000018FAFFF0940>)
2025-12-03 09:47:24,631:INFO:Checking exceptions
2025-12-03 09:47:24,631:INFO:Preloading libraries
2025-12-03 09:47:25,009:INFO:Initializing get_config()
2025-12-03 09:47:25,009:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018F86ECEB30>, variable=target_param)
2025-12-03 09:47:25,009:INFO:Variable:  returned as HeartDisease
2025-12-03 09:47:25,009:INFO:get_config() successfully completed......................................
2025-12-03 09:47:25,654:INFO:Initializing interpret_model()
2025-12-03 09:47:25,654:INFO:interpret_model(estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=0.7, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=0.4, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=6, max_leaves=None,
              min_child_weight=1, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=60, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...), use_train_data=False, X_new_sample=None, y_new_sample=None, feature=None, kwargs={}, observation=None, plot=summary, save=False, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018F86ECEB30>)
2025-12-03 09:47:25,654:INFO:Checking exceptions
2025-12-03 09:47:25,654:INFO:Soft dependency imported: shap: 0.49.1
2025-12-03 09:47:25,725:INFO:plot type: summary
2025-12-03 09:47:25,725:INFO:Creating TreeExplainer
2025-12-03 09:47:25,735:INFO:Compiling shap values
2025-12-03 09:47:29,034:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:4145: FutureWarning: The NumPy global RNG was seeded by calling `np.random.seed`. In a future version this function will no longer use the global RNG. Pass `rng` explicitly to opt-in to the new behaviour and silence this warning.

2025-12-03 09:47:30,175:INFO:Visual Rendered Successfully
2025-12-03 09:47:30,175:INFO:interpret_model() successfully completed......................................
2025-12-03 09:47:30,361:INFO:Initializing predict_model()
2025-12-03 09:47:30,361:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018F86ECEB30>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...), probability_threshold=None, encoded_labels=False, raw_score=True, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000018FA22B4E50>)
2025-12-03 09:47:30,361:INFO:Checking exceptions
2025-12-03 09:47:30,361:INFO:Preloading libraries
2025-12-03 09:47:30,759:INFO:Initializing get_config()
2025-12-03 09:47:30,759:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018F86ECEB30>, variable=target_param)
2025-12-03 09:47:30,759:INFO:Variable:  returned as HeartDisease
2025-12-03 09:47:30,759:INFO:get_config() successfully completed......................................
2025-12-03 09:47:30,870:INFO:Initializing finalize_model()
2025-12-03 09:47:30,870:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018F86ECEB30>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=0.7, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=0.4, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=6, max_leaves=None,
              min_child_weight=1, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=60, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2025-12-03 09:47:30,870:INFO:Finalizing XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=0.7, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=0.4, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=6, max_leaves=None,
              min_child_weight=1, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=60, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2025-12-03 09:47:30,888:INFO:Initializing create_model()
2025-12-03 09:47:30,888:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018F86ECEB30>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=0.7, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=0.4, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=6, max_leaves=None,
              min_child_weight=1, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=60, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2025-12-03 09:47:30,888:INFO:Checking exceptions
2025-12-03 09:47:30,888:INFO:Importing libraries
2025-12-03 09:47:30,888:INFO:Copying training dataset
2025-12-03 09:47:30,891:INFO:Defining folds
2025-12-03 09:47:30,892:INFO:Declaring metric variables
2025-12-03 09:47:30,892:INFO:Importing untrained model
2025-12-03 09:47:30,892:INFO:Declaring custom model
2025-12-03 09:47:30,892:INFO:Extreme Gradient Boosting Imported successfully
2025-12-03 09:47:30,894:INFO:Cross validation set to False
2025-12-03 09:47:30,895:INFO:Fitting Model
2025-12-03 09:47:30,980:INFO:Warning: No categorical columns found. Calling 'transform' will only return input data.
2025-12-03 09:47:31,500:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'IncomeRatio', 'SystolicBP',
                                             'BMI', 'WaistCircumference',
                                             'Height', 'TotalCholesterol',
                                             'Triglycerides', 'LDL', 'HDL',
                                             'HbA1c', 'Glucose', 'Creatinine',
                                             'UricAcid', 'ALT_Enzyme',
                                             'Albumin', 'Potassium', 'Sodium',
                                             'GGT_Enzyme', 'AST_Enzyme'],
                                    transformer=Si...
                               feature_types=None, gamma=None, grow_policy=None,
                               importance_type=None,
                               interaction_constraints=None, learning_rate=0.4,
                               max_bin=None, max_cat_threshold=None,
                               max_cat_to_onehot=None, max_delta_step=None,
                               max_depth=6, max_leaves=None, min_child_weight=1,
                               missing=nan, monotone_constraints=None,
                               multi_strategy=None, n_estimators=60, n_jobs=1,
                               num_parallel_tree=None,
                               objective='binary:logistic', ...))],
         verbose=False)
2025-12-03 09:47:31,502:INFO:create_model() successfully completed......................................
2025-12-03 09:47:31,673:INFO:_master_model_container: 5
2025-12-03 09:47:31,673:INFO:_display_container: 7
2025-12-03 09:47:31,688:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'IncomeRatio', 'SystolicBP',
                                             'BMI', 'WaistCircumference',
                                             'Height', 'TotalCholesterol',
                                             'Triglycerides', 'LDL', 'HDL',
                                             'HbA1c', 'Glucose', 'Creatinine',
                                             'UricAcid', 'ALT_Enzyme',
                                             'Albumin', 'Potassium', 'Sodium',
                                             'GGT_Enzyme', 'AST_Enzyme'],
                                    transformer=Si...
                               feature_types=None, gamma=None, grow_policy=None,
                               importance_type=None,
                               interaction_constraints=None, learning_rate=0.4,
                               max_bin=None, max_cat_threshold=None,
                               max_cat_to_onehot=None, max_delta_step=None,
                               max_depth=6, max_leaves=None, min_child_weight=1,
                               missing=nan, monotone_constraints=None,
                               multi_strategy=None, n_estimators=60, n_jobs=1,
                               num_parallel_tree=None,
                               objective='binary:logistic', ...))],
         verbose=False)
2025-12-03 09:47:31,688:INFO:finalize_model() successfully completed......................................
2025-12-03 09:47:31,883:INFO:Initializing save_model()
2025-12-03 09:47:31,883:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'IncomeRatio', 'SystolicBP',
                                             'BMI', 'WaistCircumference',
                                             'Height', 'TotalCholesterol',
                                             'Triglycerides', 'LDL', 'HDL',
                                             'HbA1c', 'Glucose', 'Creatinine',
                                             'UricAcid', 'ALT_Enzyme',
                                             'Albumin', 'Potassium', 'Sodium',
                                             'GGT_Enzyme', 'AST_Enzyme'],
                                    transformer=Si...
                               feature_types=None, gamma=None, grow_policy=None,
                               importance_type=None,
                               interaction_constraints=None, learning_rate=0.4,
                               max_bin=None, max_cat_threshold=None,
                               max_cat_to_onehot=None, max_delta_step=None,
                               max_depth=6, max_leaves=None, min_child_weight=1,
                               missing=nan, monotone_constraints=None,
                               multi_strategy=None, n_estimators=60, n_jobs=1,
                               num_parallel_tree=None,
                               objective='binary:logistic', ...))],
         verbose=False), model_name=../models\best_pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\OMAR\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'IncomeRatio', 'SystolicBP',
                                             'BMI', 'WaistCircumference',
                                             'Height', 'TotalCholesterol',
                                             'Triglycerides', 'LDL', 'HDL',
                                             'HbA1c', 'Glucose', 'Creatinine',
                                             'UricAcid', 'ALT_Enzyme',
                                             'Albumin', 'Potassium', 'Sodium',
                                             'G...
                                    transformer=TargetEncoder(cols=[],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=RobustScaler(copy=True,
                                                             quantile_range=(25.0,
                                                                             75.0),
                                                             unit_variance=False,
                                                             with_centering=True,
                                                             with_scaling=True)))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2025-12-03 09:47:31,883:INFO:Adding model into prep_pipe
2025-12-03 09:47:31,883:WARNING:Only Model saved as it was a pipeline.
2025-12-03 09:47:31,890:INFO:../models\best_pipeline.pkl saved in current working directory
2025-12-03 09:47:31,916:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'IncomeRatio', 'SystolicBP',
                                             'BMI', 'WaistCircumference',
                                             'Height', 'TotalCholesterol',
                                             'Triglycerides', 'LDL', 'HDL',
                                             'HbA1c', 'Glucose', 'Creatinine',
                                             'UricAcid', 'ALT_Enzyme',
                                             'Albumin', 'Potassium', 'Sodium',
                                             'GGT_Enzyme', 'AST_Enzyme'],
                                    transformer=Si...
                               feature_types=None, gamma=None, grow_policy=None,
                               importance_type=None,
                               interaction_constraints=None, learning_rate=0.4,
                               max_bin=None, max_cat_threshold=None,
                               max_cat_to_onehot=None, max_delta_step=None,
                               max_depth=6, max_leaves=None, min_child_weight=1,
                               missing=nan, monotone_constraints=None,
                               multi_strategy=None, n_estimators=60, n_jobs=1,
                               num_parallel_tree=None,
                               objective='binary:logistic', ...))],
         verbose=False)
2025-12-03 09:47:31,916:INFO:save_model() successfully completed......................................
2025-12-03 09:59:38,938:INFO:PyCaret ClassificationExperiment
2025-12-03 09:59:38,938:INFO:Logging name: clf-default-name
2025-12-03 09:59:38,938:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-12-03 09:59:38,938:INFO:version 3.3.2
2025-12-03 09:59:38,938:INFO:Initializing setup()
2025-12-03 09:59:38,938:INFO:self.USI: ed5f
2025-12-03 09:59:38,938:INFO:self._variable_keys: {'idx', 'html_param', '_available_plots', 'y_test', 'USI', 'target_param', 'memory', 'pipeline', 'n_jobs_param', 'X_test', 'seed', 'is_multiclass', 'gpu_param', 'logging_param', 'y_train', 'log_plots_param', 'X_train', 'gpu_n_jobs_param', 'fix_imbalance', 'exp_name_log', 'fold_shuffle_param', 'fold_groups_param', 'X', 'data', 'fold_generator', 'y', 'exp_id', '_ml_usecase'}
2025-12-03 09:59:38,938:INFO:Checking environment
2025-12-03 09:59:38,938:INFO:python_version: 3.10.19
2025-12-03 09:59:38,938:INFO:python_build: ('main', 'Oct 21 2025 16:41:31')
2025-12-03 09:59:38,938:INFO:machine: AMD64
2025-12-03 09:59:38,938:INFO:platform: Windows-10-10.0.26100-SP0
2025-12-03 09:59:38,938:INFO:Memory: svmem(total=16282144768, available=5349040128, percent=67.1, used=10933104640, free=5349040128)
2025-12-03 09:59:38,938:INFO:Physical Core: 6
2025-12-03 09:59:38,938:INFO:Logical Core: 12
2025-12-03 09:59:38,938:INFO:Checking libraries
2025-12-03 09:59:38,938:INFO:System:
2025-12-03 09:59:38,938:INFO:    python: 3.10.19 | packaged by Anaconda, Inc. | (main, Oct 21 2025, 16:41:31) [MSC v.1929 64 bit (AMD64)]
2025-12-03 09:59:38,939:INFO:executable: c:\Users\OMAR\miniconda3\envs\xgb_env\python.exe
2025-12-03 09:59:38,939:INFO:   machine: Windows-10-10.0.26100-SP0
2025-12-03 09:59:38,939:INFO:PyCaret required dependencies:
2025-12-03 09:59:38,939:INFO:                 pip: 25.3
2025-12-03 09:59:38,939:INFO:          setuptools: 80.9.0
2025-12-03 09:59:38,939:INFO:             pycaret: 3.3.2
2025-12-03 09:59:38,939:INFO:             IPython: 8.37.0
2025-12-03 09:59:38,939:INFO:          ipywidgets: 8.1.8
2025-12-03 09:59:38,939:INFO:                tqdm: 4.67.1
2025-12-03 09:59:38,939:INFO:               numpy: 1.26.4
2025-12-03 09:59:38,939:INFO:              pandas: 2.1.4
2025-12-03 09:59:38,939:INFO:              jinja2: 3.1.6
2025-12-03 09:59:38,939:INFO:               scipy: 1.11.4
2025-12-03 09:59:38,939:INFO:              joblib: 1.3.2
2025-12-03 09:59:38,939:INFO:             sklearn: 1.4.2
2025-12-03 09:59:38,939:INFO:                pyod: 2.0.5
2025-12-03 09:59:38,939:INFO:            imblearn: 0.14.0
2025-12-03 09:59:38,939:INFO:   category_encoders: 2.7.0
2025-12-03 09:59:38,939:INFO:            lightgbm: 4.6.0
2025-12-03 09:59:38,939:INFO:               numba: 0.62.1
2025-12-03 09:59:38,939:INFO:            requests: 2.32.5
2025-12-03 09:59:38,939:INFO:          matplotlib: 3.7.5
2025-12-03 09:59:38,939:INFO:          scikitplot: 0.3.7
2025-12-03 09:59:38,939:INFO:         yellowbrick: 1.5
2025-12-03 09:59:38,939:INFO:              plotly: 5.24.1
2025-12-03 09:59:38,939:INFO:    plotly-resampler: Not installed
2025-12-03 09:59:38,939:INFO:             kaleido: 1.2.0
2025-12-03 09:59:38,939:INFO:           schemdraw: 0.15
2025-12-03 09:59:38,939:INFO:         statsmodels: 0.14.5
2025-12-03 09:59:38,939:INFO:              sktime: 0.26.0
2025-12-03 09:59:38,939:INFO:               tbats: 1.1.3
2025-12-03 09:59:38,939:INFO:            pmdarima: 2.0.4
2025-12-03 09:59:38,939:INFO:              psutil: 7.1.3
2025-12-03 09:59:38,939:INFO:          markupsafe: 3.0.3
2025-12-03 09:59:38,939:INFO:             pickle5: Not installed
2025-12-03 09:59:38,939:INFO:         cloudpickle: 3.1.2
2025-12-03 09:59:38,939:INFO:         deprecation: 2.1.0
2025-12-03 09:59:38,939:INFO:              xxhash: 3.6.0
2025-12-03 09:59:38,939:INFO:           wurlitzer: Not installed
2025-12-03 09:59:38,939:INFO:PyCaret optional dependencies:
2025-12-03 09:59:38,940:INFO:                shap: 0.49.1
2025-12-03 09:59:38,940:INFO:           interpret: 0.7.3
2025-12-03 09:59:38,940:INFO:                umap: 0.5.7
2025-12-03 09:59:38,940:INFO:     ydata_profiling: 4.18.0
2025-12-03 09:59:38,940:INFO:  explainerdashboard: 0.5.1
2025-12-03 09:59:38,940:INFO:             autoviz: Not installed
2025-12-03 09:59:38,940:INFO:           fairlearn: 0.7.0
2025-12-03 09:59:38,940:INFO:          deepchecks: Not installed
2025-12-03 09:59:38,940:INFO:             xgboost: 2.1.3
2025-12-03 09:59:38,940:INFO:            catboost: 1.2.8
2025-12-03 09:59:38,940:INFO:              kmodes: 0.12.2
2025-12-03 09:59:38,940:INFO:             mlxtend: 0.23.4
2025-12-03 09:59:38,940:INFO:       statsforecast: 1.5.0
2025-12-03 09:59:38,940:INFO:        tune_sklearn: Not installed
2025-12-03 09:59:38,940:INFO:                 ray: Not installed
2025-12-03 09:59:38,940:INFO:            hyperopt: 0.2.7
2025-12-03 09:59:38,940:INFO:              optuna: 4.6.0
2025-12-03 09:59:38,940:INFO:               skopt: 0.10.2
2025-12-03 09:59:38,940:INFO:              mlflow: 3.6.0
2025-12-03 09:59:38,940:INFO:              gradio: 6.0.1
2025-12-03 09:59:38,940:INFO:             fastapi: 0.123.0
2025-12-03 09:59:38,940:INFO:             uvicorn: 0.38.0
2025-12-03 09:59:38,940:INFO:              m2cgen: 0.10.0
2025-12-03 09:59:38,940:INFO:           evidently: 0.4.40
2025-12-03 09:59:38,940:INFO:               fugue: 0.8.7
2025-12-03 09:59:38,940:INFO:           streamlit: 1.51.0
2025-12-03 09:59:38,940:INFO:             prophet: Not installed
2025-12-03 09:59:38,940:INFO:None
2025-12-03 09:59:38,940:INFO:Set up data.
2025-12-03 09:59:38,956:INFO:Set up folding strategy.
2025-12-03 09:59:38,956:INFO:Set up train/test split.
2025-12-03 09:59:38,982:INFO:Set up index.
2025-12-03 09:59:38,982:INFO:Assigning column types.
2025-12-03 09:59:39,000:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-12-03 09:59:39,026:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-12-03 09:59:39,027:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-03 09:59:39,044:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-03 09:59:39,044:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-03 09:59:39,069:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-12-03 09:59:39,069:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-03 09:59:39,088:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-03 09:59:39,091:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-03 09:59:39,091:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-12-03 09:59:39,120:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-03 09:59:39,137:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-03 09:59:39,140:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-03 09:59:39,170:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-03 09:59:39,188:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-03 09:59:39,188:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-03 09:59:39,188:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-12-03 09:59:39,230:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-03 09:59:39,231:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-03 09:59:39,273:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-03 09:59:39,276:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-03 09:59:39,277:INFO:Preparing preprocessing pipeline...
2025-12-03 09:59:39,282:INFO:Set up simple imputation.
2025-12-03 09:59:39,293:INFO:Set up encoding of ordinal features.
2025-12-03 09:59:39,300:INFO:Set up encoding of categorical features.
2025-12-03 09:59:39,301:INFO:Set up feature normalization.
2025-12-03 09:59:39,475:INFO:Finished creating preprocessing pipeline.
2025-12-03 09:59:39,489:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\OMAR\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'IncomeRatio', 'SystolicBP',
                                             'BMI', 'WaistCircumference',
                                             'Height', 'TotalCholesterol',
                                             'Triglycerides', 'LDL', 'HDL',
                                             'HbA1c', 'Glucose', 'Creatinine',
                                             'UricAcid', 'ALT_Enzyme',
                                             'Albumin', 'Potassium', 'Sodium',
                                             'G...
                                    transformer=TargetEncoder(cols=[],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=RobustScaler(copy=True,
                                                             quantile_range=(25.0,
                                                                             75.0),
                                                             unit_variance=False,
                                                             with_centering=True,
                                                             with_scaling=True)))],
         verbose=False)
2025-12-03 09:59:39,489:INFO:Creating final display dataframe.
2025-12-03 09:59:39,712:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target      HeartDisease
2                   Target type            Binary
3           Original data shape       (43695, 28)
4        Transformed data shape       (43695, 32)
5   Transformed train set shape       (30586, 32)
6    Transformed test set shape       (13109, 32)
7              Numeric features                20
8          Categorical features                 7
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15                    Normalize              True
16             Normalize method            robust
17               Fold Generator   StratifiedKFold
18                  Fold Number                10
19                     CPU Jobs                 1
20                      Use GPU             False
21               Log Experiment             False
22              Experiment Name  clf-default-name
23                          USI              ed5f
2025-12-03 09:59:39,763:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-03 09:59:39,764:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-03 09:59:39,815:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-03 09:59:39,817:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-03 09:59:39,819:INFO:setup() successfully completed in 0.89s...............
2025-12-03 09:59:39,865:INFO:Initializing get_config()
2025-12-03 09:59:39,865:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FAFF34DC0>, variable=y_train)
2025-12-03 09:59:39,865:INFO:Variable: 'y_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_train_transformed' instead.
2025-12-03 09:59:39,865:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_train_transformed' instead.

2025-12-03 09:59:39,876:INFO:Variable:  returned as 15208    0.0
25325    0.0
5132     0.0
17217    0.0
6382     0.0
        ... 
6265     0.0
42694    0.0
13399    0.0
39959    0.0
6616     0.0
Name: HeartDisease, Length: 30586, dtype: float32
2025-12-03 09:59:39,876:INFO:get_config() successfully completed......................................
2025-12-03 09:59:39,878:INFO:Initializing create_model()
2025-12-03 09:59:39,878:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FAFF34DC0>, estimator=xgboost, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={'scale_pos_weight': 76.32522407170295})
2025-12-03 09:59:39,878:INFO:Checking exceptions
2025-12-03 09:59:39,889:INFO:Importing libraries
2025-12-03 09:59:39,889:INFO:Copying training dataset
2025-12-03 09:59:39,915:INFO:Defining folds
2025-12-03 09:59:39,915:INFO:Declaring metric variables
2025-12-03 09:59:39,919:INFO:Importing untrained model
2025-12-03 09:59:39,921:INFO:Extreme Gradient Boosting Imported successfully
2025-12-03 09:59:39,925:INFO:Starting cross validation
2025-12-03 09:59:39,928:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-12-03 09:59:46,196:INFO:Calculating mean and std
2025-12-03 09:59:46,197:INFO:Creating metrics dataframe
2025-12-03 09:59:46,201:INFO:Finalizing model
2025-12-03 09:59:46,295:INFO:Warning: No categorical columns found. Calling 'transform' will only return input data.
2025-12-03 09:59:46,808:INFO:Uploading results into container
2025-12-03 09:59:46,808:INFO:Uploading model into container now
2025-12-03 09:59:46,817:INFO:_master_model_container: 1
2025-12-03 09:59:46,817:INFO:_display_container: 2
2025-12-03 09:59:46,817:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2025-12-03 09:59:46,818:INFO:create_model() successfully completed......................................
2025-12-03 09:59:47,017:INFO:Initializing create_model()
2025-12-03 09:59:47,017:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FAFF34DC0>, estimator=lr, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-03 09:59:47,017:INFO:Checking exceptions
2025-12-03 09:59:47,027:INFO:Importing libraries
2025-12-03 09:59:47,027:INFO:Copying training dataset
2025-12-03 09:59:47,058:INFO:Defining folds
2025-12-03 09:59:47,058:INFO:Declaring metric variables
2025-12-03 09:59:47,061:INFO:Importing untrained model
2025-12-03 09:59:47,063:INFO:Logistic Regression Imported successfully
2025-12-03 09:59:47,072:INFO:Starting cross validation
2025-12-03 09:59:47,075:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-12-03 09:59:47,968:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-12-03 09:59:48,531:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-12-03 09:59:48,891:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-12-03 09:59:48,894:INFO:Calculating mean and std
2025-12-03 09:59:48,894:INFO:Creating metrics dataframe
2025-12-03 09:59:48,901:INFO:Finalizing model
2025-12-03 09:59:48,978:INFO:Warning: No categorical columns found. Calling 'transform' will only return input data.
2025-12-03 09:59:49,085:INFO:Uploading results into container
2025-12-03 09:59:49,087:INFO:Uploading model into container now
2025-12-03 09:59:49,094:INFO:_master_model_container: 2
2025-12-03 09:59:49,094:INFO:_display_container: 3
2025-12-03 09:59:49,094:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-12-03 09:59:49,094:INFO:create_model() successfully completed......................................
2025-12-03 09:59:49,258:INFO:Initializing create_model()
2025-12-03 09:59:49,258:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FAFF34DC0>, estimator=rf, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-03 09:59:49,258:INFO:Checking exceptions
2025-12-03 09:59:49,273:INFO:Importing libraries
2025-12-03 09:59:49,273:INFO:Copying training dataset
2025-12-03 09:59:49,302:INFO:Defining folds
2025-12-03 09:59:49,302:INFO:Declaring metric variables
2025-12-03 09:59:49,305:INFO:Importing untrained model
2025-12-03 09:59:49,310:INFO:Random Forest Classifier Imported successfully
2025-12-03 09:59:49,315:INFO:Starting cross validation
2025-12-03 09:59:49,317:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-12-03 10:00:30,678:INFO:Calculating mean and std
2025-12-03 10:00:30,680:INFO:Creating metrics dataframe
2025-12-03 10:00:30,684:INFO:Finalizing model
2025-12-03 10:00:30,776:INFO:Warning: No categorical columns found. Calling 'transform' will only return input data.
2025-12-03 10:00:35,408:INFO:Uploading results into container
2025-12-03 10:00:35,413:INFO:Uploading model into container now
2025-12-03 10:00:35,425:INFO:_master_model_container: 3
2025-12-03 10:00:35,425:INFO:_display_container: 4
2025-12-03 10:00:35,426:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2025-12-03 10:00:35,426:INFO:create_model() successfully completed......................................
2025-12-03 10:00:35,653:INFO:Initializing get_config()
2025-12-03 10:00:35,653:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FAFF34DC0>, variable=X_train_transformed)
2025-12-03 10:00:35,700:INFO:Variable: X_train returned as             Age  IncomeRatio  SystolicBP       BMI  WaistCircumference  \
15208  0.954545     0.854789    0.359485  0.518044            0.206281   
25325 -0.272727     0.253271   -0.812170 -0.966167           -0.799656   
5132   0.181818    -0.407608   -0.372799  0.054886            0.319578   
17217  0.500000    -0.751898    0.013314 -0.260904            0.278379   
6382   0.568182     0.054503    1.131712  2.675938            1.888566   
...         ...          ...         ...       ...                 ...   
6265  -0.545455    -0.431352   -0.591719  0.191728           -0.377368   
42694 -0.022727    -0.221612   -0.892056 -0.260904           -0.047778   
13399  0.454545     0.388518    0.377985  0.271482            0.183567   
39959  0.954545    -0.193911    0.625770  0.991728            1.160720   
6616   0.613636    -0.447182    0.652399 -0.871430           -0.514698   

         Height  TotalCholesterol  Triglycerides       LDL       HDL  ...  \
15208 -0.487303          0.625876       0.583394  0.005397  0.314564  ...   
25325 -0.300856          0.033588      -0.261476  0.000256  0.303682  ...   
5132   0.766972          0.181594       0.479279  0.948690 -1.340476  ...   
17217  0.745785          0.227516       0.346113  0.002441 -0.274561  ...   
6382   0.237295          0.867515       0.635574  0.002754  0.829819  ...   
...         ...               ...            ...       ...       ...  ...   
6265  -1.737339         -1.393483      -0.471046 -3.840886  0.063832  ...   
42694  0.000000          0.029167      -0.131730  0.000893  0.063832  ...   
13399 -0.147405          0.462357       0.380371  0.003925  0.256949  ...   
39959  0.368655          1.528031       1.934134  0.011744  0.191497  ...   
6616  -0.021187         -0.224877      -0.043571 -1.609476  0.510658  ...   

       Race_5.0  Race_1.0  Race_4.0  Race_3.0  Race_2.0  Education  Smoking  \
15208       1.0       0.0       0.0       0.0       0.0  -0.659696      0.0   
25325       0.0       1.0       0.0       0.0       0.0   0.185278      0.0   
5132        0.0       1.0       0.0       0.0       0.0  -0.659696      1.0   
17217       0.0       0.0       1.0       0.0       0.0  -0.056119      1.0   
6382        0.0       0.0       1.0       0.0       0.0   0.547458      1.0   
...         ...       ...       ...       ...       ...        ...      ...   
6265        0.0       1.0       0.0       0.0       0.0  -0.769055      0.0   
42694       0.0       1.0       0.0       0.0       0.0   0.547458      0.0   
13399       0.0       0.0       1.0       0.0       0.0   0.547458      0.0   
39959       0.0       0.0       0.0       1.0       0.0   0.547458      0.0   
6616        0.0       0.0       0.0       1.0       0.0   0.547458      1.0   

       PhysicalActivity  HealthInsurance   Alcohol  
15208          0.000000              0.0 -0.886483  
25325          0.000000              0.0  0.592213  
5132           0.000000             -1.0  0.312949  
17217          0.000000              0.0  0.592213  
6382           0.000000              0.0  0.597293  
...                 ...              ...       ...  
6265           0.662459              0.0 -0.501621  
42694          0.000000             -1.0  0.592213  
13399          0.000000              0.0 -0.224534  
39959          0.000000              0.0  0.592213  
6616           0.000000              0.0  0.290247  

[30586 rows x 31 columns]
2025-12-03 10:00:35,700:INFO:get_config() successfully completed......................................
2025-12-03 10:00:35,700:INFO:Initializing get_config()
2025-12-03 10:00:35,700:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FAFF34DC0>, variable=y_train)
2025-12-03 10:00:35,700:INFO:Variable: 'y_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_train_transformed' instead.
2025-12-03 10:00:35,700:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_train_transformed' instead.

2025-12-03 10:00:35,708:INFO:Variable:  returned as 15208    0.0
25325    0.0
5132     0.0
17217    0.0
6382     0.0
        ... 
6265     0.0
42694    0.0
13399    0.0
39959    0.0
6616     0.0
Name: HeartDisease, Length: 30586, dtype: float32
2025-12-03 10:00:35,708:INFO:get_config() successfully completed......................................
2025-12-03 10:00:35,708:INFO:Initializing get_config()
2025-12-03 10:00:35,708:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FAFF34DC0>, variable=X_test_transformed)
2025-12-03 10:00:35,784:INFO:Variable: X_test returned as             Age  IncomeRatio  SystolicBP       BMI  WaistCircumference  \
28456 -0.477273    -0.304717   -0.519256 -0.987220           -0.923253   
8993   0.818182     0.253271    2.156910  0.770675            0.920394   
34312  0.704545     0.055403    0.519256  0.518044            0.662901   
4802  -0.545455     0.253730   -0.331933 -0.229036           -0.436352   
25895  0.704545     1.226781   -0.093200 -0.226100            0.012322   
...         ...          ...         ...       ...                 ...   
18045 -0.568182    -0.083104   -0.568713 -1.176693           -1.338674   
5425   0.590909     0.362732    2.210168  0.139096            0.292112   
12819  0.909091    -0.019787    0.899042  0.454886            0.971892   
33659 -0.522727     1.060572   -0.525683 -0.587220           -0.906087   
19531 -0.590909    -0.344290   -0.510287 -0.945114           -1.215078   

         Height  TotalCholesterol  Triglycerides       LDL       HDL  ...  \
28456 -1.080540         -0.078535      -0.470757 -0.026922  0.418008  ...   
8993  -0.279669          0.765897       0.705031  0.006026  0.446825  ...   
34312  0.559339         -0.123259       0.929511 -1.031826 -1.404309  ...   
4802  -0.504861         -0.188325      -0.322647  0.000015 -0.138743  ...   
25895  0.216731          0.892919       1.291109  0.008211 -0.255329  ...   
...         ...               ...            ...       ...       ...  ...   
18045 -2.080569         -0.340947      -0.470582 -0.848950  0.393794  ...   
5425   0.156785          0.435639      -0.065356  1.113733  0.127664  ...   
12819  1.194951         -0.732967      -0.470025 -0.211535 -1.085148  ...   
33659 -1.254274         -1.063225      -0.470958 -2.849419  0.127664  ...   
19531 -2.339052         -0.356898      -0.470595 -0.900608  0.393896  ...   

       Race_5.0  Race_1.0  Race_4.0  Race_3.0  Race_2.0  Education   Smoking  \
28456       1.0       0.0       0.0       0.0       0.0  -0.012820  0.000000   
8993        0.0       0.0       1.0       0.0       0.0   0.547458  1.000000   
34312       0.0       0.0       0.0       1.0       0.0  -0.659696  0.000000   
4802        1.0       0.0       0.0       0.0       0.0   0.262895  0.073612   
25895       0.0       0.0       0.0       1.0       0.0   1.151035  0.000000   
...         ...       ...       ...       ...       ...        ...       ...   
18045       0.0       0.0       0.0       1.0       0.0  -0.793202  0.000000   
5425        0.0       0.0       1.0       0.0       0.0   0.547458  1.000000   
12819       0.0       0.0       0.0       1.0       0.0   1.151035  1.000000   
33659       0.0       0.0       1.0       0.0       0.0   0.258362  0.000000   
19531       1.0       0.0       0.0       0.0       0.0  -0.821118  0.000000   

       PhysicalActivity  HealthInsurance   Alcohol  
28456          0.660578              0.0 -0.518600  
8993           0.000000              0.0  0.115329  
34312          0.000000              0.0  0.592213  
4802           1.012447              0.0 -0.103347  
25895          0.000000              0.0 -0.886483  
...                 ...              ...       ...  
18045          0.904383              0.0 -0.482716  
5425           1.598141              0.0  0.097790  
12819          1.598141              0.0  0.612947  
33659          1.162475              0.0 -0.154408  
19531          0.791302              0.0 -0.683278  

[13109 rows x 31 columns]
2025-12-03 10:00:35,784:INFO:get_config() successfully completed......................................
2025-12-03 10:00:35,784:INFO:Initializing get_config()
2025-12-03 10:00:35,784:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FAFF34DC0>, variable=y_test)
2025-12-03 10:00:35,784:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-12-03 10:00:35,784:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-12-03 10:00:35,788:INFO:Variable:  returned as 28456    0.0
8993     0.0
34312    0.0
4802     0.0
25895    0.0
        ... 
18045    0.0
5425     0.0
12819    0.0
33659    0.0
19531    0.0
Name: HeartDisease, Length: 13109, dtype: float32
2025-12-03 10:00:35,788:INFO:get_config() successfully completed......................................
2025-12-03 10:00:35,950:INFO:Initializing get_config()
2025-12-03 10:00:35,950:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FAFF34DC0>, variable=X_train_transformed)
2025-12-03 10:00:35,994:INFO:Variable: X_train returned as             Age  IncomeRatio  SystolicBP       BMI  WaistCircumference  \
15208  0.954545     0.854789    0.359485  0.518044            0.206281   
25325 -0.272727     0.253271   -0.812170 -0.966167           -0.799656   
5132   0.181818    -0.407608   -0.372799  0.054886            0.319578   
17217  0.500000    -0.751898    0.013314 -0.260904            0.278379   
6382   0.568182     0.054503    1.131712  2.675938            1.888566   
...         ...          ...         ...       ...                 ...   
6265  -0.545455    -0.431352   -0.591719  0.191728           -0.377368   
42694 -0.022727    -0.221612   -0.892056 -0.260904           -0.047778   
13399  0.454545     0.388518    0.377985  0.271482            0.183567   
39959  0.954545    -0.193911    0.625770  0.991728            1.160720   
6616   0.613636    -0.447182    0.652399 -0.871430           -0.514698   

         Height  TotalCholesterol  Triglycerides       LDL       HDL  ...  \
15208 -0.487303          0.625876       0.583394  0.005397  0.314564  ...   
25325 -0.300856          0.033588      -0.261476  0.000256  0.303682  ...   
5132   0.766972          0.181594       0.479279  0.948690 -1.340476  ...   
17217  0.745785          0.227516       0.346113  0.002441 -0.274561  ...   
6382   0.237295          0.867515       0.635574  0.002754  0.829819  ...   
...         ...               ...            ...       ...       ...  ...   
6265  -1.737339         -1.393483      -0.471046 -3.840886  0.063832  ...   
42694  0.000000          0.029167      -0.131730  0.000893  0.063832  ...   
13399 -0.147405          0.462357       0.380371  0.003925  0.256949  ...   
39959  0.368655          1.528031       1.934134  0.011744  0.191497  ...   
6616  -0.021187         -0.224877      -0.043571 -1.609476  0.510658  ...   

       Race_5.0  Race_1.0  Race_4.0  Race_3.0  Race_2.0  Education  Smoking  \
15208       1.0       0.0       0.0       0.0       0.0  -0.659696      0.0   
25325       0.0       1.0       0.0       0.0       0.0   0.185278      0.0   
5132        0.0       1.0       0.0       0.0       0.0  -0.659696      1.0   
17217       0.0       0.0       1.0       0.0       0.0  -0.056119      1.0   
6382        0.0       0.0       1.0       0.0       0.0   0.547458      1.0   
...         ...       ...       ...       ...       ...        ...      ...   
6265        0.0       1.0       0.0       0.0       0.0  -0.769055      0.0   
42694       0.0       1.0       0.0       0.0       0.0   0.547458      0.0   
13399       0.0       0.0       1.0       0.0       0.0   0.547458      0.0   
39959       0.0       0.0       0.0       1.0       0.0   0.547458      0.0   
6616        0.0       0.0       0.0       1.0       0.0   0.547458      1.0   

       PhysicalActivity  HealthInsurance   Alcohol  
15208          0.000000              0.0 -0.886483  
25325          0.000000              0.0  0.592213  
5132           0.000000             -1.0  0.312949  
17217          0.000000              0.0  0.592213  
6382           0.000000              0.0  0.597293  
...                 ...              ...       ...  
6265           0.662459              0.0 -0.501621  
42694          0.000000             -1.0  0.592213  
13399          0.000000              0.0 -0.224534  
39959          0.000000              0.0  0.592213  
6616           0.000000              0.0  0.290247  

[30586 rows x 31 columns]
2025-12-03 10:00:35,994:INFO:get_config() successfully completed......................................
2025-12-03 10:00:35,994:INFO:Initializing get_config()
2025-12-03 10:00:35,994:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FAFF34DC0>, variable=y_train)
2025-12-03 10:00:35,994:INFO:Variable: 'y_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_train_transformed' instead.
2025-12-03 10:00:35,994:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_train_transformed' instead.

2025-12-03 10:00:36,005:INFO:Variable:  returned as 15208    0.0
25325    0.0
5132     0.0
17217    0.0
6382     0.0
        ... 
6265     0.0
42694    0.0
13399    0.0
39959    0.0
6616     0.0
Name: HeartDisease, Length: 30586, dtype: float32
2025-12-03 10:00:36,005:INFO:get_config() successfully completed......................................
2025-12-03 10:00:36,006:INFO:Initializing get_config()
2025-12-03 10:00:36,006:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FAFF34DC0>, variable=X_test_transformed)
2025-12-03 10:00:36,076:INFO:Variable: X_test returned as             Age  IncomeRatio  SystolicBP       BMI  WaistCircumference  \
28456 -0.477273    -0.304717   -0.519256 -0.987220           -0.923253   
8993   0.818182     0.253271    2.156910  0.770675            0.920394   
34312  0.704545     0.055403    0.519256  0.518044            0.662901   
4802  -0.545455     0.253730   -0.331933 -0.229036           -0.436352   
25895  0.704545     1.226781   -0.093200 -0.226100            0.012322   
...         ...          ...         ...       ...                 ...   
18045 -0.568182    -0.083104   -0.568713 -1.176693           -1.338674   
5425   0.590909     0.362732    2.210168  0.139096            0.292112   
12819  0.909091    -0.019787    0.899042  0.454886            0.971892   
33659 -0.522727     1.060572   -0.525683 -0.587220           -0.906087   
19531 -0.590909    -0.344290   -0.510287 -0.945114           -1.215078   

         Height  TotalCholesterol  Triglycerides       LDL       HDL  ...  \
28456 -1.080540         -0.078535      -0.470757 -0.026922  0.418008  ...   
8993  -0.279669          0.765897       0.705031  0.006026  0.446825  ...   
34312  0.559339         -0.123259       0.929511 -1.031826 -1.404309  ...   
4802  -0.504861         -0.188325      -0.322647  0.000015 -0.138743  ...   
25895  0.216731          0.892919       1.291109  0.008211 -0.255329  ...   
...         ...               ...            ...       ...       ...  ...   
18045 -2.080569         -0.340947      -0.470582 -0.848950  0.393794  ...   
5425   0.156785          0.435639      -0.065356  1.113733  0.127664  ...   
12819  1.194951         -0.732967      -0.470025 -0.211535 -1.085148  ...   
33659 -1.254274         -1.063225      -0.470958 -2.849419  0.127664  ...   
19531 -2.339052         -0.356898      -0.470595 -0.900608  0.393896  ...   

       Race_5.0  Race_1.0  Race_4.0  Race_3.0  Race_2.0  Education   Smoking  \
28456       1.0       0.0       0.0       0.0       0.0  -0.012820  0.000000   
8993        0.0       0.0       1.0       0.0       0.0   0.547458  1.000000   
34312       0.0       0.0       0.0       1.0       0.0  -0.659696  0.000000   
4802        1.0       0.0       0.0       0.0       0.0   0.262895  0.073612   
25895       0.0       0.0       0.0       1.0       0.0   1.151035  0.000000   
...         ...       ...       ...       ...       ...        ...       ...   
18045       0.0       0.0       0.0       1.0       0.0  -0.793202  0.000000   
5425        0.0       0.0       1.0       0.0       0.0   0.547458  1.000000   
12819       0.0       0.0       0.0       1.0       0.0   1.151035  1.000000   
33659       0.0       0.0       1.0       0.0       0.0   0.258362  0.000000   
19531       1.0       0.0       0.0       0.0       0.0  -0.821118  0.000000   

       PhysicalActivity  HealthInsurance   Alcohol  
28456          0.660578              0.0 -0.518600  
8993           0.000000              0.0  0.115329  
34312          0.000000              0.0  0.592213  
4802           1.012447              0.0 -0.103347  
25895          0.000000              0.0 -0.886483  
...                 ...              ...       ...  
18045          0.904383              0.0 -0.482716  
5425           1.598141              0.0  0.097790  
12819          1.598141              0.0  0.612947  
33659          1.162475              0.0 -0.154408  
19531          0.791302              0.0 -0.683278  

[13109 rows x 31 columns]
2025-12-03 10:00:36,078:INFO:get_config() successfully completed......................................
2025-12-03 10:00:36,078:INFO:Initializing get_config()
2025-12-03 10:00:36,078:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FAFF34DC0>, variable=y_test)
2025-12-03 10:00:36,078:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-12-03 10:00:36,078:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-12-03 10:00:36,082:INFO:Variable:  returned as 28456    0.0
8993     0.0
34312    0.0
4802     0.0
25895    0.0
        ... 
18045    0.0
5425     0.0
12819    0.0
33659    0.0
19531    0.0
Name: HeartDisease, Length: 13109, dtype: float32
2025-12-03 10:00:36,082:INFO:get_config() successfully completed......................................
2025-12-03 10:00:36,208:INFO:Initializing get_config()
2025-12-03 10:00:36,208:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FAFF34DC0>, variable=X_test_transformed)
2025-12-03 10:00:36,291:INFO:Variable: X_test returned as             Age  IncomeRatio  SystolicBP       BMI  WaistCircumference  \
28456 -0.477273    -0.304717   -0.519256 -0.987220           -0.923253   
8993   0.818182     0.253271    2.156910  0.770675            0.920394   
34312  0.704545     0.055403    0.519256  0.518044            0.662901   
4802  -0.545455     0.253730   -0.331933 -0.229036           -0.436352   
25895  0.704545     1.226781   -0.093200 -0.226100            0.012322   
...         ...          ...         ...       ...                 ...   
18045 -0.568182    -0.083104   -0.568713 -1.176693           -1.338674   
5425   0.590909     0.362732    2.210168  0.139096            0.292112   
12819  0.909091    -0.019787    0.899042  0.454886            0.971892   
33659 -0.522727     1.060572   -0.525683 -0.587220           -0.906087   
19531 -0.590909    -0.344290   -0.510287 -0.945114           -1.215078   

         Height  TotalCholesterol  Triglycerides       LDL       HDL  ...  \
28456 -1.080540         -0.078535      -0.470757 -0.026922  0.418008  ...   
8993  -0.279669          0.765897       0.705031  0.006026  0.446825  ...   
34312  0.559339         -0.123259       0.929511 -1.031826 -1.404309  ...   
4802  -0.504861         -0.188325      -0.322647  0.000015 -0.138743  ...   
25895  0.216731          0.892919       1.291109  0.008211 -0.255329  ...   
...         ...               ...            ...       ...       ...  ...   
18045 -2.080569         -0.340947      -0.470582 -0.848950  0.393794  ...   
5425   0.156785          0.435639      -0.065356  1.113733  0.127664  ...   
12819  1.194951         -0.732967      -0.470025 -0.211535 -1.085148  ...   
33659 -1.254274         -1.063225      -0.470958 -2.849419  0.127664  ...   
19531 -2.339052         -0.356898      -0.470595 -0.900608  0.393896  ...   

       Race_5.0  Race_1.0  Race_4.0  Race_3.0  Race_2.0  Education   Smoking  \
28456       1.0       0.0       0.0       0.0       0.0  -0.012820  0.000000   
8993        0.0       0.0       1.0       0.0       0.0   0.547458  1.000000   
34312       0.0       0.0       0.0       1.0       0.0  -0.659696  0.000000   
4802        1.0       0.0       0.0       0.0       0.0   0.262895  0.073612   
25895       0.0       0.0       0.0       1.0       0.0   1.151035  0.000000   
...         ...       ...       ...       ...       ...        ...       ...   
18045       0.0       0.0       0.0       1.0       0.0  -0.793202  0.000000   
5425        0.0       0.0       1.0       0.0       0.0   0.547458  1.000000   
12819       0.0       0.0       0.0       1.0       0.0   1.151035  1.000000   
33659       0.0       0.0       1.0       0.0       0.0   0.258362  0.000000   
19531       1.0       0.0       0.0       0.0       0.0  -0.821118  0.000000   

       PhysicalActivity  HealthInsurance   Alcohol  
28456          0.660578              0.0 -0.518600  
8993           0.000000              0.0  0.115329  
34312          0.000000              0.0  0.592213  
4802           1.012447              0.0 -0.103347  
25895          0.000000              0.0 -0.886483  
...                 ...              ...       ...  
18045          0.904383              0.0 -0.482716  
5425           1.598141              0.0  0.097790  
12819          1.598141              0.0  0.612947  
33659          1.162475              0.0 -0.154408  
19531          0.791302              0.0 -0.683278  

[13109 rows x 31 columns]
2025-12-03 10:00:36,292:INFO:get_config() successfully completed......................................
2025-12-03 10:00:36,318:INFO:Initializing get_config()
2025-12-03 10:00:36,318:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FAFF34DC0>, variable=y_test)
2025-12-03 10:00:36,318:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-12-03 10:00:36,318:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-12-03 10:00:36,323:INFO:Variable:  returned as 28456    0.0
8993     0.0
34312    0.0
4802     0.0
25895    0.0
        ... 
18045    0.0
5425     0.0
12819    0.0
33659    0.0
19531    0.0
Name: HeartDisease, Length: 13109, dtype: float32
2025-12-03 10:00:36,323:INFO:get_config() successfully completed......................................
2025-12-03 10:00:36,326:INFO:Initializing get_config()
2025-12-03 10:00:36,326:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FAFF34DC0>, variable=y_test)
2025-12-03 10:00:36,326:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-12-03 10:00:36,326:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-12-03 10:00:36,330:INFO:Variable:  returned as 28456    0.0
8993     0.0
34312    0.0
4802     0.0
25895    0.0
        ... 
18045    0.0
5425     0.0
12819    0.0
33659    0.0
19531    0.0
Name: HeartDisease, Length: 13109, dtype: float32
2025-12-03 10:00:36,330:INFO:get_config() successfully completed......................................
2025-12-03 10:00:36,332:INFO:Initializing get_config()
2025-12-03 10:00:36,332:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FAFF34DC0>, variable=X_test_transformed)
2025-12-03 10:00:36,403:INFO:Variable: X_test returned as             Age  IncomeRatio  SystolicBP       BMI  WaistCircumference  \
28456 -0.477273    -0.304717   -0.519256 -0.987220           -0.923253   
8993   0.818182     0.253271    2.156910  0.770675            0.920394   
34312  0.704545     0.055403    0.519256  0.518044            0.662901   
4802  -0.545455     0.253730   -0.331933 -0.229036           -0.436352   
25895  0.704545     1.226781   -0.093200 -0.226100            0.012322   
...         ...          ...         ...       ...                 ...   
18045 -0.568182    -0.083104   -0.568713 -1.176693           -1.338674   
5425   0.590909     0.362732    2.210168  0.139096            0.292112   
12819  0.909091    -0.019787    0.899042  0.454886            0.971892   
33659 -0.522727     1.060572   -0.525683 -0.587220           -0.906087   
19531 -0.590909    -0.344290   -0.510287 -0.945114           -1.215078   

         Height  TotalCholesterol  Triglycerides       LDL       HDL  ...  \
28456 -1.080540         -0.078535      -0.470757 -0.026922  0.418008  ...   
8993  -0.279669          0.765897       0.705031  0.006026  0.446825  ...   
34312  0.559339         -0.123259       0.929511 -1.031826 -1.404309  ...   
4802  -0.504861         -0.188325      -0.322647  0.000015 -0.138743  ...   
25895  0.216731          0.892919       1.291109  0.008211 -0.255329  ...   
...         ...               ...            ...       ...       ...  ...   
18045 -2.080569         -0.340947      -0.470582 -0.848950  0.393794  ...   
5425   0.156785          0.435639      -0.065356  1.113733  0.127664  ...   
12819  1.194951         -0.732967      -0.470025 -0.211535 -1.085148  ...   
33659 -1.254274         -1.063225      -0.470958 -2.849419  0.127664  ...   
19531 -2.339052         -0.356898      -0.470595 -0.900608  0.393896  ...   

       Race_5.0  Race_1.0  Race_4.0  Race_3.0  Race_2.0  Education   Smoking  \
28456       1.0       0.0       0.0       0.0       0.0  -0.012820  0.000000   
8993        0.0       0.0       1.0       0.0       0.0   0.547458  1.000000   
34312       0.0       0.0       0.0       1.0       0.0  -0.659696  0.000000   
4802        1.0       0.0       0.0       0.0       0.0   0.262895  0.073612   
25895       0.0       0.0       0.0       1.0       0.0   1.151035  0.000000   
...         ...       ...       ...       ...       ...        ...       ...   
18045       0.0       0.0       0.0       1.0       0.0  -0.793202  0.000000   
5425        0.0       0.0       1.0       0.0       0.0   0.547458  1.000000   
12819       0.0       0.0       0.0       1.0       0.0   1.151035  1.000000   
33659       0.0       0.0       1.0       0.0       0.0   0.258362  0.000000   
19531       1.0       0.0       0.0       0.0       0.0  -0.821118  0.000000   

       PhysicalActivity  HealthInsurance   Alcohol  
28456          0.660578              0.0 -0.518600  
8993           0.000000              0.0  0.115329  
34312          0.000000              0.0  0.592213  
4802           1.012447              0.0 -0.103347  
25895          0.000000              0.0 -0.886483  
...                 ...              ...       ...  
18045          0.904383              0.0 -0.482716  
5425           1.598141              0.0  0.097790  
12819          1.598141              0.0  0.612947  
33659          1.162475              0.0 -0.154408  
19531          0.791302              0.0 -0.683278  

[13109 rows x 31 columns]
2025-12-03 10:00:36,403:INFO:get_config() successfully completed......................................
2025-12-03 10:00:36,404:INFO:Initializing get_config()
2025-12-03 10:00:36,404:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FAFF34DC0>, variable=y_test)
2025-12-03 10:00:36,404:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-12-03 10:00:36,404:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-12-03 10:00:36,410:INFO:Variable:  returned as 28456    0.0
8993     0.0
34312    0.0
4802     0.0
25895    0.0
        ... 
18045    0.0
5425     0.0
12819    0.0
33659    0.0
19531    0.0
Name: HeartDisease, Length: 13109, dtype: float32
2025-12-03 10:00:36,410:INFO:get_config() successfully completed......................................
2025-12-03 10:00:36,413:INFO:Initializing get_config()
2025-12-03 10:00:36,413:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FAFF34DC0>, variable=y_test)
2025-12-03 10:00:36,414:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-12-03 10:00:36,414:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-12-03 10:00:36,418:INFO:Variable:  returned as 28456    0.0
8993     0.0
34312    0.0
4802     0.0
25895    0.0
        ... 
18045    0.0
5425     0.0
12819    0.0
33659    0.0
19531    0.0
Name: HeartDisease, Length: 13109, dtype: float32
2025-12-03 10:00:36,418:INFO:get_config() successfully completed......................................
2025-12-03 10:00:36,420:INFO:Initializing get_config()
2025-12-03 10:00:36,420:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FAFF34DC0>, variable=X_test_transformed)
2025-12-03 10:00:36,502:INFO:Variable: X_test returned as             Age  IncomeRatio  SystolicBP       BMI  WaistCircumference  \
28456 -0.477273    -0.304717   -0.519256 -0.987220           -0.923253   
8993   0.818182     0.253271    2.156910  0.770675            0.920394   
34312  0.704545     0.055403    0.519256  0.518044            0.662901   
4802  -0.545455     0.253730   -0.331933 -0.229036           -0.436352   
25895  0.704545     1.226781   -0.093200 -0.226100            0.012322   
...         ...          ...         ...       ...                 ...   
18045 -0.568182    -0.083104   -0.568713 -1.176693           -1.338674   
5425   0.590909     0.362732    2.210168  0.139096            0.292112   
12819  0.909091    -0.019787    0.899042  0.454886            0.971892   
33659 -0.522727     1.060572   -0.525683 -0.587220           -0.906087   
19531 -0.590909    -0.344290   -0.510287 -0.945114           -1.215078   

         Height  TotalCholesterol  Triglycerides       LDL       HDL  ...  \
28456 -1.080540         -0.078535      -0.470757 -0.026922  0.418008  ...   
8993  -0.279669          0.765897       0.705031  0.006026  0.446825  ...   
34312  0.559339         -0.123259       0.929511 -1.031826 -1.404309  ...   
4802  -0.504861         -0.188325      -0.322647  0.000015 -0.138743  ...   
25895  0.216731          0.892919       1.291109  0.008211 -0.255329  ...   
...         ...               ...            ...       ...       ...  ...   
18045 -2.080569         -0.340947      -0.470582 -0.848950  0.393794  ...   
5425   0.156785          0.435639      -0.065356  1.113733  0.127664  ...   
12819  1.194951         -0.732967      -0.470025 -0.211535 -1.085148  ...   
33659 -1.254274         -1.063225      -0.470958 -2.849419  0.127664  ...   
19531 -2.339052         -0.356898      -0.470595 -0.900608  0.393896  ...   

       Race_5.0  Race_1.0  Race_4.0  Race_3.0  Race_2.0  Education   Smoking  \
28456       1.0       0.0       0.0       0.0       0.0  -0.012820  0.000000   
8993        0.0       0.0       1.0       0.0       0.0   0.547458  1.000000   
34312       0.0       0.0       0.0       1.0       0.0  -0.659696  0.000000   
4802        1.0       0.0       0.0       0.0       0.0   0.262895  0.073612   
25895       0.0       0.0       0.0       1.0       0.0   1.151035  0.000000   
...         ...       ...       ...       ...       ...        ...       ...   
18045       0.0       0.0       0.0       1.0       0.0  -0.793202  0.000000   
5425        0.0       0.0       1.0       0.0       0.0   0.547458  1.000000   
12819       0.0       0.0       0.0       1.0       0.0   1.151035  1.000000   
33659       0.0       0.0       1.0       0.0       0.0   0.258362  0.000000   
19531       1.0       0.0       0.0       0.0       0.0  -0.821118  0.000000   

       PhysicalActivity  HealthInsurance   Alcohol  
28456          0.660578              0.0 -0.518600  
8993           0.000000              0.0  0.115329  
34312          0.000000              0.0  0.592213  
4802           1.012447              0.0 -0.103347  
25895          0.000000              0.0 -0.886483  
...                 ...              ...       ...  
18045          0.904383              0.0 -0.482716  
5425           1.598141              0.0  0.097790  
12819          1.598141              0.0  0.612947  
33659          1.162475              0.0 -0.154408  
19531          0.791302              0.0 -0.683278  

[13109 rows x 31 columns]
2025-12-03 10:00:36,502:INFO:get_config() successfully completed......................................
2025-12-03 10:00:36,556:INFO:Initializing get_config()
2025-12-03 10:00:36,556:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FAFF34DC0>, variable=y_test)
2025-12-03 10:00:36,558:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-12-03 10:00:36,558:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-12-03 10:00:36,562:INFO:Variable:  returned as 28456    0.0
8993     0.0
34312    0.0
4802     0.0
25895    0.0
        ... 
18045    0.0
5425     0.0
12819    0.0
33659    0.0
19531    0.0
Name: HeartDisease, Length: 13109, dtype: float32
2025-12-03 10:00:36,562:INFO:get_config() successfully completed......................................
2025-12-03 10:00:36,562:INFO:Initializing get_config()
2025-12-03 10:00:36,562:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FAFF34DC0>, variable=y_test)
2025-12-03 10:00:36,562:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-12-03 10:00:36,562:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-12-03 10:00:36,570:INFO:Variable:  returned as 28456    0.0
8993     0.0
34312    0.0
4802     0.0
25895    0.0
        ... 
18045    0.0
5425     0.0
12819    0.0
33659    0.0
19531    0.0
Name: HeartDisease, Length: 13109, dtype: float32
2025-12-03 10:00:36,570:INFO:get_config() successfully completed......................................
2025-12-03 10:00:36,607:INFO:Initializing plot_model()
2025-12-03 10:00:36,607:INFO:plot_model(plot=error, fold=None, verbose=True, display=None, display_format=None, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FAFF34DC0>, system=True)
2025-12-03 10:00:36,607:INFO:Checking exceptions
2025-12-03 10:00:36,627:INFO:Preloading libraries
2025-12-03 10:00:36,634:INFO:Copying training dataset
2025-12-03 10:00:36,634:INFO:Plot type: error
2025-12-03 10:00:36,854:INFO:Fitting Model
2025-12-03 10:00:36,854:INFO:Scoring test/hold-out set
2025-12-03 10:00:37,027:INFO:Visual Rendered Successfully
2025-12-03 10:00:37,206:INFO:plot_model() successfully completed......................................
2025-12-03 10:00:37,250:INFO:Initializing get_config()
2025-12-03 10:00:37,252:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FAFF34DC0>, variable=X_test_transformed)
2025-12-03 10:00:37,334:INFO:Variable: X_test returned as             Age  IncomeRatio  SystolicBP       BMI  WaistCircumference  \
28456 -0.477273    -0.304717   -0.519256 -0.987220           -0.923253   
8993   0.818182     0.253271    2.156910  0.770675            0.920394   
34312  0.704545     0.055403    0.519256  0.518044            0.662901   
4802  -0.545455     0.253730   -0.331933 -0.229036           -0.436352   
25895  0.704545     1.226781   -0.093200 -0.226100            0.012322   
...         ...          ...         ...       ...                 ...   
18045 -0.568182    -0.083104   -0.568713 -1.176693           -1.338674   
5425   0.590909     0.362732    2.210168  0.139096            0.292112   
12819  0.909091    -0.019787    0.899042  0.454886            0.971892   
33659 -0.522727     1.060572   -0.525683 -0.587220           -0.906087   
19531 -0.590909    -0.344290   -0.510287 -0.945114           -1.215078   

         Height  TotalCholesterol  Triglycerides       LDL       HDL  ...  \
28456 -1.080540         -0.078535      -0.470757 -0.026922  0.418008  ...   
8993  -0.279669          0.765897       0.705031  0.006026  0.446825  ...   
34312  0.559339         -0.123259       0.929511 -1.031826 -1.404309  ...   
4802  -0.504861         -0.188325      -0.322647  0.000015 -0.138743  ...   
25895  0.216731          0.892919       1.291109  0.008211 -0.255329  ...   
...         ...               ...            ...       ...       ...  ...   
18045 -2.080569         -0.340947      -0.470582 -0.848950  0.393794  ...   
5425   0.156785          0.435639      -0.065356  1.113733  0.127664  ...   
12819  1.194951         -0.732967      -0.470025 -0.211535 -1.085148  ...   
33659 -1.254274         -1.063225      -0.470958 -2.849419  0.127664  ...   
19531 -2.339052         -0.356898      -0.470595 -0.900608  0.393896  ...   

       Race_5.0  Race_1.0  Race_4.0  Race_3.0  Race_2.0  Education   Smoking  \
28456       1.0       0.0       0.0       0.0       0.0  -0.012820  0.000000   
8993        0.0       0.0       1.0       0.0       0.0   0.547458  1.000000   
34312       0.0       0.0       0.0       1.0       0.0  -0.659696  0.000000   
4802        1.0       0.0       0.0       0.0       0.0   0.262895  0.073612   
25895       0.0       0.0       0.0       1.0       0.0   1.151035  0.000000   
...         ...       ...       ...       ...       ...        ...       ...   
18045       0.0       0.0       0.0       1.0       0.0  -0.793202  0.000000   
5425        0.0       0.0       1.0       0.0       0.0   0.547458  1.000000   
12819       0.0       0.0       0.0       1.0       0.0   1.151035  1.000000   
33659       0.0       0.0       1.0       0.0       0.0   0.258362  0.000000   
19531       1.0       0.0       0.0       0.0       0.0  -0.821118  0.000000   

       PhysicalActivity  HealthInsurance   Alcohol  
28456          0.660578              0.0 -0.518600  
8993           0.000000              0.0  0.115329  
34312          0.000000              0.0  0.592213  
4802           1.012447              0.0 -0.103347  
25895          0.000000              0.0 -0.886483  
...                 ...              ...       ...  
18045          0.904383              0.0 -0.482716  
5425           1.598141              0.0  0.097790  
12819          1.598141              0.0  0.612947  
33659          1.162475              0.0 -0.154408  
19531          0.791302              0.0 -0.683278  

[13109 rows x 31 columns]
2025-12-03 10:00:37,334:INFO:get_config() successfully completed......................................
2025-12-03 10:00:37,364:INFO:Initializing get_config()
2025-12-03 10:00:37,364:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FAFF34DC0>, variable=y_test)
2025-12-03 10:00:37,364:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-12-03 10:00:37,364:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-12-03 10:00:37,370:INFO:Variable:  returned as 28456    0.0
8993     0.0
34312    0.0
4802     0.0
25895    0.0
        ... 
18045    0.0
5425     0.0
12819    0.0
33659    0.0
19531    0.0
Name: HeartDisease, Length: 13109, dtype: float32
2025-12-03 10:00:37,370:INFO:get_config() successfully completed......................................
2025-12-03 10:00:37,371:INFO:Initializing get_config()
2025-12-03 10:00:37,371:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FAFF34DC0>, variable=y_test)
2025-12-03 10:00:37,371:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-12-03 10:00:37,371:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-12-03 10:00:37,376:INFO:Variable:  returned as 28456    0.0
8993     0.0
34312    0.0
4802     0.0
25895    0.0
        ... 
18045    0.0
5425     0.0
12819    0.0
33659    0.0
19531    0.0
Name: HeartDisease, Length: 13109, dtype: float32
2025-12-03 10:00:37,376:INFO:get_config() successfully completed......................................
2025-12-03 10:00:37,377:INFO:Initializing get_config()
2025-12-03 10:00:37,377:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FAFF34DC0>, variable=X_test_transformed)
2025-12-03 10:00:37,444:INFO:Variable: X_test returned as             Age  IncomeRatio  SystolicBP       BMI  WaistCircumference  \
28456 -0.477273    -0.304717   -0.519256 -0.987220           -0.923253   
8993   0.818182     0.253271    2.156910  0.770675            0.920394   
34312  0.704545     0.055403    0.519256  0.518044            0.662901   
4802  -0.545455     0.253730   -0.331933 -0.229036           -0.436352   
25895  0.704545     1.226781   -0.093200 -0.226100            0.012322   
...         ...          ...         ...       ...                 ...   
18045 -0.568182    -0.083104   -0.568713 -1.176693           -1.338674   
5425   0.590909     0.362732    2.210168  0.139096            0.292112   
12819  0.909091    -0.019787    0.899042  0.454886            0.971892   
33659 -0.522727     1.060572   -0.525683 -0.587220           -0.906087   
19531 -0.590909    -0.344290   -0.510287 -0.945114           -1.215078   

         Height  TotalCholesterol  Triglycerides       LDL       HDL  ...  \
28456 -1.080540         -0.078535      -0.470757 -0.026922  0.418008  ...   
8993  -0.279669          0.765897       0.705031  0.006026  0.446825  ...   
34312  0.559339         -0.123259       0.929511 -1.031826 -1.404309  ...   
4802  -0.504861         -0.188325      -0.322647  0.000015 -0.138743  ...   
25895  0.216731          0.892919       1.291109  0.008211 -0.255329  ...   
...         ...               ...            ...       ...       ...  ...   
18045 -2.080569         -0.340947      -0.470582 -0.848950  0.393794  ...   
5425   0.156785          0.435639      -0.065356  1.113733  0.127664  ...   
12819  1.194951         -0.732967      -0.470025 -0.211535 -1.085148  ...   
33659 -1.254274         -1.063225      -0.470958 -2.849419  0.127664  ...   
19531 -2.339052         -0.356898      -0.470595 -0.900608  0.393896  ...   

       Race_5.0  Race_1.0  Race_4.0  Race_3.0  Race_2.0  Education   Smoking  \
28456       1.0       0.0       0.0       0.0       0.0  -0.012820  0.000000   
8993        0.0       0.0       1.0       0.0       0.0   0.547458  1.000000   
34312       0.0       0.0       0.0       1.0       0.0  -0.659696  0.000000   
4802        1.0       0.0       0.0       0.0       0.0   0.262895  0.073612   
25895       0.0       0.0       0.0       1.0       0.0   1.151035  0.000000   
...         ...       ...       ...       ...       ...        ...       ...   
18045       0.0       0.0       0.0       1.0       0.0  -0.793202  0.000000   
5425        0.0       0.0       1.0       0.0       0.0   0.547458  1.000000   
12819       0.0       0.0       0.0       1.0       0.0   1.151035  1.000000   
33659       0.0       0.0       1.0       0.0       0.0   0.258362  0.000000   
19531       1.0       0.0       0.0       0.0       0.0  -0.821118  0.000000   

       PhysicalActivity  HealthInsurance   Alcohol  
28456          0.660578              0.0 -0.518600  
8993           0.000000              0.0  0.115329  
34312          0.000000              0.0  0.592213  
4802           1.012447              0.0 -0.103347  
25895          0.000000              0.0 -0.886483  
...                 ...              ...       ...  
18045          0.904383              0.0 -0.482716  
5425           1.598141              0.0  0.097790  
12819          1.598141              0.0  0.612947  
33659          1.162475              0.0 -0.154408  
19531          0.791302              0.0 -0.683278  

[13109 rows x 31 columns]
2025-12-03 10:00:37,444:INFO:get_config() successfully completed......................................
2025-12-03 10:00:37,449:INFO:Initializing get_config()
2025-12-03 10:00:37,449:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FAFF34DC0>, variable=y_test)
2025-12-03 10:00:37,450:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-12-03 10:00:37,450:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-12-03 10:00:37,453:INFO:Variable:  returned as 28456    0.0
8993     0.0
34312    0.0
4802     0.0
25895    0.0
        ... 
18045    0.0
5425     0.0
12819    0.0
33659    0.0
19531    0.0
Name: HeartDisease, Length: 13109, dtype: float32
2025-12-03 10:00:37,453:INFO:get_config() successfully completed......................................
2025-12-03 10:00:37,455:INFO:Initializing get_config()
2025-12-03 10:00:37,455:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FAFF34DC0>, variable=y_test)
2025-12-03 10:00:37,455:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-12-03 10:00:37,455:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-12-03 10:00:37,460:INFO:Variable:  returned as 28456    0.0
8993     0.0
34312    0.0
4802     0.0
25895    0.0
        ... 
18045    0.0
5425     0.0
12819    0.0
33659    0.0
19531    0.0
Name: HeartDisease, Length: 13109, dtype: float32
2025-12-03 10:00:37,460:INFO:get_config() successfully completed......................................
2025-12-03 10:00:37,464:INFO:Initializing get_config()
2025-12-03 10:00:37,464:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FAFF34DC0>, variable=X_test_transformed)
2025-12-03 10:00:37,539:INFO:Variable: X_test returned as             Age  IncomeRatio  SystolicBP       BMI  WaistCircumference  \
28456 -0.477273    -0.304717   -0.519256 -0.987220           -0.923253   
8993   0.818182     0.253271    2.156910  0.770675            0.920394   
34312  0.704545     0.055403    0.519256  0.518044            0.662901   
4802  -0.545455     0.253730   -0.331933 -0.229036           -0.436352   
25895  0.704545     1.226781   -0.093200 -0.226100            0.012322   
...         ...          ...         ...       ...                 ...   
18045 -0.568182    -0.083104   -0.568713 -1.176693           -1.338674   
5425   0.590909     0.362732    2.210168  0.139096            0.292112   
12819  0.909091    -0.019787    0.899042  0.454886            0.971892   
33659 -0.522727     1.060572   -0.525683 -0.587220           -0.906087   
19531 -0.590909    -0.344290   -0.510287 -0.945114           -1.215078   

         Height  TotalCholesterol  Triglycerides       LDL       HDL  ...  \
28456 -1.080540         -0.078535      -0.470757 -0.026922  0.418008  ...   
8993  -0.279669          0.765897       0.705031  0.006026  0.446825  ...   
34312  0.559339         -0.123259       0.929511 -1.031826 -1.404309  ...   
4802  -0.504861         -0.188325      -0.322647  0.000015 -0.138743  ...   
25895  0.216731          0.892919       1.291109  0.008211 -0.255329  ...   
...         ...               ...            ...       ...       ...  ...   
18045 -2.080569         -0.340947      -0.470582 -0.848950  0.393794  ...   
5425   0.156785          0.435639      -0.065356  1.113733  0.127664  ...   
12819  1.194951         -0.732967      -0.470025 -0.211535 -1.085148  ...   
33659 -1.254274         -1.063225      -0.470958 -2.849419  0.127664  ...   
19531 -2.339052         -0.356898      -0.470595 -0.900608  0.393896  ...   

       Race_5.0  Race_1.0  Race_4.0  Race_3.0  Race_2.0  Education   Smoking  \
28456       1.0       0.0       0.0       0.0       0.0  -0.012820  0.000000   
8993        0.0       0.0       1.0       0.0       0.0   0.547458  1.000000   
34312       0.0       0.0       0.0       1.0       0.0  -0.659696  0.000000   
4802        1.0       0.0       0.0       0.0       0.0   0.262895  0.073612   
25895       0.0       0.0       0.0       1.0       0.0   1.151035  0.000000   
...         ...       ...       ...       ...       ...        ...       ...   
18045       0.0       0.0       0.0       1.0       0.0  -0.793202  0.000000   
5425        0.0       0.0       1.0       0.0       0.0   0.547458  1.000000   
12819       0.0       0.0       0.0       1.0       0.0   1.151035  1.000000   
33659       0.0       0.0       1.0       0.0       0.0   0.258362  0.000000   
19531       1.0       0.0       0.0       0.0       0.0  -0.821118  0.000000   

       PhysicalActivity  HealthInsurance   Alcohol  
28456          0.660578              0.0 -0.518600  
8993           0.000000              0.0  0.115329  
34312          0.000000              0.0  0.592213  
4802           1.012447              0.0 -0.103347  
25895          0.000000              0.0 -0.886483  
...                 ...              ...       ...  
18045          0.904383              0.0 -0.482716  
5425           1.598141              0.0  0.097790  
12819          1.598141              0.0  0.612947  
33659          1.162475              0.0 -0.154408  
19531          0.791302              0.0 -0.683278  

[13109 rows x 31 columns]
2025-12-03 10:00:37,539:INFO:get_config() successfully completed......................................
2025-12-03 10:00:37,594:INFO:Initializing get_config()
2025-12-03 10:00:37,594:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FAFF34DC0>, variable=y_test)
2025-12-03 10:00:37,594:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-12-03 10:00:37,594:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-12-03 10:00:37,603:INFO:Variable:  returned as 28456    0.0
8993     0.0
34312    0.0
4802     0.0
25895    0.0
        ... 
18045    0.0
5425     0.0
12819    0.0
33659    0.0
19531    0.0
Name: HeartDisease, Length: 13109, dtype: float32
2025-12-03 10:00:37,603:INFO:get_config() successfully completed......................................
2025-12-03 10:00:37,604:INFO:Initializing get_config()
2025-12-03 10:00:37,604:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FAFF34DC0>, variable=y_test)
2025-12-03 10:00:37,604:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-12-03 10:00:37,604:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-12-03 10:00:37,609:INFO:Variable:  returned as 28456    0.0
8993     0.0
34312    0.0
4802     0.0
25895    0.0
        ... 
18045    0.0
5425     0.0
12819    0.0
33659    0.0
19531    0.0
Name: HeartDisease, Length: 13109, dtype: float32
2025-12-03 10:00:37,609:INFO:get_config() successfully completed......................................
2025-12-03 10:00:37,705:INFO:Initializing get_config()
2025-12-03 10:00:37,705:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FAFF34DC0>, variable=X_test_transformed)
2025-12-03 10:00:37,791:INFO:Variable: X_test returned as             Age  IncomeRatio  SystolicBP       BMI  WaistCircumference  \
28456 -0.477273    -0.304717   -0.519256 -0.987220           -0.923253   
8993   0.818182     0.253271    2.156910  0.770675            0.920394   
34312  0.704545     0.055403    0.519256  0.518044            0.662901   
4802  -0.545455     0.253730   -0.331933 -0.229036           -0.436352   
25895  0.704545     1.226781   -0.093200 -0.226100            0.012322   
...         ...          ...         ...       ...                 ...   
18045 -0.568182    -0.083104   -0.568713 -1.176693           -1.338674   
5425   0.590909     0.362732    2.210168  0.139096            0.292112   
12819  0.909091    -0.019787    0.899042  0.454886            0.971892   
33659 -0.522727     1.060572   -0.525683 -0.587220           -0.906087   
19531 -0.590909    -0.344290   -0.510287 -0.945114           -1.215078   

         Height  TotalCholesterol  Triglycerides       LDL       HDL  ...  \
28456 -1.080540         -0.078535      -0.470757 -0.026922  0.418008  ...   
8993  -0.279669          0.765897       0.705031  0.006026  0.446825  ...   
34312  0.559339         -0.123259       0.929511 -1.031826 -1.404309  ...   
4802  -0.504861         -0.188325      -0.322647  0.000015 -0.138743  ...   
25895  0.216731          0.892919       1.291109  0.008211 -0.255329  ...   
...         ...               ...            ...       ...       ...  ...   
18045 -2.080569         -0.340947      -0.470582 -0.848950  0.393794  ...   
5425   0.156785          0.435639      -0.065356  1.113733  0.127664  ...   
12819  1.194951         -0.732967      -0.470025 -0.211535 -1.085148  ...   
33659 -1.254274         -1.063225      -0.470958 -2.849419  0.127664  ...   
19531 -2.339052         -0.356898      -0.470595 -0.900608  0.393896  ...   

       Race_5.0  Race_1.0  Race_4.0  Race_3.0  Race_2.0  Education   Smoking  \
28456       1.0       0.0       0.0       0.0       0.0  -0.012820  0.000000   
8993        0.0       0.0       1.0       0.0       0.0   0.547458  1.000000   
34312       0.0       0.0       0.0       1.0       0.0  -0.659696  0.000000   
4802        1.0       0.0       0.0       0.0       0.0   0.262895  0.073612   
25895       0.0       0.0       0.0       1.0       0.0   1.151035  0.000000   
...         ...       ...       ...       ...       ...        ...       ...   
18045       0.0       0.0       0.0       1.0       0.0  -0.793202  0.000000   
5425        0.0       0.0       1.0       0.0       0.0   0.547458  1.000000   
12819       0.0       0.0       0.0       1.0       0.0   1.151035  1.000000   
33659       0.0       0.0       1.0       0.0       0.0   0.258362  0.000000   
19531       1.0       0.0       0.0       0.0       0.0  -0.821118  0.000000   

       PhysicalActivity  HealthInsurance   Alcohol  
28456          0.660578              0.0 -0.518600  
8993           0.000000              0.0  0.115329  
34312          0.000000              0.0  0.592213  
4802           1.012447              0.0 -0.103347  
25895          0.000000              0.0 -0.886483  
...                 ...              ...       ...  
18045          0.904383              0.0 -0.482716  
5425           1.598141              0.0  0.097790  
12819          1.598141              0.0  0.612947  
33659          1.162475              0.0 -0.154408  
19531          0.791302              0.0 -0.683278  

[13109 rows x 31 columns]
2025-12-03 10:00:37,791:INFO:get_config() successfully completed......................................
2025-12-03 10:00:37,821:INFO:Initializing get_config()
2025-12-03 10:00:37,821:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FAFF34DC0>, variable=y_test)
2025-12-03 10:00:37,821:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-12-03 10:00:37,821:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-12-03 10:00:37,827:INFO:Variable:  returned as 28456    0.0
8993     0.0
34312    0.0
4802     0.0
25895    0.0
        ... 
18045    0.0
5425     0.0
12819    0.0
33659    0.0
19531    0.0
Name: HeartDisease, Length: 13109, dtype: float32
2025-12-03 10:00:37,827:INFO:get_config() successfully completed......................................
2025-12-03 10:00:37,827:INFO:Initializing get_config()
2025-12-03 10:00:37,827:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FAFF34DC0>, variable=X_test_transformed)
2025-12-03 10:00:37,895:INFO:Variable: X_test returned as             Age  IncomeRatio  SystolicBP       BMI  WaistCircumference  \
28456 -0.477273    -0.304717   -0.519256 -0.987220           -0.923253   
8993   0.818182     0.253271    2.156910  0.770675            0.920394   
34312  0.704545     0.055403    0.519256  0.518044            0.662901   
4802  -0.545455     0.253730   -0.331933 -0.229036           -0.436352   
25895  0.704545     1.226781   -0.093200 -0.226100            0.012322   
...         ...          ...         ...       ...                 ...   
18045 -0.568182    -0.083104   -0.568713 -1.176693           -1.338674   
5425   0.590909     0.362732    2.210168  0.139096            0.292112   
12819  0.909091    -0.019787    0.899042  0.454886            0.971892   
33659 -0.522727     1.060572   -0.525683 -0.587220           -0.906087   
19531 -0.590909    -0.344290   -0.510287 -0.945114           -1.215078   

         Height  TotalCholesterol  Triglycerides       LDL       HDL  ...  \
28456 -1.080540         -0.078535      -0.470757 -0.026922  0.418008  ...   
8993  -0.279669          0.765897       0.705031  0.006026  0.446825  ...   
34312  0.559339         -0.123259       0.929511 -1.031826 -1.404309  ...   
4802  -0.504861         -0.188325      -0.322647  0.000015 -0.138743  ...   
25895  0.216731          0.892919       1.291109  0.008211 -0.255329  ...   
...         ...               ...            ...       ...       ...  ...   
18045 -2.080569         -0.340947      -0.470582 -0.848950  0.393794  ...   
5425   0.156785          0.435639      -0.065356  1.113733  0.127664  ...   
12819  1.194951         -0.732967      -0.470025 -0.211535 -1.085148  ...   
33659 -1.254274         -1.063225      -0.470958 -2.849419  0.127664  ...   
19531 -2.339052         -0.356898      -0.470595 -0.900608  0.393896  ...   

       Race_5.0  Race_1.0  Race_4.0  Race_3.0  Race_2.0  Education   Smoking  \
28456       1.0       0.0       0.0       0.0       0.0  -0.012820  0.000000   
8993        0.0       0.0       1.0       0.0       0.0   0.547458  1.000000   
34312       0.0       0.0       0.0       1.0       0.0  -0.659696  0.000000   
4802        1.0       0.0       0.0       0.0       0.0   0.262895  0.073612   
25895       0.0       0.0       0.0       1.0       0.0   1.151035  0.000000   
...         ...       ...       ...       ...       ...        ...       ...   
18045       0.0       0.0       0.0       1.0       0.0  -0.793202  0.000000   
5425        0.0       0.0       1.0       0.0       0.0   0.547458  1.000000   
12819       0.0       0.0       0.0       1.0       0.0   1.151035  1.000000   
33659       0.0       0.0       1.0       0.0       0.0   0.258362  0.000000   
19531       1.0       0.0       0.0       0.0       0.0  -0.821118  0.000000   

       PhysicalActivity  HealthInsurance   Alcohol  
28456          0.660578              0.0 -0.518600  
8993           0.000000              0.0  0.115329  
34312          0.000000              0.0  0.592213  
4802           1.012447              0.0 -0.103347  
25895          0.000000              0.0 -0.886483  
...                 ...              ...       ...  
18045          0.904383              0.0 -0.482716  
5425           1.598141              0.0  0.097790  
12819          1.598141              0.0  0.612947  
33659          1.162475              0.0 -0.154408  
19531          0.791302              0.0 -0.683278  

[13109 rows x 31 columns]
2025-12-03 10:00:37,895:INFO:get_config() successfully completed......................................
2025-12-03 10:00:37,896:INFO:Initializing get_config()
2025-12-03 10:00:37,896:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FAFF34DC0>, variable=y_test)
2025-12-03 10:00:37,896:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-12-03 10:00:37,896:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-12-03 10:00:37,902:INFO:Variable:  returned as 28456    0.0
8993     0.0
34312    0.0
4802     0.0
25895    0.0
        ... 
18045    0.0
5425     0.0
12819    0.0
33659    0.0
19531    0.0
Name: HeartDisease, Length: 13109, dtype: float32
2025-12-03 10:00:37,902:INFO:get_config() successfully completed......................................
2025-12-03 10:00:37,902:INFO:Initializing get_config()
2025-12-03 10:00:37,902:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FAFF34DC0>, variable=X_test_transformed)
2025-12-03 10:00:37,984:INFO:Variable: X_test returned as             Age  IncomeRatio  SystolicBP       BMI  WaistCircumference  \
28456 -0.477273    -0.304717   -0.519256 -0.987220           -0.923253   
8993   0.818182     0.253271    2.156910  0.770675            0.920394   
34312  0.704545     0.055403    0.519256  0.518044            0.662901   
4802  -0.545455     0.253730   -0.331933 -0.229036           -0.436352   
25895  0.704545     1.226781   -0.093200 -0.226100            0.012322   
...         ...          ...         ...       ...                 ...   
18045 -0.568182    -0.083104   -0.568713 -1.176693           -1.338674   
5425   0.590909     0.362732    2.210168  0.139096            0.292112   
12819  0.909091    -0.019787    0.899042  0.454886            0.971892   
33659 -0.522727     1.060572   -0.525683 -0.587220           -0.906087   
19531 -0.590909    -0.344290   -0.510287 -0.945114           -1.215078   

         Height  TotalCholesterol  Triglycerides       LDL       HDL  ...  \
28456 -1.080540         -0.078535      -0.470757 -0.026922  0.418008  ...   
8993  -0.279669          0.765897       0.705031  0.006026  0.446825  ...   
34312  0.559339         -0.123259       0.929511 -1.031826 -1.404309  ...   
4802  -0.504861         -0.188325      -0.322647  0.000015 -0.138743  ...   
25895  0.216731          0.892919       1.291109  0.008211 -0.255329  ...   
...         ...               ...            ...       ...       ...  ...   
18045 -2.080569         -0.340947      -0.470582 -0.848950  0.393794  ...   
5425   0.156785          0.435639      -0.065356  1.113733  0.127664  ...   
12819  1.194951         -0.732967      -0.470025 -0.211535 -1.085148  ...   
33659 -1.254274         -1.063225      -0.470958 -2.849419  0.127664  ...   
19531 -2.339052         -0.356898      -0.470595 -0.900608  0.393896  ...   

       Race_5.0  Race_1.0  Race_4.0  Race_3.0  Race_2.0  Education   Smoking  \
28456       1.0       0.0       0.0       0.0       0.0  -0.012820  0.000000   
8993        0.0       0.0       1.0       0.0       0.0   0.547458  1.000000   
34312       0.0       0.0       0.0       1.0       0.0  -0.659696  0.000000   
4802        1.0       0.0       0.0       0.0       0.0   0.262895  0.073612   
25895       0.0       0.0       0.0       1.0       0.0   1.151035  0.000000   
...         ...       ...       ...       ...       ...        ...       ...   
18045       0.0       0.0       0.0       1.0       0.0  -0.793202  0.000000   
5425        0.0       0.0       1.0       0.0       0.0   0.547458  1.000000   
12819       0.0       0.0       0.0       1.0       0.0   1.151035  1.000000   
33659       0.0       0.0       1.0       0.0       0.0   0.258362  0.000000   
19531       1.0       0.0       0.0       0.0       0.0  -0.821118  0.000000   

       PhysicalActivity  HealthInsurance   Alcohol  
28456          0.660578              0.0 -0.518600  
8993           0.000000              0.0  0.115329  
34312          0.000000              0.0  0.592213  
4802           1.012447              0.0 -0.103347  
25895          0.000000              0.0 -0.886483  
...                 ...              ...       ...  
18045          0.904383              0.0 -0.482716  
5425           1.598141              0.0  0.097790  
12819          1.598141              0.0  0.612947  
33659          1.162475              0.0 -0.154408  
19531          0.791302              0.0 -0.683278  

[13109 rows x 31 columns]
2025-12-03 10:00:37,984:INFO:get_config() successfully completed......................................
2025-12-03 10:00:38,040:INFO:Initializing get_config()
2025-12-03 10:00:38,040:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FAFF34DC0>, variable=y_test)
2025-12-03 10:00:38,040:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-12-03 10:00:38,040:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-12-03 10:00:38,045:INFO:Variable:  returned as 28456    0.0
8993     0.0
34312    0.0
4802     0.0
25895    0.0
        ... 
18045    0.0
5425     0.0
12819    0.0
33659    0.0
19531    0.0
Name: HeartDisease, Length: 13109, dtype: float32
2025-12-03 10:00:38,045:INFO:get_config() successfully completed......................................
2025-12-03 10:00:38,064:INFO:Initializing get_config()
2025-12-03 10:00:38,064:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FAFF34DC0>, variable=X_test_transformed)
2025-12-03 10:00:38,154:INFO:Variable: X_test returned as             Age  IncomeRatio  SystolicBP       BMI  WaistCircumference  \
28456 -0.477273    -0.304717   -0.519256 -0.987220           -0.923253   
8993   0.818182     0.253271    2.156910  0.770675            0.920394   
34312  0.704545     0.055403    0.519256  0.518044            0.662901   
4802  -0.545455     0.253730   -0.331933 -0.229036           -0.436352   
25895  0.704545     1.226781   -0.093200 -0.226100            0.012322   
...         ...          ...         ...       ...                 ...   
18045 -0.568182    -0.083104   -0.568713 -1.176693           -1.338674   
5425   0.590909     0.362732    2.210168  0.139096            0.292112   
12819  0.909091    -0.019787    0.899042  0.454886            0.971892   
33659 -0.522727     1.060572   -0.525683 -0.587220           -0.906087   
19531 -0.590909    -0.344290   -0.510287 -0.945114           -1.215078   

         Height  TotalCholesterol  Triglycerides       LDL       HDL  ...  \
28456 -1.080540         -0.078535      -0.470757 -0.026922  0.418008  ...   
8993  -0.279669          0.765897       0.705031  0.006026  0.446825  ...   
34312  0.559339         -0.123259       0.929511 -1.031826 -1.404309  ...   
4802  -0.504861         -0.188325      -0.322647  0.000015 -0.138743  ...   
25895  0.216731          0.892919       1.291109  0.008211 -0.255329  ...   
...         ...               ...            ...       ...       ...  ...   
18045 -2.080569         -0.340947      -0.470582 -0.848950  0.393794  ...   
5425   0.156785          0.435639      -0.065356  1.113733  0.127664  ...   
12819  1.194951         -0.732967      -0.470025 -0.211535 -1.085148  ...   
33659 -1.254274         -1.063225      -0.470958 -2.849419  0.127664  ...   
19531 -2.339052         -0.356898      -0.470595 -0.900608  0.393896  ...   

       Race_5.0  Race_1.0  Race_4.0  Race_3.0  Race_2.0  Education   Smoking  \
28456       1.0       0.0       0.0       0.0       0.0  -0.012820  0.000000   
8993        0.0       0.0       1.0       0.0       0.0   0.547458  1.000000   
34312       0.0       0.0       0.0       1.0       0.0  -0.659696  0.000000   
4802        1.0       0.0       0.0       0.0       0.0   0.262895  0.073612   
25895       0.0       0.0       0.0       1.0       0.0   1.151035  0.000000   
...         ...       ...       ...       ...       ...        ...       ...   
18045       0.0       0.0       0.0       1.0       0.0  -0.793202  0.000000   
5425        0.0       0.0       1.0       0.0       0.0   0.547458  1.000000   
12819       0.0       0.0       0.0       1.0       0.0   1.151035  1.000000   
33659       0.0       0.0       1.0       0.0       0.0   0.258362  0.000000   
19531       1.0       0.0       0.0       0.0       0.0  -0.821118  0.000000   

       PhysicalActivity  HealthInsurance   Alcohol  
28456          0.660578              0.0 -0.518600  
8993           0.000000              0.0  0.115329  
34312          0.000000              0.0  0.592213  
4802           1.012447              0.0 -0.103347  
25895          0.000000              0.0 -0.886483  
...                 ...              ...       ...  
18045          0.904383              0.0 -0.482716  
5425           1.598141              0.0  0.097790  
12819          1.598141              0.0  0.612947  
33659          1.162475              0.0 -0.154408  
19531          0.791302              0.0 -0.683278  

[13109 rows x 31 columns]
2025-12-03 10:00:38,154:INFO:get_config() successfully completed......................................
2025-12-03 10:00:38,184:INFO:Initializing get_config()
2025-12-03 10:00:38,187:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FAFF34DC0>, variable=y_test)
2025-12-03 10:00:38,187:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-12-03 10:00:38,187:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-12-03 10:00:38,194:INFO:Variable:  returned as 28456    0.0
8993     0.0
34312    0.0
4802     0.0
25895    0.0
        ... 
18045    0.0
5425     0.0
12819    0.0
33659    0.0
19531    0.0
Name: HeartDisease, Length: 13109, dtype: float32
2025-12-03 10:00:38,194:INFO:get_config() successfully completed......................................
2025-12-03 10:00:38,415:INFO:Initializing get_config()
2025-12-03 10:00:38,416:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FAFF34DC0>, variable=y_test)
2025-12-03 10:00:38,416:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-12-03 10:00:38,416:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-12-03 10:00:38,425:INFO:Variable:  returned as 28456    0.0
8993     0.0
34312    0.0
4802     0.0
25895    0.0
        ... 
18045    0.0
5425     0.0
12819    0.0
33659    0.0
19531    0.0
Name: HeartDisease, Length: 13109, dtype: float32
2025-12-03 10:00:38,425:INFO:get_config() successfully completed......................................
2025-12-03 10:00:38,426:INFO:Initializing get_config()
2025-12-03 10:00:38,426:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FAFF34DC0>, variable=X_test_transformed)
2025-12-03 10:00:38,528:INFO:Variable: X_test returned as             Age  IncomeRatio  SystolicBP       BMI  WaistCircumference  \
28456 -0.477273    -0.304717   -0.519256 -0.987220           -0.923253   
8993   0.818182     0.253271    2.156910  0.770675            0.920394   
34312  0.704545     0.055403    0.519256  0.518044            0.662901   
4802  -0.545455     0.253730   -0.331933 -0.229036           -0.436352   
25895  0.704545     1.226781   -0.093200 -0.226100            0.012322   
...         ...          ...         ...       ...                 ...   
18045 -0.568182    -0.083104   -0.568713 -1.176693           -1.338674   
5425   0.590909     0.362732    2.210168  0.139096            0.292112   
12819  0.909091    -0.019787    0.899042  0.454886            0.971892   
33659 -0.522727     1.060572   -0.525683 -0.587220           -0.906087   
19531 -0.590909    -0.344290   -0.510287 -0.945114           -1.215078   

         Height  TotalCholesterol  Triglycerides       LDL       HDL  ...  \
28456 -1.080540         -0.078535      -0.470757 -0.026922  0.418008  ...   
8993  -0.279669          0.765897       0.705031  0.006026  0.446825  ...   
34312  0.559339         -0.123259       0.929511 -1.031826 -1.404309  ...   
4802  -0.504861         -0.188325      -0.322647  0.000015 -0.138743  ...   
25895  0.216731          0.892919       1.291109  0.008211 -0.255329  ...   
...         ...               ...            ...       ...       ...  ...   
18045 -2.080569         -0.340947      -0.470582 -0.848950  0.393794  ...   
5425   0.156785          0.435639      -0.065356  1.113733  0.127664  ...   
12819  1.194951         -0.732967      -0.470025 -0.211535 -1.085148  ...   
33659 -1.254274         -1.063225      -0.470958 -2.849419  0.127664  ...   
19531 -2.339052         -0.356898      -0.470595 -0.900608  0.393896  ...   

       Race_5.0  Race_1.0  Race_4.0  Race_3.0  Race_2.0  Education   Smoking  \
28456       1.0       0.0       0.0       0.0       0.0  -0.012820  0.000000   
8993        0.0       0.0       1.0       0.0       0.0   0.547458  1.000000   
34312       0.0       0.0       0.0       1.0       0.0  -0.659696  0.000000   
4802        1.0       0.0       0.0       0.0       0.0   0.262895  0.073612   
25895       0.0       0.0       0.0       1.0       0.0   1.151035  0.000000   
...         ...       ...       ...       ...       ...        ...       ...   
18045       0.0       0.0       0.0       1.0       0.0  -0.793202  0.000000   
5425        0.0       0.0       1.0       0.0       0.0   0.547458  1.000000   
12819       0.0       0.0       0.0       1.0       0.0   1.151035  1.000000   
33659       0.0       0.0       1.0       0.0       0.0   0.258362  0.000000   
19531       1.0       0.0       0.0       0.0       0.0  -0.821118  0.000000   

       PhysicalActivity  HealthInsurance   Alcohol  
28456          0.660578              0.0 -0.518600  
8993           0.000000              0.0  0.115329  
34312          0.000000              0.0  0.592213  
4802           1.012447              0.0 -0.103347  
25895          0.000000              0.0 -0.886483  
...                 ...              ...       ...  
18045          0.904383              0.0 -0.482716  
5425           1.598141              0.0  0.097790  
12819          1.598141              0.0  0.612947  
33659          1.162475              0.0 -0.154408  
19531          0.791302              0.0 -0.683278  

[13109 rows x 31 columns]
2025-12-03 10:00:38,528:INFO:get_config() successfully completed......................................
2025-12-03 10:00:38,625:INFO:Initializing get_config()
2025-12-03 10:00:38,625:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FAFF34DC0>, variable=X_train_transformed)
2025-12-03 10:00:38,668:INFO:Variable: X_train returned as             Age  IncomeRatio  SystolicBP       BMI  WaistCircumference  \
15208  0.954545     0.854789    0.359485  0.518044            0.206281   
25325 -0.272727     0.253271   -0.812170 -0.966167           -0.799656   
5132   0.181818    -0.407608   -0.372799  0.054886            0.319578   
17217  0.500000    -0.751898    0.013314 -0.260904            0.278379   
6382   0.568182     0.054503    1.131712  2.675938            1.888566   
...         ...          ...         ...       ...                 ...   
6265  -0.545455    -0.431352   -0.591719  0.191728           -0.377368   
42694 -0.022727    -0.221612   -0.892056 -0.260904           -0.047778   
13399  0.454545     0.388518    0.377985  0.271482            0.183567   
39959  0.954545    -0.193911    0.625770  0.991728            1.160720   
6616   0.613636    -0.447182    0.652399 -0.871430           -0.514698   

         Height  TotalCholesterol  Triglycerides       LDL       HDL  ...  \
15208 -0.487303          0.625876       0.583394  0.005397  0.314564  ...   
25325 -0.300856          0.033588      -0.261476  0.000256  0.303682  ...   
5132   0.766972          0.181594       0.479279  0.948690 -1.340476  ...   
17217  0.745785          0.227516       0.346113  0.002441 -0.274561  ...   
6382   0.237295          0.867515       0.635574  0.002754  0.829819  ...   
...         ...               ...            ...       ...       ...  ...   
6265  -1.737339         -1.393483      -0.471046 -3.840886  0.063832  ...   
42694  0.000000          0.029167      -0.131730  0.000893  0.063832  ...   
13399 -0.147405          0.462357       0.380371  0.003925  0.256949  ...   
39959  0.368655          1.528031       1.934134  0.011744  0.191497  ...   
6616  -0.021187         -0.224877      -0.043571 -1.609476  0.510658  ...   

       Race_5.0  Race_1.0  Race_4.0  Race_3.0  Race_2.0  Education  Smoking  \
15208       1.0       0.0       0.0       0.0       0.0  -0.659696      0.0   
25325       0.0       1.0       0.0       0.0       0.0   0.185278      0.0   
5132        0.0       1.0       0.0       0.0       0.0  -0.659696      1.0   
17217       0.0       0.0       1.0       0.0       0.0  -0.056119      1.0   
6382        0.0       0.0       1.0       0.0       0.0   0.547458      1.0   
...         ...       ...       ...       ...       ...        ...      ...   
6265        0.0       1.0       0.0       0.0       0.0  -0.769055      0.0   
42694       0.0       1.0       0.0       0.0       0.0   0.547458      0.0   
13399       0.0       0.0       1.0       0.0       0.0   0.547458      0.0   
39959       0.0       0.0       0.0       1.0       0.0   0.547458      0.0   
6616        0.0       0.0       0.0       1.0       0.0   0.547458      1.0   

       PhysicalActivity  HealthInsurance   Alcohol  
15208          0.000000              0.0 -0.886483  
25325          0.000000              0.0  0.592213  
5132           0.000000             -1.0  0.312949  
17217          0.000000              0.0  0.592213  
6382           0.000000              0.0  0.597293  
...                 ...              ...       ...  
6265           0.662459              0.0 -0.501621  
42694          0.000000             -1.0  0.592213  
13399          0.000000              0.0 -0.224534  
39959          0.000000              0.0  0.592213  
6616           0.000000              0.0  0.290247  

[30586 rows x 31 columns]
2025-12-03 10:00:38,668:INFO:get_config() successfully completed......................................
2025-12-03 10:00:38,688:INFO:Initializing tune_model()
2025-12-03 10:00:38,688:INFO:tune_model(estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...), fold=None, round=4, n_iter=5, custom_grid=None, optimize=Recall, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=False, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FAFF34DC0>)
2025-12-03 10:00:38,691:INFO:Checking exceptions
2025-12-03 10:00:38,702:INFO:Copying training dataset
2025-12-03 10:00:38,717:INFO:Checking base model
2025-12-03 10:00:38,717:INFO:Base model : Extreme Gradient Boosting
2025-12-03 10:00:38,717:INFO:Declaring metric variables
2025-12-03 10:00:38,718:INFO:Defining Hyperparameters
2025-12-03 10:00:38,884:INFO:Tuning with n_jobs=1
2025-12-03 10:00:38,884:INFO:Initializing RandomizedSearchCV
2025-12-03 10:01:13,708:INFO:best_params: {'actual_estimator__subsample': 0.7, 'actual_estimator__scale_pos_weight': 38.0, 'actual_estimator__reg_lambda': 0.7, 'actual_estimator__reg_alpha': 0.001, 'actual_estimator__n_estimators': 60, 'actual_estimator__min_child_weight': 1, 'actual_estimator__max_depth': 6, 'actual_estimator__learning_rate': 0.4, 'actual_estimator__colsample_bytree': 0.7}
2025-12-03 10:01:13,708:INFO:Hyperparameter search completed
2025-12-03 10:01:13,708:INFO:SubProcess create_model() called ==================================
2025-12-03 10:01:13,710:INFO:Initializing create_model()
2025-12-03 10:01:13,710:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FAFF34DC0>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000018FA2634820>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'subsample': 0.7, 'scale_pos_weight': 38.0, 'reg_lambda': 0.7, 'reg_alpha': 0.001, 'n_estimators': 60, 'min_child_weight': 1, 'max_depth': 6, 'learning_rate': 0.4, 'colsample_bytree': 0.7})
2025-12-03 10:01:13,711:INFO:Checking exceptions
2025-12-03 10:01:13,711:INFO:Importing libraries
2025-12-03 10:01:13,711:INFO:Copying training dataset
2025-12-03 10:01:13,731:INFO:Defining folds
2025-12-03 10:01:13,731:INFO:Declaring metric variables
2025-12-03 10:01:13,731:INFO:Importing untrained model
2025-12-03 10:01:13,731:INFO:Declaring custom model
2025-12-03 10:01:13,734:INFO:Extreme Gradient Boosting Imported successfully
2025-12-03 10:01:13,734:INFO:Starting cross validation
2025-12-03 10:01:13,734:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-12-03 10:01:18,625:INFO:Calculating mean and std
2025-12-03 10:01:18,625:INFO:Creating metrics dataframe
2025-12-03 10:01:18,626:INFO:Finalizing model
2025-12-03 10:01:18,693:INFO:Warning: No categorical columns found. Calling 'transform' will only return input data.
2025-12-03 10:01:19,084:INFO:Uploading results into container
2025-12-03 10:01:19,085:INFO:Uploading model into container now
2025-12-03 10:01:19,085:INFO:_master_model_container: 4
2025-12-03 10:01:19,085:INFO:_display_container: 5
2025-12-03 10:01:19,086:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=0.7, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=0.4, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=6, max_leaves=None,
              min_child_weight=1, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=60, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2025-12-03 10:01:19,086:INFO:create_model() successfully completed......................................
2025-12-03 10:01:19,270:INFO:SubProcess create_model() end ==================================
2025-12-03 10:01:19,270:INFO:choose_better activated
2025-12-03 10:01:19,270:INFO:SubProcess create_model() called ==================================
2025-12-03 10:01:19,270:INFO:Initializing create_model()
2025-12-03 10:01:19,270:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FAFF34DC0>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-03 10:01:19,273:INFO:Checking exceptions
2025-12-03 10:01:19,273:INFO:Importing libraries
2025-12-03 10:01:19,273:INFO:Copying training dataset
2025-12-03 10:01:19,294:INFO:Defining folds
2025-12-03 10:01:19,294:INFO:Declaring metric variables
2025-12-03 10:01:19,294:INFO:Importing untrained model
2025-12-03 10:01:19,294:INFO:Declaring custom model
2025-12-03 10:01:19,294:INFO:Extreme Gradient Boosting Imported successfully
2025-12-03 10:01:19,294:INFO:Starting cross validation
2025-12-03 10:01:19,294:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-12-03 10:01:25,370:INFO:Calculating mean and std
2025-12-03 10:01:25,372:INFO:Creating metrics dataframe
2025-12-03 10:01:25,373:INFO:Finalizing model
2025-12-03 10:01:25,443:INFO:Warning: No categorical columns found. Calling 'transform' will only return input data.
2025-12-03 10:01:25,975:INFO:Uploading results into container
2025-12-03 10:01:25,976:INFO:Uploading model into container now
2025-12-03 10:01:25,976:INFO:_master_model_container: 5
2025-12-03 10:01:25,976:INFO:_display_container: 6
2025-12-03 10:01:25,976:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2025-12-03 10:01:25,976:INFO:create_model() successfully completed......................................
2025-12-03 10:01:26,161:INFO:SubProcess create_model() end ==================================
2025-12-03 10:01:26,162:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...) result for Recall is 0.3112
2025-12-03 10:01:26,163:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=0.7, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=0.4, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=6, max_leaves=None,
              min_child_weight=1, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=60, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...) result for Recall is 0.3316
2025-12-03 10:01:26,163:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=0.7, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=0.4, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=6, max_leaves=None,
              min_child_weight=1, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=60, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...) is best model
2025-12-03 10:01:26,163:INFO:choose_better completed
2025-12-03 10:01:26,163:INFO:_master_model_container: 5
2025-12-03 10:01:26,163:INFO:_display_container: 5
2025-12-03 10:01:26,164:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=0.7, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=0.4, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=6, max_leaves=None,
              min_child_weight=1, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=60, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2025-12-03 10:01:26,164:INFO:tune_model() successfully completed......................................
2025-12-03 10:01:26,356:INFO:Initializing predict_model()
2025-12-03 10:01:26,356:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FAFF34DC0>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=0.7, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=0.4, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=6, max_leaves=None,
              min_child_weight=1, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=60, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...), probability_threshold=None, encoded_labels=False, raw_score=True, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000018FB006BD00>)
2025-12-03 10:01:26,356:INFO:Checking exceptions
2025-12-03 10:01:26,356:INFO:Preloading libraries
2025-12-03 10:01:26,802:INFO:Initializing get_config()
2025-12-03 10:01:26,802:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FAFF34DC0>, variable=target_param)
2025-12-03 10:01:26,804:INFO:Variable:  returned as HeartDisease
2025-12-03 10:01:26,804:INFO:get_config() successfully completed......................................
2025-12-03 10:01:27,505:INFO:Initializing interpret_model()
2025-12-03 10:01:27,505:INFO:interpret_model(estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=0.7, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=0.4, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=6, max_leaves=None,
              min_child_weight=1, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=60, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...), use_train_data=False, X_new_sample=None, y_new_sample=None, feature=None, kwargs={}, observation=None, plot=summary, save=False, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FAFF34DC0>)
2025-12-03 10:01:27,505:INFO:Checking exceptions
2025-12-03 10:01:27,505:INFO:Soft dependency imported: shap: 0.49.1
2025-12-03 10:01:27,589:INFO:plot type: summary
2025-12-03 10:01:27,589:INFO:Creating TreeExplainer
2025-12-03 10:01:27,600:INFO:Compiling shap values
2025-12-03 10:01:31,032:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:4145: FutureWarning: The NumPy global RNG was seeded by calling `np.random.seed`. In a future version this function will no longer use the global RNG. Pass `rng` explicitly to opt-in to the new behaviour and silence this warning.

2025-12-03 10:01:32,225:INFO:Visual Rendered Successfully
2025-12-03 10:01:32,225:INFO:interpret_model() successfully completed......................................
2025-12-03 10:01:32,429:INFO:Initializing predict_model()
2025-12-03 10:01:32,430:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FAFF34DC0>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...), probability_threshold=None, encoded_labels=False, raw_score=True, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000018FB006B400>)
2025-12-03 10:01:32,430:INFO:Checking exceptions
2025-12-03 10:01:32,430:INFO:Preloading libraries
2025-12-03 10:01:32,870:INFO:Initializing get_config()
2025-12-03 10:01:32,870:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FAFF34DC0>, variable=target_param)
2025-12-03 10:01:32,870:INFO:Variable:  returned as HeartDisease
2025-12-03 10:01:32,870:INFO:get_config() successfully completed......................................
2025-12-03 10:01:32,994:INFO:Initializing finalize_model()
2025-12-03 10:01:32,994:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FAFF34DC0>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=0.7, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=0.4, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=6, max_leaves=None,
              min_child_weight=1, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=60, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2025-12-03 10:01:32,994:INFO:Finalizing XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=0.7, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=0.4, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=6, max_leaves=None,
              min_child_weight=1, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=60, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2025-12-03 10:01:33,014:INFO:Initializing create_model()
2025-12-03 10:01:33,017:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FAFF34DC0>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=0.7, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=0.4, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=6, max_leaves=None,
              min_child_weight=1, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=60, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2025-12-03 10:01:33,017:INFO:Checking exceptions
2025-12-03 10:01:33,019:INFO:Importing libraries
2025-12-03 10:01:33,019:INFO:Copying training dataset
2025-12-03 10:01:33,022:INFO:Defining folds
2025-12-03 10:01:33,022:INFO:Declaring metric variables
2025-12-03 10:01:33,022:INFO:Importing untrained model
2025-12-03 10:01:33,022:INFO:Declaring custom model
2025-12-03 10:01:33,025:INFO:Extreme Gradient Boosting Imported successfully
2025-12-03 10:01:33,026:INFO:Cross validation set to False
2025-12-03 10:01:33,026:INFO:Fitting Model
2025-12-03 10:01:33,120:INFO:Warning: No categorical columns found. Calling 'transform' will only return input data.
2025-12-03 10:01:33,684:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'IncomeRatio', 'SystolicBP',
                                             'BMI', 'WaistCircumference',
                                             'Height', 'TotalCholesterol',
                                             'Triglycerides', 'LDL', 'HDL',
                                             'HbA1c', 'Glucose', 'Creatinine',
                                             'UricAcid', 'ALT_Enzyme',
                                             'Albumin', 'Potassium', 'Sodium',
                                             'GGT_Enzyme', 'AST_Enzyme'],
                                    transformer=Si...
                               feature_types=None, gamma=None, grow_policy=None,
                               importance_type=None,
                               interaction_constraints=None, learning_rate=0.4,
                               max_bin=None, max_cat_threshold=None,
                               max_cat_to_onehot=None, max_delta_step=None,
                               max_depth=6, max_leaves=None, min_child_weight=1,
                               missing=nan, monotone_constraints=None,
                               multi_strategy=None, n_estimators=60, n_jobs=1,
                               num_parallel_tree=None,
                               objective='binary:logistic', ...))],
         verbose=False)
2025-12-03 10:01:33,684:INFO:create_model() successfully completed......................................
2025-12-03 10:01:33,865:INFO:_master_model_container: 5
2025-12-03 10:01:33,865:INFO:_display_container: 7
2025-12-03 10:01:33,891:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'IncomeRatio', 'SystolicBP',
                                             'BMI', 'WaistCircumference',
                                             'Height', 'TotalCholesterol',
                                             'Triglycerides', 'LDL', 'HDL',
                                             'HbA1c', 'Glucose', 'Creatinine',
                                             'UricAcid', 'ALT_Enzyme',
                                             'Albumin', 'Potassium', 'Sodium',
                                             'GGT_Enzyme', 'AST_Enzyme'],
                                    transformer=Si...
                               feature_types=None, gamma=None, grow_policy=None,
                               importance_type=None,
                               interaction_constraints=None, learning_rate=0.4,
                               max_bin=None, max_cat_threshold=None,
                               max_cat_to_onehot=None, max_delta_step=None,
                               max_depth=6, max_leaves=None, min_child_weight=1,
                               missing=nan, monotone_constraints=None,
                               multi_strategy=None, n_estimators=60, n_jobs=1,
                               num_parallel_tree=None,
                               objective='binary:logistic', ...))],
         verbose=False)
2025-12-03 10:01:33,891:INFO:finalize_model() successfully completed......................................
2025-12-03 10:01:34,128:INFO:Initializing save_model()
2025-12-03 10:01:34,128:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'IncomeRatio', 'SystolicBP',
                                             'BMI', 'WaistCircumference',
                                             'Height', 'TotalCholesterol',
                                             'Triglycerides', 'LDL', 'HDL',
                                             'HbA1c', 'Glucose', 'Creatinine',
                                             'UricAcid', 'ALT_Enzyme',
                                             'Albumin', 'Potassium', 'Sodium',
                                             'GGT_Enzyme', 'AST_Enzyme'],
                                    transformer=Si...
                               feature_types=None, gamma=None, grow_policy=None,
                               importance_type=None,
                               interaction_constraints=None, learning_rate=0.4,
                               max_bin=None, max_cat_threshold=None,
                               max_cat_to_onehot=None, max_delta_step=None,
                               max_depth=6, max_leaves=None, min_child_weight=1,
                               missing=nan, monotone_constraints=None,
                               multi_strategy=None, n_estimators=60, n_jobs=1,
                               num_parallel_tree=None,
                               objective='binary:logistic', ...))],
         verbose=False), model_name=../models\best_pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\OMAR\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'IncomeRatio', 'SystolicBP',
                                             'BMI', 'WaistCircumference',
                                             'Height', 'TotalCholesterol',
                                             'Triglycerides', 'LDL', 'HDL',
                                             'HbA1c', 'Glucose', 'Creatinine',
                                             'UricAcid', 'ALT_Enzyme',
                                             'Albumin', 'Potassium', 'Sodium',
                                             'G...
                                    transformer=TargetEncoder(cols=[],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=RobustScaler(copy=True,
                                                             quantile_range=(25.0,
                                                                             75.0),
                                                             unit_variance=False,
                                                             with_centering=True,
                                                             with_scaling=True)))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2025-12-03 10:01:34,128:INFO:Adding model into prep_pipe
2025-12-03 10:01:34,128:WARNING:Only Model saved as it was a pipeline.
2025-12-03 10:01:34,134:INFO:../models\best_pipeline.pkl saved in current working directory
2025-12-03 10:01:34,154:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'IncomeRatio', 'SystolicBP',
                                             'BMI', 'WaistCircumference',
                                             'Height', 'TotalCholesterol',
                                             'Triglycerides', 'LDL', 'HDL',
                                             'HbA1c', 'Glucose', 'Creatinine',
                                             'UricAcid', 'ALT_Enzyme',
                                             'Albumin', 'Potassium', 'Sodium',
                                             'GGT_Enzyme', 'AST_Enzyme'],
                                    transformer=Si...
                               feature_types=None, gamma=None, grow_policy=None,
                               importance_type=None,
                               interaction_constraints=None, learning_rate=0.4,
                               max_bin=None, max_cat_threshold=None,
                               max_cat_to_onehot=None, max_delta_step=None,
                               max_depth=6, max_leaves=None, min_child_weight=1,
                               missing=nan, monotone_constraints=None,
                               multi_strategy=None, n_estimators=60, n_jobs=1,
                               num_parallel_tree=None,
                               objective='binary:logistic', ...))],
         verbose=False)
2025-12-03 10:01:34,154:INFO:save_model() successfully completed......................................
2025-12-03 10:07:04,676:INFO:PyCaret ClassificationExperiment
2025-12-03 10:07:04,676:INFO:Logging name: clf-default-name
2025-12-03 10:07:04,676:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-12-03 10:07:04,676:INFO:version 3.3.2
2025-12-03 10:07:04,676:INFO:Initializing setup()
2025-12-03 10:07:04,676:INFO:self.USI: a6ca
2025-12-03 10:07:04,676:INFO:self._variable_keys: {'idx', 'html_param', '_available_plots', 'y_test', 'USI', 'target_param', 'memory', 'pipeline', 'n_jobs_param', 'X_test', 'seed', 'is_multiclass', 'gpu_param', 'logging_param', 'y_train', 'log_plots_param', 'X_train', 'gpu_n_jobs_param', 'fix_imbalance', 'exp_name_log', 'fold_shuffle_param', 'fold_groups_param', 'X', 'data', 'fold_generator', 'y', 'exp_id', '_ml_usecase'}
2025-12-03 10:07:04,676:INFO:Checking environment
2025-12-03 10:07:04,676:INFO:python_version: 3.10.19
2025-12-03 10:07:04,676:INFO:python_build: ('main', 'Oct 21 2025 16:41:31')
2025-12-03 10:07:04,676:INFO:machine: AMD64
2025-12-03 10:07:04,676:INFO:platform: Windows-10-10.0.26100-SP0
2025-12-03 10:07:04,676:INFO:Memory: svmem(total=16282144768, available=5445709824, percent=66.6, used=10836434944, free=5445709824)
2025-12-03 10:07:04,676:INFO:Physical Core: 6
2025-12-03 10:07:04,676:INFO:Logical Core: 12
2025-12-03 10:07:04,676:INFO:Checking libraries
2025-12-03 10:07:04,676:INFO:System:
2025-12-03 10:07:04,676:INFO:    python: 3.10.19 | packaged by Anaconda, Inc. | (main, Oct 21 2025, 16:41:31) [MSC v.1929 64 bit (AMD64)]
2025-12-03 10:07:04,676:INFO:executable: c:\Users\OMAR\miniconda3\envs\xgb_env\python.exe
2025-12-03 10:07:04,676:INFO:   machine: Windows-10-10.0.26100-SP0
2025-12-03 10:07:04,676:INFO:PyCaret required dependencies:
2025-12-03 10:07:04,676:INFO:                 pip: 25.3
2025-12-03 10:07:04,676:INFO:          setuptools: 80.9.0
2025-12-03 10:07:04,676:INFO:             pycaret: 3.3.2
2025-12-03 10:07:04,676:INFO:             IPython: 8.37.0
2025-12-03 10:07:04,676:INFO:          ipywidgets: 8.1.8
2025-12-03 10:07:04,676:INFO:                tqdm: 4.67.1
2025-12-03 10:07:04,676:INFO:               numpy: 1.26.4
2025-12-03 10:07:04,676:INFO:              pandas: 2.1.4
2025-12-03 10:07:04,676:INFO:              jinja2: 3.1.6
2025-12-03 10:07:04,676:INFO:               scipy: 1.11.4
2025-12-03 10:07:04,676:INFO:              joblib: 1.3.2
2025-12-03 10:07:04,676:INFO:             sklearn: 1.4.2
2025-12-03 10:07:04,676:INFO:                pyod: 2.0.5
2025-12-03 10:07:04,676:INFO:            imblearn: 0.14.0
2025-12-03 10:07:04,676:INFO:   category_encoders: 2.7.0
2025-12-03 10:07:04,676:INFO:            lightgbm: 4.6.0
2025-12-03 10:07:04,676:INFO:               numba: 0.62.1
2025-12-03 10:07:04,676:INFO:            requests: 2.32.5
2025-12-03 10:07:04,676:INFO:          matplotlib: 3.7.5
2025-12-03 10:07:04,676:INFO:          scikitplot: 0.3.7
2025-12-03 10:07:04,676:INFO:         yellowbrick: 1.5
2025-12-03 10:07:04,676:INFO:              plotly: 5.24.1
2025-12-03 10:07:04,676:INFO:    plotly-resampler: Not installed
2025-12-03 10:07:04,676:INFO:             kaleido: 1.2.0
2025-12-03 10:07:04,676:INFO:           schemdraw: 0.15
2025-12-03 10:07:04,676:INFO:         statsmodels: 0.14.5
2025-12-03 10:07:04,676:INFO:              sktime: 0.26.0
2025-12-03 10:07:04,676:INFO:               tbats: 1.1.3
2025-12-03 10:07:04,676:INFO:            pmdarima: 2.0.4
2025-12-03 10:07:04,676:INFO:              psutil: 7.1.3
2025-12-03 10:07:04,676:INFO:          markupsafe: 3.0.3
2025-12-03 10:07:04,676:INFO:             pickle5: Not installed
2025-12-03 10:07:04,676:INFO:         cloudpickle: 3.1.2
2025-12-03 10:07:04,676:INFO:         deprecation: 2.1.0
2025-12-03 10:07:04,676:INFO:              xxhash: 3.6.0
2025-12-03 10:07:04,676:INFO:           wurlitzer: Not installed
2025-12-03 10:07:04,676:INFO:PyCaret optional dependencies:
2025-12-03 10:07:04,676:INFO:                shap: 0.49.1
2025-12-03 10:07:04,676:INFO:           interpret: 0.7.3
2025-12-03 10:07:04,676:INFO:                umap: 0.5.7
2025-12-03 10:07:04,676:INFO:     ydata_profiling: 4.18.0
2025-12-03 10:07:04,679:INFO:  explainerdashboard: 0.5.1
2025-12-03 10:07:04,679:INFO:             autoviz: Not installed
2025-12-03 10:07:04,679:INFO:           fairlearn: 0.7.0
2025-12-03 10:07:04,679:INFO:          deepchecks: Not installed
2025-12-03 10:07:04,679:INFO:             xgboost: 2.1.3
2025-12-03 10:07:04,679:INFO:            catboost: 1.2.8
2025-12-03 10:07:04,679:INFO:              kmodes: 0.12.2
2025-12-03 10:07:04,679:INFO:             mlxtend: 0.23.4
2025-12-03 10:07:04,679:INFO:       statsforecast: 1.5.0
2025-12-03 10:07:04,679:INFO:        tune_sklearn: Not installed
2025-12-03 10:07:04,679:INFO:                 ray: Not installed
2025-12-03 10:07:04,679:INFO:            hyperopt: 0.2.7
2025-12-03 10:07:04,679:INFO:              optuna: 4.6.0
2025-12-03 10:07:04,679:INFO:               skopt: 0.10.2
2025-12-03 10:07:04,679:INFO:              mlflow: 3.6.0
2025-12-03 10:07:04,679:INFO:              gradio: 6.0.1
2025-12-03 10:07:04,679:INFO:             fastapi: 0.123.0
2025-12-03 10:07:04,679:INFO:             uvicorn: 0.38.0
2025-12-03 10:07:04,679:INFO:              m2cgen: 0.10.0
2025-12-03 10:07:04,679:INFO:           evidently: 0.4.40
2025-12-03 10:07:04,679:INFO:               fugue: 0.8.7
2025-12-03 10:07:04,679:INFO:           streamlit: 1.51.0
2025-12-03 10:07:04,679:INFO:             prophet: Not installed
2025-12-03 10:07:04,679:INFO:None
2025-12-03 10:07:04,679:INFO:Set up data.
2025-12-03 10:07:04,708:INFO:Set up folding strategy.
2025-12-03 10:07:04,708:INFO:Set up train/test split.
2025-12-03 10:07:04,737:INFO:Set up index.
2025-12-03 10:07:04,738:INFO:Assigning column types.
2025-12-03 10:07:04,753:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-12-03 10:07:04,779:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-12-03 10:07:04,779:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-03 10:07:04,794:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-03 10:07:04,794:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-03 10:07:04,823:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-12-03 10:07:04,825:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-03 10:07:04,842:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-03 10:07:04,842:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-03 10:07:04,842:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-12-03 10:07:04,869:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-03 10:07:04,885:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-03 10:07:04,887:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-03 10:07:04,908:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-03 10:07:04,928:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-03 10:07:04,930:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-03 10:07:04,930:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-12-03 10:07:04,969:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-03 10:07:04,973:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-03 10:07:05,017:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-03 10:07:05,019:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-03 10:07:05,020:INFO:Preparing preprocessing pipeline...
2025-12-03 10:07:05,023:INFO:Set up simple imputation.
2025-12-03 10:07:05,034:INFO:Set up encoding of ordinal features.
2025-12-03 10:07:05,041:INFO:Set up encoding of categorical features.
2025-12-03 10:07:05,041:INFO:Set up feature normalization.
2025-12-03 10:07:05,226:INFO:Finished creating preprocessing pipeline.
2025-12-03 10:07:05,240:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\OMAR\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'IncomeRatio', 'SystolicBP',
                                             'BMI', 'WaistCircumference',
                                             'Height', 'TotalCholesterol',
                                             'Triglycerides', 'LDL', 'HDL',
                                             'HbA1c', 'Glucose', 'Creatinine',
                                             'UricAcid', 'ALT_Enzyme',
                                             'Albumin', 'Potassium', 'Sodium',
                                             'G...
                                    transformer=TargetEncoder(cols=[],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=RobustScaler(copy=True,
                                                             quantile_range=(25.0,
                                                                             75.0),
                                                             unit_variance=False,
                                                             with_centering=True,
                                                             with_scaling=True)))],
         verbose=False)
2025-12-03 10:07:05,240:INFO:Creating final display dataframe.
2025-12-03 10:07:05,472:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target      HeartDisease
2                   Target type            Binary
3           Original data shape       (43695, 28)
4        Transformed data shape       (43695, 32)
5   Transformed train set shape       (30586, 32)
6    Transformed test set shape       (13109, 32)
7              Numeric features                20
8          Categorical features                 7
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15                    Normalize              True
16             Normalize method            robust
17               Fold Generator   StratifiedKFold
18                  Fold Number                10
19                     CPU Jobs                 1
20                      Use GPU             False
21               Log Experiment             False
22              Experiment Name  clf-default-name
23                          USI              a6ca
2025-12-03 10:07:05,519:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-03 10:07:05,521:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-03 10:07:05,566:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-03 10:07:05,567:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-03 10:07:05,568:INFO:setup() successfully completed in 0.9s...............
2025-12-03 10:07:05,606:INFO:Initializing get_config()
2025-12-03 10:07:05,606:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FAFD711B0>, variable=y_train)
2025-12-03 10:07:05,608:INFO:Variable: 'y_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_train_transformed' instead.
2025-12-03 10:07:05,608:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_train_transformed' instead.

2025-12-03 10:07:05,617:INFO:Variable:  returned as 15208    0.0
25325    0.0
5132     0.0
17217    0.0
6382     0.0
        ... 
6265     0.0
42694    0.0
13399    0.0
39959    0.0
6616     0.0
Name: HeartDisease, Length: 30586, dtype: float32
2025-12-03 10:07:05,617:INFO:get_config() successfully completed......................................
2025-12-03 10:07:05,617:INFO:Initializing create_model()
2025-12-03 10:07:05,617:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FAFD711B0>, estimator=xgboost, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={'scale_pos_weight': 76.32522407170295})
2025-12-03 10:07:05,617:INFO:Checking exceptions
2025-12-03 10:07:05,627:INFO:Importing libraries
2025-12-03 10:07:05,627:INFO:Copying training dataset
2025-12-03 10:07:05,655:INFO:Defining folds
2025-12-03 10:07:05,655:INFO:Declaring metric variables
2025-12-03 10:07:05,657:INFO:Importing untrained model
2025-12-03 10:07:05,665:INFO:Extreme Gradient Boosting Imported successfully
2025-12-03 10:07:05,671:INFO:Starting cross validation
2025-12-03 10:07:05,673:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-12-03 10:07:12,182:INFO:Calculating mean and std
2025-12-03 10:07:12,183:INFO:Creating metrics dataframe
2025-12-03 10:07:12,187:INFO:Finalizing model
2025-12-03 10:07:12,268:INFO:Warning: No categorical columns found. Calling 'transform' will only return input data.
2025-12-03 10:07:12,816:INFO:Uploading results into container
2025-12-03 10:07:12,817:INFO:Uploading model into container now
2025-12-03 10:07:12,825:INFO:_master_model_container: 1
2025-12-03 10:07:12,826:INFO:_display_container: 2
2025-12-03 10:07:12,826:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2025-12-03 10:07:12,826:INFO:create_model() successfully completed......................................
2025-12-03 10:07:13,038:INFO:Initializing create_model()
2025-12-03 10:07:13,038:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FAFD711B0>, estimator=lr, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-03 10:07:13,039:INFO:Checking exceptions
2025-12-03 10:07:13,054:INFO:Importing libraries
2025-12-03 10:07:13,054:INFO:Copying training dataset
2025-12-03 10:07:13,081:INFO:Defining folds
2025-12-03 10:07:13,081:INFO:Declaring metric variables
2025-12-03 10:07:13,084:INFO:Importing untrained model
2025-12-03 10:07:13,087:INFO:Logistic Regression Imported successfully
2025-12-03 10:07:13,093:INFO:Starting cross validation
2025-12-03 10:07:13,094:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-12-03 10:07:14,052:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-12-03 10:07:14,612:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-12-03 10:07:14,986:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-12-03 10:07:14,991:INFO:Calculating mean and std
2025-12-03 10:07:14,991:INFO:Creating metrics dataframe
2025-12-03 10:07:14,994:INFO:Finalizing model
2025-12-03 10:07:15,073:INFO:Warning: No categorical columns found. Calling 'transform' will only return input data.
2025-12-03 10:07:15,172:INFO:Uploading results into container
2025-12-03 10:07:15,173:INFO:Uploading model into container now
2025-12-03 10:07:15,181:INFO:_master_model_container: 2
2025-12-03 10:07:15,181:INFO:_display_container: 3
2025-12-03 10:07:15,181:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-12-03 10:07:15,181:INFO:create_model() successfully completed......................................
2025-12-03 10:07:15,369:INFO:Initializing create_model()
2025-12-03 10:07:15,369:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FAFD711B0>, estimator=rf, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-03 10:07:15,369:INFO:Checking exceptions
2025-12-03 10:07:15,380:INFO:Importing libraries
2025-12-03 10:07:15,380:INFO:Copying training dataset
2025-12-03 10:07:15,408:INFO:Defining folds
2025-12-03 10:07:15,408:INFO:Declaring metric variables
2025-12-03 10:07:15,411:INFO:Importing untrained model
2025-12-03 10:07:15,413:INFO:Random Forest Classifier Imported successfully
2025-12-03 10:07:15,418:INFO:Starting cross validation
2025-12-03 10:07:15,419:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-12-03 10:07:56,079:INFO:Calculating mean and std
2025-12-03 10:07:56,080:INFO:Creating metrics dataframe
2025-12-03 10:07:56,081:INFO:Finalizing model
2025-12-03 10:07:56,158:INFO:Warning: No categorical columns found. Calling 'transform' will only return input data.
2025-12-03 10:08:00,608:INFO:Uploading results into container
2025-12-03 10:08:00,609:INFO:Uploading model into container now
2025-12-03 10:08:00,619:INFO:_master_model_container: 3
2025-12-03 10:08:00,619:INFO:_display_container: 4
2025-12-03 10:08:00,619:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2025-12-03 10:08:00,619:INFO:create_model() successfully completed......................................
2025-12-03 10:08:00,828:INFO:Initializing get_config()
2025-12-03 10:08:00,830:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FAFD711B0>, variable=X_train_transformed)
2025-12-03 10:08:00,869:INFO:Variable: X_train returned as             Age  IncomeRatio  SystolicBP       BMI  WaistCircumference  \
15208  0.954545     0.854789    0.359485  0.518044            0.206281   
25325 -0.272727     0.253271   -0.812170 -0.966167           -0.799656   
5132   0.181818    -0.407608   -0.372799  0.054886            0.319578   
17217  0.500000    -0.751898    0.013314 -0.260904            0.278379   
6382   0.568182     0.054503    1.131712  2.675938            1.888566   
...         ...          ...         ...       ...                 ...   
6265  -0.545455    -0.431352   -0.591719  0.191728           -0.377368   
42694 -0.022727    -0.221612   -0.892056 -0.260904           -0.047778   
13399  0.454545     0.388518    0.377985  0.271482            0.183567   
39959  0.954545    -0.193911    0.625770  0.991728            1.160720   
6616   0.613636    -0.447182    0.652399 -0.871430           -0.514698   

         Height  TotalCholesterol  Triglycerides       LDL       HDL  ...  \
15208 -0.487303          0.625876       0.583394  0.005397  0.314564  ...   
25325 -0.300856          0.033588      -0.261476  0.000256  0.303682  ...   
5132   0.766972          0.181594       0.479279  0.948690 -1.340476  ...   
17217  0.745785          0.227516       0.346113  0.002441 -0.274561  ...   
6382   0.237295          0.867515       0.635574  0.002754  0.829819  ...   
...         ...               ...            ...       ...       ...  ...   
6265  -1.737339         -1.393483      -0.471046 -3.840886  0.063832  ...   
42694  0.000000          0.029167      -0.131730  0.000893  0.063832  ...   
13399 -0.147405          0.462357       0.380371  0.003925  0.256949  ...   
39959  0.368655          1.528031       1.934134  0.011744  0.191497  ...   
6616  -0.021187         -0.224877      -0.043571 -1.609476  0.510658  ...   

       Race_5.0  Race_1.0  Race_4.0  Race_3.0  Race_2.0  Education  Smoking  \
15208       1.0       0.0       0.0       0.0       0.0  -0.659696      0.0   
25325       0.0       1.0       0.0       0.0       0.0   0.185278      0.0   
5132        0.0       1.0       0.0       0.0       0.0  -0.659696      1.0   
17217       0.0       0.0       1.0       0.0       0.0  -0.056119      1.0   
6382        0.0       0.0       1.0       0.0       0.0   0.547458      1.0   
...         ...       ...       ...       ...       ...        ...      ...   
6265        0.0       1.0       0.0       0.0       0.0  -0.769055      0.0   
42694       0.0       1.0       0.0       0.0       0.0   0.547458      0.0   
13399       0.0       0.0       1.0       0.0       0.0   0.547458      0.0   
39959       0.0       0.0       0.0       1.0       0.0   0.547458      0.0   
6616        0.0       0.0       0.0       1.0       0.0   0.547458      1.0   

       PhysicalActivity  HealthInsurance   Alcohol  
15208          0.000000              0.0 -0.886483  
25325          0.000000              0.0  0.592213  
5132           0.000000             -1.0  0.312949  
17217          0.000000              0.0  0.592213  
6382           0.000000              0.0  0.597293  
...                 ...              ...       ...  
6265           0.662459              0.0 -0.501621  
42694          0.000000             -1.0  0.592213  
13399          0.000000              0.0 -0.224534  
39959          0.000000              0.0  0.592213  
6616           0.000000              0.0  0.290247  

[30586 rows x 31 columns]
2025-12-03 10:08:00,870:INFO:get_config() successfully completed......................................
2025-12-03 10:08:00,870:INFO:Initializing get_config()
2025-12-03 10:08:00,870:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FAFD711B0>, variable=y_train)
2025-12-03 10:08:00,870:INFO:Variable: 'y_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_train_transformed' instead.
2025-12-03 10:08:00,870:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_train_transformed' instead.

2025-12-03 10:08:00,876:INFO:Variable:  returned as 15208    0.0
25325    0.0
5132     0.0
17217    0.0
6382     0.0
        ... 
6265     0.0
42694    0.0
13399    0.0
39959    0.0
6616     0.0
Name: HeartDisease, Length: 30586, dtype: float32
2025-12-03 10:08:00,876:INFO:get_config() successfully completed......................................
2025-12-03 10:08:00,880:INFO:Initializing get_config()
2025-12-03 10:08:00,880:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FAFD711B0>, variable=X_test_transformed)
2025-12-03 10:08:00,960:INFO:Variable: X_test returned as             Age  IncomeRatio  SystolicBP       BMI  WaistCircumference  \
28456 -0.477273    -0.304717   -0.519256 -0.987220           -0.923253   
8993   0.818182     0.253271    2.156910  0.770675            0.920394   
34312  0.704545     0.055403    0.519256  0.518044            0.662901   
4802  -0.545455     0.253730   -0.331933 -0.229036           -0.436352   
25895  0.704545     1.226781   -0.093200 -0.226100            0.012322   
...         ...          ...         ...       ...                 ...   
18045 -0.568182    -0.083104   -0.568713 -1.176693           -1.338674   
5425   0.590909     0.362732    2.210168  0.139096            0.292112   
12819  0.909091    -0.019787    0.899042  0.454886            0.971892   
33659 -0.522727     1.060572   -0.525683 -0.587220           -0.906087   
19531 -0.590909    -0.344290   -0.510287 -0.945114           -1.215078   

         Height  TotalCholesterol  Triglycerides       LDL       HDL  ...  \
28456 -1.080540         -0.078535      -0.470757 -0.026922  0.418008  ...   
8993  -0.279669          0.765897       0.705031  0.006026  0.446825  ...   
34312  0.559339         -0.123259       0.929511 -1.031826 -1.404309  ...   
4802  -0.504861         -0.188325      -0.322647  0.000015 -0.138743  ...   
25895  0.216731          0.892919       1.291109  0.008211 -0.255329  ...   
...         ...               ...            ...       ...       ...  ...   
18045 -2.080569         -0.340947      -0.470582 -0.848950  0.393794  ...   
5425   0.156785          0.435639      -0.065356  1.113733  0.127664  ...   
12819  1.194951         -0.732967      -0.470025 -0.211535 -1.085148  ...   
33659 -1.254274         -1.063225      -0.470958 -2.849419  0.127664  ...   
19531 -2.339052         -0.356898      -0.470595 -0.900608  0.393896  ...   

       Race_5.0  Race_1.0  Race_4.0  Race_3.0  Race_2.0  Education   Smoking  \
28456       1.0       0.0       0.0       0.0       0.0  -0.012820  0.000000   
8993        0.0       0.0       1.0       0.0       0.0   0.547458  1.000000   
34312       0.0       0.0       0.0       1.0       0.0  -0.659696  0.000000   
4802        1.0       0.0       0.0       0.0       0.0   0.262895  0.073612   
25895       0.0       0.0       0.0       1.0       0.0   1.151035  0.000000   
...         ...       ...       ...       ...       ...        ...       ...   
18045       0.0       0.0       0.0       1.0       0.0  -0.793202  0.000000   
5425        0.0       0.0       1.0       0.0       0.0   0.547458  1.000000   
12819       0.0       0.0       0.0       1.0       0.0   1.151035  1.000000   
33659       0.0       0.0       1.0       0.0       0.0   0.258362  0.000000   
19531       1.0       0.0       0.0       0.0       0.0  -0.821118  0.000000   

       PhysicalActivity  HealthInsurance   Alcohol  
28456          0.660578              0.0 -0.518600  
8993           0.000000              0.0  0.115329  
34312          0.000000              0.0  0.592213  
4802           1.012447              0.0 -0.103347  
25895          0.000000              0.0 -0.886483  
...                 ...              ...       ...  
18045          0.904383              0.0 -0.482716  
5425           1.598141              0.0  0.097790  
12819          1.598141              0.0  0.612947  
33659          1.162475              0.0 -0.154408  
19531          0.791302              0.0 -0.683278  

[13109 rows x 31 columns]
2025-12-03 10:08:00,960:INFO:get_config() successfully completed......................................
2025-12-03 10:08:00,960:INFO:Initializing get_config()
2025-12-03 10:08:00,960:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FAFD711B0>, variable=y_test)
2025-12-03 10:08:00,961:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-12-03 10:08:00,961:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-12-03 10:08:00,963:INFO:Variable:  returned as 28456    0.0
8993     0.0
34312    0.0
4802     0.0
25895    0.0
        ... 
18045    0.0
5425     0.0
12819    0.0
33659    0.0
19531    0.0
Name: HeartDisease, Length: 13109, dtype: float32
2025-12-03 10:08:00,963:INFO:get_config() successfully completed......................................
2025-12-03 10:08:01,114:INFO:Initializing get_config()
2025-12-03 10:08:01,114:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FAFD711B0>, variable=X_train_transformed)
2025-12-03 10:08:01,154:INFO:Variable: X_train returned as             Age  IncomeRatio  SystolicBP       BMI  WaistCircumference  \
15208  0.954545     0.854789    0.359485  0.518044            0.206281   
25325 -0.272727     0.253271   -0.812170 -0.966167           -0.799656   
5132   0.181818    -0.407608   -0.372799  0.054886            0.319578   
17217  0.500000    -0.751898    0.013314 -0.260904            0.278379   
6382   0.568182     0.054503    1.131712  2.675938            1.888566   
...         ...          ...         ...       ...                 ...   
6265  -0.545455    -0.431352   -0.591719  0.191728           -0.377368   
42694 -0.022727    -0.221612   -0.892056 -0.260904           -0.047778   
13399  0.454545     0.388518    0.377985  0.271482            0.183567   
39959  0.954545    -0.193911    0.625770  0.991728            1.160720   
6616   0.613636    -0.447182    0.652399 -0.871430           -0.514698   

         Height  TotalCholesterol  Triglycerides       LDL       HDL  ...  \
15208 -0.487303          0.625876       0.583394  0.005397  0.314564  ...   
25325 -0.300856          0.033588      -0.261476  0.000256  0.303682  ...   
5132   0.766972          0.181594       0.479279  0.948690 -1.340476  ...   
17217  0.745785          0.227516       0.346113  0.002441 -0.274561  ...   
6382   0.237295          0.867515       0.635574  0.002754  0.829819  ...   
...         ...               ...            ...       ...       ...  ...   
6265  -1.737339         -1.393483      -0.471046 -3.840886  0.063832  ...   
42694  0.000000          0.029167      -0.131730  0.000893  0.063832  ...   
13399 -0.147405          0.462357       0.380371  0.003925  0.256949  ...   
39959  0.368655          1.528031       1.934134  0.011744  0.191497  ...   
6616  -0.021187         -0.224877      -0.043571 -1.609476  0.510658  ...   

       Race_5.0  Race_1.0  Race_4.0  Race_3.0  Race_2.0  Education  Smoking  \
15208       1.0       0.0       0.0       0.0       0.0  -0.659696      0.0   
25325       0.0       1.0       0.0       0.0       0.0   0.185278      0.0   
5132        0.0       1.0       0.0       0.0       0.0  -0.659696      1.0   
17217       0.0       0.0       1.0       0.0       0.0  -0.056119      1.0   
6382        0.0       0.0       1.0       0.0       0.0   0.547458      1.0   
...         ...       ...       ...       ...       ...        ...      ...   
6265        0.0       1.0       0.0       0.0       0.0  -0.769055      0.0   
42694       0.0       1.0       0.0       0.0       0.0   0.547458      0.0   
13399       0.0       0.0       1.0       0.0       0.0   0.547458      0.0   
39959       0.0       0.0       0.0       1.0       0.0   0.547458      0.0   
6616        0.0       0.0       0.0       1.0       0.0   0.547458      1.0   

       PhysicalActivity  HealthInsurance   Alcohol  
15208          0.000000              0.0 -0.886483  
25325          0.000000              0.0  0.592213  
5132           0.000000             -1.0  0.312949  
17217          0.000000              0.0  0.592213  
6382           0.000000              0.0  0.597293  
...                 ...              ...       ...  
6265           0.662459              0.0 -0.501621  
42694          0.000000             -1.0  0.592213  
13399          0.000000              0.0 -0.224534  
39959          0.000000              0.0  0.592213  
6616           0.000000              0.0  0.290247  

[30586 rows x 31 columns]
2025-12-03 10:08:01,154:INFO:get_config() successfully completed......................................
2025-12-03 10:08:01,154:INFO:Initializing get_config()
2025-12-03 10:08:01,154:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FAFD711B0>, variable=y_train)
2025-12-03 10:08:01,154:INFO:Variable: 'y_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_train_transformed' instead.
2025-12-03 10:08:01,154:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_train_transformed' instead.

2025-12-03 10:08:01,160:INFO:Variable:  returned as 15208    0.0
25325    0.0
5132     0.0
17217    0.0
6382     0.0
        ... 
6265     0.0
42694    0.0
13399    0.0
39959    0.0
6616     0.0
Name: HeartDisease, Length: 30586, dtype: float32
2025-12-03 10:08:01,160:INFO:get_config() successfully completed......................................
2025-12-03 10:08:01,163:INFO:Initializing get_config()
2025-12-03 10:08:01,163:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FAFD711B0>, variable=X_test_transformed)
2025-12-03 10:08:01,244:INFO:Variable: X_test returned as             Age  IncomeRatio  SystolicBP       BMI  WaistCircumference  \
28456 -0.477273    -0.304717   -0.519256 -0.987220           -0.923253   
8993   0.818182     0.253271    2.156910  0.770675            0.920394   
34312  0.704545     0.055403    0.519256  0.518044            0.662901   
4802  -0.545455     0.253730   -0.331933 -0.229036           -0.436352   
25895  0.704545     1.226781   -0.093200 -0.226100            0.012322   
...         ...          ...         ...       ...                 ...   
18045 -0.568182    -0.083104   -0.568713 -1.176693           -1.338674   
5425   0.590909     0.362732    2.210168  0.139096            0.292112   
12819  0.909091    -0.019787    0.899042  0.454886            0.971892   
33659 -0.522727     1.060572   -0.525683 -0.587220           -0.906087   
19531 -0.590909    -0.344290   -0.510287 -0.945114           -1.215078   

         Height  TotalCholesterol  Triglycerides       LDL       HDL  ...  \
28456 -1.080540         -0.078535      -0.470757 -0.026922  0.418008  ...   
8993  -0.279669          0.765897       0.705031  0.006026  0.446825  ...   
34312  0.559339         -0.123259       0.929511 -1.031826 -1.404309  ...   
4802  -0.504861         -0.188325      -0.322647  0.000015 -0.138743  ...   
25895  0.216731          0.892919       1.291109  0.008211 -0.255329  ...   
...         ...               ...            ...       ...       ...  ...   
18045 -2.080569         -0.340947      -0.470582 -0.848950  0.393794  ...   
5425   0.156785          0.435639      -0.065356  1.113733  0.127664  ...   
12819  1.194951         -0.732967      -0.470025 -0.211535 -1.085148  ...   
33659 -1.254274         -1.063225      -0.470958 -2.849419  0.127664  ...   
19531 -2.339052         -0.356898      -0.470595 -0.900608  0.393896  ...   

       Race_5.0  Race_1.0  Race_4.0  Race_3.0  Race_2.0  Education   Smoking  \
28456       1.0       0.0       0.0       0.0       0.0  -0.012820  0.000000   
8993        0.0       0.0       1.0       0.0       0.0   0.547458  1.000000   
34312       0.0       0.0       0.0       1.0       0.0  -0.659696  0.000000   
4802        1.0       0.0       0.0       0.0       0.0   0.262895  0.073612   
25895       0.0       0.0       0.0       1.0       0.0   1.151035  0.000000   
...         ...       ...       ...       ...       ...        ...       ...   
18045       0.0       0.0       0.0       1.0       0.0  -0.793202  0.000000   
5425        0.0       0.0       1.0       0.0       0.0   0.547458  1.000000   
12819       0.0       0.0       0.0       1.0       0.0   1.151035  1.000000   
33659       0.0       0.0       1.0       0.0       0.0   0.258362  0.000000   
19531       1.0       0.0       0.0       0.0       0.0  -0.821118  0.000000   

       PhysicalActivity  HealthInsurance   Alcohol  
28456          0.660578              0.0 -0.518600  
8993           0.000000              0.0  0.115329  
34312          0.000000              0.0  0.592213  
4802           1.012447              0.0 -0.103347  
25895          0.000000              0.0 -0.886483  
...                 ...              ...       ...  
18045          0.904383              0.0 -0.482716  
5425           1.598141              0.0  0.097790  
12819          1.598141              0.0  0.612947  
33659          1.162475              0.0 -0.154408  
19531          0.791302              0.0 -0.683278  

[13109 rows x 31 columns]
2025-12-03 10:08:01,245:INFO:get_config() successfully completed......................................
2025-12-03 10:08:01,245:INFO:Initializing get_config()
2025-12-03 10:08:01,245:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FAFD711B0>, variable=y_test)
2025-12-03 10:08:01,245:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-12-03 10:08:01,245:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-12-03 10:08:01,251:INFO:Variable:  returned as 28456    0.0
8993     0.0
34312    0.0
4802     0.0
25895    0.0
        ... 
18045    0.0
5425     0.0
12819    0.0
33659    0.0
19531    0.0
Name: HeartDisease, Length: 13109, dtype: float32
2025-12-03 10:08:01,251:INFO:get_config() successfully completed......................................
2025-12-03 10:08:01,375:INFO:Initializing get_config()
2025-12-03 10:08:01,375:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FAFD711B0>, variable=X_test_transformed)
2025-12-03 10:08:01,454:INFO:Variable: X_test returned as             Age  IncomeRatio  SystolicBP       BMI  WaistCircumference  \
28456 -0.477273    -0.304717   -0.519256 -0.987220           -0.923253   
8993   0.818182     0.253271    2.156910  0.770675            0.920394   
34312  0.704545     0.055403    0.519256  0.518044            0.662901   
4802  -0.545455     0.253730   -0.331933 -0.229036           -0.436352   
25895  0.704545     1.226781   -0.093200 -0.226100            0.012322   
...         ...          ...         ...       ...                 ...   
18045 -0.568182    -0.083104   -0.568713 -1.176693           -1.338674   
5425   0.590909     0.362732    2.210168  0.139096            0.292112   
12819  0.909091    -0.019787    0.899042  0.454886            0.971892   
33659 -0.522727     1.060572   -0.525683 -0.587220           -0.906087   
19531 -0.590909    -0.344290   -0.510287 -0.945114           -1.215078   

         Height  TotalCholesterol  Triglycerides       LDL       HDL  ...  \
28456 -1.080540         -0.078535      -0.470757 -0.026922  0.418008  ...   
8993  -0.279669          0.765897       0.705031  0.006026  0.446825  ...   
34312  0.559339         -0.123259       0.929511 -1.031826 -1.404309  ...   
4802  -0.504861         -0.188325      -0.322647  0.000015 -0.138743  ...   
25895  0.216731          0.892919       1.291109  0.008211 -0.255329  ...   
...         ...               ...            ...       ...       ...  ...   
18045 -2.080569         -0.340947      -0.470582 -0.848950  0.393794  ...   
5425   0.156785          0.435639      -0.065356  1.113733  0.127664  ...   
12819  1.194951         -0.732967      -0.470025 -0.211535 -1.085148  ...   
33659 -1.254274         -1.063225      -0.470958 -2.849419  0.127664  ...   
19531 -2.339052         -0.356898      -0.470595 -0.900608  0.393896  ...   

       Race_5.0  Race_1.0  Race_4.0  Race_3.0  Race_2.0  Education   Smoking  \
28456       1.0       0.0       0.0       0.0       0.0  -0.012820  0.000000   
8993        0.0       0.0       1.0       0.0       0.0   0.547458  1.000000   
34312       0.0       0.0       0.0       1.0       0.0  -0.659696  0.000000   
4802        1.0       0.0       0.0       0.0       0.0   0.262895  0.073612   
25895       0.0       0.0       0.0       1.0       0.0   1.151035  0.000000   
...         ...       ...       ...       ...       ...        ...       ...   
18045       0.0       0.0       0.0       1.0       0.0  -0.793202  0.000000   
5425        0.0       0.0       1.0       0.0       0.0   0.547458  1.000000   
12819       0.0       0.0       0.0       1.0       0.0   1.151035  1.000000   
33659       0.0       0.0       1.0       0.0       0.0   0.258362  0.000000   
19531       1.0       0.0       0.0       0.0       0.0  -0.821118  0.000000   

       PhysicalActivity  HealthInsurance   Alcohol  
28456          0.660578              0.0 -0.518600  
8993           0.000000              0.0  0.115329  
34312          0.000000              0.0  0.592213  
4802           1.012447              0.0 -0.103347  
25895          0.000000              0.0 -0.886483  
...                 ...              ...       ...  
18045          0.904383              0.0 -0.482716  
5425           1.598141              0.0  0.097790  
12819          1.598141              0.0  0.612947  
33659          1.162475              0.0 -0.154408  
19531          0.791302              0.0 -0.683278  

[13109 rows x 31 columns]
2025-12-03 10:08:01,454:INFO:get_config() successfully completed......................................
2025-12-03 10:08:01,454:INFO:Initializing get_config()
2025-12-03 10:08:01,454:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FAFD711B0>, variable=y_test)
2025-12-03 10:08:01,454:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-12-03 10:08:01,454:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-12-03 10:08:01,459:INFO:Variable:  returned as 28456    0.0
8993     0.0
34312    0.0
4802     0.0
25895    0.0
        ... 
18045    0.0
5425     0.0
12819    0.0
33659    0.0
19531    0.0
Name: HeartDisease, Length: 13109, dtype: float32
2025-12-03 10:08:01,459:INFO:get_config() successfully completed......................................
2025-12-03 10:08:01,530:INFO:Initializing plot_model()
2025-12-03 10:08:01,530:INFO:plot_model(plot=error, fold=None, verbose=True, display=None, display_format=None, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FAFD711B0>, system=True)
2025-12-03 10:08:01,530:INFO:Checking exceptions
2025-12-03 10:08:01,550:INFO:Preloading libraries
2025-12-03 10:08:01,572:INFO:Copying training dataset
2025-12-03 10:08:01,573:INFO:Plot type: error
2025-12-03 10:08:01,794:INFO:Fitting Model
2025-12-03 10:08:01,794:INFO:Scoring test/hold-out set
2025-12-03 10:08:01,952:INFO:Visual Rendered Successfully
2025-12-03 10:08:02,126:INFO:plot_model() successfully completed......................................
2025-12-03 10:08:02,167:INFO:Initializing get_config()
2025-12-03 10:08:02,167:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FAFD711B0>, variable=X_test_transformed)
2025-12-03 10:08:02,242:INFO:Variable: X_test returned as             Age  IncomeRatio  SystolicBP       BMI  WaistCircumference  \
28456 -0.477273    -0.304717   -0.519256 -0.987220           -0.923253   
8993   0.818182     0.253271    2.156910  0.770675            0.920394   
34312  0.704545     0.055403    0.519256  0.518044            0.662901   
4802  -0.545455     0.253730   -0.331933 -0.229036           -0.436352   
25895  0.704545     1.226781   -0.093200 -0.226100            0.012322   
...         ...          ...         ...       ...                 ...   
18045 -0.568182    -0.083104   -0.568713 -1.176693           -1.338674   
5425   0.590909     0.362732    2.210168  0.139096            0.292112   
12819  0.909091    -0.019787    0.899042  0.454886            0.971892   
33659 -0.522727     1.060572   -0.525683 -0.587220           -0.906087   
19531 -0.590909    -0.344290   -0.510287 -0.945114           -1.215078   

         Height  TotalCholesterol  Triglycerides       LDL       HDL  ...  \
28456 -1.080540         -0.078535      -0.470757 -0.026922  0.418008  ...   
8993  -0.279669          0.765897       0.705031  0.006026  0.446825  ...   
34312  0.559339         -0.123259       0.929511 -1.031826 -1.404309  ...   
4802  -0.504861         -0.188325      -0.322647  0.000015 -0.138743  ...   
25895  0.216731          0.892919       1.291109  0.008211 -0.255329  ...   
...         ...               ...            ...       ...       ...  ...   
18045 -2.080569         -0.340947      -0.470582 -0.848950  0.393794  ...   
5425   0.156785          0.435639      -0.065356  1.113733  0.127664  ...   
12819  1.194951         -0.732967      -0.470025 -0.211535 -1.085148  ...   
33659 -1.254274         -1.063225      -0.470958 -2.849419  0.127664  ...   
19531 -2.339052         -0.356898      -0.470595 -0.900608  0.393896  ...   

       Race_5.0  Race_1.0  Race_4.0  Race_3.0  Race_2.0  Education   Smoking  \
28456       1.0       0.0       0.0       0.0       0.0  -0.012820  0.000000   
8993        0.0       0.0       1.0       0.0       0.0   0.547458  1.000000   
34312       0.0       0.0       0.0       1.0       0.0  -0.659696  0.000000   
4802        1.0       0.0       0.0       0.0       0.0   0.262895  0.073612   
25895       0.0       0.0       0.0       1.0       0.0   1.151035  0.000000   
...         ...       ...       ...       ...       ...        ...       ...   
18045       0.0       0.0       0.0       1.0       0.0  -0.793202  0.000000   
5425        0.0       0.0       1.0       0.0       0.0   0.547458  1.000000   
12819       0.0       0.0       0.0       1.0       0.0   1.151035  1.000000   
33659       0.0       0.0       1.0       0.0       0.0   0.258362  0.000000   
19531       1.0       0.0       0.0       0.0       0.0  -0.821118  0.000000   

       PhysicalActivity  HealthInsurance   Alcohol  
28456          0.660578              0.0 -0.518600  
8993           0.000000              0.0  0.115329  
34312          0.000000              0.0  0.592213  
4802           1.012447              0.0 -0.103347  
25895          0.000000              0.0 -0.886483  
...                 ...              ...       ...  
18045          0.904383              0.0 -0.482716  
5425           1.598141              0.0  0.097790  
12819          1.598141              0.0  0.612947  
33659          1.162475              0.0 -0.154408  
19531          0.791302              0.0 -0.683278  

[13109 rows x 31 columns]
2025-12-03 10:08:02,242:INFO:get_config() successfully completed......................................
2025-12-03 10:08:02,270:INFO:Initializing get_config()
2025-12-03 10:08:02,270:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FAFD711B0>, variable=y_test)
2025-12-03 10:08:02,270:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-12-03 10:08:02,270:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-12-03 10:08:02,275:INFO:Variable:  returned as 28456    0.0
8993     0.0
34312    0.0
4802     0.0
25895    0.0
        ... 
18045    0.0
5425     0.0
12819    0.0
33659    0.0
19531    0.0
Name: HeartDisease, Length: 13109, dtype: float32
2025-12-03 10:08:02,275:INFO:get_config() successfully completed......................................
2025-12-03 10:08:02,276:INFO:Initializing get_config()
2025-12-03 10:08:02,276:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FAFD711B0>, variable=y_test)
2025-12-03 10:08:02,276:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-12-03 10:08:02,276:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-12-03 10:08:02,281:INFO:Variable:  returned as 28456    0.0
8993     0.0
34312    0.0
4802     0.0
25895    0.0
        ... 
18045    0.0
5425     0.0
12819    0.0
33659    0.0
19531    0.0
Name: HeartDisease, Length: 13109, dtype: float32
2025-12-03 10:08:02,281:INFO:get_config() successfully completed......................................
2025-12-03 10:08:02,281:INFO:Initializing get_config()
2025-12-03 10:08:02,281:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FAFD711B0>, variable=X_test_transformed)
2025-12-03 10:08:02,350:INFO:Variable: X_test returned as             Age  IncomeRatio  SystolicBP       BMI  WaistCircumference  \
28456 -0.477273    -0.304717   -0.519256 -0.987220           -0.923253   
8993   0.818182     0.253271    2.156910  0.770675            0.920394   
34312  0.704545     0.055403    0.519256  0.518044            0.662901   
4802  -0.545455     0.253730   -0.331933 -0.229036           -0.436352   
25895  0.704545     1.226781   -0.093200 -0.226100            0.012322   
...         ...          ...         ...       ...                 ...   
18045 -0.568182    -0.083104   -0.568713 -1.176693           -1.338674   
5425   0.590909     0.362732    2.210168  0.139096            0.292112   
12819  0.909091    -0.019787    0.899042  0.454886            0.971892   
33659 -0.522727     1.060572   -0.525683 -0.587220           -0.906087   
19531 -0.590909    -0.344290   -0.510287 -0.945114           -1.215078   

         Height  TotalCholesterol  Triglycerides       LDL       HDL  ...  \
28456 -1.080540         -0.078535      -0.470757 -0.026922  0.418008  ...   
8993  -0.279669          0.765897       0.705031  0.006026  0.446825  ...   
34312  0.559339         -0.123259       0.929511 -1.031826 -1.404309  ...   
4802  -0.504861         -0.188325      -0.322647  0.000015 -0.138743  ...   
25895  0.216731          0.892919       1.291109  0.008211 -0.255329  ...   
...         ...               ...            ...       ...       ...  ...   
18045 -2.080569         -0.340947      -0.470582 -0.848950  0.393794  ...   
5425   0.156785          0.435639      -0.065356  1.113733  0.127664  ...   
12819  1.194951         -0.732967      -0.470025 -0.211535 -1.085148  ...   
33659 -1.254274         -1.063225      -0.470958 -2.849419  0.127664  ...   
19531 -2.339052         -0.356898      -0.470595 -0.900608  0.393896  ...   

       Race_5.0  Race_1.0  Race_4.0  Race_3.0  Race_2.0  Education   Smoking  \
28456       1.0       0.0       0.0       0.0       0.0  -0.012820  0.000000   
8993        0.0       0.0       1.0       0.0       0.0   0.547458  1.000000   
34312       0.0       0.0       0.0       1.0       0.0  -0.659696  0.000000   
4802        1.0       0.0       0.0       0.0       0.0   0.262895  0.073612   
25895       0.0       0.0       0.0       1.0       0.0   1.151035  0.000000   
...         ...       ...       ...       ...       ...        ...       ...   
18045       0.0       0.0       0.0       1.0       0.0  -0.793202  0.000000   
5425        0.0       0.0       1.0       0.0       0.0   0.547458  1.000000   
12819       0.0       0.0       0.0       1.0       0.0   1.151035  1.000000   
33659       0.0       0.0       1.0       0.0       0.0   0.258362  0.000000   
19531       1.0       0.0       0.0       0.0       0.0  -0.821118  0.000000   

       PhysicalActivity  HealthInsurance   Alcohol  
28456          0.660578              0.0 -0.518600  
8993           0.000000              0.0  0.115329  
34312          0.000000              0.0  0.592213  
4802           1.012447              0.0 -0.103347  
25895          0.000000              0.0 -0.886483  
...                 ...              ...       ...  
18045          0.904383              0.0 -0.482716  
5425           1.598141              0.0  0.097790  
12819          1.598141              0.0  0.612947  
33659          1.162475              0.0 -0.154408  
19531          0.791302              0.0 -0.683278  

[13109 rows x 31 columns]
2025-12-03 10:08:02,350:INFO:get_config() successfully completed......................................
2025-12-03 10:08:02,351:INFO:Initializing get_config()
2025-12-03 10:08:02,351:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FAFD711B0>, variable=y_test)
2025-12-03 10:08:02,351:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-12-03 10:08:02,351:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-12-03 10:08:02,356:INFO:Variable:  returned as 28456    0.0
8993     0.0
34312    0.0
4802     0.0
25895    0.0
        ... 
18045    0.0
5425     0.0
12819    0.0
33659    0.0
19531    0.0
Name: HeartDisease, Length: 13109, dtype: float32
2025-12-03 10:08:02,356:INFO:get_config() successfully completed......................................
2025-12-03 10:08:02,356:INFO:Initializing get_config()
2025-12-03 10:08:02,356:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FAFD711B0>, variable=y_test)
2025-12-03 10:08:02,356:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-12-03 10:08:02,356:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-12-03 10:08:02,358:INFO:Variable:  returned as 28456    0.0
8993     0.0
34312    0.0
4802     0.0
25895    0.0
        ... 
18045    0.0
5425     0.0
12819    0.0
33659    0.0
19531    0.0
Name: HeartDisease, Length: 13109, dtype: float32
2025-12-03 10:08:02,358:INFO:get_config() successfully completed......................................
2025-12-03 10:08:02,364:INFO:Initializing get_config()
2025-12-03 10:08:02,364:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FAFD711B0>, variable=X_test_transformed)
2025-12-03 10:08:02,434:INFO:Variable: X_test returned as             Age  IncomeRatio  SystolicBP       BMI  WaistCircumference  \
28456 -0.477273    -0.304717   -0.519256 -0.987220           -0.923253   
8993   0.818182     0.253271    2.156910  0.770675            0.920394   
34312  0.704545     0.055403    0.519256  0.518044            0.662901   
4802  -0.545455     0.253730   -0.331933 -0.229036           -0.436352   
25895  0.704545     1.226781   -0.093200 -0.226100            0.012322   
...         ...          ...         ...       ...                 ...   
18045 -0.568182    -0.083104   -0.568713 -1.176693           -1.338674   
5425   0.590909     0.362732    2.210168  0.139096            0.292112   
12819  0.909091    -0.019787    0.899042  0.454886            0.971892   
33659 -0.522727     1.060572   -0.525683 -0.587220           -0.906087   
19531 -0.590909    -0.344290   -0.510287 -0.945114           -1.215078   

         Height  TotalCholesterol  Triglycerides       LDL       HDL  ...  \
28456 -1.080540         -0.078535      -0.470757 -0.026922  0.418008  ...   
8993  -0.279669          0.765897       0.705031  0.006026  0.446825  ...   
34312  0.559339         -0.123259       0.929511 -1.031826 -1.404309  ...   
4802  -0.504861         -0.188325      -0.322647  0.000015 -0.138743  ...   
25895  0.216731          0.892919       1.291109  0.008211 -0.255329  ...   
...         ...               ...            ...       ...       ...  ...   
18045 -2.080569         -0.340947      -0.470582 -0.848950  0.393794  ...   
5425   0.156785          0.435639      -0.065356  1.113733  0.127664  ...   
12819  1.194951         -0.732967      -0.470025 -0.211535 -1.085148  ...   
33659 -1.254274         -1.063225      -0.470958 -2.849419  0.127664  ...   
19531 -2.339052         -0.356898      -0.470595 -0.900608  0.393896  ...   

       Race_5.0  Race_1.0  Race_4.0  Race_3.0  Race_2.0  Education   Smoking  \
28456       1.0       0.0       0.0       0.0       0.0  -0.012820  0.000000   
8993        0.0       0.0       1.0       0.0       0.0   0.547458  1.000000   
34312       0.0       0.0       0.0       1.0       0.0  -0.659696  0.000000   
4802        1.0       0.0       0.0       0.0       0.0   0.262895  0.073612   
25895       0.0       0.0       0.0       1.0       0.0   1.151035  0.000000   
...         ...       ...       ...       ...       ...        ...       ...   
18045       0.0       0.0       0.0       1.0       0.0  -0.793202  0.000000   
5425        0.0       0.0       1.0       0.0       0.0   0.547458  1.000000   
12819       0.0       0.0       0.0       1.0       0.0   1.151035  1.000000   
33659       0.0       0.0       1.0       0.0       0.0   0.258362  0.000000   
19531       1.0       0.0       0.0       0.0       0.0  -0.821118  0.000000   

       PhysicalActivity  HealthInsurance   Alcohol  
28456          0.660578              0.0 -0.518600  
8993           0.000000              0.0  0.115329  
34312          0.000000              0.0  0.592213  
4802           1.012447              0.0 -0.103347  
25895          0.000000              0.0 -0.886483  
...                 ...              ...       ...  
18045          0.904383              0.0 -0.482716  
5425           1.598141              0.0  0.097790  
12819          1.598141              0.0  0.612947  
33659          1.162475              0.0 -0.154408  
19531          0.791302              0.0 -0.683278  

[13109 rows x 31 columns]
2025-12-03 10:08:02,434:INFO:get_config() successfully completed......................................
2025-12-03 10:08:02,489:INFO:Initializing get_config()
2025-12-03 10:08:02,489:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FAFD711B0>, variable=y_test)
2025-12-03 10:08:02,489:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-12-03 10:08:02,489:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-12-03 10:08:02,495:INFO:Variable:  returned as 28456    0.0
8993     0.0
34312    0.0
4802     0.0
25895    0.0
        ... 
18045    0.0
5425     0.0
12819    0.0
33659    0.0
19531    0.0
Name: HeartDisease, Length: 13109, dtype: float32
2025-12-03 10:08:02,495:INFO:get_config() successfully completed......................................
2025-12-03 10:08:02,496:INFO:Initializing get_config()
2025-12-03 10:08:02,496:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FAFD711B0>, variable=y_test)
2025-12-03 10:08:02,496:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-12-03 10:08:02,496:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-12-03 10:08:02,502:INFO:Variable:  returned as 28456    0.0
8993     0.0
34312    0.0
4802     0.0
25895    0.0
        ... 
18045    0.0
5425     0.0
12819    0.0
33659    0.0
19531    0.0
Name: HeartDisease, Length: 13109, dtype: float32
2025-12-03 10:08:02,502:INFO:get_config() successfully completed......................................
2025-12-03 10:08:02,598:INFO:Initializing get_config()
2025-12-03 10:08:02,598:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FAFD711B0>, variable=X_test_transformed)
2025-12-03 10:08:02,676:INFO:Variable: X_test returned as             Age  IncomeRatio  SystolicBP       BMI  WaistCircumference  \
28456 -0.477273    -0.304717   -0.519256 -0.987220           -0.923253   
8993   0.818182     0.253271    2.156910  0.770675            0.920394   
34312  0.704545     0.055403    0.519256  0.518044            0.662901   
4802  -0.545455     0.253730   -0.331933 -0.229036           -0.436352   
25895  0.704545     1.226781   -0.093200 -0.226100            0.012322   
...         ...          ...         ...       ...                 ...   
18045 -0.568182    -0.083104   -0.568713 -1.176693           -1.338674   
5425   0.590909     0.362732    2.210168  0.139096            0.292112   
12819  0.909091    -0.019787    0.899042  0.454886            0.971892   
33659 -0.522727     1.060572   -0.525683 -0.587220           -0.906087   
19531 -0.590909    -0.344290   -0.510287 -0.945114           -1.215078   

         Height  TotalCholesterol  Triglycerides       LDL       HDL  ...  \
28456 -1.080540         -0.078535      -0.470757 -0.026922  0.418008  ...   
8993  -0.279669          0.765897       0.705031  0.006026  0.446825  ...   
34312  0.559339         -0.123259       0.929511 -1.031826 -1.404309  ...   
4802  -0.504861         -0.188325      -0.322647  0.000015 -0.138743  ...   
25895  0.216731          0.892919       1.291109  0.008211 -0.255329  ...   
...         ...               ...            ...       ...       ...  ...   
18045 -2.080569         -0.340947      -0.470582 -0.848950  0.393794  ...   
5425   0.156785          0.435639      -0.065356  1.113733  0.127664  ...   
12819  1.194951         -0.732967      -0.470025 -0.211535 -1.085148  ...   
33659 -1.254274         -1.063225      -0.470958 -2.849419  0.127664  ...   
19531 -2.339052         -0.356898      -0.470595 -0.900608  0.393896  ...   

       Race_5.0  Race_1.0  Race_4.0  Race_3.0  Race_2.0  Education   Smoking  \
28456       1.0       0.0       0.0       0.0       0.0  -0.012820  0.000000   
8993        0.0       0.0       1.0       0.0       0.0   0.547458  1.000000   
34312       0.0       0.0       0.0       1.0       0.0  -0.659696  0.000000   
4802        1.0       0.0       0.0       0.0       0.0   0.262895  0.073612   
25895       0.0       0.0       0.0       1.0       0.0   1.151035  0.000000   
...         ...       ...       ...       ...       ...        ...       ...   
18045       0.0       0.0       0.0       1.0       0.0  -0.793202  0.000000   
5425        0.0       0.0       1.0       0.0       0.0   0.547458  1.000000   
12819       0.0       0.0       0.0       1.0       0.0   1.151035  1.000000   
33659       0.0       0.0       1.0       0.0       0.0   0.258362  0.000000   
19531       1.0       0.0       0.0       0.0       0.0  -0.821118  0.000000   

       PhysicalActivity  HealthInsurance   Alcohol  
28456          0.660578              0.0 -0.518600  
8993           0.000000              0.0  0.115329  
34312          0.000000              0.0  0.592213  
4802           1.012447              0.0 -0.103347  
25895          0.000000              0.0 -0.886483  
...                 ...              ...       ...  
18045          0.904383              0.0 -0.482716  
5425           1.598141              0.0  0.097790  
12819          1.598141              0.0  0.612947  
33659          1.162475              0.0 -0.154408  
19531          0.791302              0.0 -0.683278  

[13109 rows x 31 columns]
2025-12-03 10:08:02,676:INFO:get_config() successfully completed......................................
2025-12-03 10:08:02,704:INFO:Initializing get_config()
2025-12-03 10:08:02,704:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FAFD711B0>, variable=y_test)
2025-12-03 10:08:02,704:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-12-03 10:08:02,704:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-12-03 10:08:02,709:INFO:Variable:  returned as 28456    0.0
8993     0.0
34312    0.0
4802     0.0
25895    0.0
        ... 
18045    0.0
5425     0.0
12819    0.0
33659    0.0
19531    0.0
Name: HeartDisease, Length: 13109, dtype: float32
2025-12-03 10:08:02,709:INFO:get_config() successfully completed......................................
2025-12-03 10:08:02,709:INFO:Initializing get_config()
2025-12-03 10:08:02,709:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FAFD711B0>, variable=X_test_transformed)
2025-12-03 10:08:02,780:INFO:Variable: X_test returned as             Age  IncomeRatio  SystolicBP       BMI  WaistCircumference  \
28456 -0.477273    -0.304717   -0.519256 -0.987220           -0.923253   
8993   0.818182     0.253271    2.156910  0.770675            0.920394   
34312  0.704545     0.055403    0.519256  0.518044            0.662901   
4802  -0.545455     0.253730   -0.331933 -0.229036           -0.436352   
25895  0.704545     1.226781   -0.093200 -0.226100            0.012322   
...         ...          ...         ...       ...                 ...   
18045 -0.568182    -0.083104   -0.568713 -1.176693           -1.338674   
5425   0.590909     0.362732    2.210168  0.139096            0.292112   
12819  0.909091    -0.019787    0.899042  0.454886            0.971892   
33659 -0.522727     1.060572   -0.525683 -0.587220           -0.906087   
19531 -0.590909    -0.344290   -0.510287 -0.945114           -1.215078   

         Height  TotalCholesterol  Triglycerides       LDL       HDL  ...  \
28456 -1.080540         -0.078535      -0.470757 -0.026922  0.418008  ...   
8993  -0.279669          0.765897       0.705031  0.006026  0.446825  ...   
34312  0.559339         -0.123259       0.929511 -1.031826 -1.404309  ...   
4802  -0.504861         -0.188325      -0.322647  0.000015 -0.138743  ...   
25895  0.216731          0.892919       1.291109  0.008211 -0.255329  ...   
...         ...               ...            ...       ...       ...  ...   
18045 -2.080569         -0.340947      -0.470582 -0.848950  0.393794  ...   
5425   0.156785          0.435639      -0.065356  1.113733  0.127664  ...   
12819  1.194951         -0.732967      -0.470025 -0.211535 -1.085148  ...   
33659 -1.254274         -1.063225      -0.470958 -2.849419  0.127664  ...   
19531 -2.339052         -0.356898      -0.470595 -0.900608  0.393896  ...   

       Race_5.0  Race_1.0  Race_4.0  Race_3.0  Race_2.0  Education   Smoking  \
28456       1.0       0.0       0.0       0.0       0.0  -0.012820  0.000000   
8993        0.0       0.0       1.0       0.0       0.0   0.547458  1.000000   
34312       0.0       0.0       0.0       1.0       0.0  -0.659696  0.000000   
4802        1.0       0.0       0.0       0.0       0.0   0.262895  0.073612   
25895       0.0       0.0       0.0       1.0       0.0   1.151035  0.000000   
...         ...       ...       ...       ...       ...        ...       ...   
18045       0.0       0.0       0.0       1.0       0.0  -0.793202  0.000000   
5425        0.0       0.0       1.0       0.0       0.0   0.547458  1.000000   
12819       0.0       0.0       0.0       1.0       0.0   1.151035  1.000000   
33659       0.0       0.0       1.0       0.0       0.0   0.258362  0.000000   
19531       1.0       0.0       0.0       0.0       0.0  -0.821118  0.000000   

       PhysicalActivity  HealthInsurance   Alcohol  
28456          0.660578              0.0 -0.518600  
8993           0.000000              0.0  0.115329  
34312          0.000000              0.0  0.592213  
4802           1.012447              0.0 -0.103347  
25895          0.000000              0.0 -0.886483  
...                 ...              ...       ...  
18045          0.904383              0.0 -0.482716  
5425           1.598141              0.0  0.097790  
12819          1.598141              0.0  0.612947  
33659          1.162475              0.0 -0.154408  
19531          0.791302              0.0 -0.683278  

[13109 rows x 31 columns]
2025-12-03 10:08:02,780:INFO:get_config() successfully completed......................................
2025-12-03 10:08:02,781:INFO:Initializing get_config()
2025-12-03 10:08:02,781:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FAFD711B0>, variable=y_test)
2025-12-03 10:08:02,781:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-12-03 10:08:02,781:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-12-03 10:08:02,785:INFO:Variable:  returned as 28456    0.0
8993     0.0
34312    0.0
4802     0.0
25895    0.0
        ... 
18045    0.0
5425     0.0
12819    0.0
33659    0.0
19531    0.0
Name: HeartDisease, Length: 13109, dtype: float32
2025-12-03 10:08:02,785:INFO:get_config() successfully completed......................................
2025-12-03 10:08:02,785:INFO:Initializing get_config()
2025-12-03 10:08:02,785:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FAFD711B0>, variable=X_test_transformed)
2025-12-03 10:08:02,859:INFO:Variable: X_test returned as             Age  IncomeRatio  SystolicBP       BMI  WaistCircumference  \
28456 -0.477273    -0.304717   -0.519256 -0.987220           -0.923253   
8993   0.818182     0.253271    2.156910  0.770675            0.920394   
34312  0.704545     0.055403    0.519256  0.518044            0.662901   
4802  -0.545455     0.253730   -0.331933 -0.229036           -0.436352   
25895  0.704545     1.226781   -0.093200 -0.226100            0.012322   
...         ...          ...         ...       ...                 ...   
18045 -0.568182    -0.083104   -0.568713 -1.176693           -1.338674   
5425   0.590909     0.362732    2.210168  0.139096            0.292112   
12819  0.909091    -0.019787    0.899042  0.454886            0.971892   
33659 -0.522727     1.060572   -0.525683 -0.587220           -0.906087   
19531 -0.590909    -0.344290   -0.510287 -0.945114           -1.215078   

         Height  TotalCholesterol  Triglycerides       LDL       HDL  ...  \
28456 -1.080540         -0.078535      -0.470757 -0.026922  0.418008  ...   
8993  -0.279669          0.765897       0.705031  0.006026  0.446825  ...   
34312  0.559339         -0.123259       0.929511 -1.031826 -1.404309  ...   
4802  -0.504861         -0.188325      -0.322647  0.000015 -0.138743  ...   
25895  0.216731          0.892919       1.291109  0.008211 -0.255329  ...   
...         ...               ...            ...       ...       ...  ...   
18045 -2.080569         -0.340947      -0.470582 -0.848950  0.393794  ...   
5425   0.156785          0.435639      -0.065356  1.113733  0.127664  ...   
12819  1.194951         -0.732967      -0.470025 -0.211535 -1.085148  ...   
33659 -1.254274         -1.063225      -0.470958 -2.849419  0.127664  ...   
19531 -2.339052         -0.356898      -0.470595 -0.900608  0.393896  ...   

       Race_5.0  Race_1.0  Race_4.0  Race_3.0  Race_2.0  Education   Smoking  \
28456       1.0       0.0       0.0       0.0       0.0  -0.012820  0.000000   
8993        0.0       0.0       1.0       0.0       0.0   0.547458  1.000000   
34312       0.0       0.0       0.0       1.0       0.0  -0.659696  0.000000   
4802        1.0       0.0       0.0       0.0       0.0   0.262895  0.073612   
25895       0.0       0.0       0.0       1.0       0.0   1.151035  0.000000   
...         ...       ...       ...       ...       ...        ...       ...   
18045       0.0       0.0       0.0       1.0       0.0  -0.793202  0.000000   
5425        0.0       0.0       1.0       0.0       0.0   0.547458  1.000000   
12819       0.0       0.0       0.0       1.0       0.0   1.151035  1.000000   
33659       0.0       0.0       1.0       0.0       0.0   0.258362  0.000000   
19531       1.0       0.0       0.0       0.0       0.0  -0.821118  0.000000   

       PhysicalActivity  HealthInsurance   Alcohol  
28456          0.660578              0.0 -0.518600  
8993           0.000000              0.0  0.115329  
34312          0.000000              0.0  0.592213  
4802           1.012447              0.0 -0.103347  
25895          0.000000              0.0 -0.886483  
...                 ...              ...       ...  
18045          0.904383              0.0 -0.482716  
5425           1.598141              0.0  0.097790  
12819          1.598141              0.0  0.612947  
33659          1.162475              0.0 -0.154408  
19531          0.791302              0.0 -0.683278  

[13109 rows x 31 columns]
2025-12-03 10:08:02,859:INFO:get_config() successfully completed......................................
2025-12-03 10:08:02,912:INFO:Initializing get_config()
2025-12-03 10:08:02,912:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FAFD711B0>, variable=y_test)
2025-12-03 10:08:02,912:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-12-03 10:08:02,912:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-12-03 10:08:02,919:INFO:Variable:  returned as 28456    0.0
8993     0.0
34312    0.0
4802     0.0
25895    0.0
        ... 
18045    0.0
5425     0.0
12819    0.0
33659    0.0
19531    0.0
Name: HeartDisease, Length: 13109, dtype: float32
2025-12-03 10:08:02,919:INFO:get_config() successfully completed......................................
2025-12-03 10:08:02,938:INFO:Initializing get_config()
2025-12-03 10:08:02,938:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FAFD711B0>, variable=X_test_transformed)
2025-12-03 10:08:03,016:INFO:Variable: X_test returned as             Age  IncomeRatio  SystolicBP       BMI  WaistCircumference  \
28456 -0.477273    -0.304717   -0.519256 -0.987220           -0.923253   
8993   0.818182     0.253271    2.156910  0.770675            0.920394   
34312  0.704545     0.055403    0.519256  0.518044            0.662901   
4802  -0.545455     0.253730   -0.331933 -0.229036           -0.436352   
25895  0.704545     1.226781   -0.093200 -0.226100            0.012322   
...         ...          ...         ...       ...                 ...   
18045 -0.568182    -0.083104   -0.568713 -1.176693           -1.338674   
5425   0.590909     0.362732    2.210168  0.139096            0.292112   
12819  0.909091    -0.019787    0.899042  0.454886            0.971892   
33659 -0.522727     1.060572   -0.525683 -0.587220           -0.906087   
19531 -0.590909    -0.344290   -0.510287 -0.945114           -1.215078   

         Height  TotalCholesterol  Triglycerides       LDL       HDL  ...  \
28456 -1.080540         -0.078535      -0.470757 -0.026922  0.418008  ...   
8993  -0.279669          0.765897       0.705031  0.006026  0.446825  ...   
34312  0.559339         -0.123259       0.929511 -1.031826 -1.404309  ...   
4802  -0.504861         -0.188325      -0.322647  0.000015 -0.138743  ...   
25895  0.216731          0.892919       1.291109  0.008211 -0.255329  ...   
...         ...               ...            ...       ...       ...  ...   
18045 -2.080569         -0.340947      -0.470582 -0.848950  0.393794  ...   
5425   0.156785          0.435639      -0.065356  1.113733  0.127664  ...   
12819  1.194951         -0.732967      -0.470025 -0.211535 -1.085148  ...   
33659 -1.254274         -1.063225      -0.470958 -2.849419  0.127664  ...   
19531 -2.339052         -0.356898      -0.470595 -0.900608  0.393896  ...   

       Race_5.0  Race_1.0  Race_4.0  Race_3.0  Race_2.0  Education   Smoking  \
28456       1.0       0.0       0.0       0.0       0.0  -0.012820  0.000000   
8993        0.0       0.0       1.0       0.0       0.0   0.547458  1.000000   
34312       0.0       0.0       0.0       1.0       0.0  -0.659696  0.000000   
4802        1.0       0.0       0.0       0.0       0.0   0.262895  0.073612   
25895       0.0       0.0       0.0       1.0       0.0   1.151035  0.000000   
...         ...       ...       ...       ...       ...        ...       ...   
18045       0.0       0.0       0.0       1.0       0.0  -0.793202  0.000000   
5425        0.0       0.0       1.0       0.0       0.0   0.547458  1.000000   
12819       0.0       0.0       0.0       1.0       0.0   1.151035  1.000000   
33659       0.0       0.0       1.0       0.0       0.0   0.258362  0.000000   
19531       1.0       0.0       0.0       0.0       0.0  -0.821118  0.000000   

       PhysicalActivity  HealthInsurance   Alcohol  
28456          0.660578              0.0 -0.518600  
8993           0.000000              0.0  0.115329  
34312          0.000000              0.0  0.592213  
4802           1.012447              0.0 -0.103347  
25895          0.000000              0.0 -0.886483  
...                 ...              ...       ...  
18045          0.904383              0.0 -0.482716  
5425           1.598141              0.0  0.097790  
12819          1.598141              0.0  0.612947  
33659          1.162475              0.0 -0.154408  
19531          0.791302              0.0 -0.683278  

[13109 rows x 31 columns]
2025-12-03 10:08:03,017:INFO:get_config() successfully completed......................................
2025-12-03 10:08:03,044:INFO:Initializing get_config()
2025-12-03 10:08:03,044:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FAFD711B0>, variable=y_test)
2025-12-03 10:08:03,044:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-12-03 10:08:03,044:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-12-03 10:08:03,049:INFO:Variable:  returned as 28456    0.0
8993     0.0
34312    0.0
4802     0.0
25895    0.0
        ... 
18045    0.0
5425     0.0
12819    0.0
33659    0.0
19531    0.0
Name: HeartDisease, Length: 13109, dtype: float32
2025-12-03 10:08:03,049:INFO:get_config() successfully completed......................................
2025-12-03 10:08:03,265:INFO:Initializing get_config()
2025-12-03 10:08:03,265:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FAFD711B0>, variable=y_test)
2025-12-03 10:08:03,265:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-12-03 10:08:03,265:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-12-03 10:08:03,274:INFO:Variable:  returned as 28456    0.0
8993     0.0
34312    0.0
4802     0.0
25895    0.0
        ... 
18045    0.0
5425     0.0
12819    0.0
33659    0.0
19531    0.0
Name: HeartDisease, Length: 13109, dtype: float32
2025-12-03 10:08:03,274:INFO:get_config() successfully completed......................................
2025-12-03 10:08:03,274:INFO:Initializing get_config()
2025-12-03 10:08:03,274:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FAFD711B0>, variable=X_test_transformed)
2025-12-03 10:08:03,359:INFO:Variable: X_test returned as             Age  IncomeRatio  SystolicBP       BMI  WaistCircumference  \
28456 -0.477273    -0.304717   -0.519256 -0.987220           -0.923253   
8993   0.818182     0.253271    2.156910  0.770675            0.920394   
34312  0.704545     0.055403    0.519256  0.518044            0.662901   
4802  -0.545455     0.253730   -0.331933 -0.229036           -0.436352   
25895  0.704545     1.226781   -0.093200 -0.226100            0.012322   
...         ...          ...         ...       ...                 ...   
18045 -0.568182    -0.083104   -0.568713 -1.176693           -1.338674   
5425   0.590909     0.362732    2.210168  0.139096            0.292112   
12819  0.909091    -0.019787    0.899042  0.454886            0.971892   
33659 -0.522727     1.060572   -0.525683 -0.587220           -0.906087   
19531 -0.590909    -0.344290   -0.510287 -0.945114           -1.215078   

         Height  TotalCholesterol  Triglycerides       LDL       HDL  ...  \
28456 -1.080540         -0.078535      -0.470757 -0.026922  0.418008  ...   
8993  -0.279669          0.765897       0.705031  0.006026  0.446825  ...   
34312  0.559339         -0.123259       0.929511 -1.031826 -1.404309  ...   
4802  -0.504861         -0.188325      -0.322647  0.000015 -0.138743  ...   
25895  0.216731          0.892919       1.291109  0.008211 -0.255329  ...   
...         ...               ...            ...       ...       ...  ...   
18045 -2.080569         -0.340947      -0.470582 -0.848950  0.393794  ...   
5425   0.156785          0.435639      -0.065356  1.113733  0.127664  ...   
12819  1.194951         -0.732967      -0.470025 -0.211535 -1.085148  ...   
33659 -1.254274         -1.063225      -0.470958 -2.849419  0.127664  ...   
19531 -2.339052         -0.356898      -0.470595 -0.900608  0.393896  ...   

       Race_5.0  Race_1.0  Race_4.0  Race_3.0  Race_2.0  Education   Smoking  \
28456       1.0       0.0       0.0       0.0       0.0  -0.012820  0.000000   
8993        0.0       0.0       1.0       0.0       0.0   0.547458  1.000000   
34312       0.0       0.0       0.0       1.0       0.0  -0.659696  0.000000   
4802        1.0       0.0       0.0       0.0       0.0   0.262895  0.073612   
25895       0.0       0.0       0.0       1.0       0.0   1.151035  0.000000   
...         ...       ...       ...       ...       ...        ...       ...   
18045       0.0       0.0       0.0       1.0       0.0  -0.793202  0.000000   
5425        0.0       0.0       1.0       0.0       0.0   0.547458  1.000000   
12819       0.0       0.0       0.0       1.0       0.0   1.151035  1.000000   
33659       0.0       0.0       1.0       0.0       0.0   0.258362  0.000000   
19531       1.0       0.0       0.0       0.0       0.0  -0.821118  0.000000   

       PhysicalActivity  HealthInsurance   Alcohol  
28456          0.660578              0.0 -0.518600  
8993           0.000000              0.0  0.115329  
34312          0.000000              0.0  0.592213  
4802           1.012447              0.0 -0.103347  
25895          0.000000              0.0 -0.886483  
...                 ...              ...       ...  
18045          0.904383              0.0 -0.482716  
5425           1.598141              0.0  0.097790  
12819          1.598141              0.0  0.612947  
33659          1.162475              0.0 -0.154408  
19531          0.791302              0.0 -0.683278  

[13109 rows x 31 columns]
2025-12-03 10:08:03,359:INFO:get_config() successfully completed......................................
2025-12-03 10:08:03,446:INFO:Initializing get_config()
2025-12-03 10:08:03,446:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FAFD711B0>, variable=X_train_transformed)
2025-12-03 10:08:03,482:INFO:Variable: X_train returned as             Age  IncomeRatio  SystolicBP       BMI  WaistCircumference  \
15208  0.954545     0.854789    0.359485  0.518044            0.206281   
25325 -0.272727     0.253271   -0.812170 -0.966167           -0.799656   
5132   0.181818    -0.407608   -0.372799  0.054886            0.319578   
17217  0.500000    -0.751898    0.013314 -0.260904            0.278379   
6382   0.568182     0.054503    1.131712  2.675938            1.888566   
...         ...          ...         ...       ...                 ...   
6265  -0.545455    -0.431352   -0.591719  0.191728           -0.377368   
42694 -0.022727    -0.221612   -0.892056 -0.260904           -0.047778   
13399  0.454545     0.388518    0.377985  0.271482            0.183567   
39959  0.954545    -0.193911    0.625770  0.991728            1.160720   
6616   0.613636    -0.447182    0.652399 -0.871430           -0.514698   

         Height  TotalCholesterol  Triglycerides       LDL       HDL  ...  \
15208 -0.487303          0.625876       0.583394  0.005397  0.314564  ...   
25325 -0.300856          0.033588      -0.261476  0.000256  0.303682  ...   
5132   0.766972          0.181594       0.479279  0.948690 -1.340476  ...   
17217  0.745785          0.227516       0.346113  0.002441 -0.274561  ...   
6382   0.237295          0.867515       0.635574  0.002754  0.829819  ...   
...         ...               ...            ...       ...       ...  ...   
6265  -1.737339         -1.393483      -0.471046 -3.840886  0.063832  ...   
42694  0.000000          0.029167      -0.131730  0.000893  0.063832  ...   
13399 -0.147405          0.462357       0.380371  0.003925  0.256949  ...   
39959  0.368655          1.528031       1.934134  0.011744  0.191497  ...   
6616  -0.021187         -0.224877      -0.043571 -1.609476  0.510658  ...   

       Race_5.0  Race_1.0  Race_4.0  Race_3.0  Race_2.0  Education  Smoking  \
15208       1.0       0.0       0.0       0.0       0.0  -0.659696      0.0   
25325       0.0       1.0       0.0       0.0       0.0   0.185278      0.0   
5132        0.0       1.0       0.0       0.0       0.0  -0.659696      1.0   
17217       0.0       0.0       1.0       0.0       0.0  -0.056119      1.0   
6382        0.0       0.0       1.0       0.0       0.0   0.547458      1.0   
...         ...       ...       ...       ...       ...        ...      ...   
6265        0.0       1.0       0.0       0.0       0.0  -0.769055      0.0   
42694       0.0       1.0       0.0       0.0       0.0   0.547458      0.0   
13399       0.0       0.0       1.0       0.0       0.0   0.547458      0.0   
39959       0.0       0.0       0.0       1.0       0.0   0.547458      0.0   
6616        0.0       0.0       0.0       1.0       0.0   0.547458      1.0   

       PhysicalActivity  HealthInsurance   Alcohol  
15208          0.000000              0.0 -0.886483  
25325          0.000000              0.0  0.592213  
5132           0.000000             -1.0  0.312949  
17217          0.000000              0.0  0.592213  
6382           0.000000              0.0  0.597293  
...                 ...              ...       ...  
6265           0.662459              0.0 -0.501621  
42694          0.000000             -1.0  0.592213  
13399          0.000000              0.0 -0.224534  
39959          0.000000              0.0  0.592213  
6616           0.000000              0.0  0.290247  

[30586 rows x 31 columns]
2025-12-03 10:08:03,482:INFO:get_config() successfully completed......................................
2025-12-03 10:08:03,508:INFO:Initializing tune_model()
2025-12-03 10:08:03,508:INFO:tune_model(estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...), fold=None, round=4, n_iter=5, custom_grid=None, optimize=Recall, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=False, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FAFD711B0>)
2025-12-03 10:08:03,508:INFO:Checking exceptions
2025-12-03 10:08:03,519:INFO:Copying training dataset
2025-12-03 10:08:03,534:INFO:Checking base model
2025-12-03 10:08:03,534:INFO:Base model : Extreme Gradient Boosting
2025-12-03 10:08:03,534:INFO:Declaring metric variables
2025-12-03 10:08:03,534:INFO:Defining Hyperparameters
2025-12-03 10:08:03,706:INFO:Tuning with n_jobs=1
2025-12-03 10:08:03,706:INFO:Initializing RandomizedSearchCV
2025-12-03 10:08:38,456:INFO:best_params: {'actual_estimator__subsample': 0.7, 'actual_estimator__scale_pos_weight': 38.0, 'actual_estimator__reg_lambda': 0.7, 'actual_estimator__reg_alpha': 0.001, 'actual_estimator__n_estimators': 60, 'actual_estimator__min_child_weight': 1, 'actual_estimator__max_depth': 6, 'actual_estimator__learning_rate': 0.4, 'actual_estimator__colsample_bytree': 0.7}
2025-12-03 10:08:38,459:INFO:Hyperparameter search completed
2025-12-03 10:08:38,459:INFO:SubProcess create_model() called ==================================
2025-12-03 10:08:38,459:INFO:Initializing create_model()
2025-12-03 10:08:38,459:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FAFD711B0>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000018FB020BFA0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'subsample': 0.7, 'scale_pos_weight': 38.0, 'reg_lambda': 0.7, 'reg_alpha': 0.001, 'n_estimators': 60, 'min_child_weight': 1, 'max_depth': 6, 'learning_rate': 0.4, 'colsample_bytree': 0.7})
2025-12-03 10:08:38,459:INFO:Checking exceptions
2025-12-03 10:08:38,459:INFO:Importing libraries
2025-12-03 10:08:38,459:INFO:Copying training dataset
2025-12-03 10:08:38,481:INFO:Defining folds
2025-12-03 10:08:38,483:INFO:Declaring metric variables
2025-12-03 10:08:38,483:INFO:Importing untrained model
2025-12-03 10:08:38,483:INFO:Declaring custom model
2025-12-03 10:08:38,483:INFO:Extreme Gradient Boosting Imported successfully
2025-12-03 10:08:38,483:INFO:Starting cross validation
2025-12-03 10:08:38,484:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-12-03 10:08:43,371:INFO:Calculating mean and std
2025-12-03 10:08:43,371:INFO:Creating metrics dataframe
2025-12-03 10:08:43,373:INFO:Finalizing model
2025-12-03 10:08:43,453:INFO:Warning: No categorical columns found. Calling 'transform' will only return input data.
2025-12-03 10:08:43,860:INFO:Uploading results into container
2025-12-03 10:08:43,861:INFO:Uploading model into container now
2025-12-03 10:08:43,861:INFO:_master_model_container: 4
2025-12-03 10:08:43,861:INFO:_display_container: 5
2025-12-03 10:08:43,861:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=0.7, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=0.4, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=6, max_leaves=None,
              min_child_weight=1, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=60, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2025-12-03 10:08:43,861:INFO:create_model() successfully completed......................................
2025-12-03 10:08:44,050:INFO:SubProcess create_model() end ==================================
2025-12-03 10:08:44,050:INFO:choose_better activated
2025-12-03 10:08:44,050:INFO:SubProcess create_model() called ==================================
2025-12-03 10:08:44,052:INFO:Initializing create_model()
2025-12-03 10:08:44,052:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FAFD711B0>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-03 10:08:44,052:INFO:Checking exceptions
2025-12-03 10:08:44,052:INFO:Importing libraries
2025-12-03 10:08:44,052:INFO:Copying training dataset
2025-12-03 10:08:44,076:INFO:Defining folds
2025-12-03 10:08:44,076:INFO:Declaring metric variables
2025-12-03 10:08:44,076:INFO:Importing untrained model
2025-12-03 10:08:44,076:INFO:Declaring custom model
2025-12-03 10:08:44,076:INFO:Extreme Gradient Boosting Imported successfully
2025-12-03 10:08:44,076:INFO:Starting cross validation
2025-12-03 10:08:44,078:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-12-03 10:08:50,082:INFO:Calculating mean and std
2025-12-03 10:08:50,082:INFO:Creating metrics dataframe
2025-12-03 10:08:50,082:INFO:Finalizing model
2025-12-03 10:08:50,162:INFO:Warning: No categorical columns found. Calling 'transform' will only return input data.
2025-12-03 10:08:50,692:INFO:Uploading results into container
2025-12-03 10:08:50,693:INFO:Uploading model into container now
2025-12-03 10:08:50,693:INFO:_master_model_container: 5
2025-12-03 10:08:50,693:INFO:_display_container: 6
2025-12-03 10:08:50,693:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2025-12-03 10:08:50,693:INFO:create_model() successfully completed......................................
2025-12-03 10:08:50,880:INFO:SubProcess create_model() end ==================================
2025-12-03 10:08:50,881:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...) result for Recall is 0.3112
2025-12-03 10:08:50,881:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=0.7, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=0.4, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=6, max_leaves=None,
              min_child_weight=1, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=60, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...) result for Recall is 0.3316
2025-12-03 10:08:50,882:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=0.7, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=0.4, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=6, max_leaves=None,
              min_child_weight=1, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=60, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...) is best model
2025-12-03 10:08:50,882:INFO:choose_better completed
2025-12-03 10:08:50,882:INFO:_master_model_container: 5
2025-12-03 10:08:50,882:INFO:_display_container: 5
2025-12-03 10:08:50,882:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=0.7, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=0.4, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=6, max_leaves=None,
              min_child_weight=1, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=60, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2025-12-03 10:08:50,882:INFO:tune_model() successfully completed......................................
2025-12-03 10:08:51,081:INFO:Initializing predict_model()
2025-12-03 10:08:51,081:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FAFD711B0>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=0.7, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=0.4, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=6, max_leaves=None,
              min_child_weight=1, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=60, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...), probability_threshold=None, encoded_labels=False, raw_score=True, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000018FAB4AA830>)
2025-12-03 10:08:51,081:INFO:Checking exceptions
2025-12-03 10:08:51,081:INFO:Preloading libraries
2025-12-03 10:08:51,504:INFO:Initializing get_config()
2025-12-03 10:08:51,504:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FAFD711B0>, variable=target_param)
2025-12-03 10:08:51,504:INFO:Variable:  returned as HeartDisease
2025-12-03 10:08:51,504:INFO:get_config() successfully completed......................................
2025-12-03 10:08:52,173:INFO:Initializing interpret_model()
2025-12-03 10:08:52,173:INFO:interpret_model(estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=0.7, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=0.4, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=6, max_leaves=None,
              min_child_weight=1, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=60, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...), use_train_data=False, X_new_sample=None, y_new_sample=None, feature=None, kwargs={}, observation=None, plot=summary, save=False, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FAFD711B0>)
2025-12-03 10:08:52,173:INFO:Checking exceptions
2025-12-03 10:08:52,173:INFO:Soft dependency imported: shap: 0.49.1
2025-12-03 10:08:52,250:INFO:plot type: summary
2025-12-03 10:08:52,250:INFO:Creating TreeExplainer
2025-12-03 10:08:52,264:INFO:Compiling shap values
2025-12-03 10:08:55,618:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:4145: FutureWarning: The NumPy global RNG was seeded by calling `np.random.seed`. In a future version this function will no longer use the global RNG. Pass `rng` explicitly to opt-in to the new behaviour and silence this warning.

2025-12-03 10:08:56,786:INFO:Visual Rendered Successfully
2025-12-03 10:08:56,786:INFO:interpret_model() successfully completed......................................
2025-12-03 10:08:56,989:INFO:Initializing predict_model()
2025-12-03 10:08:56,989:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FAFD711B0>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...), probability_threshold=None, encoded_labels=False, raw_score=True, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000018FB0254160>)
2025-12-03 10:08:56,989:INFO:Checking exceptions
2025-12-03 10:08:56,990:INFO:Preloading libraries
2025-12-03 10:08:57,433:INFO:Initializing get_config()
2025-12-03 10:08:57,435:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FAFD711B0>, variable=target_param)
2025-12-03 10:08:57,436:INFO:Variable:  returned as HeartDisease
2025-12-03 10:08:57,436:INFO:get_config() successfully completed......................................
2025-12-03 10:08:57,562:INFO:Initializing finalize_model()
2025-12-03 10:08:57,562:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FAFD711B0>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=0.7, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=0.4, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=6, max_leaves=None,
              min_child_weight=1, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=60, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2025-12-03 10:08:57,562:INFO:Finalizing XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=0.7, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=0.4, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=6, max_leaves=None,
              min_child_weight=1, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=60, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2025-12-03 10:08:57,580:INFO:Initializing create_model()
2025-12-03 10:08:57,580:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FAFD711B0>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=0.7, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=0.4, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=6, max_leaves=None,
              min_child_weight=1, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=60, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2025-12-03 10:08:57,580:INFO:Checking exceptions
2025-12-03 10:08:57,582:INFO:Importing libraries
2025-12-03 10:08:57,582:INFO:Copying training dataset
2025-12-03 10:08:57,584:INFO:Defining folds
2025-12-03 10:08:57,584:INFO:Declaring metric variables
2025-12-03 10:08:57,585:INFO:Importing untrained model
2025-12-03 10:08:57,585:INFO:Declaring custom model
2025-12-03 10:08:57,585:INFO:Extreme Gradient Boosting Imported successfully
2025-12-03 10:08:57,586:INFO:Cross validation set to False
2025-12-03 10:08:57,586:INFO:Fitting Model
2025-12-03 10:08:57,680:INFO:Warning: No categorical columns found. Calling 'transform' will only return input data.
2025-12-03 10:08:58,208:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'IncomeRatio', 'SystolicBP',
                                             'BMI', 'WaistCircumference',
                                             'Height', 'TotalCholesterol',
                                             'Triglycerides', 'LDL', 'HDL',
                                             'HbA1c', 'Glucose', 'Creatinine',
                                             'UricAcid', 'ALT_Enzyme',
                                             'Albumin', 'Potassium', 'Sodium',
                                             'GGT_Enzyme', 'AST_Enzyme'],
                                    transformer=Si...
                               feature_types=None, gamma=None, grow_policy=None,
                               importance_type=None,
                               interaction_constraints=None, learning_rate=0.4,
                               max_bin=None, max_cat_threshold=None,
                               max_cat_to_onehot=None, max_delta_step=None,
                               max_depth=6, max_leaves=None, min_child_weight=1,
                               missing=nan, monotone_constraints=None,
                               multi_strategy=None, n_estimators=60, n_jobs=1,
                               num_parallel_tree=None,
                               objective='binary:logistic', ...))],
         verbose=False)
2025-12-03 10:08:58,208:INFO:create_model() successfully completed......................................
2025-12-03 10:08:58,381:INFO:_master_model_container: 5
2025-12-03 10:08:58,381:INFO:_display_container: 7
2025-12-03 10:08:58,394:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'IncomeRatio', 'SystolicBP',
                                             'BMI', 'WaistCircumference',
                                             'Height', 'TotalCholesterol',
                                             'Triglycerides', 'LDL', 'HDL',
                                             'HbA1c', 'Glucose', 'Creatinine',
                                             'UricAcid', 'ALT_Enzyme',
                                             'Albumin', 'Potassium', 'Sodium',
                                             'GGT_Enzyme', 'AST_Enzyme'],
                                    transformer=Si...
                               feature_types=None, gamma=None, grow_policy=None,
                               importance_type=None,
                               interaction_constraints=None, learning_rate=0.4,
                               max_bin=None, max_cat_threshold=None,
                               max_cat_to_onehot=None, max_delta_step=None,
                               max_depth=6, max_leaves=None, min_child_weight=1,
                               missing=nan, monotone_constraints=None,
                               multi_strategy=None, n_estimators=60, n_jobs=1,
                               num_parallel_tree=None,
                               objective='binary:logistic', ...))],
         verbose=False)
2025-12-03 10:08:58,394:INFO:finalize_model() successfully completed......................................
2025-12-03 10:08:58,599:INFO:Initializing save_model()
2025-12-03 10:08:58,599:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'IncomeRatio', 'SystolicBP',
                                             'BMI', 'WaistCircumference',
                                             'Height', 'TotalCholesterol',
                                             'Triglycerides', 'LDL', 'HDL',
                                             'HbA1c', 'Glucose', 'Creatinine',
                                             'UricAcid', 'ALT_Enzyme',
                                             'Albumin', 'Potassium', 'Sodium',
                                             'GGT_Enzyme', 'AST_Enzyme'],
                                    transformer=Si...
                               feature_types=None, gamma=None, grow_policy=None,
                               importance_type=None,
                               interaction_constraints=None, learning_rate=0.4,
                               max_bin=None, max_cat_threshold=None,
                               max_cat_to_onehot=None, max_delta_step=None,
                               max_depth=6, max_leaves=None, min_child_weight=1,
                               missing=nan, monotone_constraints=None,
                               multi_strategy=None, n_estimators=60, n_jobs=1,
                               num_parallel_tree=None,
                               objective='binary:logistic', ...))],
         verbose=False), model_name=../models\best_pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\OMAR\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'IncomeRatio', 'SystolicBP',
                                             'BMI', 'WaistCircumference',
                                             'Height', 'TotalCholesterol',
                                             'Triglycerides', 'LDL', 'HDL',
                                             'HbA1c', 'Glucose', 'Creatinine',
                                             'UricAcid', 'ALT_Enzyme',
                                             'Albumin', 'Potassium', 'Sodium',
                                             'G...
                                    transformer=TargetEncoder(cols=[],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=RobustScaler(copy=True,
                                                             quantile_range=(25.0,
                                                                             75.0),
                                                             unit_variance=False,
                                                             with_centering=True,
                                                             with_scaling=True)))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2025-12-03 10:08:58,599:INFO:Adding model into prep_pipe
2025-12-03 10:08:58,599:WARNING:Only Model saved as it was a pipeline.
2025-12-03 10:08:58,607:INFO:../models\best_pipeline.pkl saved in current working directory
2025-12-03 10:08:58,638:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'IncomeRatio', 'SystolicBP',
                                             'BMI', 'WaistCircumference',
                                             'Height', 'TotalCholesterol',
                                             'Triglycerides', 'LDL', 'HDL',
                                             'HbA1c', 'Glucose', 'Creatinine',
                                             'UricAcid', 'ALT_Enzyme',
                                             'Albumin', 'Potassium', 'Sodium',
                                             'GGT_Enzyme', 'AST_Enzyme'],
                                    transformer=Si...
                               feature_types=None, gamma=None, grow_policy=None,
                               importance_type=None,
                               interaction_constraints=None, learning_rate=0.4,
                               max_bin=None, max_cat_threshold=None,
                               max_cat_to_onehot=None, max_delta_step=None,
                               max_depth=6, max_leaves=None, min_child_weight=1,
                               missing=nan, monotone_constraints=None,
                               multi_strategy=None, n_estimators=60, n_jobs=1,
                               num_parallel_tree=None,
                               objective='binary:logistic', ...))],
         verbose=False)
2025-12-03 10:08:58,638:INFO:save_model() successfully completed......................................
2025-12-03 10:17:39,052:INFO:PyCaret ClassificationExperiment
2025-12-03 10:17:39,052:INFO:Logging name: clf-default-name
2025-12-03 10:17:39,052:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-12-03 10:17:39,052:INFO:version 3.3.2
2025-12-03 10:17:39,052:INFO:Initializing setup()
2025-12-03 10:17:39,052:INFO:self.USI: 783f
2025-12-03 10:17:39,052:INFO:self._variable_keys: {'idx', 'html_param', '_available_plots', 'y_test', 'USI', 'target_param', 'memory', 'pipeline', 'n_jobs_param', 'X_test', 'seed', 'is_multiclass', 'gpu_param', 'logging_param', 'y_train', 'log_plots_param', 'X_train', 'gpu_n_jobs_param', 'fix_imbalance', 'exp_name_log', 'fold_shuffle_param', 'fold_groups_param', 'X', 'data', 'fold_generator', 'y', 'exp_id', '_ml_usecase'}
2025-12-03 10:17:39,052:INFO:Checking environment
2025-12-03 10:17:39,052:INFO:python_version: 3.10.19
2025-12-03 10:17:39,052:INFO:python_build: ('main', 'Oct 21 2025 16:41:31')
2025-12-03 10:17:39,052:INFO:machine: AMD64
2025-12-03 10:17:39,052:INFO:platform: Windows-10-10.0.26100-SP0
2025-12-03 10:17:39,053:INFO:Memory: svmem(total=16282144768, available=5661192192, percent=65.2, used=10620952576, free=5661192192)
2025-12-03 10:17:39,053:INFO:Physical Core: 6
2025-12-03 10:17:39,053:INFO:Logical Core: 12
2025-12-03 10:17:39,053:INFO:Checking libraries
2025-12-03 10:17:39,053:INFO:System:
2025-12-03 10:17:39,053:INFO:    python: 3.10.19 | packaged by Anaconda, Inc. | (main, Oct 21 2025, 16:41:31) [MSC v.1929 64 bit (AMD64)]
2025-12-03 10:17:39,053:INFO:executable: c:\Users\OMAR\miniconda3\envs\xgb_env\python.exe
2025-12-03 10:17:39,053:INFO:   machine: Windows-10-10.0.26100-SP0
2025-12-03 10:17:39,053:INFO:PyCaret required dependencies:
2025-12-03 10:17:39,053:INFO:                 pip: 25.3
2025-12-03 10:17:39,053:INFO:          setuptools: 80.9.0
2025-12-03 10:17:39,053:INFO:             pycaret: 3.3.2
2025-12-03 10:17:39,053:INFO:             IPython: 8.37.0
2025-12-03 10:17:39,053:INFO:          ipywidgets: 8.1.8
2025-12-03 10:17:39,053:INFO:                tqdm: 4.67.1
2025-12-03 10:17:39,053:INFO:               numpy: 1.26.4
2025-12-03 10:17:39,053:INFO:              pandas: 2.1.4
2025-12-03 10:17:39,053:INFO:              jinja2: 3.1.6
2025-12-03 10:17:39,053:INFO:               scipy: 1.11.4
2025-12-03 10:17:39,053:INFO:              joblib: 1.3.2
2025-12-03 10:17:39,053:INFO:             sklearn: 1.4.2
2025-12-03 10:17:39,053:INFO:                pyod: 2.0.5
2025-12-03 10:17:39,053:INFO:            imblearn: 0.14.0
2025-12-03 10:17:39,053:INFO:   category_encoders: 2.7.0
2025-12-03 10:17:39,053:INFO:            lightgbm: 4.6.0
2025-12-03 10:17:39,053:INFO:               numba: 0.62.1
2025-12-03 10:17:39,053:INFO:            requests: 2.32.5
2025-12-03 10:17:39,053:INFO:          matplotlib: 3.7.5
2025-12-03 10:17:39,053:INFO:          scikitplot: 0.3.7
2025-12-03 10:17:39,053:INFO:         yellowbrick: 1.5
2025-12-03 10:17:39,053:INFO:              plotly: 5.24.1
2025-12-03 10:17:39,053:INFO:    plotly-resampler: Not installed
2025-12-03 10:17:39,053:INFO:             kaleido: 1.2.0
2025-12-03 10:17:39,053:INFO:           schemdraw: 0.15
2025-12-03 10:17:39,053:INFO:         statsmodels: 0.14.5
2025-12-03 10:17:39,053:INFO:              sktime: 0.26.0
2025-12-03 10:17:39,053:INFO:               tbats: 1.1.3
2025-12-03 10:17:39,054:INFO:            pmdarima: 2.0.4
2025-12-03 10:17:39,054:INFO:              psutil: 7.1.3
2025-12-03 10:17:39,054:INFO:          markupsafe: 3.0.3
2025-12-03 10:17:39,054:INFO:             pickle5: Not installed
2025-12-03 10:17:39,054:INFO:         cloudpickle: 3.1.2
2025-12-03 10:17:39,054:INFO:         deprecation: 2.1.0
2025-12-03 10:17:39,054:INFO:              xxhash: 3.6.0
2025-12-03 10:17:39,054:INFO:           wurlitzer: Not installed
2025-12-03 10:17:39,054:INFO:PyCaret optional dependencies:
2025-12-03 10:17:39,054:INFO:                shap: 0.49.1
2025-12-03 10:17:39,054:INFO:           interpret: 0.7.3
2025-12-03 10:17:39,054:INFO:                umap: 0.5.7
2025-12-03 10:17:39,054:INFO:     ydata_profiling: 4.18.0
2025-12-03 10:17:39,054:INFO:  explainerdashboard: 0.5.1
2025-12-03 10:17:39,054:INFO:             autoviz: Not installed
2025-12-03 10:17:39,054:INFO:           fairlearn: 0.7.0
2025-12-03 10:17:39,054:INFO:          deepchecks: Not installed
2025-12-03 10:17:39,054:INFO:             xgboost: 2.1.3
2025-12-03 10:17:39,054:INFO:            catboost: 1.2.8
2025-12-03 10:17:39,054:INFO:              kmodes: 0.12.2
2025-12-03 10:17:39,054:INFO:             mlxtend: 0.23.4
2025-12-03 10:17:39,054:INFO:       statsforecast: 1.5.0
2025-12-03 10:17:39,054:INFO:        tune_sklearn: Not installed
2025-12-03 10:17:39,054:INFO:                 ray: Not installed
2025-12-03 10:17:39,054:INFO:            hyperopt: 0.2.7
2025-12-03 10:17:39,054:INFO:              optuna: 4.6.0
2025-12-03 10:17:39,055:INFO:               skopt: 0.10.2
2025-12-03 10:17:39,055:INFO:              mlflow: 3.6.0
2025-12-03 10:17:39,055:INFO:              gradio: 6.0.1
2025-12-03 10:17:39,055:INFO:             fastapi: 0.123.0
2025-12-03 10:17:39,055:INFO:             uvicorn: 0.38.0
2025-12-03 10:17:39,055:INFO:              m2cgen: 0.10.0
2025-12-03 10:17:39,055:INFO:           evidently: 0.4.40
2025-12-03 10:17:39,055:INFO:               fugue: 0.8.7
2025-12-03 10:17:39,055:INFO:           streamlit: 1.51.0
2025-12-03 10:17:39,055:INFO:             prophet: Not installed
2025-12-03 10:17:39,055:INFO:None
2025-12-03 10:17:39,055:INFO:Set up data.
2025-12-03 10:17:39,085:INFO:Set up folding strategy.
2025-12-03 10:17:39,086:INFO:Set up train/test split.
2025-12-03 10:17:39,117:INFO:Set up index.
2025-12-03 10:17:39,117:INFO:Assigning column types.
2025-12-03 10:17:39,136:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-12-03 10:17:39,158:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-12-03 10:17:39,158:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-03 10:17:39,180:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-03 10:17:39,182:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-03 10:17:39,208:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-12-03 10:17:39,208:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-03 10:17:39,225:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-03 10:17:39,226:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-03 10:17:39,226:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-12-03 10:17:39,254:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-03 10:17:39,270:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-03 10:17:39,272:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-03 10:17:39,300:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-03 10:17:39,317:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-03 10:17:39,319:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-03 10:17:39,320:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-12-03 10:17:39,362:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-03 10:17:39,364:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-03 10:17:39,409:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-03 10:17:39,409:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-03 10:17:39,409:INFO:Preparing preprocessing pipeline...
2025-12-03 10:17:39,409:INFO:Set up simple imputation.
2025-12-03 10:17:39,428:INFO:Set up encoding of ordinal features.
2025-12-03 10:17:39,436:INFO:Set up encoding of categorical features.
2025-12-03 10:17:39,437:INFO:Set up feature normalization.
2025-12-03 10:17:39,605:INFO:Finished creating preprocessing pipeline.
2025-12-03 10:17:39,619:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\OMAR\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'IncomeRatio', 'SystolicBP',
                                             'BMI', 'WaistCircumference',
                                             'Height', 'TotalCholesterol',
                                             'Triglycerides', 'LDL', 'HDL',
                                             'HbA1c', 'Glucose', 'Creatinine',
                                             'UricAcid', 'ALT_Enzyme',
                                             'Albumin', 'Potassium', 'Sodium',
                                             'G...
                                    transformer=TargetEncoder(cols=[],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=RobustScaler(copy=True,
                                                             quantile_range=(25.0,
                                                                             75.0),
                                                             unit_variance=False,
                                                             with_centering=True,
                                                             with_scaling=True)))],
         verbose=False)
2025-12-03 10:17:39,619:INFO:Creating final display dataframe.
2025-12-03 10:17:39,820:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target      HeartDisease
2                   Target type            Binary
3           Original data shape       (43695, 28)
4        Transformed data shape       (43695, 32)
5   Transformed train set shape       (30586, 32)
6    Transformed test set shape       (13109, 32)
7              Numeric features                20
8          Categorical features                 7
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15                    Normalize              True
16             Normalize method            robust
17               Fold Generator   StratifiedKFold
18                  Fold Number                10
19                     CPU Jobs                 1
20                      Use GPU             False
21               Log Experiment             False
22              Experiment Name  clf-default-name
23                          USI              783f
2025-12-03 10:17:39,869:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-03 10:17:39,870:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-03 10:17:39,908:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-03 10:17:39,914:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-03 10:17:39,914:INFO:setup() successfully completed in 0.87s...............
2025-12-03 10:17:39,959:INFO:Initializing get_config()
2025-12-03 10:17:39,962:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FA2637A00>, variable=y_train)
2025-12-03 10:17:39,962:INFO:Variable: 'y_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_train_transformed' instead.
2025-12-03 10:17:39,962:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_train_transformed' instead.

2025-12-03 10:17:39,971:INFO:Variable:  returned as 15208    0.0
25325    0.0
5132     0.0
17217    0.0
6382     0.0
        ... 
6265     0.0
42694    0.0
13399    0.0
39959    0.0
6616     0.0
Name: HeartDisease, Length: 30586, dtype: float32
2025-12-03 10:17:39,972:INFO:get_config() successfully completed......................................
2025-12-03 10:17:39,972:INFO:Initializing create_model()
2025-12-03 10:17:39,972:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FA2637A00>, estimator=xgboost, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={'scale_pos_weight': 76.32522407170295})
2025-12-03 10:17:39,972:INFO:Checking exceptions
2025-12-03 10:17:39,983:INFO:Importing libraries
2025-12-03 10:17:39,983:INFO:Copying training dataset
2025-12-03 10:17:40,012:INFO:Defining folds
2025-12-03 10:17:40,012:INFO:Declaring metric variables
2025-12-03 10:17:40,015:INFO:Importing untrained model
2025-12-03 10:17:40,021:INFO:Extreme Gradient Boosting Imported successfully
2025-12-03 10:17:40,028:INFO:Starting cross validation
2025-12-03 10:17:40,031:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-12-03 10:17:46,194:INFO:Calculating mean and std
2025-12-03 10:17:46,194:INFO:Creating metrics dataframe
2025-12-03 10:17:46,200:INFO:Finalizing model
2025-12-03 10:17:46,276:INFO:Warning: No categorical columns found. Calling 'transform' will only return input data.
2025-12-03 10:17:46,809:INFO:Uploading results into container
2025-12-03 10:17:46,809:INFO:Uploading model into container now
2025-12-03 10:17:46,818:INFO:_master_model_container: 1
2025-12-03 10:17:46,819:INFO:_display_container: 2
2025-12-03 10:17:46,819:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2025-12-03 10:17:46,819:INFO:create_model() successfully completed......................................
2025-12-03 10:17:47,030:INFO:Initializing create_model()
2025-12-03 10:17:47,030:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FA2637A00>, estimator=lr, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-03 10:17:47,030:INFO:Checking exceptions
2025-12-03 10:17:47,041:INFO:Importing libraries
2025-12-03 10:17:47,041:INFO:Copying training dataset
2025-12-03 10:17:47,074:INFO:Defining folds
2025-12-03 10:17:47,074:INFO:Declaring metric variables
2025-12-03 10:17:47,077:INFO:Importing untrained model
2025-12-03 10:17:47,080:INFO:Logistic Regression Imported successfully
2025-12-03 10:17:47,089:INFO:Starting cross validation
2025-12-03 10:17:47,091:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-12-03 10:17:48,120:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-12-03 10:17:48,710:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-12-03 10:17:49,089:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-12-03 10:17:49,092:INFO:Calculating mean and std
2025-12-03 10:17:49,094:INFO:Creating metrics dataframe
2025-12-03 10:17:49,094:INFO:Finalizing model
2025-12-03 10:17:49,179:INFO:Warning: No categorical columns found. Calling 'transform' will only return input data.
2025-12-03 10:17:49,284:INFO:Uploading results into container
2025-12-03 10:17:49,284:INFO:Uploading model into container now
2025-12-03 10:17:49,291:INFO:_master_model_container: 2
2025-12-03 10:17:49,291:INFO:_display_container: 3
2025-12-03 10:17:49,291:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-12-03 10:17:49,291:INFO:create_model() successfully completed......................................
2025-12-03 10:17:49,458:INFO:Initializing create_model()
2025-12-03 10:17:49,458:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FA2637A00>, estimator=rf, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-03 10:17:49,458:INFO:Checking exceptions
2025-12-03 10:17:49,470:INFO:Importing libraries
2025-12-03 10:17:49,470:INFO:Copying training dataset
2025-12-03 10:17:49,497:INFO:Defining folds
2025-12-03 10:17:49,497:INFO:Declaring metric variables
2025-12-03 10:17:49,500:INFO:Importing untrained model
2025-12-03 10:17:49,506:INFO:Random Forest Classifier Imported successfully
2025-12-03 10:17:49,513:INFO:Starting cross validation
2025-12-03 10:17:49,514:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-12-03 10:18:29,768:INFO:Calculating mean and std
2025-12-03 10:18:29,769:INFO:Creating metrics dataframe
2025-12-03 10:18:29,773:INFO:Finalizing model
2025-12-03 10:18:29,856:INFO:Warning: No categorical columns found. Calling 'transform' will only return input data.
2025-12-03 10:18:34,282:INFO:Uploading results into container
2025-12-03 10:18:34,284:INFO:Uploading model into container now
2025-12-03 10:18:34,291:INFO:_master_model_container: 3
2025-12-03 10:18:34,291:INFO:_display_container: 4
2025-12-03 10:18:34,291:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2025-12-03 10:18:34,291:INFO:create_model() successfully completed......................................
2025-12-03 10:18:34,506:INFO:Initializing get_config()
2025-12-03 10:18:34,506:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FA2637A00>, variable=X_train_transformed)
2025-12-03 10:18:34,549:INFO:Variable: X_train returned as             Age  IncomeRatio  SystolicBP       BMI  WaistCircumference  \
15208  0.954545     0.854789    0.359485  0.518044            0.206281   
25325 -0.272727     0.253271   -0.812170 -0.966167           -0.799656   
5132   0.181818    -0.407608   -0.372799  0.054886            0.319578   
17217  0.500000    -0.751898    0.013314 -0.260904            0.278379   
6382   0.568182     0.054503    1.131712  2.675938            1.888566   
...         ...          ...         ...       ...                 ...   
6265  -0.545455    -0.431352   -0.591719  0.191728           -0.377368   
42694 -0.022727    -0.221612   -0.892056 -0.260904           -0.047778   
13399  0.454545     0.388518    0.377985  0.271482            0.183567   
39959  0.954545    -0.193911    0.625770  0.991728            1.160720   
6616   0.613636    -0.447182    0.652399 -0.871430           -0.514698   

         Height  TotalCholesterol  Triglycerides       LDL       HDL  ...  \
15208 -0.487303          0.625876       0.583394  0.005397  0.314564  ...   
25325 -0.300856          0.033588      -0.261476  0.000256  0.303682  ...   
5132   0.766972          0.181594       0.479279  0.948690 -1.340476  ...   
17217  0.745785          0.227516       0.346113  0.002441 -0.274561  ...   
6382   0.237295          0.867515       0.635574  0.002754  0.829819  ...   
...         ...               ...            ...       ...       ...  ...   
6265  -1.737339         -1.393483      -0.471046 -3.840886  0.063832  ...   
42694  0.000000          0.029167      -0.131730  0.000893  0.063832  ...   
13399 -0.147405          0.462357       0.380371  0.003925  0.256949  ...   
39959  0.368655          1.528031       1.934134  0.011744  0.191497  ...   
6616  -0.021187         -0.224877      -0.043571 -1.609476  0.510658  ...   

       Race_5.0  Race_1.0  Race_4.0  Race_3.0  Race_2.0  Education  Smoking  \
15208       1.0       0.0       0.0       0.0       0.0  -0.659696      0.0   
25325       0.0       1.0       0.0       0.0       0.0   0.185278      0.0   
5132        0.0       1.0       0.0       0.0       0.0  -0.659696      1.0   
17217       0.0       0.0       1.0       0.0       0.0  -0.056119      1.0   
6382        0.0       0.0       1.0       0.0       0.0   0.547458      1.0   
...         ...       ...       ...       ...       ...        ...      ...   
6265        0.0       1.0       0.0       0.0       0.0  -0.769055      0.0   
42694       0.0       1.0       0.0       0.0       0.0   0.547458      0.0   
13399       0.0       0.0       1.0       0.0       0.0   0.547458      0.0   
39959       0.0       0.0       0.0       1.0       0.0   0.547458      0.0   
6616        0.0       0.0       0.0       1.0       0.0   0.547458      1.0   

       PhysicalActivity  HealthInsurance   Alcohol  
15208          0.000000              0.0 -0.886483  
25325          0.000000              0.0  0.592213  
5132           0.000000             -1.0  0.312949  
17217          0.000000              0.0  0.592213  
6382           0.000000              0.0  0.597293  
...                 ...              ...       ...  
6265           0.662459              0.0 -0.501621  
42694          0.000000             -1.0  0.592213  
13399          0.000000              0.0 -0.224534  
39959          0.000000              0.0  0.592213  
6616           0.000000              0.0  0.290247  

[30586 rows x 31 columns]
2025-12-03 10:18:34,549:INFO:get_config() successfully completed......................................
2025-12-03 10:18:34,549:INFO:Initializing get_config()
2025-12-03 10:18:34,549:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FA2637A00>, variable=y_train)
2025-12-03 10:18:34,549:INFO:Variable: 'y_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_train_transformed' instead.
2025-12-03 10:18:34,549:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_train_transformed' instead.

2025-12-03 10:18:34,558:INFO:Variable:  returned as 15208    0.0
25325    0.0
5132     0.0
17217    0.0
6382     0.0
        ... 
6265     0.0
42694    0.0
13399    0.0
39959    0.0
6616     0.0
Name: HeartDisease, Length: 30586, dtype: float32
2025-12-03 10:18:34,558:INFO:get_config() successfully completed......................................
2025-12-03 10:18:34,562:INFO:Initializing get_config()
2025-12-03 10:18:34,562:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FA2637A00>, variable=X_test_transformed)
2025-12-03 10:18:34,639:INFO:Variable: X_test returned as             Age  IncomeRatio  SystolicBP       BMI  WaistCircumference  \
28456 -0.477273    -0.304717   -0.519256 -0.987220           -0.923253   
8993   0.818182     0.253271    2.156910  0.770675            0.920394   
34312  0.704545     0.055403    0.519256  0.518044            0.662901   
4802  -0.545455     0.253730   -0.331933 -0.229036           -0.436352   
25895  0.704545     1.226781   -0.093200 -0.226100            0.012322   
...         ...          ...         ...       ...                 ...   
18045 -0.568182    -0.083104   -0.568713 -1.176693           -1.338674   
5425   0.590909     0.362732    2.210168  0.139096            0.292112   
12819  0.909091    -0.019787    0.899042  0.454886            0.971892   
33659 -0.522727     1.060572   -0.525683 -0.587220           -0.906087   
19531 -0.590909    -0.344290   -0.510287 -0.945114           -1.215078   

         Height  TotalCholesterol  Triglycerides       LDL       HDL  ...  \
28456 -1.080540         -0.078535      -0.470757 -0.026922  0.418008  ...   
8993  -0.279669          0.765897       0.705031  0.006026  0.446825  ...   
34312  0.559339         -0.123259       0.929511 -1.031826 -1.404309  ...   
4802  -0.504861         -0.188325      -0.322647  0.000015 -0.138743  ...   
25895  0.216731          0.892919       1.291109  0.008211 -0.255329  ...   
...         ...               ...            ...       ...       ...  ...   
18045 -2.080569         -0.340947      -0.470582 -0.848950  0.393794  ...   
5425   0.156785          0.435639      -0.065356  1.113733  0.127664  ...   
12819  1.194951         -0.732967      -0.470025 -0.211535 -1.085148  ...   
33659 -1.254274         -1.063225      -0.470958 -2.849419  0.127664  ...   
19531 -2.339052         -0.356898      -0.470595 -0.900608  0.393896  ...   

       Race_5.0  Race_1.0  Race_4.0  Race_3.0  Race_2.0  Education   Smoking  \
28456       1.0       0.0       0.0       0.0       0.0  -0.012820  0.000000   
8993        0.0       0.0       1.0       0.0       0.0   0.547458  1.000000   
34312       0.0       0.0       0.0       1.0       0.0  -0.659696  0.000000   
4802        1.0       0.0       0.0       0.0       0.0   0.262895  0.073612   
25895       0.0       0.0       0.0       1.0       0.0   1.151035  0.000000   
...         ...       ...       ...       ...       ...        ...       ...   
18045       0.0       0.0       0.0       1.0       0.0  -0.793202  0.000000   
5425        0.0       0.0       1.0       0.0       0.0   0.547458  1.000000   
12819       0.0       0.0       0.0       1.0       0.0   1.151035  1.000000   
33659       0.0       0.0       1.0       0.0       0.0   0.258362  0.000000   
19531       1.0       0.0       0.0       0.0       0.0  -0.821118  0.000000   

       PhysicalActivity  HealthInsurance   Alcohol  
28456          0.660578              0.0 -0.518600  
8993           0.000000              0.0  0.115329  
34312          0.000000              0.0  0.592213  
4802           1.012447              0.0 -0.103347  
25895          0.000000              0.0 -0.886483  
...                 ...              ...       ...  
18045          0.904383              0.0 -0.482716  
5425           1.598141              0.0  0.097790  
12819          1.598141              0.0  0.612947  
33659          1.162475              0.0 -0.154408  
19531          0.791302              0.0 -0.683278  

[13109 rows x 31 columns]
2025-12-03 10:18:34,639:INFO:get_config() successfully completed......................................
2025-12-03 10:18:34,639:INFO:Initializing get_config()
2025-12-03 10:18:34,639:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FA2637A00>, variable=y_test)
2025-12-03 10:18:34,639:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-12-03 10:18:34,639:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-12-03 10:18:34,644:INFO:Variable:  returned as 28456    0.0
8993     0.0
34312    0.0
4802     0.0
25895    0.0
        ... 
18045    0.0
5425     0.0
12819    0.0
33659    0.0
19531    0.0
Name: HeartDisease, Length: 13109, dtype: float32
2025-12-03 10:18:34,644:INFO:get_config() successfully completed......................................
2025-12-03 10:18:34,796:INFO:Initializing get_config()
2025-12-03 10:18:34,796:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FA2637A00>, variable=X_train_transformed)
2025-12-03 10:18:34,838:INFO:Variable: X_train returned as             Age  IncomeRatio  SystolicBP       BMI  WaistCircumference  \
15208  0.954545     0.854789    0.359485  0.518044            0.206281   
25325 -0.272727     0.253271   -0.812170 -0.966167           -0.799656   
5132   0.181818    -0.407608   -0.372799  0.054886            0.319578   
17217  0.500000    -0.751898    0.013314 -0.260904            0.278379   
6382   0.568182     0.054503    1.131712  2.675938            1.888566   
...         ...          ...         ...       ...                 ...   
6265  -0.545455    -0.431352   -0.591719  0.191728           -0.377368   
42694 -0.022727    -0.221612   -0.892056 -0.260904           -0.047778   
13399  0.454545     0.388518    0.377985  0.271482            0.183567   
39959  0.954545    -0.193911    0.625770  0.991728            1.160720   
6616   0.613636    -0.447182    0.652399 -0.871430           -0.514698   

         Height  TotalCholesterol  Triglycerides       LDL       HDL  ...  \
15208 -0.487303          0.625876       0.583394  0.005397  0.314564  ...   
25325 -0.300856          0.033588      -0.261476  0.000256  0.303682  ...   
5132   0.766972          0.181594       0.479279  0.948690 -1.340476  ...   
17217  0.745785          0.227516       0.346113  0.002441 -0.274561  ...   
6382   0.237295          0.867515       0.635574  0.002754  0.829819  ...   
...         ...               ...            ...       ...       ...  ...   
6265  -1.737339         -1.393483      -0.471046 -3.840886  0.063832  ...   
42694  0.000000          0.029167      -0.131730  0.000893  0.063832  ...   
13399 -0.147405          0.462357       0.380371  0.003925  0.256949  ...   
39959  0.368655          1.528031       1.934134  0.011744  0.191497  ...   
6616  -0.021187         -0.224877      -0.043571 -1.609476  0.510658  ...   

       Race_5.0  Race_1.0  Race_4.0  Race_3.0  Race_2.0  Education  Smoking  \
15208       1.0       0.0       0.0       0.0       0.0  -0.659696      0.0   
25325       0.0       1.0       0.0       0.0       0.0   0.185278      0.0   
5132        0.0       1.0       0.0       0.0       0.0  -0.659696      1.0   
17217       0.0       0.0       1.0       0.0       0.0  -0.056119      1.0   
6382        0.0       0.0       1.0       0.0       0.0   0.547458      1.0   
...         ...       ...       ...       ...       ...        ...      ...   
6265        0.0       1.0       0.0       0.0       0.0  -0.769055      0.0   
42694       0.0       1.0       0.0       0.0       0.0   0.547458      0.0   
13399       0.0       0.0       1.0       0.0       0.0   0.547458      0.0   
39959       0.0       0.0       0.0       1.0       0.0   0.547458      0.0   
6616        0.0       0.0       0.0       1.0       0.0   0.547458      1.0   

       PhysicalActivity  HealthInsurance   Alcohol  
15208          0.000000              0.0 -0.886483  
25325          0.000000              0.0  0.592213  
5132           0.000000             -1.0  0.312949  
17217          0.000000              0.0  0.592213  
6382           0.000000              0.0  0.597293  
...                 ...              ...       ...  
6265           0.662459              0.0 -0.501621  
42694          0.000000             -1.0  0.592213  
13399          0.000000              0.0 -0.224534  
39959          0.000000              0.0  0.592213  
6616           0.000000              0.0  0.290247  

[30586 rows x 31 columns]
2025-12-03 10:18:34,838:INFO:get_config() successfully completed......................................
2025-12-03 10:18:34,838:INFO:Initializing get_config()
2025-12-03 10:18:34,838:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FA2637A00>, variable=y_train)
2025-12-03 10:18:34,838:INFO:Variable: 'y_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_train_transformed' instead.
2025-12-03 10:18:34,841:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_train_transformed' instead.

2025-12-03 10:18:34,845:INFO:Variable:  returned as 15208    0.0
25325    0.0
5132     0.0
17217    0.0
6382     0.0
        ... 
6265     0.0
42694    0.0
13399    0.0
39959    0.0
6616     0.0
Name: HeartDisease, Length: 30586, dtype: float32
2025-12-03 10:18:34,845:INFO:get_config() successfully completed......................................
2025-12-03 10:18:34,850:INFO:Initializing get_config()
2025-12-03 10:18:34,850:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FA2637A00>, variable=X_test_transformed)
2025-12-03 10:18:34,923:INFO:Variable: X_test returned as             Age  IncomeRatio  SystolicBP       BMI  WaistCircumference  \
28456 -0.477273    -0.304717   -0.519256 -0.987220           -0.923253   
8993   0.818182     0.253271    2.156910  0.770675            0.920394   
34312  0.704545     0.055403    0.519256  0.518044            0.662901   
4802  -0.545455     0.253730   -0.331933 -0.229036           -0.436352   
25895  0.704545     1.226781   -0.093200 -0.226100            0.012322   
...         ...          ...         ...       ...                 ...   
18045 -0.568182    -0.083104   -0.568713 -1.176693           -1.338674   
5425   0.590909     0.362732    2.210168  0.139096            0.292112   
12819  0.909091    -0.019787    0.899042  0.454886            0.971892   
33659 -0.522727     1.060572   -0.525683 -0.587220           -0.906087   
19531 -0.590909    -0.344290   -0.510287 -0.945114           -1.215078   

         Height  TotalCholesterol  Triglycerides       LDL       HDL  ...  \
28456 -1.080540         -0.078535      -0.470757 -0.026922  0.418008  ...   
8993  -0.279669          0.765897       0.705031  0.006026  0.446825  ...   
34312  0.559339         -0.123259       0.929511 -1.031826 -1.404309  ...   
4802  -0.504861         -0.188325      -0.322647  0.000015 -0.138743  ...   
25895  0.216731          0.892919       1.291109  0.008211 -0.255329  ...   
...         ...               ...            ...       ...       ...  ...   
18045 -2.080569         -0.340947      -0.470582 -0.848950  0.393794  ...   
5425   0.156785          0.435639      -0.065356  1.113733  0.127664  ...   
12819  1.194951         -0.732967      -0.470025 -0.211535 -1.085148  ...   
33659 -1.254274         -1.063225      -0.470958 -2.849419  0.127664  ...   
19531 -2.339052         -0.356898      -0.470595 -0.900608  0.393896  ...   

       Race_5.0  Race_1.0  Race_4.0  Race_3.0  Race_2.0  Education   Smoking  \
28456       1.0       0.0       0.0       0.0       0.0  -0.012820  0.000000   
8993        0.0       0.0       1.0       0.0       0.0   0.547458  1.000000   
34312       0.0       0.0       0.0       1.0       0.0  -0.659696  0.000000   
4802        1.0       0.0       0.0       0.0       0.0   0.262895  0.073612   
25895       0.0       0.0       0.0       1.0       0.0   1.151035  0.000000   
...         ...       ...       ...       ...       ...        ...       ...   
18045       0.0       0.0       0.0       1.0       0.0  -0.793202  0.000000   
5425        0.0       0.0       1.0       0.0       0.0   0.547458  1.000000   
12819       0.0       0.0       0.0       1.0       0.0   1.151035  1.000000   
33659       0.0       0.0       1.0       0.0       0.0   0.258362  0.000000   
19531       1.0       0.0       0.0       0.0       0.0  -0.821118  0.000000   

       PhysicalActivity  HealthInsurance   Alcohol  
28456          0.660578              0.0 -0.518600  
8993           0.000000              0.0  0.115329  
34312          0.000000              0.0  0.592213  
4802           1.012447              0.0 -0.103347  
25895          0.000000              0.0 -0.886483  
...                 ...              ...       ...  
18045          0.904383              0.0 -0.482716  
5425           1.598141              0.0  0.097790  
12819          1.598141              0.0  0.612947  
33659          1.162475              0.0 -0.154408  
19531          0.791302              0.0 -0.683278  

[13109 rows x 31 columns]
2025-12-03 10:18:34,923:INFO:get_config() successfully completed......................................
2025-12-03 10:18:34,923:INFO:Initializing get_config()
2025-12-03 10:18:34,923:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FA2637A00>, variable=y_test)
2025-12-03 10:18:34,923:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-12-03 10:18:34,923:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-12-03 10:18:34,930:INFO:Variable:  returned as 28456    0.0
8993     0.0
34312    0.0
4802     0.0
25895    0.0
        ... 
18045    0.0
5425     0.0
12819    0.0
33659    0.0
19531    0.0
Name: HeartDisease, Length: 13109, dtype: float32
2025-12-03 10:18:34,930:INFO:get_config() successfully completed......................................
2025-12-03 10:18:35,055:INFO:Initializing get_config()
2025-12-03 10:18:35,056:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FA2637A00>, variable=X_test_transformed)
2025-12-03 10:18:35,131:INFO:Variable: X_test returned as             Age  IncomeRatio  SystolicBP       BMI  WaistCircumference  \
28456 -0.477273    -0.304717   -0.519256 -0.987220           -0.923253   
8993   0.818182     0.253271    2.156910  0.770675            0.920394   
34312  0.704545     0.055403    0.519256  0.518044            0.662901   
4802  -0.545455     0.253730   -0.331933 -0.229036           -0.436352   
25895  0.704545     1.226781   -0.093200 -0.226100            0.012322   
...         ...          ...         ...       ...                 ...   
18045 -0.568182    -0.083104   -0.568713 -1.176693           -1.338674   
5425   0.590909     0.362732    2.210168  0.139096            0.292112   
12819  0.909091    -0.019787    0.899042  0.454886            0.971892   
33659 -0.522727     1.060572   -0.525683 -0.587220           -0.906087   
19531 -0.590909    -0.344290   -0.510287 -0.945114           -1.215078   

         Height  TotalCholesterol  Triglycerides       LDL       HDL  ...  \
28456 -1.080540         -0.078535      -0.470757 -0.026922  0.418008  ...   
8993  -0.279669          0.765897       0.705031  0.006026  0.446825  ...   
34312  0.559339         -0.123259       0.929511 -1.031826 -1.404309  ...   
4802  -0.504861         -0.188325      -0.322647  0.000015 -0.138743  ...   
25895  0.216731          0.892919       1.291109  0.008211 -0.255329  ...   
...         ...               ...            ...       ...       ...  ...   
18045 -2.080569         -0.340947      -0.470582 -0.848950  0.393794  ...   
5425   0.156785          0.435639      -0.065356  1.113733  0.127664  ...   
12819  1.194951         -0.732967      -0.470025 -0.211535 -1.085148  ...   
33659 -1.254274         -1.063225      -0.470958 -2.849419  0.127664  ...   
19531 -2.339052         -0.356898      -0.470595 -0.900608  0.393896  ...   

       Race_5.0  Race_1.0  Race_4.0  Race_3.0  Race_2.0  Education   Smoking  \
28456       1.0       0.0       0.0       0.0       0.0  -0.012820  0.000000   
8993        0.0       0.0       1.0       0.0       0.0   0.547458  1.000000   
34312       0.0       0.0       0.0       1.0       0.0  -0.659696  0.000000   
4802        1.0       0.0       0.0       0.0       0.0   0.262895  0.073612   
25895       0.0       0.0       0.0       1.0       0.0   1.151035  0.000000   
...         ...       ...       ...       ...       ...        ...       ...   
18045       0.0       0.0       0.0       1.0       0.0  -0.793202  0.000000   
5425        0.0       0.0       1.0       0.0       0.0   0.547458  1.000000   
12819       0.0       0.0       0.0       1.0       0.0   1.151035  1.000000   
33659       0.0       0.0       1.0       0.0       0.0   0.258362  0.000000   
19531       1.0       0.0       0.0       0.0       0.0  -0.821118  0.000000   

       PhysicalActivity  HealthInsurance   Alcohol  
28456          0.660578              0.0 -0.518600  
8993           0.000000              0.0  0.115329  
34312          0.000000              0.0  0.592213  
4802           1.012447              0.0 -0.103347  
25895          0.000000              0.0 -0.886483  
...                 ...              ...       ...  
18045          0.904383              0.0 -0.482716  
5425           1.598141              0.0  0.097790  
12819          1.598141              0.0  0.612947  
33659          1.162475              0.0 -0.154408  
19531          0.791302              0.0 -0.683278  

[13109 rows x 31 columns]
2025-12-03 10:18:35,131:INFO:get_config() successfully completed......................................
2025-12-03 10:18:35,156:INFO:Initializing get_config()
2025-12-03 10:18:35,156:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FA2637A00>, variable=y_test)
2025-12-03 10:18:35,158:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-12-03 10:18:35,158:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-12-03 10:18:35,162:INFO:Variable:  returned as 28456    0.0
8993     0.0
34312    0.0
4802     0.0
25895    0.0
        ... 
18045    0.0
5425     0.0
12819    0.0
33659    0.0
19531    0.0
Name: HeartDisease, Length: 13109, dtype: float32
2025-12-03 10:18:35,162:INFO:get_config() successfully completed......................................
2025-12-03 10:18:35,162:INFO:Initializing get_config()
2025-12-03 10:18:35,162:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FA2637A00>, variable=y_test)
2025-12-03 10:18:35,162:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-12-03 10:18:35,162:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-12-03 10:18:35,170:INFO:Variable:  returned as 28456    0.0
8993     0.0
34312    0.0
4802     0.0
25895    0.0
        ... 
18045    0.0
5425     0.0
12819    0.0
33659    0.0
19531    0.0
Name: HeartDisease, Length: 13109, dtype: float32
2025-12-03 10:18:35,170:INFO:get_config() successfully completed......................................
2025-12-03 10:18:35,170:INFO:Initializing get_config()
2025-12-03 10:18:35,170:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FA2637A00>, variable=X_test_transformed)
2025-12-03 10:18:35,244:INFO:Variable: X_test returned as             Age  IncomeRatio  SystolicBP       BMI  WaistCircumference  \
28456 -0.477273    -0.304717   -0.519256 -0.987220           -0.923253   
8993   0.818182     0.253271    2.156910  0.770675            0.920394   
34312  0.704545     0.055403    0.519256  0.518044            0.662901   
4802  -0.545455     0.253730   -0.331933 -0.229036           -0.436352   
25895  0.704545     1.226781   -0.093200 -0.226100            0.012322   
...         ...          ...         ...       ...                 ...   
18045 -0.568182    -0.083104   -0.568713 -1.176693           -1.338674   
5425   0.590909     0.362732    2.210168  0.139096            0.292112   
12819  0.909091    -0.019787    0.899042  0.454886            0.971892   
33659 -0.522727     1.060572   -0.525683 -0.587220           -0.906087   
19531 -0.590909    -0.344290   -0.510287 -0.945114           -1.215078   

         Height  TotalCholesterol  Triglycerides       LDL       HDL  ...  \
28456 -1.080540         -0.078535      -0.470757 -0.026922  0.418008  ...   
8993  -0.279669          0.765897       0.705031  0.006026  0.446825  ...   
34312  0.559339         -0.123259       0.929511 -1.031826 -1.404309  ...   
4802  -0.504861         -0.188325      -0.322647  0.000015 -0.138743  ...   
25895  0.216731          0.892919       1.291109  0.008211 -0.255329  ...   
...         ...               ...            ...       ...       ...  ...   
18045 -2.080569         -0.340947      -0.470582 -0.848950  0.393794  ...   
5425   0.156785          0.435639      -0.065356  1.113733  0.127664  ...   
12819  1.194951         -0.732967      -0.470025 -0.211535 -1.085148  ...   
33659 -1.254274         -1.063225      -0.470958 -2.849419  0.127664  ...   
19531 -2.339052         -0.356898      -0.470595 -0.900608  0.393896  ...   

       Race_5.0  Race_1.0  Race_4.0  Race_3.0  Race_2.0  Education   Smoking  \
28456       1.0       0.0       0.0       0.0       0.0  -0.012820  0.000000   
8993        0.0       0.0       1.0       0.0       0.0   0.547458  1.000000   
34312       0.0       0.0       0.0       1.0       0.0  -0.659696  0.000000   
4802        1.0       0.0       0.0       0.0       0.0   0.262895  0.073612   
25895       0.0       0.0       0.0       1.0       0.0   1.151035  0.000000   
...         ...       ...       ...       ...       ...        ...       ...   
18045       0.0       0.0       0.0       1.0       0.0  -0.793202  0.000000   
5425        0.0       0.0       1.0       0.0       0.0   0.547458  1.000000   
12819       0.0       0.0       0.0       1.0       0.0   1.151035  1.000000   
33659       0.0       0.0       1.0       0.0       0.0   0.258362  0.000000   
19531       1.0       0.0       0.0       0.0       0.0  -0.821118  0.000000   

       PhysicalActivity  HealthInsurance   Alcohol  
28456          0.660578              0.0 -0.518600  
8993           0.000000              0.0  0.115329  
34312          0.000000              0.0  0.592213  
4802           1.012447              0.0 -0.103347  
25895          0.000000              0.0 -0.886483  
...                 ...              ...       ...  
18045          0.904383              0.0 -0.482716  
5425           1.598141              0.0  0.097790  
12819          1.598141              0.0  0.612947  
33659          1.162475              0.0 -0.154408  
19531          0.791302              0.0 -0.683278  

[13109 rows x 31 columns]
2025-12-03 10:18:35,244:INFO:get_config() successfully completed......................................
2025-12-03 10:18:35,244:INFO:Initializing get_config()
2025-12-03 10:18:35,244:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FA2637A00>, variable=y_test)
2025-12-03 10:18:35,248:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-12-03 10:18:35,248:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-12-03 10:18:35,252:INFO:Variable:  returned as 28456    0.0
8993     0.0
34312    0.0
4802     0.0
25895    0.0
        ... 
18045    0.0
5425     0.0
12819    0.0
33659    0.0
19531    0.0
Name: HeartDisease, Length: 13109, dtype: float32
2025-12-03 10:18:35,252:INFO:get_config() successfully completed......................................
2025-12-03 10:18:35,255:INFO:Initializing get_config()
2025-12-03 10:18:35,255:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FA2637A00>, variable=y_test)
2025-12-03 10:18:35,256:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-12-03 10:18:35,256:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-12-03 10:18:35,258:INFO:Variable:  returned as 28456    0.0
8993     0.0
34312    0.0
4802     0.0
25895    0.0
        ... 
18045    0.0
5425     0.0
12819    0.0
33659    0.0
19531    0.0
Name: HeartDisease, Length: 13109, dtype: float32
2025-12-03 10:18:35,258:INFO:get_config() successfully completed......................................
2025-12-03 10:18:35,262:INFO:Initializing get_config()
2025-12-03 10:18:35,262:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FA2637A00>, variable=X_test_transformed)
2025-12-03 10:18:35,338:INFO:Variable: X_test returned as             Age  IncomeRatio  SystolicBP       BMI  WaistCircumference  \
28456 -0.477273    -0.304717   -0.519256 -0.987220           -0.923253   
8993   0.818182     0.253271    2.156910  0.770675            0.920394   
34312  0.704545     0.055403    0.519256  0.518044            0.662901   
4802  -0.545455     0.253730   -0.331933 -0.229036           -0.436352   
25895  0.704545     1.226781   -0.093200 -0.226100            0.012322   
...         ...          ...         ...       ...                 ...   
18045 -0.568182    -0.083104   -0.568713 -1.176693           -1.338674   
5425   0.590909     0.362732    2.210168  0.139096            0.292112   
12819  0.909091    -0.019787    0.899042  0.454886            0.971892   
33659 -0.522727     1.060572   -0.525683 -0.587220           -0.906087   
19531 -0.590909    -0.344290   -0.510287 -0.945114           -1.215078   

         Height  TotalCholesterol  Triglycerides       LDL       HDL  ...  \
28456 -1.080540         -0.078535      -0.470757 -0.026922  0.418008  ...   
8993  -0.279669          0.765897       0.705031  0.006026  0.446825  ...   
34312  0.559339         -0.123259       0.929511 -1.031826 -1.404309  ...   
4802  -0.504861         -0.188325      -0.322647  0.000015 -0.138743  ...   
25895  0.216731          0.892919       1.291109  0.008211 -0.255329  ...   
...         ...               ...            ...       ...       ...  ...   
18045 -2.080569         -0.340947      -0.470582 -0.848950  0.393794  ...   
5425   0.156785          0.435639      -0.065356  1.113733  0.127664  ...   
12819  1.194951         -0.732967      -0.470025 -0.211535 -1.085148  ...   
33659 -1.254274         -1.063225      -0.470958 -2.849419  0.127664  ...   
19531 -2.339052         -0.356898      -0.470595 -0.900608  0.393896  ...   

       Race_5.0  Race_1.0  Race_4.0  Race_3.0  Race_2.0  Education   Smoking  \
28456       1.0       0.0       0.0       0.0       0.0  -0.012820  0.000000   
8993        0.0       0.0       1.0       0.0       0.0   0.547458  1.000000   
34312       0.0       0.0       0.0       1.0       0.0  -0.659696  0.000000   
4802        1.0       0.0       0.0       0.0       0.0   0.262895  0.073612   
25895       0.0       0.0       0.0       1.0       0.0   1.151035  0.000000   
...         ...       ...       ...       ...       ...        ...       ...   
18045       0.0       0.0       0.0       1.0       0.0  -0.793202  0.000000   
5425        0.0       0.0       1.0       0.0       0.0   0.547458  1.000000   
12819       0.0       0.0       0.0       1.0       0.0   1.151035  1.000000   
33659       0.0       0.0       1.0       0.0       0.0   0.258362  0.000000   
19531       1.0       0.0       0.0       0.0       0.0  -0.821118  0.000000   

       PhysicalActivity  HealthInsurance   Alcohol  
28456          0.660578              0.0 -0.518600  
8993           0.000000              0.0  0.115329  
34312          0.000000              0.0  0.592213  
4802           1.012447              0.0 -0.103347  
25895          0.000000              0.0 -0.886483  
...                 ...              ...       ...  
18045          0.904383              0.0 -0.482716  
5425           1.598141              0.0  0.097790  
12819          1.598141              0.0  0.612947  
33659          1.162475              0.0 -0.154408  
19531          0.791302              0.0 -0.683278  

[13109 rows x 31 columns]
2025-12-03 10:18:35,338:INFO:get_config() successfully completed......................................
2025-12-03 10:18:35,394:INFO:Initializing get_config()
2025-12-03 10:18:35,394:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FA2637A00>, variable=y_test)
2025-12-03 10:18:35,394:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-12-03 10:18:35,394:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-12-03 10:18:35,402:INFO:Variable:  returned as 28456    0.0
8993     0.0
34312    0.0
4802     0.0
25895    0.0
        ... 
18045    0.0
5425     0.0
12819    0.0
33659    0.0
19531    0.0
Name: HeartDisease, Length: 13109, dtype: float32
2025-12-03 10:18:35,403:INFO:get_config() successfully completed......................................
2025-12-03 10:18:35,406:INFO:Initializing get_config()
2025-12-03 10:18:35,406:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FA2637A00>, variable=y_test)
2025-12-03 10:18:35,406:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-12-03 10:18:35,406:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-12-03 10:18:35,409:INFO:Variable:  returned as 28456    0.0
8993     0.0
34312    0.0
4802     0.0
25895    0.0
        ... 
18045    0.0
5425     0.0
12819    0.0
33659    0.0
19531    0.0
Name: HeartDisease, Length: 13109, dtype: float32
2025-12-03 10:18:35,409:INFO:get_config() successfully completed......................................
2025-12-03 10:18:35,417:INFO:Initializing get_config()
2025-12-03 10:18:35,417:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FA2637A00>, variable=y_test)
2025-12-03 10:18:35,417:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-12-03 10:18:35,417:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-12-03 10:18:35,423:INFO:Variable:  returned as 28456    0.0
8993     0.0
34312    0.0
4802     0.0
25895    0.0
        ... 
18045    0.0
5425     0.0
12819    0.0
33659    0.0
19531    0.0
Name: HeartDisease, Length: 13109, dtype: float32
2025-12-03 10:18:35,423:INFO:get_config() successfully completed......................................
2025-12-03 10:18:35,425:INFO:Initializing get_config()
2025-12-03 10:18:35,425:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FA2637A00>, variable=X_test_transformed)
2025-12-03 10:18:35,506:INFO:Variable: X_test returned as             Age  IncomeRatio  SystolicBP       BMI  WaistCircumference  \
28456 -0.477273    -0.304717   -0.519256 -0.987220           -0.923253   
8993   0.818182     0.253271    2.156910  0.770675            0.920394   
34312  0.704545     0.055403    0.519256  0.518044            0.662901   
4802  -0.545455     0.253730   -0.331933 -0.229036           -0.436352   
25895  0.704545     1.226781   -0.093200 -0.226100            0.012322   
...         ...          ...         ...       ...                 ...   
18045 -0.568182    -0.083104   -0.568713 -1.176693           -1.338674   
5425   0.590909     0.362732    2.210168  0.139096            0.292112   
12819  0.909091    -0.019787    0.899042  0.454886            0.971892   
33659 -0.522727     1.060572   -0.525683 -0.587220           -0.906087   
19531 -0.590909    -0.344290   -0.510287 -0.945114           -1.215078   

         Height  TotalCholesterol  Triglycerides       LDL       HDL  ...  \
28456 -1.080540         -0.078535      -0.470757 -0.026922  0.418008  ...   
8993  -0.279669          0.765897       0.705031  0.006026  0.446825  ...   
34312  0.559339         -0.123259       0.929511 -1.031826 -1.404309  ...   
4802  -0.504861         -0.188325      -0.322647  0.000015 -0.138743  ...   
25895  0.216731          0.892919       1.291109  0.008211 -0.255329  ...   
...         ...               ...            ...       ...       ...  ...   
18045 -2.080569         -0.340947      -0.470582 -0.848950  0.393794  ...   
5425   0.156785          0.435639      -0.065356  1.113733  0.127664  ...   
12819  1.194951         -0.732967      -0.470025 -0.211535 -1.085148  ...   
33659 -1.254274         -1.063225      -0.470958 -2.849419  0.127664  ...   
19531 -2.339052         -0.356898      -0.470595 -0.900608  0.393896  ...   

       Race_5.0  Race_1.0  Race_4.0  Race_3.0  Race_2.0  Education   Smoking  \
28456       1.0       0.0       0.0       0.0       0.0  -0.012820  0.000000   
8993        0.0       0.0       1.0       0.0       0.0   0.547458  1.000000   
34312       0.0       0.0       0.0       1.0       0.0  -0.659696  0.000000   
4802        1.0       0.0       0.0       0.0       0.0   0.262895  0.073612   
25895       0.0       0.0       0.0       1.0       0.0   1.151035  0.000000   
...         ...       ...       ...       ...       ...        ...       ...   
18045       0.0       0.0       0.0       1.0       0.0  -0.793202  0.000000   
5425        0.0       0.0       1.0       0.0       0.0   0.547458  1.000000   
12819       0.0       0.0       0.0       1.0       0.0   1.151035  1.000000   
33659       0.0       0.0       1.0       0.0       0.0   0.258362  0.000000   
19531       1.0       0.0       0.0       0.0       0.0  -0.821118  0.000000   

       PhysicalActivity  HealthInsurance   Alcohol  
28456          0.660578              0.0 -0.518600  
8993           0.000000              0.0  0.115329  
34312          0.000000              0.0  0.592213  
4802           1.012447              0.0 -0.103347  
25895          0.000000              0.0 -0.886483  
...                 ...              ...       ...  
18045          0.904383              0.0 -0.482716  
5425           1.598141              0.0  0.097790  
12819          1.598141              0.0  0.612947  
33659          1.162475              0.0 -0.154408  
19531          0.791302              0.0 -0.683278  

[13109 rows x 31 columns]
2025-12-03 10:18:35,506:INFO:get_config() successfully completed......................................
2025-12-03 10:18:35,539:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pandas\io\formats\style.py:3823: RuntimeWarning: invalid value encountered in scalar multiply

2025-12-03 10:18:35,575:INFO:Initializing plot_model()
2025-12-03 10:18:35,577:INFO:plot_model(plot=error, fold=None, verbose=True, display=None, display_format=None, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FA2637A00>, system=True)
2025-12-03 10:18:35,577:INFO:Checking exceptions
2025-12-03 10:18:35,600:INFO:Preloading libraries
2025-12-03 10:18:35,608:INFO:Copying training dataset
2025-12-03 10:18:35,608:INFO:Plot type: error
2025-12-03 10:18:35,849:INFO:Fitting Model
2025-12-03 10:18:35,850:INFO:Scoring test/hold-out set
2025-12-03 10:18:36,009:INFO:Visual Rendered Successfully
2025-12-03 10:18:36,188:INFO:plot_model() successfully completed......................................
2025-12-03 10:18:36,226:INFO:Initializing get_config()
2025-12-03 10:18:36,226:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FA2637A00>, variable=X_test_transformed)
2025-12-03 10:18:36,311:INFO:Variable: X_test returned as             Age  IncomeRatio  SystolicBP       BMI  WaistCircumference  \
28456 -0.477273    -0.304717   -0.519256 -0.987220           -0.923253   
8993   0.818182     0.253271    2.156910  0.770675            0.920394   
34312  0.704545     0.055403    0.519256  0.518044            0.662901   
4802  -0.545455     0.253730   -0.331933 -0.229036           -0.436352   
25895  0.704545     1.226781   -0.093200 -0.226100            0.012322   
...         ...          ...         ...       ...                 ...   
18045 -0.568182    -0.083104   -0.568713 -1.176693           -1.338674   
5425   0.590909     0.362732    2.210168  0.139096            0.292112   
12819  0.909091    -0.019787    0.899042  0.454886            0.971892   
33659 -0.522727     1.060572   -0.525683 -0.587220           -0.906087   
19531 -0.590909    -0.344290   -0.510287 -0.945114           -1.215078   

         Height  TotalCholesterol  Triglycerides       LDL       HDL  ...  \
28456 -1.080540         -0.078535      -0.470757 -0.026922  0.418008  ...   
8993  -0.279669          0.765897       0.705031  0.006026  0.446825  ...   
34312  0.559339         -0.123259       0.929511 -1.031826 -1.404309  ...   
4802  -0.504861         -0.188325      -0.322647  0.000015 -0.138743  ...   
25895  0.216731          0.892919       1.291109  0.008211 -0.255329  ...   
...         ...               ...            ...       ...       ...  ...   
18045 -2.080569         -0.340947      -0.470582 -0.848950  0.393794  ...   
5425   0.156785          0.435639      -0.065356  1.113733  0.127664  ...   
12819  1.194951         -0.732967      -0.470025 -0.211535 -1.085148  ...   
33659 -1.254274         -1.063225      -0.470958 -2.849419  0.127664  ...   
19531 -2.339052         -0.356898      -0.470595 -0.900608  0.393896  ...   

       Race_5.0  Race_1.0  Race_4.0  Race_3.0  Race_2.0  Education   Smoking  \
28456       1.0       0.0       0.0       0.0       0.0  -0.012820  0.000000   
8993        0.0       0.0       1.0       0.0       0.0   0.547458  1.000000   
34312       0.0       0.0       0.0       1.0       0.0  -0.659696  0.000000   
4802        1.0       0.0       0.0       0.0       0.0   0.262895  0.073612   
25895       0.0       0.0       0.0       1.0       0.0   1.151035  0.000000   
...         ...       ...       ...       ...       ...        ...       ...   
18045       0.0       0.0       0.0       1.0       0.0  -0.793202  0.000000   
5425        0.0       0.0       1.0       0.0       0.0   0.547458  1.000000   
12819       0.0       0.0       0.0       1.0       0.0   1.151035  1.000000   
33659       0.0       0.0       1.0       0.0       0.0   0.258362  0.000000   
19531       1.0       0.0       0.0       0.0       0.0  -0.821118  0.000000   

       PhysicalActivity  HealthInsurance   Alcohol  
28456          0.660578              0.0 -0.518600  
8993           0.000000              0.0  0.115329  
34312          0.000000              0.0  0.592213  
4802           1.012447              0.0 -0.103347  
25895          0.000000              0.0 -0.886483  
...                 ...              ...       ...  
18045          0.904383              0.0 -0.482716  
5425           1.598141              0.0  0.097790  
12819          1.598141              0.0  0.612947  
33659          1.162475              0.0 -0.154408  
19531          0.791302              0.0 -0.683278  

[13109 rows x 31 columns]
2025-12-03 10:18:36,311:INFO:get_config() successfully completed......................................
2025-12-03 10:18:36,338:INFO:Initializing get_config()
2025-12-03 10:18:36,338:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FA2637A00>, variable=y_test)
2025-12-03 10:18:36,338:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-12-03 10:18:36,338:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-12-03 10:18:36,341:INFO:Variable:  returned as 28456    0.0
8993     0.0
34312    0.0
4802     0.0
25895    0.0
        ... 
18045    0.0
5425     0.0
12819    0.0
33659    0.0
19531    0.0
Name: HeartDisease, Length: 13109, dtype: float32
2025-12-03 10:18:36,341:INFO:get_config() successfully completed......................................
2025-12-03 10:18:36,344:INFO:Initializing get_config()
2025-12-03 10:18:36,344:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FA2637A00>, variable=y_test)
2025-12-03 10:18:36,344:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-12-03 10:18:36,344:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-12-03 10:18:36,349:INFO:Variable:  returned as 28456    0.0
8993     0.0
34312    0.0
4802     0.0
25895    0.0
        ... 
18045    0.0
5425     0.0
12819    0.0
33659    0.0
19531    0.0
Name: HeartDisease, Length: 13109, dtype: float32
2025-12-03 10:18:36,349:INFO:get_config() successfully completed......................................
2025-12-03 10:18:36,350:INFO:Initializing get_config()
2025-12-03 10:18:36,350:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FA2637A00>, variable=X_test_transformed)
2025-12-03 10:18:36,420:INFO:Variable: X_test returned as             Age  IncomeRatio  SystolicBP       BMI  WaistCircumference  \
28456 -0.477273    -0.304717   -0.519256 -0.987220           -0.923253   
8993   0.818182     0.253271    2.156910  0.770675            0.920394   
34312  0.704545     0.055403    0.519256  0.518044            0.662901   
4802  -0.545455     0.253730   -0.331933 -0.229036           -0.436352   
25895  0.704545     1.226781   -0.093200 -0.226100            0.012322   
...         ...          ...         ...       ...                 ...   
18045 -0.568182    -0.083104   -0.568713 -1.176693           -1.338674   
5425   0.590909     0.362732    2.210168  0.139096            0.292112   
12819  0.909091    -0.019787    0.899042  0.454886            0.971892   
33659 -0.522727     1.060572   -0.525683 -0.587220           -0.906087   
19531 -0.590909    -0.344290   -0.510287 -0.945114           -1.215078   

         Height  TotalCholesterol  Triglycerides       LDL       HDL  ...  \
28456 -1.080540         -0.078535      -0.470757 -0.026922  0.418008  ...   
8993  -0.279669          0.765897       0.705031  0.006026  0.446825  ...   
34312  0.559339         -0.123259       0.929511 -1.031826 -1.404309  ...   
4802  -0.504861         -0.188325      -0.322647  0.000015 -0.138743  ...   
25895  0.216731          0.892919       1.291109  0.008211 -0.255329  ...   
...         ...               ...            ...       ...       ...  ...   
18045 -2.080569         -0.340947      -0.470582 -0.848950  0.393794  ...   
5425   0.156785          0.435639      -0.065356  1.113733  0.127664  ...   
12819  1.194951         -0.732967      -0.470025 -0.211535 -1.085148  ...   
33659 -1.254274         -1.063225      -0.470958 -2.849419  0.127664  ...   
19531 -2.339052         -0.356898      -0.470595 -0.900608  0.393896  ...   

       Race_5.0  Race_1.0  Race_4.0  Race_3.0  Race_2.0  Education   Smoking  \
28456       1.0       0.0       0.0       0.0       0.0  -0.012820  0.000000   
8993        0.0       0.0       1.0       0.0       0.0   0.547458  1.000000   
34312       0.0       0.0       0.0       1.0       0.0  -0.659696  0.000000   
4802        1.0       0.0       0.0       0.0       0.0   0.262895  0.073612   
25895       0.0       0.0       0.0       1.0       0.0   1.151035  0.000000   
...         ...       ...       ...       ...       ...        ...       ...   
18045       0.0       0.0       0.0       1.0       0.0  -0.793202  0.000000   
5425        0.0       0.0       1.0       0.0       0.0   0.547458  1.000000   
12819       0.0       0.0       0.0       1.0       0.0   1.151035  1.000000   
33659       0.0       0.0       1.0       0.0       0.0   0.258362  0.000000   
19531       1.0       0.0       0.0       0.0       0.0  -0.821118  0.000000   

       PhysicalActivity  HealthInsurance   Alcohol  
28456          0.660578              0.0 -0.518600  
8993           0.000000              0.0  0.115329  
34312          0.000000              0.0  0.592213  
4802           1.012447              0.0 -0.103347  
25895          0.000000              0.0 -0.886483  
...                 ...              ...       ...  
18045          0.904383              0.0 -0.482716  
5425           1.598141              0.0  0.097790  
12819          1.598141              0.0  0.612947  
33659          1.162475              0.0 -0.154408  
19531          0.791302              0.0 -0.683278  

[13109 rows x 31 columns]
2025-12-03 10:18:36,420:INFO:get_config() successfully completed......................................
2025-12-03 10:18:36,422:INFO:Initializing get_config()
2025-12-03 10:18:36,422:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FA2637A00>, variable=y_test)
2025-12-03 10:18:36,422:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-12-03 10:18:36,422:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-12-03 10:18:36,428:INFO:Variable:  returned as 28456    0.0
8993     0.0
34312    0.0
4802     0.0
25895    0.0
        ... 
18045    0.0
5425     0.0
12819    0.0
33659    0.0
19531    0.0
Name: HeartDisease, Length: 13109, dtype: float32
2025-12-03 10:18:36,428:INFO:get_config() successfully completed......................................
2025-12-03 10:18:36,428:INFO:Initializing get_config()
2025-12-03 10:18:36,428:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FA2637A00>, variable=y_test)
2025-12-03 10:18:36,428:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-12-03 10:18:36,428:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-12-03 10:18:36,434:INFO:Variable:  returned as 28456    0.0
8993     0.0
34312    0.0
4802     0.0
25895    0.0
        ... 
18045    0.0
5425     0.0
12819    0.0
33659    0.0
19531    0.0
Name: HeartDisease, Length: 13109, dtype: float32
2025-12-03 10:18:36,434:INFO:get_config() successfully completed......................................
2025-12-03 10:18:36,435:INFO:Initializing get_config()
2025-12-03 10:18:36,435:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FA2637A00>, variable=X_test_transformed)
2025-12-03 10:18:36,509:INFO:Variable: X_test returned as             Age  IncomeRatio  SystolicBP       BMI  WaistCircumference  \
28456 -0.477273    -0.304717   -0.519256 -0.987220           -0.923253   
8993   0.818182     0.253271    2.156910  0.770675            0.920394   
34312  0.704545     0.055403    0.519256  0.518044            0.662901   
4802  -0.545455     0.253730   -0.331933 -0.229036           -0.436352   
25895  0.704545     1.226781   -0.093200 -0.226100            0.012322   
...         ...          ...         ...       ...                 ...   
18045 -0.568182    -0.083104   -0.568713 -1.176693           -1.338674   
5425   0.590909     0.362732    2.210168  0.139096            0.292112   
12819  0.909091    -0.019787    0.899042  0.454886            0.971892   
33659 -0.522727     1.060572   -0.525683 -0.587220           -0.906087   
19531 -0.590909    -0.344290   -0.510287 -0.945114           -1.215078   

         Height  TotalCholesterol  Triglycerides       LDL       HDL  ...  \
28456 -1.080540         -0.078535      -0.470757 -0.026922  0.418008  ...   
8993  -0.279669          0.765897       0.705031  0.006026  0.446825  ...   
34312  0.559339         -0.123259       0.929511 -1.031826 -1.404309  ...   
4802  -0.504861         -0.188325      -0.322647  0.000015 -0.138743  ...   
25895  0.216731          0.892919       1.291109  0.008211 -0.255329  ...   
...         ...               ...            ...       ...       ...  ...   
18045 -2.080569         -0.340947      -0.470582 -0.848950  0.393794  ...   
5425   0.156785          0.435639      -0.065356  1.113733  0.127664  ...   
12819  1.194951         -0.732967      -0.470025 -0.211535 -1.085148  ...   
33659 -1.254274         -1.063225      -0.470958 -2.849419  0.127664  ...   
19531 -2.339052         -0.356898      -0.470595 -0.900608  0.393896  ...   

       Race_5.0  Race_1.0  Race_4.0  Race_3.0  Race_2.0  Education   Smoking  \
28456       1.0       0.0       0.0       0.0       0.0  -0.012820  0.000000   
8993        0.0       0.0       1.0       0.0       0.0   0.547458  1.000000   
34312       0.0       0.0       0.0       1.0       0.0  -0.659696  0.000000   
4802        1.0       0.0       0.0       0.0       0.0   0.262895  0.073612   
25895       0.0       0.0       0.0       1.0       0.0   1.151035  0.000000   
...         ...       ...       ...       ...       ...        ...       ...   
18045       0.0       0.0       0.0       1.0       0.0  -0.793202  0.000000   
5425        0.0       0.0       1.0       0.0       0.0   0.547458  1.000000   
12819       0.0       0.0       0.0       1.0       0.0   1.151035  1.000000   
33659       0.0       0.0       1.0       0.0       0.0   0.258362  0.000000   
19531       1.0       0.0       0.0       0.0       0.0  -0.821118  0.000000   

       PhysicalActivity  HealthInsurance   Alcohol  
28456          0.660578              0.0 -0.518600  
8993           0.000000              0.0  0.115329  
34312          0.000000              0.0  0.592213  
4802           1.012447              0.0 -0.103347  
25895          0.000000              0.0 -0.886483  
...                 ...              ...       ...  
18045          0.904383              0.0 -0.482716  
5425           1.598141              0.0  0.097790  
12819          1.598141              0.0  0.612947  
33659          1.162475              0.0 -0.154408  
19531          0.791302              0.0 -0.683278  

[13109 rows x 31 columns]
2025-12-03 10:18:36,509:INFO:get_config() successfully completed......................................
2025-12-03 10:18:36,570:INFO:Initializing get_config()
2025-12-03 10:18:36,570:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FA2637A00>, variable=y_test)
2025-12-03 10:18:36,570:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-12-03 10:18:36,570:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-12-03 10:18:36,576:INFO:Variable:  returned as 28456    0.0
8993     0.0
34312    0.0
4802     0.0
25895    0.0
        ... 
18045    0.0
5425     0.0
12819    0.0
33659    0.0
19531    0.0
Name: HeartDisease, Length: 13109, dtype: float32
2025-12-03 10:18:36,576:INFO:get_config() successfully completed......................................
2025-12-03 10:18:36,578:INFO:Initializing get_config()
2025-12-03 10:18:36,578:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FA2637A00>, variable=y_test)
2025-12-03 10:18:36,578:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-12-03 10:18:36,578:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-12-03 10:18:36,583:INFO:Variable:  returned as 28456    0.0
8993     0.0
34312    0.0
4802     0.0
25895    0.0
        ... 
18045    0.0
5425     0.0
12819    0.0
33659    0.0
19531    0.0
Name: HeartDisease, Length: 13109, dtype: float32
2025-12-03 10:18:36,583:INFO:get_config() successfully completed......................................
2025-12-03 10:18:36,676:INFO:Initializing get_config()
2025-12-03 10:18:36,676:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FA2637A00>, variable=X_test_transformed)
2025-12-03 10:18:36,758:INFO:Variable: X_test returned as             Age  IncomeRatio  SystolicBP       BMI  WaistCircumference  \
28456 -0.477273    -0.304717   -0.519256 -0.987220           -0.923253   
8993   0.818182     0.253271    2.156910  0.770675            0.920394   
34312  0.704545     0.055403    0.519256  0.518044            0.662901   
4802  -0.545455     0.253730   -0.331933 -0.229036           -0.436352   
25895  0.704545     1.226781   -0.093200 -0.226100            0.012322   
...         ...          ...         ...       ...                 ...   
18045 -0.568182    -0.083104   -0.568713 -1.176693           -1.338674   
5425   0.590909     0.362732    2.210168  0.139096            0.292112   
12819  0.909091    -0.019787    0.899042  0.454886            0.971892   
33659 -0.522727     1.060572   -0.525683 -0.587220           -0.906087   
19531 -0.590909    -0.344290   -0.510287 -0.945114           -1.215078   

         Height  TotalCholesterol  Triglycerides       LDL       HDL  ...  \
28456 -1.080540         -0.078535      -0.470757 -0.026922  0.418008  ...   
8993  -0.279669          0.765897       0.705031  0.006026  0.446825  ...   
34312  0.559339         -0.123259       0.929511 -1.031826 -1.404309  ...   
4802  -0.504861         -0.188325      -0.322647  0.000015 -0.138743  ...   
25895  0.216731          0.892919       1.291109  0.008211 -0.255329  ...   
...         ...               ...            ...       ...       ...  ...   
18045 -2.080569         -0.340947      -0.470582 -0.848950  0.393794  ...   
5425   0.156785          0.435639      -0.065356  1.113733  0.127664  ...   
12819  1.194951         -0.732967      -0.470025 -0.211535 -1.085148  ...   
33659 -1.254274         -1.063225      -0.470958 -2.849419  0.127664  ...   
19531 -2.339052         -0.356898      -0.470595 -0.900608  0.393896  ...   

       Race_5.0  Race_1.0  Race_4.0  Race_3.0  Race_2.0  Education   Smoking  \
28456       1.0       0.0       0.0       0.0       0.0  -0.012820  0.000000   
8993        0.0       0.0       1.0       0.0       0.0   0.547458  1.000000   
34312       0.0       0.0       0.0       1.0       0.0  -0.659696  0.000000   
4802        1.0       0.0       0.0       0.0       0.0   0.262895  0.073612   
25895       0.0       0.0       0.0       1.0       0.0   1.151035  0.000000   
...         ...       ...       ...       ...       ...        ...       ...   
18045       0.0       0.0       0.0       1.0       0.0  -0.793202  0.000000   
5425        0.0       0.0       1.0       0.0       0.0   0.547458  1.000000   
12819       0.0       0.0       0.0       1.0       0.0   1.151035  1.000000   
33659       0.0       0.0       1.0       0.0       0.0   0.258362  0.000000   
19531       1.0       0.0       0.0       0.0       0.0  -0.821118  0.000000   

       PhysicalActivity  HealthInsurance   Alcohol  
28456          0.660578              0.0 -0.518600  
8993           0.000000              0.0  0.115329  
34312          0.000000              0.0  0.592213  
4802           1.012447              0.0 -0.103347  
25895          0.000000              0.0 -0.886483  
...                 ...              ...       ...  
18045          0.904383              0.0 -0.482716  
5425           1.598141              0.0  0.097790  
12819          1.598141              0.0  0.612947  
33659          1.162475              0.0 -0.154408  
19531          0.791302              0.0 -0.683278  

[13109 rows x 31 columns]
2025-12-03 10:18:36,763:INFO:get_config() successfully completed......................................
2025-12-03 10:18:36,788:INFO:Initializing get_config()
2025-12-03 10:18:36,788:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FA2637A00>, variable=y_test)
2025-12-03 10:18:36,788:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-12-03 10:18:36,788:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-12-03 10:18:36,796:INFO:Variable:  returned as 28456    0.0
8993     0.0
34312    0.0
4802     0.0
25895    0.0
        ... 
18045    0.0
5425     0.0
12819    0.0
33659    0.0
19531    0.0
Name: HeartDisease, Length: 13109, dtype: float32
2025-12-03 10:18:36,796:INFO:get_config() successfully completed......................................
2025-12-03 10:18:36,796:INFO:Initializing get_config()
2025-12-03 10:18:36,796:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FA2637A00>, variable=X_test_transformed)
2025-12-03 10:18:36,876:INFO:Variable: X_test returned as             Age  IncomeRatio  SystolicBP       BMI  WaistCircumference  \
28456 -0.477273    -0.304717   -0.519256 -0.987220           -0.923253   
8993   0.818182     0.253271    2.156910  0.770675            0.920394   
34312  0.704545     0.055403    0.519256  0.518044            0.662901   
4802  -0.545455     0.253730   -0.331933 -0.229036           -0.436352   
25895  0.704545     1.226781   -0.093200 -0.226100            0.012322   
...         ...          ...         ...       ...                 ...   
18045 -0.568182    -0.083104   -0.568713 -1.176693           -1.338674   
5425   0.590909     0.362732    2.210168  0.139096            0.292112   
12819  0.909091    -0.019787    0.899042  0.454886            0.971892   
33659 -0.522727     1.060572   -0.525683 -0.587220           -0.906087   
19531 -0.590909    -0.344290   -0.510287 -0.945114           -1.215078   

         Height  TotalCholesterol  Triglycerides       LDL       HDL  ...  \
28456 -1.080540         -0.078535      -0.470757 -0.026922  0.418008  ...   
8993  -0.279669          0.765897       0.705031  0.006026  0.446825  ...   
34312  0.559339         -0.123259       0.929511 -1.031826 -1.404309  ...   
4802  -0.504861         -0.188325      -0.322647  0.000015 -0.138743  ...   
25895  0.216731          0.892919       1.291109  0.008211 -0.255329  ...   
...         ...               ...            ...       ...       ...  ...   
18045 -2.080569         -0.340947      -0.470582 -0.848950  0.393794  ...   
5425   0.156785          0.435639      -0.065356  1.113733  0.127664  ...   
12819  1.194951         -0.732967      -0.470025 -0.211535 -1.085148  ...   
33659 -1.254274         -1.063225      -0.470958 -2.849419  0.127664  ...   
19531 -2.339052         -0.356898      -0.470595 -0.900608  0.393896  ...   

       Race_5.0  Race_1.0  Race_4.0  Race_3.0  Race_2.0  Education   Smoking  \
28456       1.0       0.0       0.0       0.0       0.0  -0.012820  0.000000   
8993        0.0       0.0       1.0       0.0       0.0   0.547458  1.000000   
34312       0.0       0.0       0.0       1.0       0.0  -0.659696  0.000000   
4802        1.0       0.0       0.0       0.0       0.0   0.262895  0.073612   
25895       0.0       0.0       0.0       1.0       0.0   1.151035  0.000000   
...         ...       ...       ...       ...       ...        ...       ...   
18045       0.0       0.0       0.0       1.0       0.0  -0.793202  0.000000   
5425        0.0       0.0       1.0       0.0       0.0   0.547458  1.000000   
12819       0.0       0.0       0.0       1.0       0.0   1.151035  1.000000   
33659       0.0       0.0       1.0       0.0       0.0   0.258362  0.000000   
19531       1.0       0.0       0.0       0.0       0.0  -0.821118  0.000000   

       PhysicalActivity  HealthInsurance   Alcohol  
28456          0.660578              0.0 -0.518600  
8993           0.000000              0.0  0.115329  
34312          0.000000              0.0  0.592213  
4802           1.012447              0.0 -0.103347  
25895          0.000000              0.0 -0.886483  
...                 ...              ...       ...  
18045          0.904383              0.0 -0.482716  
5425           1.598141              0.0  0.097790  
12819          1.598141              0.0  0.612947  
33659          1.162475              0.0 -0.154408  
19531          0.791302              0.0 -0.683278  

[13109 rows x 31 columns]
2025-12-03 10:18:36,876:INFO:get_config() successfully completed......................................
2025-12-03 10:18:36,876:INFO:Initializing get_config()
2025-12-03 10:18:36,876:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FA2637A00>, variable=y_test)
2025-12-03 10:18:36,876:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-12-03 10:18:36,876:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-12-03 10:18:36,884:INFO:Variable:  returned as 28456    0.0
8993     0.0
34312    0.0
4802     0.0
25895    0.0
        ... 
18045    0.0
5425     0.0
12819    0.0
33659    0.0
19531    0.0
Name: HeartDisease, Length: 13109, dtype: float32
2025-12-03 10:18:36,884:INFO:get_config() successfully completed......................................
2025-12-03 10:18:36,885:INFO:Initializing get_config()
2025-12-03 10:18:36,885:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FA2637A00>, variable=X_test_transformed)
2025-12-03 10:18:36,969:INFO:Variable: X_test returned as             Age  IncomeRatio  SystolicBP       BMI  WaistCircumference  \
28456 -0.477273    -0.304717   -0.519256 -0.987220           -0.923253   
8993   0.818182     0.253271    2.156910  0.770675            0.920394   
34312  0.704545     0.055403    0.519256  0.518044            0.662901   
4802  -0.545455     0.253730   -0.331933 -0.229036           -0.436352   
25895  0.704545     1.226781   -0.093200 -0.226100            0.012322   
...         ...          ...         ...       ...                 ...   
18045 -0.568182    -0.083104   -0.568713 -1.176693           -1.338674   
5425   0.590909     0.362732    2.210168  0.139096            0.292112   
12819  0.909091    -0.019787    0.899042  0.454886            0.971892   
33659 -0.522727     1.060572   -0.525683 -0.587220           -0.906087   
19531 -0.590909    -0.344290   -0.510287 -0.945114           -1.215078   

         Height  TotalCholesterol  Triglycerides       LDL       HDL  ...  \
28456 -1.080540         -0.078535      -0.470757 -0.026922  0.418008  ...   
8993  -0.279669          0.765897       0.705031  0.006026  0.446825  ...   
34312  0.559339         -0.123259       0.929511 -1.031826 -1.404309  ...   
4802  -0.504861         -0.188325      -0.322647  0.000015 -0.138743  ...   
25895  0.216731          0.892919       1.291109  0.008211 -0.255329  ...   
...         ...               ...            ...       ...       ...  ...   
18045 -2.080569         -0.340947      -0.470582 -0.848950  0.393794  ...   
5425   0.156785          0.435639      -0.065356  1.113733  0.127664  ...   
12819  1.194951         -0.732967      -0.470025 -0.211535 -1.085148  ...   
33659 -1.254274         -1.063225      -0.470958 -2.849419  0.127664  ...   
19531 -2.339052         -0.356898      -0.470595 -0.900608  0.393896  ...   

       Race_5.0  Race_1.0  Race_4.0  Race_3.0  Race_2.0  Education   Smoking  \
28456       1.0       0.0       0.0       0.0       0.0  -0.012820  0.000000   
8993        0.0       0.0       1.0       0.0       0.0   0.547458  1.000000   
34312       0.0       0.0       0.0       1.0       0.0  -0.659696  0.000000   
4802        1.0       0.0       0.0       0.0       0.0   0.262895  0.073612   
25895       0.0       0.0       0.0       1.0       0.0   1.151035  0.000000   
...         ...       ...       ...       ...       ...        ...       ...   
18045       0.0       0.0       0.0       1.0       0.0  -0.793202  0.000000   
5425        0.0       0.0       1.0       0.0       0.0   0.547458  1.000000   
12819       0.0       0.0       0.0       1.0       0.0   1.151035  1.000000   
33659       0.0       0.0       1.0       0.0       0.0   0.258362  0.000000   
19531       1.0       0.0       0.0       0.0       0.0  -0.821118  0.000000   

       PhysicalActivity  HealthInsurance   Alcohol  
28456          0.660578              0.0 -0.518600  
8993           0.000000              0.0  0.115329  
34312          0.000000              0.0  0.592213  
4802           1.012447              0.0 -0.103347  
25895          0.000000              0.0 -0.886483  
...                 ...              ...       ...  
18045          0.904383              0.0 -0.482716  
5425           1.598141              0.0  0.097790  
12819          1.598141              0.0  0.612947  
33659          1.162475              0.0 -0.154408  
19531          0.791302              0.0 -0.683278  

[13109 rows x 31 columns]
2025-12-03 10:18:36,969:INFO:get_config() successfully completed......................................
2025-12-03 10:18:37,023:INFO:Initializing get_config()
2025-12-03 10:18:37,023:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FA2637A00>, variable=y_test)
2025-12-03 10:18:37,024:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-12-03 10:18:37,024:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-12-03 10:18:37,028:INFO:Variable:  returned as 28456    0.0
8993     0.0
34312    0.0
4802     0.0
25895    0.0
        ... 
18045    0.0
5425     0.0
12819    0.0
33659    0.0
19531    0.0
Name: HeartDisease, Length: 13109, dtype: float32
2025-12-03 10:18:37,028:INFO:get_config() successfully completed......................................
2025-12-03 10:18:37,056:INFO:Initializing get_config()
2025-12-03 10:18:37,056:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FA2637A00>, variable=X_test_transformed)
2025-12-03 10:18:37,144:INFO:Variable: X_test returned as             Age  IncomeRatio  SystolicBP       BMI  WaistCircumference  \
28456 -0.477273    -0.304717   -0.519256 -0.987220           -0.923253   
8993   0.818182     0.253271    2.156910  0.770675            0.920394   
34312  0.704545     0.055403    0.519256  0.518044            0.662901   
4802  -0.545455     0.253730   -0.331933 -0.229036           -0.436352   
25895  0.704545     1.226781   -0.093200 -0.226100            0.012322   
...         ...          ...         ...       ...                 ...   
18045 -0.568182    -0.083104   -0.568713 -1.176693           -1.338674   
5425   0.590909     0.362732    2.210168  0.139096            0.292112   
12819  0.909091    -0.019787    0.899042  0.454886            0.971892   
33659 -0.522727     1.060572   -0.525683 -0.587220           -0.906087   
19531 -0.590909    -0.344290   -0.510287 -0.945114           -1.215078   

         Height  TotalCholesterol  Triglycerides       LDL       HDL  ...  \
28456 -1.080540         -0.078535      -0.470757 -0.026922  0.418008  ...   
8993  -0.279669          0.765897       0.705031  0.006026  0.446825  ...   
34312  0.559339         -0.123259       0.929511 -1.031826 -1.404309  ...   
4802  -0.504861         -0.188325      -0.322647  0.000015 -0.138743  ...   
25895  0.216731          0.892919       1.291109  0.008211 -0.255329  ...   
...         ...               ...            ...       ...       ...  ...   
18045 -2.080569         -0.340947      -0.470582 -0.848950  0.393794  ...   
5425   0.156785          0.435639      -0.065356  1.113733  0.127664  ...   
12819  1.194951         -0.732967      -0.470025 -0.211535 -1.085148  ...   
33659 -1.254274         -1.063225      -0.470958 -2.849419  0.127664  ...   
19531 -2.339052         -0.356898      -0.470595 -0.900608  0.393896  ...   

       Race_5.0  Race_1.0  Race_4.0  Race_3.0  Race_2.0  Education   Smoking  \
28456       1.0       0.0       0.0       0.0       0.0  -0.012820  0.000000   
8993        0.0       0.0       1.0       0.0       0.0   0.547458  1.000000   
34312       0.0       0.0       0.0       1.0       0.0  -0.659696  0.000000   
4802        1.0       0.0       0.0       0.0       0.0   0.262895  0.073612   
25895       0.0       0.0       0.0       1.0       0.0   1.151035  0.000000   
...         ...       ...       ...       ...       ...        ...       ...   
18045       0.0       0.0       0.0       1.0       0.0  -0.793202  0.000000   
5425        0.0       0.0       1.0       0.0       0.0   0.547458  1.000000   
12819       0.0       0.0       0.0       1.0       0.0   1.151035  1.000000   
33659       0.0       0.0       1.0       0.0       0.0   0.258362  0.000000   
19531       1.0       0.0       0.0       0.0       0.0  -0.821118  0.000000   

       PhysicalActivity  HealthInsurance   Alcohol  
28456          0.660578              0.0 -0.518600  
8993           0.000000              0.0  0.115329  
34312          0.000000              0.0  0.592213  
4802           1.012447              0.0 -0.103347  
25895          0.000000              0.0 -0.886483  
...                 ...              ...       ...  
18045          0.904383              0.0 -0.482716  
5425           1.598141              0.0  0.097790  
12819          1.598141              0.0  0.612947  
33659          1.162475              0.0 -0.154408  
19531          0.791302              0.0 -0.683278  

[13109 rows x 31 columns]
2025-12-03 10:18:37,144:INFO:get_config() successfully completed......................................
2025-12-03 10:18:37,169:INFO:Initializing get_config()
2025-12-03 10:18:37,169:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FA2637A00>, variable=y_test)
2025-12-03 10:18:37,169:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-12-03 10:18:37,169:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-12-03 10:18:37,176:INFO:Variable:  returned as 28456    0.0
8993     0.0
34312    0.0
4802     0.0
25895    0.0
        ... 
18045    0.0
5425     0.0
12819    0.0
33659    0.0
19531    0.0
Name: HeartDisease, Length: 13109, dtype: float32
2025-12-03 10:18:37,176:INFO:get_config() successfully completed......................................
2025-12-03 10:18:37,394:INFO:Initializing get_config()
2025-12-03 10:18:37,394:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FA2637A00>, variable=y_test)
2025-12-03 10:18:37,394:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-12-03 10:18:37,394:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-12-03 10:18:37,402:INFO:Variable:  returned as 28456    0.0
8993     0.0
34312    0.0
4802     0.0
25895    0.0
        ... 
18045    0.0
5425     0.0
12819    0.0
33659    0.0
19531    0.0
Name: HeartDisease, Length: 13109, dtype: float32
2025-12-03 10:18:37,402:INFO:get_config() successfully completed......................................
2025-12-03 10:18:37,402:INFO:Initializing get_config()
2025-12-03 10:18:37,402:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FA2637A00>, variable=X_test_transformed)
2025-12-03 10:18:37,483:INFO:Variable: X_test returned as             Age  IncomeRatio  SystolicBP       BMI  WaistCircumference  \
28456 -0.477273    -0.304717   -0.519256 -0.987220           -0.923253   
8993   0.818182     0.253271    2.156910  0.770675            0.920394   
34312  0.704545     0.055403    0.519256  0.518044            0.662901   
4802  -0.545455     0.253730   -0.331933 -0.229036           -0.436352   
25895  0.704545     1.226781   -0.093200 -0.226100            0.012322   
...         ...          ...         ...       ...                 ...   
18045 -0.568182    -0.083104   -0.568713 -1.176693           -1.338674   
5425   0.590909     0.362732    2.210168  0.139096            0.292112   
12819  0.909091    -0.019787    0.899042  0.454886            0.971892   
33659 -0.522727     1.060572   -0.525683 -0.587220           -0.906087   
19531 -0.590909    -0.344290   -0.510287 -0.945114           -1.215078   

         Height  TotalCholesterol  Triglycerides       LDL       HDL  ...  \
28456 -1.080540         -0.078535      -0.470757 -0.026922  0.418008  ...   
8993  -0.279669          0.765897       0.705031  0.006026  0.446825  ...   
34312  0.559339         -0.123259       0.929511 -1.031826 -1.404309  ...   
4802  -0.504861         -0.188325      -0.322647  0.000015 -0.138743  ...   
25895  0.216731          0.892919       1.291109  0.008211 -0.255329  ...   
...         ...               ...            ...       ...       ...  ...   
18045 -2.080569         -0.340947      -0.470582 -0.848950  0.393794  ...   
5425   0.156785          0.435639      -0.065356  1.113733  0.127664  ...   
12819  1.194951         -0.732967      -0.470025 -0.211535 -1.085148  ...   
33659 -1.254274         -1.063225      -0.470958 -2.849419  0.127664  ...   
19531 -2.339052         -0.356898      -0.470595 -0.900608  0.393896  ...   

       Race_5.0  Race_1.0  Race_4.0  Race_3.0  Race_2.0  Education   Smoking  \
28456       1.0       0.0       0.0       0.0       0.0  -0.012820  0.000000   
8993        0.0       0.0       1.0       0.0       0.0   0.547458  1.000000   
34312       0.0       0.0       0.0       1.0       0.0  -0.659696  0.000000   
4802        1.0       0.0       0.0       0.0       0.0   0.262895  0.073612   
25895       0.0       0.0       0.0       1.0       0.0   1.151035  0.000000   
...         ...       ...       ...       ...       ...        ...       ...   
18045       0.0       0.0       0.0       1.0       0.0  -0.793202  0.000000   
5425        0.0       0.0       1.0       0.0       0.0   0.547458  1.000000   
12819       0.0       0.0       0.0       1.0       0.0   1.151035  1.000000   
33659       0.0       0.0       1.0       0.0       0.0   0.258362  0.000000   
19531       1.0       0.0       0.0       0.0       0.0  -0.821118  0.000000   

       PhysicalActivity  HealthInsurance   Alcohol  
28456          0.660578              0.0 -0.518600  
8993           0.000000              0.0  0.115329  
34312          0.000000              0.0  0.592213  
4802           1.012447              0.0 -0.103347  
25895          0.000000              0.0 -0.886483  
...                 ...              ...       ...  
18045          0.904383              0.0 -0.482716  
5425           1.598141              0.0  0.097790  
12819          1.598141              0.0  0.612947  
33659          1.162475              0.0 -0.154408  
19531          0.791302              0.0 -0.683278  

[13109 rows x 31 columns]
2025-12-03 10:18:37,483:INFO:get_config() successfully completed......................................
2025-12-03 10:18:37,576:INFO:Initializing get_config()
2025-12-03 10:18:37,576:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FA2637A00>, variable=X_train_transformed)
2025-12-03 10:18:37,614:INFO:Variable: X_train returned as             Age  IncomeRatio  SystolicBP       BMI  WaistCircumference  \
15208  0.954545     0.854789    0.359485  0.518044            0.206281   
25325 -0.272727     0.253271   -0.812170 -0.966167           -0.799656   
5132   0.181818    -0.407608   -0.372799  0.054886            0.319578   
17217  0.500000    -0.751898    0.013314 -0.260904            0.278379   
6382   0.568182     0.054503    1.131712  2.675938            1.888566   
...         ...          ...         ...       ...                 ...   
6265  -0.545455    -0.431352   -0.591719  0.191728           -0.377368   
42694 -0.022727    -0.221612   -0.892056 -0.260904           -0.047778   
13399  0.454545     0.388518    0.377985  0.271482            0.183567   
39959  0.954545    -0.193911    0.625770  0.991728            1.160720   
6616   0.613636    -0.447182    0.652399 -0.871430           -0.514698   

         Height  TotalCholesterol  Triglycerides       LDL       HDL  ...  \
15208 -0.487303          0.625876       0.583394  0.005397  0.314564  ...   
25325 -0.300856          0.033588      -0.261476  0.000256  0.303682  ...   
5132   0.766972          0.181594       0.479279  0.948690 -1.340476  ...   
17217  0.745785          0.227516       0.346113  0.002441 -0.274561  ...   
6382   0.237295          0.867515       0.635574  0.002754  0.829819  ...   
...         ...               ...            ...       ...       ...  ...   
6265  -1.737339         -1.393483      -0.471046 -3.840886  0.063832  ...   
42694  0.000000          0.029167      -0.131730  0.000893  0.063832  ...   
13399 -0.147405          0.462357       0.380371  0.003925  0.256949  ...   
39959  0.368655          1.528031       1.934134  0.011744  0.191497  ...   
6616  -0.021187         -0.224877      -0.043571 -1.609476  0.510658  ...   

       Race_5.0  Race_1.0  Race_4.0  Race_3.0  Race_2.0  Education  Smoking  \
15208       1.0       0.0       0.0       0.0       0.0  -0.659696      0.0   
25325       0.0       1.0       0.0       0.0       0.0   0.185278      0.0   
5132        0.0       1.0       0.0       0.0       0.0  -0.659696      1.0   
17217       0.0       0.0       1.0       0.0       0.0  -0.056119      1.0   
6382        0.0       0.0       1.0       0.0       0.0   0.547458      1.0   
...         ...       ...       ...       ...       ...        ...      ...   
6265        0.0       1.0       0.0       0.0       0.0  -0.769055      0.0   
42694       0.0       1.0       0.0       0.0       0.0   0.547458      0.0   
13399       0.0       0.0       1.0       0.0       0.0   0.547458      0.0   
39959       0.0       0.0       0.0       1.0       0.0   0.547458      0.0   
6616        0.0       0.0       0.0       1.0       0.0   0.547458      1.0   

       PhysicalActivity  HealthInsurance   Alcohol  
15208          0.000000              0.0 -0.886483  
25325          0.000000              0.0  0.592213  
5132           0.000000             -1.0  0.312949  
17217          0.000000              0.0  0.592213  
6382           0.000000              0.0  0.597293  
...                 ...              ...       ...  
6265           0.662459              0.0 -0.501621  
42694          0.000000             -1.0  0.592213  
13399          0.000000              0.0 -0.224534  
39959          0.000000              0.0  0.592213  
6616           0.000000              0.0  0.290247  

[30586 rows x 31 columns]
2025-12-03 10:18:37,614:INFO:get_config() successfully completed......................................
2025-12-03 10:18:37,634:INFO:Initializing tune_model()
2025-12-03 10:18:37,634:INFO:tune_model(estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...), fold=None, round=4, n_iter=5, custom_grid=None, optimize=Recall, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=False, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FA2637A00>)
2025-12-03 10:18:37,634:INFO:Checking exceptions
2025-12-03 10:18:37,644:INFO:Copying training dataset
2025-12-03 10:18:37,664:INFO:Checking base model
2025-12-03 10:18:37,664:INFO:Base model : Extreme Gradient Boosting
2025-12-03 10:18:37,665:INFO:Declaring metric variables
2025-12-03 10:18:37,665:INFO:Defining Hyperparameters
2025-12-03 10:18:37,838:INFO:Tuning with n_jobs=1
2025-12-03 10:18:37,838:INFO:Initializing RandomizedSearchCV
2025-12-03 10:19:16,224:INFO:best_params: {'actual_estimator__subsample': 0.7, 'actual_estimator__scale_pos_weight': 38.0, 'actual_estimator__reg_lambda': 0.7, 'actual_estimator__reg_alpha': 0.001, 'actual_estimator__n_estimators': 60, 'actual_estimator__min_child_weight': 1, 'actual_estimator__max_depth': 6, 'actual_estimator__learning_rate': 0.4, 'actual_estimator__colsample_bytree': 0.7}
2025-12-03 10:19:16,225:INFO:Hyperparameter search completed
2025-12-03 10:19:16,225:INFO:SubProcess create_model() called ==================================
2025-12-03 10:19:16,225:INFO:Initializing create_model()
2025-12-03 10:19:16,225:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FA2637A00>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000018FB0063160>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'subsample': 0.7, 'scale_pos_weight': 38.0, 'reg_lambda': 0.7, 'reg_alpha': 0.001, 'n_estimators': 60, 'min_child_weight': 1, 'max_depth': 6, 'learning_rate': 0.4, 'colsample_bytree': 0.7})
2025-12-03 10:19:16,225:INFO:Checking exceptions
2025-12-03 10:19:16,226:INFO:Importing libraries
2025-12-03 10:19:16,226:INFO:Copying training dataset
2025-12-03 10:19:16,248:INFO:Defining folds
2025-12-03 10:19:16,248:INFO:Declaring metric variables
2025-12-03 10:19:16,248:INFO:Importing untrained model
2025-12-03 10:19:16,248:INFO:Declaring custom model
2025-12-03 10:19:16,249:INFO:Extreme Gradient Boosting Imported successfully
2025-12-03 10:19:16,249:INFO:Starting cross validation
2025-12-03 10:19:16,250:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-12-03 10:19:21,684:INFO:Calculating mean and std
2025-12-03 10:19:21,684:INFO:Creating metrics dataframe
2025-12-03 10:19:21,685:INFO:Finalizing model
2025-12-03 10:19:21,781:INFO:Warning: No categorical columns found. Calling 'transform' will only return input data.
2025-12-03 10:19:22,240:INFO:Uploading results into container
2025-12-03 10:19:22,240:INFO:Uploading model into container now
2025-12-03 10:19:22,241:INFO:_master_model_container: 4
2025-12-03 10:19:22,241:INFO:_display_container: 5
2025-12-03 10:19:22,241:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=0.7, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=0.4, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=6, max_leaves=None,
              min_child_weight=1, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=60, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2025-12-03 10:19:22,241:INFO:create_model() successfully completed......................................
2025-12-03 10:19:22,457:INFO:SubProcess create_model() end ==================================
2025-12-03 10:19:22,457:INFO:choose_better activated
2025-12-03 10:19:22,457:INFO:SubProcess create_model() called ==================================
2025-12-03 10:19:22,459:INFO:Initializing create_model()
2025-12-03 10:19:22,459:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FA2637A00>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-03 10:19:22,459:INFO:Checking exceptions
2025-12-03 10:19:22,460:INFO:Importing libraries
2025-12-03 10:19:22,460:INFO:Copying training dataset
2025-12-03 10:19:22,486:INFO:Defining folds
2025-12-03 10:19:22,486:INFO:Declaring metric variables
2025-12-03 10:19:22,486:INFO:Importing untrained model
2025-12-03 10:19:22,486:INFO:Declaring custom model
2025-12-03 10:19:22,488:INFO:Extreme Gradient Boosting Imported successfully
2025-12-03 10:19:22,488:INFO:Starting cross validation
2025-12-03 10:19:22,489:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-12-03 10:19:29,506:INFO:Calculating mean and std
2025-12-03 10:19:29,507:INFO:Creating metrics dataframe
2025-12-03 10:19:29,508:INFO:Finalizing model
2025-12-03 10:19:29,594:INFO:Warning: No categorical columns found. Calling 'transform' will only return input data.
2025-12-03 10:19:30,192:INFO:Uploading results into container
2025-12-03 10:19:30,192:INFO:Uploading model into container now
2025-12-03 10:19:30,192:INFO:_master_model_container: 5
2025-12-03 10:19:30,192:INFO:_display_container: 6
2025-12-03 10:19:30,194:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2025-12-03 10:19:30,194:INFO:create_model() successfully completed......................................
2025-12-03 10:19:30,425:INFO:SubProcess create_model() end ==================================
2025-12-03 10:19:30,426:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...) result for Recall is 0.3112
2025-12-03 10:19:30,427:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=0.7, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=0.4, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=6, max_leaves=None,
              min_child_weight=1, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=60, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...) result for Recall is 0.3316
2025-12-03 10:19:30,427:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=0.7, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=0.4, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=6, max_leaves=None,
              min_child_weight=1, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=60, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...) is best model
2025-12-03 10:19:30,427:INFO:choose_better completed
2025-12-03 10:19:30,427:INFO:_master_model_container: 5
2025-12-03 10:19:30,427:INFO:_display_container: 5
2025-12-03 10:19:30,427:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=0.7, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=0.4, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=6, max_leaves=None,
              min_child_weight=1, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=60, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2025-12-03 10:19:30,427:INFO:tune_model() successfully completed......................................
2025-12-03 10:19:30,638:INFO:Initializing predict_model()
2025-12-03 10:19:30,638:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FA2637A00>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=0.7, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=0.4, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=6, max_leaves=None,
              min_child_weight=1, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=60, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...), probability_threshold=None, encoded_labels=False, raw_score=True, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000018FAFF577F0>)
2025-12-03 10:19:30,638:INFO:Checking exceptions
2025-12-03 10:19:30,638:INFO:Preloading libraries
2025-12-03 10:19:31,090:INFO:Initializing get_config()
2025-12-03 10:19:31,090:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FA2637A00>, variable=target_param)
2025-12-03 10:19:31,090:INFO:Variable:  returned as HeartDisease
2025-12-03 10:19:31,090:INFO:get_config() successfully completed......................................
2025-12-03 10:19:31,848:INFO:Initializing interpret_model()
2025-12-03 10:19:31,849:INFO:interpret_model(estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=0.7, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=0.4, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=6, max_leaves=None,
              min_child_weight=1, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=60, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...), use_train_data=False, X_new_sample=None, y_new_sample=None, feature=None, kwargs={}, observation=None, plot=summary, save=False, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FA2637A00>)
2025-12-03 10:19:31,849:INFO:Checking exceptions
2025-12-03 10:19:31,849:INFO:Soft dependency imported: shap: 0.49.1
2025-12-03 10:19:31,928:INFO:plot type: summary
2025-12-03 10:19:31,928:INFO:Creating TreeExplainer
2025-12-03 10:19:31,945:INFO:Compiling shap values
2025-12-03 10:19:35,480:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:4145: FutureWarning: The NumPy global RNG was seeded by calling `np.random.seed`. In a future version this function will no longer use the global RNG. Pass `rng` explicitly to opt-in to the new behaviour and silence this warning.

2025-12-03 10:19:36,821:INFO:Visual Rendered Successfully
2025-12-03 10:19:36,822:INFO:interpret_model() successfully completed......................................
2025-12-03 10:19:37,041:INFO:Initializing predict_model()
2025-12-03 10:19:37,041:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FA2637A00>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...), probability_threshold=None, encoded_labels=False, raw_score=True, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000018FAFCFD5A0>)
2025-12-03 10:19:37,041:INFO:Checking exceptions
2025-12-03 10:19:37,041:INFO:Preloading libraries
2025-12-03 10:19:37,516:INFO:Initializing get_config()
2025-12-03 10:19:37,516:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FA2637A00>, variable=target_param)
2025-12-03 10:19:37,517:INFO:Variable:  returned as HeartDisease
2025-12-03 10:19:37,517:INFO:get_config() successfully completed......................................
2025-12-03 10:19:37,659:INFO:Initializing finalize_model()
2025-12-03 10:19:37,659:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FA2637A00>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=0.7, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=0.4, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=6, max_leaves=None,
              min_child_weight=1, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=60, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2025-12-03 10:19:37,660:INFO:Finalizing XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=0.7, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=0.4, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=6, max_leaves=None,
              min_child_weight=1, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=60, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2025-12-03 10:19:37,677:INFO:Initializing create_model()
2025-12-03 10:19:37,678:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FA2637A00>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=0.7, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=0.4, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=6, max_leaves=None,
              min_child_weight=1, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=60, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2025-12-03 10:19:37,678:INFO:Checking exceptions
2025-12-03 10:19:37,680:INFO:Importing libraries
2025-12-03 10:19:37,680:INFO:Copying training dataset
2025-12-03 10:19:37,683:INFO:Defining folds
2025-12-03 10:19:37,683:INFO:Declaring metric variables
2025-12-03 10:19:37,684:INFO:Importing untrained model
2025-12-03 10:19:37,684:INFO:Declaring custom model
2025-12-03 10:19:37,685:INFO:Extreme Gradient Boosting Imported successfully
2025-12-03 10:19:37,686:INFO:Cross validation set to False
2025-12-03 10:19:37,686:INFO:Fitting Model
2025-12-03 10:19:37,784:INFO:Warning: No categorical columns found. Calling 'transform' will only return input data.
2025-12-03 10:19:38,401:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'IncomeRatio', 'SystolicBP',
                                             'BMI', 'WaistCircumference',
                                             'Height', 'TotalCholesterol',
                                             'Triglycerides', 'LDL', 'HDL',
                                             'HbA1c', 'Glucose', 'Creatinine',
                                             'UricAcid', 'ALT_Enzyme',
                                             'Albumin', 'Potassium', 'Sodium',
                                             'GGT_Enzyme', 'AST_Enzyme'],
                                    transformer=Si...
                               feature_types=None, gamma=None, grow_policy=None,
                               importance_type=None,
                               interaction_constraints=None, learning_rate=0.4,
                               max_bin=None, max_cat_threshold=None,
                               max_cat_to_onehot=None, max_delta_step=None,
                               max_depth=6, max_leaves=None, min_child_weight=1,
                               missing=nan, monotone_constraints=None,
                               multi_strategy=None, n_estimators=60, n_jobs=1,
                               num_parallel_tree=None,
                               objective='binary:logistic', ...))],
         verbose=False)
2025-12-03 10:19:38,401:INFO:create_model() successfully completed......................................
2025-12-03 10:19:38,606:INFO:_master_model_container: 5
2025-12-03 10:19:38,606:INFO:_display_container: 7
2025-12-03 10:19:38,623:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'IncomeRatio', 'SystolicBP',
                                             'BMI', 'WaistCircumference',
                                             'Height', 'TotalCholesterol',
                                             'Triglycerides', 'LDL', 'HDL',
                                             'HbA1c', 'Glucose', 'Creatinine',
                                             'UricAcid', 'ALT_Enzyme',
                                             'Albumin', 'Potassium', 'Sodium',
                                             'GGT_Enzyme', 'AST_Enzyme'],
                                    transformer=Si...
                               feature_types=None, gamma=None, grow_policy=None,
                               importance_type=None,
                               interaction_constraints=None, learning_rate=0.4,
                               max_bin=None, max_cat_threshold=None,
                               max_cat_to_onehot=None, max_delta_step=None,
                               max_depth=6, max_leaves=None, min_child_weight=1,
                               missing=nan, monotone_constraints=None,
                               multi_strategy=None, n_estimators=60, n_jobs=1,
                               num_parallel_tree=None,
                               objective='binary:logistic', ...))],
         verbose=False)
2025-12-03 10:19:38,623:INFO:finalize_model() successfully completed......................................
2025-12-03 10:19:38,857:INFO:Initializing save_model()
2025-12-03 10:19:38,857:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'IncomeRatio', 'SystolicBP',
                                             'BMI', 'WaistCircumference',
                                             'Height', 'TotalCholesterol',
                                             'Triglycerides', 'LDL', 'HDL',
                                             'HbA1c', 'Glucose', 'Creatinine',
                                             'UricAcid', 'ALT_Enzyme',
                                             'Albumin', 'Potassium', 'Sodium',
                                             'GGT_Enzyme', 'AST_Enzyme'],
                                    transformer=Si...
                               feature_types=None, gamma=None, grow_policy=None,
                               importance_type=None,
                               interaction_constraints=None, learning_rate=0.4,
                               max_bin=None, max_cat_threshold=None,
                               max_cat_to_onehot=None, max_delta_step=None,
                               max_depth=6, max_leaves=None, min_child_weight=1,
                               missing=nan, monotone_constraints=None,
                               multi_strategy=None, n_estimators=60, n_jobs=1,
                               num_parallel_tree=None,
                               objective='binary:logistic', ...))],
         verbose=False), model_name=../models\best_pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\OMAR\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'IncomeRatio', 'SystolicBP',
                                             'BMI', 'WaistCircumference',
                                             'Height', 'TotalCholesterol',
                                             'Triglycerides', 'LDL', 'HDL',
                                             'HbA1c', 'Glucose', 'Creatinine',
                                             'UricAcid', 'ALT_Enzyme',
                                             'Albumin', 'Potassium', 'Sodium',
                                             'G...
                                    transformer=TargetEncoder(cols=[],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=RobustScaler(copy=True,
                                                             quantile_range=(25.0,
                                                                             75.0),
                                                             unit_variance=False,
                                                             with_centering=True,
                                                             with_scaling=True)))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2025-12-03 10:19:38,857:INFO:Adding model into prep_pipe
2025-12-03 10:19:38,857:WARNING:Only Model saved as it was a pipeline.
2025-12-03 10:19:38,866:INFO:../models\best_pipeline.pkl saved in current working directory
2025-12-03 10:19:38,890:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'IncomeRatio', 'SystolicBP',
                                             'BMI', 'WaistCircumference',
                                             'Height', 'TotalCholesterol',
                                             'Triglycerides', 'LDL', 'HDL',
                                             'HbA1c', 'Glucose', 'Creatinine',
                                             'UricAcid', 'ALT_Enzyme',
                                             'Albumin', 'Potassium', 'Sodium',
                                             'GGT_Enzyme', 'AST_Enzyme'],
                                    transformer=Si...
                               feature_types=None, gamma=None, grow_policy=None,
                               importance_type=None,
                               interaction_constraints=None, learning_rate=0.4,
                               max_bin=None, max_cat_threshold=None,
                               max_cat_to_onehot=None, max_delta_step=None,
                               max_depth=6, max_leaves=None, min_child_weight=1,
                               missing=nan, monotone_constraints=None,
                               multi_strategy=None, n_estimators=60, n_jobs=1,
                               num_parallel_tree=None,
                               objective='binary:logistic', ...))],
         verbose=False)
2025-12-03 10:19:38,890:INFO:save_model() successfully completed......................................
2025-12-03 10:20:09,058:INFO:PyCaret ClassificationExperiment
2025-12-03 10:20:09,058:INFO:Logging name: clf-default-name
2025-12-03 10:20:09,058:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-12-03 10:20:09,058:INFO:version 3.3.2
2025-12-03 10:20:09,058:INFO:Initializing setup()
2025-12-03 10:20:09,058:INFO:self.USI: c620
2025-12-03 10:20:09,058:INFO:self._variable_keys: {'idx', 'html_param', '_available_plots', 'y_test', 'USI', 'target_param', 'memory', 'pipeline', 'n_jobs_param', 'X_test', 'seed', 'is_multiclass', 'gpu_param', 'logging_param', 'y_train', 'log_plots_param', 'X_train', 'gpu_n_jobs_param', 'fix_imbalance', 'exp_name_log', 'fold_shuffle_param', 'fold_groups_param', 'X', 'data', 'fold_generator', 'y', 'exp_id', '_ml_usecase'}
2025-12-03 10:20:09,058:INFO:Checking environment
2025-12-03 10:20:09,058:INFO:python_version: 3.10.19
2025-12-03 10:20:09,058:INFO:python_build: ('main', 'Oct 21 2025 16:41:31')
2025-12-03 10:20:09,058:INFO:machine: AMD64
2025-12-03 10:20:09,058:INFO:platform: Windows-10-10.0.26100-SP0
2025-12-03 10:20:09,058:INFO:Memory: svmem(total=16282144768, available=4976058368, percent=69.4, used=11306086400, free=4976058368)
2025-12-03 10:20:09,058:INFO:Physical Core: 6
2025-12-03 10:20:09,058:INFO:Logical Core: 12
2025-12-03 10:20:09,058:INFO:Checking libraries
2025-12-03 10:20:09,058:INFO:System:
2025-12-03 10:20:09,058:INFO:    python: 3.10.19 | packaged by Anaconda, Inc. | (main, Oct 21 2025, 16:41:31) [MSC v.1929 64 bit (AMD64)]
2025-12-03 10:20:09,058:INFO:executable: c:\Users\OMAR\miniconda3\envs\xgb_env\python.exe
2025-12-03 10:20:09,058:INFO:   machine: Windows-10-10.0.26100-SP0
2025-12-03 10:20:09,058:INFO:PyCaret required dependencies:
2025-12-03 10:20:09,058:INFO:                 pip: 25.3
2025-12-03 10:20:09,058:INFO:          setuptools: 80.9.0
2025-12-03 10:20:09,058:INFO:             pycaret: 3.3.2
2025-12-03 10:20:09,058:INFO:             IPython: 8.37.0
2025-12-03 10:20:09,058:INFO:          ipywidgets: 8.1.8
2025-12-03 10:20:09,058:INFO:                tqdm: 4.67.1
2025-12-03 10:20:09,058:INFO:               numpy: 1.26.4
2025-12-03 10:20:09,058:INFO:              pandas: 2.1.4
2025-12-03 10:20:09,058:INFO:              jinja2: 3.1.6
2025-12-03 10:20:09,058:INFO:               scipy: 1.11.4
2025-12-03 10:20:09,058:INFO:              joblib: 1.3.2
2025-12-03 10:20:09,060:INFO:             sklearn: 1.4.2
2025-12-03 10:20:09,060:INFO:                pyod: 2.0.5
2025-12-03 10:20:09,060:INFO:            imblearn: 0.14.0
2025-12-03 10:20:09,060:INFO:   category_encoders: 2.7.0
2025-12-03 10:20:09,060:INFO:            lightgbm: 4.6.0
2025-12-03 10:20:09,060:INFO:               numba: 0.62.1
2025-12-03 10:20:09,060:INFO:            requests: 2.32.5
2025-12-03 10:20:09,060:INFO:          matplotlib: 3.7.5
2025-12-03 10:20:09,060:INFO:          scikitplot: 0.3.7
2025-12-03 10:20:09,061:INFO:         yellowbrick: 1.5
2025-12-03 10:20:09,061:INFO:              plotly: 5.24.1
2025-12-03 10:20:09,061:INFO:    plotly-resampler: Not installed
2025-12-03 10:20:09,061:INFO:             kaleido: 1.2.0
2025-12-03 10:20:09,061:INFO:           schemdraw: 0.15
2025-12-03 10:20:09,061:INFO:         statsmodels: 0.14.5
2025-12-03 10:20:09,061:INFO:              sktime: 0.26.0
2025-12-03 10:20:09,061:INFO:               tbats: 1.1.3
2025-12-03 10:20:09,061:INFO:            pmdarima: 2.0.4
2025-12-03 10:20:09,061:INFO:              psutil: 7.1.3
2025-12-03 10:20:09,061:INFO:          markupsafe: 3.0.3
2025-12-03 10:20:09,061:INFO:             pickle5: Not installed
2025-12-03 10:20:09,061:INFO:         cloudpickle: 3.1.2
2025-12-03 10:20:09,061:INFO:         deprecation: 2.1.0
2025-12-03 10:20:09,061:INFO:              xxhash: 3.6.0
2025-12-03 10:20:09,061:INFO:           wurlitzer: Not installed
2025-12-03 10:20:09,061:INFO:PyCaret optional dependencies:
2025-12-03 10:20:09,061:INFO:                shap: 0.49.1
2025-12-03 10:20:09,061:INFO:           interpret: 0.7.3
2025-12-03 10:20:09,061:INFO:                umap: 0.5.7
2025-12-03 10:20:09,061:INFO:     ydata_profiling: 4.18.0
2025-12-03 10:20:09,061:INFO:  explainerdashboard: 0.5.1
2025-12-03 10:20:09,061:INFO:             autoviz: Not installed
2025-12-03 10:20:09,061:INFO:           fairlearn: 0.7.0
2025-12-03 10:20:09,061:INFO:          deepchecks: Not installed
2025-12-03 10:20:09,061:INFO:             xgboost: 2.1.3
2025-12-03 10:20:09,061:INFO:            catboost: 1.2.8
2025-12-03 10:20:09,061:INFO:              kmodes: 0.12.2
2025-12-03 10:20:09,061:INFO:             mlxtend: 0.23.4
2025-12-03 10:20:09,061:INFO:       statsforecast: 1.5.0
2025-12-03 10:20:09,061:INFO:        tune_sklearn: Not installed
2025-12-03 10:20:09,061:INFO:                 ray: Not installed
2025-12-03 10:20:09,061:INFO:            hyperopt: 0.2.7
2025-12-03 10:20:09,061:INFO:              optuna: 4.6.0
2025-12-03 10:20:09,062:INFO:               skopt: 0.10.2
2025-12-03 10:20:09,062:INFO:              mlflow: 3.6.0
2025-12-03 10:20:09,062:INFO:              gradio: 6.0.1
2025-12-03 10:20:09,062:INFO:             fastapi: 0.123.0
2025-12-03 10:20:09,062:INFO:             uvicorn: 0.38.0
2025-12-03 10:20:09,062:INFO:              m2cgen: 0.10.0
2025-12-03 10:20:09,062:INFO:           evidently: 0.4.40
2025-12-03 10:20:09,062:INFO:               fugue: 0.8.7
2025-12-03 10:20:09,062:INFO:           streamlit: 1.51.0
2025-12-03 10:20:09,062:INFO:             prophet: Not installed
2025-12-03 10:20:09,062:INFO:None
2025-12-03 10:20:09,062:INFO:Set up data.
2025-12-03 10:20:09,088:INFO:Set up folding strategy.
2025-12-03 10:20:09,088:INFO:Set up train/test split.
2025-12-03 10:20:09,112:INFO:Set up index.
2025-12-03 10:20:09,112:INFO:Assigning column types.
2025-12-03 10:20:09,130:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-12-03 10:20:09,158:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-12-03 10:20:09,158:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-03 10:20:09,176:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-03 10:20:09,180:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-03 10:20:09,209:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-12-03 10:20:09,209:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-03 10:20:09,228:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-03 10:20:09,230:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-03 10:20:09,231:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-12-03 10:20:09,256:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-03 10:20:09,273:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-03 10:20:09,276:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-03 10:20:09,305:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-03 10:20:09,320:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-03 10:20:09,323:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-03 10:20:09,323:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-12-03 10:20:09,368:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-03 10:20:09,370:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-03 10:20:09,414:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-03 10:20:09,417:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-03 10:20:09,418:INFO:Preparing preprocessing pipeline...
2025-12-03 10:20:09,420:INFO:Set up simple imputation.
2025-12-03 10:20:09,434:INFO:Set up encoding of ordinal features.
2025-12-03 10:20:09,441:INFO:Set up encoding of categorical features.
2025-12-03 10:20:09,441:INFO:Set up feature normalization.
2025-12-03 10:20:09,615:INFO:Finished creating preprocessing pipeline.
2025-12-03 10:20:09,628:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\OMAR\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'IncomeRatio', 'SystolicBP',
                                             'BMI', 'WaistCircumference',
                                             'Height', 'TotalCholesterol',
                                             'Triglycerides', 'LDL', 'HDL',
                                             'HbA1c', 'Glucose', 'Creatinine',
                                             'UricAcid', 'ALT_Enzyme',
                                             'Albumin', 'Potassium', 'Sodium',
                                             'G...
                                    transformer=TargetEncoder(cols=[],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=RobustScaler(copy=True,
                                                             quantile_range=(25.0,
                                                                             75.0),
                                                             unit_variance=False,
                                                             with_centering=True,
                                                             with_scaling=True)))],
         verbose=False)
2025-12-03 10:20:09,630:INFO:Creating final display dataframe.
2025-12-03 10:20:09,855:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target      HeartDisease
2                   Target type            Binary
3           Original data shape       (43695, 28)
4        Transformed data shape       (43695, 32)
5   Transformed train set shape       (30586, 32)
6    Transformed test set shape       (13109, 32)
7              Numeric features                20
8          Categorical features                 7
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15                    Normalize              True
16             Normalize method            robust
17               Fold Generator   StratifiedKFold
18                  Fold Number                10
19                     CPU Jobs                 1
20                      Use GPU             False
21               Log Experiment             False
22              Experiment Name  clf-default-name
23                          USI              c620
2025-12-03 10:20:09,904:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-03 10:20:09,906:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-03 10:20:09,950:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-03 10:20:09,952:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-03 10:20:09,953:INFO:setup() successfully completed in 0.9s...............
2025-12-03 10:20:10,003:INFO:Initializing get_config()
2025-12-03 10:20:10,003:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FAFD737C0>, variable=y_train)
2025-12-03 10:20:10,003:INFO:Variable: 'y_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_train_transformed' instead.
2025-12-03 10:20:10,003:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_train_transformed' instead.

2025-12-03 10:20:10,013:INFO:Variable:  returned as 15208    0.0
25325    0.0
5132     0.0
17217    0.0
6382     0.0
        ... 
6265     0.0
42694    0.0
13399    0.0
39959    0.0
6616     0.0
Name: HeartDisease, Length: 30586, dtype: float32
2025-12-03 10:20:10,013:INFO:get_config() successfully completed......................................
2025-12-03 10:20:10,014:INFO:Initializing create_model()
2025-12-03 10:20:10,014:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FAFD737C0>, estimator=xgboost, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={'scale_pos_weight': 76.32522407170295})
2025-12-03 10:20:10,014:INFO:Checking exceptions
2025-12-03 10:20:10,023:INFO:Importing libraries
2025-12-03 10:20:10,023:INFO:Copying training dataset
2025-12-03 10:20:10,059:INFO:Defining folds
2025-12-03 10:20:10,059:INFO:Declaring metric variables
2025-12-03 10:20:10,062:INFO:Importing untrained model
2025-12-03 10:20:10,066:INFO:Extreme Gradient Boosting Imported successfully
2025-12-03 10:20:10,073:INFO:Starting cross validation
2025-12-03 10:20:10,075:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-12-03 10:20:16,680:INFO:Calculating mean and std
2025-12-03 10:20:16,681:INFO:Creating metrics dataframe
2025-12-03 10:20:16,686:INFO:Finalizing model
2025-12-03 10:20:16,770:INFO:Warning: No categorical columns found. Calling 'transform' will only return input data.
2025-12-03 10:20:17,334:INFO:Uploading results into container
2025-12-03 10:20:17,334:INFO:Uploading model into container now
2025-12-03 10:20:17,343:INFO:_master_model_container: 1
2025-12-03 10:20:17,343:INFO:_display_container: 2
2025-12-03 10:20:17,344:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2025-12-03 10:20:17,344:INFO:create_model() successfully completed......................................
2025-12-03 10:20:17,579:INFO:Initializing create_model()
2025-12-03 10:20:17,579:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FAFD737C0>, estimator=lr, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-03 10:20:17,579:INFO:Checking exceptions
2025-12-03 10:20:17,591:INFO:Importing libraries
2025-12-03 10:20:17,591:INFO:Copying training dataset
2025-12-03 10:20:17,623:INFO:Defining folds
2025-12-03 10:20:17,623:INFO:Declaring metric variables
2025-12-03 10:20:17,626:INFO:Importing untrained model
2025-12-03 10:20:17,631:INFO:Logistic Regression Imported successfully
2025-12-03 10:20:17,638:INFO:Starting cross validation
2025-12-03 10:20:17,640:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-12-03 10:20:18,633:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-12-03 10:20:19,258:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-12-03 10:20:19,658:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-12-03 10:20:19,660:INFO:Calculating mean and std
2025-12-03 10:20:19,660:INFO:Creating metrics dataframe
2025-12-03 10:20:19,669:INFO:Finalizing model
2025-12-03 10:20:19,754:INFO:Warning: No categorical columns found. Calling 'transform' will only return input data.
2025-12-03 10:20:19,858:INFO:Uploading results into container
2025-12-03 10:20:19,858:INFO:Uploading model into container now
2025-12-03 10:20:19,867:INFO:_master_model_container: 2
2025-12-03 10:20:19,867:INFO:_display_container: 3
2025-12-03 10:20:19,868:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-12-03 10:20:19,868:INFO:create_model() successfully completed......................................
2025-12-03 10:20:20,049:INFO:Initializing create_model()
2025-12-03 10:20:20,049:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FAFD737C0>, estimator=rf, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-03 10:20:20,049:INFO:Checking exceptions
2025-12-03 10:20:20,060:INFO:Importing libraries
2025-12-03 10:20:20,060:INFO:Copying training dataset
2025-12-03 10:20:20,090:INFO:Defining folds
2025-12-03 10:20:20,091:INFO:Declaring metric variables
2025-12-03 10:20:20,094:INFO:Importing untrained model
2025-12-03 10:20:20,097:INFO:Random Forest Classifier Imported successfully
2025-12-03 10:20:20,104:INFO:Starting cross validation
2025-12-03 10:20:20,106:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-12-03 10:21:01,844:INFO:Calculating mean and std
2025-12-03 10:21:01,844:INFO:Creating metrics dataframe
2025-12-03 10:21:01,850:INFO:Finalizing model
2025-12-03 10:21:01,938:INFO:Warning: No categorical columns found. Calling 'transform' will only return input data.
2025-12-03 10:21:06,552:INFO:Uploading results into container
2025-12-03 10:21:06,554:INFO:Uploading model into container now
2025-12-03 10:21:06,564:INFO:_master_model_container: 3
2025-12-03 10:21:06,564:INFO:_display_container: 4
2025-12-03 10:21:06,564:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2025-12-03 10:21:06,564:INFO:create_model() successfully completed......................................
2025-12-03 10:21:06,792:INFO:Initializing get_config()
2025-12-03 10:21:06,792:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FAFD737C0>, variable=X_train_transformed)
2025-12-03 10:21:06,832:INFO:Variable: X_train returned as             Age  IncomeRatio  SystolicBP       BMI  WaistCircumference  \
15208  0.954545     0.854789    0.359485  0.518044            0.206281   
25325 -0.272727     0.253271   -0.812170 -0.966167           -0.799656   
5132   0.181818    -0.407608   -0.372799  0.054886            0.319578   
17217  0.500000    -0.751898    0.013314 -0.260904            0.278379   
6382   0.568182     0.054503    1.131712  2.675938            1.888566   
...         ...          ...         ...       ...                 ...   
6265  -0.545455    -0.431352   -0.591719  0.191728           -0.377368   
42694 -0.022727    -0.221612   -0.892056 -0.260904           -0.047778   
13399  0.454545     0.388518    0.377985  0.271482            0.183567   
39959  0.954545    -0.193911    0.625770  0.991728            1.160720   
6616   0.613636    -0.447182    0.652399 -0.871430           -0.514698   

         Height  TotalCholesterol  Triglycerides       LDL       HDL  ...  \
15208 -0.487303          0.625876       0.583394  0.005397  0.314564  ...   
25325 -0.300856          0.033588      -0.261476  0.000256  0.303682  ...   
5132   0.766972          0.181594       0.479279  0.948690 -1.340476  ...   
17217  0.745785          0.227516       0.346113  0.002441 -0.274561  ...   
6382   0.237295          0.867515       0.635574  0.002754  0.829819  ...   
...         ...               ...            ...       ...       ...  ...   
6265  -1.737339         -1.393483      -0.471046 -3.840886  0.063832  ...   
42694  0.000000          0.029167      -0.131730  0.000893  0.063832  ...   
13399 -0.147405          0.462357       0.380371  0.003925  0.256949  ...   
39959  0.368655          1.528031       1.934134  0.011744  0.191497  ...   
6616  -0.021187         -0.224877      -0.043571 -1.609476  0.510658  ...   

       Race_5.0  Race_1.0  Race_4.0  Race_3.0  Race_2.0  Education  Smoking  \
15208       1.0       0.0       0.0       0.0       0.0  -0.659696      0.0   
25325       0.0       1.0       0.0       0.0       0.0   0.185278      0.0   
5132        0.0       1.0       0.0       0.0       0.0  -0.659696      1.0   
17217       0.0       0.0       1.0       0.0       0.0  -0.056119      1.0   
6382        0.0       0.0       1.0       0.0       0.0   0.547458      1.0   
...         ...       ...       ...       ...       ...        ...      ...   
6265        0.0       1.0       0.0       0.0       0.0  -0.769055      0.0   
42694       0.0       1.0       0.0       0.0       0.0   0.547458      0.0   
13399       0.0       0.0       1.0       0.0       0.0   0.547458      0.0   
39959       0.0       0.0       0.0       1.0       0.0   0.547458      0.0   
6616        0.0       0.0       0.0       1.0       0.0   0.547458      1.0   

       PhysicalActivity  HealthInsurance   Alcohol  
15208          0.000000              0.0 -0.886483  
25325          0.000000              0.0  0.592213  
5132           0.000000             -1.0  0.312949  
17217          0.000000              0.0  0.592213  
6382           0.000000              0.0  0.597293  
...                 ...              ...       ...  
6265           0.662459              0.0 -0.501621  
42694          0.000000             -1.0  0.592213  
13399          0.000000              0.0 -0.224534  
39959          0.000000              0.0  0.592213  
6616           0.000000              0.0  0.290247  

[30586 rows x 31 columns]
2025-12-03 10:21:06,832:INFO:get_config() successfully completed......................................
2025-12-03 10:21:06,832:INFO:Initializing get_config()
2025-12-03 10:21:06,832:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FAFD737C0>, variable=y_train)
2025-12-03 10:21:06,832:INFO:Variable: 'y_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_train_transformed' instead.
2025-12-03 10:21:06,832:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_train_transformed' instead.

2025-12-03 10:21:06,838:INFO:Variable:  returned as 15208    0.0
25325    0.0
5132     0.0
17217    0.0
6382     0.0
        ... 
6265     0.0
42694    0.0
13399    0.0
39959    0.0
6616     0.0
Name: HeartDisease, Length: 30586, dtype: float32
2025-12-03 10:21:06,839:INFO:get_config() successfully completed......................................
2025-12-03 10:21:06,840:INFO:Initializing get_config()
2025-12-03 10:21:06,840:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FAFD737C0>, variable=X_test_transformed)
2025-12-03 10:21:06,921:INFO:Variable: X_test returned as             Age  IncomeRatio  SystolicBP       BMI  WaistCircumference  \
28456 -0.477273    -0.304717   -0.519256 -0.987220           -0.923253   
8993   0.818182     0.253271    2.156910  0.770675            0.920394   
34312  0.704545     0.055403    0.519256  0.518044            0.662901   
4802  -0.545455     0.253730   -0.331933 -0.229036           -0.436352   
25895  0.704545     1.226781   -0.093200 -0.226100            0.012322   
...         ...          ...         ...       ...                 ...   
18045 -0.568182    -0.083104   -0.568713 -1.176693           -1.338674   
5425   0.590909     0.362732    2.210168  0.139096            0.292112   
12819  0.909091    -0.019787    0.899042  0.454886            0.971892   
33659 -0.522727     1.060572   -0.525683 -0.587220           -0.906087   
19531 -0.590909    -0.344290   -0.510287 -0.945114           -1.215078   

         Height  TotalCholesterol  Triglycerides       LDL       HDL  ...  \
28456 -1.080540         -0.078535      -0.470757 -0.026922  0.418008  ...   
8993  -0.279669          0.765897       0.705031  0.006026  0.446825  ...   
34312  0.559339         -0.123259       0.929511 -1.031826 -1.404309  ...   
4802  -0.504861         -0.188325      -0.322647  0.000015 -0.138743  ...   
25895  0.216731          0.892919       1.291109  0.008211 -0.255329  ...   
...         ...               ...            ...       ...       ...  ...   
18045 -2.080569         -0.340947      -0.470582 -0.848950  0.393794  ...   
5425   0.156785          0.435639      -0.065356  1.113733  0.127664  ...   
12819  1.194951         -0.732967      -0.470025 -0.211535 -1.085148  ...   
33659 -1.254274         -1.063225      -0.470958 -2.849419  0.127664  ...   
19531 -2.339052         -0.356898      -0.470595 -0.900608  0.393896  ...   

       Race_5.0  Race_1.0  Race_4.0  Race_3.0  Race_2.0  Education   Smoking  \
28456       1.0       0.0       0.0       0.0       0.0  -0.012820  0.000000   
8993        0.0       0.0       1.0       0.0       0.0   0.547458  1.000000   
34312       0.0       0.0       0.0       1.0       0.0  -0.659696  0.000000   
4802        1.0       0.0       0.0       0.0       0.0   0.262895  0.073612   
25895       0.0       0.0       0.0       1.0       0.0   1.151035  0.000000   
...         ...       ...       ...       ...       ...        ...       ...   
18045       0.0       0.0       0.0       1.0       0.0  -0.793202  0.000000   
5425        0.0       0.0       1.0       0.0       0.0   0.547458  1.000000   
12819       0.0       0.0       0.0       1.0       0.0   1.151035  1.000000   
33659       0.0       0.0       1.0       0.0       0.0   0.258362  0.000000   
19531       1.0       0.0       0.0       0.0       0.0  -0.821118  0.000000   

       PhysicalActivity  HealthInsurance   Alcohol  
28456          0.660578              0.0 -0.518600  
8993           0.000000              0.0  0.115329  
34312          0.000000              0.0  0.592213  
4802           1.012447              0.0 -0.103347  
25895          0.000000              0.0 -0.886483  
...                 ...              ...       ...  
18045          0.904383              0.0 -0.482716  
5425           1.598141              0.0  0.097790  
12819          1.598141              0.0  0.612947  
33659          1.162475              0.0 -0.154408  
19531          0.791302              0.0 -0.683278  

[13109 rows x 31 columns]
2025-12-03 10:21:06,921:INFO:get_config() successfully completed......................................
2025-12-03 10:21:06,921:INFO:Initializing get_config()
2025-12-03 10:21:06,921:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FAFD737C0>, variable=y_test)
2025-12-03 10:21:06,923:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-12-03 10:21:06,923:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-12-03 10:21:06,929:INFO:Variable:  returned as 28456    0.0
8993     0.0
34312    0.0
4802     0.0
25895    0.0
        ... 
18045    0.0
5425     0.0
12819    0.0
33659    0.0
19531    0.0
Name: HeartDisease, Length: 13109, dtype: float32
2025-12-03 10:21:06,929:INFO:get_config() successfully completed......................................
2025-12-03 10:21:07,092:INFO:Initializing get_config()
2025-12-03 10:21:07,092:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FAFD737C0>, variable=X_train_transformed)
2025-12-03 10:21:07,131:INFO:Variable: X_train returned as             Age  IncomeRatio  SystolicBP       BMI  WaistCircumference  \
15208  0.954545     0.854789    0.359485  0.518044            0.206281   
25325 -0.272727     0.253271   -0.812170 -0.966167           -0.799656   
5132   0.181818    -0.407608   -0.372799  0.054886            0.319578   
17217  0.500000    -0.751898    0.013314 -0.260904            0.278379   
6382   0.568182     0.054503    1.131712  2.675938            1.888566   
...         ...          ...         ...       ...                 ...   
6265  -0.545455    -0.431352   -0.591719  0.191728           -0.377368   
42694 -0.022727    -0.221612   -0.892056 -0.260904           -0.047778   
13399  0.454545     0.388518    0.377985  0.271482            0.183567   
39959  0.954545    -0.193911    0.625770  0.991728            1.160720   
6616   0.613636    -0.447182    0.652399 -0.871430           -0.514698   

         Height  TotalCholesterol  Triglycerides       LDL       HDL  ...  \
15208 -0.487303          0.625876       0.583394  0.005397  0.314564  ...   
25325 -0.300856          0.033588      -0.261476  0.000256  0.303682  ...   
5132   0.766972          0.181594       0.479279  0.948690 -1.340476  ...   
17217  0.745785          0.227516       0.346113  0.002441 -0.274561  ...   
6382   0.237295          0.867515       0.635574  0.002754  0.829819  ...   
...         ...               ...            ...       ...       ...  ...   
6265  -1.737339         -1.393483      -0.471046 -3.840886  0.063832  ...   
42694  0.000000          0.029167      -0.131730  0.000893  0.063832  ...   
13399 -0.147405          0.462357       0.380371  0.003925  0.256949  ...   
39959  0.368655          1.528031       1.934134  0.011744  0.191497  ...   
6616  -0.021187         -0.224877      -0.043571 -1.609476  0.510658  ...   

       Race_5.0  Race_1.0  Race_4.0  Race_3.0  Race_2.0  Education  Smoking  \
15208       1.0       0.0       0.0       0.0       0.0  -0.659696      0.0   
25325       0.0       1.0       0.0       0.0       0.0   0.185278      0.0   
5132        0.0       1.0       0.0       0.0       0.0  -0.659696      1.0   
17217       0.0       0.0       1.0       0.0       0.0  -0.056119      1.0   
6382        0.0       0.0       1.0       0.0       0.0   0.547458      1.0   
...         ...       ...       ...       ...       ...        ...      ...   
6265        0.0       1.0       0.0       0.0       0.0  -0.769055      0.0   
42694       0.0       1.0       0.0       0.0       0.0   0.547458      0.0   
13399       0.0       0.0       1.0       0.0       0.0   0.547458      0.0   
39959       0.0       0.0       0.0       1.0       0.0   0.547458      0.0   
6616        0.0       0.0       0.0       1.0       0.0   0.547458      1.0   

       PhysicalActivity  HealthInsurance   Alcohol  
15208          0.000000              0.0 -0.886483  
25325          0.000000              0.0  0.592213  
5132           0.000000             -1.0  0.312949  
17217          0.000000              0.0  0.592213  
6382           0.000000              0.0  0.597293  
...                 ...              ...       ...  
6265           0.662459              0.0 -0.501621  
42694          0.000000             -1.0  0.592213  
13399          0.000000              0.0 -0.224534  
39959          0.000000              0.0  0.592213  
6616           0.000000              0.0  0.290247  

[30586 rows x 31 columns]
2025-12-03 10:21:07,131:INFO:get_config() successfully completed......................................
2025-12-03 10:21:07,131:INFO:Initializing get_config()
2025-12-03 10:21:07,131:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FAFD737C0>, variable=y_train)
2025-12-03 10:21:07,131:INFO:Variable: 'y_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_train_transformed' instead.
2025-12-03 10:21:07,131:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_train_transformed' instead.

2025-12-03 10:21:07,136:INFO:Variable:  returned as 15208    0.0
25325    0.0
5132     0.0
17217    0.0
6382     0.0
        ... 
6265     0.0
42694    0.0
13399    0.0
39959    0.0
6616     0.0
Name: HeartDisease, Length: 30586, dtype: float32
2025-12-03 10:21:07,138:INFO:get_config() successfully completed......................................
2025-12-03 10:21:07,139:INFO:Initializing get_config()
2025-12-03 10:21:07,140:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FAFD737C0>, variable=X_test_transformed)
2025-12-03 10:21:07,219:INFO:Variable: X_test returned as             Age  IncomeRatio  SystolicBP       BMI  WaistCircumference  \
28456 -0.477273    -0.304717   -0.519256 -0.987220           -0.923253   
8993   0.818182     0.253271    2.156910  0.770675            0.920394   
34312  0.704545     0.055403    0.519256  0.518044            0.662901   
4802  -0.545455     0.253730   -0.331933 -0.229036           -0.436352   
25895  0.704545     1.226781   -0.093200 -0.226100            0.012322   
...         ...          ...         ...       ...                 ...   
18045 -0.568182    -0.083104   -0.568713 -1.176693           -1.338674   
5425   0.590909     0.362732    2.210168  0.139096            0.292112   
12819  0.909091    -0.019787    0.899042  0.454886            0.971892   
33659 -0.522727     1.060572   -0.525683 -0.587220           -0.906087   
19531 -0.590909    -0.344290   -0.510287 -0.945114           -1.215078   

         Height  TotalCholesterol  Triglycerides       LDL       HDL  ...  \
28456 -1.080540         -0.078535      -0.470757 -0.026922  0.418008  ...   
8993  -0.279669          0.765897       0.705031  0.006026  0.446825  ...   
34312  0.559339         -0.123259       0.929511 -1.031826 -1.404309  ...   
4802  -0.504861         -0.188325      -0.322647  0.000015 -0.138743  ...   
25895  0.216731          0.892919       1.291109  0.008211 -0.255329  ...   
...         ...               ...            ...       ...       ...  ...   
18045 -2.080569         -0.340947      -0.470582 -0.848950  0.393794  ...   
5425   0.156785          0.435639      -0.065356  1.113733  0.127664  ...   
12819  1.194951         -0.732967      -0.470025 -0.211535 -1.085148  ...   
33659 -1.254274         -1.063225      -0.470958 -2.849419  0.127664  ...   
19531 -2.339052         -0.356898      -0.470595 -0.900608  0.393896  ...   

       Race_5.0  Race_1.0  Race_4.0  Race_3.0  Race_2.0  Education   Smoking  \
28456       1.0       0.0       0.0       0.0       0.0  -0.012820  0.000000   
8993        0.0       0.0       1.0       0.0       0.0   0.547458  1.000000   
34312       0.0       0.0       0.0       1.0       0.0  -0.659696  0.000000   
4802        1.0       0.0       0.0       0.0       0.0   0.262895  0.073612   
25895       0.0       0.0       0.0       1.0       0.0   1.151035  0.000000   
...         ...       ...       ...       ...       ...        ...       ...   
18045       0.0       0.0       0.0       1.0       0.0  -0.793202  0.000000   
5425        0.0       0.0       1.0       0.0       0.0   0.547458  1.000000   
12819       0.0       0.0       0.0       1.0       0.0   1.151035  1.000000   
33659       0.0       0.0       1.0       0.0       0.0   0.258362  0.000000   
19531       1.0       0.0       0.0       0.0       0.0  -0.821118  0.000000   

       PhysicalActivity  HealthInsurance   Alcohol  
28456          0.660578              0.0 -0.518600  
8993           0.000000              0.0  0.115329  
34312          0.000000              0.0  0.592213  
4802           1.012447              0.0 -0.103347  
25895          0.000000              0.0 -0.886483  
...                 ...              ...       ...  
18045          0.904383              0.0 -0.482716  
5425           1.598141              0.0  0.097790  
12819          1.598141              0.0  0.612947  
33659          1.162475              0.0 -0.154408  
19531          0.791302              0.0 -0.683278  

[13109 rows x 31 columns]
2025-12-03 10:21:07,219:INFO:get_config() successfully completed......................................
2025-12-03 10:21:07,219:INFO:Initializing get_config()
2025-12-03 10:21:07,219:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FAFD737C0>, variable=y_test)
2025-12-03 10:21:07,219:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-12-03 10:21:07,219:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-12-03 10:21:07,223:INFO:Variable:  returned as 28456    0.0
8993     0.0
34312    0.0
4802     0.0
25895    0.0
        ... 
18045    0.0
5425     0.0
12819    0.0
33659    0.0
19531    0.0
Name: HeartDisease, Length: 13109, dtype: float32
2025-12-03 10:21:07,225:INFO:get_config() successfully completed......................................
2025-12-03 10:21:07,359:INFO:Initializing get_config()
2025-12-03 10:21:07,359:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FAFD737C0>, variable=X_test_transformed)
2025-12-03 10:21:07,443:INFO:Variable: X_test returned as             Age  IncomeRatio  SystolicBP       BMI  WaistCircumference  \
28456 -0.477273    -0.304717   -0.519256 -0.987220           -0.923253   
8993   0.818182     0.253271    2.156910  0.770675            0.920394   
34312  0.704545     0.055403    0.519256  0.518044            0.662901   
4802  -0.545455     0.253730   -0.331933 -0.229036           -0.436352   
25895  0.704545     1.226781   -0.093200 -0.226100            0.012322   
...         ...          ...         ...       ...                 ...   
18045 -0.568182    -0.083104   -0.568713 -1.176693           -1.338674   
5425   0.590909     0.362732    2.210168  0.139096            0.292112   
12819  0.909091    -0.019787    0.899042  0.454886            0.971892   
33659 -0.522727     1.060572   -0.525683 -0.587220           -0.906087   
19531 -0.590909    -0.344290   -0.510287 -0.945114           -1.215078   

         Height  TotalCholesterol  Triglycerides       LDL       HDL  ...  \
28456 -1.080540         -0.078535      -0.470757 -0.026922  0.418008  ...   
8993  -0.279669          0.765897       0.705031  0.006026  0.446825  ...   
34312  0.559339         -0.123259       0.929511 -1.031826 -1.404309  ...   
4802  -0.504861         -0.188325      -0.322647  0.000015 -0.138743  ...   
25895  0.216731          0.892919       1.291109  0.008211 -0.255329  ...   
...         ...               ...            ...       ...       ...  ...   
18045 -2.080569         -0.340947      -0.470582 -0.848950  0.393794  ...   
5425   0.156785          0.435639      -0.065356  1.113733  0.127664  ...   
12819  1.194951         -0.732967      -0.470025 -0.211535 -1.085148  ...   
33659 -1.254274         -1.063225      -0.470958 -2.849419  0.127664  ...   
19531 -2.339052         -0.356898      -0.470595 -0.900608  0.393896  ...   

       Race_5.0  Race_1.0  Race_4.0  Race_3.0  Race_2.0  Education   Smoking  \
28456       1.0       0.0       0.0       0.0       0.0  -0.012820  0.000000   
8993        0.0       0.0       1.0       0.0       0.0   0.547458  1.000000   
34312       0.0       0.0       0.0       1.0       0.0  -0.659696  0.000000   
4802        1.0       0.0       0.0       0.0       0.0   0.262895  0.073612   
25895       0.0       0.0       0.0       1.0       0.0   1.151035  0.000000   
...         ...       ...       ...       ...       ...        ...       ...   
18045       0.0       0.0       0.0       1.0       0.0  -0.793202  0.000000   
5425        0.0       0.0       1.0       0.0       0.0   0.547458  1.000000   
12819       0.0       0.0       0.0       1.0       0.0   1.151035  1.000000   
33659       0.0       0.0       1.0       0.0       0.0   0.258362  0.000000   
19531       1.0       0.0       0.0       0.0       0.0  -0.821118  0.000000   

       PhysicalActivity  HealthInsurance   Alcohol  
28456          0.660578              0.0 -0.518600  
8993           0.000000              0.0  0.115329  
34312          0.000000              0.0  0.592213  
4802           1.012447              0.0 -0.103347  
25895          0.000000              0.0 -0.886483  
...                 ...              ...       ...  
18045          0.904383              0.0 -0.482716  
5425           1.598141              0.0  0.097790  
12819          1.598141              0.0  0.612947  
33659          1.162475              0.0 -0.154408  
19531          0.791302              0.0 -0.683278  

[13109 rows x 31 columns]
2025-12-03 10:21:07,444:INFO:get_config() successfully completed......................................
2025-12-03 10:21:07,471:INFO:Initializing get_config()
2025-12-03 10:21:07,471:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FAFD737C0>, variable=y_test)
2025-12-03 10:21:07,471:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-12-03 10:21:07,471:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-12-03 10:21:07,477:INFO:Variable:  returned as 28456    0.0
8993     0.0
34312    0.0
4802     0.0
25895    0.0
        ... 
18045    0.0
5425     0.0
12819    0.0
33659    0.0
19531    0.0
Name: HeartDisease, Length: 13109, dtype: float32
2025-12-03 10:21:07,478:INFO:get_config() successfully completed......................................
2025-12-03 10:21:07,481:INFO:Initializing get_config()
2025-12-03 10:21:07,481:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FAFD737C0>, variable=y_test)
2025-12-03 10:21:07,481:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-12-03 10:21:07,481:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-12-03 10:21:07,484:INFO:Variable:  returned as 28456    0.0
8993     0.0
34312    0.0
4802     0.0
25895    0.0
        ... 
18045    0.0
5425     0.0
12819    0.0
33659    0.0
19531    0.0
Name: HeartDisease, Length: 13109, dtype: float32
2025-12-03 10:21:07,484:INFO:get_config() successfully completed......................................
2025-12-03 10:21:07,489:INFO:Initializing get_config()
2025-12-03 10:21:07,489:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FAFD737C0>, variable=X_test_transformed)
2025-12-03 10:21:07,569:INFO:Variable: X_test returned as             Age  IncomeRatio  SystolicBP       BMI  WaistCircumference  \
28456 -0.477273    -0.304717   -0.519256 -0.987220           -0.923253   
8993   0.818182     0.253271    2.156910  0.770675            0.920394   
34312  0.704545     0.055403    0.519256  0.518044            0.662901   
4802  -0.545455     0.253730   -0.331933 -0.229036           -0.436352   
25895  0.704545     1.226781   -0.093200 -0.226100            0.012322   
...         ...          ...         ...       ...                 ...   
18045 -0.568182    -0.083104   -0.568713 -1.176693           -1.338674   
5425   0.590909     0.362732    2.210168  0.139096            0.292112   
12819  0.909091    -0.019787    0.899042  0.454886            0.971892   
33659 -0.522727     1.060572   -0.525683 -0.587220           -0.906087   
19531 -0.590909    -0.344290   -0.510287 -0.945114           -1.215078   

         Height  TotalCholesterol  Triglycerides       LDL       HDL  ...  \
28456 -1.080540         -0.078535      -0.470757 -0.026922  0.418008  ...   
8993  -0.279669          0.765897       0.705031  0.006026  0.446825  ...   
34312  0.559339         -0.123259       0.929511 -1.031826 -1.404309  ...   
4802  -0.504861         -0.188325      -0.322647  0.000015 -0.138743  ...   
25895  0.216731          0.892919       1.291109  0.008211 -0.255329  ...   
...         ...               ...            ...       ...       ...  ...   
18045 -2.080569         -0.340947      -0.470582 -0.848950  0.393794  ...   
5425   0.156785          0.435639      -0.065356  1.113733  0.127664  ...   
12819  1.194951         -0.732967      -0.470025 -0.211535 -1.085148  ...   
33659 -1.254274         -1.063225      -0.470958 -2.849419  0.127664  ...   
19531 -2.339052         -0.356898      -0.470595 -0.900608  0.393896  ...   

       Race_5.0  Race_1.0  Race_4.0  Race_3.0  Race_2.0  Education   Smoking  \
28456       1.0       0.0       0.0       0.0       0.0  -0.012820  0.000000   
8993        0.0       0.0       1.0       0.0       0.0   0.547458  1.000000   
34312       0.0       0.0       0.0       1.0       0.0  -0.659696  0.000000   
4802        1.0       0.0       0.0       0.0       0.0   0.262895  0.073612   
25895       0.0       0.0       0.0       1.0       0.0   1.151035  0.000000   
...         ...       ...       ...       ...       ...        ...       ...   
18045       0.0       0.0       0.0       1.0       0.0  -0.793202  0.000000   
5425        0.0       0.0       1.0       0.0       0.0   0.547458  1.000000   
12819       0.0       0.0       0.0       1.0       0.0   1.151035  1.000000   
33659       0.0       0.0       1.0       0.0       0.0   0.258362  0.000000   
19531       1.0       0.0       0.0       0.0       0.0  -0.821118  0.000000   

       PhysicalActivity  HealthInsurance   Alcohol  
28456          0.660578              0.0 -0.518600  
8993           0.000000              0.0  0.115329  
34312          0.000000              0.0  0.592213  
4802           1.012447              0.0 -0.103347  
25895          0.000000              0.0 -0.886483  
...                 ...              ...       ...  
18045          0.904383              0.0 -0.482716  
5425           1.598141              0.0  0.097790  
12819          1.598141              0.0  0.612947  
33659          1.162475              0.0 -0.154408  
19531          0.791302              0.0 -0.683278  

[13109 rows x 31 columns]
2025-12-03 10:21:07,569:INFO:get_config() successfully completed......................................
2025-12-03 10:21:07,570:INFO:Initializing get_config()
2025-12-03 10:21:07,570:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FAFD737C0>, variable=y_test)
2025-12-03 10:21:07,570:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-12-03 10:21:07,570:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-12-03 10:21:07,576:INFO:Variable:  returned as 28456    0.0
8993     0.0
34312    0.0
4802     0.0
25895    0.0
        ... 
18045    0.0
5425     0.0
12819    0.0
33659    0.0
19531    0.0
Name: HeartDisease, Length: 13109, dtype: float32
2025-12-03 10:21:07,576:INFO:get_config() successfully completed......................................
2025-12-03 10:21:07,579:INFO:Initializing get_config()
2025-12-03 10:21:07,579:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FAFD737C0>, variable=y_test)
2025-12-03 10:21:07,579:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-12-03 10:21:07,579:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-12-03 10:21:07,584:INFO:Variable:  returned as 28456    0.0
8993     0.0
34312    0.0
4802     0.0
25895    0.0
        ... 
18045    0.0
5425     0.0
12819    0.0
33659    0.0
19531    0.0
Name: HeartDisease, Length: 13109, dtype: float32
2025-12-03 10:21:07,584:INFO:get_config() successfully completed......................................
2025-12-03 10:21:07,584:INFO:Initializing get_config()
2025-12-03 10:21:07,584:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FAFD737C0>, variable=X_test_transformed)
2025-12-03 10:21:07,662:INFO:Variable: X_test returned as             Age  IncomeRatio  SystolicBP       BMI  WaistCircumference  \
28456 -0.477273    -0.304717   -0.519256 -0.987220           -0.923253   
8993   0.818182     0.253271    2.156910  0.770675            0.920394   
34312  0.704545     0.055403    0.519256  0.518044            0.662901   
4802  -0.545455     0.253730   -0.331933 -0.229036           -0.436352   
25895  0.704545     1.226781   -0.093200 -0.226100            0.012322   
...         ...          ...         ...       ...                 ...   
18045 -0.568182    -0.083104   -0.568713 -1.176693           -1.338674   
5425   0.590909     0.362732    2.210168  0.139096            0.292112   
12819  0.909091    -0.019787    0.899042  0.454886            0.971892   
33659 -0.522727     1.060572   -0.525683 -0.587220           -0.906087   
19531 -0.590909    -0.344290   -0.510287 -0.945114           -1.215078   

         Height  TotalCholesterol  Triglycerides       LDL       HDL  ...  \
28456 -1.080540         -0.078535      -0.470757 -0.026922  0.418008  ...   
8993  -0.279669          0.765897       0.705031  0.006026  0.446825  ...   
34312  0.559339         -0.123259       0.929511 -1.031826 -1.404309  ...   
4802  -0.504861         -0.188325      -0.322647  0.000015 -0.138743  ...   
25895  0.216731          0.892919       1.291109  0.008211 -0.255329  ...   
...         ...               ...            ...       ...       ...  ...   
18045 -2.080569         -0.340947      -0.470582 -0.848950  0.393794  ...   
5425   0.156785          0.435639      -0.065356  1.113733  0.127664  ...   
12819  1.194951         -0.732967      -0.470025 -0.211535 -1.085148  ...   
33659 -1.254274         -1.063225      -0.470958 -2.849419  0.127664  ...   
19531 -2.339052         -0.356898      -0.470595 -0.900608  0.393896  ...   

       Race_5.0  Race_1.0  Race_4.0  Race_3.0  Race_2.0  Education   Smoking  \
28456       1.0       0.0       0.0       0.0       0.0  -0.012820  0.000000   
8993        0.0       0.0       1.0       0.0       0.0   0.547458  1.000000   
34312       0.0       0.0       0.0       1.0       0.0  -0.659696  0.000000   
4802        1.0       0.0       0.0       0.0       0.0   0.262895  0.073612   
25895       0.0       0.0       0.0       1.0       0.0   1.151035  0.000000   
...         ...       ...       ...       ...       ...        ...       ...   
18045       0.0       0.0       0.0       1.0       0.0  -0.793202  0.000000   
5425        0.0       0.0       1.0       0.0       0.0   0.547458  1.000000   
12819       0.0       0.0       0.0       1.0       0.0   1.151035  1.000000   
33659       0.0       0.0       1.0       0.0       0.0   0.258362  0.000000   
19531       1.0       0.0       0.0       0.0       0.0  -0.821118  0.000000   

       PhysicalActivity  HealthInsurance   Alcohol  
28456          0.660578              0.0 -0.518600  
8993           0.000000              0.0  0.115329  
34312          0.000000              0.0  0.592213  
4802           1.012447              0.0 -0.103347  
25895          0.000000              0.0 -0.886483  
...                 ...              ...       ...  
18045          0.904383              0.0 -0.482716  
5425           1.598141              0.0  0.097790  
12819          1.598141              0.0  0.612947  
33659          1.162475              0.0 -0.154408  
19531          0.791302              0.0 -0.683278  

[13109 rows x 31 columns]
2025-12-03 10:21:07,662:INFO:get_config() successfully completed......................................
2025-12-03 10:21:07,723:INFO:Initializing get_config()
2025-12-03 10:21:07,723:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FAFD737C0>, variable=y_test)
2025-12-03 10:21:07,723:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-12-03 10:21:07,723:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-12-03 10:21:07,729:INFO:Variable:  returned as 28456    0.0
8993     0.0
34312    0.0
4802     0.0
25895    0.0
        ... 
18045    0.0
5425     0.0
12819    0.0
33659    0.0
19531    0.0
Name: HeartDisease, Length: 13109, dtype: float32
2025-12-03 10:21:07,730:INFO:get_config() successfully completed......................................
2025-12-03 10:21:07,731:INFO:Initializing get_config()
2025-12-03 10:21:07,731:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FAFD737C0>, variable=y_test)
2025-12-03 10:21:07,731:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-12-03 10:21:07,731:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-12-03 10:21:07,738:INFO:Variable:  returned as 28456    0.0
8993     0.0
34312    0.0
4802     0.0
25895    0.0
        ... 
18045    0.0
5425     0.0
12819    0.0
33659    0.0
19531    0.0
Name: HeartDisease, Length: 13109, dtype: float32
2025-12-03 10:21:07,738:INFO:get_config() successfully completed......................................
2025-12-03 10:21:07,743:INFO:Initializing get_config()
2025-12-03 10:21:07,743:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FAFD737C0>, variable=y_test)
2025-12-03 10:21:07,744:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-12-03 10:21:07,744:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-12-03 10:21:07,750:INFO:Variable:  returned as 28456    0.0
8993     0.0
34312    0.0
4802     0.0
25895    0.0
        ... 
18045    0.0
5425     0.0
12819    0.0
33659    0.0
19531    0.0
Name: HeartDisease, Length: 13109, dtype: float32
2025-12-03 10:21:07,750:INFO:get_config() successfully completed......................................
2025-12-03 10:21:07,750:INFO:Initializing get_config()
2025-12-03 10:21:07,750:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FAFD737C0>, variable=X_test_transformed)
2025-12-03 10:21:07,825:INFO:Variable: X_test returned as             Age  IncomeRatio  SystolicBP       BMI  WaistCircumference  \
28456 -0.477273    -0.304717   -0.519256 -0.987220           -0.923253   
8993   0.818182     0.253271    2.156910  0.770675            0.920394   
34312  0.704545     0.055403    0.519256  0.518044            0.662901   
4802  -0.545455     0.253730   -0.331933 -0.229036           -0.436352   
25895  0.704545     1.226781   -0.093200 -0.226100            0.012322   
...         ...          ...         ...       ...                 ...   
18045 -0.568182    -0.083104   -0.568713 -1.176693           -1.338674   
5425   0.590909     0.362732    2.210168  0.139096            0.292112   
12819  0.909091    -0.019787    0.899042  0.454886            0.971892   
33659 -0.522727     1.060572   -0.525683 -0.587220           -0.906087   
19531 -0.590909    -0.344290   -0.510287 -0.945114           -1.215078   

         Height  TotalCholesterol  Triglycerides       LDL       HDL  ...  \
28456 -1.080540         -0.078535      -0.470757 -0.026922  0.418008  ...   
8993  -0.279669          0.765897       0.705031  0.006026  0.446825  ...   
34312  0.559339         -0.123259       0.929511 -1.031826 -1.404309  ...   
4802  -0.504861         -0.188325      -0.322647  0.000015 -0.138743  ...   
25895  0.216731          0.892919       1.291109  0.008211 -0.255329  ...   
...         ...               ...            ...       ...       ...  ...   
18045 -2.080569         -0.340947      -0.470582 -0.848950  0.393794  ...   
5425   0.156785          0.435639      -0.065356  1.113733  0.127664  ...   
12819  1.194951         -0.732967      -0.470025 -0.211535 -1.085148  ...   
33659 -1.254274         -1.063225      -0.470958 -2.849419  0.127664  ...   
19531 -2.339052         -0.356898      -0.470595 -0.900608  0.393896  ...   

       Race_5.0  Race_1.0  Race_4.0  Race_3.0  Race_2.0  Education   Smoking  \
28456       1.0       0.0       0.0       0.0       0.0  -0.012820  0.000000   
8993        0.0       0.0       1.0       0.0       0.0   0.547458  1.000000   
34312       0.0       0.0       0.0       1.0       0.0  -0.659696  0.000000   
4802        1.0       0.0       0.0       0.0       0.0   0.262895  0.073612   
25895       0.0       0.0       0.0       1.0       0.0   1.151035  0.000000   
...         ...       ...       ...       ...       ...        ...       ...   
18045       0.0       0.0       0.0       1.0       0.0  -0.793202  0.000000   
5425        0.0       0.0       1.0       0.0       0.0   0.547458  1.000000   
12819       0.0       0.0       0.0       1.0       0.0   1.151035  1.000000   
33659       0.0       0.0       1.0       0.0       0.0   0.258362  0.000000   
19531       1.0       0.0       0.0       0.0       0.0  -0.821118  0.000000   

       PhysicalActivity  HealthInsurance   Alcohol  
28456          0.660578              0.0 -0.518600  
8993           0.000000              0.0  0.115329  
34312          0.000000              0.0  0.592213  
4802           1.012447              0.0 -0.103347  
25895          0.000000              0.0 -0.886483  
...                 ...              ...       ...  
18045          0.904383              0.0 -0.482716  
5425           1.598141              0.0  0.097790  
12819          1.598141              0.0  0.612947  
33659          1.162475              0.0 -0.154408  
19531          0.791302              0.0 -0.683278  

[13109 rows x 31 columns]
2025-12-03 10:21:07,825:INFO:get_config() successfully completed......................................
2025-12-03 10:21:07,861:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pandas\io\formats\style.py:3823: RuntimeWarning: invalid value encountered in scalar multiply

2025-12-03 10:21:07,902:INFO:Initializing plot_model()
2025-12-03 10:21:07,902:INFO:plot_model(plot=error, fold=None, verbose=True, display=None, display_format=None, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FAFD737C0>, system=True)
2025-12-03 10:21:07,902:INFO:Checking exceptions
2025-12-03 10:21:07,925:INFO:Preloading libraries
2025-12-03 10:21:07,932:INFO:Copying training dataset
2025-12-03 10:21:07,932:INFO:Plot type: error
2025-12-03 10:21:08,176:INFO:Fitting Model
2025-12-03 10:21:08,176:INFO:Scoring test/hold-out set
2025-12-03 10:21:08,347:INFO:Visual Rendered Successfully
2025-12-03 10:21:08,529:INFO:plot_model() successfully completed......................................
2025-12-03 10:21:08,560:INFO:Initializing get_config()
2025-12-03 10:21:08,561:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FAFD737C0>, variable=X_test_transformed)
2025-12-03 10:21:08,641:INFO:Variable: X_test returned as             Age  IncomeRatio  SystolicBP       BMI  WaistCircumference  \
28456 -0.477273    -0.304717   -0.519256 -0.987220           -0.923253   
8993   0.818182     0.253271    2.156910  0.770675            0.920394   
34312  0.704545     0.055403    0.519256  0.518044            0.662901   
4802  -0.545455     0.253730   -0.331933 -0.229036           -0.436352   
25895  0.704545     1.226781   -0.093200 -0.226100            0.012322   
...         ...          ...         ...       ...                 ...   
18045 -0.568182    -0.083104   -0.568713 -1.176693           -1.338674   
5425   0.590909     0.362732    2.210168  0.139096            0.292112   
12819  0.909091    -0.019787    0.899042  0.454886            0.971892   
33659 -0.522727     1.060572   -0.525683 -0.587220           -0.906087   
19531 -0.590909    -0.344290   -0.510287 -0.945114           -1.215078   

         Height  TotalCholesterol  Triglycerides       LDL       HDL  ...  \
28456 -1.080540         -0.078535      -0.470757 -0.026922  0.418008  ...   
8993  -0.279669          0.765897       0.705031  0.006026  0.446825  ...   
34312  0.559339         -0.123259       0.929511 -1.031826 -1.404309  ...   
4802  -0.504861         -0.188325      -0.322647  0.000015 -0.138743  ...   
25895  0.216731          0.892919       1.291109  0.008211 -0.255329  ...   
...         ...               ...            ...       ...       ...  ...   
18045 -2.080569         -0.340947      -0.470582 -0.848950  0.393794  ...   
5425   0.156785          0.435639      -0.065356  1.113733  0.127664  ...   
12819  1.194951         -0.732967      -0.470025 -0.211535 -1.085148  ...   
33659 -1.254274         -1.063225      -0.470958 -2.849419  0.127664  ...   
19531 -2.339052         -0.356898      -0.470595 -0.900608  0.393896  ...   

       Race_5.0  Race_1.0  Race_4.0  Race_3.0  Race_2.0  Education   Smoking  \
28456       1.0       0.0       0.0       0.0       0.0  -0.012820  0.000000   
8993        0.0       0.0       1.0       0.0       0.0   0.547458  1.000000   
34312       0.0       0.0       0.0       1.0       0.0  -0.659696  0.000000   
4802        1.0       0.0       0.0       0.0       0.0   0.262895  0.073612   
25895       0.0       0.0       0.0       1.0       0.0   1.151035  0.000000   
...         ...       ...       ...       ...       ...        ...       ...   
18045       0.0       0.0       0.0       1.0       0.0  -0.793202  0.000000   
5425        0.0       0.0       1.0       0.0       0.0   0.547458  1.000000   
12819       0.0       0.0       0.0       1.0       0.0   1.151035  1.000000   
33659       0.0       0.0       1.0       0.0       0.0   0.258362  0.000000   
19531       1.0       0.0       0.0       0.0       0.0  -0.821118  0.000000   

       PhysicalActivity  HealthInsurance   Alcohol  
28456          0.660578              0.0 -0.518600  
8993           0.000000              0.0  0.115329  
34312          0.000000              0.0  0.592213  
4802           1.012447              0.0 -0.103347  
25895          0.000000              0.0 -0.886483  
...                 ...              ...       ...  
18045          0.904383              0.0 -0.482716  
5425           1.598141              0.0  0.097790  
12819          1.598141              0.0  0.612947  
33659          1.162475              0.0 -0.154408  
19531          0.791302              0.0 -0.683278  

[13109 rows x 31 columns]
2025-12-03 10:21:08,641:INFO:get_config() successfully completed......................................
2025-12-03 10:21:08,670:INFO:Initializing get_config()
2025-12-03 10:21:08,670:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FAFD737C0>, variable=y_test)
2025-12-03 10:21:08,670:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-12-03 10:21:08,670:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-12-03 10:21:08,676:INFO:Variable:  returned as 28456    0.0
8993     0.0
34312    0.0
4802     0.0
25895    0.0
        ... 
18045    0.0
5425     0.0
12819    0.0
33659    0.0
19531    0.0
Name: HeartDisease, Length: 13109, dtype: float32
2025-12-03 10:21:08,678:INFO:get_config() successfully completed......................................
2025-12-03 10:21:08,679:INFO:Initializing get_config()
2025-12-03 10:21:08,679:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FAFD737C0>, variable=y_test)
2025-12-03 10:21:08,679:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-12-03 10:21:08,679:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-12-03 10:21:08,684:INFO:Variable:  returned as 28456    0.0
8993     0.0
34312    0.0
4802     0.0
25895    0.0
        ... 
18045    0.0
5425     0.0
12819    0.0
33659    0.0
19531    0.0
Name: HeartDisease, Length: 13109, dtype: float32
2025-12-03 10:21:08,684:INFO:get_config() successfully completed......................................
2025-12-03 10:21:08,684:INFO:Initializing get_config()
2025-12-03 10:21:08,684:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FAFD737C0>, variable=X_test_transformed)
2025-12-03 10:21:08,770:INFO:Variable: X_test returned as             Age  IncomeRatio  SystolicBP       BMI  WaistCircumference  \
28456 -0.477273    -0.304717   -0.519256 -0.987220           -0.923253   
8993   0.818182     0.253271    2.156910  0.770675            0.920394   
34312  0.704545     0.055403    0.519256  0.518044            0.662901   
4802  -0.545455     0.253730   -0.331933 -0.229036           -0.436352   
25895  0.704545     1.226781   -0.093200 -0.226100            0.012322   
...         ...          ...         ...       ...                 ...   
18045 -0.568182    -0.083104   -0.568713 -1.176693           -1.338674   
5425   0.590909     0.362732    2.210168  0.139096            0.292112   
12819  0.909091    -0.019787    0.899042  0.454886            0.971892   
33659 -0.522727     1.060572   -0.525683 -0.587220           -0.906087   
19531 -0.590909    -0.344290   -0.510287 -0.945114           -1.215078   

         Height  TotalCholesterol  Triglycerides       LDL       HDL  ...  \
28456 -1.080540         -0.078535      -0.470757 -0.026922  0.418008  ...   
8993  -0.279669          0.765897       0.705031  0.006026  0.446825  ...   
34312  0.559339         -0.123259       0.929511 -1.031826 -1.404309  ...   
4802  -0.504861         -0.188325      -0.322647  0.000015 -0.138743  ...   
25895  0.216731          0.892919       1.291109  0.008211 -0.255329  ...   
...         ...               ...            ...       ...       ...  ...   
18045 -2.080569         -0.340947      -0.470582 -0.848950  0.393794  ...   
5425   0.156785          0.435639      -0.065356  1.113733  0.127664  ...   
12819  1.194951         -0.732967      -0.470025 -0.211535 -1.085148  ...   
33659 -1.254274         -1.063225      -0.470958 -2.849419  0.127664  ...   
19531 -2.339052         -0.356898      -0.470595 -0.900608  0.393896  ...   

       Race_5.0  Race_1.0  Race_4.0  Race_3.0  Race_2.0  Education   Smoking  \
28456       1.0       0.0       0.0       0.0       0.0  -0.012820  0.000000   
8993        0.0       0.0       1.0       0.0       0.0   0.547458  1.000000   
34312       0.0       0.0       0.0       1.0       0.0  -0.659696  0.000000   
4802        1.0       0.0       0.0       0.0       0.0   0.262895  0.073612   
25895       0.0       0.0       0.0       1.0       0.0   1.151035  0.000000   
...         ...       ...       ...       ...       ...        ...       ...   
18045       0.0       0.0       0.0       1.0       0.0  -0.793202  0.000000   
5425        0.0       0.0       1.0       0.0       0.0   0.547458  1.000000   
12819       0.0       0.0       0.0       1.0       0.0   1.151035  1.000000   
33659       0.0       0.0       1.0       0.0       0.0   0.258362  0.000000   
19531       1.0       0.0       0.0       0.0       0.0  -0.821118  0.000000   

       PhysicalActivity  HealthInsurance   Alcohol  
28456          0.660578              0.0 -0.518600  
8993           0.000000              0.0  0.115329  
34312          0.000000              0.0  0.592213  
4802           1.012447              0.0 -0.103347  
25895          0.000000              0.0 -0.886483  
...                 ...              ...       ...  
18045          0.904383              0.0 -0.482716  
5425           1.598141              0.0  0.097790  
12819          1.598141              0.0  0.612947  
33659          1.162475              0.0 -0.154408  
19531          0.791302              0.0 -0.683278  

[13109 rows x 31 columns]
2025-12-03 10:21:08,770:INFO:get_config() successfully completed......................................
2025-12-03 10:21:08,773:INFO:Initializing get_config()
2025-12-03 10:21:08,773:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FAFD737C0>, variable=y_test)
2025-12-03 10:21:08,774:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-12-03 10:21:08,774:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-12-03 10:21:08,780:INFO:Variable:  returned as 28456    0.0
8993     0.0
34312    0.0
4802     0.0
25895    0.0
        ... 
18045    0.0
5425     0.0
12819    0.0
33659    0.0
19531    0.0
Name: HeartDisease, Length: 13109, dtype: float32
2025-12-03 10:21:08,780:INFO:get_config() successfully completed......................................
2025-12-03 10:21:08,782:INFO:Initializing get_config()
2025-12-03 10:21:08,782:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FAFD737C0>, variable=y_test)
2025-12-03 10:21:08,782:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-12-03 10:21:08,782:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-12-03 10:21:08,788:INFO:Variable:  returned as 28456    0.0
8993     0.0
34312    0.0
4802     0.0
25895    0.0
        ... 
18045    0.0
5425     0.0
12819    0.0
33659    0.0
19531    0.0
Name: HeartDisease, Length: 13109, dtype: float32
2025-12-03 10:21:08,788:INFO:get_config() successfully completed......................................
2025-12-03 10:21:08,789:INFO:Initializing get_config()
2025-12-03 10:21:08,789:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FAFD737C0>, variable=X_test_transformed)
2025-12-03 10:21:08,870:INFO:Variable: X_test returned as             Age  IncomeRatio  SystolicBP       BMI  WaistCircumference  \
28456 -0.477273    -0.304717   -0.519256 -0.987220           -0.923253   
8993   0.818182     0.253271    2.156910  0.770675            0.920394   
34312  0.704545     0.055403    0.519256  0.518044            0.662901   
4802  -0.545455     0.253730   -0.331933 -0.229036           -0.436352   
25895  0.704545     1.226781   -0.093200 -0.226100            0.012322   
...         ...          ...         ...       ...                 ...   
18045 -0.568182    -0.083104   -0.568713 -1.176693           -1.338674   
5425   0.590909     0.362732    2.210168  0.139096            0.292112   
12819  0.909091    -0.019787    0.899042  0.454886            0.971892   
33659 -0.522727     1.060572   -0.525683 -0.587220           -0.906087   
19531 -0.590909    -0.344290   -0.510287 -0.945114           -1.215078   

         Height  TotalCholesterol  Triglycerides       LDL       HDL  ...  \
28456 -1.080540         -0.078535      -0.470757 -0.026922  0.418008  ...   
8993  -0.279669          0.765897       0.705031  0.006026  0.446825  ...   
34312  0.559339         -0.123259       0.929511 -1.031826 -1.404309  ...   
4802  -0.504861         -0.188325      -0.322647  0.000015 -0.138743  ...   
25895  0.216731          0.892919       1.291109  0.008211 -0.255329  ...   
...         ...               ...            ...       ...       ...  ...   
18045 -2.080569         -0.340947      -0.470582 -0.848950  0.393794  ...   
5425   0.156785          0.435639      -0.065356  1.113733  0.127664  ...   
12819  1.194951         -0.732967      -0.470025 -0.211535 -1.085148  ...   
33659 -1.254274         -1.063225      -0.470958 -2.849419  0.127664  ...   
19531 -2.339052         -0.356898      -0.470595 -0.900608  0.393896  ...   

       Race_5.0  Race_1.0  Race_4.0  Race_3.0  Race_2.0  Education   Smoking  \
28456       1.0       0.0       0.0       0.0       0.0  -0.012820  0.000000   
8993        0.0       0.0       1.0       0.0       0.0   0.547458  1.000000   
34312       0.0       0.0       0.0       1.0       0.0  -0.659696  0.000000   
4802        1.0       0.0       0.0       0.0       0.0   0.262895  0.073612   
25895       0.0       0.0       0.0       1.0       0.0   1.151035  0.000000   
...         ...       ...       ...       ...       ...        ...       ...   
18045       0.0       0.0       0.0       1.0       0.0  -0.793202  0.000000   
5425        0.0       0.0       1.0       0.0       0.0   0.547458  1.000000   
12819       0.0       0.0       0.0       1.0       0.0   1.151035  1.000000   
33659       0.0       0.0       1.0       0.0       0.0   0.258362  0.000000   
19531       1.0       0.0       0.0       0.0       0.0  -0.821118  0.000000   

       PhysicalActivity  HealthInsurance   Alcohol  
28456          0.660578              0.0 -0.518600  
8993           0.000000              0.0  0.115329  
34312          0.000000              0.0  0.592213  
4802           1.012447              0.0 -0.103347  
25895          0.000000              0.0 -0.886483  
...                 ...              ...       ...  
18045          0.904383              0.0 -0.482716  
5425           1.598141              0.0  0.097790  
12819          1.598141              0.0  0.612947  
33659          1.162475              0.0 -0.154408  
19531          0.791302              0.0 -0.683278  

[13109 rows x 31 columns]
2025-12-03 10:21:08,870:INFO:get_config() successfully completed......................................
2025-12-03 10:21:08,934:INFO:Initializing get_config()
2025-12-03 10:21:08,934:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FAFD737C0>, variable=y_test)
2025-12-03 10:21:08,934:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-12-03 10:21:08,934:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-12-03 10:21:08,941:INFO:Variable:  returned as 28456    0.0
8993     0.0
34312    0.0
4802     0.0
25895    0.0
        ... 
18045    0.0
5425     0.0
12819    0.0
33659    0.0
19531    0.0
Name: HeartDisease, Length: 13109, dtype: float32
2025-12-03 10:21:08,941:INFO:get_config() successfully completed......................................
2025-12-03 10:21:08,941:INFO:Initializing get_config()
2025-12-03 10:21:08,941:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FAFD737C0>, variable=y_test)
2025-12-03 10:21:08,941:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-12-03 10:21:08,941:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-12-03 10:21:08,949:INFO:Variable:  returned as 28456    0.0
8993     0.0
34312    0.0
4802     0.0
25895    0.0
        ... 
18045    0.0
5425     0.0
12819    0.0
33659    0.0
19531    0.0
Name: HeartDisease, Length: 13109, dtype: float32
2025-12-03 10:21:08,949:INFO:get_config() successfully completed......................................
2025-12-03 10:21:09,044:INFO:Initializing get_config()
2025-12-03 10:21:09,044:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FAFD737C0>, variable=X_test_transformed)
2025-12-03 10:21:09,124:INFO:Variable: X_test returned as             Age  IncomeRatio  SystolicBP       BMI  WaistCircumference  \
28456 -0.477273    -0.304717   -0.519256 -0.987220           -0.923253   
8993   0.818182     0.253271    2.156910  0.770675            0.920394   
34312  0.704545     0.055403    0.519256  0.518044            0.662901   
4802  -0.545455     0.253730   -0.331933 -0.229036           -0.436352   
25895  0.704545     1.226781   -0.093200 -0.226100            0.012322   
...         ...          ...         ...       ...                 ...   
18045 -0.568182    -0.083104   -0.568713 -1.176693           -1.338674   
5425   0.590909     0.362732    2.210168  0.139096            0.292112   
12819  0.909091    -0.019787    0.899042  0.454886            0.971892   
33659 -0.522727     1.060572   -0.525683 -0.587220           -0.906087   
19531 -0.590909    -0.344290   -0.510287 -0.945114           -1.215078   

         Height  TotalCholesterol  Triglycerides       LDL       HDL  ...  \
28456 -1.080540         -0.078535      -0.470757 -0.026922  0.418008  ...   
8993  -0.279669          0.765897       0.705031  0.006026  0.446825  ...   
34312  0.559339         -0.123259       0.929511 -1.031826 -1.404309  ...   
4802  -0.504861         -0.188325      -0.322647  0.000015 -0.138743  ...   
25895  0.216731          0.892919       1.291109  0.008211 -0.255329  ...   
...         ...               ...            ...       ...       ...  ...   
18045 -2.080569         -0.340947      -0.470582 -0.848950  0.393794  ...   
5425   0.156785          0.435639      -0.065356  1.113733  0.127664  ...   
12819  1.194951         -0.732967      -0.470025 -0.211535 -1.085148  ...   
33659 -1.254274         -1.063225      -0.470958 -2.849419  0.127664  ...   
19531 -2.339052         -0.356898      -0.470595 -0.900608  0.393896  ...   

       Race_5.0  Race_1.0  Race_4.0  Race_3.0  Race_2.0  Education   Smoking  \
28456       1.0       0.0       0.0       0.0       0.0  -0.012820  0.000000   
8993        0.0       0.0       1.0       0.0       0.0   0.547458  1.000000   
34312       0.0       0.0       0.0       1.0       0.0  -0.659696  0.000000   
4802        1.0       0.0       0.0       0.0       0.0   0.262895  0.073612   
25895       0.0       0.0       0.0       1.0       0.0   1.151035  0.000000   
...         ...       ...       ...       ...       ...        ...       ...   
18045       0.0       0.0       0.0       1.0       0.0  -0.793202  0.000000   
5425        0.0       0.0       1.0       0.0       0.0   0.547458  1.000000   
12819       0.0       0.0       0.0       1.0       0.0   1.151035  1.000000   
33659       0.0       0.0       1.0       0.0       0.0   0.258362  0.000000   
19531       1.0       0.0       0.0       0.0       0.0  -0.821118  0.000000   

       PhysicalActivity  HealthInsurance   Alcohol  
28456          0.660578              0.0 -0.518600  
8993           0.000000              0.0  0.115329  
34312          0.000000              0.0  0.592213  
4802           1.012447              0.0 -0.103347  
25895          0.000000              0.0 -0.886483  
...                 ...              ...       ...  
18045          0.904383              0.0 -0.482716  
5425           1.598141              0.0  0.097790  
12819          1.598141              0.0  0.612947  
33659          1.162475              0.0 -0.154408  
19531          0.791302              0.0 -0.683278  

[13109 rows x 31 columns]
2025-12-03 10:21:09,124:INFO:get_config() successfully completed......................................
2025-12-03 10:21:09,153:INFO:Initializing get_config()
2025-12-03 10:21:09,154:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FAFD737C0>, variable=y_test)
2025-12-03 10:21:09,154:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-12-03 10:21:09,154:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-12-03 10:21:09,159:INFO:Variable:  returned as 28456    0.0
8993     0.0
34312    0.0
4802     0.0
25895    0.0
        ... 
18045    0.0
5425     0.0
12819    0.0
33659    0.0
19531    0.0
Name: HeartDisease, Length: 13109, dtype: float32
2025-12-03 10:21:09,159:INFO:get_config() successfully completed......................................
2025-12-03 10:21:09,159:INFO:Initializing get_config()
2025-12-03 10:21:09,159:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FAFD737C0>, variable=X_test_transformed)
2025-12-03 10:21:09,243:INFO:Variable: X_test returned as             Age  IncomeRatio  SystolicBP       BMI  WaistCircumference  \
28456 -0.477273    -0.304717   -0.519256 -0.987220           -0.923253   
8993   0.818182     0.253271    2.156910  0.770675            0.920394   
34312  0.704545     0.055403    0.519256  0.518044            0.662901   
4802  -0.545455     0.253730   -0.331933 -0.229036           -0.436352   
25895  0.704545     1.226781   -0.093200 -0.226100            0.012322   
...         ...          ...         ...       ...                 ...   
18045 -0.568182    -0.083104   -0.568713 -1.176693           -1.338674   
5425   0.590909     0.362732    2.210168  0.139096            0.292112   
12819  0.909091    -0.019787    0.899042  0.454886            0.971892   
33659 -0.522727     1.060572   -0.525683 -0.587220           -0.906087   
19531 -0.590909    -0.344290   -0.510287 -0.945114           -1.215078   

         Height  TotalCholesterol  Triglycerides       LDL       HDL  ...  \
28456 -1.080540         -0.078535      -0.470757 -0.026922  0.418008  ...   
8993  -0.279669          0.765897       0.705031  0.006026  0.446825  ...   
34312  0.559339         -0.123259       0.929511 -1.031826 -1.404309  ...   
4802  -0.504861         -0.188325      -0.322647  0.000015 -0.138743  ...   
25895  0.216731          0.892919       1.291109  0.008211 -0.255329  ...   
...         ...               ...            ...       ...       ...  ...   
18045 -2.080569         -0.340947      -0.470582 -0.848950  0.393794  ...   
5425   0.156785          0.435639      -0.065356  1.113733  0.127664  ...   
12819  1.194951         -0.732967      -0.470025 -0.211535 -1.085148  ...   
33659 -1.254274         -1.063225      -0.470958 -2.849419  0.127664  ...   
19531 -2.339052         -0.356898      -0.470595 -0.900608  0.393896  ...   

       Race_5.0  Race_1.0  Race_4.0  Race_3.0  Race_2.0  Education   Smoking  \
28456       1.0       0.0       0.0       0.0       0.0  -0.012820  0.000000   
8993        0.0       0.0       1.0       0.0       0.0   0.547458  1.000000   
34312       0.0       0.0       0.0       1.0       0.0  -0.659696  0.000000   
4802        1.0       0.0       0.0       0.0       0.0   0.262895  0.073612   
25895       0.0       0.0       0.0       1.0       0.0   1.151035  0.000000   
...         ...       ...       ...       ...       ...        ...       ...   
18045       0.0       0.0       0.0       1.0       0.0  -0.793202  0.000000   
5425        0.0       0.0       1.0       0.0       0.0   0.547458  1.000000   
12819       0.0       0.0       0.0       1.0       0.0   1.151035  1.000000   
33659       0.0       0.0       1.0       0.0       0.0   0.258362  0.000000   
19531       1.0       0.0       0.0       0.0       0.0  -0.821118  0.000000   

       PhysicalActivity  HealthInsurance   Alcohol  
28456          0.660578              0.0 -0.518600  
8993           0.000000              0.0  0.115329  
34312          0.000000              0.0  0.592213  
4802           1.012447              0.0 -0.103347  
25895          0.000000              0.0 -0.886483  
...                 ...              ...       ...  
18045          0.904383              0.0 -0.482716  
5425           1.598141              0.0  0.097790  
12819          1.598141              0.0  0.612947  
33659          1.162475              0.0 -0.154408  
19531          0.791302              0.0 -0.683278  

[13109 rows x 31 columns]
2025-12-03 10:21:09,243:INFO:get_config() successfully completed......................................
2025-12-03 10:21:09,244:INFO:Initializing get_config()
2025-12-03 10:21:09,244:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FAFD737C0>, variable=y_test)
2025-12-03 10:21:09,244:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-12-03 10:21:09,244:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-12-03 10:21:09,250:INFO:Variable:  returned as 28456    0.0
8993     0.0
34312    0.0
4802     0.0
25895    0.0
        ... 
18045    0.0
5425     0.0
12819    0.0
33659    0.0
19531    0.0
Name: HeartDisease, Length: 13109, dtype: float32
2025-12-03 10:21:09,250:INFO:get_config() successfully completed......................................
2025-12-03 10:21:09,252:INFO:Initializing get_config()
2025-12-03 10:21:09,252:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FAFD737C0>, variable=X_test_transformed)
2025-12-03 10:21:09,334:INFO:Variable: X_test returned as             Age  IncomeRatio  SystolicBP       BMI  WaistCircumference  \
28456 -0.477273    -0.304717   -0.519256 -0.987220           -0.923253   
8993   0.818182     0.253271    2.156910  0.770675            0.920394   
34312  0.704545     0.055403    0.519256  0.518044            0.662901   
4802  -0.545455     0.253730   -0.331933 -0.229036           -0.436352   
25895  0.704545     1.226781   -0.093200 -0.226100            0.012322   
...         ...          ...         ...       ...                 ...   
18045 -0.568182    -0.083104   -0.568713 -1.176693           -1.338674   
5425   0.590909     0.362732    2.210168  0.139096            0.292112   
12819  0.909091    -0.019787    0.899042  0.454886            0.971892   
33659 -0.522727     1.060572   -0.525683 -0.587220           -0.906087   
19531 -0.590909    -0.344290   -0.510287 -0.945114           -1.215078   

         Height  TotalCholesterol  Triglycerides       LDL       HDL  ...  \
28456 -1.080540         -0.078535      -0.470757 -0.026922  0.418008  ...   
8993  -0.279669          0.765897       0.705031  0.006026  0.446825  ...   
34312  0.559339         -0.123259       0.929511 -1.031826 -1.404309  ...   
4802  -0.504861         -0.188325      -0.322647  0.000015 -0.138743  ...   
25895  0.216731          0.892919       1.291109  0.008211 -0.255329  ...   
...         ...               ...            ...       ...       ...  ...   
18045 -2.080569         -0.340947      -0.470582 -0.848950  0.393794  ...   
5425   0.156785          0.435639      -0.065356  1.113733  0.127664  ...   
12819  1.194951         -0.732967      -0.470025 -0.211535 -1.085148  ...   
33659 -1.254274         -1.063225      -0.470958 -2.849419  0.127664  ...   
19531 -2.339052         -0.356898      -0.470595 -0.900608  0.393896  ...   

       Race_5.0  Race_1.0  Race_4.0  Race_3.0  Race_2.0  Education   Smoking  \
28456       1.0       0.0       0.0       0.0       0.0  -0.012820  0.000000   
8993        0.0       0.0       1.0       0.0       0.0   0.547458  1.000000   
34312       0.0       0.0       0.0       1.0       0.0  -0.659696  0.000000   
4802        1.0       0.0       0.0       0.0       0.0   0.262895  0.073612   
25895       0.0       0.0       0.0       1.0       0.0   1.151035  0.000000   
...         ...       ...       ...       ...       ...        ...       ...   
18045       0.0       0.0       0.0       1.0       0.0  -0.793202  0.000000   
5425        0.0       0.0       1.0       0.0       0.0   0.547458  1.000000   
12819       0.0       0.0       0.0       1.0       0.0   1.151035  1.000000   
33659       0.0       0.0       1.0       0.0       0.0   0.258362  0.000000   
19531       1.0       0.0       0.0       0.0       0.0  -0.821118  0.000000   

       PhysicalActivity  HealthInsurance   Alcohol  
28456          0.660578              0.0 -0.518600  
8993           0.000000              0.0  0.115329  
34312          0.000000              0.0  0.592213  
4802           1.012447              0.0 -0.103347  
25895          0.000000              0.0 -0.886483  
...                 ...              ...       ...  
18045          0.904383              0.0 -0.482716  
5425           1.598141              0.0  0.097790  
12819          1.598141              0.0  0.612947  
33659          1.162475              0.0 -0.154408  
19531          0.791302              0.0 -0.683278  

[13109 rows x 31 columns]
2025-12-03 10:21:09,334:INFO:get_config() successfully completed......................................
2025-12-03 10:21:09,394:INFO:Initializing get_config()
2025-12-03 10:21:09,394:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FAFD737C0>, variable=y_test)
2025-12-03 10:21:09,394:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-12-03 10:21:09,394:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-12-03 10:21:09,400:INFO:Variable:  returned as 28456    0.0
8993     0.0
34312    0.0
4802     0.0
25895    0.0
        ... 
18045    0.0
5425     0.0
12819    0.0
33659    0.0
19531    0.0
Name: HeartDisease, Length: 13109, dtype: float32
2025-12-03 10:21:09,400:INFO:get_config() successfully completed......................................
2025-12-03 10:21:09,417:INFO:Initializing get_config()
2025-12-03 10:21:09,417:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FAFD737C0>, variable=X_test_transformed)
2025-12-03 10:21:09,509:INFO:Variable: X_test returned as             Age  IncomeRatio  SystolicBP       BMI  WaistCircumference  \
28456 -0.477273    -0.304717   -0.519256 -0.987220           -0.923253   
8993   0.818182     0.253271    2.156910  0.770675            0.920394   
34312  0.704545     0.055403    0.519256  0.518044            0.662901   
4802  -0.545455     0.253730   -0.331933 -0.229036           -0.436352   
25895  0.704545     1.226781   -0.093200 -0.226100            0.012322   
...         ...          ...         ...       ...                 ...   
18045 -0.568182    -0.083104   -0.568713 -1.176693           -1.338674   
5425   0.590909     0.362732    2.210168  0.139096            0.292112   
12819  0.909091    -0.019787    0.899042  0.454886            0.971892   
33659 -0.522727     1.060572   -0.525683 -0.587220           -0.906087   
19531 -0.590909    -0.344290   -0.510287 -0.945114           -1.215078   

         Height  TotalCholesterol  Triglycerides       LDL       HDL  ...  \
28456 -1.080540         -0.078535      -0.470757 -0.026922  0.418008  ...   
8993  -0.279669          0.765897       0.705031  0.006026  0.446825  ...   
34312  0.559339         -0.123259       0.929511 -1.031826 -1.404309  ...   
4802  -0.504861         -0.188325      -0.322647  0.000015 -0.138743  ...   
25895  0.216731          0.892919       1.291109  0.008211 -0.255329  ...   
...         ...               ...            ...       ...       ...  ...   
18045 -2.080569         -0.340947      -0.470582 -0.848950  0.393794  ...   
5425   0.156785          0.435639      -0.065356  1.113733  0.127664  ...   
12819  1.194951         -0.732967      -0.470025 -0.211535 -1.085148  ...   
33659 -1.254274         -1.063225      -0.470958 -2.849419  0.127664  ...   
19531 -2.339052         -0.356898      -0.470595 -0.900608  0.393896  ...   

       Race_5.0  Race_1.0  Race_4.0  Race_3.0  Race_2.0  Education   Smoking  \
28456       1.0       0.0       0.0       0.0       0.0  -0.012820  0.000000   
8993        0.0       0.0       1.0       0.0       0.0   0.547458  1.000000   
34312       0.0       0.0       0.0       1.0       0.0  -0.659696  0.000000   
4802        1.0       0.0       0.0       0.0       0.0   0.262895  0.073612   
25895       0.0       0.0       0.0       1.0       0.0   1.151035  0.000000   
...         ...       ...       ...       ...       ...        ...       ...   
18045       0.0       0.0       0.0       1.0       0.0  -0.793202  0.000000   
5425        0.0       0.0       1.0       0.0       0.0   0.547458  1.000000   
12819       0.0       0.0       0.0       1.0       0.0   1.151035  1.000000   
33659       0.0       0.0       1.0       0.0       0.0   0.258362  0.000000   
19531       1.0       0.0       0.0       0.0       0.0  -0.821118  0.000000   

       PhysicalActivity  HealthInsurance   Alcohol  
28456          0.660578              0.0 -0.518600  
8993           0.000000              0.0  0.115329  
34312          0.000000              0.0  0.592213  
4802           1.012447              0.0 -0.103347  
25895          0.000000              0.0 -0.886483  
...                 ...              ...       ...  
18045          0.904383              0.0 -0.482716  
5425           1.598141              0.0  0.097790  
12819          1.598141              0.0  0.612947  
33659          1.162475              0.0 -0.154408  
19531          0.791302              0.0 -0.683278  

[13109 rows x 31 columns]
2025-12-03 10:21:09,509:INFO:get_config() successfully completed......................................
2025-12-03 10:21:09,534:INFO:Initializing get_config()
2025-12-03 10:21:09,534:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FAFD737C0>, variable=y_test)
2025-12-03 10:21:09,534:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-12-03 10:21:09,534:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-12-03 10:21:09,541:INFO:Variable:  returned as 28456    0.0
8993     0.0
34312    0.0
4802     0.0
25895    0.0
        ... 
18045    0.0
5425     0.0
12819    0.0
33659    0.0
19531    0.0
Name: HeartDisease, Length: 13109, dtype: float32
2025-12-03 10:21:09,541:INFO:get_config() successfully completed......................................
2025-12-03 10:21:09,760:INFO:Initializing get_config()
2025-12-03 10:21:09,761:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FAFD737C0>, variable=y_test)
2025-12-03 10:21:09,761:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-12-03 10:21:09,761:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-12-03 10:21:09,764:INFO:Variable:  returned as 28456    0.0
8993     0.0
34312    0.0
4802     0.0
25895    0.0
        ... 
18045    0.0
5425     0.0
12819    0.0
33659    0.0
19531    0.0
Name: HeartDisease, Length: 13109, dtype: float32
2025-12-03 10:21:09,764:INFO:get_config() successfully completed......................................
2025-12-03 10:21:09,767:INFO:Initializing get_config()
2025-12-03 10:21:09,767:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FAFD737C0>, variable=X_test_transformed)
2025-12-03 10:21:09,849:INFO:Variable: X_test returned as             Age  IncomeRatio  SystolicBP       BMI  WaistCircumference  \
28456 -0.477273    -0.304717   -0.519256 -0.987220           -0.923253   
8993   0.818182     0.253271    2.156910  0.770675            0.920394   
34312  0.704545     0.055403    0.519256  0.518044            0.662901   
4802  -0.545455     0.253730   -0.331933 -0.229036           -0.436352   
25895  0.704545     1.226781   -0.093200 -0.226100            0.012322   
...         ...          ...         ...       ...                 ...   
18045 -0.568182    -0.083104   -0.568713 -1.176693           -1.338674   
5425   0.590909     0.362732    2.210168  0.139096            0.292112   
12819  0.909091    -0.019787    0.899042  0.454886            0.971892   
33659 -0.522727     1.060572   -0.525683 -0.587220           -0.906087   
19531 -0.590909    -0.344290   -0.510287 -0.945114           -1.215078   

         Height  TotalCholesterol  Triglycerides       LDL       HDL  ...  \
28456 -1.080540         -0.078535      -0.470757 -0.026922  0.418008  ...   
8993  -0.279669          0.765897       0.705031  0.006026  0.446825  ...   
34312  0.559339         -0.123259       0.929511 -1.031826 -1.404309  ...   
4802  -0.504861         -0.188325      -0.322647  0.000015 -0.138743  ...   
25895  0.216731          0.892919       1.291109  0.008211 -0.255329  ...   
...         ...               ...            ...       ...       ...  ...   
18045 -2.080569         -0.340947      -0.470582 -0.848950  0.393794  ...   
5425   0.156785          0.435639      -0.065356  1.113733  0.127664  ...   
12819  1.194951         -0.732967      -0.470025 -0.211535 -1.085148  ...   
33659 -1.254274         -1.063225      -0.470958 -2.849419  0.127664  ...   
19531 -2.339052         -0.356898      -0.470595 -0.900608  0.393896  ...   

       Race_5.0  Race_1.0  Race_4.0  Race_3.0  Race_2.0  Education   Smoking  \
28456       1.0       0.0       0.0       0.0       0.0  -0.012820  0.000000   
8993        0.0       0.0       1.0       0.0       0.0   0.547458  1.000000   
34312       0.0       0.0       0.0       1.0       0.0  -0.659696  0.000000   
4802        1.0       0.0       0.0       0.0       0.0   0.262895  0.073612   
25895       0.0       0.0       0.0       1.0       0.0   1.151035  0.000000   
...         ...       ...       ...       ...       ...        ...       ...   
18045       0.0       0.0       0.0       1.0       0.0  -0.793202  0.000000   
5425        0.0       0.0       1.0       0.0       0.0   0.547458  1.000000   
12819       0.0       0.0       0.0       1.0       0.0   1.151035  1.000000   
33659       0.0       0.0       1.0       0.0       0.0   0.258362  0.000000   
19531       1.0       0.0       0.0       0.0       0.0  -0.821118  0.000000   

       PhysicalActivity  HealthInsurance   Alcohol  
28456          0.660578              0.0 -0.518600  
8993           0.000000              0.0  0.115329  
34312          0.000000              0.0  0.592213  
4802           1.012447              0.0 -0.103347  
25895          0.000000              0.0 -0.886483  
...                 ...              ...       ...  
18045          0.904383              0.0 -0.482716  
5425           1.598141              0.0  0.097790  
12819          1.598141              0.0  0.612947  
33659          1.162475              0.0 -0.154408  
19531          0.791302              0.0 -0.683278  

[13109 rows x 31 columns]
2025-12-03 10:21:09,849:INFO:get_config() successfully completed......................................
2025-12-03 10:21:09,947:INFO:Initializing get_config()
2025-12-03 10:21:09,947:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FAFD737C0>, variable=X_train_transformed)
2025-12-03 10:21:09,989:INFO:Variable: X_train returned as             Age  IncomeRatio  SystolicBP       BMI  WaistCircumference  \
15208  0.954545     0.854789    0.359485  0.518044            0.206281   
25325 -0.272727     0.253271   -0.812170 -0.966167           -0.799656   
5132   0.181818    -0.407608   -0.372799  0.054886            0.319578   
17217  0.500000    -0.751898    0.013314 -0.260904            0.278379   
6382   0.568182     0.054503    1.131712  2.675938            1.888566   
...         ...          ...         ...       ...                 ...   
6265  -0.545455    -0.431352   -0.591719  0.191728           -0.377368   
42694 -0.022727    -0.221612   -0.892056 -0.260904           -0.047778   
13399  0.454545     0.388518    0.377985  0.271482            0.183567   
39959  0.954545    -0.193911    0.625770  0.991728            1.160720   
6616   0.613636    -0.447182    0.652399 -0.871430           -0.514698   

         Height  TotalCholesterol  Triglycerides       LDL       HDL  ...  \
15208 -0.487303          0.625876       0.583394  0.005397  0.314564  ...   
25325 -0.300856          0.033588      -0.261476  0.000256  0.303682  ...   
5132   0.766972          0.181594       0.479279  0.948690 -1.340476  ...   
17217  0.745785          0.227516       0.346113  0.002441 -0.274561  ...   
6382   0.237295          0.867515       0.635574  0.002754  0.829819  ...   
...         ...               ...            ...       ...       ...  ...   
6265  -1.737339         -1.393483      -0.471046 -3.840886  0.063832  ...   
42694  0.000000          0.029167      -0.131730  0.000893  0.063832  ...   
13399 -0.147405          0.462357       0.380371  0.003925  0.256949  ...   
39959  0.368655          1.528031       1.934134  0.011744  0.191497  ...   
6616  -0.021187         -0.224877      -0.043571 -1.609476  0.510658  ...   

       Race_5.0  Race_1.0  Race_4.0  Race_3.0  Race_2.0  Education  Smoking  \
15208       1.0       0.0       0.0       0.0       0.0  -0.659696      0.0   
25325       0.0       1.0       0.0       0.0       0.0   0.185278      0.0   
5132        0.0       1.0       0.0       0.0       0.0  -0.659696      1.0   
17217       0.0       0.0       1.0       0.0       0.0  -0.056119      1.0   
6382        0.0       0.0       1.0       0.0       0.0   0.547458      1.0   
...         ...       ...       ...       ...       ...        ...      ...   
6265        0.0       1.0       0.0       0.0       0.0  -0.769055      0.0   
42694       0.0       1.0       0.0       0.0       0.0   0.547458      0.0   
13399       0.0       0.0       1.0       0.0       0.0   0.547458      0.0   
39959       0.0       0.0       0.0       1.0       0.0   0.547458      0.0   
6616        0.0       0.0       0.0       1.0       0.0   0.547458      1.0   

       PhysicalActivity  HealthInsurance   Alcohol  
15208          0.000000              0.0 -0.886483  
25325          0.000000              0.0  0.592213  
5132           0.000000             -1.0  0.312949  
17217          0.000000              0.0  0.592213  
6382           0.000000              0.0  0.597293  
...                 ...              ...       ...  
6265           0.662459              0.0 -0.501621  
42694          0.000000             -1.0  0.592213  
13399          0.000000              0.0 -0.224534  
39959          0.000000              0.0  0.592213  
6616           0.000000              0.0  0.290247  

[30586 rows x 31 columns]
2025-12-03 10:21:09,989:INFO:get_config() successfully completed......................................
2025-12-03 10:21:10,005:INFO:Initializing tune_model()
2025-12-03 10:21:10,005:INFO:tune_model(estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...), fold=None, round=4, n_iter=5, custom_grid=None, optimize=Recall, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=False, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FAFD737C0>)
2025-12-03 10:21:10,005:INFO:Checking exceptions
2025-12-03 10:21:10,012:INFO:Copying training dataset
2025-12-03 10:21:10,029:INFO:Checking base model
2025-12-03 10:21:10,029:INFO:Base model : Extreme Gradient Boosting
2025-12-03 10:21:10,029:INFO:Declaring metric variables
2025-12-03 10:21:10,029:INFO:Defining Hyperparameters
2025-12-03 10:21:10,219:INFO:Tuning with n_jobs=1
2025-12-03 10:21:10,219:INFO:Initializing RandomizedSearchCV
2025-12-03 10:21:47,741:INFO:best_params: {'actual_estimator__subsample': 0.7, 'actual_estimator__scale_pos_weight': 38.0, 'actual_estimator__reg_lambda': 0.7, 'actual_estimator__reg_alpha': 0.001, 'actual_estimator__n_estimators': 60, 'actual_estimator__min_child_weight': 1, 'actual_estimator__max_depth': 6, 'actual_estimator__learning_rate': 0.4, 'actual_estimator__colsample_bytree': 0.7}
2025-12-03 10:21:47,741:INFO:Hyperparameter search completed
2025-12-03 10:21:47,741:INFO:SubProcess create_model() called ==================================
2025-12-03 10:21:47,742:INFO:Initializing create_model()
2025-12-03 10:21:47,742:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FAFD737C0>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000018FB007C3D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'subsample': 0.7, 'scale_pos_weight': 38.0, 'reg_lambda': 0.7, 'reg_alpha': 0.001, 'n_estimators': 60, 'min_child_weight': 1, 'max_depth': 6, 'learning_rate': 0.4, 'colsample_bytree': 0.7})
2025-12-03 10:21:47,742:INFO:Checking exceptions
2025-12-03 10:21:47,742:INFO:Importing libraries
2025-12-03 10:21:47,742:INFO:Copying training dataset
2025-12-03 10:21:47,763:INFO:Defining folds
2025-12-03 10:21:47,763:INFO:Declaring metric variables
2025-12-03 10:21:47,764:INFO:Importing untrained model
2025-12-03 10:21:47,764:INFO:Declaring custom model
2025-12-03 10:21:47,765:INFO:Extreme Gradient Boosting Imported successfully
2025-12-03 10:21:47,766:INFO:Starting cross validation
2025-12-03 10:21:47,766:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-12-03 10:21:53,126:INFO:Calculating mean and std
2025-12-03 10:21:53,126:INFO:Creating metrics dataframe
2025-12-03 10:21:53,128:INFO:Finalizing model
2025-12-03 10:21:53,214:INFO:Warning: No categorical columns found. Calling 'transform' will only return input data.
2025-12-03 10:21:53,644:INFO:Uploading results into container
2025-12-03 10:21:53,646:INFO:Uploading model into container now
2025-12-03 10:21:53,646:INFO:_master_model_container: 4
2025-12-03 10:21:53,646:INFO:_display_container: 5
2025-12-03 10:21:53,647:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=0.7, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=0.4, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=6, max_leaves=None,
              min_child_weight=1, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=60, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2025-12-03 10:21:53,647:INFO:create_model() successfully completed......................................
2025-12-03 10:21:53,869:INFO:SubProcess create_model() end ==================================
2025-12-03 10:21:53,869:INFO:choose_better activated
2025-12-03 10:21:53,869:INFO:SubProcess create_model() called ==================================
2025-12-03 10:21:53,870:INFO:Initializing create_model()
2025-12-03 10:21:53,870:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FAFD737C0>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-03 10:21:53,870:INFO:Checking exceptions
2025-12-03 10:21:53,873:INFO:Importing libraries
2025-12-03 10:21:53,873:INFO:Copying training dataset
2025-12-03 10:21:53,896:INFO:Defining folds
2025-12-03 10:21:53,897:INFO:Declaring metric variables
2025-12-03 10:21:53,897:INFO:Importing untrained model
2025-12-03 10:21:53,897:INFO:Declaring custom model
2025-12-03 10:21:53,898:INFO:Extreme Gradient Boosting Imported successfully
2025-12-03 10:21:53,898:INFO:Starting cross validation
2025-12-03 10:21:53,899:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-12-03 10:22:00,603:INFO:Calculating mean and std
2025-12-03 10:22:00,603:INFO:Creating metrics dataframe
2025-12-03 10:22:00,605:INFO:Finalizing model
2025-12-03 10:22:00,692:INFO:Warning: No categorical columns found. Calling 'transform' will only return input data.
2025-12-03 10:22:01,266:INFO:Uploading results into container
2025-12-03 10:22:01,266:INFO:Uploading model into container now
2025-12-03 10:22:01,267:INFO:_master_model_container: 5
2025-12-03 10:22:01,267:INFO:_display_container: 6
2025-12-03 10:22:01,267:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2025-12-03 10:22:01,267:INFO:create_model() successfully completed......................................
2025-12-03 10:22:01,487:INFO:SubProcess create_model() end ==================================
2025-12-03 10:22:01,488:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...) result for Recall is 0.3112
2025-12-03 10:22:01,488:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=0.7, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=0.4, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=6, max_leaves=None,
              min_child_weight=1, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=60, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...) result for Recall is 0.3316
2025-12-03 10:22:01,489:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=0.7, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=0.4, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=6, max_leaves=None,
              min_child_weight=1, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=60, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...) is best model
2025-12-03 10:22:01,489:INFO:choose_better completed
2025-12-03 10:22:01,489:INFO:_master_model_container: 5
2025-12-03 10:22:01,489:INFO:_display_container: 5
2025-12-03 10:22:01,489:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=0.7, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=0.4, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=6, max_leaves=None,
              min_child_weight=1, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=60, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2025-12-03 10:22:01,489:INFO:tune_model() successfully completed......................................
2025-12-03 10:22:01,698:INFO:Initializing predict_model()
2025-12-03 10:22:01,698:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FAFD737C0>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=0.7, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=0.4, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=6, max_leaves=None,
              min_child_weight=1, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=60, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...), probability_threshold=None, encoded_labels=False, raw_score=True, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000018FAFFB7370>)
2025-12-03 10:22:01,698:INFO:Checking exceptions
2025-12-03 10:22:01,698:INFO:Preloading libraries
2025-12-03 10:22:02,265:INFO:Initializing get_config()
2025-12-03 10:22:02,265:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FAFD737C0>, variable=target_param)
2025-12-03 10:22:02,265:INFO:Variable:  returned as HeartDisease
2025-12-03 10:22:02,265:INFO:get_config() successfully completed......................................
2025-12-03 10:22:03,016:INFO:Initializing interpret_model()
2025-12-03 10:22:03,016:INFO:interpret_model(estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=0.7, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=0.4, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=6, max_leaves=None,
              min_child_weight=1, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=60, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...), use_train_data=False, X_new_sample=None, y_new_sample=None, feature=None, kwargs={}, observation=None, plot=summary, save=False, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FAFD737C0>)
2025-12-03 10:22:03,016:INFO:Checking exceptions
2025-12-03 10:22:03,016:INFO:Soft dependency imported: shap: 0.49.1
2025-12-03 10:22:03,102:INFO:plot type: summary
2025-12-03 10:22:03,102:INFO:Creating TreeExplainer
2025-12-03 10:22:03,113:INFO:Compiling shap values
2025-12-03 10:22:06,550:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:4145: FutureWarning: The NumPy global RNG was seeded by calling `np.random.seed`. In a future version this function will no longer use the global RNG. Pass `rng` explicitly to opt-in to the new behaviour and silence this warning.

2025-12-03 10:22:07,777:INFO:Visual Rendered Successfully
2025-12-03 10:22:07,778:INFO:interpret_model() successfully completed......................................
2025-12-03 10:22:07,984:INFO:Initializing predict_model()
2025-12-03 10:22:07,984:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FAFD737C0>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...), probability_threshold=None, encoded_labels=False, raw_score=True, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000018FB015CE50>)
2025-12-03 10:22:07,984:INFO:Checking exceptions
2025-12-03 10:22:07,984:INFO:Preloading libraries
2025-12-03 10:22:08,459:INFO:Initializing get_config()
2025-12-03 10:22:08,460:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FAFD737C0>, variable=target_param)
2025-12-03 10:22:08,460:INFO:Variable:  returned as HeartDisease
2025-12-03 10:22:08,460:INFO:get_config() successfully completed......................................
2025-12-03 10:22:08,600:INFO:Initializing finalize_model()
2025-12-03 10:22:08,600:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FAFD737C0>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=0.7, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=0.4, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=6, max_leaves=None,
              min_child_weight=1, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=60, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2025-12-03 10:22:08,601:INFO:Finalizing XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=0.7, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=0.4, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=6, max_leaves=None,
              min_child_weight=1, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=60, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2025-12-03 10:22:08,617:INFO:Initializing create_model()
2025-12-03 10:22:08,618:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FAFD737C0>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=0.7, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=0.4, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=6, max_leaves=None,
              min_child_weight=1, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=60, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2025-12-03 10:22:08,618:INFO:Checking exceptions
2025-12-03 10:22:08,619:INFO:Importing libraries
2025-12-03 10:22:08,619:INFO:Copying training dataset
2025-12-03 10:22:08,622:INFO:Defining folds
2025-12-03 10:22:08,622:INFO:Declaring metric variables
2025-12-03 10:22:08,622:INFO:Importing untrained model
2025-12-03 10:22:08,622:INFO:Declaring custom model
2025-12-03 10:22:08,624:INFO:Extreme Gradient Boosting Imported successfully
2025-12-03 10:22:08,625:INFO:Cross validation set to False
2025-12-03 10:22:08,625:INFO:Fitting Model
2025-12-03 10:22:08,734:INFO:Warning: No categorical columns found. Calling 'transform' will only return input data.
2025-12-03 10:22:09,318:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'IncomeRatio', 'SystolicBP',
                                             'BMI', 'WaistCircumference',
                                             'Height', 'TotalCholesterol',
                                             'Triglycerides', 'LDL', 'HDL',
                                             'HbA1c', 'Glucose', 'Creatinine',
                                             'UricAcid', 'ALT_Enzyme',
                                             'Albumin', 'Potassium', 'Sodium',
                                             'GGT_Enzyme', 'AST_Enzyme'],
                                    transformer=Si...
                               feature_types=None, gamma=None, grow_policy=None,
                               importance_type=None,
                               interaction_constraints=None, learning_rate=0.4,
                               max_bin=None, max_cat_threshold=None,
                               max_cat_to_onehot=None, max_delta_step=None,
                               max_depth=6, max_leaves=None, min_child_weight=1,
                               missing=nan, monotone_constraints=None,
                               multi_strategy=None, n_estimators=60, n_jobs=1,
                               num_parallel_tree=None,
                               objective='binary:logistic', ...))],
         verbose=False)
2025-12-03 10:22:09,318:INFO:create_model() successfully completed......................................
2025-12-03 10:22:09,571:INFO:_master_model_container: 5
2025-12-03 10:22:09,572:INFO:_display_container: 7
2025-12-03 10:22:09,596:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'IncomeRatio', 'SystolicBP',
                                             'BMI', 'WaistCircumference',
                                             'Height', 'TotalCholesterol',
                                             'Triglycerides', 'LDL', 'HDL',
                                             'HbA1c', 'Glucose', 'Creatinine',
                                             'UricAcid', 'ALT_Enzyme',
                                             'Albumin', 'Potassium', 'Sodium',
                                             'GGT_Enzyme', 'AST_Enzyme'],
                                    transformer=Si...
                               feature_types=None, gamma=None, grow_policy=None,
                               importance_type=None,
                               interaction_constraints=None, learning_rate=0.4,
                               max_bin=None, max_cat_threshold=None,
                               max_cat_to_onehot=None, max_delta_step=None,
                               max_depth=6, max_leaves=None, min_child_weight=1,
                               missing=nan, monotone_constraints=None,
                               multi_strategy=None, n_estimators=60, n_jobs=1,
                               num_parallel_tree=None,
                               objective='binary:logistic', ...))],
         verbose=False)
2025-12-03 10:22:09,596:INFO:finalize_model() successfully completed......................................
2025-12-03 10:22:09,829:INFO:Initializing save_model()
2025-12-03 10:22:09,829:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'IncomeRatio', 'SystolicBP',
                                             'BMI', 'WaistCircumference',
                                             'Height', 'TotalCholesterol',
                                             'Triglycerides', 'LDL', 'HDL',
                                             'HbA1c', 'Glucose', 'Creatinine',
                                             'UricAcid', 'ALT_Enzyme',
                                             'Albumin', 'Potassium', 'Sodium',
                                             'GGT_Enzyme', 'AST_Enzyme'],
                                    transformer=Si...
                               feature_types=None, gamma=None, grow_policy=None,
                               importance_type=None,
                               interaction_constraints=None, learning_rate=0.4,
                               max_bin=None, max_cat_threshold=None,
                               max_cat_to_onehot=None, max_delta_step=None,
                               max_depth=6, max_leaves=None, min_child_weight=1,
                               missing=nan, monotone_constraints=None,
                               multi_strategy=None, n_estimators=60, n_jobs=1,
                               num_parallel_tree=None,
                               objective='binary:logistic', ...))],
         verbose=False), model_name=../models\best_pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\OMAR\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'IncomeRatio', 'SystolicBP',
                                             'BMI', 'WaistCircumference',
                                             'Height', 'TotalCholesterol',
                                             'Triglycerides', 'LDL', 'HDL',
                                             'HbA1c', 'Glucose', 'Creatinine',
                                             'UricAcid', 'ALT_Enzyme',
                                             'Albumin', 'Potassium', 'Sodium',
                                             'G...
                                    transformer=TargetEncoder(cols=[],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=RobustScaler(copy=True,
                                                             quantile_range=(25.0,
                                                                             75.0),
                                                             unit_variance=False,
                                                             with_centering=True,
                                                             with_scaling=True)))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2025-12-03 10:22:09,829:INFO:Adding model into prep_pipe
2025-12-03 10:22:09,829:WARNING:Only Model saved as it was a pipeline.
2025-12-03 10:22:09,834:INFO:../models\best_pipeline.pkl saved in current working directory
2025-12-03 10:22:09,852:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'IncomeRatio', 'SystolicBP',
                                             'BMI', 'WaistCircumference',
                                             'Height', 'TotalCholesterol',
                                             'Triglycerides', 'LDL', 'HDL',
                                             'HbA1c', 'Glucose', 'Creatinine',
                                             'UricAcid', 'ALT_Enzyme',
                                             'Albumin', 'Potassium', 'Sodium',
                                             'GGT_Enzyme', 'AST_Enzyme'],
                                    transformer=Si...
                               feature_types=None, gamma=None, grow_policy=None,
                               importance_type=None,
                               interaction_constraints=None, learning_rate=0.4,
                               max_bin=None, max_cat_threshold=None,
                               max_cat_to_onehot=None, max_delta_step=None,
                               max_depth=6, max_leaves=None, min_child_weight=1,
                               missing=nan, monotone_constraints=None,
                               multi_strategy=None, n_estimators=60, n_jobs=1,
                               num_parallel_tree=None,
                               objective='binary:logistic', ...))],
         verbose=False)
2025-12-03 10:22:09,852:INFO:save_model() successfully completed......................................
2025-12-03 11:18:21,967:INFO:PyCaret ClassificationExperiment
2025-12-03 11:18:21,967:INFO:Logging name: clf-default-name
2025-12-03 11:18:21,967:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-12-03 11:18:21,967:INFO:version 3.3.2
2025-12-03 11:18:21,967:INFO:Initializing setup()
2025-12-03 11:18:21,967:INFO:self.USI: 18b9
2025-12-03 11:18:21,967:INFO:self._variable_keys: {'idx', 'html_param', '_available_plots', 'y_test', 'USI', 'target_param', 'memory', 'pipeline', 'n_jobs_param', 'X_test', 'seed', 'is_multiclass', 'gpu_param', 'logging_param', 'y_train', 'log_plots_param', 'X_train', 'gpu_n_jobs_param', 'fix_imbalance', 'exp_name_log', 'fold_shuffle_param', 'fold_groups_param', 'X', 'data', 'fold_generator', 'y', 'exp_id', '_ml_usecase'}
2025-12-03 11:18:21,967:INFO:Checking environment
2025-12-03 11:18:21,967:INFO:python_version: 3.10.19
2025-12-03 11:18:21,967:INFO:python_build: ('main', 'Oct 21 2025 16:41:31')
2025-12-03 11:18:21,967:INFO:machine: AMD64
2025-12-03 11:18:21,967:INFO:platform: Windows-10-10.0.26100-SP0
2025-12-03 11:18:21,968:INFO:Memory: svmem(total=16282144768, available=4472532992, percent=72.5, used=11809611776, free=4472532992)
2025-12-03 11:18:21,968:INFO:Physical Core: 6
2025-12-03 11:18:21,968:INFO:Logical Core: 12
2025-12-03 11:18:21,968:INFO:Checking libraries
2025-12-03 11:18:21,968:INFO:System:
2025-12-03 11:18:21,968:INFO:    python: 3.10.19 | packaged by Anaconda, Inc. | (main, Oct 21 2025, 16:41:31) [MSC v.1929 64 bit (AMD64)]
2025-12-03 11:18:21,968:INFO:executable: c:\Users\OMAR\miniconda3\envs\xgb_env\python.exe
2025-12-03 11:18:21,969:INFO:   machine: Windows-10-10.0.26100-SP0
2025-12-03 11:18:21,969:INFO:PyCaret required dependencies:
2025-12-03 11:18:21,969:INFO:                 pip: 25.3
2025-12-03 11:18:21,969:INFO:          setuptools: 80.9.0
2025-12-03 11:18:21,969:INFO:             pycaret: 3.3.2
2025-12-03 11:18:21,969:INFO:             IPython: 8.37.0
2025-12-03 11:18:21,970:INFO:          ipywidgets: 8.1.8
2025-12-03 11:18:21,970:INFO:                tqdm: 4.67.1
2025-12-03 11:18:21,970:INFO:               numpy: 1.26.4
2025-12-03 11:18:21,970:INFO:              pandas: 2.1.4
2025-12-03 11:18:21,970:INFO:              jinja2: 3.1.6
2025-12-03 11:18:21,970:INFO:               scipy: 1.11.4
2025-12-03 11:18:21,970:INFO:              joblib: 1.3.2
2025-12-03 11:18:21,970:INFO:             sklearn: 1.4.2
2025-12-03 11:18:21,970:INFO:                pyod: 2.0.5
2025-12-03 11:18:21,970:INFO:            imblearn: 0.14.0
2025-12-03 11:18:21,970:INFO:   category_encoders: 2.7.0
2025-12-03 11:18:21,970:INFO:            lightgbm: 4.6.0
2025-12-03 11:18:21,970:INFO:               numba: 0.62.1
2025-12-03 11:18:21,970:INFO:            requests: 2.32.5
2025-12-03 11:18:21,970:INFO:          matplotlib: 3.7.5
2025-12-03 11:18:21,970:INFO:          scikitplot: 0.3.7
2025-12-03 11:18:21,970:INFO:         yellowbrick: 1.5
2025-12-03 11:18:21,970:INFO:              plotly: 5.24.1
2025-12-03 11:18:21,970:INFO:    plotly-resampler: Not installed
2025-12-03 11:18:21,970:INFO:             kaleido: 1.2.0
2025-12-03 11:18:21,970:INFO:           schemdraw: 0.15
2025-12-03 11:18:21,970:INFO:         statsmodels: 0.14.5
2025-12-03 11:18:21,970:INFO:              sktime: 0.26.0
2025-12-03 11:18:21,970:INFO:               tbats: 1.1.3
2025-12-03 11:18:21,970:INFO:            pmdarima: 2.0.4
2025-12-03 11:18:21,970:INFO:              psutil: 7.1.3
2025-12-03 11:18:21,970:INFO:          markupsafe: 3.0.3
2025-12-03 11:18:21,970:INFO:             pickle5: Not installed
2025-12-03 11:18:21,970:INFO:         cloudpickle: 3.1.2
2025-12-03 11:18:21,970:INFO:         deprecation: 2.1.0
2025-12-03 11:18:21,970:INFO:              xxhash: 3.6.0
2025-12-03 11:18:21,970:INFO:           wurlitzer: Not installed
2025-12-03 11:18:21,970:INFO:PyCaret optional dependencies:
2025-12-03 11:18:21,970:INFO:                shap: 0.49.1
2025-12-03 11:18:21,970:INFO:           interpret: 0.7.3
2025-12-03 11:18:21,970:INFO:                umap: 0.5.7
2025-12-03 11:18:21,970:INFO:     ydata_profiling: 4.18.0
2025-12-03 11:18:21,970:INFO:  explainerdashboard: 0.5.1
2025-12-03 11:18:21,970:INFO:             autoviz: Not installed
2025-12-03 11:18:21,970:INFO:           fairlearn: 0.7.0
2025-12-03 11:18:21,970:INFO:          deepchecks: Not installed
2025-12-03 11:18:21,970:INFO:             xgboost: 2.1.3
2025-12-03 11:18:21,970:INFO:            catboost: 1.2.8
2025-12-03 11:18:21,970:INFO:              kmodes: 0.12.2
2025-12-03 11:18:21,970:INFO:             mlxtend: 0.23.4
2025-12-03 11:18:21,970:INFO:       statsforecast: 1.5.0
2025-12-03 11:18:21,970:INFO:        tune_sklearn: Not installed
2025-12-03 11:18:21,970:INFO:                 ray: Not installed
2025-12-03 11:18:21,970:INFO:            hyperopt: 0.2.7
2025-12-03 11:18:21,970:INFO:              optuna: 4.6.0
2025-12-03 11:18:21,970:INFO:               skopt: 0.10.2
2025-12-03 11:18:21,970:INFO:              mlflow: 3.6.0
2025-12-03 11:18:21,970:INFO:              gradio: 6.0.1
2025-12-03 11:18:21,970:INFO:             fastapi: 0.123.0
2025-12-03 11:18:21,970:INFO:             uvicorn: 0.38.0
2025-12-03 11:18:21,970:INFO:              m2cgen: 0.10.0
2025-12-03 11:18:21,970:INFO:           evidently: 0.4.40
2025-12-03 11:18:21,970:INFO:               fugue: 0.8.7
2025-12-03 11:18:21,970:INFO:           streamlit: 1.51.0
2025-12-03 11:18:21,970:INFO:             prophet: Not installed
2025-12-03 11:18:21,971:INFO:None
2025-12-03 11:18:21,971:INFO:Set up data.
2025-12-03 11:18:21,994:INFO:Set up folding strategy.
2025-12-03 11:18:21,995:INFO:Set up train/test split.
2025-12-03 11:18:22,032:INFO:Set up index.
2025-12-03 11:18:22,032:INFO:Assigning column types.
2025-12-03 11:18:22,049:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-12-03 11:18:22,076:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-12-03 11:18:22,079:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-03 11:18:22,096:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-03 11:18:22,098:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-03 11:18:22,126:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-12-03 11:18:22,126:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-03 11:18:22,143:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-03 11:18:22,145:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-03 11:18:22,146:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-12-03 11:18:22,174:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-03 11:18:22,192:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-03 11:18:22,194:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-03 11:18:22,223:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-03 11:18:22,240:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-03 11:18:22,241:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-03 11:18:22,242:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-12-03 11:18:22,287:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-03 11:18:22,289:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-03 11:18:22,334:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-03 11:18:22,337:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-03 11:18:22,338:INFO:Preparing preprocessing pipeline...
2025-12-03 11:18:22,341:INFO:Set up simple imputation.
2025-12-03 11:18:22,356:INFO:Set up encoding of ordinal features.
2025-12-03 11:18:22,359:INFO:Set up encoding of categorical features.
2025-12-03 11:18:22,359:INFO:Set up feature normalization.
2025-12-03 11:18:22,530:INFO:Finished creating preprocessing pipeline.
2025-12-03 11:18:22,545:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\OMAR\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'IncomeRatio', 'SystolicBP',
                                             'BMI', 'WaistCircumference',
                                             'Height', 'TotalCholesterol',
                                             'Triglycerides', 'LDL', 'HDL',
                                             'HbA1c', 'Glucose', 'Creatinine',
                                             'UricAcid', 'ALT_Enzyme',
                                             'Albumin', 'Potassium', 'Sodium',
                                             'G...
                                    transformer=TargetEncoder(cols=[],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=RobustScaler(copy=True,
                                                             quantile_range=(25.0,
                                                                             75.0),
                                                             unit_variance=False,
                                                             with_centering=True,
                                                             with_scaling=True)))],
         verbose=False)
2025-12-03 11:18:22,545:INFO:Creating final display dataframe.
2025-12-03 11:18:22,750:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target      HeartDisease
2                   Target type            Binary
3           Original data shape       (43695, 28)
4        Transformed data shape       (43695, 32)
5   Transformed train set shape       (30586, 32)
6    Transformed test set shape       (13109, 32)
7              Numeric features                20
8          Categorical features                 7
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15                    Normalize              True
16             Normalize method            robust
17               Fold Generator   StratifiedKFold
18                  Fold Number                10
19                     CPU Jobs                 1
20                      Use GPU             False
21               Log Experiment             False
22              Experiment Name  clf-default-name
23                          USI              18b9
2025-12-03 11:18:22,803:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-03 11:18:22,805:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-03 11:18:22,849:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-03 11:18:22,850:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-03 11:18:22,852:INFO:setup() successfully completed in 0.9s...............
2025-12-03 11:18:22,909:INFO:Initializing get_config()
2025-12-03 11:18:22,909:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FA2378B80>, variable=y_train)
2025-12-03 11:18:22,909:INFO:Variable: 'y_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_train_transformed' instead.
2025-12-03 11:18:22,910:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_train_transformed' instead.

2025-12-03 11:18:22,920:INFO:Variable:  returned as 15208    0.0
25325    0.0
5132     0.0
17217    0.0
6382     0.0
        ... 
6265     0.0
42694    0.0
13399    0.0
39959    0.0
6616     0.0
Name: HeartDisease, Length: 30586, dtype: float32
2025-12-03 11:18:22,921:INFO:get_config() successfully completed......................................
2025-12-03 11:18:22,921:INFO:Initializing create_model()
2025-12-03 11:18:22,922:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FA2378B80>, estimator=xgboost, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={'scale_pos_weight': 76.32522407170295})
2025-12-03 11:18:22,922:INFO:Checking exceptions
2025-12-03 11:18:22,934:INFO:Importing libraries
2025-12-03 11:18:22,934:INFO:Copying training dataset
2025-12-03 11:18:22,966:INFO:Defining folds
2025-12-03 11:18:22,966:INFO:Declaring metric variables
2025-12-03 11:18:22,970:INFO:Importing untrained model
2025-12-03 11:18:22,976:INFO:Extreme Gradient Boosting Imported successfully
2025-12-03 11:18:22,982:INFO:Starting cross validation
2025-12-03 11:18:22,985:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-12-03 11:18:29,131:INFO:Calculating mean and std
2025-12-03 11:18:29,131:INFO:Creating metrics dataframe
2025-12-03 11:18:29,134:INFO:Finalizing model
2025-12-03 11:18:29,208:INFO:Warning: No categorical columns found. Calling 'transform' will only return input data.
2025-12-03 11:18:29,723:INFO:Uploading results into container
2025-12-03 11:18:29,723:INFO:Uploading model into container now
2025-12-03 11:18:29,733:INFO:_master_model_container: 1
2025-12-03 11:18:29,733:INFO:_display_container: 2
2025-12-03 11:18:29,734:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2025-12-03 11:18:29,734:INFO:create_model() successfully completed......................................
2025-12-03 11:18:30,008:INFO:Initializing create_model()
2025-12-03 11:18:30,008:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FA2378B80>, estimator=lr, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-03 11:18:30,008:INFO:Checking exceptions
2025-12-03 11:18:30,026:INFO:Importing libraries
2025-12-03 11:18:30,026:INFO:Copying training dataset
2025-12-03 11:18:30,063:INFO:Defining folds
2025-12-03 11:18:30,063:INFO:Declaring metric variables
2025-12-03 11:18:30,065:INFO:Importing untrained model
2025-12-03 11:18:30,068:INFO:Logistic Regression Imported successfully
2025-12-03 11:18:30,072:INFO:Starting cross validation
2025-12-03 11:18:30,072:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-12-03 11:18:30,980:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-12-03 11:18:31,532:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-12-03 11:18:31,885:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.

2025-12-03 11:18:31,892:INFO:Calculating mean and std
2025-12-03 11:18:31,892:INFO:Creating metrics dataframe
2025-12-03 11:18:31,896:INFO:Finalizing model
2025-12-03 11:18:31,969:INFO:Warning: No categorical columns found. Calling 'transform' will only return input data.
2025-12-03 11:18:32,064:INFO:Uploading results into container
2025-12-03 11:18:32,064:INFO:Uploading model into container now
2025-12-03 11:18:32,073:INFO:_master_model_container: 2
2025-12-03 11:18:32,073:INFO:_display_container: 3
2025-12-03 11:18:32,075:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-12-03 11:18:32,075:INFO:create_model() successfully completed......................................
2025-12-03 11:18:32,244:INFO:Initializing create_model()
2025-12-03 11:18:32,244:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FA2378B80>, estimator=rf, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-03 11:18:32,244:INFO:Checking exceptions
2025-12-03 11:18:32,254:INFO:Importing libraries
2025-12-03 11:18:32,255:INFO:Copying training dataset
2025-12-03 11:18:32,284:INFO:Defining folds
2025-12-03 11:18:32,284:INFO:Declaring metric variables
2025-12-03 11:18:32,287:INFO:Importing untrained model
2025-12-03 11:18:32,291:INFO:Random Forest Classifier Imported successfully
2025-12-03 11:18:32,299:INFO:Starting cross validation
2025-12-03 11:18:32,301:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-12-03 11:19:12,044:INFO:Calculating mean and std
2025-12-03 11:19:12,044:INFO:Creating metrics dataframe
2025-12-03 11:19:12,044:INFO:Finalizing model
2025-12-03 11:19:12,122:INFO:Warning: No categorical columns found. Calling 'transform' will only return input data.
2025-12-03 11:19:16,538:INFO:Uploading results into container
2025-12-03 11:19:16,541:INFO:Uploading model into container now
2025-12-03 11:19:16,548:INFO:_master_model_container: 3
2025-12-03 11:19:16,548:INFO:_display_container: 4
2025-12-03 11:19:16,549:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2025-12-03 11:19:16,549:INFO:create_model() successfully completed......................................
2025-12-03 11:19:16,768:INFO:Initializing get_config()
2025-12-03 11:19:16,768:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FA2378B80>, variable=X_train_transformed)
2025-12-03 11:19:16,810:INFO:Variable: X_train returned as             Age  IncomeRatio  SystolicBP       BMI  WaistCircumference  \
15208  0.954545     0.854789    0.359485  0.518044            0.206281   
25325 -0.272727     0.253271   -0.812170 -0.966167           -0.799656   
5132   0.181818    -0.407608   -0.372799  0.054886            0.319578   
17217  0.500000    -0.751898    0.013314 -0.260904            0.278379   
6382   0.568182     0.054503    1.131712  2.675938            1.888566   
...         ...          ...         ...       ...                 ...   
6265  -0.545455    -0.431352   -0.591719  0.191728           -0.377368   
42694 -0.022727    -0.221612   -0.892056 -0.260904           -0.047778   
13399  0.454545     0.388518    0.377985  0.271482            0.183567   
39959  0.954545    -0.193911    0.625770  0.991728            1.160720   
6616   0.613636    -0.447182    0.652399 -0.871430           -0.514698   

         Height  TotalCholesterol  Triglycerides       LDL       HDL  ...  \
15208 -0.487303          0.625876       0.583394  0.005397  0.314564  ...   
25325 -0.300856          0.033588      -0.261476  0.000256  0.303682  ...   
5132   0.766972          0.181594       0.479279  0.948690 -1.340476  ...   
17217  0.745785          0.227516       0.346113  0.002441 -0.274561  ...   
6382   0.237295          0.867515       0.635574  0.002754  0.829819  ...   
...         ...               ...            ...       ...       ...  ...   
6265  -1.737339         -1.393483      -0.471046 -3.840886  0.063832  ...   
42694  0.000000          0.029167      -0.131730  0.000893  0.063832  ...   
13399 -0.147405          0.462357       0.380371  0.003925  0.256949  ...   
39959  0.368655          1.528031       1.934134  0.011744  0.191497  ...   
6616  -0.021187         -0.224877      -0.043571 -1.609476  0.510658  ...   

       Race_5.0  Race_1.0  Race_4.0  Race_3.0  Race_2.0  Education  Smoking  \
15208       1.0       0.0       0.0       0.0       0.0  -0.659696      0.0   
25325       0.0       1.0       0.0       0.0       0.0   0.185278      0.0   
5132        0.0       1.0       0.0       0.0       0.0  -0.659696      1.0   
17217       0.0       0.0       1.0       0.0       0.0  -0.056119      1.0   
6382        0.0       0.0       1.0       0.0       0.0   0.547458      1.0   
...         ...       ...       ...       ...       ...        ...      ...   
6265        0.0       1.0       0.0       0.0       0.0  -0.769055      0.0   
42694       0.0       1.0       0.0       0.0       0.0   0.547458      0.0   
13399       0.0       0.0       1.0       0.0       0.0   0.547458      0.0   
39959       0.0       0.0       0.0       1.0       0.0   0.547458      0.0   
6616        0.0       0.0       0.0       1.0       0.0   0.547458      1.0   

       PhysicalActivity  HealthInsurance   Alcohol  
15208          0.000000              0.0 -0.886483  
25325          0.000000              0.0  0.592213  
5132           0.000000             -1.0  0.312949  
17217          0.000000              0.0  0.592213  
6382           0.000000              0.0  0.597293  
...                 ...              ...       ...  
6265           0.662459              0.0 -0.501621  
42694          0.000000             -1.0  0.592213  
13399          0.000000              0.0 -0.224534  
39959          0.000000              0.0  0.592213  
6616           0.000000              0.0  0.290247  

[30586 rows x 31 columns]
2025-12-03 11:19:16,810:INFO:get_config() successfully completed......................................
2025-12-03 11:19:16,810:INFO:Initializing get_config()
2025-12-03 11:19:16,810:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FA2378B80>, variable=y_train)
2025-12-03 11:19:16,810:INFO:Variable: 'y_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_train_transformed' instead.
2025-12-03 11:19:16,810:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_train_transformed' instead.

2025-12-03 11:19:16,817:INFO:Variable:  returned as 15208    0.0
25325    0.0
5132     0.0
17217    0.0
6382     0.0
        ... 
6265     0.0
42694    0.0
13399    0.0
39959    0.0
6616     0.0
Name: HeartDisease, Length: 30586, dtype: float32
2025-12-03 11:19:16,817:INFO:get_config() successfully completed......................................
2025-12-03 11:19:16,819:INFO:Initializing get_config()
2025-12-03 11:19:16,819:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FA2378B80>, variable=X_test_transformed)
2025-12-03 11:19:16,887:INFO:Variable: X_test returned as             Age  IncomeRatio  SystolicBP       BMI  WaistCircumference  \
28456 -0.477273    -0.304717   -0.519256 -0.987220           -0.923253   
8993   0.818182     0.253271    2.156910  0.770675            0.920394   
34312  0.704545     0.055403    0.519256  0.518044            0.662901   
4802  -0.545455     0.253730   -0.331933 -0.229036           -0.436352   
25895  0.704545     1.226781   -0.093200 -0.226100            0.012322   
...         ...          ...         ...       ...                 ...   
18045 -0.568182    -0.083104   -0.568713 -1.176693           -1.338674   
5425   0.590909     0.362732    2.210168  0.139096            0.292112   
12819  0.909091    -0.019787    0.899042  0.454886            0.971892   
33659 -0.522727     1.060572   -0.525683 -0.587220           -0.906087   
19531 -0.590909    -0.344290   -0.510287 -0.945114           -1.215078   

         Height  TotalCholesterol  Triglycerides       LDL       HDL  ...  \
28456 -1.080540         -0.078535      -0.470757 -0.026922  0.418008  ...   
8993  -0.279669          0.765897       0.705031  0.006026  0.446825  ...   
34312  0.559339         -0.123259       0.929511 -1.031826 -1.404309  ...   
4802  -0.504861         -0.188325      -0.322647  0.000015 -0.138743  ...   
25895  0.216731          0.892919       1.291109  0.008211 -0.255329  ...   
...         ...               ...            ...       ...       ...  ...   
18045 -2.080569         -0.340947      -0.470582 -0.848950  0.393794  ...   
5425   0.156785          0.435639      -0.065356  1.113733  0.127664  ...   
12819  1.194951         -0.732967      -0.470025 -0.211535 -1.085148  ...   
33659 -1.254274         -1.063225      -0.470958 -2.849419  0.127664  ...   
19531 -2.339052         -0.356898      -0.470595 -0.900608  0.393896  ...   

       Race_5.0  Race_1.0  Race_4.0  Race_3.0  Race_2.0  Education   Smoking  \
28456       1.0       0.0       0.0       0.0       0.0  -0.012820  0.000000   
8993        0.0       0.0       1.0       0.0       0.0   0.547458  1.000000   
34312       0.0       0.0       0.0       1.0       0.0  -0.659696  0.000000   
4802        1.0       0.0       0.0       0.0       0.0   0.262895  0.073612   
25895       0.0       0.0       0.0       1.0       0.0   1.151035  0.000000   
...         ...       ...       ...       ...       ...        ...       ...   
18045       0.0       0.0       0.0       1.0       0.0  -0.793202  0.000000   
5425        0.0       0.0       1.0       0.0       0.0   0.547458  1.000000   
12819       0.0       0.0       0.0       1.0       0.0   1.151035  1.000000   
33659       0.0       0.0       1.0       0.0       0.0   0.258362  0.000000   
19531       1.0       0.0       0.0       0.0       0.0  -0.821118  0.000000   

       PhysicalActivity  HealthInsurance   Alcohol  
28456          0.660578              0.0 -0.518600  
8993           0.000000              0.0  0.115329  
34312          0.000000              0.0  0.592213  
4802           1.012447              0.0 -0.103347  
25895          0.000000              0.0 -0.886483  
...                 ...              ...       ...  
18045          0.904383              0.0 -0.482716  
5425           1.598141              0.0  0.097790  
12819          1.598141              0.0  0.612947  
33659          1.162475              0.0 -0.154408  
19531          0.791302              0.0 -0.683278  

[13109 rows x 31 columns]
2025-12-03 11:19:16,887:INFO:get_config() successfully completed......................................
2025-12-03 11:19:16,888:INFO:Initializing get_config()
2025-12-03 11:19:16,888:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FA2378B80>, variable=y_test)
2025-12-03 11:19:16,888:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-12-03 11:19:16,888:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-12-03 11:19:16,892:INFO:Variable:  returned as 28456    0.0
8993     0.0
34312    0.0
4802     0.0
25895    0.0
        ... 
18045    0.0
5425     0.0
12819    0.0
33659    0.0
19531    0.0
Name: HeartDisease, Length: 13109, dtype: float32
2025-12-03 11:19:16,892:INFO:get_config() successfully completed......................................
2025-12-03 11:19:17,044:INFO:Initializing get_config()
2025-12-03 11:19:17,044:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FA2378B80>, variable=X_train_transformed)
2025-12-03 11:19:17,082:INFO:Variable: X_train returned as             Age  IncomeRatio  SystolicBP       BMI  WaistCircumference  \
15208  0.954545     0.854789    0.359485  0.518044            0.206281   
25325 -0.272727     0.253271   -0.812170 -0.966167           -0.799656   
5132   0.181818    -0.407608   -0.372799  0.054886            0.319578   
17217  0.500000    -0.751898    0.013314 -0.260904            0.278379   
6382   0.568182     0.054503    1.131712  2.675938            1.888566   
...         ...          ...         ...       ...                 ...   
6265  -0.545455    -0.431352   -0.591719  0.191728           -0.377368   
42694 -0.022727    -0.221612   -0.892056 -0.260904           -0.047778   
13399  0.454545     0.388518    0.377985  0.271482            0.183567   
39959  0.954545    -0.193911    0.625770  0.991728            1.160720   
6616   0.613636    -0.447182    0.652399 -0.871430           -0.514698   

         Height  TotalCholesterol  Triglycerides       LDL       HDL  ...  \
15208 -0.487303          0.625876       0.583394  0.005397  0.314564  ...   
25325 -0.300856          0.033588      -0.261476  0.000256  0.303682  ...   
5132   0.766972          0.181594       0.479279  0.948690 -1.340476  ...   
17217  0.745785          0.227516       0.346113  0.002441 -0.274561  ...   
6382   0.237295          0.867515       0.635574  0.002754  0.829819  ...   
...         ...               ...            ...       ...       ...  ...   
6265  -1.737339         -1.393483      -0.471046 -3.840886  0.063832  ...   
42694  0.000000          0.029167      -0.131730  0.000893  0.063832  ...   
13399 -0.147405          0.462357       0.380371  0.003925  0.256949  ...   
39959  0.368655          1.528031       1.934134  0.011744  0.191497  ...   
6616  -0.021187         -0.224877      -0.043571 -1.609476  0.510658  ...   

       Race_5.0  Race_1.0  Race_4.0  Race_3.0  Race_2.0  Education  Smoking  \
15208       1.0       0.0       0.0       0.0       0.0  -0.659696      0.0   
25325       0.0       1.0       0.0       0.0       0.0   0.185278      0.0   
5132        0.0       1.0       0.0       0.0       0.0  -0.659696      1.0   
17217       0.0       0.0       1.0       0.0       0.0  -0.056119      1.0   
6382        0.0       0.0       1.0       0.0       0.0   0.547458      1.0   
...         ...       ...       ...       ...       ...        ...      ...   
6265        0.0       1.0       0.0       0.0       0.0  -0.769055      0.0   
42694       0.0       1.0       0.0       0.0       0.0   0.547458      0.0   
13399       0.0       0.0       1.0       0.0       0.0   0.547458      0.0   
39959       0.0       0.0       0.0       1.0       0.0   0.547458      0.0   
6616        0.0       0.0       0.0       1.0       0.0   0.547458      1.0   

       PhysicalActivity  HealthInsurance   Alcohol  
15208          0.000000              0.0 -0.886483  
25325          0.000000              0.0  0.592213  
5132           0.000000             -1.0  0.312949  
17217          0.000000              0.0  0.592213  
6382           0.000000              0.0  0.597293  
...                 ...              ...       ...  
6265           0.662459              0.0 -0.501621  
42694          0.000000             -1.0  0.592213  
13399          0.000000              0.0 -0.224534  
39959          0.000000              0.0  0.592213  
6616           0.000000              0.0  0.290247  

[30586 rows x 31 columns]
2025-12-03 11:19:17,082:INFO:get_config() successfully completed......................................
2025-12-03 11:19:17,082:INFO:Initializing get_config()
2025-12-03 11:19:17,082:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FA2378B80>, variable=y_train)
2025-12-03 11:19:17,083:INFO:Variable: 'y_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_train_transformed' instead.
2025-12-03 11:19:17,083:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_train_transformed' instead.

2025-12-03 11:19:17,089:INFO:Variable:  returned as 15208    0.0
25325    0.0
5132     0.0
17217    0.0
6382     0.0
        ... 
6265     0.0
42694    0.0
13399    0.0
39959    0.0
6616     0.0
Name: HeartDisease, Length: 30586, dtype: float32
2025-12-03 11:19:17,090:INFO:get_config() successfully completed......................................
2025-12-03 11:19:17,092:INFO:Initializing get_config()
2025-12-03 11:19:17,092:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FA2378B80>, variable=X_test_transformed)
2025-12-03 11:19:17,159:INFO:Variable: X_test returned as             Age  IncomeRatio  SystolicBP       BMI  WaistCircumference  \
28456 -0.477273    -0.304717   -0.519256 -0.987220           -0.923253   
8993   0.818182     0.253271    2.156910  0.770675            0.920394   
34312  0.704545     0.055403    0.519256  0.518044            0.662901   
4802  -0.545455     0.253730   -0.331933 -0.229036           -0.436352   
25895  0.704545     1.226781   -0.093200 -0.226100            0.012322   
...         ...          ...         ...       ...                 ...   
18045 -0.568182    -0.083104   -0.568713 -1.176693           -1.338674   
5425   0.590909     0.362732    2.210168  0.139096            0.292112   
12819  0.909091    -0.019787    0.899042  0.454886            0.971892   
33659 -0.522727     1.060572   -0.525683 -0.587220           -0.906087   
19531 -0.590909    -0.344290   -0.510287 -0.945114           -1.215078   

         Height  TotalCholesterol  Triglycerides       LDL       HDL  ...  \
28456 -1.080540         -0.078535      -0.470757 -0.026922  0.418008  ...   
8993  -0.279669          0.765897       0.705031  0.006026  0.446825  ...   
34312  0.559339         -0.123259       0.929511 -1.031826 -1.404309  ...   
4802  -0.504861         -0.188325      -0.322647  0.000015 -0.138743  ...   
25895  0.216731          0.892919       1.291109  0.008211 -0.255329  ...   
...         ...               ...            ...       ...       ...  ...   
18045 -2.080569         -0.340947      -0.470582 -0.848950  0.393794  ...   
5425   0.156785          0.435639      -0.065356  1.113733  0.127664  ...   
12819  1.194951         -0.732967      -0.470025 -0.211535 -1.085148  ...   
33659 -1.254274         -1.063225      -0.470958 -2.849419  0.127664  ...   
19531 -2.339052         -0.356898      -0.470595 -0.900608  0.393896  ...   

       Race_5.0  Race_1.0  Race_4.0  Race_3.0  Race_2.0  Education   Smoking  \
28456       1.0       0.0       0.0       0.0       0.0  -0.012820  0.000000   
8993        0.0       0.0       1.0       0.0       0.0   0.547458  1.000000   
34312       0.0       0.0       0.0       1.0       0.0  -0.659696  0.000000   
4802        1.0       0.0       0.0       0.0       0.0   0.262895  0.073612   
25895       0.0       0.0       0.0       1.0       0.0   1.151035  0.000000   
...         ...       ...       ...       ...       ...        ...       ...   
18045       0.0       0.0       0.0       1.0       0.0  -0.793202  0.000000   
5425        0.0       0.0       1.0       0.0       0.0   0.547458  1.000000   
12819       0.0       0.0       0.0       1.0       0.0   1.151035  1.000000   
33659       0.0       0.0       1.0       0.0       0.0   0.258362  0.000000   
19531       1.0       0.0       0.0       0.0       0.0  -0.821118  0.000000   

       PhysicalActivity  HealthInsurance   Alcohol  
28456          0.660578              0.0 -0.518600  
8993           0.000000              0.0  0.115329  
34312          0.000000              0.0  0.592213  
4802           1.012447              0.0 -0.103347  
25895          0.000000              0.0 -0.886483  
...                 ...              ...       ...  
18045          0.904383              0.0 -0.482716  
5425           1.598141              0.0  0.097790  
12819          1.598141              0.0  0.612947  
33659          1.162475              0.0 -0.154408  
19531          0.791302              0.0 -0.683278  

[13109 rows x 31 columns]
2025-12-03 11:19:17,159:INFO:get_config() successfully completed......................................
2025-12-03 11:19:17,159:INFO:Initializing get_config()
2025-12-03 11:19:17,159:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FA2378B80>, variable=y_test)
2025-12-03 11:19:17,159:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-12-03 11:19:17,159:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-12-03 11:19:17,167:INFO:Variable:  returned as 28456    0.0
8993     0.0
34312    0.0
4802     0.0
25895    0.0
        ... 
18045    0.0
5425     0.0
12819    0.0
33659    0.0
19531    0.0
Name: HeartDisease, Length: 13109, dtype: float32
2025-12-03 11:19:17,167:INFO:get_config() successfully completed......................................
2025-12-03 11:19:17,292:INFO:Initializing get_config()
2025-12-03 11:19:17,292:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FA2378B80>, variable=X_test_transformed)
2025-12-03 11:19:17,370:INFO:Variable: X_test returned as             Age  IncomeRatio  SystolicBP       BMI  WaistCircumference  \
28456 -0.477273    -0.304717   -0.519256 -0.987220           -0.923253   
8993   0.818182     0.253271    2.156910  0.770675            0.920394   
34312  0.704545     0.055403    0.519256  0.518044            0.662901   
4802  -0.545455     0.253730   -0.331933 -0.229036           -0.436352   
25895  0.704545     1.226781   -0.093200 -0.226100            0.012322   
...         ...          ...         ...       ...                 ...   
18045 -0.568182    -0.083104   -0.568713 -1.176693           -1.338674   
5425   0.590909     0.362732    2.210168  0.139096            0.292112   
12819  0.909091    -0.019787    0.899042  0.454886            0.971892   
33659 -0.522727     1.060572   -0.525683 -0.587220           -0.906087   
19531 -0.590909    -0.344290   -0.510287 -0.945114           -1.215078   

         Height  TotalCholesterol  Triglycerides       LDL       HDL  ...  \
28456 -1.080540         -0.078535      -0.470757 -0.026922  0.418008  ...   
8993  -0.279669          0.765897       0.705031  0.006026  0.446825  ...   
34312  0.559339         -0.123259       0.929511 -1.031826 -1.404309  ...   
4802  -0.504861         -0.188325      -0.322647  0.000015 -0.138743  ...   
25895  0.216731          0.892919       1.291109  0.008211 -0.255329  ...   
...         ...               ...            ...       ...       ...  ...   
18045 -2.080569         -0.340947      -0.470582 -0.848950  0.393794  ...   
5425   0.156785          0.435639      -0.065356  1.113733  0.127664  ...   
12819  1.194951         -0.732967      -0.470025 -0.211535 -1.085148  ...   
33659 -1.254274         -1.063225      -0.470958 -2.849419  0.127664  ...   
19531 -2.339052         -0.356898      -0.470595 -0.900608  0.393896  ...   

       Race_5.0  Race_1.0  Race_4.0  Race_3.0  Race_2.0  Education   Smoking  \
28456       1.0       0.0       0.0       0.0       0.0  -0.012820  0.000000   
8993        0.0       0.0       1.0       0.0       0.0   0.547458  1.000000   
34312       0.0       0.0       0.0       1.0       0.0  -0.659696  0.000000   
4802        1.0       0.0       0.0       0.0       0.0   0.262895  0.073612   
25895       0.0       0.0       0.0       1.0       0.0   1.151035  0.000000   
...         ...       ...       ...       ...       ...        ...       ...   
18045       0.0       0.0       0.0       1.0       0.0  -0.793202  0.000000   
5425        0.0       0.0       1.0       0.0       0.0   0.547458  1.000000   
12819       0.0       0.0       0.0       1.0       0.0   1.151035  1.000000   
33659       0.0       0.0       1.0       0.0       0.0   0.258362  0.000000   
19531       1.0       0.0       0.0       0.0       0.0  -0.821118  0.000000   

       PhysicalActivity  HealthInsurance   Alcohol  
28456          0.660578              0.0 -0.518600  
8993           0.000000              0.0  0.115329  
34312          0.000000              0.0  0.592213  
4802           1.012447              0.0 -0.103347  
25895          0.000000              0.0 -0.886483  
...                 ...              ...       ...  
18045          0.904383              0.0 -0.482716  
5425           1.598141              0.0  0.097790  
12819          1.598141              0.0  0.612947  
33659          1.162475              0.0 -0.154408  
19531          0.791302              0.0 -0.683278  

[13109 rows x 31 columns]
2025-12-03 11:19:17,370:INFO:get_config() successfully completed......................................
2025-12-03 11:19:17,396:INFO:Initializing get_config()
2025-12-03 11:19:17,396:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FA2378B80>, variable=y_test)
2025-12-03 11:19:17,396:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-12-03 11:19:17,396:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-12-03 11:19:17,402:INFO:Variable:  returned as 28456    0.0
8993     0.0
34312    0.0
4802     0.0
25895    0.0
        ... 
18045    0.0
5425     0.0
12819    0.0
33659    0.0
19531    0.0
Name: HeartDisease, Length: 13109, dtype: float32
2025-12-03 11:19:17,402:INFO:get_config() successfully completed......................................
2025-12-03 11:19:17,404:INFO:Initializing get_config()
2025-12-03 11:19:17,404:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FA2378B80>, variable=y_test)
2025-12-03 11:19:17,404:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-12-03 11:19:17,406:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-12-03 11:19:17,409:INFO:Variable:  returned as 28456    0.0
8993     0.0
34312    0.0
4802     0.0
25895    0.0
        ... 
18045    0.0
5425     0.0
12819    0.0
33659    0.0
19531    0.0
Name: HeartDisease, Length: 13109, dtype: float32
2025-12-03 11:19:17,409:INFO:get_config() successfully completed......................................
2025-12-03 11:19:17,411:INFO:Initializing get_config()
2025-12-03 11:19:17,411:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FA2378B80>, variable=X_test_transformed)
2025-12-03 11:19:17,484:INFO:Variable: X_test returned as             Age  IncomeRatio  SystolicBP       BMI  WaistCircumference  \
28456 -0.477273    -0.304717   -0.519256 -0.987220           -0.923253   
8993   0.818182     0.253271    2.156910  0.770675            0.920394   
34312  0.704545     0.055403    0.519256  0.518044            0.662901   
4802  -0.545455     0.253730   -0.331933 -0.229036           -0.436352   
25895  0.704545     1.226781   -0.093200 -0.226100            0.012322   
...         ...          ...         ...       ...                 ...   
18045 -0.568182    -0.083104   -0.568713 -1.176693           -1.338674   
5425   0.590909     0.362732    2.210168  0.139096            0.292112   
12819  0.909091    -0.019787    0.899042  0.454886            0.971892   
33659 -0.522727     1.060572   -0.525683 -0.587220           -0.906087   
19531 -0.590909    -0.344290   -0.510287 -0.945114           -1.215078   

         Height  TotalCholesterol  Triglycerides       LDL       HDL  ...  \
28456 -1.080540         -0.078535      -0.470757 -0.026922  0.418008  ...   
8993  -0.279669          0.765897       0.705031  0.006026  0.446825  ...   
34312  0.559339         -0.123259       0.929511 -1.031826 -1.404309  ...   
4802  -0.504861         -0.188325      -0.322647  0.000015 -0.138743  ...   
25895  0.216731          0.892919       1.291109  0.008211 -0.255329  ...   
...         ...               ...            ...       ...       ...  ...   
18045 -2.080569         -0.340947      -0.470582 -0.848950  0.393794  ...   
5425   0.156785          0.435639      -0.065356  1.113733  0.127664  ...   
12819  1.194951         -0.732967      -0.470025 -0.211535 -1.085148  ...   
33659 -1.254274         -1.063225      -0.470958 -2.849419  0.127664  ...   
19531 -2.339052         -0.356898      -0.470595 -0.900608  0.393896  ...   

       Race_5.0  Race_1.0  Race_4.0  Race_3.0  Race_2.0  Education   Smoking  \
28456       1.0       0.0       0.0       0.0       0.0  -0.012820  0.000000   
8993        0.0       0.0       1.0       0.0       0.0   0.547458  1.000000   
34312       0.0       0.0       0.0       1.0       0.0  -0.659696  0.000000   
4802        1.0       0.0       0.0       0.0       0.0   0.262895  0.073612   
25895       0.0       0.0       0.0       1.0       0.0   1.151035  0.000000   
...         ...       ...       ...       ...       ...        ...       ...   
18045       0.0       0.0       0.0       1.0       0.0  -0.793202  0.000000   
5425        0.0       0.0       1.0       0.0       0.0   0.547458  1.000000   
12819       0.0       0.0       0.0       1.0       0.0   1.151035  1.000000   
33659       0.0       0.0       1.0       0.0       0.0   0.258362  0.000000   
19531       1.0       0.0       0.0       0.0       0.0  -0.821118  0.000000   

       PhysicalActivity  HealthInsurance   Alcohol  
28456          0.660578              0.0 -0.518600  
8993           0.000000              0.0  0.115329  
34312          0.000000              0.0  0.592213  
4802           1.012447              0.0 -0.103347  
25895          0.000000              0.0 -0.886483  
...                 ...              ...       ...  
18045          0.904383              0.0 -0.482716  
5425           1.598141              0.0  0.097790  
12819          1.598141              0.0  0.612947  
33659          1.162475              0.0 -0.154408  
19531          0.791302              0.0 -0.683278  

[13109 rows x 31 columns]
2025-12-03 11:19:17,487:INFO:get_config() successfully completed......................................
2025-12-03 11:19:17,489:INFO:Initializing get_config()
2025-12-03 11:19:17,489:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FA2378B80>, variable=y_test)
2025-12-03 11:19:17,489:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-12-03 11:19:17,489:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-12-03 11:19:17,494:INFO:Variable:  returned as 28456    0.0
8993     0.0
34312    0.0
4802     0.0
25895    0.0
        ... 
18045    0.0
5425     0.0
12819    0.0
33659    0.0
19531    0.0
Name: HeartDisease, Length: 13109, dtype: float32
2025-12-03 11:19:17,494:INFO:get_config() successfully completed......................................
2025-12-03 11:19:17,495:INFO:Initializing get_config()
2025-12-03 11:19:17,495:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FA2378B80>, variable=y_test)
2025-12-03 11:19:17,495:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-12-03 11:19:17,495:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-12-03 11:19:17,502:INFO:Variable:  returned as 28456    0.0
8993     0.0
34312    0.0
4802     0.0
25895    0.0
        ... 
18045    0.0
5425     0.0
12819    0.0
33659    0.0
19531    0.0
Name: HeartDisease, Length: 13109, dtype: float32
2025-12-03 11:19:17,502:INFO:get_config() successfully completed......................................
2025-12-03 11:19:17,505:INFO:Initializing get_config()
2025-12-03 11:19:17,505:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FA2378B80>, variable=X_test_transformed)
2025-12-03 11:19:17,574:INFO:Variable: X_test returned as             Age  IncomeRatio  SystolicBP       BMI  WaistCircumference  \
28456 -0.477273    -0.304717   -0.519256 -0.987220           -0.923253   
8993   0.818182     0.253271    2.156910  0.770675            0.920394   
34312  0.704545     0.055403    0.519256  0.518044            0.662901   
4802  -0.545455     0.253730   -0.331933 -0.229036           -0.436352   
25895  0.704545     1.226781   -0.093200 -0.226100            0.012322   
...         ...          ...         ...       ...                 ...   
18045 -0.568182    -0.083104   -0.568713 -1.176693           -1.338674   
5425   0.590909     0.362732    2.210168  0.139096            0.292112   
12819  0.909091    -0.019787    0.899042  0.454886            0.971892   
33659 -0.522727     1.060572   -0.525683 -0.587220           -0.906087   
19531 -0.590909    -0.344290   -0.510287 -0.945114           -1.215078   

         Height  TotalCholesterol  Triglycerides       LDL       HDL  ...  \
28456 -1.080540         -0.078535      -0.470757 -0.026922  0.418008  ...   
8993  -0.279669          0.765897       0.705031  0.006026  0.446825  ...   
34312  0.559339         -0.123259       0.929511 -1.031826 -1.404309  ...   
4802  -0.504861         -0.188325      -0.322647  0.000015 -0.138743  ...   
25895  0.216731          0.892919       1.291109  0.008211 -0.255329  ...   
...         ...               ...            ...       ...       ...  ...   
18045 -2.080569         -0.340947      -0.470582 -0.848950  0.393794  ...   
5425   0.156785          0.435639      -0.065356  1.113733  0.127664  ...   
12819  1.194951         -0.732967      -0.470025 -0.211535 -1.085148  ...   
33659 -1.254274         -1.063225      -0.470958 -2.849419  0.127664  ...   
19531 -2.339052         -0.356898      -0.470595 -0.900608  0.393896  ...   

       Race_5.0  Race_1.0  Race_4.0  Race_3.0  Race_2.0  Education   Smoking  \
28456       1.0       0.0       0.0       0.0       0.0  -0.012820  0.000000   
8993        0.0       0.0       1.0       0.0       0.0   0.547458  1.000000   
34312       0.0       0.0       0.0       1.0       0.0  -0.659696  0.000000   
4802        1.0       0.0       0.0       0.0       0.0   0.262895  0.073612   
25895       0.0       0.0       0.0       1.0       0.0   1.151035  0.000000   
...         ...       ...       ...       ...       ...        ...       ...   
18045       0.0       0.0       0.0       1.0       0.0  -0.793202  0.000000   
5425        0.0       0.0       1.0       0.0       0.0   0.547458  1.000000   
12819       0.0       0.0       0.0       1.0       0.0   1.151035  1.000000   
33659       0.0       0.0       1.0       0.0       0.0   0.258362  0.000000   
19531       1.0       0.0       0.0       0.0       0.0  -0.821118  0.000000   

       PhysicalActivity  HealthInsurance   Alcohol  
28456          0.660578              0.0 -0.518600  
8993           0.000000              0.0  0.115329  
34312          0.000000              0.0  0.592213  
4802           1.012447              0.0 -0.103347  
25895          0.000000              0.0 -0.886483  
...                 ...              ...       ...  
18045          0.904383              0.0 -0.482716  
5425           1.598141              0.0  0.097790  
12819          1.598141              0.0  0.612947  
33659          1.162475              0.0 -0.154408  
19531          0.791302              0.0 -0.683278  

[13109 rows x 31 columns]
2025-12-03 11:19:17,574:INFO:get_config() successfully completed......................................
2025-12-03 11:19:17,628:INFO:Initializing get_config()
2025-12-03 11:19:17,628:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FA2378B80>, variable=y_test)
2025-12-03 11:19:17,630:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-12-03 11:19:17,630:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-12-03 11:19:17,634:INFO:Variable:  returned as 28456    0.0
8993     0.0
34312    0.0
4802     0.0
25895    0.0
        ... 
18045    0.0
5425     0.0
12819    0.0
33659    0.0
19531    0.0
Name: HeartDisease, Length: 13109, dtype: float32
2025-12-03 11:19:17,634:INFO:get_config() successfully completed......................................
2025-12-03 11:19:17,636:INFO:Initializing get_config()
2025-12-03 11:19:17,636:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FA2378B80>, variable=y_test)
2025-12-03 11:19:17,636:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-12-03 11:19:17,636:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-12-03 11:19:17,641:INFO:Variable:  returned as 28456    0.0
8993     0.0
34312    0.0
4802     0.0
25895    0.0
        ... 
18045    0.0
5425     0.0
12819    0.0
33659    0.0
19531    0.0
Name: HeartDisease, Length: 13109, dtype: float32
2025-12-03 11:19:17,641:INFO:get_config() successfully completed......................................
2025-12-03 11:19:17,646:INFO:Initializing get_config()
2025-12-03 11:19:17,646:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FA2378B80>, variable=y_test)
2025-12-03 11:19:17,646:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-12-03 11:19:17,646:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-12-03 11:19:17,654:INFO:Variable:  returned as 28456    0.0
8993     0.0
34312    0.0
4802     0.0
25895    0.0
        ... 
18045    0.0
5425     0.0
12819    0.0
33659    0.0
19531    0.0
Name: HeartDisease, Length: 13109, dtype: float32
2025-12-03 11:19:17,654:INFO:get_config() successfully completed......................................
2025-12-03 11:19:17,654:INFO:Initializing get_config()
2025-12-03 11:19:17,654:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FA2378B80>, variable=X_test_transformed)
2025-12-03 11:19:17,723:INFO:Variable: X_test returned as             Age  IncomeRatio  SystolicBP       BMI  WaistCircumference  \
28456 -0.477273    -0.304717   -0.519256 -0.987220           -0.923253   
8993   0.818182     0.253271    2.156910  0.770675            0.920394   
34312  0.704545     0.055403    0.519256  0.518044            0.662901   
4802  -0.545455     0.253730   -0.331933 -0.229036           -0.436352   
25895  0.704545     1.226781   -0.093200 -0.226100            0.012322   
...         ...          ...         ...       ...                 ...   
18045 -0.568182    -0.083104   -0.568713 -1.176693           -1.338674   
5425   0.590909     0.362732    2.210168  0.139096            0.292112   
12819  0.909091    -0.019787    0.899042  0.454886            0.971892   
33659 -0.522727     1.060572   -0.525683 -0.587220           -0.906087   
19531 -0.590909    -0.344290   -0.510287 -0.945114           -1.215078   

         Height  TotalCholesterol  Triglycerides       LDL       HDL  ...  \
28456 -1.080540         -0.078535      -0.470757 -0.026922  0.418008  ...   
8993  -0.279669          0.765897       0.705031  0.006026  0.446825  ...   
34312  0.559339         -0.123259       0.929511 -1.031826 -1.404309  ...   
4802  -0.504861         -0.188325      -0.322647  0.000015 -0.138743  ...   
25895  0.216731          0.892919       1.291109  0.008211 -0.255329  ...   
...         ...               ...            ...       ...       ...  ...   
18045 -2.080569         -0.340947      -0.470582 -0.848950  0.393794  ...   
5425   0.156785          0.435639      -0.065356  1.113733  0.127664  ...   
12819  1.194951         -0.732967      -0.470025 -0.211535 -1.085148  ...   
33659 -1.254274         -1.063225      -0.470958 -2.849419  0.127664  ...   
19531 -2.339052         -0.356898      -0.470595 -0.900608  0.393896  ...   

       Race_5.0  Race_1.0  Race_4.0  Race_3.0  Race_2.0  Education   Smoking  \
28456       1.0       0.0       0.0       0.0       0.0  -0.012820  0.000000   
8993        0.0       0.0       1.0       0.0       0.0   0.547458  1.000000   
34312       0.0       0.0       0.0       1.0       0.0  -0.659696  0.000000   
4802        1.0       0.0       0.0       0.0       0.0   0.262895  0.073612   
25895       0.0       0.0       0.0       1.0       0.0   1.151035  0.000000   
...         ...       ...       ...       ...       ...        ...       ...   
18045       0.0       0.0       0.0       1.0       0.0  -0.793202  0.000000   
5425        0.0       0.0       1.0       0.0       0.0   0.547458  1.000000   
12819       0.0       0.0       0.0       1.0       0.0   1.151035  1.000000   
33659       0.0       0.0       1.0       0.0       0.0   0.258362  0.000000   
19531       1.0       0.0       0.0       0.0       0.0  -0.821118  0.000000   

       PhysicalActivity  HealthInsurance   Alcohol  
28456          0.660578              0.0 -0.518600  
8993           0.000000              0.0  0.115329  
34312          0.000000              0.0  0.592213  
4802           1.012447              0.0 -0.103347  
25895          0.000000              0.0 -0.886483  
...                 ...              ...       ...  
18045          0.904383              0.0 -0.482716  
5425           1.598141              0.0  0.097790  
12819          1.598141              0.0  0.612947  
33659          1.162475              0.0 -0.154408  
19531          0.791302              0.0 -0.683278  

[13109 rows x 31 columns]
2025-12-03 11:19:17,723:INFO:get_config() successfully completed......................................
2025-12-03 11:19:17,755:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pandas\io\formats\style.py:3823: RuntimeWarning: invalid value encountered in scalar multiply

2025-12-03 11:19:17,783:INFO:Initializing plot_model()
2025-12-03 11:19:17,783:INFO:plot_model(plot=error, fold=None, verbose=True, display=None, display_format=None, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FA2378B80>, system=True)
2025-12-03 11:19:17,783:INFO:Checking exceptions
2025-12-03 11:19:17,801:INFO:Preloading libraries
2025-12-03 11:19:17,811:INFO:Copying training dataset
2025-12-03 11:19:17,811:INFO:Plot type: error
2025-12-03 11:19:18,020:INFO:Fitting Model
2025-12-03 11:19:18,023:INFO:Scoring test/hold-out set
2025-12-03 11:19:18,180:INFO:Visual Rendered Successfully
2025-12-03 11:19:18,353:INFO:plot_model() successfully completed......................................
2025-12-03 11:19:18,353:INFO:Initializing get_config()
2025-12-03 11:19:18,356:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FA2378B80>, variable=X_train_transformed)
2025-12-03 11:19:18,395:INFO:Variable: X_train returned as             Age  IncomeRatio  SystolicBP       BMI  WaistCircumference  \
15208  0.954545     0.854789    0.359485  0.518044            0.206281   
25325 -0.272727     0.253271   -0.812170 -0.966167           -0.799656   
5132   0.181818    -0.407608   -0.372799  0.054886            0.319578   
17217  0.500000    -0.751898    0.013314 -0.260904            0.278379   
6382   0.568182     0.054503    1.131712  2.675938            1.888566   
...         ...          ...         ...       ...                 ...   
6265  -0.545455    -0.431352   -0.591719  0.191728           -0.377368   
42694 -0.022727    -0.221612   -0.892056 -0.260904           -0.047778   
13399  0.454545     0.388518    0.377985  0.271482            0.183567   
39959  0.954545    -0.193911    0.625770  0.991728            1.160720   
6616   0.613636    -0.447182    0.652399 -0.871430           -0.514698   

         Height  TotalCholesterol  Triglycerides       LDL       HDL  ...  \
15208 -0.487303          0.625876       0.583394  0.005397  0.314564  ...   
25325 -0.300856          0.033588      -0.261476  0.000256  0.303682  ...   
5132   0.766972          0.181594       0.479279  0.948690 -1.340476  ...   
17217  0.745785          0.227516       0.346113  0.002441 -0.274561  ...   
6382   0.237295          0.867515       0.635574  0.002754  0.829819  ...   
...         ...               ...            ...       ...       ...  ...   
6265  -1.737339         -1.393483      -0.471046 -3.840886  0.063832  ...   
42694  0.000000          0.029167      -0.131730  0.000893  0.063832  ...   
13399 -0.147405          0.462357       0.380371  0.003925  0.256949  ...   
39959  0.368655          1.528031       1.934134  0.011744  0.191497  ...   
6616  -0.021187         -0.224877      -0.043571 -1.609476  0.510658  ...   

       Race_5.0  Race_1.0  Race_4.0  Race_3.0  Race_2.0  Education  Smoking  \
15208       1.0       0.0       0.0       0.0       0.0  -0.659696      0.0   
25325       0.0       1.0       0.0       0.0       0.0   0.185278      0.0   
5132        0.0       1.0       0.0       0.0       0.0  -0.659696      1.0   
17217       0.0       0.0       1.0       0.0       0.0  -0.056119      1.0   
6382        0.0       0.0       1.0       0.0       0.0   0.547458      1.0   
...         ...       ...       ...       ...       ...        ...      ...   
6265        0.0       1.0       0.0       0.0       0.0  -0.769055      0.0   
42694       0.0       1.0       0.0       0.0       0.0   0.547458      0.0   
13399       0.0       0.0       1.0       0.0       0.0   0.547458      0.0   
39959       0.0       0.0       0.0       1.0       0.0   0.547458      0.0   
6616        0.0       0.0       0.0       1.0       0.0   0.547458      1.0   

       PhysicalActivity  HealthInsurance   Alcohol  
15208          0.000000              0.0 -0.886483  
25325          0.000000              0.0  0.592213  
5132           0.000000             -1.0  0.312949  
17217          0.000000              0.0  0.592213  
6382           0.000000              0.0  0.597293  
...                 ...              ...       ...  
6265           0.662459              0.0 -0.501621  
42694          0.000000             -1.0  0.592213  
13399          0.000000              0.0 -0.224534  
39959          0.000000              0.0  0.592213  
6616           0.000000              0.0  0.290247  

[30586 rows x 31 columns]
2025-12-03 11:19:18,395:INFO:get_config() successfully completed......................................
2025-12-03 11:19:18,395:INFO:Initializing get_config()
2025-12-03 11:19:18,395:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FA2378B80>, variable=y_train)
2025-12-03 11:19:18,395:INFO:Variable: 'y_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_train_transformed' instead.
2025-12-03 11:19:18,395:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_train_transformed' instead.

2025-12-03 11:19:18,401:INFO:Variable:  returned as 15208    0.0
25325    0.0
5132     0.0
17217    0.0
6382     0.0
        ... 
6265     0.0
42694    0.0
13399    0.0
39959    0.0
6616     0.0
Name: HeartDisease, Length: 30586, dtype: float32
2025-12-03 11:19:18,401:INFO:get_config() successfully completed......................................
2025-12-03 11:19:22,994:INFO:Initializing get_config()
2025-12-03 11:19:22,994:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FA2378B80>, variable=X_test_transformed)
2025-12-03 11:19:23,073:INFO:Variable: X_test returned as             Age  IncomeRatio  SystolicBP       BMI  WaistCircumference  \
28456 -0.477273    -0.304717   -0.519256 -0.987220           -0.923253   
8993   0.818182     0.253271    2.156910  0.770675            0.920394   
34312  0.704545     0.055403    0.519256  0.518044            0.662901   
4802  -0.545455     0.253730   -0.331933 -0.229036           -0.436352   
25895  0.704545     1.226781   -0.093200 -0.226100            0.012322   
...         ...          ...         ...       ...                 ...   
18045 -0.568182    -0.083104   -0.568713 -1.176693           -1.338674   
5425   0.590909     0.362732    2.210168  0.139096            0.292112   
12819  0.909091    -0.019787    0.899042  0.454886            0.971892   
33659 -0.522727     1.060572   -0.525683 -0.587220           -0.906087   
19531 -0.590909    -0.344290   -0.510287 -0.945114           -1.215078   

         Height  TotalCholesterol  Triglycerides       LDL       HDL  ...  \
28456 -1.080540         -0.078535      -0.470757 -0.026922  0.418008  ...   
8993  -0.279669          0.765897       0.705031  0.006026  0.446825  ...   
34312  0.559339         -0.123259       0.929511 -1.031826 -1.404309  ...   
4802  -0.504861         -0.188325      -0.322647  0.000015 -0.138743  ...   
25895  0.216731          0.892919       1.291109  0.008211 -0.255329  ...   
...         ...               ...            ...       ...       ...  ...   
18045 -2.080569         -0.340947      -0.470582 -0.848950  0.393794  ...   
5425   0.156785          0.435639      -0.065356  1.113733  0.127664  ...   
12819  1.194951         -0.732967      -0.470025 -0.211535 -1.085148  ...   
33659 -1.254274         -1.063225      -0.470958 -2.849419  0.127664  ...   
19531 -2.339052         -0.356898      -0.470595 -0.900608  0.393896  ...   

       Race_5.0  Race_1.0  Race_4.0  Race_3.0  Race_2.0  Education   Smoking  \
28456       1.0       0.0       0.0       0.0       0.0  -0.012820  0.000000   
8993        0.0       0.0       1.0       0.0       0.0   0.547458  1.000000   
34312       0.0       0.0       0.0       1.0       0.0  -0.659696  0.000000   
4802        1.0       0.0       0.0       0.0       0.0   0.262895  0.073612   
25895       0.0       0.0       0.0       1.0       0.0   1.151035  0.000000   
...         ...       ...       ...       ...       ...        ...       ...   
18045       0.0       0.0       0.0       1.0       0.0  -0.793202  0.000000   
5425        0.0       0.0       1.0       0.0       0.0   0.547458  1.000000   
12819       0.0       0.0       0.0       1.0       0.0   1.151035  1.000000   
33659       0.0       0.0       1.0       0.0       0.0   0.258362  0.000000   
19531       1.0       0.0       0.0       0.0       0.0  -0.821118  0.000000   

       PhysicalActivity  HealthInsurance   Alcohol  
28456          0.660578              0.0 -0.518600  
8993           0.000000              0.0  0.115329  
34312          0.000000              0.0  0.592213  
4802           1.012447              0.0 -0.103347  
25895          0.000000              0.0 -0.886483  
...                 ...              ...       ...  
18045          0.904383              0.0 -0.482716  
5425           1.598141              0.0  0.097790  
12819          1.598141              0.0  0.612947  
33659          1.162475              0.0 -0.154408  
19531          0.791302              0.0 -0.683278  

[13109 rows x 31 columns]
2025-12-03 11:19:23,073:INFO:get_config() successfully completed......................................
2025-12-03 11:19:23,100:INFO:Initializing get_config()
2025-12-03 11:19:23,101:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FA2378B80>, variable=y_test)
2025-12-03 11:19:23,101:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-12-03 11:19:23,101:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-12-03 11:19:23,106:INFO:Variable:  returned as 28456    0.0
8993     0.0
34312    0.0
4802     0.0
25895    0.0
        ... 
18045    0.0
5425     0.0
12819    0.0
33659    0.0
19531    0.0
Name: HeartDisease, Length: 13109, dtype: float32
2025-12-03 11:19:23,106:INFO:get_config() successfully completed......................................
2025-12-03 11:19:23,106:INFO:Initializing get_config()
2025-12-03 11:19:23,106:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FA2378B80>, variable=y_test)
2025-12-03 11:19:23,106:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-12-03 11:19:23,106:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-12-03 11:19:23,112:INFO:Variable:  returned as 28456    0.0
8993     0.0
34312    0.0
4802     0.0
25895    0.0
        ... 
18045    0.0
5425     0.0
12819    0.0
33659    0.0
19531    0.0
Name: HeartDisease, Length: 13109, dtype: float32
2025-12-03 11:19:23,112:INFO:get_config() successfully completed......................................
2025-12-03 11:19:23,117:INFO:Initializing get_config()
2025-12-03 11:19:23,117:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FA2378B80>, variable=X_test_transformed)
2025-12-03 11:19:23,188:INFO:Variable: X_test returned as             Age  IncomeRatio  SystolicBP       BMI  WaistCircumference  \
28456 -0.477273    -0.304717   -0.519256 -0.987220           -0.923253   
8993   0.818182     0.253271    2.156910  0.770675            0.920394   
34312  0.704545     0.055403    0.519256  0.518044            0.662901   
4802  -0.545455     0.253730   -0.331933 -0.229036           -0.436352   
25895  0.704545     1.226781   -0.093200 -0.226100            0.012322   
...         ...          ...         ...       ...                 ...   
18045 -0.568182    -0.083104   -0.568713 -1.176693           -1.338674   
5425   0.590909     0.362732    2.210168  0.139096            0.292112   
12819  0.909091    -0.019787    0.899042  0.454886            0.971892   
33659 -0.522727     1.060572   -0.525683 -0.587220           -0.906087   
19531 -0.590909    -0.344290   -0.510287 -0.945114           -1.215078   

         Height  TotalCholesterol  Triglycerides       LDL       HDL  ...  \
28456 -1.080540         -0.078535      -0.470757 -0.026922  0.418008  ...   
8993  -0.279669          0.765897       0.705031  0.006026  0.446825  ...   
34312  0.559339         -0.123259       0.929511 -1.031826 -1.404309  ...   
4802  -0.504861         -0.188325      -0.322647  0.000015 -0.138743  ...   
25895  0.216731          0.892919       1.291109  0.008211 -0.255329  ...   
...         ...               ...            ...       ...       ...  ...   
18045 -2.080569         -0.340947      -0.470582 -0.848950  0.393794  ...   
5425   0.156785          0.435639      -0.065356  1.113733  0.127664  ...   
12819  1.194951         -0.732967      -0.470025 -0.211535 -1.085148  ...   
33659 -1.254274         -1.063225      -0.470958 -2.849419  0.127664  ...   
19531 -2.339052         -0.356898      -0.470595 -0.900608  0.393896  ...   

       Race_5.0  Race_1.0  Race_4.0  Race_3.0  Race_2.0  Education   Smoking  \
28456       1.0       0.0       0.0       0.0       0.0  -0.012820  0.000000   
8993        0.0       0.0       1.0       0.0       0.0   0.547458  1.000000   
34312       0.0       0.0       0.0       1.0       0.0  -0.659696  0.000000   
4802        1.0       0.0       0.0       0.0       0.0   0.262895  0.073612   
25895       0.0       0.0       0.0       1.0       0.0   1.151035  0.000000   
...         ...       ...       ...       ...       ...        ...       ...   
18045       0.0       0.0       0.0       1.0       0.0  -0.793202  0.000000   
5425        0.0       0.0       1.0       0.0       0.0   0.547458  1.000000   
12819       0.0       0.0       0.0       1.0       0.0   1.151035  1.000000   
33659       0.0       0.0       1.0       0.0       0.0   0.258362  0.000000   
19531       1.0       0.0       0.0       0.0       0.0  -0.821118  0.000000   

       PhysicalActivity  HealthInsurance   Alcohol  
28456          0.660578              0.0 -0.518600  
8993           0.000000              0.0  0.115329  
34312          0.000000              0.0  0.592213  
4802           1.012447              0.0 -0.103347  
25895          0.000000              0.0 -0.886483  
...                 ...              ...       ...  
18045          0.904383              0.0 -0.482716  
5425           1.598141              0.0  0.097790  
12819          1.598141              0.0  0.612947  
33659          1.162475              0.0 -0.154408  
19531          0.791302              0.0 -0.683278  

[13109 rows x 31 columns]
2025-12-03 11:19:23,188:INFO:get_config() successfully completed......................................
2025-12-03 11:19:23,188:INFO:Initializing get_config()
2025-12-03 11:19:23,188:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FA2378B80>, variable=y_test)
2025-12-03 11:19:23,191:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-12-03 11:19:23,191:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-12-03 11:19:23,196:INFO:Variable:  returned as 28456    0.0
8993     0.0
34312    0.0
4802     0.0
25895    0.0
        ... 
18045    0.0
5425     0.0
12819    0.0
33659    0.0
19531    0.0
Name: HeartDisease, Length: 13109, dtype: float32
2025-12-03 11:19:23,196:INFO:get_config() successfully completed......................................
2025-12-03 11:19:23,197:INFO:Initializing get_config()
2025-12-03 11:19:23,197:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FA2378B80>, variable=y_test)
2025-12-03 11:19:23,197:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-12-03 11:19:23,197:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-12-03 11:19:23,202:INFO:Variable:  returned as 28456    0.0
8993     0.0
34312    0.0
4802     0.0
25895    0.0
        ... 
18045    0.0
5425     0.0
12819    0.0
33659    0.0
19531    0.0
Name: HeartDisease, Length: 13109, dtype: float32
2025-12-03 11:19:23,202:INFO:get_config() successfully completed......................................
2025-12-03 11:19:23,205:INFO:Initializing get_config()
2025-12-03 11:19:23,206:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FA2378B80>, variable=X_test_transformed)
2025-12-03 11:19:23,280:INFO:Variable: X_test returned as             Age  IncomeRatio  SystolicBP       BMI  WaistCircumference  \
28456 -0.477273    -0.304717   -0.519256 -0.987220           -0.923253   
8993   0.818182     0.253271    2.156910  0.770675            0.920394   
34312  0.704545     0.055403    0.519256  0.518044            0.662901   
4802  -0.545455     0.253730   -0.331933 -0.229036           -0.436352   
25895  0.704545     1.226781   -0.093200 -0.226100            0.012322   
...         ...          ...         ...       ...                 ...   
18045 -0.568182    -0.083104   -0.568713 -1.176693           -1.338674   
5425   0.590909     0.362732    2.210168  0.139096            0.292112   
12819  0.909091    -0.019787    0.899042  0.454886            0.971892   
33659 -0.522727     1.060572   -0.525683 -0.587220           -0.906087   
19531 -0.590909    -0.344290   -0.510287 -0.945114           -1.215078   

         Height  TotalCholesterol  Triglycerides       LDL       HDL  ...  \
28456 -1.080540         -0.078535      -0.470757 -0.026922  0.418008  ...   
8993  -0.279669          0.765897       0.705031  0.006026  0.446825  ...   
34312  0.559339         -0.123259       0.929511 -1.031826 -1.404309  ...   
4802  -0.504861         -0.188325      -0.322647  0.000015 -0.138743  ...   
25895  0.216731          0.892919       1.291109  0.008211 -0.255329  ...   
...         ...               ...            ...       ...       ...  ...   
18045 -2.080569         -0.340947      -0.470582 -0.848950  0.393794  ...   
5425   0.156785          0.435639      -0.065356  1.113733  0.127664  ...   
12819  1.194951         -0.732967      -0.470025 -0.211535 -1.085148  ...   
33659 -1.254274         -1.063225      -0.470958 -2.849419  0.127664  ...   
19531 -2.339052         -0.356898      -0.470595 -0.900608  0.393896  ...   

       Race_5.0  Race_1.0  Race_4.0  Race_3.0  Race_2.0  Education   Smoking  \
28456       1.0       0.0       0.0       0.0       0.0  -0.012820  0.000000   
8993        0.0       0.0       1.0       0.0       0.0   0.547458  1.000000   
34312       0.0       0.0       0.0       1.0       0.0  -0.659696  0.000000   
4802        1.0       0.0       0.0       0.0       0.0   0.262895  0.073612   
25895       0.0       0.0       0.0       1.0       0.0   1.151035  0.000000   
...         ...       ...       ...       ...       ...        ...       ...   
18045       0.0       0.0       0.0       1.0       0.0  -0.793202  0.000000   
5425        0.0       0.0       1.0       0.0       0.0   0.547458  1.000000   
12819       0.0       0.0       0.0       1.0       0.0   1.151035  1.000000   
33659       0.0       0.0       1.0       0.0       0.0   0.258362  0.000000   
19531       1.0       0.0       0.0       0.0       0.0  -0.821118  0.000000   

       PhysicalActivity  HealthInsurance   Alcohol  
28456          0.660578              0.0 -0.518600  
8993           0.000000              0.0  0.115329  
34312          0.000000              0.0  0.592213  
4802           1.012447              0.0 -0.103347  
25895          0.000000              0.0 -0.886483  
...                 ...              ...       ...  
18045          0.904383              0.0 -0.482716  
5425           1.598141              0.0  0.097790  
12819          1.598141              0.0  0.612947  
33659          1.162475              0.0 -0.154408  
19531          0.791302              0.0 -0.683278  

[13109 rows x 31 columns]
2025-12-03 11:19:23,280:INFO:get_config() successfully completed......................................
2025-12-03 11:19:23,346:INFO:Initializing get_config()
2025-12-03 11:19:23,346:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FA2378B80>, variable=y_test)
2025-12-03 11:19:23,346:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-12-03 11:19:23,346:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-12-03 11:19:23,354:INFO:Variable:  returned as 28456    0.0
8993     0.0
34312    0.0
4802     0.0
25895    0.0
        ... 
18045    0.0
5425     0.0
12819    0.0
33659    0.0
19531    0.0
Name: HeartDisease, Length: 13109, dtype: float32
2025-12-03 11:19:23,354:INFO:get_config() successfully completed......................................
2025-12-03 11:19:23,354:INFO:Initializing get_config()
2025-12-03 11:19:23,354:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FA2378B80>, variable=y_test)
2025-12-03 11:19:23,354:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-12-03 11:19:23,354:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-12-03 11:19:23,358:INFO:Variable:  returned as 28456    0.0
8993     0.0
34312    0.0
4802     0.0
25895    0.0
        ... 
18045    0.0
5425     0.0
12819    0.0
33659    0.0
19531    0.0
Name: HeartDisease, Length: 13109, dtype: float32
2025-12-03 11:19:23,358:INFO:get_config() successfully completed......................................
2025-12-03 11:19:23,484:INFO:Initializing get_config()
2025-12-03 11:19:23,485:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FA2378B80>, variable=X_test_transformed)
2025-12-03 11:19:23,562:INFO:Variable: X_test returned as             Age  IncomeRatio  SystolicBP       BMI  WaistCircumference  \
28456 -0.477273    -0.304717   -0.519256 -0.987220           -0.923253   
8993   0.818182     0.253271    2.156910  0.770675            0.920394   
34312  0.704545     0.055403    0.519256  0.518044            0.662901   
4802  -0.545455     0.253730   -0.331933 -0.229036           -0.436352   
25895  0.704545     1.226781   -0.093200 -0.226100            0.012322   
...         ...          ...         ...       ...                 ...   
18045 -0.568182    -0.083104   -0.568713 -1.176693           -1.338674   
5425   0.590909     0.362732    2.210168  0.139096            0.292112   
12819  0.909091    -0.019787    0.899042  0.454886            0.971892   
33659 -0.522727     1.060572   -0.525683 -0.587220           -0.906087   
19531 -0.590909    -0.344290   -0.510287 -0.945114           -1.215078   

         Height  TotalCholesterol  Triglycerides       LDL       HDL  ...  \
28456 -1.080540         -0.078535      -0.470757 -0.026922  0.418008  ...   
8993  -0.279669          0.765897       0.705031  0.006026  0.446825  ...   
34312  0.559339         -0.123259       0.929511 -1.031826 -1.404309  ...   
4802  -0.504861         -0.188325      -0.322647  0.000015 -0.138743  ...   
25895  0.216731          0.892919       1.291109  0.008211 -0.255329  ...   
...         ...               ...            ...       ...       ...  ...   
18045 -2.080569         -0.340947      -0.470582 -0.848950  0.393794  ...   
5425   0.156785          0.435639      -0.065356  1.113733  0.127664  ...   
12819  1.194951         -0.732967      -0.470025 -0.211535 -1.085148  ...   
33659 -1.254274         -1.063225      -0.470958 -2.849419  0.127664  ...   
19531 -2.339052         -0.356898      -0.470595 -0.900608  0.393896  ...   

       Race_5.0  Race_1.0  Race_4.0  Race_3.0  Race_2.0  Education   Smoking  \
28456       1.0       0.0       0.0       0.0       0.0  -0.012820  0.000000   
8993        0.0       0.0       1.0       0.0       0.0   0.547458  1.000000   
34312       0.0       0.0       0.0       1.0       0.0  -0.659696  0.000000   
4802        1.0       0.0       0.0       0.0       0.0   0.262895  0.073612   
25895       0.0       0.0       0.0       1.0       0.0   1.151035  0.000000   
...         ...       ...       ...       ...       ...        ...       ...   
18045       0.0       0.0       0.0       1.0       0.0  -0.793202  0.000000   
5425        0.0       0.0       1.0       0.0       0.0   0.547458  1.000000   
12819       0.0       0.0       0.0       1.0       0.0   1.151035  1.000000   
33659       0.0       0.0       1.0       0.0       0.0   0.258362  0.000000   
19531       1.0       0.0       0.0       0.0       0.0  -0.821118  0.000000   

       PhysicalActivity  HealthInsurance   Alcohol  
28456          0.660578              0.0 -0.518600  
8993           0.000000              0.0  0.115329  
34312          0.000000              0.0  0.592213  
4802           1.012447              0.0 -0.103347  
25895          0.000000              0.0 -0.886483  
...                 ...              ...       ...  
18045          0.904383              0.0 -0.482716  
5425           1.598141              0.0  0.097790  
12819          1.598141              0.0  0.612947  
33659          1.162475              0.0 -0.154408  
19531          0.791302              0.0 -0.683278  

[13109 rows x 31 columns]
2025-12-03 11:19:23,562:INFO:get_config() successfully completed......................................
2025-12-03 11:19:23,588:INFO:Initializing get_config()
2025-12-03 11:19:23,588:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FA2378B80>, variable=y_test)
2025-12-03 11:19:23,588:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-12-03 11:19:23,588:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-12-03 11:19:23,594:INFO:Variable:  returned as 28456    0.0
8993     0.0
34312    0.0
4802     0.0
25895    0.0
        ... 
18045    0.0
5425     0.0
12819    0.0
33659    0.0
19531    0.0
Name: HeartDisease, Length: 13109, dtype: float32
2025-12-03 11:19:23,594:INFO:get_config() successfully completed......................................
2025-12-03 11:19:23,839:INFO:Initializing get_config()
2025-12-03 11:19:23,839:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FA2378B80>, variable=y_test)
2025-12-03 11:19:23,840:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-12-03 11:19:23,840:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-12-03 11:19:23,846:INFO:Variable:  returned as 28456    0.0
8993     0.0
34312    0.0
4802     0.0
25895    0.0
        ... 
18045    0.0
5425     0.0
12819    0.0
33659    0.0
19531    0.0
Name: HeartDisease, Length: 13109, dtype: float32
2025-12-03 11:19:23,846:INFO:get_config() successfully completed......................................
2025-12-03 11:19:23,846:INFO:Initializing get_config()
2025-12-03 11:19:23,846:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FA2378B80>, variable=X_test_transformed)
2025-12-03 11:19:23,932:INFO:Variable: X_test returned as             Age  IncomeRatio  SystolicBP       BMI  WaistCircumference  \
28456 -0.477273    -0.304717   -0.519256 -0.987220           -0.923253   
8993   0.818182     0.253271    2.156910  0.770675            0.920394   
34312  0.704545     0.055403    0.519256  0.518044            0.662901   
4802  -0.545455     0.253730   -0.331933 -0.229036           -0.436352   
25895  0.704545     1.226781   -0.093200 -0.226100            0.012322   
...         ...          ...         ...       ...                 ...   
18045 -0.568182    -0.083104   -0.568713 -1.176693           -1.338674   
5425   0.590909     0.362732    2.210168  0.139096            0.292112   
12819  0.909091    -0.019787    0.899042  0.454886            0.971892   
33659 -0.522727     1.060572   -0.525683 -0.587220           -0.906087   
19531 -0.590909    -0.344290   -0.510287 -0.945114           -1.215078   

         Height  TotalCholesterol  Triglycerides       LDL       HDL  ...  \
28456 -1.080540         -0.078535      -0.470757 -0.026922  0.418008  ...   
8993  -0.279669          0.765897       0.705031  0.006026  0.446825  ...   
34312  0.559339         -0.123259       0.929511 -1.031826 -1.404309  ...   
4802  -0.504861         -0.188325      -0.322647  0.000015 -0.138743  ...   
25895  0.216731          0.892919       1.291109  0.008211 -0.255329  ...   
...         ...               ...            ...       ...       ...  ...   
18045 -2.080569         -0.340947      -0.470582 -0.848950  0.393794  ...   
5425   0.156785          0.435639      -0.065356  1.113733  0.127664  ...   
12819  1.194951         -0.732967      -0.470025 -0.211535 -1.085148  ...   
33659 -1.254274         -1.063225      -0.470958 -2.849419  0.127664  ...   
19531 -2.339052         -0.356898      -0.470595 -0.900608  0.393896  ...   

       Race_5.0  Race_1.0  Race_4.0  Race_3.0  Race_2.0  Education   Smoking  \
28456       1.0       0.0       0.0       0.0       0.0  -0.012820  0.000000   
8993        0.0       0.0       1.0       0.0       0.0   0.547458  1.000000   
34312       0.0       0.0       0.0       1.0       0.0  -0.659696  0.000000   
4802        1.0       0.0       0.0       0.0       0.0   0.262895  0.073612   
25895       0.0       0.0       0.0       1.0       0.0   1.151035  0.000000   
...         ...       ...       ...       ...       ...        ...       ...   
18045       0.0       0.0       0.0       1.0       0.0  -0.793202  0.000000   
5425        0.0       0.0       1.0       0.0       0.0   0.547458  1.000000   
12819       0.0       0.0       0.0       1.0       0.0   1.151035  1.000000   
33659       0.0       0.0       1.0       0.0       0.0   0.258362  0.000000   
19531       1.0       0.0       0.0       0.0       0.0  -0.821118  0.000000   

       PhysicalActivity  HealthInsurance   Alcohol  
28456          0.660578              0.0 -0.518600  
8993           0.000000              0.0  0.115329  
34312          0.000000              0.0  0.592213  
4802           1.012447              0.0 -0.103347  
25895          0.000000              0.0 -0.886483  
...                 ...              ...       ...  
18045          0.904383              0.0 -0.482716  
5425           1.598141              0.0  0.097790  
12819          1.598141              0.0  0.612947  
33659          1.162475              0.0 -0.154408  
19531          0.791302              0.0 -0.683278  

[13109 rows x 31 columns]
2025-12-03 11:19:23,932:INFO:get_config() successfully completed......................................
2025-12-03 11:19:24,030:INFO:Initializing get_config()
2025-12-03 11:19:24,030:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FA2378B80>, variable=X_train_transformed)
2025-12-03 11:19:24,068:INFO:Variable: X_train returned as             Age  IncomeRatio  SystolicBP       BMI  WaistCircumference  \
15208  0.954545     0.854789    0.359485  0.518044            0.206281   
25325 -0.272727     0.253271   -0.812170 -0.966167           -0.799656   
5132   0.181818    -0.407608   -0.372799  0.054886            0.319578   
17217  0.500000    -0.751898    0.013314 -0.260904            0.278379   
6382   0.568182     0.054503    1.131712  2.675938            1.888566   
...         ...          ...         ...       ...                 ...   
6265  -0.545455    -0.431352   -0.591719  0.191728           -0.377368   
42694 -0.022727    -0.221612   -0.892056 -0.260904           -0.047778   
13399  0.454545     0.388518    0.377985  0.271482            0.183567   
39959  0.954545    -0.193911    0.625770  0.991728            1.160720   
6616   0.613636    -0.447182    0.652399 -0.871430           -0.514698   

         Height  TotalCholesterol  Triglycerides       LDL       HDL  ...  \
15208 -0.487303          0.625876       0.583394  0.005397  0.314564  ...   
25325 -0.300856          0.033588      -0.261476  0.000256  0.303682  ...   
5132   0.766972          0.181594       0.479279  0.948690 -1.340476  ...   
17217  0.745785          0.227516       0.346113  0.002441 -0.274561  ...   
6382   0.237295          0.867515       0.635574  0.002754  0.829819  ...   
...         ...               ...            ...       ...       ...  ...   
6265  -1.737339         -1.393483      -0.471046 -3.840886  0.063832  ...   
42694  0.000000          0.029167      -0.131730  0.000893  0.063832  ...   
13399 -0.147405          0.462357       0.380371  0.003925  0.256949  ...   
39959  0.368655          1.528031       1.934134  0.011744  0.191497  ...   
6616  -0.021187         -0.224877      -0.043571 -1.609476  0.510658  ...   

       Race_5.0  Race_1.0  Race_4.0  Race_3.0  Race_2.0  Education  Smoking  \
15208       1.0       0.0       0.0       0.0       0.0  -0.659696      0.0   
25325       0.0       1.0       0.0       0.0       0.0   0.185278      0.0   
5132        0.0       1.0       0.0       0.0       0.0  -0.659696      1.0   
17217       0.0       0.0       1.0       0.0       0.0  -0.056119      1.0   
6382        0.0       0.0       1.0       0.0       0.0   0.547458      1.0   
...         ...       ...       ...       ...       ...        ...      ...   
6265        0.0       1.0       0.0       0.0       0.0  -0.769055      0.0   
42694       0.0       1.0       0.0       0.0       0.0   0.547458      0.0   
13399       0.0       0.0       1.0       0.0       0.0   0.547458      0.0   
39959       0.0       0.0       0.0       1.0       0.0   0.547458      0.0   
6616        0.0       0.0       0.0       1.0       0.0   0.547458      1.0   

       PhysicalActivity  HealthInsurance   Alcohol  
15208          0.000000              0.0 -0.886483  
25325          0.000000              0.0  0.592213  
5132           0.000000             -1.0  0.312949  
17217          0.000000              0.0  0.592213  
6382           0.000000              0.0  0.597293  
...                 ...              ...       ...  
6265           0.662459              0.0 -0.501621  
42694          0.000000             -1.0  0.592213  
13399          0.000000              0.0 -0.224534  
39959          0.000000              0.0  0.592213  
6616           0.000000              0.0  0.290247  

[30586 rows x 31 columns]
2025-12-03 11:19:24,068:INFO:get_config() successfully completed......................................
2025-12-03 11:19:24,084:INFO:Initializing tune_model()
2025-12-03 11:19:24,084:INFO:tune_model(estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...), fold=None, round=4, n_iter=5, custom_grid=None, optimize=Recall, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=False, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FA2378B80>)
2025-12-03 11:19:24,084:INFO:Checking exceptions
2025-12-03 11:19:24,094:INFO:Copying training dataset
2025-12-03 11:19:24,110:INFO:Checking base model
2025-12-03 11:19:24,111:INFO:Base model : Extreme Gradient Boosting
2025-12-03 11:19:24,111:INFO:Declaring metric variables
2025-12-03 11:19:24,111:INFO:Defining Hyperparameters
2025-12-03 11:19:24,288:INFO:Tuning with n_jobs=1
2025-12-03 11:19:24,288:INFO:Initializing RandomizedSearchCV
2025-12-03 11:19:58,028:INFO:best_params: {'actual_estimator__subsample': 0.7, 'actual_estimator__scale_pos_weight': 38.0, 'actual_estimator__reg_lambda': 0.7, 'actual_estimator__reg_alpha': 0.001, 'actual_estimator__n_estimators': 60, 'actual_estimator__min_child_weight': 1, 'actual_estimator__max_depth': 6, 'actual_estimator__learning_rate': 0.4, 'actual_estimator__colsample_bytree': 0.7}
2025-12-03 11:19:58,028:INFO:Hyperparameter search completed
2025-12-03 11:19:58,028:INFO:SubProcess create_model() called ==================================
2025-12-03 11:19:58,029:INFO:Initializing create_model()
2025-12-03 11:19:58,029:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FA2378B80>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000018FB022B250>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'subsample': 0.7, 'scale_pos_weight': 38.0, 'reg_lambda': 0.7, 'reg_alpha': 0.001, 'n_estimators': 60, 'min_child_weight': 1, 'max_depth': 6, 'learning_rate': 0.4, 'colsample_bytree': 0.7})
2025-12-03 11:19:58,029:INFO:Checking exceptions
2025-12-03 11:19:58,029:INFO:Importing libraries
2025-12-03 11:19:58,029:INFO:Copying training dataset
2025-12-03 11:19:58,049:INFO:Defining folds
2025-12-03 11:19:58,049:INFO:Declaring metric variables
2025-12-03 11:19:58,049:INFO:Importing untrained model
2025-12-03 11:19:58,049:INFO:Declaring custom model
2025-12-03 11:19:58,050:INFO:Extreme Gradient Boosting Imported successfully
2025-12-03 11:19:58,050:INFO:Starting cross validation
2025-12-03 11:19:58,050:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-12-03 11:20:02,702:INFO:Calculating mean and std
2025-12-03 11:20:02,702:INFO:Creating metrics dataframe
2025-12-03 11:20:02,702:INFO:Finalizing model
2025-12-03 11:20:02,771:INFO:Warning: No categorical columns found. Calling 'transform' will only return input data.
2025-12-03 11:20:03,154:INFO:Uploading results into container
2025-12-03 11:20:03,154:INFO:Uploading model into container now
2025-12-03 11:20:03,155:INFO:_master_model_container: 4
2025-12-03 11:20:03,155:INFO:_display_container: 5
2025-12-03 11:20:03,155:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=0.7, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=0.4, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=6, max_leaves=None,
              min_child_weight=1, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=60, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2025-12-03 11:20:03,155:INFO:create_model() successfully completed......................................
2025-12-03 11:20:03,338:INFO:SubProcess create_model() end ==================================
2025-12-03 11:20:03,338:INFO:choose_better activated
2025-12-03 11:20:03,338:INFO:SubProcess create_model() called ==================================
2025-12-03 11:20:03,338:INFO:Initializing create_model()
2025-12-03 11:20:03,338:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FA2378B80>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-03 11:20:03,338:INFO:Checking exceptions
2025-12-03 11:20:03,341:INFO:Importing libraries
2025-12-03 11:20:03,341:INFO:Copying training dataset
2025-12-03 11:20:03,361:INFO:Defining folds
2025-12-03 11:20:03,361:INFO:Declaring metric variables
2025-12-03 11:20:03,361:INFO:Importing untrained model
2025-12-03 11:20:03,361:INFO:Declaring custom model
2025-12-03 11:20:03,361:INFO:Extreme Gradient Boosting Imported successfully
2025-12-03 11:20:03,361:INFO:Starting cross validation
2025-12-03 11:20:03,364:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-12-03 11:20:09,302:INFO:Calculating mean and std
2025-12-03 11:20:09,302:INFO:Creating metrics dataframe
2025-12-03 11:20:09,302:INFO:Finalizing model
2025-12-03 11:20:09,369:INFO:Warning: No categorical columns found. Calling 'transform' will only return input data.
2025-12-03 11:20:09,880:INFO:Uploading results into container
2025-12-03 11:20:09,880:INFO:Uploading model into container now
2025-12-03 11:20:09,880:INFO:_master_model_container: 5
2025-12-03 11:20:09,880:INFO:_display_container: 6
2025-12-03 11:20:09,881:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2025-12-03 11:20:09,881:INFO:create_model() successfully completed......................................
2025-12-03 11:20:10,060:INFO:SubProcess create_model() end ==================================
2025-12-03 11:20:10,060:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...) result for Recall is 0.3112
2025-12-03 11:20:10,067:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=0.7, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=0.4, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=6, max_leaves=None,
              min_child_weight=1, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=60, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...) result for Recall is 0.3316
2025-12-03 11:20:10,067:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=0.7, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=0.4, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=6, max_leaves=None,
              min_child_weight=1, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=60, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...) is best model
2025-12-03 11:20:10,067:INFO:choose_better completed
2025-12-03 11:20:10,068:INFO:_master_model_container: 5
2025-12-03 11:20:10,068:INFO:_display_container: 5
2025-12-03 11:20:10,068:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=0.7, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=0.4, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=6, max_leaves=None,
              min_child_weight=1, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=60, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2025-12-03 11:20:10,068:INFO:tune_model() successfully completed......................................
2025-12-03 11:20:10,244:INFO:Initializing predict_model()
2025-12-03 11:20:10,249:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FA2378B80>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=0.7, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=0.4, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=6, max_leaves=None,
              min_child_weight=1, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=60, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...), probability_threshold=None, encoded_labels=False, raw_score=True, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000018FB01A8DC0>)
2025-12-03 11:20:10,249:INFO:Checking exceptions
2025-12-03 11:20:10,249:INFO:Preloading libraries
2025-12-03 11:20:10,649:INFO:Initializing get_config()
2025-12-03 11:20:10,649:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FA2378B80>, variable=target_param)
2025-12-03 11:20:10,649:INFO:Variable:  returned as HeartDisease
2025-12-03 11:20:10,649:INFO:get_config() successfully completed......................................
2025-12-03 11:20:11,310:INFO:Initializing interpret_model()
2025-12-03 11:20:11,310:INFO:interpret_model(estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=0.7, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=0.4, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=6, max_leaves=None,
              min_child_weight=1, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=60, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...), use_train_data=False, X_new_sample=None, y_new_sample=None, feature=None, kwargs={}, observation=None, plot=summary, save=False, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FA2378B80>)
2025-12-03 11:20:11,310:INFO:Checking exceptions
2025-12-03 11:20:11,310:INFO:Soft dependency imported: shap: 0.49.1
2025-12-03 11:20:11,397:INFO:plot type: summary
2025-12-03 11:20:11,397:INFO:Creating TreeExplainer
2025-12-03 11:20:11,409:INFO:Compiling shap values
2025-12-03 11:20:14,696:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:4145: FutureWarning: The NumPy global RNG was seeded by calling `np.random.seed`. In a future version this function will no longer use the global RNG. Pass `rng` explicitly to opt-in to the new behaviour and silence this warning.

2025-12-03 11:20:15,834:INFO:Visual Rendered Successfully
2025-12-03 11:20:15,834:INFO:interpret_model() successfully completed......................................
2025-12-03 11:20:16,036:INFO:Initializing predict_model()
2025-12-03 11:20:16,036:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FA2378B80>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...), probability_threshold=None, encoded_labels=False, raw_score=True, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000018FA22FF910>)
2025-12-03 11:20:16,036:INFO:Checking exceptions
2025-12-03 11:20:16,036:INFO:Preloading libraries
2025-12-03 11:20:16,459:INFO:Initializing get_config()
2025-12-03 11:20:16,459:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FA2378B80>, variable=target_param)
2025-12-03 11:20:16,459:INFO:Variable:  returned as HeartDisease
2025-12-03 11:20:16,459:INFO:get_config() successfully completed......................................
2025-12-03 11:20:16,567:INFO:Initializing finalize_model()
2025-12-03 11:20:16,567:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FA2378B80>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=0.7, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=0.4, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=6, max_leaves=None,
              min_child_weight=1, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=60, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2025-12-03 11:20:16,567:INFO:Finalizing XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=0.7, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=0.4, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=6, max_leaves=None,
              min_child_weight=1, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=60, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2025-12-03 11:20:16,583:INFO:Initializing create_model()
2025-12-03 11:20:16,583:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018FA2378B80>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=0.7, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=0.4, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=6, max_leaves=None,
              min_child_weight=1, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=60, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2025-12-03 11:20:16,583:INFO:Checking exceptions
2025-12-03 11:20:16,585:INFO:Importing libraries
2025-12-03 11:20:16,585:INFO:Copying training dataset
2025-12-03 11:20:16,588:INFO:Defining folds
2025-12-03 11:20:16,588:INFO:Declaring metric variables
2025-12-03 11:20:16,588:INFO:Importing untrained model
2025-12-03 11:20:16,588:INFO:Declaring custom model
2025-12-03 11:20:16,588:INFO:Extreme Gradient Boosting Imported successfully
2025-12-03 11:20:16,589:INFO:Cross validation set to False
2025-12-03 11:20:16,589:INFO:Fitting Model
2025-12-03 11:20:16,678:INFO:Warning: No categorical columns found. Calling 'transform' will only return input data.
2025-12-03 11:20:17,197:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'IncomeRatio', 'SystolicBP',
                                             'BMI', 'WaistCircumference',
                                             'Height', 'TotalCholesterol',
                                             'Triglycerides', 'LDL', 'HDL',
                                             'HbA1c', 'Glucose', 'Creatinine',
                                             'UricAcid', 'ALT_Enzyme',
                                             'Albumin', 'Potassium', 'Sodium',
                                             'GGT_Enzyme', 'AST_Enzyme'],
                                    transformer=Si...
                               feature_types=None, gamma=None, grow_policy=None,
                               importance_type=None,
                               interaction_constraints=None, learning_rate=0.4,
                               max_bin=None, max_cat_threshold=None,
                               max_cat_to_onehot=None, max_delta_step=None,
                               max_depth=6, max_leaves=None, min_child_weight=1,
                               missing=nan, monotone_constraints=None,
                               multi_strategy=None, n_estimators=60, n_jobs=1,
                               num_parallel_tree=None,
                               objective='binary:logistic', ...))],
         verbose=False)
2025-12-03 11:20:17,197:INFO:create_model() successfully completed......................................
2025-12-03 11:20:17,376:INFO:_master_model_container: 5
2025-12-03 11:20:17,376:INFO:_display_container: 7
2025-12-03 11:20:17,391:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'IncomeRatio', 'SystolicBP',
                                             'BMI', 'WaistCircumference',
                                             'Height', 'TotalCholesterol',
                                             'Triglycerides', 'LDL', 'HDL',
                                             'HbA1c', 'Glucose', 'Creatinine',
                                             'UricAcid', 'ALT_Enzyme',
                                             'Albumin', 'Potassium', 'Sodium',
                                             'GGT_Enzyme', 'AST_Enzyme'],
                                    transformer=Si...
                               feature_types=None, gamma=None, grow_policy=None,
                               importance_type=None,
                               interaction_constraints=None, learning_rate=0.4,
                               max_bin=None, max_cat_threshold=None,
                               max_cat_to_onehot=None, max_delta_step=None,
                               max_depth=6, max_leaves=None, min_child_weight=1,
                               missing=nan, monotone_constraints=None,
                               multi_strategy=None, n_estimators=60, n_jobs=1,
                               num_parallel_tree=None,
                               objective='binary:logistic', ...))],
         verbose=False)
2025-12-03 11:20:17,391:INFO:finalize_model() successfully completed......................................
2025-12-03 11:20:17,581:INFO:Initializing save_model()
2025-12-03 11:20:17,581:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'IncomeRatio', 'SystolicBP',
                                             'BMI', 'WaistCircumference',
                                             'Height', 'TotalCholesterol',
                                             'Triglycerides', 'LDL', 'HDL',
                                             'HbA1c', 'Glucose', 'Creatinine',
                                             'UricAcid', 'ALT_Enzyme',
                                             'Albumin', 'Potassium', 'Sodium',
                                             'GGT_Enzyme', 'AST_Enzyme'],
                                    transformer=Si...
                               feature_types=None, gamma=None, grow_policy=None,
                               importance_type=None,
                               interaction_constraints=None, learning_rate=0.4,
                               max_bin=None, max_cat_threshold=None,
                               max_cat_to_onehot=None, max_delta_step=None,
                               max_depth=6, max_leaves=None, min_child_weight=1,
                               missing=nan, monotone_constraints=None,
                               multi_strategy=None, n_estimators=60, n_jobs=1,
                               num_parallel_tree=None,
                               objective='binary:logistic', ...))],
         verbose=False), model_name=../models\best_pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\OMAR\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'IncomeRatio', 'SystolicBP',
                                             'BMI', 'WaistCircumference',
                                             'Height', 'TotalCholesterol',
                                             'Triglycerides', 'LDL', 'HDL',
                                             'HbA1c', 'Glucose', 'Creatinine',
                                             'UricAcid', 'ALT_Enzyme',
                                             'Albumin', 'Potassium', 'Sodium',
                                             'G...
                                    transformer=TargetEncoder(cols=[],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=RobustScaler(copy=True,
                                                             quantile_range=(25.0,
                                                                             75.0),
                                                             unit_variance=False,
                                                             with_centering=True,
                                                             with_scaling=True)))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2025-12-03 11:20:17,581:INFO:Adding model into prep_pipe
2025-12-03 11:20:17,581:WARNING:Only Model saved as it was a pipeline.
2025-12-03 11:20:17,588:INFO:../models\best_pipeline.pkl saved in current working directory
2025-12-03 11:20:17,605:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'IncomeRatio', 'SystolicBP',
                                             'BMI', 'WaistCircumference',
                                             'Height', 'TotalCholesterol',
                                             'Triglycerides', 'LDL', 'HDL',
                                             'HbA1c', 'Glucose', 'Creatinine',
                                             'UricAcid', 'ALT_Enzyme',
                                             'Albumin', 'Potassium', 'Sodium',
                                             'GGT_Enzyme', 'AST_Enzyme'],
                                    transformer=Si...
                               feature_types=None, gamma=None, grow_policy=None,
                               importance_type=None,
                               interaction_constraints=None, learning_rate=0.4,
                               max_bin=None, max_cat_threshold=None,
                               max_cat_to_onehot=None, max_delta_step=None,
                               max_depth=6, max_leaves=None, min_child_weight=1,
                               missing=nan, monotone_constraints=None,
                               multi_strategy=None, n_estimators=60, n_jobs=1,
                               num_parallel_tree=None,
                               objective='binary:logistic', ...))],
         verbose=False)
2025-12-03 11:20:17,605:INFO:save_model() successfully completed......................................
2025-12-03 11:35:01,334:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-12-03 11:35:01,334:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-12-03 11:35:01,334:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-12-03 11:35:01,334:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-12-03 11:35:03,183:INFO:PyCaret ClassificationExperiment
2025-12-03 11:35:03,183:INFO:Logging name: clf-default-name
2025-12-03 11:35:03,183:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-12-03 11:35:03,183:INFO:version 3.3.2
2025-12-03 11:35:03,183:INFO:Initializing setup()
2025-12-03 11:35:03,183:INFO:self.USI: e6d3
2025-12-03 11:35:03,183:INFO:self._variable_keys: {'memory', 'y', 'seed', 'logging_param', '_ml_usecase', 'y_test', 'n_jobs_param', 'is_multiclass', 'fix_imbalance', 'html_param', 'exp_id', 'target_param', 'gpu_n_jobs_param', 'X', 'exp_name_log', 'fold_shuffle_param', 'USI', 'data', 'idx', 'X_train', 'X_test', 'fold_groups_param', 'y_train', 'gpu_param', 'fold_generator', '_available_plots', 'log_plots_param', 'pipeline'}
2025-12-03 11:35:03,183:INFO:Checking environment
2025-12-03 11:35:03,183:INFO:python_version: 3.10.19
2025-12-03 11:35:03,183:INFO:python_build: ('main', 'Oct 21 2025 16:41:31')
2025-12-03 11:35:03,183:INFO:machine: AMD64
2025-12-03 11:35:03,183:INFO:platform: Windows-10-10.0.26100-SP0
2025-12-03 11:35:03,183:INFO:Memory: svmem(total=16282144768, available=4902322176, percent=69.9, used=11379822592, free=4902322176)
2025-12-03 11:35:03,183:INFO:Physical Core: 6
2025-12-03 11:35:03,183:INFO:Logical Core: 12
2025-12-03 11:35:03,183:INFO:Checking libraries
2025-12-03 11:35:03,183:INFO:System:
2025-12-03 11:35:03,183:INFO:    python: 3.10.19 | packaged by Anaconda, Inc. | (main, Oct 21 2025, 16:41:31) [MSC v.1929 64 bit (AMD64)]
2025-12-03 11:35:03,183:INFO:executable: c:\Users\OMAR\miniconda3\envs\xgb_env\python.exe
2025-12-03 11:35:03,183:INFO:   machine: Windows-10-10.0.26100-SP0
2025-12-03 11:35:03,183:INFO:PyCaret required dependencies:
2025-12-03 11:35:03,185:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-03 11:35:03,763:INFO:                 pip: 25.3
2025-12-03 11:35:03,763:INFO:          setuptools: 80.9.0
2025-12-03 11:35:03,763:INFO:             pycaret: 3.3.2
2025-12-03 11:35:03,763:INFO:             IPython: 8.37.0
2025-12-03 11:35:03,763:INFO:          ipywidgets: 8.1.8
2025-12-03 11:35:03,763:INFO:                tqdm: 4.67.1
2025-12-03 11:35:03,763:INFO:               numpy: 1.26.4
2025-12-03 11:35:03,763:INFO:              pandas: 2.1.4
2025-12-03 11:35:03,763:INFO:              jinja2: 3.1.6
2025-12-03 11:35:03,763:INFO:               scipy: 1.11.4
2025-12-03 11:35:03,763:INFO:              joblib: 1.3.2
2025-12-03 11:35:03,763:INFO:             sklearn: 1.4.2
2025-12-03 11:35:03,763:INFO:                pyod: 2.0.5
2025-12-03 11:35:03,763:INFO:            imblearn: 0.14.0
2025-12-03 11:35:03,763:INFO:   category_encoders: 2.7.0
2025-12-03 11:35:03,763:INFO:            lightgbm: 4.6.0
2025-12-03 11:35:03,763:INFO:               numba: 0.62.1
2025-12-03 11:35:03,763:INFO:            requests: 2.32.5
2025-12-03 11:35:03,763:INFO:          matplotlib: 3.7.5
2025-12-03 11:35:03,763:INFO:          scikitplot: 0.3.7
2025-12-03 11:35:03,763:INFO:         yellowbrick: 1.5
2025-12-03 11:35:03,763:INFO:              plotly: 5.24.1
2025-12-03 11:35:03,763:INFO:    plotly-resampler: Not installed
2025-12-03 11:35:03,763:INFO:             kaleido: 1.2.0
2025-12-03 11:35:03,763:INFO:           schemdraw: 0.15
2025-12-03 11:35:03,763:INFO:         statsmodels: 0.14.5
2025-12-03 11:35:03,763:INFO:              sktime: 0.26.0
2025-12-03 11:35:03,763:INFO:               tbats: 1.1.3
2025-12-03 11:35:03,763:INFO:            pmdarima: 2.0.4
2025-12-03 11:35:03,763:INFO:              psutil: 7.1.3
2025-12-03 11:35:03,763:INFO:          markupsafe: 3.0.3
2025-12-03 11:35:03,763:INFO:             pickle5: Not installed
2025-12-03 11:35:03,763:INFO:         cloudpickle: 3.1.2
2025-12-03 11:35:03,763:INFO:         deprecation: 2.1.0
2025-12-03 11:35:03,763:INFO:              xxhash: 3.6.0
2025-12-03 11:35:03,763:INFO:           wurlitzer: Not installed
2025-12-03 11:35:03,763:INFO:PyCaret optional dependencies:
2025-12-03 11:35:06,454:INFO:                shap: 0.49.1
2025-12-03 11:35:06,454:INFO:           interpret: 0.7.3
2025-12-03 11:35:06,454:INFO:                umap: 0.5.7
2025-12-03 11:35:06,454:INFO:     ydata_profiling: 4.18.0
2025-12-03 11:35:06,454:INFO:  explainerdashboard: 0.5.1
2025-12-03 11:35:06,454:INFO:             autoviz: Not installed
2025-12-03 11:35:06,454:INFO:           fairlearn: 0.7.0
2025-12-03 11:35:06,454:INFO:          deepchecks: Not installed
2025-12-03 11:35:06,454:INFO:             xgboost: 2.1.3
2025-12-03 11:35:06,454:INFO:            catboost: 1.2.8
2025-12-03 11:35:06,454:INFO:              kmodes: 0.12.2
2025-12-03 11:35:06,454:INFO:             mlxtend: 0.23.4
2025-12-03 11:35:06,454:INFO:       statsforecast: 1.5.0
2025-12-03 11:35:06,454:INFO:        tune_sklearn: Not installed
2025-12-03 11:35:06,454:INFO:                 ray: Not installed
2025-12-03 11:35:06,454:INFO:            hyperopt: 0.2.7
2025-12-03 11:35:06,454:INFO:              optuna: 4.6.0
2025-12-03 11:35:06,454:INFO:               skopt: 0.10.2
2025-12-03 11:35:06,454:INFO:              mlflow: 3.6.0
2025-12-03 11:35:06,454:INFO:              gradio: 6.0.1
2025-12-03 11:35:06,454:INFO:             fastapi: 0.123.0
2025-12-03 11:35:06,454:INFO:             uvicorn: 0.38.0
2025-12-03 11:35:06,454:INFO:              m2cgen: 0.10.0
2025-12-03 11:35:06,454:INFO:           evidently: 0.4.40
2025-12-03 11:35:06,454:INFO:               fugue: 0.8.7
2025-12-03 11:35:06,454:INFO:           streamlit: 1.51.0
2025-12-03 11:35:06,454:INFO:             prophet: Not installed
2025-12-03 11:35:06,454:INFO:None
2025-12-03 11:35:06,454:INFO:Set up data.
2025-12-03 11:35:06,473:INFO:Set up folding strategy.
2025-12-03 11:35:06,473:INFO:Set up train/test split.
2025-12-03 11:35:06,494:INFO:Set up index.
2025-12-03 11:35:06,499:INFO:Assigning column types.
2025-12-03 11:35:06,519:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-12-03 11:35:06,544:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-12-03 11:35:06,544:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-03 11:35:06,566:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-03 11:35:06,568:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-03 11:35:06,608:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-12-03 11:35:06,614:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-03 11:35:06,630:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-03 11:35:06,631:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-03 11:35:06,631:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-12-03 11:35:06,656:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-03 11:35:06,671:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-03 11:35:06,673:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-03 11:35:06,699:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-03 11:35:06,709:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-03 11:35:06,715:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-03 11:35:06,716:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-12-03 11:35:06,756:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-03 11:35:06,756:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-03 11:35:06,798:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-03 11:35:06,799:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-03 11:35:06,800:INFO:Preparing preprocessing pipeline...
2025-12-03 11:35:06,805:INFO:Set up simple imputation.
2025-12-03 11:35:06,816:INFO:Set up encoding of ordinal features.
2025-12-03 11:35:06,823:INFO:Set up encoding of categorical features.
2025-12-03 11:35:06,823:INFO:Set up imbalanced handling.
2025-12-03 11:35:06,823:INFO:Set up feature normalization.
2025-12-03 11:35:06,984:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\joblib\externals\loky\backend\context.py:136: UserWarning: Could not find the number of physical cores for the following reason:
[WinError 2] El sistema no puede encontrar el archivo especificado
Returning the number of logical cores instead. You can silence this warning by setting LOKY_MAX_CPU_COUNT to the number of cores you want to use.

2025-12-03 11:35:07,138:INFO:Finished creating preprocessing pipeline.
2025-12-03 11:35:07,155:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\OMAR\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'IncomeRatio', 'SystolicBP',
                                             'BMI', 'WaistCircumference',
                                             'Height', 'TotalCholesterol',
                                             'Triglycerides', 'LDL', 'HDL',
                                             'HbA1c', 'Glucose', 'Creatinine',
                                             'UricAcid', 'ALT_Enzyme',
                                             'Albumin', 'Potassium', 'Sodium',
                                             'G...
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              random_state=42,
                                                                              sampling_strategy='auto')))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=RobustScaler(copy=True,
                                                             quantile_range=(25.0,
                                                                             75.0),
                                                             unit_variance=False,
                                                             with_centering=True,
                                                             with_scaling=True)))],
         verbose=False)
2025-12-03 11:35:07,156:INFO:Creating final display dataframe.
2025-12-03 11:35:07,631:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target      HeartDisease
2                   Target type            Binary
3           Original data shape       (43695, 28)
4        Transformed data shape       (72719, 32)
5   Transformed train set shape       (59610, 32)
6    Transformed test set shape       (13109, 32)
7              Numeric features                20
8          Categorical features                 7
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15                Fix imbalance              True
16         Fix imbalance method             SMOTE
17                    Normalize              True
18             Normalize method            robust
19               Fold Generator   StratifiedKFold
20                  Fold Number                10
21                     CPU Jobs                 1
22                      Use GPU             False
23               Log Experiment             False
24              Experiment Name  clf-default-name
25                          USI              e6d3
2025-12-03 11:35:07,679:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-03 11:35:07,682:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-03 11:35:07,724:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-03 11:35:07,726:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-03 11:35:07,726:INFO:setup() successfully completed in 4.55s...............
2025-12-03 11:35:07,936:INFO:Initializing get_config()
2025-12-03 11:35:07,936:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E64581EE90>, variable=y_train)
2025-12-03 11:35:07,936:INFO:Variable: 'y_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_train_transformed' instead.
2025-12-03 11:35:07,936:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_train_transformed' instead.

2025-12-03 11:35:07,950:INFO:Variable:  returned as 15208    0.0
25325    0.0
5132     0.0
17217    0.0
6382     0.0
        ... 
6265     0.0
42694    0.0
13399    0.0
39959    0.0
6616     0.0
Name: HeartDisease, Length: 30586, dtype: float32
2025-12-03 11:35:07,950:INFO:get_config() successfully completed......................................
2025-12-03 11:35:07,951:INFO:Initializing create_model()
2025-12-03 11:35:07,951:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E64581EE90>, estimator=xgboost, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={'scale_pos_weight': 76.32522407170295})
2025-12-03 11:35:07,951:INFO:Checking exceptions
2025-12-03 11:35:07,967:INFO:Importing libraries
2025-12-03 11:35:07,968:INFO:Copying training dataset
2025-12-03 11:35:08,002:INFO:Defining folds
2025-12-03 11:35:08,002:INFO:Declaring metric variables
2025-12-03 11:35:08,005:INFO:Importing untrained model
2025-12-03 11:35:08,008:INFO:Extreme Gradient Boosting Imported successfully
2025-12-03 11:35:08,015:INFO:Starting cross validation
2025-12-03 11:35:08,017:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-12-03 11:35:19,841:INFO:Calculating mean and std
2025-12-03 11:35:19,842:INFO:Creating metrics dataframe
2025-12-03 11:35:19,847:INFO:Finalizing model
2025-12-03 11:35:19,920:INFO:Warning: No categorical columns found. Calling 'transform' will only return input data.
2025-12-03 11:35:21,026:INFO:Uploading results into container
2025-12-03 11:35:21,026:INFO:Uploading model into container now
2025-12-03 11:35:21,034:INFO:_master_model_container: 1
2025-12-03 11:35:21,034:INFO:_display_container: 2
2025-12-03 11:35:21,036:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2025-12-03 11:35:21,036:INFO:create_model() successfully completed......................................
2025-12-03 11:35:21,240:INFO:Initializing create_model()
2025-12-03 11:35:21,241:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E64581EE90>, estimator=lr, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-03 11:35:21,241:INFO:Checking exceptions
2025-12-03 11:35:21,251:INFO:Importing libraries
2025-12-03 11:35:21,251:INFO:Copying training dataset
2025-12-03 11:35:21,284:INFO:Defining folds
2025-12-03 11:35:21,285:INFO:Declaring metric variables
2025-12-03 11:35:21,288:INFO:Importing untrained model
2025-12-03 11:35:21,293:INFO:Logistic Regression Imported successfully
2025-12-03 11:35:21,303:INFO:Starting cross validation
2025-12-03 11:35:21,305:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-12-03 11:35:24,588:INFO:Calculating mean and std
2025-12-03 11:35:24,588:INFO:Creating metrics dataframe
2025-12-03 11:35:24,594:INFO:Finalizing model
2025-12-03 11:35:24,669:INFO:Warning: No categorical columns found. Calling 'transform' will only return input data.
2025-12-03 11:35:24,933:INFO:Uploading results into container
2025-12-03 11:35:24,934:INFO:Uploading model into container now
2025-12-03 11:35:24,944:INFO:_master_model_container: 2
2025-12-03 11:35:24,944:INFO:_display_container: 3
2025-12-03 11:35:24,944:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-12-03 11:35:24,944:INFO:create_model() successfully completed......................................
2025-12-03 11:35:25,099:INFO:Initializing create_model()
2025-12-03 11:35:25,099:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E64581EE90>, estimator=rf, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-03 11:35:25,099:INFO:Checking exceptions
2025-12-03 11:35:25,109:INFO:Importing libraries
2025-12-03 11:35:25,109:INFO:Copying training dataset
2025-12-03 11:35:25,147:INFO:Defining folds
2025-12-03 11:35:25,147:INFO:Declaring metric variables
2025-12-03 11:35:25,150:INFO:Importing untrained model
2025-12-03 11:35:25,155:INFO:Random Forest Classifier Imported successfully
2025-12-03 11:35:25,163:INFO:Starting cross validation
2025-12-03 11:35:25,165:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-12-03 11:37:34,633:INFO:Calculating mean and std
2025-12-03 11:37:34,634:INFO:Creating metrics dataframe
2025-12-03 11:37:34,638:INFO:Finalizing model
2025-12-03 11:37:34,719:INFO:Warning: No categorical columns found. Calling 'transform' will only return input data.
2025-12-03 11:37:48,492:INFO:Uploading results into container
2025-12-03 11:37:48,494:INFO:Uploading model into container now
2025-12-03 11:37:48,505:INFO:_master_model_container: 3
2025-12-03 11:37:48,506:INFO:_display_container: 4
2025-12-03 11:37:48,506:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2025-12-03 11:37:48,506:INFO:create_model() successfully completed......................................
2025-12-03 11:37:48,711:INFO:Initializing get_config()
2025-12-03 11:37:48,711:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E64581EE90>, variable=X_train_transformed)
2025-12-03 11:37:48,768:INFO:Variable: X_train returned as             Age  IncomeRatio  SystolicBP       BMI  WaistCircumference  \
15208  0.281967     1.073479   -0.029334  0.320615           -0.184205   
25325 -0.959685     0.336748   -1.131593 -1.420125           -1.360604   
5132  -0.499814    -0.472688   -0.718246 -0.222594           -0.051710   
17217 -0.177904    -0.894370   -0.355002 -0.592965           -0.099890   
6382  -0.108923     0.093300    0.697155  2.851479            1.783151   
...         ...          ...         ...       ...                 ...   
72714  0.209599    -0.574548    0.093968 -0.084224            0.048339   
72715  0.410044     0.140941    1.545471  0.784710            0.534682   
72716  0.336375     0.706350   -0.225611 -0.316094            0.087200   
72717  0.465916     0.152440   -0.649398  0.648433            0.661659   
72718  0.465916     0.204596    0.822492 -0.260262           -0.112576   

         Height  TotalCholesterol  Triglycerides       LDL       HDL  ...  \
15208 -0.949100          0.573893       0.496366  0.004515  0.470102  ...   
25325 -0.676156          0.027513      -0.418808  0.000788  0.460074  ...   
5132   0.887068          0.164048       0.383587  0.688473 -1.055073  ...   
17217  0.856051          0.206410       0.239340  0.002372 -0.072797  ...   
6382   0.111659          0.796802       0.552888  0.002599  0.944927  ...   
...         ...               ...            ...       ...       ...  ...   
72714  0.529966          0.966537       0.338163  2.847690 -1.107269  ...   
72715 -0.193825          1.002684       1.137561  0.006116  0.578610  ...   
72716  0.850772          0.698204       0.800524  0.005273  0.320829  ...   
72717  0.196053         -0.854465      -0.645063 -1.338104 -0.093582  ...   
72718 -0.754937         -1.171319      -0.645250 -1.650124 -0.583170  ...   

       Race_5.0  Race_1.0  Race_4.0  Race_3.0  Race_2.0  Education   Smoking  \
15208  1.000000       0.0  0.000000 -0.145400   0.00000  -0.656011 -0.319015   
25325  0.000000       1.0  0.000000 -0.145400   0.00000   0.170835 -0.319015   
5132   0.000000       1.0  0.000000 -0.145400   0.00000  -0.656011  0.680985   
17217  0.000000       0.0  3.236622 -0.145400   0.00000  -0.065383  0.680985   
6382   0.000000       0.0  3.236622 -0.145400   0.00000   0.525245  0.680985   
...         ...       ...       ...       ...       ...        ...       ...   
72714  0.000000       0.0  3.236622 -0.145400   0.00000   0.525245  0.672319   
72715  0.000000       0.0  0.000000  0.854600   0.00000  -0.656011  0.680985   
72716  0.402414       0.0  0.000000  0.452186   0.00000   0.409971  0.680985   
72717  0.000000       0.0  0.000000 -0.030279   0.88488   1.115873  0.680985   
72718  0.000000       0.0  0.000000  0.854600   0.00000  -0.067269 -0.315822   

       PhysicalActivity  HealthInsurance   Alcohol  
15208          0.000000              0.0 -1.284779  
25325          0.000000              0.0  0.445085  
5132           0.000000             -1.0  0.118386  
17217          0.000000              0.0  0.445085  
6382           0.000000              0.0  0.451028  
...                 ...              ...       ...  
72714          0.000000              0.0  0.115540  
72715          0.000000              0.0  0.077133  
72716          0.000000              0.0  0.430065  
72717          0.000000              0.0  0.364598  
72718          0.006717              0.0 -0.723887  

[59610 rows x 31 columns]
2025-12-03 11:37:48,768:INFO:get_config() successfully completed......................................
2025-12-03 11:37:48,769:INFO:Initializing get_config()
2025-12-03 11:37:48,769:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E64581EE90>, variable=y_train)
2025-12-03 11:37:48,769:INFO:Variable: 'y_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_train_transformed' instead.
2025-12-03 11:37:48,769:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_train_transformed' instead.

2025-12-03 11:37:48,778:INFO:Variable:  returned as 15208    0.0
25325    0.0
5132     0.0
17217    0.0
6382     0.0
        ... 
6265     0.0
42694    0.0
13399    0.0
39959    0.0
6616     0.0
Name: HeartDisease, Length: 30586, dtype: float32
2025-12-03 11:37:48,778:INFO:get_config() successfully completed......................................
2025-12-03 11:37:48,781:INFO:Initializing get_config()
2025-12-03 11:37:48,781:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E64581EE90>, variable=X_test_transformed)
2025-12-03 11:37:48,850:INFO:Variable: X_test returned as             Age  IncomeRatio  SystolicBP       BMI  WaistCircumference  \
28456 -1.166627    -0.346668   -0.856028 -1.444817           -1.505144   
8993   0.144006     0.336748    1.661631  0.616912            0.650918   
34312  0.029038     0.094402    0.120974  0.320615            0.349792   
4802  -1.235607     0.337310   -0.679800 -0.555589           -0.935736   
25895  0.029038     1.529090   -0.455207 -0.552146           -0.411032   
...         ...          ...         ...       ...                 ...   
18045 -1.258601    -0.075240   -0.902556 -1.667039           -1.990961   
5425  -0.085930     0.470814    1.711734 -0.123829           -0.083830   
12819  0.235980     0.002310    0.478266  0.246541            0.711143   
33659 -1.212614     1.325519   -0.862074 -0.975681           -1.485069   
19531 -1.281594    -0.395137   -0.847590 -1.395434           -1.846420   

         Height  TotalCholesterol  Triglycerides       LDL       HDL  ...  \
28456 -1.817558         -0.075919      -0.645504 -0.018918  0.565429  ...   
8993  -0.645140          0.703061       0.628124  0.004972  0.591985  ...   
34312  0.583108         -0.117177       0.871284 -0.747548 -1.113897  ...   
4802  -0.974805         -0.177199      -0.485069  0.000613  0.052365  ...   
25895  0.081554          0.820238       1.262972  0.006556 -0.055073  ...   
...         ...               ...            ...       ...       ...  ...   
18045 -3.281529         -0.317991      -0.645314 -0.614949  0.543115  ...   
5425  -0.006203          0.398401      -0.206369  0.808141  0.297868  ...   
12819  1.513598         -0.679626      -0.644711 -0.152776 -0.819779  ...   
33659 -2.071891         -0.984285      -0.645722 -2.065437  0.297868  ...   
19531 -3.659929         -0.332706      -0.645328 -0.652405  0.543209  ...   

       Race_5.0  Race_1.0  Race_4.0  Race_3.0  Race_2.0  Education   Smoking  \
28456       1.0       0.0  0.000000   -0.1454       0.0  -0.023013 -0.319015   
8993        0.0       0.0  3.236622   -0.1454       0.0   0.525245  0.680985   
34312       0.0       0.0  0.000000    0.8546       0.0  -0.656011 -0.319015   
4802        1.0       0.0  0.000000   -0.1454       0.0   0.246788 -0.245402   
25895       0.0       0.0  0.000000    0.8546       0.0   1.115873 -0.319015   
...         ...       ...       ...       ...       ...        ...       ...   
18045       0.0       0.0  0.000000    0.8546       0.0  -0.786652 -0.319015   
5425        0.0       0.0  3.236622   -0.1454       0.0   0.525245  0.680985   
12819       0.0       0.0  0.000000    0.8546       0.0   1.115873  0.680985   
33659       0.0       0.0  3.236622   -0.1454       0.0   0.242351 -0.319015   
19531       1.0       0.0  0.000000   -0.1454       0.0  -0.813970 -0.319015   

       PhysicalActivity  HealthInsurance   Alcohol  
28456          0.869504              0.0 -0.854408  
8993           0.000000              0.0 -0.112801  
34312          0.000000              0.0  0.445085  
4802           1.332660              0.0 -0.368621  
25895          0.000000              0.0 -1.284779  
...                 ...              ...       ...  
18045          1.190419              0.0 -0.812429  
5425           2.103596              0.0 -0.133319  
12819          2.103596              0.0  0.469341  
33659          1.530139              0.0 -0.428356  
19531          1.041572              0.0 -1.047058  

[13109 rows x 31 columns]
2025-12-03 11:37:48,850:INFO:get_config() successfully completed......................................
2025-12-03 11:37:48,850:INFO:Initializing get_config()
2025-12-03 11:37:48,850:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E64581EE90>, variable=y_test)
2025-12-03 11:37:48,852:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-12-03 11:37:48,852:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-12-03 11:37:48,857:INFO:Variable:  returned as 28456    0.0
8993     0.0
34312    0.0
4802     0.0
25895    0.0
        ... 
18045    0.0
5425     0.0
12819    0.0
33659    0.0
19531    0.0
Name: HeartDisease, Length: 13109, dtype: float32
2025-12-03 11:37:48,857:INFO:get_config() successfully completed......................................
2025-12-03 11:37:49,011:INFO:Initializing get_config()
2025-12-03 11:37:49,011:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E64581EE90>, variable=X_train_transformed)
2025-12-03 11:37:49,060:INFO:Variable: X_train returned as             Age  IncomeRatio  SystolicBP       BMI  WaistCircumference  \
15208  0.281967     1.073479   -0.029334  0.320615           -0.184205   
25325 -0.959685     0.336748   -1.131593 -1.420125           -1.360604   
5132  -0.499814    -0.472688   -0.718246 -0.222594           -0.051710   
17217 -0.177904    -0.894370   -0.355002 -0.592965           -0.099890   
6382  -0.108923     0.093300    0.697155  2.851479            1.783151   
...         ...          ...         ...       ...                 ...   
72714  0.209599    -0.574548    0.093968 -0.084224            0.048339   
72715  0.410044     0.140941    1.545471  0.784710            0.534682   
72716  0.336375     0.706350   -0.225611 -0.316094            0.087200   
72717  0.465916     0.152440   -0.649398  0.648433            0.661659   
72718  0.465916     0.204596    0.822492 -0.260262           -0.112576   

         Height  TotalCholesterol  Triglycerides       LDL       HDL  ...  \
15208 -0.949100          0.573893       0.496366  0.004515  0.470102  ...   
25325 -0.676156          0.027513      -0.418808  0.000788  0.460074  ...   
5132   0.887068          0.164048       0.383587  0.688473 -1.055073  ...   
17217  0.856051          0.206410       0.239340  0.002372 -0.072797  ...   
6382   0.111659          0.796802       0.552888  0.002599  0.944927  ...   
...         ...               ...            ...       ...       ...  ...   
72714  0.529966          0.966537       0.338163  2.847690 -1.107269  ...   
72715 -0.193825          1.002684       1.137561  0.006116  0.578610  ...   
72716  0.850772          0.698204       0.800524  0.005273  0.320829  ...   
72717  0.196053         -0.854465      -0.645063 -1.338104 -0.093582  ...   
72718 -0.754937         -1.171319      -0.645250 -1.650124 -0.583170  ...   

       Race_5.0  Race_1.0  Race_4.0  Race_3.0  Race_2.0  Education   Smoking  \
15208  1.000000       0.0  0.000000 -0.145400   0.00000  -0.656011 -0.319015   
25325  0.000000       1.0  0.000000 -0.145400   0.00000   0.170835 -0.319015   
5132   0.000000       1.0  0.000000 -0.145400   0.00000  -0.656011  0.680985   
17217  0.000000       0.0  3.236622 -0.145400   0.00000  -0.065383  0.680985   
6382   0.000000       0.0  3.236622 -0.145400   0.00000   0.525245  0.680985   
...         ...       ...       ...       ...       ...        ...       ...   
72714  0.000000       0.0  3.236622 -0.145400   0.00000   0.525245  0.672319   
72715  0.000000       0.0  0.000000  0.854600   0.00000  -0.656011  0.680985   
72716  0.402414       0.0  0.000000  0.452186   0.00000   0.409971  0.680985   
72717  0.000000       0.0  0.000000 -0.030279   0.88488   1.115873  0.680985   
72718  0.000000       0.0  0.000000  0.854600   0.00000  -0.067269 -0.315822   

       PhysicalActivity  HealthInsurance   Alcohol  
15208          0.000000              0.0 -1.284779  
25325          0.000000              0.0  0.445085  
5132           0.000000             -1.0  0.118386  
17217          0.000000              0.0  0.445085  
6382           0.000000              0.0  0.451028  
...                 ...              ...       ...  
72714          0.000000              0.0  0.115540  
72715          0.000000              0.0  0.077133  
72716          0.000000              0.0  0.430065  
72717          0.000000              0.0  0.364598  
72718          0.006717              0.0 -0.723887  

[59610 rows x 31 columns]
2025-12-03 11:37:49,066:INFO:get_config() successfully completed......................................
2025-12-03 11:37:49,066:INFO:Initializing get_config()
2025-12-03 11:37:49,066:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E64581EE90>, variable=y_train)
2025-12-03 11:37:49,066:INFO:Variable: 'y_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_train_transformed' instead.
2025-12-03 11:37:49,066:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_train_transformed' instead.

2025-12-03 11:37:49,073:INFO:Variable:  returned as 15208    0.0
25325    0.0
5132     0.0
17217    0.0
6382     0.0
        ... 
6265     0.0
42694    0.0
13399    0.0
39959    0.0
6616     0.0
Name: HeartDisease, Length: 30586, dtype: float32
2025-12-03 11:37:49,073:INFO:get_config() successfully completed......................................
2025-12-03 11:37:49,075:INFO:Initializing get_config()
2025-12-03 11:37:49,075:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E64581EE90>, variable=X_test_transformed)
2025-12-03 11:37:49,149:INFO:Variable: X_test returned as             Age  IncomeRatio  SystolicBP       BMI  WaistCircumference  \
28456 -1.166627    -0.346668   -0.856028 -1.444817           -1.505144   
8993   0.144006     0.336748    1.661631  0.616912            0.650918   
34312  0.029038     0.094402    0.120974  0.320615            0.349792   
4802  -1.235607     0.337310   -0.679800 -0.555589           -0.935736   
25895  0.029038     1.529090   -0.455207 -0.552146           -0.411032   
...         ...          ...         ...       ...                 ...   
18045 -1.258601    -0.075240   -0.902556 -1.667039           -1.990961   
5425  -0.085930     0.470814    1.711734 -0.123829           -0.083830   
12819  0.235980     0.002310    0.478266  0.246541            0.711143   
33659 -1.212614     1.325519   -0.862074 -0.975681           -1.485069   
19531 -1.281594    -0.395137   -0.847590 -1.395434           -1.846420   

         Height  TotalCholesterol  Triglycerides       LDL       HDL  ...  \
28456 -1.817558         -0.075919      -0.645504 -0.018918  0.565429  ...   
8993  -0.645140          0.703061       0.628124  0.004972  0.591985  ...   
34312  0.583108         -0.117177       0.871284 -0.747548 -1.113897  ...   
4802  -0.974805         -0.177199      -0.485069  0.000613  0.052365  ...   
25895  0.081554          0.820238       1.262972  0.006556 -0.055073  ...   
...         ...               ...            ...       ...       ...  ...   
18045 -3.281529         -0.317991      -0.645314 -0.614949  0.543115  ...   
5425  -0.006203          0.398401      -0.206369  0.808141  0.297868  ...   
12819  1.513598         -0.679626      -0.644711 -0.152776 -0.819779  ...   
33659 -2.071891         -0.984285      -0.645722 -2.065437  0.297868  ...   
19531 -3.659929         -0.332706      -0.645328 -0.652405  0.543209  ...   

       Race_5.0  Race_1.0  Race_4.0  Race_3.0  Race_2.0  Education   Smoking  \
28456       1.0       0.0  0.000000   -0.1454       0.0  -0.023013 -0.319015   
8993        0.0       0.0  3.236622   -0.1454       0.0   0.525245  0.680985   
34312       0.0       0.0  0.000000    0.8546       0.0  -0.656011 -0.319015   
4802        1.0       0.0  0.000000   -0.1454       0.0   0.246788 -0.245402   
25895       0.0       0.0  0.000000    0.8546       0.0   1.115873 -0.319015   
...         ...       ...       ...       ...       ...        ...       ...   
18045       0.0       0.0  0.000000    0.8546       0.0  -0.786652 -0.319015   
5425        0.0       0.0  3.236622   -0.1454       0.0   0.525245  0.680985   
12819       0.0       0.0  0.000000    0.8546       0.0   1.115873  0.680985   
33659       0.0       0.0  3.236622   -0.1454       0.0   0.242351 -0.319015   
19531       1.0       0.0  0.000000   -0.1454       0.0  -0.813970 -0.319015   

       PhysicalActivity  HealthInsurance   Alcohol  
28456          0.869504              0.0 -0.854408  
8993           0.000000              0.0 -0.112801  
34312          0.000000              0.0  0.445085  
4802           1.332660              0.0 -0.368621  
25895          0.000000              0.0 -1.284779  
...                 ...              ...       ...  
18045          1.190419              0.0 -0.812429  
5425           2.103596              0.0 -0.133319  
12819          2.103596              0.0  0.469341  
33659          1.530139              0.0 -0.428356  
19531          1.041572              0.0 -1.047058  

[13109 rows x 31 columns]
2025-12-03 11:37:49,149:INFO:get_config() successfully completed......................................
2025-12-03 11:37:49,149:INFO:Initializing get_config()
2025-12-03 11:37:49,149:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E64581EE90>, variable=y_test)
2025-12-03 11:37:49,149:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-12-03 11:37:49,149:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-12-03 11:37:49,153:INFO:Variable:  returned as 28456    0.0
8993     0.0
34312    0.0
4802     0.0
25895    0.0
        ... 
18045    0.0
5425     0.0
12819    0.0
33659    0.0
19531    0.0
Name: HeartDisease, Length: 13109, dtype: float32
2025-12-03 11:37:49,153:INFO:get_config() successfully completed......................................
2025-12-03 11:37:49,284:INFO:Initializing get_config()
2025-12-03 11:37:49,284:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E64581EE90>, variable=X_test_transformed)
2025-12-03 11:37:49,361:INFO:Variable: X_test returned as             Age  IncomeRatio  SystolicBP       BMI  WaistCircumference  \
28456 -1.166627    -0.346668   -0.856028 -1.444817           -1.505144   
8993   0.144006     0.336748    1.661631  0.616912            0.650918   
34312  0.029038     0.094402    0.120974  0.320615            0.349792   
4802  -1.235607     0.337310   -0.679800 -0.555589           -0.935736   
25895  0.029038     1.529090   -0.455207 -0.552146           -0.411032   
...         ...          ...         ...       ...                 ...   
18045 -1.258601    -0.075240   -0.902556 -1.667039           -1.990961   
5425  -0.085930     0.470814    1.711734 -0.123829           -0.083830   
12819  0.235980     0.002310    0.478266  0.246541            0.711143   
33659 -1.212614     1.325519   -0.862074 -0.975681           -1.485069   
19531 -1.281594    -0.395137   -0.847590 -1.395434           -1.846420   

         Height  TotalCholesterol  Triglycerides       LDL       HDL  ...  \
28456 -1.817558         -0.075919      -0.645504 -0.018918  0.565429  ...   
8993  -0.645140          0.703061       0.628124  0.004972  0.591985  ...   
34312  0.583108         -0.117177       0.871284 -0.747548 -1.113897  ...   
4802  -0.974805         -0.177199      -0.485069  0.000613  0.052365  ...   
25895  0.081554          0.820238       1.262972  0.006556 -0.055073  ...   
...         ...               ...            ...       ...       ...  ...   
18045 -3.281529         -0.317991      -0.645314 -0.614949  0.543115  ...   
5425  -0.006203          0.398401      -0.206369  0.808141  0.297868  ...   
12819  1.513598         -0.679626      -0.644711 -0.152776 -0.819779  ...   
33659 -2.071891         -0.984285      -0.645722 -2.065437  0.297868  ...   
19531 -3.659929         -0.332706      -0.645328 -0.652405  0.543209  ...   

       Race_5.0  Race_1.0  Race_4.0  Race_3.0  Race_2.0  Education   Smoking  \
28456       1.0       0.0  0.000000   -0.1454       0.0  -0.023013 -0.319015   
8993        0.0       0.0  3.236622   -0.1454       0.0   0.525245  0.680985   
34312       0.0       0.0  0.000000    0.8546       0.0  -0.656011 -0.319015   
4802        1.0       0.0  0.000000   -0.1454       0.0   0.246788 -0.245402   
25895       0.0       0.0  0.000000    0.8546       0.0   1.115873 -0.319015   
...         ...       ...       ...       ...       ...        ...       ...   
18045       0.0       0.0  0.000000    0.8546       0.0  -0.786652 -0.319015   
5425        0.0       0.0  3.236622   -0.1454       0.0   0.525245  0.680985   
12819       0.0       0.0  0.000000    0.8546       0.0   1.115873  0.680985   
33659       0.0       0.0  3.236622   -0.1454       0.0   0.242351 -0.319015   
19531       1.0       0.0  0.000000   -0.1454       0.0  -0.813970 -0.319015   

       PhysicalActivity  HealthInsurance   Alcohol  
28456          0.869504              0.0 -0.854408  
8993           0.000000              0.0 -0.112801  
34312          0.000000              0.0  0.445085  
4802           1.332660              0.0 -0.368621  
25895          0.000000              0.0 -1.284779  
...                 ...              ...       ...  
18045          1.190419              0.0 -0.812429  
5425           2.103596              0.0 -0.133319  
12819          2.103596              0.0  0.469341  
33659          1.530139              0.0 -0.428356  
19531          1.041572              0.0 -1.047058  

[13109 rows x 31 columns]
2025-12-03 11:37:49,361:INFO:get_config() successfully completed......................................
2025-12-03 11:37:49,390:INFO:Initializing get_config()
2025-12-03 11:37:49,390:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E64581EE90>, variable=y_test)
2025-12-03 11:37:49,391:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-12-03 11:37:49,391:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-12-03 11:37:49,395:INFO:Variable:  returned as 28456    0.0
8993     0.0
34312    0.0
4802     0.0
25895    0.0
        ... 
18045    0.0
5425     0.0
12819    0.0
33659    0.0
19531    0.0
Name: HeartDisease, Length: 13109, dtype: float32
2025-12-03 11:37:49,395:INFO:get_config() successfully completed......................................
2025-12-03 11:37:49,399:INFO:Initializing get_config()
2025-12-03 11:37:49,399:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E64581EE90>, variable=y_test)
2025-12-03 11:37:49,399:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-12-03 11:37:49,399:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-12-03 11:37:49,404:INFO:Variable:  returned as 28456    0.0
8993     0.0
34312    0.0
4802     0.0
25895    0.0
        ... 
18045    0.0
5425     0.0
12819    0.0
33659    0.0
19531    0.0
Name: HeartDisease, Length: 13109, dtype: float32
2025-12-03 11:37:49,404:INFO:get_config() successfully completed......................................
2025-12-03 11:37:49,407:INFO:Initializing get_config()
2025-12-03 11:37:49,407:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E64581EE90>, variable=X_test_transformed)
2025-12-03 11:37:49,479:INFO:Variable: X_test returned as             Age  IncomeRatio  SystolicBP       BMI  WaistCircumference  \
28456 -1.166627    -0.346668   -0.856028 -1.444817           -1.505144   
8993   0.144006     0.336748    1.661631  0.616912            0.650918   
34312  0.029038     0.094402    0.120974  0.320615            0.349792   
4802  -1.235607     0.337310   -0.679800 -0.555589           -0.935736   
25895  0.029038     1.529090   -0.455207 -0.552146           -0.411032   
...         ...          ...         ...       ...                 ...   
18045 -1.258601    -0.075240   -0.902556 -1.667039           -1.990961   
5425  -0.085930     0.470814    1.711734 -0.123829           -0.083830   
12819  0.235980     0.002310    0.478266  0.246541            0.711143   
33659 -1.212614     1.325519   -0.862074 -0.975681           -1.485069   
19531 -1.281594    -0.395137   -0.847590 -1.395434           -1.846420   

         Height  TotalCholesterol  Triglycerides       LDL       HDL  ...  \
28456 -1.817558         -0.075919      -0.645504 -0.018918  0.565429  ...   
8993  -0.645140          0.703061       0.628124  0.004972  0.591985  ...   
34312  0.583108         -0.117177       0.871284 -0.747548 -1.113897  ...   
4802  -0.974805         -0.177199      -0.485069  0.000613  0.052365  ...   
25895  0.081554          0.820238       1.262972  0.006556 -0.055073  ...   
...         ...               ...            ...       ...       ...  ...   
18045 -3.281529         -0.317991      -0.645314 -0.614949  0.543115  ...   
5425  -0.006203          0.398401      -0.206369  0.808141  0.297868  ...   
12819  1.513598         -0.679626      -0.644711 -0.152776 -0.819779  ...   
33659 -2.071891         -0.984285      -0.645722 -2.065437  0.297868  ...   
19531 -3.659929         -0.332706      -0.645328 -0.652405  0.543209  ...   

       Race_5.0  Race_1.0  Race_4.0  Race_3.0  Race_2.0  Education   Smoking  \
28456       1.0       0.0  0.000000   -0.1454       0.0  -0.023013 -0.319015   
8993        0.0       0.0  3.236622   -0.1454       0.0   0.525245  0.680985   
34312       0.0       0.0  0.000000    0.8546       0.0  -0.656011 -0.319015   
4802        1.0       0.0  0.000000   -0.1454       0.0   0.246788 -0.245402   
25895       0.0       0.0  0.000000    0.8546       0.0   1.115873 -0.319015   
...         ...       ...       ...       ...       ...        ...       ...   
18045       0.0       0.0  0.000000    0.8546       0.0  -0.786652 -0.319015   
5425        0.0       0.0  3.236622   -0.1454       0.0   0.525245  0.680985   
12819       0.0       0.0  0.000000    0.8546       0.0   1.115873  0.680985   
33659       0.0       0.0  3.236622   -0.1454       0.0   0.242351 -0.319015   
19531       1.0       0.0  0.000000   -0.1454       0.0  -0.813970 -0.319015   

       PhysicalActivity  HealthInsurance   Alcohol  
28456          0.869504              0.0 -0.854408  
8993           0.000000              0.0 -0.112801  
34312          0.000000              0.0  0.445085  
4802           1.332660              0.0 -0.368621  
25895          0.000000              0.0 -1.284779  
...                 ...              ...       ...  
18045          1.190419              0.0 -0.812429  
5425           2.103596              0.0 -0.133319  
12819          2.103596              0.0  0.469341  
33659          1.530139              0.0 -0.428356  
19531          1.041572              0.0 -1.047058  

[13109 rows x 31 columns]
2025-12-03 11:37:49,479:INFO:get_config() successfully completed......................................
2025-12-03 11:37:49,481:INFO:Initializing get_config()
2025-12-03 11:37:49,481:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E64581EE90>, variable=y_test)
2025-12-03 11:37:49,481:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-12-03 11:37:49,481:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-12-03 11:37:49,488:INFO:Variable:  returned as 28456    0.0
8993     0.0
34312    0.0
4802     0.0
25895    0.0
        ... 
18045    0.0
5425     0.0
12819    0.0
33659    0.0
19531    0.0
Name: HeartDisease, Length: 13109, dtype: float32
2025-12-03 11:37:49,488:INFO:get_config() successfully completed......................................
2025-12-03 11:37:49,490:INFO:Initializing get_config()
2025-12-03 11:37:49,490:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E64581EE90>, variable=y_test)
2025-12-03 11:37:49,490:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-12-03 11:37:49,490:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-12-03 11:37:49,495:INFO:Variable:  returned as 28456    0.0
8993     0.0
34312    0.0
4802     0.0
25895    0.0
        ... 
18045    0.0
5425     0.0
12819    0.0
33659    0.0
19531    0.0
Name: HeartDisease, Length: 13109, dtype: float32
2025-12-03 11:37:49,495:INFO:get_config() successfully completed......................................
2025-12-03 11:37:49,497:INFO:Initializing get_config()
2025-12-03 11:37:49,497:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E64581EE90>, variable=X_test_transformed)
2025-12-03 11:37:49,567:INFO:Variable: X_test returned as             Age  IncomeRatio  SystolicBP       BMI  WaistCircumference  \
28456 -1.166627    -0.346668   -0.856028 -1.444817           -1.505144   
8993   0.144006     0.336748    1.661631  0.616912            0.650918   
34312  0.029038     0.094402    0.120974  0.320615            0.349792   
4802  -1.235607     0.337310   -0.679800 -0.555589           -0.935736   
25895  0.029038     1.529090   -0.455207 -0.552146           -0.411032   
...         ...          ...         ...       ...                 ...   
18045 -1.258601    -0.075240   -0.902556 -1.667039           -1.990961   
5425  -0.085930     0.470814    1.711734 -0.123829           -0.083830   
12819  0.235980     0.002310    0.478266  0.246541            0.711143   
33659 -1.212614     1.325519   -0.862074 -0.975681           -1.485069   
19531 -1.281594    -0.395137   -0.847590 -1.395434           -1.846420   

         Height  TotalCholesterol  Triglycerides       LDL       HDL  ...  \
28456 -1.817558         -0.075919      -0.645504 -0.018918  0.565429  ...   
8993  -0.645140          0.703061       0.628124  0.004972  0.591985  ...   
34312  0.583108         -0.117177       0.871284 -0.747548 -1.113897  ...   
4802  -0.974805         -0.177199      -0.485069  0.000613  0.052365  ...   
25895  0.081554          0.820238       1.262972  0.006556 -0.055073  ...   
...         ...               ...            ...       ...       ...  ...   
18045 -3.281529         -0.317991      -0.645314 -0.614949  0.543115  ...   
5425  -0.006203          0.398401      -0.206369  0.808141  0.297868  ...   
12819  1.513598         -0.679626      -0.644711 -0.152776 -0.819779  ...   
33659 -2.071891         -0.984285      -0.645722 -2.065437  0.297868  ...   
19531 -3.659929         -0.332706      -0.645328 -0.652405  0.543209  ...   

       Race_5.0  Race_1.0  Race_4.0  Race_3.0  Race_2.0  Education   Smoking  \
28456       1.0       0.0  0.000000   -0.1454       0.0  -0.023013 -0.319015   
8993        0.0       0.0  3.236622   -0.1454       0.0   0.525245  0.680985   
34312       0.0       0.0  0.000000    0.8546       0.0  -0.656011 -0.319015   
4802        1.0       0.0  0.000000   -0.1454       0.0   0.246788 -0.245402   
25895       0.0       0.0  0.000000    0.8546       0.0   1.115873 -0.319015   
...         ...       ...       ...       ...       ...        ...       ...   
18045       0.0       0.0  0.000000    0.8546       0.0  -0.786652 -0.319015   
5425        0.0       0.0  3.236622   -0.1454       0.0   0.525245  0.680985   
12819       0.0       0.0  0.000000    0.8546       0.0   1.115873  0.680985   
33659       0.0       0.0  3.236622   -0.1454       0.0   0.242351 -0.319015   
19531       1.0       0.0  0.000000   -0.1454       0.0  -0.813970 -0.319015   

       PhysicalActivity  HealthInsurance   Alcohol  
28456          0.869504              0.0 -0.854408  
8993           0.000000              0.0 -0.112801  
34312          0.000000              0.0  0.445085  
4802           1.332660              0.0 -0.368621  
25895          0.000000              0.0 -1.284779  
...                 ...              ...       ...  
18045          1.190419              0.0 -0.812429  
5425           2.103596              0.0 -0.133319  
12819          2.103596              0.0  0.469341  
33659          1.530139              0.0 -0.428356  
19531          1.041572              0.0 -1.047058  

[13109 rows x 31 columns]
2025-12-03 11:37:49,567:INFO:get_config() successfully completed......................................
2025-12-03 11:37:49,639:INFO:Initializing get_config()
2025-12-03 11:37:49,640:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E64581EE90>, variable=y_test)
2025-12-03 11:37:49,640:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-12-03 11:37:49,640:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-12-03 11:37:49,645:INFO:Variable:  returned as 28456    0.0
8993     0.0
34312    0.0
4802     0.0
25895    0.0
        ... 
18045    0.0
5425     0.0
12819    0.0
33659    0.0
19531    0.0
Name: HeartDisease, Length: 13109, dtype: float32
2025-12-03 11:37:49,645:INFO:get_config() successfully completed......................................
2025-12-03 11:37:49,647:INFO:Initializing get_config()
2025-12-03 11:37:49,647:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E64581EE90>, variable=y_test)
2025-12-03 11:37:49,647:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-12-03 11:37:49,647:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-12-03 11:37:49,652:INFO:Variable:  returned as 28456    0.0
8993     0.0
34312    0.0
4802     0.0
25895    0.0
        ... 
18045    0.0
5425     0.0
12819    0.0
33659    0.0
19531    0.0
Name: HeartDisease, Length: 13109, dtype: float32
2025-12-03 11:37:49,652:INFO:get_config() successfully completed......................................
2025-12-03 11:37:49,656:INFO:Initializing get_config()
2025-12-03 11:37:49,656:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E64581EE90>, variable=y_test)
2025-12-03 11:37:49,657:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-12-03 11:37:49,657:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-12-03 11:37:49,664:INFO:Variable:  returned as 28456    0.0
8993     0.0
34312    0.0
4802     0.0
25895    0.0
        ... 
18045    0.0
5425     0.0
12819    0.0
33659    0.0
19531    0.0
Name: HeartDisease, Length: 13109, dtype: float32
2025-12-03 11:37:49,664:INFO:get_config() successfully completed......................................
2025-12-03 11:37:49,664:INFO:Initializing get_config()
2025-12-03 11:37:49,664:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E64581EE90>, variable=X_test_transformed)
2025-12-03 11:37:49,731:INFO:Variable: X_test returned as             Age  IncomeRatio  SystolicBP       BMI  WaistCircumference  \
28456 -1.166627    -0.346668   -0.856028 -1.444817           -1.505144   
8993   0.144006     0.336748    1.661631  0.616912            0.650918   
34312  0.029038     0.094402    0.120974  0.320615            0.349792   
4802  -1.235607     0.337310   -0.679800 -0.555589           -0.935736   
25895  0.029038     1.529090   -0.455207 -0.552146           -0.411032   
...         ...          ...         ...       ...                 ...   
18045 -1.258601    -0.075240   -0.902556 -1.667039           -1.990961   
5425  -0.085930     0.470814    1.711734 -0.123829           -0.083830   
12819  0.235980     0.002310    0.478266  0.246541            0.711143   
33659 -1.212614     1.325519   -0.862074 -0.975681           -1.485069   
19531 -1.281594    -0.395137   -0.847590 -1.395434           -1.846420   

         Height  TotalCholesterol  Triglycerides       LDL       HDL  ...  \
28456 -1.817558         -0.075919      -0.645504 -0.018918  0.565429  ...   
8993  -0.645140          0.703061       0.628124  0.004972  0.591985  ...   
34312  0.583108         -0.117177       0.871284 -0.747548 -1.113897  ...   
4802  -0.974805         -0.177199      -0.485069  0.000613  0.052365  ...   
25895  0.081554          0.820238       1.262972  0.006556 -0.055073  ...   
...         ...               ...            ...       ...       ...  ...   
18045 -3.281529         -0.317991      -0.645314 -0.614949  0.543115  ...   
5425  -0.006203          0.398401      -0.206369  0.808141  0.297868  ...   
12819  1.513598         -0.679626      -0.644711 -0.152776 -0.819779  ...   
33659 -2.071891         -0.984285      -0.645722 -2.065437  0.297868  ...   
19531 -3.659929         -0.332706      -0.645328 -0.652405  0.543209  ...   

       Race_5.0  Race_1.0  Race_4.0  Race_3.0  Race_2.0  Education   Smoking  \
28456       1.0       0.0  0.000000   -0.1454       0.0  -0.023013 -0.319015   
8993        0.0       0.0  3.236622   -0.1454       0.0   0.525245  0.680985   
34312       0.0       0.0  0.000000    0.8546       0.0  -0.656011 -0.319015   
4802        1.0       0.0  0.000000   -0.1454       0.0   0.246788 -0.245402   
25895       0.0       0.0  0.000000    0.8546       0.0   1.115873 -0.319015   
...         ...       ...       ...       ...       ...        ...       ...   
18045       0.0       0.0  0.000000    0.8546       0.0  -0.786652 -0.319015   
5425        0.0       0.0  3.236622   -0.1454       0.0   0.525245  0.680985   
12819       0.0       0.0  0.000000    0.8546       0.0   1.115873  0.680985   
33659       0.0       0.0  3.236622   -0.1454       0.0   0.242351 -0.319015   
19531       1.0       0.0  0.000000   -0.1454       0.0  -0.813970 -0.319015   

       PhysicalActivity  HealthInsurance   Alcohol  
28456          0.869504              0.0 -0.854408  
8993           0.000000              0.0 -0.112801  
34312          0.000000              0.0  0.445085  
4802           1.332660              0.0 -0.368621  
25895          0.000000              0.0 -1.284779  
...                 ...              ...       ...  
18045          1.190419              0.0 -0.812429  
5425           2.103596              0.0 -0.133319  
12819          2.103596              0.0  0.469341  
33659          1.530139              0.0 -0.428356  
19531          1.041572              0.0 -1.047058  

[13109 rows x 31 columns]
2025-12-03 11:37:49,731:INFO:get_config() successfully completed......................................
2025-12-03 11:37:49,767:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pandas\io\formats\style.py:3823: RuntimeWarning: invalid value encountered in scalar multiply

2025-12-03 11:37:49,802:INFO:Initializing plot_model()
2025-12-03 11:37:49,802:INFO:plot_model(plot=error, fold=None, verbose=True, display=None, display_format=None, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E64581EE90>, system=True)
2025-12-03 11:37:49,802:INFO:Checking exceptions
2025-12-03 11:37:49,821:INFO:Preloading libraries
2025-12-03 11:37:49,849:INFO:Copying training dataset
2025-12-03 11:37:49,849:INFO:Plot type: error
2025-12-03 11:37:50,088:INFO:Fitting Model
2025-12-03 11:37:50,089:INFO:Scoring test/hold-out set
2025-12-03 11:37:50,258:INFO:Visual Rendered Successfully
2025-12-03 11:37:50,420:INFO:plot_model() successfully completed......................................
2025-12-03 11:37:50,422:INFO:Initializing get_config()
2025-12-03 11:37:50,422:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E64581EE90>, variable=X_train_transformed)
2025-12-03 11:37:50,467:INFO:Variable: X_train returned as             Age  IncomeRatio  SystolicBP       BMI  WaistCircumference  \
15208  0.281967     1.073479   -0.029334  0.320615           -0.184205   
25325 -0.959685     0.336748   -1.131593 -1.420125           -1.360604   
5132  -0.499814    -0.472688   -0.718246 -0.222594           -0.051710   
17217 -0.177904    -0.894370   -0.355002 -0.592965           -0.099890   
6382  -0.108923     0.093300    0.697155  2.851479            1.783151   
...         ...          ...         ...       ...                 ...   
72714  0.209599    -0.574548    0.093968 -0.084224            0.048339   
72715  0.410044     0.140941    1.545471  0.784710            0.534682   
72716  0.336375     0.706350   -0.225611 -0.316094            0.087200   
72717  0.465916     0.152440   -0.649398  0.648433            0.661659   
72718  0.465916     0.204596    0.822492 -0.260262           -0.112576   

         Height  TotalCholesterol  Triglycerides       LDL       HDL  ...  \
15208 -0.949100          0.573893       0.496366  0.004515  0.470102  ...   
25325 -0.676156          0.027513      -0.418808  0.000788  0.460074  ...   
5132   0.887068          0.164048       0.383587  0.688473 -1.055073  ...   
17217  0.856051          0.206410       0.239340  0.002372 -0.072797  ...   
6382   0.111659          0.796802       0.552888  0.002599  0.944927  ...   
...         ...               ...            ...       ...       ...  ...   
72714  0.529966          0.966537       0.338163  2.847690 -1.107269  ...   
72715 -0.193825          1.002684       1.137561  0.006116  0.578610  ...   
72716  0.850772          0.698204       0.800524  0.005273  0.320829  ...   
72717  0.196053         -0.854465      -0.645063 -1.338104 -0.093582  ...   
72718 -0.754937         -1.171319      -0.645250 -1.650124 -0.583170  ...   

       Race_5.0  Race_1.0  Race_4.0  Race_3.0  Race_2.0  Education   Smoking  \
15208  1.000000       0.0  0.000000 -0.145400   0.00000  -0.656011 -0.319015   
25325  0.000000       1.0  0.000000 -0.145400   0.00000   0.170835 -0.319015   
5132   0.000000       1.0  0.000000 -0.145400   0.00000  -0.656011  0.680985   
17217  0.000000       0.0  3.236622 -0.145400   0.00000  -0.065383  0.680985   
6382   0.000000       0.0  3.236622 -0.145400   0.00000   0.525245  0.680985   
...         ...       ...       ...       ...       ...        ...       ...   
72714  0.000000       0.0  3.236622 -0.145400   0.00000   0.525245  0.672319   
72715  0.000000       0.0  0.000000  0.854600   0.00000  -0.656011  0.680985   
72716  0.402414       0.0  0.000000  0.452186   0.00000   0.409971  0.680985   
72717  0.000000       0.0  0.000000 -0.030279   0.88488   1.115873  0.680985   
72718  0.000000       0.0  0.000000  0.854600   0.00000  -0.067269 -0.315822   

       PhysicalActivity  HealthInsurance   Alcohol  
15208          0.000000              0.0 -1.284779  
25325          0.000000              0.0  0.445085  
5132           0.000000             -1.0  0.118386  
17217          0.000000              0.0  0.445085  
6382           0.000000              0.0  0.451028  
...                 ...              ...       ...  
72714          0.000000              0.0  0.115540  
72715          0.000000              0.0  0.077133  
72716          0.000000              0.0  0.430065  
72717          0.000000              0.0  0.364598  
72718          0.006717              0.0 -0.723887  

[59610 rows x 31 columns]
2025-12-03 11:37:50,467:INFO:get_config() successfully completed......................................
2025-12-03 11:37:50,467:INFO:Initializing get_config()
2025-12-03 11:37:50,467:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E64581EE90>, variable=y_train)
2025-12-03 11:37:50,467:INFO:Variable: 'y_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_train_transformed' instead.
2025-12-03 11:37:50,467:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_train_transformed' instead.

2025-12-03 11:37:50,475:INFO:Variable:  returned as 15208    0.0
25325    0.0
5132     0.0
17217    0.0
6382     0.0
        ... 
6265     0.0
42694    0.0
13399    0.0
39959    0.0
6616     0.0
Name: HeartDisease, Length: 30586, dtype: float32
2025-12-03 11:37:50,475:INFO:get_config() successfully completed......................................
2025-12-03 11:43:35,633:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-12-03 11:43:35,633:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-12-03 11:43:35,634:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-12-03 11:43:35,634:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-12-03 11:43:37,412:INFO:PyCaret ClassificationExperiment
2025-12-03 11:43:37,412:INFO:Logging name: clf-default-name
2025-12-03 11:43:37,412:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-12-03 11:43:37,412:INFO:version 3.3.2
2025-12-03 11:43:37,414:INFO:Initializing setup()
2025-12-03 11:43:37,414:INFO:self.USI: ea3c
2025-12-03 11:43:37,414:INFO:self._variable_keys: {'y', 'is_multiclass', 'y_train', 'X', 'target_param', 'X_train', 'exp_name_log', 'pipeline', 'fold_generator', 'fold_groups_param', 'X_test', 'data', 'gpu_param', '_available_plots', 'USI', 'idx', 'logging_param', 'memory', 'fix_imbalance', 'log_plots_param', 'y_test', 'n_jobs_param', '_ml_usecase', 'html_param', 'gpu_n_jobs_param', 'fold_shuffle_param', 'seed', 'exp_id'}
2025-12-03 11:43:37,414:INFO:Checking environment
2025-12-03 11:43:37,414:INFO:python_version: 3.10.19
2025-12-03 11:43:37,414:INFO:python_build: ('main', 'Oct 21 2025 16:41:31')
2025-12-03 11:43:37,414:INFO:machine: AMD64
2025-12-03 11:43:37,414:INFO:platform: Windows-10-10.0.26100-SP0
2025-12-03 11:43:37,414:INFO:Memory: svmem(total=16282144768, available=5161476096, percent=68.3, used=11120668672, free=5161476096)
2025-12-03 11:43:37,414:INFO:Physical Core: 6
2025-12-03 11:43:37,414:INFO:Logical Core: 12
2025-12-03 11:43:37,414:INFO:Checking libraries
2025-12-03 11:43:37,414:INFO:System:
2025-12-03 11:43:37,414:INFO:    python: 3.10.19 | packaged by Anaconda, Inc. | (main, Oct 21 2025, 16:41:31) [MSC v.1929 64 bit (AMD64)]
2025-12-03 11:43:37,414:INFO:executable: c:\Users\OMAR\miniconda3\envs\xgb_env\python.exe
2025-12-03 11:43:37,414:INFO:   machine: Windows-10-10.0.26100-SP0
2025-12-03 11:43:37,414:INFO:PyCaret required dependencies:
2025-12-03 11:43:37,414:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-03 11:43:37,963:INFO:                 pip: 25.3
2025-12-03 11:43:37,964:INFO:          setuptools: 80.9.0
2025-12-03 11:43:37,964:INFO:             pycaret: 3.3.2
2025-12-03 11:43:37,964:INFO:             IPython: 8.37.0
2025-12-03 11:43:37,964:INFO:          ipywidgets: 8.1.8
2025-12-03 11:43:37,964:INFO:                tqdm: 4.67.1
2025-12-03 11:43:37,964:INFO:               numpy: 1.26.4
2025-12-03 11:43:37,964:INFO:              pandas: 2.1.4
2025-12-03 11:43:37,964:INFO:              jinja2: 3.1.6
2025-12-03 11:43:37,964:INFO:               scipy: 1.11.4
2025-12-03 11:43:37,964:INFO:              joblib: 1.3.2
2025-12-03 11:43:37,964:INFO:             sklearn: 1.4.2
2025-12-03 11:43:37,964:INFO:                pyod: 2.0.5
2025-12-03 11:43:37,964:INFO:            imblearn: 0.14.0
2025-12-03 11:43:37,964:INFO:   category_encoders: 2.7.0
2025-12-03 11:43:37,964:INFO:            lightgbm: 4.6.0
2025-12-03 11:43:37,964:INFO:               numba: 0.62.1
2025-12-03 11:43:37,964:INFO:            requests: 2.32.5
2025-12-03 11:43:37,964:INFO:          matplotlib: 3.7.5
2025-12-03 11:43:37,964:INFO:          scikitplot: 0.3.7
2025-12-03 11:43:37,964:INFO:         yellowbrick: 1.5
2025-12-03 11:43:37,964:INFO:              plotly: 5.24.1
2025-12-03 11:43:37,964:INFO:    plotly-resampler: Not installed
2025-12-03 11:43:37,964:INFO:             kaleido: 1.2.0
2025-12-03 11:43:37,964:INFO:           schemdraw: 0.15
2025-12-03 11:43:37,964:INFO:         statsmodels: 0.14.5
2025-12-03 11:43:37,964:INFO:              sktime: 0.26.0
2025-12-03 11:43:37,964:INFO:               tbats: 1.1.3
2025-12-03 11:43:37,964:INFO:            pmdarima: 2.0.4
2025-12-03 11:43:37,964:INFO:              psutil: 7.1.3
2025-12-03 11:43:37,964:INFO:          markupsafe: 3.0.3
2025-12-03 11:43:37,964:INFO:             pickle5: Not installed
2025-12-03 11:43:37,964:INFO:         cloudpickle: 3.1.2
2025-12-03 11:43:37,964:INFO:         deprecation: 2.1.0
2025-12-03 11:43:37,964:INFO:              xxhash: 3.6.0
2025-12-03 11:43:37,964:INFO:           wurlitzer: Not installed
2025-12-03 11:43:37,964:INFO:PyCaret optional dependencies:
2025-12-03 11:43:40,669:INFO:                shap: 0.49.1
2025-12-03 11:43:40,669:INFO:           interpret: 0.7.3
2025-12-03 11:43:40,669:INFO:                umap: 0.5.7
2025-12-03 11:43:40,669:INFO:     ydata_profiling: 4.18.0
2025-12-03 11:43:40,669:INFO:  explainerdashboard: 0.5.1
2025-12-03 11:43:40,669:INFO:             autoviz: Not installed
2025-12-03 11:43:40,669:INFO:           fairlearn: 0.7.0
2025-12-03 11:43:40,669:INFO:          deepchecks: Not installed
2025-12-03 11:43:40,669:INFO:             xgboost: 2.1.3
2025-12-03 11:43:40,669:INFO:            catboost: 1.2.8
2025-12-03 11:43:40,669:INFO:              kmodes: 0.12.2
2025-12-03 11:43:40,669:INFO:             mlxtend: 0.23.4
2025-12-03 11:43:40,669:INFO:       statsforecast: 1.5.0
2025-12-03 11:43:40,669:INFO:        tune_sklearn: Not installed
2025-12-03 11:43:40,669:INFO:                 ray: Not installed
2025-12-03 11:43:40,669:INFO:            hyperopt: 0.2.7
2025-12-03 11:43:40,669:INFO:              optuna: 4.6.0
2025-12-03 11:43:40,669:INFO:               skopt: 0.10.2
2025-12-03 11:43:40,669:INFO:              mlflow: 3.6.0
2025-12-03 11:43:40,669:INFO:              gradio: 6.0.1
2025-12-03 11:43:40,669:INFO:             fastapi: 0.123.0
2025-12-03 11:43:40,669:INFO:             uvicorn: 0.38.0
2025-12-03 11:43:40,669:INFO:              m2cgen: 0.10.0
2025-12-03 11:43:40,669:INFO:           evidently: 0.4.40
2025-12-03 11:43:40,669:INFO:               fugue: 0.8.7
2025-12-03 11:43:40,669:INFO:           streamlit: 1.51.0
2025-12-03 11:43:40,669:INFO:             prophet: Not installed
2025-12-03 11:43:40,669:INFO:None
2025-12-03 11:43:40,669:INFO:Set up data.
2025-12-03 11:43:40,688:INFO:Set up folding strategy.
2025-12-03 11:43:40,688:INFO:Set up train/test split.
2025-12-03 11:43:40,711:INFO:Set up index.
2025-12-03 11:43:40,712:INFO:Assigning column types.
2025-12-03 11:43:40,733:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-12-03 11:43:40,757:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-12-03 11:43:40,760:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-03 11:43:40,779:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-03 11:43:40,782:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-03 11:43:40,824:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-12-03 11:43:40,825:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-03 11:43:40,838:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-03 11:43:40,843:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-03 11:43:40,843:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-12-03 11:43:40,867:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-03 11:43:40,881:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-03 11:43:40,884:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-03 11:43:40,910:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-03 11:43:40,926:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-03 11:43:40,926:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-03 11:43:40,926:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-12-03 11:43:40,967:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-03 11:43:40,969:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-03 11:43:41,010:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-03 11:43:41,012:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-03 11:43:41,013:INFO:Preparing preprocessing pipeline...
2025-12-03 11:43:41,017:INFO:Set up simple imputation.
2025-12-03 11:43:41,028:INFO:Set up encoding of ordinal features.
2025-12-03 11:43:41,035:INFO:Set up encoding of categorical features.
2025-12-03 11:43:41,035:INFO:Set up imbalanced handling.
2025-12-03 11:43:41,035:INFO:Set up feature normalization.
2025-12-03 11:43:41,225:INFO:Finished creating preprocessing pipeline.
2025-12-03 11:43:41,238:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\OMAR\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'IncomeRatio', 'SystolicBP',
                                             'BMI', 'WaistCircumference',
                                             'Height', 'TotalCholesterol',
                                             'Triglycerides', 'LDL', 'HDL',
                                             'HbA1c', 'Glucose', 'Creatinine',
                                             'UricAcid', 'ALT_Enzyme',
                                             'Albumin', 'Potassium', 'Sodium',
                                             'G...
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              random_state=42,
                                                                              sampling_strategy='auto')))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=RobustScaler(copy=True,
                                                             quantile_range=(25.0,
                                                                             75.0),
                                                             unit_variance=False,
                                                             with_centering=True,
                                                             with_scaling=True)))],
         verbose=False)
2025-12-03 11:43:41,241:INFO:Creating final display dataframe.
2025-12-03 11:43:41,644:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target      HeartDisease
2                   Target type            Binary
3           Original data shape       (43695, 28)
4        Transformed data shape       (72719, 32)
5   Transformed train set shape       (59610, 32)
6    Transformed test set shape       (13109, 32)
7              Numeric features                20
8          Categorical features                 7
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15                Fix imbalance              True
16         Fix imbalance method             SMOTE
17                    Normalize              True
18             Normalize method            robust
19               Fold Generator   StratifiedKFold
20                  Fold Number                10
21                     CPU Jobs                 1
22                      Use GPU             False
23               Log Experiment             False
24              Experiment Name  clf-default-name
25                          USI              ea3c
2025-12-03 11:43:41,694:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-03 11:43:41,694:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-03 11:43:41,749:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-03 11:43:41,752:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-03 11:43:41,753:INFO:setup() successfully completed in 4.35s...............
2025-12-03 11:43:42,056:INFO:Initializing get_config()
2025-12-03 11:43:42,056:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FCB038FE80>, variable=y_train)
2025-12-03 11:43:42,056:INFO:Variable: 'y_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_train_transformed' instead.
2025-12-03 11:43:42,056:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_train_transformed' instead.

2025-12-03 11:43:42,070:INFO:Variable:  returned as 15208    0.0
25325    0.0
5132     0.0
17217    0.0
6382     0.0
        ... 
6265     0.0
42694    0.0
13399    0.0
39959    0.0
6616     0.0
Name: HeartDisease, Length: 30586, dtype: float32
2025-12-03 11:43:42,070:INFO:get_config() successfully completed......................................
2025-12-03 11:43:42,072:INFO:Initializing create_model()
2025-12-03 11:43:42,072:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FCB038FE80>, estimator=xgboost, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={'scale_pos_weight': 76.32522407170295})
2025-12-03 11:43:42,072:INFO:Checking exceptions
2025-12-03 11:43:42,086:INFO:Importing libraries
2025-12-03 11:43:42,086:INFO:Copying training dataset
2025-12-03 11:43:42,126:INFO:Defining folds
2025-12-03 11:43:42,126:INFO:Declaring metric variables
2025-12-03 11:43:42,130:INFO:Importing untrained model
2025-12-03 11:43:42,134:INFO:Extreme Gradient Boosting Imported successfully
2025-12-03 11:43:42,144:INFO:Starting cross validation
2025-12-03 11:43:42,145:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-12-03 11:43:42,281:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\joblib\externals\loky\backend\context.py:136: UserWarning: Could not find the number of physical cores for the following reason:
[WinError 2] El sistema no puede encontrar el archivo especificado
Returning the number of logical cores instead. You can silence this warning by setting LOKY_MAX_CPU_COUNT to the number of cores you want to use.

2025-12-03 11:43:42,283:WARNING:  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\joblib\externals\loky\backend\context.py", line 257, in _count_physical_cores
2025-12-03 11:43:42,283:WARNING:    cpu_info = subprocess.run(
2025-12-03 11:43:42,283:WARNING:  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\subprocess.py", line 503, in run
2025-12-03 11:43:42,283:WARNING:    with Popen(*popenargs, **kwargs) as process:
2025-12-03 11:43:42,283:WARNING:  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\subprocess.py", line 971, in __init__
2025-12-03 11:43:42,284:WARNING:    self._execute_child(args, executable, preexec_fn, close_fds,
2025-12-03 11:43:42,284:WARNING:  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\subprocess.py", line 1456, in _execute_child
2025-12-03 11:43:42,284:WARNING:    hp, ht, pid, tid = _winapi.CreateProcess(executable, args,
2025-12-03 11:43:54,800:INFO:Calculating mean and std
2025-12-03 11:43:54,800:INFO:Creating metrics dataframe
2025-12-03 11:43:54,805:INFO:Finalizing model
2025-12-03 11:43:54,882:INFO:Warning: No categorical columns found. Calling 'transform' will only return input data.
2025-12-03 11:43:56,067:INFO:Uploading results into container
2025-12-03 11:43:56,068:INFO:Uploading model into container now
2025-12-03 11:43:56,076:INFO:_master_model_container: 1
2025-12-03 11:43:56,076:INFO:_display_container: 2
2025-12-03 11:43:56,076:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2025-12-03 11:43:56,076:INFO:create_model() successfully completed......................................
2025-12-03 11:43:56,284:INFO:Initializing create_model()
2025-12-03 11:43:56,288:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FCB038FE80>, estimator=lr, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-03 11:43:56,288:INFO:Checking exceptions
2025-12-03 11:43:56,300:INFO:Importing libraries
2025-12-03 11:43:56,300:INFO:Copying training dataset
2025-12-03 11:43:56,337:INFO:Defining folds
2025-12-03 11:43:56,337:INFO:Declaring metric variables
2025-12-03 11:43:56,341:INFO:Importing untrained model
2025-12-03 11:43:56,346:INFO:Logistic Regression Imported successfully
2025-12-03 11:43:56,353:INFO:Starting cross validation
2025-12-03 11:43:56,355:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-12-03 11:43:59,959:INFO:Calculating mean and std
2025-12-03 11:43:59,967:INFO:Creating metrics dataframe
2025-12-03 11:43:59,970:INFO:Finalizing model
2025-12-03 11:44:00,052:INFO:Warning: No categorical columns found. Calling 'transform' will only return input data.
2025-12-03 11:44:00,349:INFO:Uploading results into container
2025-12-03 11:44:00,349:INFO:Uploading model into container now
2025-12-03 11:44:00,358:INFO:_master_model_container: 2
2025-12-03 11:44:00,358:INFO:_display_container: 3
2025-12-03 11:44:00,360:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-12-03 11:44:00,360:INFO:create_model() successfully completed......................................
2025-12-03 11:44:00,520:INFO:Initializing create_model()
2025-12-03 11:44:00,520:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FCB038FE80>, estimator=rf, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-03 11:44:00,520:INFO:Checking exceptions
2025-12-03 11:44:00,534:INFO:Importing libraries
2025-12-03 11:44:00,534:INFO:Copying training dataset
2025-12-03 11:44:00,582:INFO:Defining folds
2025-12-03 11:44:00,582:INFO:Declaring metric variables
2025-12-03 11:44:00,585:INFO:Importing untrained model
2025-12-03 11:44:00,588:INFO:Random Forest Classifier Imported successfully
2025-12-03 11:44:00,597:INFO:Starting cross validation
2025-12-03 11:44:00,598:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-12-03 11:46:11,750:INFO:Calculating mean and std
2025-12-03 11:46:11,751:INFO:Creating metrics dataframe
2025-12-03 11:46:11,756:INFO:Finalizing model
2025-12-03 11:46:11,830:INFO:Warning: No categorical columns found. Calling 'transform' will only return input data.
2025-12-03 11:46:25,511:INFO:Uploading results into container
2025-12-03 11:46:25,512:INFO:Uploading model into container now
2025-12-03 11:46:25,520:INFO:_master_model_container: 3
2025-12-03 11:46:25,520:INFO:_display_container: 4
2025-12-03 11:46:25,520:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2025-12-03 11:46:25,520:INFO:create_model() successfully completed......................................
2025-12-03 11:46:25,751:INFO:Initializing get_config()
2025-12-03 11:46:25,751:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FCB038FE80>, variable=X_train_transformed)
2025-12-03 11:46:25,931:INFO:Variable: X_train returned as             Age  IncomeRatio  SystolicBP       BMI  WaistCircumference  \
15208  0.281967     1.073479   -0.029334  0.320615           -0.184205   
25325 -0.959685     0.336748   -1.131593 -1.420125           -1.360604   
5132  -0.499814    -0.472688   -0.718246 -0.222594           -0.051710   
17217 -0.177904    -0.894370   -0.355002 -0.592965           -0.099890   
6382  -0.108923     0.093300    0.697155  2.851479            1.783151   
...         ...          ...         ...       ...                 ...   
72714  0.209599    -0.574548    0.093968 -0.084224            0.048339   
72715  0.410044     0.140941    1.545471  0.784710            0.534682   
72716  0.336375     0.706350   -0.225611 -0.316094            0.087200   
72717  0.465916     0.152440   -0.649398  0.648433            0.661659   
72718  0.465916     0.204596    0.822492 -0.260262           -0.112576   

         Height  TotalCholesterol  Triglycerides       LDL       HDL  ...  \
15208 -0.949100          0.573893       0.496366  0.004515  0.470102  ...   
25325 -0.676156          0.027513      -0.418808  0.000788  0.460074  ...   
5132   0.887068          0.164048       0.383587  0.688473 -1.055073  ...   
17217  0.856051          0.206410       0.239340  0.002372 -0.072797  ...   
6382   0.111659          0.796802       0.552888  0.002599  0.944927  ...   
...         ...               ...            ...       ...       ...  ...   
72714  0.529966          0.966537       0.338163  2.847690 -1.107269  ...   
72715 -0.193825          1.002684       1.137561  0.006116  0.578610  ...   
72716  0.850772          0.698204       0.800524  0.005273  0.320829  ...   
72717  0.196053         -0.854465      -0.645063 -1.338104 -0.093582  ...   
72718 -0.754937         -1.171319      -0.645250 -1.650124 -0.583170  ...   

       Race_5.0  Race_1.0  Race_4.0  Race_3.0  Race_2.0  Education   Smoking  \
15208  1.000000       0.0  0.000000 -0.145400   0.00000  -0.656011 -0.319015   
25325  0.000000       1.0  0.000000 -0.145400   0.00000   0.170835 -0.319015   
5132   0.000000       1.0  0.000000 -0.145400   0.00000  -0.656011  0.680985   
17217  0.000000       0.0  3.236622 -0.145400   0.00000  -0.065383  0.680985   
6382   0.000000       0.0  3.236622 -0.145400   0.00000   0.525245  0.680985   
...         ...       ...       ...       ...       ...        ...       ...   
72714  0.000000       0.0  3.236622 -0.145400   0.00000   0.525245  0.672319   
72715  0.000000       0.0  0.000000  0.854600   0.00000  -0.656011  0.680985   
72716  0.402414       0.0  0.000000  0.452186   0.00000   0.409971  0.680985   
72717  0.000000       0.0  0.000000 -0.030279   0.88488   1.115873  0.680985   
72718  0.000000       0.0  0.000000  0.854600   0.00000  -0.067269 -0.315822   

       PhysicalActivity  HealthInsurance   Alcohol  
15208          0.000000              0.0 -1.284779  
25325          0.000000              0.0  0.445085  
5132           0.000000             -1.0  0.118386  
17217          0.000000              0.0  0.445085  
6382           0.000000              0.0  0.451028  
...                 ...              ...       ...  
72714          0.000000              0.0  0.115540  
72715          0.000000              0.0  0.077133  
72716          0.000000              0.0  0.430065  
72717          0.000000              0.0  0.364598  
72718          0.006717              0.0 -0.723887  

[59610 rows x 31 columns]
2025-12-03 11:46:25,934:INFO:get_config() successfully completed......................................
2025-12-03 11:46:25,934:INFO:Initializing get_config()
2025-12-03 11:46:25,934:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FCB038FE80>, variable=y_train)
2025-12-03 11:46:25,934:INFO:Variable: 'y_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_train_transformed' instead.
2025-12-03 11:46:25,934:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_train_transformed' instead.

2025-12-03 11:46:25,941:INFO:Variable:  returned as 15208    0.0
25325    0.0
5132     0.0
17217    0.0
6382     0.0
        ... 
6265     0.0
42694    0.0
13399    0.0
39959    0.0
6616     0.0
Name: HeartDisease, Length: 30586, dtype: float32
2025-12-03 11:46:25,941:INFO:get_config() successfully completed......................................
2025-12-03 11:46:25,941:INFO:Initializing get_config()
2025-12-03 11:46:25,941:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FCB038FE80>, variable=X_test_transformed)
2025-12-03 11:46:26,013:INFO:Variable: X_test returned as             Age  IncomeRatio  SystolicBP       BMI  WaistCircumference  \
28456 -1.166627    -0.346668   -0.856028 -1.444817           -1.505144   
8993   0.144006     0.336748    1.661631  0.616912            0.650918   
34312  0.029038     0.094402    0.120974  0.320615            0.349792   
4802  -1.235607     0.337310   -0.679800 -0.555589           -0.935736   
25895  0.029038     1.529090   -0.455207 -0.552146           -0.411032   
...         ...          ...         ...       ...                 ...   
18045 -1.258601    -0.075240   -0.902556 -1.667039           -1.990961   
5425  -0.085930     0.470814    1.711734 -0.123829           -0.083830   
12819  0.235980     0.002310    0.478266  0.246541            0.711143   
33659 -1.212614     1.325519   -0.862074 -0.975681           -1.485069   
19531 -1.281594    -0.395137   -0.847590 -1.395434           -1.846420   

         Height  TotalCholesterol  Triglycerides       LDL       HDL  ...  \
28456 -1.817558         -0.075919      -0.645504 -0.018918  0.565429  ...   
8993  -0.645140          0.703061       0.628124  0.004972  0.591985  ...   
34312  0.583108         -0.117177       0.871284 -0.747548 -1.113897  ...   
4802  -0.974805         -0.177199      -0.485069  0.000613  0.052365  ...   
25895  0.081554          0.820238       1.262972  0.006556 -0.055073  ...   
...         ...               ...            ...       ...       ...  ...   
18045 -3.281529         -0.317991      -0.645314 -0.614949  0.543115  ...   
5425  -0.006203          0.398401      -0.206369  0.808141  0.297868  ...   
12819  1.513598         -0.679626      -0.644711 -0.152776 -0.819779  ...   
33659 -2.071891         -0.984285      -0.645722 -2.065437  0.297868  ...   
19531 -3.659929         -0.332706      -0.645328 -0.652405  0.543209  ...   

       Race_5.0  Race_1.0  Race_4.0  Race_3.0  Race_2.0  Education   Smoking  \
28456       1.0       0.0  0.000000   -0.1454       0.0  -0.023013 -0.319015   
8993        0.0       0.0  3.236622   -0.1454       0.0   0.525245  0.680985   
34312       0.0       0.0  0.000000    0.8546       0.0  -0.656011 -0.319015   
4802        1.0       0.0  0.000000   -0.1454       0.0   0.246788 -0.245402   
25895       0.0       0.0  0.000000    0.8546       0.0   1.115873 -0.319015   
...         ...       ...       ...       ...       ...        ...       ...   
18045       0.0       0.0  0.000000    0.8546       0.0  -0.786652 -0.319015   
5425        0.0       0.0  3.236622   -0.1454       0.0   0.525245  0.680985   
12819       0.0       0.0  0.000000    0.8546       0.0   1.115873  0.680985   
33659       0.0       0.0  3.236622   -0.1454       0.0   0.242351 -0.319015   
19531       1.0       0.0  0.000000   -0.1454       0.0  -0.813970 -0.319015   

       PhysicalActivity  HealthInsurance   Alcohol  
28456          0.869504              0.0 -0.854408  
8993           0.000000              0.0 -0.112801  
34312          0.000000              0.0  0.445085  
4802           1.332660              0.0 -0.368621  
25895          0.000000              0.0 -1.284779  
...                 ...              ...       ...  
18045          1.190419              0.0 -0.812429  
5425           2.103596              0.0 -0.133319  
12819          2.103596              0.0  0.469341  
33659          1.530139              0.0 -0.428356  
19531          1.041572              0.0 -1.047058  

[13109 rows x 31 columns]
2025-12-03 11:46:26,013:INFO:get_config() successfully completed......................................
2025-12-03 11:46:26,013:INFO:Initializing get_config()
2025-12-03 11:46:26,013:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FCB038FE80>, variable=y_test)
2025-12-03 11:46:26,013:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-12-03 11:46:26,013:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-12-03 11:46:26,019:INFO:Variable:  returned as 28456    0.0
8993     0.0
34312    0.0
4802     0.0
25895    0.0
        ... 
18045    0.0
5425     0.0
12819    0.0
33659    0.0
19531    0.0
Name: HeartDisease, Length: 13109, dtype: float32
2025-12-03 11:46:26,020:INFO:get_config() successfully completed......................................
2025-12-03 11:46:26,181:INFO:Initializing get_config()
2025-12-03 11:46:26,181:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FCB038FE80>, variable=X_train_transformed)
2025-12-03 11:46:26,244:INFO:Variable: X_train returned as             Age  IncomeRatio  SystolicBP       BMI  WaistCircumference  \
15208  0.281967     1.073479   -0.029334  0.320615           -0.184205   
25325 -0.959685     0.336748   -1.131593 -1.420125           -1.360604   
5132  -0.499814    -0.472688   -0.718246 -0.222594           -0.051710   
17217 -0.177904    -0.894370   -0.355002 -0.592965           -0.099890   
6382  -0.108923     0.093300    0.697155  2.851479            1.783151   
...         ...          ...         ...       ...                 ...   
72714  0.209599    -0.574548    0.093968 -0.084224            0.048339   
72715  0.410044     0.140941    1.545471  0.784710            0.534682   
72716  0.336375     0.706350   -0.225611 -0.316094            0.087200   
72717  0.465916     0.152440   -0.649398  0.648433            0.661659   
72718  0.465916     0.204596    0.822492 -0.260262           -0.112576   

         Height  TotalCholesterol  Triglycerides       LDL       HDL  ...  \
15208 -0.949100          0.573893       0.496366  0.004515  0.470102  ...   
25325 -0.676156          0.027513      -0.418808  0.000788  0.460074  ...   
5132   0.887068          0.164048       0.383587  0.688473 -1.055073  ...   
17217  0.856051          0.206410       0.239340  0.002372 -0.072797  ...   
6382   0.111659          0.796802       0.552888  0.002599  0.944927  ...   
...         ...               ...            ...       ...       ...  ...   
72714  0.529966          0.966537       0.338163  2.847690 -1.107269  ...   
72715 -0.193825          1.002684       1.137561  0.006116  0.578610  ...   
72716  0.850772          0.698204       0.800524  0.005273  0.320829  ...   
72717  0.196053         -0.854465      -0.645063 -1.338104 -0.093582  ...   
72718 -0.754937         -1.171319      -0.645250 -1.650124 -0.583170  ...   

       Race_5.0  Race_1.0  Race_4.0  Race_3.0  Race_2.0  Education   Smoking  \
15208  1.000000       0.0  0.000000 -0.145400   0.00000  -0.656011 -0.319015   
25325  0.000000       1.0  0.000000 -0.145400   0.00000   0.170835 -0.319015   
5132   0.000000       1.0  0.000000 -0.145400   0.00000  -0.656011  0.680985   
17217  0.000000       0.0  3.236622 -0.145400   0.00000  -0.065383  0.680985   
6382   0.000000       0.0  3.236622 -0.145400   0.00000   0.525245  0.680985   
...         ...       ...       ...       ...       ...        ...       ...   
72714  0.000000       0.0  3.236622 -0.145400   0.00000   0.525245  0.672319   
72715  0.000000       0.0  0.000000  0.854600   0.00000  -0.656011  0.680985   
72716  0.402414       0.0  0.000000  0.452186   0.00000   0.409971  0.680985   
72717  0.000000       0.0  0.000000 -0.030279   0.88488   1.115873  0.680985   
72718  0.000000       0.0  0.000000  0.854600   0.00000  -0.067269 -0.315822   

       PhysicalActivity  HealthInsurance   Alcohol  
15208          0.000000              0.0 -1.284779  
25325          0.000000              0.0  0.445085  
5132           0.000000             -1.0  0.118386  
17217          0.000000              0.0  0.445085  
6382           0.000000              0.0  0.451028  
...                 ...              ...       ...  
72714          0.000000              0.0  0.115540  
72715          0.000000              0.0  0.077133  
72716          0.000000              0.0  0.430065  
72717          0.000000              0.0  0.364598  
72718          0.006717              0.0 -0.723887  

[59610 rows x 31 columns]
2025-12-03 11:46:26,244:INFO:get_config() successfully completed......................................
2025-12-03 11:46:26,244:INFO:Initializing get_config()
2025-12-03 11:46:26,244:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FCB038FE80>, variable=y_train)
2025-12-03 11:46:26,244:INFO:Variable: 'y_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_train_transformed' instead.
2025-12-03 11:46:26,249:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_train_transformed' instead.

2025-12-03 11:46:26,256:INFO:Variable:  returned as 15208    0.0
25325    0.0
5132     0.0
17217    0.0
6382     0.0
        ... 
6265     0.0
42694    0.0
13399    0.0
39959    0.0
6616     0.0
Name: HeartDisease, Length: 30586, dtype: float32
2025-12-03 11:46:26,256:INFO:get_config() successfully completed......................................
2025-12-03 11:46:26,256:INFO:Initializing get_config()
2025-12-03 11:46:26,256:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FCB038FE80>, variable=X_test_transformed)
2025-12-03 11:46:26,328:INFO:Variable: X_test returned as             Age  IncomeRatio  SystolicBP       BMI  WaistCircumference  \
28456 -1.166627    -0.346668   -0.856028 -1.444817           -1.505144   
8993   0.144006     0.336748    1.661631  0.616912            0.650918   
34312  0.029038     0.094402    0.120974  0.320615            0.349792   
4802  -1.235607     0.337310   -0.679800 -0.555589           -0.935736   
25895  0.029038     1.529090   -0.455207 -0.552146           -0.411032   
...         ...          ...         ...       ...                 ...   
18045 -1.258601    -0.075240   -0.902556 -1.667039           -1.990961   
5425  -0.085930     0.470814    1.711734 -0.123829           -0.083830   
12819  0.235980     0.002310    0.478266  0.246541            0.711143   
33659 -1.212614     1.325519   -0.862074 -0.975681           -1.485069   
19531 -1.281594    -0.395137   -0.847590 -1.395434           -1.846420   

         Height  TotalCholesterol  Triglycerides       LDL       HDL  ...  \
28456 -1.817558         -0.075919      -0.645504 -0.018918  0.565429  ...   
8993  -0.645140          0.703061       0.628124  0.004972  0.591985  ...   
34312  0.583108         -0.117177       0.871284 -0.747548 -1.113897  ...   
4802  -0.974805         -0.177199      -0.485069  0.000613  0.052365  ...   
25895  0.081554          0.820238       1.262972  0.006556 -0.055073  ...   
...         ...               ...            ...       ...       ...  ...   
18045 -3.281529         -0.317991      -0.645314 -0.614949  0.543115  ...   
5425  -0.006203          0.398401      -0.206369  0.808141  0.297868  ...   
12819  1.513598         -0.679626      -0.644711 -0.152776 -0.819779  ...   
33659 -2.071891         -0.984285      -0.645722 -2.065437  0.297868  ...   
19531 -3.659929         -0.332706      -0.645328 -0.652405  0.543209  ...   

       Race_5.0  Race_1.0  Race_4.0  Race_3.0  Race_2.0  Education   Smoking  \
28456       1.0       0.0  0.000000   -0.1454       0.0  -0.023013 -0.319015   
8993        0.0       0.0  3.236622   -0.1454       0.0   0.525245  0.680985   
34312       0.0       0.0  0.000000    0.8546       0.0  -0.656011 -0.319015   
4802        1.0       0.0  0.000000   -0.1454       0.0   0.246788 -0.245402   
25895       0.0       0.0  0.000000    0.8546       0.0   1.115873 -0.319015   
...         ...       ...       ...       ...       ...        ...       ...   
18045       0.0       0.0  0.000000    0.8546       0.0  -0.786652 -0.319015   
5425        0.0       0.0  3.236622   -0.1454       0.0   0.525245  0.680985   
12819       0.0       0.0  0.000000    0.8546       0.0   1.115873  0.680985   
33659       0.0       0.0  3.236622   -0.1454       0.0   0.242351 -0.319015   
19531       1.0       0.0  0.000000   -0.1454       0.0  -0.813970 -0.319015   

       PhysicalActivity  HealthInsurance   Alcohol  
28456          0.869504              0.0 -0.854408  
8993           0.000000              0.0 -0.112801  
34312          0.000000              0.0  0.445085  
4802           1.332660              0.0 -0.368621  
25895          0.000000              0.0 -1.284779  
...                 ...              ...       ...  
18045          1.190419              0.0 -0.812429  
5425           2.103596              0.0 -0.133319  
12819          2.103596              0.0  0.469341  
33659          1.530139              0.0 -0.428356  
19531          1.041572              0.0 -1.047058  

[13109 rows x 31 columns]
2025-12-03 11:46:26,328:INFO:get_config() successfully completed......................................
2025-12-03 11:46:26,328:INFO:Initializing get_config()
2025-12-03 11:46:26,328:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FCB038FE80>, variable=y_test)
2025-12-03 11:46:26,329:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-12-03 11:46:26,329:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-12-03 11:46:26,333:INFO:Variable:  returned as 28456    0.0
8993     0.0
34312    0.0
4802     0.0
25895    0.0
        ... 
18045    0.0
5425     0.0
12819    0.0
33659    0.0
19531    0.0
Name: HeartDisease, Length: 13109, dtype: float32
2025-12-03 11:46:26,333:INFO:get_config() successfully completed......................................
2025-12-03 11:46:26,459:INFO:Initializing get_config()
2025-12-03 11:46:26,459:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FCB038FE80>, variable=X_test_transformed)
2025-12-03 11:46:26,541:INFO:Variable: X_test returned as             Age  IncomeRatio  SystolicBP       BMI  WaistCircumference  \
28456 -1.166627    -0.346668   -0.856028 -1.444817           -1.505144   
8993   0.144006     0.336748    1.661631  0.616912            0.650918   
34312  0.029038     0.094402    0.120974  0.320615            0.349792   
4802  -1.235607     0.337310   -0.679800 -0.555589           -0.935736   
25895  0.029038     1.529090   -0.455207 -0.552146           -0.411032   
...         ...          ...         ...       ...                 ...   
18045 -1.258601    -0.075240   -0.902556 -1.667039           -1.990961   
5425  -0.085930     0.470814    1.711734 -0.123829           -0.083830   
12819  0.235980     0.002310    0.478266  0.246541            0.711143   
33659 -1.212614     1.325519   -0.862074 -0.975681           -1.485069   
19531 -1.281594    -0.395137   -0.847590 -1.395434           -1.846420   

         Height  TotalCholesterol  Triglycerides       LDL       HDL  ...  \
28456 -1.817558         -0.075919      -0.645504 -0.018918  0.565429  ...   
8993  -0.645140          0.703061       0.628124  0.004972  0.591985  ...   
34312  0.583108         -0.117177       0.871284 -0.747548 -1.113897  ...   
4802  -0.974805         -0.177199      -0.485069  0.000613  0.052365  ...   
25895  0.081554          0.820238       1.262972  0.006556 -0.055073  ...   
...         ...               ...            ...       ...       ...  ...   
18045 -3.281529         -0.317991      -0.645314 -0.614949  0.543115  ...   
5425  -0.006203          0.398401      -0.206369  0.808141  0.297868  ...   
12819  1.513598         -0.679626      -0.644711 -0.152776 -0.819779  ...   
33659 -2.071891         -0.984285      -0.645722 -2.065437  0.297868  ...   
19531 -3.659929         -0.332706      -0.645328 -0.652405  0.543209  ...   

       Race_5.0  Race_1.0  Race_4.0  Race_3.0  Race_2.0  Education   Smoking  \
28456       1.0       0.0  0.000000   -0.1454       0.0  -0.023013 -0.319015   
8993        0.0       0.0  3.236622   -0.1454       0.0   0.525245  0.680985   
34312       0.0       0.0  0.000000    0.8546       0.0  -0.656011 -0.319015   
4802        1.0       0.0  0.000000   -0.1454       0.0   0.246788 -0.245402   
25895       0.0       0.0  0.000000    0.8546       0.0   1.115873 -0.319015   
...         ...       ...       ...       ...       ...        ...       ...   
18045       0.0       0.0  0.000000    0.8546       0.0  -0.786652 -0.319015   
5425        0.0       0.0  3.236622   -0.1454       0.0   0.525245  0.680985   
12819       0.0       0.0  0.000000    0.8546       0.0   1.115873  0.680985   
33659       0.0       0.0  3.236622   -0.1454       0.0   0.242351 -0.319015   
19531       1.0       0.0  0.000000   -0.1454       0.0  -0.813970 -0.319015   

       PhysicalActivity  HealthInsurance   Alcohol  
28456          0.869504              0.0 -0.854408  
8993           0.000000              0.0 -0.112801  
34312          0.000000              0.0  0.445085  
4802           1.332660              0.0 -0.368621  
25895          0.000000              0.0 -1.284779  
...                 ...              ...       ...  
18045          1.190419              0.0 -0.812429  
5425           2.103596              0.0 -0.133319  
12819          2.103596              0.0  0.469341  
33659          1.530139              0.0 -0.428356  
19531          1.041572              0.0 -1.047058  

[13109 rows x 31 columns]
2025-12-03 11:46:26,541:INFO:get_config() successfully completed......................................
2025-12-03 11:46:26,570:INFO:Initializing get_config()
2025-12-03 11:46:26,570:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FCB038FE80>, variable=y_test)
2025-12-03 11:46:26,570:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-12-03 11:46:26,570:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-12-03 11:46:26,575:INFO:Variable:  returned as 28456    0.0
8993     0.0
34312    0.0
4802     0.0
25895    0.0
        ... 
18045    0.0
5425     0.0
12819    0.0
33659    0.0
19531    0.0
Name: HeartDisease, Length: 13109, dtype: float32
2025-12-03 11:46:26,575:INFO:get_config() successfully completed......................................
2025-12-03 11:46:26,578:INFO:Initializing get_config()
2025-12-03 11:46:26,578:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FCB038FE80>, variable=y_test)
2025-12-03 11:46:26,578:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-12-03 11:46:26,578:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-12-03 11:46:26,581:INFO:Variable:  returned as 28456    0.0
8993     0.0
34312    0.0
4802     0.0
25895    0.0
        ... 
18045    0.0
5425     0.0
12819    0.0
33659    0.0
19531    0.0
Name: HeartDisease, Length: 13109, dtype: float32
2025-12-03 11:46:26,581:INFO:get_config() successfully completed......................................
2025-12-03 11:46:26,584:INFO:Initializing get_config()
2025-12-03 11:46:26,584:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FCB038FE80>, variable=X_test_transformed)
2025-12-03 11:46:26,650:INFO:Variable: X_test returned as             Age  IncomeRatio  SystolicBP       BMI  WaistCircumference  \
28456 -1.166627    -0.346668   -0.856028 -1.444817           -1.505144   
8993   0.144006     0.336748    1.661631  0.616912            0.650918   
34312  0.029038     0.094402    0.120974  0.320615            0.349792   
4802  -1.235607     0.337310   -0.679800 -0.555589           -0.935736   
25895  0.029038     1.529090   -0.455207 -0.552146           -0.411032   
...         ...          ...         ...       ...                 ...   
18045 -1.258601    -0.075240   -0.902556 -1.667039           -1.990961   
5425  -0.085930     0.470814    1.711734 -0.123829           -0.083830   
12819  0.235980     0.002310    0.478266  0.246541            0.711143   
33659 -1.212614     1.325519   -0.862074 -0.975681           -1.485069   
19531 -1.281594    -0.395137   -0.847590 -1.395434           -1.846420   

         Height  TotalCholesterol  Triglycerides       LDL       HDL  ...  \
28456 -1.817558         -0.075919      -0.645504 -0.018918  0.565429  ...   
8993  -0.645140          0.703061       0.628124  0.004972  0.591985  ...   
34312  0.583108         -0.117177       0.871284 -0.747548 -1.113897  ...   
4802  -0.974805         -0.177199      -0.485069  0.000613  0.052365  ...   
25895  0.081554          0.820238       1.262972  0.006556 -0.055073  ...   
...         ...               ...            ...       ...       ...  ...   
18045 -3.281529         -0.317991      -0.645314 -0.614949  0.543115  ...   
5425  -0.006203          0.398401      -0.206369  0.808141  0.297868  ...   
12819  1.513598         -0.679626      -0.644711 -0.152776 -0.819779  ...   
33659 -2.071891         -0.984285      -0.645722 -2.065437  0.297868  ...   
19531 -3.659929         -0.332706      -0.645328 -0.652405  0.543209  ...   

       Race_5.0  Race_1.0  Race_4.0  Race_3.0  Race_2.0  Education   Smoking  \
28456       1.0       0.0  0.000000   -0.1454       0.0  -0.023013 -0.319015   
8993        0.0       0.0  3.236622   -0.1454       0.0   0.525245  0.680985   
34312       0.0       0.0  0.000000    0.8546       0.0  -0.656011 -0.319015   
4802        1.0       0.0  0.000000   -0.1454       0.0   0.246788 -0.245402   
25895       0.0       0.0  0.000000    0.8546       0.0   1.115873 -0.319015   
...         ...       ...       ...       ...       ...        ...       ...   
18045       0.0       0.0  0.000000    0.8546       0.0  -0.786652 -0.319015   
5425        0.0       0.0  3.236622   -0.1454       0.0   0.525245  0.680985   
12819       0.0       0.0  0.000000    0.8546       0.0   1.115873  0.680985   
33659       0.0       0.0  3.236622   -0.1454       0.0   0.242351 -0.319015   
19531       1.0       0.0  0.000000   -0.1454       0.0  -0.813970 -0.319015   

       PhysicalActivity  HealthInsurance   Alcohol  
28456          0.869504              0.0 -0.854408  
8993           0.000000              0.0 -0.112801  
34312          0.000000              0.0  0.445085  
4802           1.332660              0.0 -0.368621  
25895          0.000000              0.0 -1.284779  
...                 ...              ...       ...  
18045          1.190419              0.0 -0.812429  
5425           2.103596              0.0 -0.133319  
12819          2.103596              0.0  0.469341  
33659          1.530139              0.0 -0.428356  
19531          1.041572              0.0 -1.047058  

[13109 rows x 31 columns]
2025-12-03 11:46:26,650:INFO:get_config() successfully completed......................................
2025-12-03 11:46:26,652:INFO:Initializing get_config()
2025-12-03 11:46:26,652:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FCB038FE80>, variable=y_test)
2025-12-03 11:46:26,652:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-12-03 11:46:26,652:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-12-03 11:46:26,657:INFO:Variable:  returned as 28456    0.0
8993     0.0
34312    0.0
4802     0.0
25895    0.0
        ... 
18045    0.0
5425     0.0
12819    0.0
33659    0.0
19531    0.0
Name: HeartDisease, Length: 13109, dtype: float32
2025-12-03 11:46:26,657:INFO:get_config() successfully completed......................................
2025-12-03 11:46:26,659:INFO:Initializing get_config()
2025-12-03 11:46:26,659:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FCB038FE80>, variable=y_test)
2025-12-03 11:46:26,659:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-12-03 11:46:26,659:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-12-03 11:46:26,664:INFO:Variable:  returned as 28456    0.0
8993     0.0
34312    0.0
4802     0.0
25895    0.0
        ... 
18045    0.0
5425     0.0
12819    0.0
33659    0.0
19531    0.0
Name: HeartDisease, Length: 13109, dtype: float32
2025-12-03 11:46:26,664:INFO:get_config() successfully completed......................................
2025-12-03 11:46:26,667:INFO:Initializing get_config()
2025-12-03 11:46:26,667:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FCB038FE80>, variable=X_test_transformed)
2025-12-03 11:46:26,738:INFO:Variable: X_test returned as             Age  IncomeRatio  SystolicBP       BMI  WaistCircumference  \
28456 -1.166627    -0.346668   -0.856028 -1.444817           -1.505144   
8993   0.144006     0.336748    1.661631  0.616912            0.650918   
34312  0.029038     0.094402    0.120974  0.320615            0.349792   
4802  -1.235607     0.337310   -0.679800 -0.555589           -0.935736   
25895  0.029038     1.529090   -0.455207 -0.552146           -0.411032   
...         ...          ...         ...       ...                 ...   
18045 -1.258601    -0.075240   -0.902556 -1.667039           -1.990961   
5425  -0.085930     0.470814    1.711734 -0.123829           -0.083830   
12819  0.235980     0.002310    0.478266  0.246541            0.711143   
33659 -1.212614     1.325519   -0.862074 -0.975681           -1.485069   
19531 -1.281594    -0.395137   -0.847590 -1.395434           -1.846420   

         Height  TotalCholesterol  Triglycerides       LDL       HDL  ...  \
28456 -1.817558         -0.075919      -0.645504 -0.018918  0.565429  ...   
8993  -0.645140          0.703061       0.628124  0.004972  0.591985  ...   
34312  0.583108         -0.117177       0.871284 -0.747548 -1.113897  ...   
4802  -0.974805         -0.177199      -0.485069  0.000613  0.052365  ...   
25895  0.081554          0.820238       1.262972  0.006556 -0.055073  ...   
...         ...               ...            ...       ...       ...  ...   
18045 -3.281529         -0.317991      -0.645314 -0.614949  0.543115  ...   
5425  -0.006203          0.398401      -0.206369  0.808141  0.297868  ...   
12819  1.513598         -0.679626      -0.644711 -0.152776 -0.819779  ...   
33659 -2.071891         -0.984285      -0.645722 -2.065437  0.297868  ...   
19531 -3.659929         -0.332706      -0.645328 -0.652405  0.543209  ...   

       Race_5.0  Race_1.0  Race_4.0  Race_3.0  Race_2.0  Education   Smoking  \
28456       1.0       0.0  0.000000   -0.1454       0.0  -0.023013 -0.319015   
8993        0.0       0.0  3.236622   -0.1454       0.0   0.525245  0.680985   
34312       0.0       0.0  0.000000    0.8546       0.0  -0.656011 -0.319015   
4802        1.0       0.0  0.000000   -0.1454       0.0   0.246788 -0.245402   
25895       0.0       0.0  0.000000    0.8546       0.0   1.115873 -0.319015   
...         ...       ...       ...       ...       ...        ...       ...   
18045       0.0       0.0  0.000000    0.8546       0.0  -0.786652 -0.319015   
5425        0.0       0.0  3.236622   -0.1454       0.0   0.525245  0.680985   
12819       0.0       0.0  0.000000    0.8546       0.0   1.115873  0.680985   
33659       0.0       0.0  3.236622   -0.1454       0.0   0.242351 -0.319015   
19531       1.0       0.0  0.000000   -0.1454       0.0  -0.813970 -0.319015   

       PhysicalActivity  HealthInsurance   Alcohol  
28456          0.869504              0.0 -0.854408  
8993           0.000000              0.0 -0.112801  
34312          0.000000              0.0  0.445085  
4802           1.332660              0.0 -0.368621  
25895          0.000000              0.0 -1.284779  
...                 ...              ...       ...  
18045          1.190419              0.0 -0.812429  
5425           2.103596              0.0 -0.133319  
12819          2.103596              0.0  0.469341  
33659          1.530139              0.0 -0.428356  
19531          1.041572              0.0 -1.047058  

[13109 rows x 31 columns]
2025-12-03 11:46:26,740:INFO:get_config() successfully completed......................................
2025-12-03 11:46:26,812:INFO:Initializing get_config()
2025-12-03 11:46:26,812:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FCB038FE80>, variable=y_test)
2025-12-03 11:46:26,812:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-12-03 11:46:26,812:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-12-03 11:46:26,817:INFO:Variable:  returned as 28456    0.0
8993     0.0
34312    0.0
4802     0.0
25895    0.0
        ... 
18045    0.0
5425     0.0
12819    0.0
33659    0.0
19531    0.0
Name: HeartDisease, Length: 13109, dtype: float32
2025-12-03 11:46:26,817:INFO:get_config() successfully completed......................................
2025-12-03 11:46:26,820:INFO:Initializing get_config()
2025-12-03 11:46:26,820:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FCB038FE80>, variable=y_test)
2025-12-03 11:46:26,820:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-12-03 11:46:26,820:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-12-03 11:46:26,823:INFO:Variable:  returned as 28456    0.0
8993     0.0
34312    0.0
4802     0.0
25895    0.0
        ... 
18045    0.0
5425     0.0
12819    0.0
33659    0.0
19531    0.0
Name: HeartDisease, Length: 13109, dtype: float32
2025-12-03 11:46:26,823:INFO:get_config() successfully completed......................................
2025-12-03 11:46:26,829:INFO:Initializing get_config()
2025-12-03 11:46:26,829:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FCB038FE80>, variable=y_test)
2025-12-03 11:46:26,829:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-12-03 11:46:26,829:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-12-03 11:46:26,838:INFO:Variable:  returned as 28456    0.0
8993     0.0
34312    0.0
4802     0.0
25895    0.0
        ... 
18045    0.0
5425     0.0
12819    0.0
33659    0.0
19531    0.0
Name: HeartDisease, Length: 13109, dtype: float32
2025-12-03 11:46:26,838:INFO:get_config() successfully completed......................................
2025-12-03 11:46:26,838:INFO:Initializing get_config()
2025-12-03 11:46:26,838:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FCB038FE80>, variable=X_test_transformed)
2025-12-03 11:46:26,909:INFO:Variable: X_test returned as             Age  IncomeRatio  SystolicBP       BMI  WaistCircumference  \
28456 -1.166627    -0.346668   -0.856028 -1.444817           -1.505144   
8993   0.144006     0.336748    1.661631  0.616912            0.650918   
34312  0.029038     0.094402    0.120974  0.320615            0.349792   
4802  -1.235607     0.337310   -0.679800 -0.555589           -0.935736   
25895  0.029038     1.529090   -0.455207 -0.552146           -0.411032   
...         ...          ...         ...       ...                 ...   
18045 -1.258601    -0.075240   -0.902556 -1.667039           -1.990961   
5425  -0.085930     0.470814    1.711734 -0.123829           -0.083830   
12819  0.235980     0.002310    0.478266  0.246541            0.711143   
33659 -1.212614     1.325519   -0.862074 -0.975681           -1.485069   
19531 -1.281594    -0.395137   -0.847590 -1.395434           -1.846420   

         Height  TotalCholesterol  Triglycerides       LDL       HDL  ...  \
28456 -1.817558         -0.075919      -0.645504 -0.018918  0.565429  ...   
8993  -0.645140          0.703061       0.628124  0.004972  0.591985  ...   
34312  0.583108         -0.117177       0.871284 -0.747548 -1.113897  ...   
4802  -0.974805         -0.177199      -0.485069  0.000613  0.052365  ...   
25895  0.081554          0.820238       1.262972  0.006556 -0.055073  ...   
...         ...               ...            ...       ...       ...  ...   
18045 -3.281529         -0.317991      -0.645314 -0.614949  0.543115  ...   
5425  -0.006203          0.398401      -0.206369  0.808141  0.297868  ...   
12819  1.513598         -0.679626      -0.644711 -0.152776 -0.819779  ...   
33659 -2.071891         -0.984285      -0.645722 -2.065437  0.297868  ...   
19531 -3.659929         -0.332706      -0.645328 -0.652405  0.543209  ...   

       Race_5.0  Race_1.0  Race_4.0  Race_3.0  Race_2.0  Education   Smoking  \
28456       1.0       0.0  0.000000   -0.1454       0.0  -0.023013 -0.319015   
8993        0.0       0.0  3.236622   -0.1454       0.0   0.525245  0.680985   
34312       0.0       0.0  0.000000    0.8546       0.0  -0.656011 -0.319015   
4802        1.0       0.0  0.000000   -0.1454       0.0   0.246788 -0.245402   
25895       0.0       0.0  0.000000    0.8546       0.0   1.115873 -0.319015   
...         ...       ...       ...       ...       ...        ...       ...   
18045       0.0       0.0  0.000000    0.8546       0.0  -0.786652 -0.319015   
5425        0.0       0.0  3.236622   -0.1454       0.0   0.525245  0.680985   
12819       0.0       0.0  0.000000    0.8546       0.0   1.115873  0.680985   
33659       0.0       0.0  3.236622   -0.1454       0.0   0.242351 -0.319015   
19531       1.0       0.0  0.000000   -0.1454       0.0  -0.813970 -0.319015   

       PhysicalActivity  HealthInsurance   Alcohol  
28456          0.869504              0.0 -0.854408  
8993           0.000000              0.0 -0.112801  
34312          0.000000              0.0  0.445085  
4802           1.332660              0.0 -0.368621  
25895          0.000000              0.0 -1.284779  
...                 ...              ...       ...  
18045          1.190419              0.0 -0.812429  
5425           2.103596              0.0 -0.133319  
12819          2.103596              0.0  0.469341  
33659          1.530139              0.0 -0.428356  
19531          1.041572              0.0 -1.047058  

[13109 rows x 31 columns]
2025-12-03 11:46:26,909:INFO:get_config() successfully completed......................................
2025-12-03 11:46:26,941:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pandas\io\formats\style.py:3823: RuntimeWarning: invalid value encountered in scalar multiply

2025-12-03 11:46:26,986:INFO:Initializing plot_model()
2025-12-03 11:46:26,986:INFO:plot_model(plot=error, fold=None, verbose=True, display=None, display_format=None, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FCB038FE80>, system=True)
2025-12-03 11:46:26,986:INFO:Checking exceptions
2025-12-03 11:46:27,008:INFO:Preloading libraries
2025-12-03 11:46:27,013:INFO:Copying training dataset
2025-12-03 11:46:27,013:INFO:Plot type: error
2025-12-03 11:46:27,238:INFO:Fitting Model
2025-12-03 11:46:27,239:INFO:Scoring test/hold-out set
2025-12-03 11:46:27,405:INFO:Visual Rendered Successfully
2025-12-03 11:46:27,582:INFO:plot_model() successfully completed......................................
2025-12-03 11:46:27,582:INFO:Initializing get_config()
2025-12-03 11:46:27,582:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FCB038FE80>, variable=train_transformed)
2025-12-03 11:46:27,626:INFO:Variable: train returned as             Age  IncomeRatio  SystolicBP       BMI  WaistCircumference  \
15208  0.281967     1.073479   -0.029334  0.320615           -0.184205   
25325 -0.959685     0.336748   -1.131593 -1.420125           -1.360604   
5132  -0.499814    -0.472688   -0.718246 -0.222594           -0.051710   
17217 -0.177904    -0.894370   -0.355002 -0.592965           -0.099890   
6382  -0.108923     0.093300    0.697155  2.851479            1.783151   
...         ...          ...         ...       ...                 ...   
72714  0.209599    -0.574548    0.093968 -0.084224            0.048339   
72715  0.410044     0.140941    1.545471  0.784710            0.534682   
72716  0.336375     0.706350   -0.225611 -0.316094            0.087200   
72717  0.465916     0.152440   -0.649398  0.648433            0.661659   
72718  0.465916     0.204596    0.822492 -0.260262           -0.112576   

         Height  TotalCholesterol  Triglycerides       LDL       HDL  ...  \
15208 -0.949100          0.573893       0.496366  0.004515  0.470102  ...   
25325 -0.676156          0.027513      -0.418808  0.000788  0.460074  ...   
5132   0.887068          0.164048       0.383587  0.688473 -1.055073  ...   
17217  0.856051          0.206410       0.239340  0.002372 -0.072797  ...   
6382   0.111659          0.796802       0.552888  0.002599  0.944927  ...   
...         ...               ...            ...       ...       ...  ...   
72714  0.529966          0.966537       0.338163  2.847690 -1.107269  ...   
72715 -0.193825          1.002684       1.137561  0.006116  0.578610  ...   
72716  0.850772          0.698204       0.800524  0.005273  0.320829  ...   
72717  0.196053         -0.854465      -0.645063 -1.338104 -0.093582  ...   
72718 -0.754937         -1.171319      -0.645250 -1.650124 -0.583170  ...   

       Race_1.0  Race_4.0  Race_3.0  Race_2.0  Education   Smoking  \
15208       0.0  0.000000 -0.145400   0.00000  -0.656011 -0.319015   
25325       1.0  0.000000 -0.145400   0.00000   0.170835 -0.319015   
5132        1.0  0.000000 -0.145400   0.00000  -0.656011  0.680985   
17217       0.0  3.236622 -0.145400   0.00000  -0.065383  0.680985   
6382        0.0  3.236622 -0.145400   0.00000   0.525245  0.680985   
...         ...       ...       ...       ...        ...       ...   
72714       0.0  3.236622 -0.145400   0.00000   0.525245  0.672319   
72715       0.0  0.000000  0.854600   0.00000  -0.656011  0.680985   
72716       0.0  0.000000  0.452186   0.00000   0.409971  0.680985   
72717       0.0  0.000000 -0.030279   0.88488   1.115873  0.680985   
72718       0.0  0.000000  0.854600   0.00000  -0.067269 -0.315822   

       PhysicalActivity  HealthInsurance   Alcohol  HeartDisease  
15208          0.000000              0.0 -1.284779           0.0  
25325          0.000000              0.0  0.445085           0.0  
5132           0.000000             -1.0  0.118386           0.0  
17217          0.000000              0.0  0.445085           0.0  
6382           0.000000              0.0  0.451028           0.0  
...                 ...              ...       ...           ...  
72714          0.000000              0.0  0.115540           1.0  
72715          0.000000              0.0  0.077133           1.0  
72716          0.000000              0.0  0.430065           1.0  
72717          0.000000              0.0  0.364598           1.0  
72718          0.006717              0.0 -0.723887           1.0  

[59610 rows x 32 columns]
2025-12-03 11:46:27,626:INFO:get_config() successfully completed......................................
2025-12-03 11:46:27,626:INFO:Initializing get_config()
2025-12-03 11:46:27,626:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FCB038FE80>, variable=target_param)
2025-12-03 11:46:27,626:INFO:Variable:  returned as HeartDisease
2025-12-03 11:46:27,626:INFO:get_config() successfully completed......................................
2025-12-03 11:46:37,020:INFO:Initializing get_config()
2025-12-03 11:46:37,023:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FCB038FE80>, variable=X_test_transformed)
2025-12-03 11:46:37,104:INFO:Variable: X_test returned as             Age  IncomeRatio  SystolicBP       BMI  WaistCircumference  \
28456 -1.166627    -0.346668   -0.856028 -1.444817           -1.505144   
8993   0.144006     0.336748    1.661631  0.616912            0.650918   
34312  0.029038     0.094402    0.120974  0.320615            0.349792   
4802  -1.235607     0.337310   -0.679800 -0.555589           -0.935736   
25895  0.029038     1.529090   -0.455207 -0.552146           -0.411032   
...         ...          ...         ...       ...                 ...   
18045 -1.258601    -0.075240   -0.902556 -1.667039           -1.990961   
5425  -0.085930     0.470814    1.711734 -0.123829           -0.083830   
12819  0.235980     0.002310    0.478266  0.246541            0.711143   
33659 -1.212614     1.325519   -0.862074 -0.975681           -1.485069   
19531 -1.281594    -0.395137   -0.847590 -1.395434           -1.846420   

         Height  TotalCholesterol  Triglycerides       LDL       HDL  ...  \
28456 -1.817558         -0.075919      -0.645504 -0.018918  0.565429  ...   
8993  -0.645140          0.703061       0.628124  0.004972  0.591985  ...   
34312  0.583108         -0.117177       0.871284 -0.747548 -1.113897  ...   
4802  -0.974805         -0.177199      -0.485069  0.000613  0.052365  ...   
25895  0.081554          0.820238       1.262972  0.006556 -0.055073  ...   
...         ...               ...            ...       ...       ...  ...   
18045 -3.281529         -0.317991      -0.645314 -0.614949  0.543115  ...   
5425  -0.006203          0.398401      -0.206369  0.808141  0.297868  ...   
12819  1.513598         -0.679626      -0.644711 -0.152776 -0.819779  ...   
33659 -2.071891         -0.984285      -0.645722 -2.065437  0.297868  ...   
19531 -3.659929         -0.332706      -0.645328 -0.652405  0.543209  ...   

       Race_5.0  Race_1.0  Race_4.0  Race_3.0  Race_2.0  Education   Smoking  \
28456       1.0       0.0  0.000000   -0.1454       0.0  -0.023013 -0.319015   
8993        0.0       0.0  3.236622   -0.1454       0.0   0.525245  0.680985   
34312       0.0       0.0  0.000000    0.8546       0.0  -0.656011 -0.319015   
4802        1.0       0.0  0.000000   -0.1454       0.0   0.246788 -0.245402   
25895       0.0       0.0  0.000000    0.8546       0.0   1.115873 -0.319015   
...         ...       ...       ...       ...       ...        ...       ...   
18045       0.0       0.0  0.000000    0.8546       0.0  -0.786652 -0.319015   
5425        0.0       0.0  3.236622   -0.1454       0.0   0.525245  0.680985   
12819       0.0       0.0  0.000000    0.8546       0.0   1.115873  0.680985   
33659       0.0       0.0  3.236622   -0.1454       0.0   0.242351 -0.319015   
19531       1.0       0.0  0.000000   -0.1454       0.0  -0.813970 -0.319015   

       PhysicalActivity  HealthInsurance   Alcohol  
28456          0.869504              0.0 -0.854408  
8993           0.000000              0.0 -0.112801  
34312          0.000000              0.0  0.445085  
4802           1.332660              0.0 -0.368621  
25895          0.000000              0.0 -1.284779  
...                 ...              ...       ...  
18045          1.190419              0.0 -0.812429  
5425           2.103596              0.0 -0.133319  
12819          2.103596              0.0  0.469341  
33659          1.530139              0.0 -0.428356  
19531          1.041572              0.0 -1.047058  

[13109 rows x 31 columns]
2025-12-03 11:46:37,104:INFO:get_config() successfully completed......................................
2025-12-03 11:46:37,131:INFO:Initializing get_config()
2025-12-03 11:46:37,131:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FCB038FE80>, variable=y_test)
2025-12-03 11:46:37,131:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-12-03 11:46:37,131:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-12-03 11:46:37,134:INFO:Variable:  returned as 28456    0.0
8993     0.0
34312    0.0
4802     0.0
25895    0.0
        ... 
18045    0.0
5425     0.0
12819    0.0
33659    0.0
19531    0.0
Name: HeartDisease, Length: 13109, dtype: float32
2025-12-03 11:46:37,134:INFO:get_config() successfully completed......................................
2025-12-03 11:46:37,138:INFO:Initializing get_config()
2025-12-03 11:46:37,138:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FCB038FE80>, variable=y_test)
2025-12-03 11:46:37,138:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-12-03 11:46:37,138:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-12-03 11:46:37,141:INFO:Variable:  returned as 28456    0.0
8993     0.0
34312    0.0
4802     0.0
25895    0.0
        ... 
18045    0.0
5425     0.0
12819    0.0
33659    0.0
19531    0.0
Name: HeartDisease, Length: 13109, dtype: float32
2025-12-03 11:46:37,141:INFO:get_config() successfully completed......................................
2025-12-03 11:46:37,147:INFO:Initializing get_config()
2025-12-03 11:46:37,147:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FCB038FE80>, variable=X_test_transformed)
2025-12-03 11:46:37,226:INFO:Variable: X_test returned as             Age  IncomeRatio  SystolicBP       BMI  WaistCircumference  \
28456 -1.166627    -0.346668   -0.856028 -1.444817           -1.505144   
8993   0.144006     0.336748    1.661631  0.616912            0.650918   
34312  0.029038     0.094402    0.120974  0.320615            0.349792   
4802  -1.235607     0.337310   -0.679800 -0.555589           -0.935736   
25895  0.029038     1.529090   -0.455207 -0.552146           -0.411032   
...         ...          ...         ...       ...                 ...   
18045 -1.258601    -0.075240   -0.902556 -1.667039           -1.990961   
5425  -0.085930     0.470814    1.711734 -0.123829           -0.083830   
12819  0.235980     0.002310    0.478266  0.246541            0.711143   
33659 -1.212614     1.325519   -0.862074 -0.975681           -1.485069   
19531 -1.281594    -0.395137   -0.847590 -1.395434           -1.846420   

         Height  TotalCholesterol  Triglycerides       LDL       HDL  ...  \
28456 -1.817558         -0.075919      -0.645504 -0.018918  0.565429  ...   
8993  -0.645140          0.703061       0.628124  0.004972  0.591985  ...   
34312  0.583108         -0.117177       0.871284 -0.747548 -1.113897  ...   
4802  -0.974805         -0.177199      -0.485069  0.000613  0.052365  ...   
25895  0.081554          0.820238       1.262972  0.006556 -0.055073  ...   
...         ...               ...            ...       ...       ...  ...   
18045 -3.281529         -0.317991      -0.645314 -0.614949  0.543115  ...   
5425  -0.006203          0.398401      -0.206369  0.808141  0.297868  ...   
12819  1.513598         -0.679626      -0.644711 -0.152776 -0.819779  ...   
33659 -2.071891         -0.984285      -0.645722 -2.065437  0.297868  ...   
19531 -3.659929         -0.332706      -0.645328 -0.652405  0.543209  ...   

       Race_5.0  Race_1.0  Race_4.0  Race_3.0  Race_2.0  Education   Smoking  \
28456       1.0       0.0  0.000000   -0.1454       0.0  -0.023013 -0.319015   
8993        0.0       0.0  3.236622   -0.1454       0.0   0.525245  0.680985   
34312       0.0       0.0  0.000000    0.8546       0.0  -0.656011 -0.319015   
4802        1.0       0.0  0.000000   -0.1454       0.0   0.246788 -0.245402   
25895       0.0       0.0  0.000000    0.8546       0.0   1.115873 -0.319015   
...         ...       ...       ...       ...       ...        ...       ...   
18045       0.0       0.0  0.000000    0.8546       0.0  -0.786652 -0.319015   
5425        0.0       0.0  3.236622   -0.1454       0.0   0.525245  0.680985   
12819       0.0       0.0  0.000000    0.8546       0.0   1.115873  0.680985   
33659       0.0       0.0  3.236622   -0.1454       0.0   0.242351 -0.319015   
19531       1.0       0.0  0.000000   -0.1454       0.0  -0.813970 -0.319015   

       PhysicalActivity  HealthInsurance   Alcohol  
28456          0.869504              0.0 -0.854408  
8993           0.000000              0.0 -0.112801  
34312          0.000000              0.0  0.445085  
4802           1.332660              0.0 -0.368621  
25895          0.000000              0.0 -1.284779  
...                 ...              ...       ...  
18045          1.190419              0.0 -0.812429  
5425           2.103596              0.0 -0.133319  
12819          2.103596              0.0  0.469341  
33659          1.530139              0.0 -0.428356  
19531          1.041572              0.0 -1.047058  

[13109 rows x 31 columns]
2025-12-03 11:46:37,226:INFO:get_config() successfully completed......................................
2025-12-03 11:46:37,228:INFO:Initializing get_config()
2025-12-03 11:46:37,228:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FCB038FE80>, variable=y_test)
2025-12-03 11:46:37,230:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-12-03 11:46:37,230:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-12-03 11:46:37,234:INFO:Variable:  returned as 28456    0.0
8993     0.0
34312    0.0
4802     0.0
25895    0.0
        ... 
18045    0.0
5425     0.0
12819    0.0
33659    0.0
19531    0.0
Name: HeartDisease, Length: 13109, dtype: float32
2025-12-03 11:46:37,234:INFO:get_config() successfully completed......................................
2025-12-03 11:46:37,235:INFO:Initializing get_config()
2025-12-03 11:46:37,235:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FCB038FE80>, variable=y_test)
2025-12-03 11:46:37,235:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-12-03 11:46:37,235:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-12-03 11:46:37,239:INFO:Variable:  returned as 28456    0.0
8993     0.0
34312    0.0
4802     0.0
25895    0.0
        ... 
18045    0.0
5425     0.0
12819    0.0
33659    0.0
19531    0.0
Name: HeartDisease, Length: 13109, dtype: float32
2025-12-03 11:46:37,240:INFO:get_config() successfully completed......................................
2025-12-03 11:46:37,243:INFO:Initializing get_config()
2025-12-03 11:46:37,243:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FCB038FE80>, variable=X_test_transformed)
2025-12-03 11:46:37,326:INFO:Variable: X_test returned as             Age  IncomeRatio  SystolicBP       BMI  WaistCircumference  \
28456 -1.166627    -0.346668   -0.856028 -1.444817           -1.505144   
8993   0.144006     0.336748    1.661631  0.616912            0.650918   
34312  0.029038     0.094402    0.120974  0.320615            0.349792   
4802  -1.235607     0.337310   -0.679800 -0.555589           -0.935736   
25895  0.029038     1.529090   -0.455207 -0.552146           -0.411032   
...         ...          ...         ...       ...                 ...   
18045 -1.258601    -0.075240   -0.902556 -1.667039           -1.990961   
5425  -0.085930     0.470814    1.711734 -0.123829           -0.083830   
12819  0.235980     0.002310    0.478266  0.246541            0.711143   
33659 -1.212614     1.325519   -0.862074 -0.975681           -1.485069   
19531 -1.281594    -0.395137   -0.847590 -1.395434           -1.846420   

         Height  TotalCholesterol  Triglycerides       LDL       HDL  ...  \
28456 -1.817558         -0.075919      -0.645504 -0.018918  0.565429  ...   
8993  -0.645140          0.703061       0.628124  0.004972  0.591985  ...   
34312  0.583108         -0.117177       0.871284 -0.747548 -1.113897  ...   
4802  -0.974805         -0.177199      -0.485069  0.000613  0.052365  ...   
25895  0.081554          0.820238       1.262972  0.006556 -0.055073  ...   
...         ...               ...            ...       ...       ...  ...   
18045 -3.281529         -0.317991      -0.645314 -0.614949  0.543115  ...   
5425  -0.006203          0.398401      -0.206369  0.808141  0.297868  ...   
12819  1.513598         -0.679626      -0.644711 -0.152776 -0.819779  ...   
33659 -2.071891         -0.984285      -0.645722 -2.065437  0.297868  ...   
19531 -3.659929         -0.332706      -0.645328 -0.652405  0.543209  ...   

       Race_5.0  Race_1.0  Race_4.0  Race_3.0  Race_2.0  Education   Smoking  \
28456       1.0       0.0  0.000000   -0.1454       0.0  -0.023013 -0.319015   
8993        0.0       0.0  3.236622   -0.1454       0.0   0.525245  0.680985   
34312       0.0       0.0  0.000000    0.8546       0.0  -0.656011 -0.319015   
4802        1.0       0.0  0.000000   -0.1454       0.0   0.246788 -0.245402   
25895       0.0       0.0  0.000000    0.8546       0.0   1.115873 -0.319015   
...         ...       ...       ...       ...       ...        ...       ...   
18045       0.0       0.0  0.000000    0.8546       0.0  -0.786652 -0.319015   
5425        0.0       0.0  3.236622   -0.1454       0.0   0.525245  0.680985   
12819       0.0       0.0  0.000000    0.8546       0.0   1.115873  0.680985   
33659       0.0       0.0  3.236622   -0.1454       0.0   0.242351 -0.319015   
19531       1.0       0.0  0.000000   -0.1454       0.0  -0.813970 -0.319015   

       PhysicalActivity  HealthInsurance   Alcohol  
28456          0.869504              0.0 -0.854408  
8993           0.000000              0.0 -0.112801  
34312          0.000000              0.0  0.445085  
4802           1.332660              0.0 -0.368621  
25895          0.000000              0.0 -1.284779  
...                 ...              ...       ...  
18045          1.190419              0.0 -0.812429  
5425           2.103596              0.0 -0.133319  
12819          2.103596              0.0  0.469341  
33659          1.530139              0.0 -0.428356  
19531          1.041572              0.0 -1.047058  

[13109 rows x 31 columns]
2025-12-03 11:46:37,326:INFO:get_config() successfully completed......................................
2025-12-03 11:46:37,406:INFO:Initializing get_config()
2025-12-03 11:46:37,406:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FCB038FE80>, variable=y_test)
2025-12-03 11:46:37,406:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-12-03 11:46:37,406:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-12-03 11:46:37,411:INFO:Variable:  returned as 28456    0.0
8993     0.0
34312    0.0
4802     0.0
25895    0.0
        ... 
18045    0.0
5425     0.0
12819    0.0
33659    0.0
19531    0.0
Name: HeartDisease, Length: 13109, dtype: float32
2025-12-03 11:46:37,411:INFO:get_config() successfully completed......................................
2025-12-03 11:46:37,411:INFO:Initializing get_config()
2025-12-03 11:46:37,411:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FCB038FE80>, variable=y_test)
2025-12-03 11:46:37,411:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-12-03 11:46:37,411:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-12-03 11:46:37,419:INFO:Variable:  returned as 28456    0.0
8993     0.0
34312    0.0
4802     0.0
25895    0.0
        ... 
18045    0.0
5425     0.0
12819    0.0
33659    0.0
19531    0.0
Name: HeartDisease, Length: 13109, dtype: float32
2025-12-03 11:46:37,419:INFO:get_config() successfully completed......................................
2025-12-03 11:46:37,588:INFO:Initializing get_config()
2025-12-03 11:46:37,588:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FCB038FE80>, variable=X_test_transformed)
2025-12-03 11:46:37,679:INFO:Variable: X_test returned as             Age  IncomeRatio  SystolicBP       BMI  WaistCircumference  \
28456 -1.166627    -0.346668   -0.856028 -1.444817           -1.505144   
8993   0.144006     0.336748    1.661631  0.616912            0.650918   
34312  0.029038     0.094402    0.120974  0.320615            0.349792   
4802  -1.235607     0.337310   -0.679800 -0.555589           -0.935736   
25895  0.029038     1.529090   -0.455207 -0.552146           -0.411032   
...         ...          ...         ...       ...                 ...   
18045 -1.258601    -0.075240   -0.902556 -1.667039           -1.990961   
5425  -0.085930     0.470814    1.711734 -0.123829           -0.083830   
12819  0.235980     0.002310    0.478266  0.246541            0.711143   
33659 -1.212614     1.325519   -0.862074 -0.975681           -1.485069   
19531 -1.281594    -0.395137   -0.847590 -1.395434           -1.846420   

         Height  TotalCholesterol  Triglycerides       LDL       HDL  ...  \
28456 -1.817558         -0.075919      -0.645504 -0.018918  0.565429  ...   
8993  -0.645140          0.703061       0.628124  0.004972  0.591985  ...   
34312  0.583108         -0.117177       0.871284 -0.747548 -1.113897  ...   
4802  -0.974805         -0.177199      -0.485069  0.000613  0.052365  ...   
25895  0.081554          0.820238       1.262972  0.006556 -0.055073  ...   
...         ...               ...            ...       ...       ...  ...   
18045 -3.281529         -0.317991      -0.645314 -0.614949  0.543115  ...   
5425  -0.006203          0.398401      -0.206369  0.808141  0.297868  ...   
12819  1.513598         -0.679626      -0.644711 -0.152776 -0.819779  ...   
33659 -2.071891         -0.984285      -0.645722 -2.065437  0.297868  ...   
19531 -3.659929         -0.332706      -0.645328 -0.652405  0.543209  ...   

       Race_5.0  Race_1.0  Race_4.0  Race_3.0  Race_2.0  Education   Smoking  \
28456       1.0       0.0  0.000000   -0.1454       0.0  -0.023013 -0.319015   
8993        0.0       0.0  3.236622   -0.1454       0.0   0.525245  0.680985   
34312       0.0       0.0  0.000000    0.8546       0.0  -0.656011 -0.319015   
4802        1.0       0.0  0.000000   -0.1454       0.0   0.246788 -0.245402   
25895       0.0       0.0  0.000000    0.8546       0.0   1.115873 -0.319015   
...         ...       ...       ...       ...       ...        ...       ...   
18045       0.0       0.0  0.000000    0.8546       0.0  -0.786652 -0.319015   
5425        0.0       0.0  3.236622   -0.1454       0.0   0.525245  0.680985   
12819       0.0       0.0  0.000000    0.8546       0.0   1.115873  0.680985   
33659       0.0       0.0  3.236622   -0.1454       0.0   0.242351 -0.319015   
19531       1.0       0.0  0.000000   -0.1454       0.0  -0.813970 -0.319015   

       PhysicalActivity  HealthInsurance   Alcohol  
28456          0.869504              0.0 -0.854408  
8993           0.000000              0.0 -0.112801  
34312          0.000000              0.0  0.445085  
4802           1.332660              0.0 -0.368621  
25895          0.000000              0.0 -1.284779  
...                 ...              ...       ...  
18045          1.190419              0.0 -0.812429  
5425           2.103596              0.0 -0.133319  
12819          2.103596              0.0  0.469341  
33659          1.530139              0.0 -0.428356  
19531          1.041572              0.0 -1.047058  

[13109 rows x 31 columns]
2025-12-03 11:46:37,679:INFO:get_config() successfully completed......................................
2025-12-03 11:46:37,706:INFO:Initializing get_config()
2025-12-03 11:46:37,706:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FCB038FE80>, variable=y_test)
2025-12-03 11:46:37,706:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-12-03 11:46:37,706:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-12-03 11:46:37,709:INFO:Variable:  returned as 28456    0.0
8993     0.0
34312    0.0
4802     0.0
25895    0.0
        ... 
18045    0.0
5425     0.0
12819    0.0
33659    0.0
19531    0.0
Name: HeartDisease, Length: 13109, dtype: float32
2025-12-03 11:46:37,712:INFO:get_config() successfully completed......................................
2025-12-03 11:46:37,978:INFO:Initializing get_config()
2025-12-03 11:46:37,978:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FCB038FE80>, variable=y_test)
2025-12-03 11:46:37,978:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-12-03 11:46:37,978:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-12-03 11:46:37,984:INFO:Variable:  returned as 28456    0.0
8993     0.0
34312    0.0
4802     0.0
25895    0.0
        ... 
18045    0.0
5425     0.0
12819    0.0
33659    0.0
19531    0.0
Name: HeartDisease, Length: 13109, dtype: float32
2025-12-03 11:46:37,984:INFO:get_config() successfully completed......................................
2025-12-03 11:46:37,984:INFO:Initializing get_config()
2025-12-03 11:46:37,984:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FCB038FE80>, variable=X_test_transformed)
2025-12-03 11:46:38,062:INFO:Variable: X_test returned as             Age  IncomeRatio  SystolicBP       BMI  WaistCircumference  \
28456 -1.166627    -0.346668   -0.856028 -1.444817           -1.505144   
8993   0.144006     0.336748    1.661631  0.616912            0.650918   
34312  0.029038     0.094402    0.120974  0.320615            0.349792   
4802  -1.235607     0.337310   -0.679800 -0.555589           -0.935736   
25895  0.029038     1.529090   -0.455207 -0.552146           -0.411032   
...         ...          ...         ...       ...                 ...   
18045 -1.258601    -0.075240   -0.902556 -1.667039           -1.990961   
5425  -0.085930     0.470814    1.711734 -0.123829           -0.083830   
12819  0.235980     0.002310    0.478266  0.246541            0.711143   
33659 -1.212614     1.325519   -0.862074 -0.975681           -1.485069   
19531 -1.281594    -0.395137   -0.847590 -1.395434           -1.846420   

         Height  TotalCholesterol  Triglycerides       LDL       HDL  ...  \
28456 -1.817558         -0.075919      -0.645504 -0.018918  0.565429  ...   
8993  -0.645140          0.703061       0.628124  0.004972  0.591985  ...   
34312  0.583108         -0.117177       0.871284 -0.747548 -1.113897  ...   
4802  -0.974805         -0.177199      -0.485069  0.000613  0.052365  ...   
25895  0.081554          0.820238       1.262972  0.006556 -0.055073  ...   
...         ...               ...            ...       ...       ...  ...   
18045 -3.281529         -0.317991      -0.645314 -0.614949  0.543115  ...   
5425  -0.006203          0.398401      -0.206369  0.808141  0.297868  ...   
12819  1.513598         -0.679626      -0.644711 -0.152776 -0.819779  ...   
33659 -2.071891         -0.984285      -0.645722 -2.065437  0.297868  ...   
19531 -3.659929         -0.332706      -0.645328 -0.652405  0.543209  ...   

       Race_5.0  Race_1.0  Race_4.0  Race_3.0  Race_2.0  Education   Smoking  \
28456       1.0       0.0  0.000000   -0.1454       0.0  -0.023013 -0.319015   
8993        0.0       0.0  3.236622   -0.1454       0.0   0.525245  0.680985   
34312       0.0       0.0  0.000000    0.8546       0.0  -0.656011 -0.319015   
4802        1.0       0.0  0.000000   -0.1454       0.0   0.246788 -0.245402   
25895       0.0       0.0  0.000000    0.8546       0.0   1.115873 -0.319015   
...         ...       ...       ...       ...       ...        ...       ...   
18045       0.0       0.0  0.000000    0.8546       0.0  -0.786652 -0.319015   
5425        0.0       0.0  3.236622   -0.1454       0.0   0.525245  0.680985   
12819       0.0       0.0  0.000000    0.8546       0.0   1.115873  0.680985   
33659       0.0       0.0  3.236622   -0.1454       0.0   0.242351 -0.319015   
19531       1.0       0.0  0.000000   -0.1454       0.0  -0.813970 -0.319015   

       PhysicalActivity  HealthInsurance   Alcohol  
28456          0.869504              0.0 -0.854408  
8993           0.000000              0.0 -0.112801  
34312          0.000000              0.0  0.445085  
4802           1.332660              0.0 -0.368621  
25895          0.000000              0.0 -1.284779  
...                 ...              ...       ...  
18045          1.190419              0.0 -0.812429  
5425           2.103596              0.0 -0.133319  
12819          2.103596              0.0  0.469341  
33659          1.530139              0.0 -0.428356  
19531          1.041572              0.0 -1.047058  

[13109 rows x 31 columns]
2025-12-03 11:46:38,062:INFO:get_config() successfully completed......................................
2025-12-03 11:46:38,155:INFO:Initializing get_config()
2025-12-03 11:46:38,155:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FCB038FE80>, variable=X_train_transformed)
2025-12-03 11:46:38,203:INFO:Variable: X_train returned as             Age  IncomeRatio  SystolicBP       BMI  WaistCircumference  \
15208  0.281967     1.073479   -0.029334  0.320615           -0.184205   
25325 -0.959685     0.336748   -1.131593 -1.420125           -1.360604   
5132  -0.499814    -0.472688   -0.718246 -0.222594           -0.051710   
17217 -0.177904    -0.894370   -0.355002 -0.592965           -0.099890   
6382  -0.108923     0.093300    0.697155  2.851479            1.783151   
...         ...          ...         ...       ...                 ...   
72714  0.209599    -0.574548    0.093968 -0.084224            0.048339   
72715  0.410044     0.140941    1.545471  0.784710            0.534682   
72716  0.336375     0.706350   -0.225611 -0.316094            0.087200   
72717  0.465916     0.152440   -0.649398  0.648433            0.661659   
72718  0.465916     0.204596    0.822492 -0.260262           -0.112576   

         Height  TotalCholesterol  Triglycerides       LDL       HDL  ...  \
15208 -0.949100          0.573893       0.496366  0.004515  0.470102  ...   
25325 -0.676156          0.027513      -0.418808  0.000788  0.460074  ...   
5132   0.887068          0.164048       0.383587  0.688473 -1.055073  ...   
17217  0.856051          0.206410       0.239340  0.002372 -0.072797  ...   
6382   0.111659          0.796802       0.552888  0.002599  0.944927  ...   
...         ...               ...            ...       ...       ...  ...   
72714  0.529966          0.966537       0.338163  2.847690 -1.107269  ...   
72715 -0.193825          1.002684       1.137561  0.006116  0.578610  ...   
72716  0.850772          0.698204       0.800524  0.005273  0.320829  ...   
72717  0.196053         -0.854465      -0.645063 -1.338104 -0.093582  ...   
72718 -0.754937         -1.171319      -0.645250 -1.650124 -0.583170  ...   

       Race_5.0  Race_1.0  Race_4.0  Race_3.0  Race_2.0  Education   Smoking  \
15208  1.000000       0.0  0.000000 -0.145400   0.00000  -0.656011 -0.319015   
25325  0.000000       1.0  0.000000 -0.145400   0.00000   0.170835 -0.319015   
5132   0.000000       1.0  0.000000 -0.145400   0.00000  -0.656011  0.680985   
17217  0.000000       0.0  3.236622 -0.145400   0.00000  -0.065383  0.680985   
6382   0.000000       0.0  3.236622 -0.145400   0.00000   0.525245  0.680985   
...         ...       ...       ...       ...       ...        ...       ...   
72714  0.000000       0.0  3.236622 -0.145400   0.00000   0.525245  0.672319   
72715  0.000000       0.0  0.000000  0.854600   0.00000  -0.656011  0.680985   
72716  0.402414       0.0  0.000000  0.452186   0.00000   0.409971  0.680985   
72717  0.000000       0.0  0.000000 -0.030279   0.88488   1.115873  0.680985   
72718  0.000000       0.0  0.000000  0.854600   0.00000  -0.067269 -0.315822   

       PhysicalActivity  HealthInsurance   Alcohol  
15208          0.000000              0.0 -1.284779  
25325          0.000000              0.0  0.445085  
5132           0.000000             -1.0  0.118386  
17217          0.000000              0.0  0.445085  
6382           0.000000              0.0  0.451028  
...                 ...              ...       ...  
72714          0.000000              0.0  0.115540  
72715          0.000000              0.0  0.077133  
72716          0.000000              0.0  0.430065  
72717          0.000000              0.0  0.364598  
72718          0.006717              0.0 -0.723887  

[59610 rows x 31 columns]
2025-12-03 11:46:38,204:INFO:get_config() successfully completed......................................
2025-12-03 11:46:38,234:INFO:Initializing tune_model()
2025-12-03 11:46:38,234:INFO:tune_model(estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...), fold=None, round=4, n_iter=5, custom_grid=None, optimize=Recall, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=False, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FCB038FE80>)
2025-12-03 11:46:38,234:INFO:Checking exceptions
2025-12-03 11:46:38,249:INFO:Copying training dataset
2025-12-03 11:46:38,270:INFO:Checking base model
2025-12-03 11:46:38,270:INFO:Base model : Extreme Gradient Boosting
2025-12-03 11:46:38,270:INFO:Declaring metric variables
2025-12-03 11:46:38,270:INFO:Defining Hyperparameters
2025-12-03 11:46:38,434:INFO:Tuning with n_jobs=1
2025-12-03 11:46:38,434:INFO:Initializing RandomizedSearchCV
2025-12-03 11:47:46,650:INFO:best_params: {'actual_estimator__subsample': 1, 'actual_estimator__scale_pos_weight': 8.5, 'actual_estimator__reg_lambda': 0.0005, 'actual_estimator__reg_alpha': 0.001, 'actual_estimator__n_estimators': 10, 'actual_estimator__min_child_weight': 3, 'actual_estimator__max_depth': 8, 'actual_estimator__learning_rate': 0.0001, 'actual_estimator__colsample_bytree': 0.7}
2025-12-03 11:47:46,651:INFO:Hyperparameter search completed
2025-12-03 11:47:46,651:INFO:SubProcess create_model() called ==================================
2025-12-03 11:47:46,651:INFO:Initializing create_model()
2025-12-03 11:47:46,651:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FCB038FE80>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FCD752BF10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'subsample': 1, 'scale_pos_weight': 8.5, 'reg_lambda': 0.0005, 'reg_alpha': 0.001, 'n_estimators': 10, 'min_child_weight': 3, 'max_depth': 8, 'learning_rate': 0.0001, 'colsample_bytree': 0.7})
2025-12-03 11:47:46,651:INFO:Checking exceptions
2025-12-03 11:47:46,651:INFO:Importing libraries
2025-12-03 11:47:46,651:INFO:Copying training dataset
2025-12-03 11:47:46,674:INFO:Defining folds
2025-12-03 11:47:46,674:INFO:Declaring metric variables
2025-12-03 11:47:46,674:INFO:Importing untrained model
2025-12-03 11:47:46,674:INFO:Declaring custom model
2025-12-03 11:47:46,675:INFO:Extreme Gradient Boosting Imported successfully
2025-12-03 11:47:46,675:INFO:Starting cross validation
2025-12-03 11:47:46,676:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-12-03 11:47:51,891:INFO:Calculating mean and std
2025-12-03 11:47:51,891:INFO:Creating metrics dataframe
2025-12-03 11:47:51,894:INFO:Finalizing model
2025-12-03 11:47:51,958:INFO:Warning: No categorical columns found. Calling 'transform' will only return input data.
2025-12-03 11:47:52,416:INFO:Uploading results into container
2025-12-03 11:47:52,417:INFO:Uploading model into container now
2025-12-03 11:47:52,417:INFO:_master_model_container: 4
2025-12-03 11:47:52,417:INFO:_display_container: 5
2025-12-03 11:47:52,418:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=0.7, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=0.0001, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=8, max_leaves=None,
              min_child_weight=3, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=10, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2025-12-03 11:47:52,418:INFO:create_model() successfully completed......................................
2025-12-03 11:47:52,598:INFO:SubProcess create_model() end ==================================
2025-12-03 11:47:52,599:INFO:choose_better activated
2025-12-03 11:47:52,599:INFO:SubProcess create_model() called ==================================
2025-12-03 11:47:52,599:INFO:Initializing create_model()
2025-12-03 11:47:52,602:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FCB038FE80>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-03 11:47:52,602:INFO:Checking exceptions
2025-12-03 11:47:52,604:INFO:Importing libraries
2025-12-03 11:47:52,604:INFO:Copying training dataset
2025-12-03 11:47:52,625:INFO:Defining folds
2025-12-03 11:47:52,626:INFO:Declaring metric variables
2025-12-03 11:47:52,626:INFO:Importing untrained model
2025-12-03 11:47:52,626:INFO:Declaring custom model
2025-12-03 11:47:52,626:INFO:Extreme Gradient Boosting Imported successfully
2025-12-03 11:47:52,626:INFO:Starting cross validation
2025-12-03 11:47:52,628:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-12-03 11:48:04,550:INFO:Calculating mean and std
2025-12-03 11:48:04,550:INFO:Creating metrics dataframe
2025-12-03 11:48:04,552:INFO:Finalizing model
2025-12-03 11:48:04,620:INFO:Warning: No categorical columns found. Calling 'transform' will only return input data.
2025-12-03 11:48:05,812:INFO:Uploading results into container
2025-12-03 11:48:05,812:INFO:Uploading model into container now
2025-12-03 11:48:05,814:INFO:_master_model_container: 5
2025-12-03 11:48:05,814:INFO:_display_container: 6
2025-12-03 11:48:05,814:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2025-12-03 11:48:05,814:INFO:create_model() successfully completed......................................
2025-12-03 11:48:06,007:INFO:SubProcess create_model() end ==================================
2025-12-03 11:48:06,008:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...) result for Recall is 0.3624
2025-12-03 11:48:06,009:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=0.7, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=0.0001, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=8, max_leaves=None,
              min_child_weight=3, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=10, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...) result for Recall is 1.0
2025-12-03 11:48:06,010:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=0.7, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=0.0001, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=8, max_leaves=None,
              min_child_weight=3, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=10, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...) is best model
2025-12-03 11:48:06,010:INFO:choose_better completed
2025-12-03 11:48:06,010:INFO:_master_model_container: 5
2025-12-03 11:48:06,010:INFO:_display_container: 5
2025-12-03 11:48:06,011:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=0.7, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=0.0001, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=8, max_leaves=None,
              min_child_weight=3, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=10, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2025-12-03 11:48:06,011:INFO:tune_model() successfully completed......................................
2025-12-03 11:48:06,217:INFO:Initializing predict_model()
2025-12-03 11:48:06,217:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FCB038FE80>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=0.7, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=0.0001, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=8, max_leaves=None,
              min_child_weight=3, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=10, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...), probability_threshold=None, encoded_labels=False, raw_score=True, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001FCD9A83520>)
2025-12-03 11:48:06,217:INFO:Checking exceptions
2025-12-03 11:48:06,218:INFO:Preloading libraries
2025-12-03 11:48:06,638:INFO:Initializing get_config()
2025-12-03 11:48:06,638:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FCB038FE80>, variable=target_param)
2025-12-03 11:48:06,638:INFO:Variable:  returned as HeartDisease
2025-12-03 11:48:06,638:INFO:get_config() successfully completed......................................
2025-12-03 11:48:07,367:INFO:Initializing interpret_model()
2025-12-03 11:48:07,367:INFO:interpret_model(estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=0.7, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=0.0001, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=8, max_leaves=None,
              min_child_weight=3, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=10, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...), use_train_data=False, X_new_sample=None, y_new_sample=None, feature=None, kwargs={}, observation=None, plot=summary, save=False, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FCB038FE80>)
2025-12-03 11:48:07,368:INFO:Checking exceptions
2025-12-03 11:48:07,368:INFO:Soft dependency imported: shap: 0.49.1
2025-12-03 11:48:07,461:INFO:plot type: summary
2025-12-03 11:48:07,461:INFO:Creating TreeExplainer
2025-12-03 11:48:07,470:INFO:Compiling shap values
2025-12-03 11:48:09,399:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:4145: FutureWarning: The NumPy global RNG was seeded by calling `np.random.seed`. In a future version this function will no longer use the global RNG. Pass `rng` explicitly to opt-in to the new behaviour and silence this warning.

2025-12-03 11:48:10,638:INFO:Visual Rendered Successfully
2025-12-03 11:48:10,638:INFO:interpret_model() successfully completed......................................
2025-12-03 11:48:10,848:INFO:Initializing predict_model()
2025-12-03 11:48:10,848:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FCB038FE80>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...), probability_threshold=None, encoded_labels=False, raw_score=True, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001FCD9AD25F0>)
2025-12-03 11:48:10,848:INFO:Checking exceptions
2025-12-03 11:48:10,848:INFO:Preloading libraries
2025-12-03 11:48:11,291:INFO:Initializing get_config()
2025-12-03 11:48:11,291:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FCB038FE80>, variable=target_param)
2025-12-03 11:48:11,291:INFO:Variable:  returned as HeartDisease
2025-12-03 11:48:11,291:INFO:get_config() successfully completed......................................
2025-12-03 11:48:11,412:INFO:Initializing finalize_model()
2025-12-03 11:48:11,412:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FCB038FE80>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=0.7, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=0.0001, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=8, max_leaves=None,
              min_child_weight=3, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=10, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2025-12-03 11:48:11,412:INFO:Finalizing XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=0.7, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=0.0001, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=8, max_leaves=None,
              min_child_weight=3, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=10, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2025-12-03 11:48:11,434:INFO:Initializing create_model()
2025-12-03 11:48:11,434:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FCB038FE80>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=0.7, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=0.0001, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=8, max_leaves=None,
              min_child_weight=3, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=10, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2025-12-03 11:48:11,434:INFO:Checking exceptions
2025-12-03 11:48:11,434:INFO:Importing libraries
2025-12-03 11:48:11,434:INFO:Copying training dataset
2025-12-03 11:48:11,438:INFO:Defining folds
2025-12-03 11:48:11,438:INFO:Declaring metric variables
2025-12-03 11:48:11,438:INFO:Importing untrained model
2025-12-03 11:48:11,438:INFO:Declaring custom model
2025-12-03 11:48:11,441:INFO:Extreme Gradient Boosting Imported successfully
2025-12-03 11:48:11,441:INFO:Cross validation set to False
2025-12-03 11:48:11,441:INFO:Fitting Model
2025-12-03 11:48:11,557:INFO:Warning: No categorical columns found. Calling 'transform' will only return input data.
2025-12-03 11:48:12,200:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'IncomeRatio', 'SystolicBP',
                                             'BMI', 'WaistCircumference',
                                             'Height', 'TotalCholesterol',
                                             'Triglycerides', 'LDL', 'HDL',
                                             'HbA1c', 'Glucose', 'Creatinine',
                                             'UricAcid', 'ALT_Enzyme',
                                             'Albumin', 'Potassium', 'Sodium',
                                             'GGT_Enzyme', 'AST_Enzyme'],
                                    transformer=Si...
                               importance_type=None,
                               interaction_constraints=None,
                               learning_rate=0.0001, max_bin=None,
                               max_cat_threshold=None, max_cat_to_onehot=None,
                               max_delta_step=None, max_depth=8,
                               max_leaves=None, min_child_weight=3, missing=nan,
                               monotone_constraints=None, multi_strategy=None,
                               n_estimators=10, n_jobs=1,
                               num_parallel_tree=None,
                               objective='binary:logistic', ...))],
         verbose=False)
2025-12-03 11:48:12,200:INFO:create_model() successfully completed......................................
2025-12-03 11:48:12,381:INFO:_master_model_container: 5
2025-12-03 11:48:12,381:INFO:_display_container: 7
2025-12-03 11:48:12,400:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'IncomeRatio', 'SystolicBP',
                                             'BMI', 'WaistCircumference',
                                             'Height', 'TotalCholesterol',
                                             'Triglycerides', 'LDL', 'HDL',
                                             'HbA1c', 'Glucose', 'Creatinine',
                                             'UricAcid', 'ALT_Enzyme',
                                             'Albumin', 'Potassium', 'Sodium',
                                             'GGT_Enzyme', 'AST_Enzyme'],
                                    transformer=Si...
                               importance_type=None,
                               interaction_constraints=None,
                               learning_rate=0.0001, max_bin=None,
                               max_cat_threshold=None, max_cat_to_onehot=None,
                               max_delta_step=None, max_depth=8,
                               max_leaves=None, min_child_weight=3, missing=nan,
                               monotone_constraints=None, multi_strategy=None,
                               n_estimators=10, n_jobs=1,
                               num_parallel_tree=None,
                               objective='binary:logistic', ...))],
         verbose=False)
2025-12-03 11:48:12,400:INFO:finalize_model() successfully completed......................................
2025-12-03 11:48:12,620:INFO:Initializing save_model()
2025-12-03 11:48:12,620:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'IncomeRatio', 'SystolicBP',
                                             'BMI', 'WaistCircumference',
                                             'Height', 'TotalCholesterol',
                                             'Triglycerides', 'LDL', 'HDL',
                                             'HbA1c', 'Glucose', 'Creatinine',
                                             'UricAcid', 'ALT_Enzyme',
                                             'Albumin', 'Potassium', 'Sodium',
                                             'GGT_Enzyme', 'AST_Enzyme'],
                                    transformer=Si...
                               importance_type=None,
                               interaction_constraints=None,
                               learning_rate=0.0001, max_bin=None,
                               max_cat_threshold=None, max_cat_to_onehot=None,
                               max_delta_step=None, max_depth=8,
                               max_leaves=None, min_child_weight=3, missing=nan,
                               monotone_constraints=None, multi_strategy=None,
                               n_estimators=10, n_jobs=1,
                               num_parallel_tree=None,
                               objective='binary:logistic', ...))],
         verbose=False), model_name=../models\best_pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\OMAR\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'IncomeRatio', 'SystolicBP',
                                             'BMI', 'WaistCircumference',
                                             'Height', 'TotalCholesterol',
                                             'Triglycerides', 'LDL', 'HDL',
                                             'HbA1c', 'Glucose', 'Creatinine',
                                             'UricAcid', 'ALT_Enzyme',
                                             'Albumin', 'Potassium', 'Sodium',
                                             'G...
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              random_state=42,
                                                                              sampling_strategy='auto')))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=RobustScaler(copy=True,
                                                             quantile_range=(25.0,
                                                                             75.0),
                                                             unit_variance=False,
                                                             with_centering=True,
                                                             with_scaling=True)))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2025-12-03 11:48:12,620:INFO:Adding model into prep_pipe
2025-12-03 11:48:12,620:WARNING:Only Model saved as it was a pipeline.
2025-12-03 11:48:12,628:INFO:../models\best_pipeline.pkl saved in current working directory
2025-12-03 11:48:12,644:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'IncomeRatio', 'SystolicBP',
                                             'BMI', 'WaistCircumference',
                                             'Height', 'TotalCholesterol',
                                             'Triglycerides', 'LDL', 'HDL',
                                             'HbA1c', 'Glucose', 'Creatinine',
                                             'UricAcid', 'ALT_Enzyme',
                                             'Albumin', 'Potassium', 'Sodium',
                                             'GGT_Enzyme', 'AST_Enzyme'],
                                    transformer=Si...
                               importance_type=None,
                               interaction_constraints=None,
                               learning_rate=0.0001, max_bin=None,
                               max_cat_threshold=None, max_cat_to_onehot=None,
                               max_delta_step=None, max_depth=8,
                               max_leaves=None, min_child_weight=3, missing=nan,
                               monotone_constraints=None, multi_strategy=None,
                               n_estimators=10, n_jobs=1,
                               num_parallel_tree=None,
                               objective='binary:logistic', ...))],
         verbose=False)
2025-12-03 11:48:12,644:INFO:save_model() successfully completed......................................
2025-12-03 11:54:41,965:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-12-03 11:54:41,965:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-12-03 11:54:41,965:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-12-03 11:54:41,965:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-12-03 11:54:43,664:INFO:Initializing load_model()
2025-12-03 11:54:43,664:INFO:load_model(model_name=../models/best_pipeline, platform=None, authentication=None, verbose=True)
2025-12-03 11:54:43,702:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-03 11:54:44,340:INFO:Initializing predict_model()
2025-12-03 11:54:44,340:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002780592A6B0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Age', 'IncomeRatio', 'SystolicBP',
                                             'BMI', 'WaistCircumference',
                                             'Height', 'TotalCholesterol',
                                             'Triglycerides', 'LDL', 'HDL',
                                             'HbA1c', 'Glucose', 'Creatinine',
                                             'UricAcid', 'ALT_Enzyme',
                                             'Albumin', 'Potassium', 'Sodium',
                                             'GGT_Enzyme', 'AST_Enzyme'],
                                    transformer=SimpleImputer()...
                               feature_types=None, gamma=None, grow_policy=None,
                               importance_type=None,
                               interaction_constraints=None,
                               learning_rate=0.0001, max_bin=None,
                               max_cat_threshold=None, max_cat_to_onehot=None,
                               max_delta_step=None, max_depth=8,
                               max_leaves=None, min_child_weight=3, missing=nan,
                               monotone_constraints=None, multi_strategy=None,
                               n_estimators=10, n_jobs=1,
                               num_parallel_tree=None, random_state=42, ...))]), probability_threshold=None, encoded_labels=False, raw_score=True, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002780591E200>)
2025-12-03 11:54:44,340:INFO:Checking exceptions
2025-12-03 11:54:44,340:INFO:Preloading libraries
2025-12-03 11:54:44,340:INFO:Set up data.
2025-12-03 11:54:44,349:INFO:Set up index.
2025-12-03 11:54:44,676:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-03 11:54:44,682:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-03 11:54:44,685:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-03 12:11:32,081:INFO:PyCaret ClassificationExperiment
2025-12-03 12:11:32,081:INFO:Logging name: clf-default-name
2025-12-03 12:11:32,081:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-12-03 12:11:32,081:INFO:version 3.3.2
2025-12-03 12:11:32,081:INFO:Initializing setup()
2025-12-03 12:11:32,081:INFO:self.USI: bc5a
2025-12-03 12:11:32,081:INFO:self._variable_keys: {'y', 'is_multiclass', 'y_train', 'X', 'target_param', 'X_train', 'exp_name_log', 'pipeline', 'fold_generator', 'fold_groups_param', 'X_test', 'data', 'gpu_param', '_available_plots', 'USI', 'idx', 'logging_param', 'memory', 'fix_imbalance', 'log_plots_param', 'y_test', 'n_jobs_param', '_ml_usecase', 'html_param', 'gpu_n_jobs_param', 'fold_shuffle_param', 'seed', 'exp_id'}
2025-12-03 12:11:32,081:INFO:Checking environment
2025-12-03 12:11:32,081:INFO:python_version: 3.10.19
2025-12-03 12:11:32,081:INFO:python_build: ('main', 'Oct 21 2025 16:41:31')
2025-12-03 12:11:32,081:INFO:machine: AMD64
2025-12-03 12:11:32,081:INFO:platform: Windows-10-10.0.26100-SP0
2025-12-03 12:11:32,081:INFO:Memory: svmem(total=16282144768, available=4904841216, percent=69.9, used=11377303552, free=4904841216)
2025-12-03 12:11:32,081:INFO:Physical Core: 6
2025-12-03 12:11:32,081:INFO:Logical Core: 12
2025-12-03 12:11:32,081:INFO:Checking libraries
2025-12-03 12:11:32,081:INFO:System:
2025-12-03 12:11:32,081:INFO:    python: 3.10.19 | packaged by Anaconda, Inc. | (main, Oct 21 2025, 16:41:31) [MSC v.1929 64 bit (AMD64)]
2025-12-03 12:11:32,081:INFO:executable: c:\Users\OMAR\miniconda3\envs\xgb_env\python.exe
2025-12-03 12:11:32,081:INFO:   machine: Windows-10-10.0.26100-SP0
2025-12-03 12:11:32,081:INFO:PyCaret required dependencies:
2025-12-03 12:11:32,081:INFO:                 pip: 25.3
2025-12-03 12:11:32,081:INFO:          setuptools: 80.9.0
2025-12-03 12:11:32,081:INFO:             pycaret: 3.3.2
2025-12-03 12:11:32,081:INFO:             IPython: 8.37.0
2025-12-03 12:11:32,081:INFO:          ipywidgets: 8.1.8
2025-12-03 12:11:32,081:INFO:                tqdm: 4.67.1
2025-12-03 12:11:32,082:INFO:               numpy: 1.26.4
2025-12-03 12:11:32,082:INFO:              pandas: 2.1.4
2025-12-03 12:11:32,082:INFO:              jinja2: 3.1.6
2025-12-03 12:11:32,082:INFO:               scipy: 1.11.4
2025-12-03 12:11:32,082:INFO:              joblib: 1.3.2
2025-12-03 12:11:32,082:INFO:             sklearn: 1.4.2
2025-12-03 12:11:32,082:INFO:                pyod: 2.0.5
2025-12-03 12:11:32,082:INFO:            imblearn: 0.14.0
2025-12-03 12:11:32,082:INFO:   category_encoders: 2.7.0
2025-12-03 12:11:32,082:INFO:            lightgbm: 4.6.0
2025-12-03 12:11:32,082:INFO:               numba: 0.62.1
2025-12-03 12:11:32,082:INFO:            requests: 2.32.5
2025-12-03 12:11:32,082:INFO:          matplotlib: 3.7.5
2025-12-03 12:11:32,082:INFO:          scikitplot: 0.3.7
2025-12-03 12:11:32,082:INFO:         yellowbrick: 1.5
2025-12-03 12:11:32,082:INFO:              plotly: 5.24.1
2025-12-03 12:11:32,082:INFO:    plotly-resampler: Not installed
2025-12-03 12:11:32,082:INFO:             kaleido: 1.2.0
2025-12-03 12:11:32,082:INFO:           schemdraw: 0.15
2025-12-03 12:11:32,082:INFO:         statsmodels: 0.14.5
2025-12-03 12:11:32,082:INFO:              sktime: 0.26.0
2025-12-03 12:11:32,082:INFO:               tbats: 1.1.3
2025-12-03 12:11:32,082:INFO:            pmdarima: 2.0.4
2025-12-03 12:11:32,082:INFO:              psutil: 7.1.3
2025-12-03 12:11:32,082:INFO:          markupsafe: 3.0.3
2025-12-03 12:11:32,082:INFO:             pickle5: Not installed
2025-12-03 12:11:32,082:INFO:         cloudpickle: 3.1.2
2025-12-03 12:11:32,082:INFO:         deprecation: 2.1.0
2025-12-03 12:11:32,082:INFO:              xxhash: 3.6.0
2025-12-03 12:11:32,082:INFO:           wurlitzer: Not installed
2025-12-03 12:11:32,082:INFO:PyCaret optional dependencies:
2025-12-03 12:11:32,082:INFO:                shap: 0.49.1
2025-12-03 12:11:32,082:INFO:           interpret: 0.7.3
2025-12-03 12:11:32,082:INFO:                umap: 0.5.7
2025-12-03 12:11:32,082:INFO:     ydata_profiling: 4.18.0
2025-12-03 12:11:32,082:INFO:  explainerdashboard: 0.5.1
2025-12-03 12:11:32,082:INFO:             autoviz: Not installed
2025-12-03 12:11:32,082:INFO:           fairlearn: 0.7.0
2025-12-03 12:11:32,082:INFO:          deepchecks: Not installed
2025-12-03 12:11:32,082:INFO:             xgboost: 2.1.3
2025-12-03 12:11:32,082:INFO:            catboost: 1.2.8
2025-12-03 12:11:32,082:INFO:              kmodes: 0.12.2
2025-12-03 12:11:32,082:INFO:             mlxtend: 0.23.4
2025-12-03 12:11:32,082:INFO:       statsforecast: 1.5.0
2025-12-03 12:11:32,082:INFO:        tune_sklearn: Not installed
2025-12-03 12:11:32,082:INFO:                 ray: Not installed
2025-12-03 12:11:32,082:INFO:            hyperopt: 0.2.7
2025-12-03 12:11:32,082:INFO:              optuna: 4.6.0
2025-12-03 12:11:32,082:INFO:               skopt: 0.10.2
2025-12-03 12:11:32,082:INFO:              mlflow: 3.6.0
2025-12-03 12:11:32,082:INFO:              gradio: 6.0.1
2025-12-03 12:11:32,082:INFO:             fastapi: 0.123.0
2025-12-03 12:11:32,082:INFO:             uvicorn: 0.38.0
2025-12-03 12:11:32,082:INFO:              m2cgen: 0.10.0
2025-12-03 12:11:32,083:INFO:           evidently: 0.4.40
2025-12-03 12:11:32,083:INFO:               fugue: 0.8.7
2025-12-03 12:11:32,083:INFO:           streamlit: 1.51.0
2025-12-03 12:11:32,083:INFO:             prophet: Not installed
2025-12-03 12:11:32,083:INFO:None
2025-12-03 12:11:32,083:INFO:Set up data.
2025-12-03 12:11:32,102:INFO:Set up folding strategy.
2025-12-03 12:11:32,102:INFO:Set up train/test split.
2025-12-03 12:11:32,123:INFO:Set up index.
2025-12-03 12:11:32,123:INFO:Assigning column types.
2025-12-03 12:11:32,140:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-12-03 12:11:32,160:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-12-03 12:11:32,167:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-03 12:11:32,182:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-03 12:11:32,184:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-03 12:11:32,210:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-12-03 12:11:32,211:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-03 12:11:32,228:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-03 12:11:32,230:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-03 12:11:32,230:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-12-03 12:11:32,255:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-03 12:11:32,271:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-03 12:11:32,271:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-03 12:11:32,296:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-03 12:11:32,314:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-03 12:11:32,314:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-03 12:11:32,314:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-12-03 12:11:32,356:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-03 12:11:32,358:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-03 12:11:32,399:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-03 12:11:32,400:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-03 12:11:32,402:INFO:Preparing preprocessing pipeline...
2025-12-03 12:11:32,406:INFO:Set up simple imputation.
2025-12-03 12:11:32,417:INFO:Set up encoding of ordinal features.
2025-12-03 12:11:32,422:INFO:Set up encoding of categorical features.
2025-12-03 12:11:32,422:INFO:Set up imbalanced handling.
2025-12-03 12:11:32,424:INFO:Set up feature normalization.
2025-12-03 12:11:32,615:INFO:Finished creating preprocessing pipeline.
2025-12-03 12:11:32,631:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\OMAR\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'IncomeRatio', 'SystolicBP',
                                             'BMI', 'WaistCircumference',
                                             'Height', 'TotalCholesterol',
                                             'Triglycerides', 'LDL', 'HDL',
                                             'HbA1c', 'Glucose', 'Creatinine',
                                             'UricAcid', 'ALT_Enzyme',
                                             'Albumin', 'Potassium', 'Sodium',
                                             'G...
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              random_state=42,
                                                                              sampling_strategy='auto')))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=RobustScaler(copy=True,
                                                             quantile_range=(25.0,
                                                                             75.0),
                                                             unit_variance=False,
                                                             with_centering=True,
                                                             with_scaling=True)))],
         verbose=False)
2025-12-03 12:11:32,631:INFO:Creating final display dataframe.
2025-12-03 12:11:32,838:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target      HeartDisease
2                   Target type            Binary
3           Original data shape       (43695, 28)
4        Transformed data shape       (72719, 32)
5   Transformed train set shape       (59610, 32)
6    Transformed test set shape       (13109, 32)
7              Numeric features                20
8          Categorical features                 7
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15                Fix imbalance              True
16         Fix imbalance method             SMOTE
17                    Normalize              True
18             Normalize method            robust
19               Fold Generator   StratifiedKFold
20                  Fold Number                10
21                     CPU Jobs                 1
22                      Use GPU             False
23               Log Experiment             False
24              Experiment Name  clf-default-name
25                          USI              bc5a
2025-12-03 12:11:32,884:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-03 12:11:32,888:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-03 12:11:32,931:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-03 12:11:32,934:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-03 12:11:32,934:INFO:setup() successfully completed in 0.86s...............
2025-12-03 12:11:32,974:INFO:Initializing get_config()
2025-12-03 12:11:32,974:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FCD92CC370>, variable=y_train)
2025-12-03 12:11:32,974:INFO:Variable: 'y_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_train_transformed' instead.
2025-12-03 12:11:32,975:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_train_transformed' instead.

2025-12-03 12:11:32,982:INFO:Variable:  returned as 15208    0.0
25325    0.0
5132     0.0
17217    0.0
6382     0.0
        ... 
6265     0.0
42694    0.0
13399    0.0
39959    0.0
6616     0.0
Name: HeartDisease, Length: 30586, dtype: float32
2025-12-03 12:11:32,982:INFO:get_config() successfully completed......................................
2025-12-03 12:11:32,983:INFO:Initializing create_model()
2025-12-03 12:11:32,984:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FCD92CC370>, estimator=xgboost, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={'scale_pos_weight': 76.32522407170295})
2025-12-03 12:11:32,984:INFO:Checking exceptions
2025-12-03 12:11:32,994:INFO:Importing libraries
2025-12-03 12:11:32,994:INFO:Copying training dataset
2025-12-03 12:11:33,029:INFO:Defining folds
2025-12-03 12:11:33,029:INFO:Declaring metric variables
2025-12-03 12:11:33,034:INFO:Importing untrained model
2025-12-03 12:11:33,038:INFO:Extreme Gradient Boosting Imported successfully
2025-12-03 12:11:33,045:INFO:Starting cross validation
2025-12-03 12:11:33,047:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-12-03 12:11:48,421:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-12-03 12:11:48,421:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-12-03 12:11:48,422:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-12-03 12:11:48,422:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-12-03 12:11:50,155:INFO:PyCaret ClassificationExperiment
2025-12-03 12:11:50,155:INFO:Logging name: clf-default-name
2025-12-03 12:11:50,155:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-12-03 12:11:50,155:INFO:version 3.3.2
2025-12-03 12:11:50,155:INFO:Initializing setup()
2025-12-03 12:11:50,155:INFO:self.USI: 08d2
2025-12-03 12:11:50,155:INFO:self._variable_keys: {'y', 'fold_groups_param', 'data', 'seed', 'gpu_n_jobs_param', 'exp_name_log', 'logging_param', 'fold_shuffle_param', 'X', 'n_jobs_param', 'gpu_param', 'memory', '_ml_usecase', 'X_train', 'fold_generator', 'pipeline', 'is_multiclass', 'idx', '_available_plots', 'html_param', 'target_param', 'y_test', 'exp_id', 'log_plots_param', 'y_train', 'fix_imbalance', 'USI', 'X_test'}
2025-12-03 12:11:50,155:INFO:Checking environment
2025-12-03 12:11:50,155:INFO:python_version: 3.10.19
2025-12-03 12:11:50,155:INFO:python_build: ('main', 'Oct 21 2025 16:41:31')
2025-12-03 12:11:50,155:INFO:machine: AMD64
2025-12-03 12:11:50,155:INFO:platform: Windows-10-10.0.26100-SP0
2025-12-03 12:11:50,155:INFO:Memory: svmem(total=16282144768, available=4945186816, percent=69.6, used=11336957952, free=4945186816)
2025-12-03 12:11:50,156:INFO:Physical Core: 6
2025-12-03 12:11:50,156:INFO:Logical Core: 12
2025-12-03 12:11:50,156:INFO:Checking libraries
2025-12-03 12:11:50,156:INFO:System:
2025-12-03 12:11:50,156:INFO:    python: 3.10.19 | packaged by Anaconda, Inc. | (main, Oct 21 2025, 16:41:31) [MSC v.1929 64 bit (AMD64)]
2025-12-03 12:11:50,156:INFO:executable: c:\Users\OMAR\miniconda3\envs\xgb_env\python.exe
2025-12-03 12:11:50,156:INFO:   machine: Windows-10-10.0.26100-SP0
2025-12-03 12:11:50,156:INFO:PyCaret required dependencies:
2025-12-03 12:11:50,156:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-03 12:11:50,692:INFO:                 pip: 25.3
2025-12-03 12:11:50,692:INFO:          setuptools: 80.9.0
2025-12-03 12:11:50,692:INFO:             pycaret: 3.3.2
2025-12-03 12:11:50,692:INFO:             IPython: 8.37.0
2025-12-03 12:11:50,692:INFO:          ipywidgets: 8.1.8
2025-12-03 12:11:50,692:INFO:                tqdm: 4.67.1
2025-12-03 12:11:50,692:INFO:               numpy: 1.26.4
2025-12-03 12:11:50,692:INFO:              pandas: 2.1.4
2025-12-03 12:11:50,692:INFO:              jinja2: 3.1.6
2025-12-03 12:11:50,692:INFO:               scipy: 1.11.4
2025-12-03 12:11:50,692:INFO:              joblib: 1.3.2
2025-12-03 12:11:50,692:INFO:             sklearn: 1.4.2
2025-12-03 12:11:50,692:INFO:                pyod: 2.0.5
2025-12-03 12:11:50,692:INFO:            imblearn: 0.14.0
2025-12-03 12:11:50,692:INFO:   category_encoders: 2.7.0
2025-12-03 12:11:50,692:INFO:            lightgbm: 4.6.0
2025-12-03 12:11:50,692:INFO:               numba: 0.62.1
2025-12-03 12:11:50,692:INFO:            requests: 2.32.5
2025-12-03 12:11:50,692:INFO:          matplotlib: 3.7.5
2025-12-03 12:11:50,692:INFO:          scikitplot: 0.3.7
2025-12-03 12:11:50,692:INFO:         yellowbrick: 1.5
2025-12-03 12:11:50,692:INFO:              plotly: 5.24.1
2025-12-03 12:11:50,692:INFO:    plotly-resampler: Not installed
2025-12-03 12:11:50,692:INFO:             kaleido: 1.2.0
2025-12-03 12:11:50,692:INFO:           schemdraw: 0.15
2025-12-03 12:11:50,692:INFO:         statsmodels: 0.14.5
2025-12-03 12:11:50,692:INFO:              sktime: 0.26.0
2025-12-03 12:11:50,692:INFO:               tbats: 1.1.3
2025-12-03 12:11:50,694:INFO:            pmdarima: 2.0.4
2025-12-03 12:11:50,694:INFO:              psutil: 7.1.3
2025-12-03 12:11:50,694:INFO:          markupsafe: 3.0.3
2025-12-03 12:11:50,694:INFO:             pickle5: Not installed
2025-12-03 12:11:50,694:INFO:         cloudpickle: 3.1.2
2025-12-03 12:11:50,694:INFO:         deprecation: 2.1.0
2025-12-03 12:11:50,694:INFO:              xxhash: 3.6.0
2025-12-03 12:11:50,694:INFO:           wurlitzer: Not installed
2025-12-03 12:11:50,694:INFO:PyCaret optional dependencies:
2025-12-03 12:11:53,331:INFO:                shap: 0.49.1
2025-12-03 12:11:53,331:INFO:           interpret: 0.7.3
2025-12-03 12:11:53,331:INFO:                umap: 0.5.7
2025-12-03 12:11:53,331:INFO:     ydata_profiling: 4.18.0
2025-12-03 12:11:53,331:INFO:  explainerdashboard: 0.5.1
2025-12-03 12:11:53,331:INFO:             autoviz: Not installed
2025-12-03 12:11:53,331:INFO:           fairlearn: 0.7.0
2025-12-03 12:11:53,331:INFO:          deepchecks: Not installed
2025-12-03 12:11:53,331:INFO:             xgboost: 2.1.3
2025-12-03 12:11:53,331:INFO:            catboost: 1.2.8
2025-12-03 12:11:53,331:INFO:              kmodes: 0.12.2
2025-12-03 12:11:53,331:INFO:             mlxtend: 0.23.4
2025-12-03 12:11:53,331:INFO:       statsforecast: 1.5.0
2025-12-03 12:11:53,331:INFO:        tune_sklearn: Not installed
2025-12-03 12:11:53,331:INFO:                 ray: Not installed
2025-12-03 12:11:53,331:INFO:            hyperopt: 0.2.7
2025-12-03 12:11:53,331:INFO:              optuna: 4.6.0
2025-12-03 12:11:53,331:INFO:               skopt: 0.10.2
2025-12-03 12:11:53,331:INFO:              mlflow: 3.6.0
2025-12-03 12:11:53,331:INFO:              gradio: 6.0.1
2025-12-03 12:11:53,331:INFO:             fastapi: 0.123.0
2025-12-03 12:11:53,331:INFO:             uvicorn: 0.38.0
2025-12-03 12:11:53,331:INFO:              m2cgen: 0.10.0
2025-12-03 12:11:53,331:INFO:           evidently: 0.4.40
2025-12-03 12:11:53,331:INFO:               fugue: 0.8.7
2025-12-03 12:11:53,331:INFO:           streamlit: 1.51.0
2025-12-03 12:11:53,331:INFO:             prophet: Not installed
2025-12-03 12:11:53,331:INFO:None
2025-12-03 12:11:53,331:INFO:Set up data.
2025-12-03 12:11:53,350:INFO:Set up folding strategy.
2025-12-03 12:11:53,350:INFO:Set up train/test split.
2025-12-03 12:11:53,373:INFO:Set up index.
2025-12-03 12:11:53,375:INFO:Assigning column types.
2025-12-03 12:11:53,394:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-12-03 12:11:53,419:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-12-03 12:11:53,419:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-03 12:11:53,441:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-03 12:11:53,444:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-03 12:11:53,488:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-12-03 12:11:53,491:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-03 12:11:53,506:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-03 12:11:53,508:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-03 12:11:53,508:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-12-03 12:11:53,534:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-03 12:11:53,550:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-03 12:11:53,553:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-03 12:11:53,579:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-03 12:11:53,595:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-03 12:11:53,597:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-03 12:11:53,597:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-12-03 12:11:53,638:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-03 12:11:53,640:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-03 12:11:53,682:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-03 12:11:53,683:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-03 12:11:53,686:INFO:Preparing preprocessing pipeline...
2025-12-03 12:11:53,690:INFO:Set up simple imputation.
2025-12-03 12:11:53,700:INFO:Set up encoding of ordinal features.
2025-12-03 12:11:53,709:INFO:Set up encoding of categorical features.
2025-12-03 12:11:53,709:INFO:Set up imbalanced handling.
2025-12-03 12:11:53,709:INFO:Set up feature normalization.
2025-12-03 12:11:53,890:INFO:Finished creating preprocessing pipeline.
2025-12-03 12:11:53,905:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\OMAR\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'IncomeRatio', 'SystolicBP',
                                             'BMI', 'WaistCircumference',
                                             'Height', 'TotalCholesterol',
                                             'Triglycerides', 'LDL', 'HDL',
                                             'HbA1c', 'Glucose', 'Creatinine',
                                             'UricAcid', 'ALT_Enzyme',
                                             'Albumin', 'Potassium', 'Sodium',
                                             'G...
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              random_state=42,
                                                                              sampling_strategy='auto')))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=RobustScaler(copy=True,
                                                             quantile_range=(25.0,
                                                                             75.0),
                                                             unit_variance=False,
                                                             with_centering=True,
                                                             with_scaling=True)))],
         verbose=False)
2025-12-03 12:11:53,906:INFO:Creating final display dataframe.
2025-12-03 12:11:54,122:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target      HeartDisease
2                   Target type            Binary
3           Original data shape       (43695, 28)
4        Transformed data shape       (72719, 32)
5   Transformed train set shape       (59610, 32)
6    Transformed test set shape       (13109, 32)
7              Numeric features                20
8          Categorical features                 7
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15                Fix imbalance              True
16         Fix imbalance method             SMOTE
17                    Normalize              True
18             Normalize method            robust
19               Fold Generator   StratifiedKFold
20                  Fold Number                10
21                     CPU Jobs                 1
22                      Use GPU             False
23               Log Experiment             False
24              Experiment Name  clf-default-name
25                          USI              08d2
2025-12-03 12:11:54,170:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-03 12:11:54,170:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-03 12:11:54,215:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-03 12:11:54,217:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-03 12:11:54,218:INFO:setup() successfully completed in 4.07s...............
2025-12-03 12:11:54,481:INFO:Initializing get_config()
2025-12-03 12:11:54,481:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000278EABAEE90>, variable=y_train)
2025-12-03 12:11:54,481:INFO:Variable: 'y_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_train_transformed' instead.
2025-12-03 12:11:54,481:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_train_transformed' instead.

2025-12-03 12:11:54,491:INFO:Variable:  returned as 15208    0.0
25325    0.0
5132     0.0
17217    0.0
6382     0.0
        ... 
6265     0.0
42694    0.0
13399    0.0
39959    0.0
6616     0.0
Name: HeartDisease, Length: 30586, dtype: float32
2025-12-03 12:11:54,491:INFO:get_config() successfully completed......................................
2025-12-03 12:11:54,491:INFO:Initializing create_model()
2025-12-03 12:11:54,491:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000278EABAEE90>, estimator=xgboost, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={'scale_pos_weight': 76.32522407170295})
2025-12-03 12:11:54,491:INFO:Checking exceptions
2025-12-03 12:11:54,503:INFO:Importing libraries
2025-12-03 12:11:54,503:INFO:Copying training dataset
2025-12-03 12:11:54,538:INFO:Defining folds
2025-12-03 12:11:54,538:INFO:Declaring metric variables
2025-12-03 12:11:54,541:INFO:Importing untrained model
2025-12-03 12:11:54,545:INFO:Extreme Gradient Boosting Imported successfully
2025-12-03 12:11:54,554:INFO:Starting cross validation
2025-12-03 12:11:54,555:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-12-03 12:11:54,663:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\joblib\externals\loky\backend\context.py:136: UserWarning: Could not find the number of physical cores for the following reason:
[WinError 2] El sistema no puede encontrar el archivo especificado
Returning the number of logical cores instead. You can silence this warning by setting LOKY_MAX_CPU_COUNT to the number of cores you want to use.

2025-12-03 12:11:54,665:WARNING:  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\joblib\externals\loky\backend\context.py", line 257, in _count_physical_cores
2025-12-03 12:11:54,665:WARNING:    cpu_info = subprocess.run(
2025-12-03 12:11:54,665:WARNING:  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\subprocess.py", line 503, in run
2025-12-03 12:11:54,665:WARNING:    with Popen(*popenargs, **kwargs) as process:
2025-12-03 12:11:54,665:WARNING:  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\subprocess.py", line 971, in __init__
2025-12-03 12:11:54,665:WARNING:    self._execute_child(args, executable, preexec_fn, close_fds,
2025-12-03 12:11:54,665:WARNING:  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\subprocess.py", line 1456, in _execute_child
2025-12-03 12:11:54,665:WARNING:    hp, ht, pid, tid = _winapi.CreateProcess(executable, args,
2025-12-03 12:12:06,395:INFO:Calculating mean and std
2025-12-03 12:12:06,395:INFO:Creating metrics dataframe
2025-12-03 12:12:06,400:INFO:Finalizing model
2025-12-03 12:12:06,479:INFO:Warning: No categorical columns found. Calling 'transform' will only return input data.
2025-12-03 12:12:07,652:INFO:Uploading results into container
2025-12-03 12:12:07,652:INFO:Uploading model into container now
2025-12-03 12:12:07,660:INFO:_master_model_container: 1
2025-12-03 12:12:07,660:INFO:_display_container: 2
2025-12-03 12:12:07,660:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2025-12-03 12:12:07,660:INFO:create_model() successfully completed......................................
2025-12-03 12:12:07,865:INFO:Initializing create_model()
2025-12-03 12:12:07,866:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000278EABAEE90>, estimator=lr, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-03 12:12:07,866:INFO:Checking exceptions
2025-12-03 12:12:07,876:INFO:Importing libraries
2025-12-03 12:12:07,876:INFO:Copying training dataset
2025-12-03 12:12:07,904:INFO:Defining folds
2025-12-03 12:12:07,904:INFO:Declaring metric variables
2025-12-03 12:12:07,907:INFO:Importing untrained model
2025-12-03 12:12:07,909:INFO:Logistic Regression Imported successfully
2025-12-03 12:12:07,913:INFO:Starting cross validation
2025-12-03 12:12:07,914:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-12-03 12:12:11,391:INFO:Calculating mean and std
2025-12-03 12:12:11,391:INFO:Creating metrics dataframe
2025-12-03 12:12:11,394:INFO:Finalizing model
2025-12-03 12:12:11,475:INFO:Warning: No categorical columns found. Calling 'transform' will only return input data.
2025-12-03 12:12:11,762:INFO:Uploading results into container
2025-12-03 12:12:11,762:INFO:Uploading model into container now
2025-12-03 12:12:11,770:INFO:_master_model_container: 2
2025-12-03 12:12:11,771:INFO:_display_container: 3
2025-12-03 12:12:11,771:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-12-03 12:12:11,771:INFO:create_model() successfully completed......................................
2025-12-03 12:12:11,949:INFO:Initializing create_model()
2025-12-03 12:12:11,950:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000278EABAEE90>, estimator=rf, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-03 12:12:11,950:INFO:Checking exceptions
2025-12-03 12:12:11,960:INFO:Importing libraries
2025-12-03 12:12:11,960:INFO:Copying training dataset
2025-12-03 12:12:11,988:INFO:Defining folds
2025-12-03 12:12:11,988:INFO:Declaring metric variables
2025-12-03 12:12:11,992:INFO:Importing untrained model
2025-12-03 12:12:11,995:INFO:Random Forest Classifier Imported successfully
2025-12-03 12:12:11,999:INFO:Starting cross validation
2025-12-03 12:12:12,000:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-12-03 12:14:21,344:INFO:Calculating mean and std
2025-12-03 12:14:21,344:INFO:Creating metrics dataframe
2025-12-03 12:14:21,350:INFO:Finalizing model
2025-12-03 12:14:21,434:INFO:Warning: No categorical columns found. Calling 'transform' will only return input data.
2025-12-03 12:14:35,530:INFO:Uploading results into container
2025-12-03 12:14:35,532:INFO:Uploading model into container now
2025-12-03 12:14:35,541:INFO:_master_model_container: 3
2025-12-03 12:14:35,544:INFO:_display_container: 4
2025-12-03 12:14:35,544:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2025-12-03 12:14:35,544:INFO:create_model() successfully completed......................................
2025-12-03 12:14:35,760:INFO:Initializing get_config()
2025-12-03 12:14:35,760:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000278EABAEE90>, variable=X_train_transformed)
2025-12-03 12:14:35,821:INFO:Variable: X_train returned as             Age  IncomeRatio  SystolicBP       BMI  WaistCircumference  \
15208  0.281967     1.073479   -0.029334  0.320615           -0.184205   
25325 -0.959685     0.336748   -1.131593 -1.420125           -1.360604   
5132  -0.499814    -0.472688   -0.718246 -0.222594           -0.051710   
17217 -0.177904    -0.894370   -0.355002 -0.592965           -0.099890   
6382  -0.108923     0.093300    0.697155  2.851479            1.783151   
...         ...          ...         ...       ...                 ...   
72714  0.209599    -0.574548    0.093968 -0.084224            0.048339   
72715  0.410044     0.140941    1.545471  0.784710            0.534682   
72716  0.336375     0.706350   -0.225611 -0.316094            0.087200   
72717  0.465916     0.152440   -0.649398  0.648433            0.661659   
72718  0.465916     0.204596    0.822492 -0.260262           -0.112576   

         Height  TotalCholesterol  Triglycerides       LDL       HDL  ...  \
15208 -0.949100          0.573893       0.496366  0.004515  0.470102  ...   
25325 -0.676156          0.027513      -0.418808  0.000788  0.460074  ...   
5132   0.887068          0.164048       0.383587  0.688473 -1.055073  ...   
17217  0.856051          0.206410       0.239340  0.002372 -0.072797  ...   
6382   0.111659          0.796802       0.552888  0.002599  0.944927  ...   
...         ...               ...            ...       ...       ...  ...   
72714  0.529966          0.966537       0.338163  2.847690 -1.107269  ...   
72715 -0.193825          1.002684       1.137561  0.006116  0.578610  ...   
72716  0.850772          0.698204       0.800524  0.005273  0.320829  ...   
72717  0.196053         -0.854465      -0.645063 -1.338104 -0.093582  ...   
72718 -0.754937         -1.171319      -0.645250 -1.650124 -0.583170  ...   

       Race_5.0  Race_1.0  Race_4.0  Race_3.0  Race_2.0  Education   Smoking  \
15208  1.000000       0.0  0.000000 -0.145400   0.00000  -0.656011 -0.319015   
25325  0.000000       1.0  0.000000 -0.145400   0.00000   0.170835 -0.319015   
5132   0.000000       1.0  0.000000 -0.145400   0.00000  -0.656011  0.680985   
17217  0.000000       0.0  3.236622 -0.145400   0.00000  -0.065383  0.680985   
6382   0.000000       0.0  3.236622 -0.145400   0.00000   0.525245  0.680985   
...         ...       ...       ...       ...       ...        ...       ...   
72714  0.000000       0.0  3.236622 -0.145400   0.00000   0.525245  0.672319   
72715  0.000000       0.0  0.000000  0.854600   0.00000  -0.656011  0.680985   
72716  0.402414       0.0  0.000000  0.452186   0.00000   0.409971  0.680985   
72717  0.000000       0.0  0.000000 -0.030279   0.88488   1.115873  0.680985   
72718  0.000000       0.0  0.000000  0.854600   0.00000  -0.067269 -0.315822   

       PhysicalActivity  HealthInsurance   Alcohol  
15208          0.000000              0.0 -1.284779  
25325          0.000000              0.0  0.445085  
5132           0.000000             -1.0  0.118386  
17217          0.000000              0.0  0.445085  
6382           0.000000              0.0  0.451028  
...                 ...              ...       ...  
72714          0.000000              0.0  0.115540  
72715          0.000000              0.0  0.077133  
72716          0.000000              0.0  0.430065  
72717          0.000000              0.0  0.364598  
72718          0.006717              0.0 -0.723887  

[59610 rows x 31 columns]
2025-12-03 12:14:35,822:INFO:get_config() successfully completed......................................
2025-12-03 12:14:35,822:INFO:Initializing get_config()
2025-12-03 12:14:35,822:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000278EABAEE90>, variable=y_train)
2025-12-03 12:14:35,822:INFO:Variable: 'y_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_train_transformed' instead.
2025-12-03 12:14:35,822:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_train_transformed' instead.

2025-12-03 12:14:35,830:INFO:Variable:  returned as 15208    0.0
25325    0.0
5132     0.0
17217    0.0
6382     0.0
        ... 
6265     0.0
42694    0.0
13399    0.0
39959    0.0
6616     0.0
Name: HeartDisease, Length: 30586, dtype: float32
2025-12-03 12:14:35,831:INFO:get_config() successfully completed......................................
2025-12-03 12:14:35,833:INFO:Initializing get_config()
2025-12-03 12:14:35,833:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000278EABAEE90>, variable=X_test_transformed)
2025-12-03 12:14:35,910:INFO:Variable: X_test returned as             Age  IncomeRatio  SystolicBP       BMI  WaistCircumference  \
28456 -1.166627    -0.346668   -0.856028 -1.444817           -1.505144   
8993   0.144006     0.336748    1.661631  0.616912            0.650918   
34312  0.029038     0.094402    0.120974  0.320615            0.349792   
4802  -1.235607     0.337310   -0.679800 -0.555589           -0.935736   
25895  0.029038     1.529090   -0.455207 -0.552146           -0.411032   
...         ...          ...         ...       ...                 ...   
18045 -1.258601    -0.075240   -0.902556 -1.667039           -1.990961   
5425  -0.085930     0.470814    1.711734 -0.123829           -0.083830   
12819  0.235980     0.002310    0.478266  0.246541            0.711143   
33659 -1.212614     1.325519   -0.862074 -0.975681           -1.485069   
19531 -1.281594    -0.395137   -0.847590 -1.395434           -1.846420   

         Height  TotalCholesterol  Triglycerides       LDL       HDL  ...  \
28456 -1.817558         -0.075919      -0.645504 -0.018918  0.565429  ...   
8993  -0.645140          0.703061       0.628124  0.004972  0.591985  ...   
34312  0.583108         -0.117177       0.871284 -0.747548 -1.113897  ...   
4802  -0.974805         -0.177199      -0.485069  0.000613  0.052365  ...   
25895  0.081554          0.820238       1.262972  0.006556 -0.055073  ...   
...         ...               ...            ...       ...       ...  ...   
18045 -3.281529         -0.317991      -0.645314 -0.614949  0.543115  ...   
5425  -0.006203          0.398401      -0.206369  0.808141  0.297868  ...   
12819  1.513598         -0.679626      -0.644711 -0.152776 -0.819779  ...   
33659 -2.071891         -0.984285      -0.645722 -2.065437  0.297868  ...   
19531 -3.659929         -0.332706      -0.645328 -0.652405  0.543209  ...   

       Race_5.0  Race_1.0  Race_4.0  Race_3.0  Race_2.0  Education   Smoking  \
28456       1.0       0.0  0.000000   -0.1454       0.0  -0.023013 -0.319015   
8993        0.0       0.0  3.236622   -0.1454       0.0   0.525245  0.680985   
34312       0.0       0.0  0.000000    0.8546       0.0  -0.656011 -0.319015   
4802        1.0       0.0  0.000000   -0.1454       0.0   0.246788 -0.245402   
25895       0.0       0.0  0.000000    0.8546       0.0   1.115873 -0.319015   
...         ...       ...       ...       ...       ...        ...       ...   
18045       0.0       0.0  0.000000    0.8546       0.0  -0.786652 -0.319015   
5425        0.0       0.0  3.236622   -0.1454       0.0   0.525245  0.680985   
12819       0.0       0.0  0.000000    0.8546       0.0   1.115873  0.680985   
33659       0.0       0.0  3.236622   -0.1454       0.0   0.242351 -0.319015   
19531       1.0       0.0  0.000000   -0.1454       0.0  -0.813970 -0.319015   

       PhysicalActivity  HealthInsurance   Alcohol  
28456          0.869504              0.0 -0.854408  
8993           0.000000              0.0 -0.112801  
34312          0.000000              0.0  0.445085  
4802           1.332660              0.0 -0.368621  
25895          0.000000              0.0 -1.284779  
...                 ...              ...       ...  
18045          1.190419              0.0 -0.812429  
5425           2.103596              0.0 -0.133319  
12819          2.103596              0.0  0.469341  
33659          1.530139              0.0 -0.428356  
19531          1.041572              0.0 -1.047058  

[13109 rows x 31 columns]
2025-12-03 12:14:35,910:INFO:get_config() successfully completed......................................
2025-12-03 12:14:35,910:INFO:Initializing get_config()
2025-12-03 12:14:35,910:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000278EABAEE90>, variable=y_test)
2025-12-03 12:14:35,910:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-12-03 12:14:35,910:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-12-03 12:14:35,910:INFO:Variable:  returned as 28456    0.0
8993     0.0
34312    0.0
4802     0.0
25895    0.0
        ... 
18045    0.0
5425     0.0
12819    0.0
33659    0.0
19531    0.0
Name: HeartDisease, Length: 13109, dtype: float32
2025-12-03 12:14:35,910:INFO:get_config() successfully completed......................................
2025-12-03 12:14:36,083:INFO:Initializing get_config()
2025-12-03 12:14:36,084:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000278EABAEE90>, variable=X_train_transformed)
2025-12-03 12:14:36,143:INFO:Variable: X_train returned as             Age  IncomeRatio  SystolicBP       BMI  WaistCircumference  \
15208  0.281967     1.073479   -0.029334  0.320615           -0.184205   
25325 -0.959685     0.336748   -1.131593 -1.420125           -1.360604   
5132  -0.499814    -0.472688   -0.718246 -0.222594           -0.051710   
17217 -0.177904    -0.894370   -0.355002 -0.592965           -0.099890   
6382  -0.108923     0.093300    0.697155  2.851479            1.783151   
...         ...          ...         ...       ...                 ...   
72714  0.209599    -0.574548    0.093968 -0.084224            0.048339   
72715  0.410044     0.140941    1.545471  0.784710            0.534682   
72716  0.336375     0.706350   -0.225611 -0.316094            0.087200   
72717  0.465916     0.152440   -0.649398  0.648433            0.661659   
72718  0.465916     0.204596    0.822492 -0.260262           -0.112576   

         Height  TotalCholesterol  Triglycerides       LDL       HDL  ...  \
15208 -0.949100          0.573893       0.496366  0.004515  0.470102  ...   
25325 -0.676156          0.027513      -0.418808  0.000788  0.460074  ...   
5132   0.887068          0.164048       0.383587  0.688473 -1.055073  ...   
17217  0.856051          0.206410       0.239340  0.002372 -0.072797  ...   
6382   0.111659          0.796802       0.552888  0.002599  0.944927  ...   
...         ...               ...            ...       ...       ...  ...   
72714  0.529966          0.966537       0.338163  2.847690 -1.107269  ...   
72715 -0.193825          1.002684       1.137561  0.006116  0.578610  ...   
72716  0.850772          0.698204       0.800524  0.005273  0.320829  ...   
72717  0.196053         -0.854465      -0.645063 -1.338104 -0.093582  ...   
72718 -0.754937         -1.171319      -0.645250 -1.650124 -0.583170  ...   

       Race_5.0  Race_1.0  Race_4.0  Race_3.0  Race_2.0  Education   Smoking  \
15208  1.000000       0.0  0.000000 -0.145400   0.00000  -0.656011 -0.319015   
25325  0.000000       1.0  0.000000 -0.145400   0.00000   0.170835 -0.319015   
5132   0.000000       1.0  0.000000 -0.145400   0.00000  -0.656011  0.680985   
17217  0.000000       0.0  3.236622 -0.145400   0.00000  -0.065383  0.680985   
6382   0.000000       0.0  3.236622 -0.145400   0.00000   0.525245  0.680985   
...         ...       ...       ...       ...       ...        ...       ...   
72714  0.000000       0.0  3.236622 -0.145400   0.00000   0.525245  0.672319   
72715  0.000000       0.0  0.000000  0.854600   0.00000  -0.656011  0.680985   
72716  0.402414       0.0  0.000000  0.452186   0.00000   0.409971  0.680985   
72717  0.000000       0.0  0.000000 -0.030279   0.88488   1.115873  0.680985   
72718  0.000000       0.0  0.000000  0.854600   0.00000  -0.067269 -0.315822   

       PhysicalActivity  HealthInsurance   Alcohol  
15208          0.000000              0.0 -1.284779  
25325          0.000000              0.0  0.445085  
5132           0.000000             -1.0  0.118386  
17217          0.000000              0.0  0.445085  
6382           0.000000              0.0  0.451028  
...                 ...              ...       ...  
72714          0.000000              0.0  0.115540  
72715          0.000000              0.0  0.077133  
72716          0.000000              0.0  0.430065  
72717          0.000000              0.0  0.364598  
72718          0.006717              0.0 -0.723887  

[59610 rows x 31 columns]
2025-12-03 12:14:36,143:INFO:get_config() successfully completed......................................
2025-12-03 12:14:36,143:INFO:Initializing get_config()
2025-12-03 12:14:36,143:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000278EABAEE90>, variable=y_train)
2025-12-03 12:14:36,143:INFO:Variable: 'y_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_train_transformed' instead.
2025-12-03 12:14:36,143:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_train_transformed' instead.

2025-12-03 12:14:36,150:INFO:Variable:  returned as 15208    0.0
25325    0.0
5132     0.0
17217    0.0
6382     0.0
        ... 
6265     0.0
42694    0.0
13399    0.0
39959    0.0
6616     0.0
Name: HeartDisease, Length: 30586, dtype: float32
2025-12-03 12:14:36,150:INFO:get_config() successfully completed......................................
2025-12-03 12:14:36,152:INFO:Initializing get_config()
2025-12-03 12:14:36,152:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000278EABAEE90>, variable=X_test_transformed)
2025-12-03 12:14:36,236:INFO:Variable: X_test returned as             Age  IncomeRatio  SystolicBP       BMI  WaistCircumference  \
28456 -1.166627    -0.346668   -0.856028 -1.444817           -1.505144   
8993   0.144006     0.336748    1.661631  0.616912            0.650918   
34312  0.029038     0.094402    0.120974  0.320615            0.349792   
4802  -1.235607     0.337310   -0.679800 -0.555589           -0.935736   
25895  0.029038     1.529090   -0.455207 -0.552146           -0.411032   
...         ...          ...         ...       ...                 ...   
18045 -1.258601    -0.075240   -0.902556 -1.667039           -1.990961   
5425  -0.085930     0.470814    1.711734 -0.123829           -0.083830   
12819  0.235980     0.002310    0.478266  0.246541            0.711143   
33659 -1.212614     1.325519   -0.862074 -0.975681           -1.485069   
19531 -1.281594    -0.395137   -0.847590 -1.395434           -1.846420   

         Height  TotalCholesterol  Triglycerides       LDL       HDL  ...  \
28456 -1.817558         -0.075919      -0.645504 -0.018918  0.565429  ...   
8993  -0.645140          0.703061       0.628124  0.004972  0.591985  ...   
34312  0.583108         -0.117177       0.871284 -0.747548 -1.113897  ...   
4802  -0.974805         -0.177199      -0.485069  0.000613  0.052365  ...   
25895  0.081554          0.820238       1.262972  0.006556 -0.055073  ...   
...         ...               ...            ...       ...       ...  ...   
18045 -3.281529         -0.317991      -0.645314 -0.614949  0.543115  ...   
5425  -0.006203          0.398401      -0.206369  0.808141  0.297868  ...   
12819  1.513598         -0.679626      -0.644711 -0.152776 -0.819779  ...   
33659 -2.071891         -0.984285      -0.645722 -2.065437  0.297868  ...   
19531 -3.659929         -0.332706      -0.645328 -0.652405  0.543209  ...   

       Race_5.0  Race_1.0  Race_4.0  Race_3.0  Race_2.0  Education   Smoking  \
28456       1.0       0.0  0.000000   -0.1454       0.0  -0.023013 -0.319015   
8993        0.0       0.0  3.236622   -0.1454       0.0   0.525245  0.680985   
34312       0.0       0.0  0.000000    0.8546       0.0  -0.656011 -0.319015   
4802        1.0       0.0  0.000000   -0.1454       0.0   0.246788 -0.245402   
25895       0.0       0.0  0.000000    0.8546       0.0   1.115873 -0.319015   
...         ...       ...       ...       ...       ...        ...       ...   
18045       0.0       0.0  0.000000    0.8546       0.0  -0.786652 -0.319015   
5425        0.0       0.0  3.236622   -0.1454       0.0   0.525245  0.680985   
12819       0.0       0.0  0.000000    0.8546       0.0   1.115873  0.680985   
33659       0.0       0.0  3.236622   -0.1454       0.0   0.242351 -0.319015   
19531       1.0       0.0  0.000000   -0.1454       0.0  -0.813970 -0.319015   

       PhysicalActivity  HealthInsurance   Alcohol  
28456          0.869504              0.0 -0.854408  
8993           0.000000              0.0 -0.112801  
34312          0.000000              0.0  0.445085  
4802           1.332660              0.0 -0.368621  
25895          0.000000              0.0 -1.284779  
...                 ...              ...       ...  
18045          1.190419              0.0 -0.812429  
5425           2.103596              0.0 -0.133319  
12819          2.103596              0.0  0.469341  
33659          1.530139              0.0 -0.428356  
19531          1.041572              0.0 -1.047058  

[13109 rows x 31 columns]
2025-12-03 12:14:36,236:INFO:get_config() successfully completed......................................
2025-12-03 12:14:36,236:INFO:Initializing get_config()
2025-12-03 12:14:36,236:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000278EABAEE90>, variable=y_test)
2025-12-03 12:14:36,236:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-12-03 12:14:36,236:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-12-03 12:14:36,241:INFO:Variable:  returned as 28456    0.0
8993     0.0
34312    0.0
4802     0.0
25895    0.0
        ... 
18045    0.0
5425     0.0
12819    0.0
33659    0.0
19531    0.0
Name: HeartDisease, Length: 13109, dtype: float32
2025-12-03 12:14:36,241:INFO:get_config() successfully completed......................................
2025-12-03 12:14:36,378:INFO:Initializing get_config()
2025-12-03 12:14:36,378:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000278EABAEE90>, variable=X_test_transformed)
2025-12-03 12:14:36,461:INFO:Variable: X_test returned as             Age  IncomeRatio  SystolicBP       BMI  WaistCircumference  \
28456 -1.166627    -0.346668   -0.856028 -1.444817           -1.505144   
8993   0.144006     0.336748    1.661631  0.616912            0.650918   
34312  0.029038     0.094402    0.120974  0.320615            0.349792   
4802  -1.235607     0.337310   -0.679800 -0.555589           -0.935736   
25895  0.029038     1.529090   -0.455207 -0.552146           -0.411032   
...         ...          ...         ...       ...                 ...   
18045 -1.258601    -0.075240   -0.902556 -1.667039           -1.990961   
5425  -0.085930     0.470814    1.711734 -0.123829           -0.083830   
12819  0.235980     0.002310    0.478266  0.246541            0.711143   
33659 -1.212614     1.325519   -0.862074 -0.975681           -1.485069   
19531 -1.281594    -0.395137   -0.847590 -1.395434           -1.846420   

         Height  TotalCholesterol  Triglycerides       LDL       HDL  ...  \
28456 -1.817558         -0.075919      -0.645504 -0.018918  0.565429  ...   
8993  -0.645140          0.703061       0.628124  0.004972  0.591985  ...   
34312  0.583108         -0.117177       0.871284 -0.747548 -1.113897  ...   
4802  -0.974805         -0.177199      -0.485069  0.000613  0.052365  ...   
25895  0.081554          0.820238       1.262972  0.006556 -0.055073  ...   
...         ...               ...            ...       ...       ...  ...   
18045 -3.281529         -0.317991      -0.645314 -0.614949  0.543115  ...   
5425  -0.006203          0.398401      -0.206369  0.808141  0.297868  ...   
12819  1.513598         -0.679626      -0.644711 -0.152776 -0.819779  ...   
33659 -2.071891         -0.984285      -0.645722 -2.065437  0.297868  ...   
19531 -3.659929         -0.332706      -0.645328 -0.652405  0.543209  ...   

       Race_5.0  Race_1.0  Race_4.0  Race_3.0  Race_2.0  Education   Smoking  \
28456       1.0       0.0  0.000000   -0.1454       0.0  -0.023013 -0.319015   
8993        0.0       0.0  3.236622   -0.1454       0.0   0.525245  0.680985   
34312       0.0       0.0  0.000000    0.8546       0.0  -0.656011 -0.319015   
4802        1.0       0.0  0.000000   -0.1454       0.0   0.246788 -0.245402   
25895       0.0       0.0  0.000000    0.8546       0.0   1.115873 -0.319015   
...         ...       ...       ...       ...       ...        ...       ...   
18045       0.0       0.0  0.000000    0.8546       0.0  -0.786652 -0.319015   
5425        0.0       0.0  3.236622   -0.1454       0.0   0.525245  0.680985   
12819       0.0       0.0  0.000000    0.8546       0.0   1.115873  0.680985   
33659       0.0       0.0  3.236622   -0.1454       0.0   0.242351 -0.319015   
19531       1.0       0.0  0.000000   -0.1454       0.0  -0.813970 -0.319015   

       PhysicalActivity  HealthInsurance   Alcohol  
28456          0.869504              0.0 -0.854408  
8993           0.000000              0.0 -0.112801  
34312          0.000000              0.0  0.445085  
4802           1.332660              0.0 -0.368621  
25895          0.000000              0.0 -1.284779  
...                 ...              ...       ...  
18045          1.190419              0.0 -0.812429  
5425           2.103596              0.0 -0.133319  
12819          2.103596              0.0  0.469341  
33659          1.530139              0.0 -0.428356  
19531          1.041572              0.0 -1.047058  

[13109 rows x 31 columns]
2025-12-03 12:14:36,461:INFO:get_config() successfully completed......................................
2025-12-03 12:14:36,491:INFO:Initializing get_config()
2025-12-03 12:14:36,492:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000278EABAEE90>, variable=y_test)
2025-12-03 12:14:36,492:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-12-03 12:14:36,492:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-12-03 12:14:36,498:INFO:Variable:  returned as 28456    0.0
8993     0.0
34312    0.0
4802     0.0
25895    0.0
        ... 
18045    0.0
5425     0.0
12819    0.0
33659    0.0
19531    0.0
Name: HeartDisease, Length: 13109, dtype: float32
2025-12-03 12:14:36,498:INFO:get_config() successfully completed......................................
2025-12-03 12:14:36,501:INFO:Initializing get_config()
2025-12-03 12:14:36,501:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000278EABAEE90>, variable=y_test)
2025-12-03 12:14:36,501:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-12-03 12:14:36,501:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-12-03 12:14:36,507:INFO:Variable:  returned as 28456    0.0
8993     0.0
34312    0.0
4802     0.0
25895    0.0
        ... 
18045    0.0
5425     0.0
12819    0.0
33659    0.0
19531    0.0
Name: HeartDisease, Length: 13109, dtype: float32
2025-12-03 12:14:36,507:INFO:get_config() successfully completed......................................
2025-12-03 12:14:36,509:INFO:Initializing get_config()
2025-12-03 12:14:36,509:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000278EABAEE90>, variable=X_test_transformed)
2025-12-03 12:14:36,585:INFO:Variable: X_test returned as             Age  IncomeRatio  SystolicBP       BMI  WaistCircumference  \
28456 -1.166627    -0.346668   -0.856028 -1.444817           -1.505144   
8993   0.144006     0.336748    1.661631  0.616912            0.650918   
34312  0.029038     0.094402    0.120974  0.320615            0.349792   
4802  -1.235607     0.337310   -0.679800 -0.555589           -0.935736   
25895  0.029038     1.529090   -0.455207 -0.552146           -0.411032   
...         ...          ...         ...       ...                 ...   
18045 -1.258601    -0.075240   -0.902556 -1.667039           -1.990961   
5425  -0.085930     0.470814    1.711734 -0.123829           -0.083830   
12819  0.235980     0.002310    0.478266  0.246541            0.711143   
33659 -1.212614     1.325519   -0.862074 -0.975681           -1.485069   
19531 -1.281594    -0.395137   -0.847590 -1.395434           -1.846420   

         Height  TotalCholesterol  Triglycerides       LDL       HDL  ...  \
28456 -1.817558         -0.075919      -0.645504 -0.018918  0.565429  ...   
8993  -0.645140          0.703061       0.628124  0.004972  0.591985  ...   
34312  0.583108         -0.117177       0.871284 -0.747548 -1.113897  ...   
4802  -0.974805         -0.177199      -0.485069  0.000613  0.052365  ...   
25895  0.081554          0.820238       1.262972  0.006556 -0.055073  ...   
...         ...               ...            ...       ...       ...  ...   
18045 -3.281529         -0.317991      -0.645314 -0.614949  0.543115  ...   
5425  -0.006203          0.398401      -0.206369  0.808141  0.297868  ...   
12819  1.513598         -0.679626      -0.644711 -0.152776 -0.819779  ...   
33659 -2.071891         -0.984285      -0.645722 -2.065437  0.297868  ...   
19531 -3.659929         -0.332706      -0.645328 -0.652405  0.543209  ...   

       Race_5.0  Race_1.0  Race_4.0  Race_3.0  Race_2.0  Education   Smoking  \
28456       1.0       0.0  0.000000   -0.1454       0.0  -0.023013 -0.319015   
8993        0.0       0.0  3.236622   -0.1454       0.0   0.525245  0.680985   
34312       0.0       0.0  0.000000    0.8546       0.0  -0.656011 -0.319015   
4802        1.0       0.0  0.000000   -0.1454       0.0   0.246788 -0.245402   
25895       0.0       0.0  0.000000    0.8546       0.0   1.115873 -0.319015   
...         ...       ...       ...       ...       ...        ...       ...   
18045       0.0       0.0  0.000000    0.8546       0.0  -0.786652 -0.319015   
5425        0.0       0.0  3.236622   -0.1454       0.0   0.525245  0.680985   
12819       0.0       0.0  0.000000    0.8546       0.0   1.115873  0.680985   
33659       0.0       0.0  3.236622   -0.1454       0.0   0.242351 -0.319015   
19531       1.0       0.0  0.000000   -0.1454       0.0  -0.813970 -0.319015   

       PhysicalActivity  HealthInsurance   Alcohol  
28456          0.869504              0.0 -0.854408  
8993           0.000000              0.0 -0.112801  
34312          0.000000              0.0  0.445085  
4802           1.332660              0.0 -0.368621  
25895          0.000000              0.0 -1.284779  
...                 ...              ...       ...  
18045          1.190419              0.0 -0.812429  
5425           2.103596              0.0 -0.133319  
12819          2.103596              0.0  0.469341  
33659          1.530139              0.0 -0.428356  
19531          1.041572              0.0 -1.047058  

[13109 rows x 31 columns]
2025-12-03 12:14:36,586:INFO:get_config() successfully completed......................................
2025-12-03 12:14:36,587:INFO:Initializing get_config()
2025-12-03 12:14:36,587:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000278EABAEE90>, variable=y_test)
2025-12-03 12:14:36,587:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-12-03 12:14:36,587:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-12-03 12:14:36,591:INFO:Variable:  returned as 28456    0.0
8993     0.0
34312    0.0
4802     0.0
25895    0.0
        ... 
18045    0.0
5425     0.0
12819    0.0
33659    0.0
19531    0.0
Name: HeartDisease, Length: 13109, dtype: float32
2025-12-03 12:14:36,591:INFO:get_config() successfully completed......................................
2025-12-03 12:14:36,594:INFO:Initializing get_config()
2025-12-03 12:14:36,594:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000278EABAEE90>, variable=y_test)
2025-12-03 12:14:36,594:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-12-03 12:14:36,594:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-12-03 12:14:36,599:INFO:Variable:  returned as 28456    0.0
8993     0.0
34312    0.0
4802     0.0
25895    0.0
        ... 
18045    0.0
5425     0.0
12819    0.0
33659    0.0
19531    0.0
Name: HeartDisease, Length: 13109, dtype: float32
2025-12-03 12:14:36,599:INFO:get_config() successfully completed......................................
2025-12-03 12:14:36,602:INFO:Initializing get_config()
2025-12-03 12:14:36,602:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000278EABAEE90>, variable=X_test_transformed)
2025-12-03 12:14:36,671:INFO:Variable: X_test returned as             Age  IncomeRatio  SystolicBP       BMI  WaistCircumference  \
28456 -1.166627    -0.346668   -0.856028 -1.444817           -1.505144   
8993   0.144006     0.336748    1.661631  0.616912            0.650918   
34312  0.029038     0.094402    0.120974  0.320615            0.349792   
4802  -1.235607     0.337310   -0.679800 -0.555589           -0.935736   
25895  0.029038     1.529090   -0.455207 -0.552146           -0.411032   
...         ...          ...         ...       ...                 ...   
18045 -1.258601    -0.075240   -0.902556 -1.667039           -1.990961   
5425  -0.085930     0.470814    1.711734 -0.123829           -0.083830   
12819  0.235980     0.002310    0.478266  0.246541            0.711143   
33659 -1.212614     1.325519   -0.862074 -0.975681           -1.485069   
19531 -1.281594    -0.395137   -0.847590 -1.395434           -1.846420   

         Height  TotalCholesterol  Triglycerides       LDL       HDL  ...  \
28456 -1.817558         -0.075919      -0.645504 -0.018918  0.565429  ...   
8993  -0.645140          0.703061       0.628124  0.004972  0.591985  ...   
34312  0.583108         -0.117177       0.871284 -0.747548 -1.113897  ...   
4802  -0.974805         -0.177199      -0.485069  0.000613  0.052365  ...   
25895  0.081554          0.820238       1.262972  0.006556 -0.055073  ...   
...         ...               ...            ...       ...       ...  ...   
18045 -3.281529         -0.317991      -0.645314 -0.614949  0.543115  ...   
5425  -0.006203          0.398401      -0.206369  0.808141  0.297868  ...   
12819  1.513598         -0.679626      -0.644711 -0.152776 -0.819779  ...   
33659 -2.071891         -0.984285      -0.645722 -2.065437  0.297868  ...   
19531 -3.659929         -0.332706      -0.645328 -0.652405  0.543209  ...   

       Race_5.0  Race_1.0  Race_4.0  Race_3.0  Race_2.0  Education   Smoking  \
28456       1.0       0.0  0.000000   -0.1454       0.0  -0.023013 -0.319015   
8993        0.0       0.0  3.236622   -0.1454       0.0   0.525245  0.680985   
34312       0.0       0.0  0.000000    0.8546       0.0  -0.656011 -0.319015   
4802        1.0       0.0  0.000000   -0.1454       0.0   0.246788 -0.245402   
25895       0.0       0.0  0.000000    0.8546       0.0   1.115873 -0.319015   
...         ...       ...       ...       ...       ...        ...       ...   
18045       0.0       0.0  0.000000    0.8546       0.0  -0.786652 -0.319015   
5425        0.0       0.0  3.236622   -0.1454       0.0   0.525245  0.680985   
12819       0.0       0.0  0.000000    0.8546       0.0   1.115873  0.680985   
33659       0.0       0.0  3.236622   -0.1454       0.0   0.242351 -0.319015   
19531       1.0       0.0  0.000000   -0.1454       0.0  -0.813970 -0.319015   

       PhysicalActivity  HealthInsurance   Alcohol  
28456          0.869504              0.0 -0.854408  
8993           0.000000              0.0 -0.112801  
34312          0.000000              0.0  0.445085  
4802           1.332660              0.0 -0.368621  
25895          0.000000              0.0 -1.284779  
...                 ...              ...       ...  
18045          1.190419              0.0 -0.812429  
5425           2.103596              0.0 -0.133319  
12819          2.103596              0.0  0.469341  
33659          1.530139              0.0 -0.428356  
19531          1.041572              0.0 -1.047058  

[13109 rows x 31 columns]
2025-12-03 12:14:36,671:INFO:get_config() successfully completed......................................
2025-12-03 12:14:36,743:INFO:Initializing get_config()
2025-12-03 12:14:36,743:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000278EABAEE90>, variable=y_test)
2025-12-03 12:14:36,744:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-12-03 12:14:36,744:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-12-03 12:14:36,749:INFO:Variable:  returned as 28456    0.0
8993     0.0
34312    0.0
4802     0.0
25895    0.0
        ... 
18045    0.0
5425     0.0
12819    0.0
33659    0.0
19531    0.0
Name: HeartDisease, Length: 13109, dtype: float32
2025-12-03 12:14:36,749:INFO:get_config() successfully completed......................................
2025-12-03 12:14:36,750:INFO:Initializing get_config()
2025-12-03 12:14:36,750:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000278EABAEE90>, variable=y_test)
2025-12-03 12:14:36,750:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-12-03 12:14:36,751:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-12-03 12:14:36,756:INFO:Variable:  returned as 28456    0.0
8993     0.0
34312    0.0
4802     0.0
25895    0.0
        ... 
18045    0.0
5425     0.0
12819    0.0
33659    0.0
19531    0.0
Name: HeartDisease, Length: 13109, dtype: float32
2025-12-03 12:14:36,756:INFO:get_config() successfully completed......................................
2025-12-03 12:14:36,761:INFO:Initializing get_config()
2025-12-03 12:14:36,761:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000278EABAEE90>, variable=y_test)
2025-12-03 12:14:36,762:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-12-03 12:14:36,762:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-12-03 12:14:36,769:INFO:Variable:  returned as 28456    0.0
8993     0.0
34312    0.0
4802     0.0
25895    0.0
        ... 
18045    0.0
5425     0.0
12819    0.0
33659    0.0
19531    0.0
Name: HeartDisease, Length: 13109, dtype: float32
2025-12-03 12:14:36,769:INFO:get_config() successfully completed......................................
2025-12-03 12:14:36,770:INFO:Initializing get_config()
2025-12-03 12:14:36,770:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000278EABAEE90>, variable=X_test_transformed)
2025-12-03 12:14:36,843:INFO:Variable: X_test returned as             Age  IncomeRatio  SystolicBP       BMI  WaistCircumference  \
28456 -1.166627    -0.346668   -0.856028 -1.444817           -1.505144   
8993   0.144006     0.336748    1.661631  0.616912            0.650918   
34312  0.029038     0.094402    0.120974  0.320615            0.349792   
4802  -1.235607     0.337310   -0.679800 -0.555589           -0.935736   
25895  0.029038     1.529090   -0.455207 -0.552146           -0.411032   
...         ...          ...         ...       ...                 ...   
18045 -1.258601    -0.075240   -0.902556 -1.667039           -1.990961   
5425  -0.085930     0.470814    1.711734 -0.123829           -0.083830   
12819  0.235980     0.002310    0.478266  0.246541            0.711143   
33659 -1.212614     1.325519   -0.862074 -0.975681           -1.485069   
19531 -1.281594    -0.395137   -0.847590 -1.395434           -1.846420   

         Height  TotalCholesterol  Triglycerides       LDL       HDL  ...  \
28456 -1.817558         -0.075919      -0.645504 -0.018918  0.565429  ...   
8993  -0.645140          0.703061       0.628124  0.004972  0.591985  ...   
34312  0.583108         -0.117177       0.871284 -0.747548 -1.113897  ...   
4802  -0.974805         -0.177199      -0.485069  0.000613  0.052365  ...   
25895  0.081554          0.820238       1.262972  0.006556 -0.055073  ...   
...         ...               ...            ...       ...       ...  ...   
18045 -3.281529         -0.317991      -0.645314 -0.614949  0.543115  ...   
5425  -0.006203          0.398401      -0.206369  0.808141  0.297868  ...   
12819  1.513598         -0.679626      -0.644711 -0.152776 -0.819779  ...   
33659 -2.071891         -0.984285      -0.645722 -2.065437  0.297868  ...   
19531 -3.659929         -0.332706      -0.645328 -0.652405  0.543209  ...   

       Race_5.0  Race_1.0  Race_4.0  Race_3.0  Race_2.0  Education   Smoking  \
28456       1.0       0.0  0.000000   -0.1454       0.0  -0.023013 -0.319015   
8993        0.0       0.0  3.236622   -0.1454       0.0   0.525245  0.680985   
34312       0.0       0.0  0.000000    0.8546       0.0  -0.656011 -0.319015   
4802        1.0       0.0  0.000000   -0.1454       0.0   0.246788 -0.245402   
25895       0.0       0.0  0.000000    0.8546       0.0   1.115873 -0.319015   
...         ...       ...       ...       ...       ...        ...       ...   
18045       0.0       0.0  0.000000    0.8546       0.0  -0.786652 -0.319015   
5425        0.0       0.0  3.236622   -0.1454       0.0   0.525245  0.680985   
12819       0.0       0.0  0.000000    0.8546       0.0   1.115873  0.680985   
33659       0.0       0.0  3.236622   -0.1454       0.0   0.242351 -0.319015   
19531       1.0       0.0  0.000000   -0.1454       0.0  -0.813970 -0.319015   

       PhysicalActivity  HealthInsurance   Alcohol  
28456          0.869504              0.0 -0.854408  
8993           0.000000              0.0 -0.112801  
34312          0.000000              0.0  0.445085  
4802           1.332660              0.0 -0.368621  
25895          0.000000              0.0 -1.284779  
...                 ...              ...       ...  
18045          1.190419              0.0 -0.812429  
5425           2.103596              0.0 -0.133319  
12819          2.103596              0.0  0.469341  
33659          1.530139              0.0 -0.428356  
19531          1.041572              0.0 -1.047058  

[13109 rows x 31 columns]
2025-12-03 12:14:36,843:INFO:get_config() successfully completed......................................
2025-12-03 12:14:36,876:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pandas\io\formats\style.py:3823: RuntimeWarning: invalid value encountered in scalar multiply

2025-12-03 12:14:36,910:INFO:Initializing plot_model()
2025-12-03 12:14:36,911:INFO:plot_model(plot=error, fold=None, verbose=True, display=None, display_format=None, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000278EABAEE90>, system=True)
2025-12-03 12:14:36,911:INFO:Checking exceptions
2025-12-03 12:14:36,929:INFO:Preloading libraries
2025-12-03 12:14:36,938:INFO:Copying training dataset
2025-12-03 12:14:36,938:INFO:Plot type: error
2025-12-03 12:14:37,179:INFO:Fitting Model
2025-12-03 12:14:37,180:INFO:Scoring test/hold-out set
2025-12-03 12:14:37,359:INFO:Visual Rendered Successfully
2025-12-03 12:14:37,528:INFO:plot_model() successfully completed......................................
2025-12-03 12:14:37,530:INFO:Initializing get_config()
2025-12-03 12:14:37,530:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000278EABAEE90>, variable=train_transformed)
2025-12-03 12:14:37,575:INFO:Variable: train returned as             Age  IncomeRatio  SystolicBP       BMI  WaistCircumference  \
15208  0.281967     1.073479   -0.029334  0.320615           -0.184205   
25325 -0.959685     0.336748   -1.131593 -1.420125           -1.360604   
5132  -0.499814    -0.472688   -0.718246 -0.222594           -0.051710   
17217 -0.177904    -0.894370   -0.355002 -0.592965           -0.099890   
6382  -0.108923     0.093300    0.697155  2.851479            1.783151   
...         ...          ...         ...       ...                 ...   
72714  0.209599    -0.574548    0.093968 -0.084224            0.048339   
72715  0.410044     0.140941    1.545471  0.784710            0.534682   
72716  0.336375     0.706350   -0.225611 -0.316094            0.087200   
72717  0.465916     0.152440   -0.649398  0.648433            0.661659   
72718  0.465916     0.204596    0.822492 -0.260262           -0.112576   

         Height  TotalCholesterol  Triglycerides       LDL       HDL  ...  \
15208 -0.949100          0.573893       0.496366  0.004515  0.470102  ...   
25325 -0.676156          0.027513      -0.418808  0.000788  0.460074  ...   
5132   0.887068          0.164048       0.383587  0.688473 -1.055073  ...   
17217  0.856051          0.206410       0.239340  0.002372 -0.072797  ...   
6382   0.111659          0.796802       0.552888  0.002599  0.944927  ...   
...         ...               ...            ...       ...       ...  ...   
72714  0.529966          0.966537       0.338163  2.847690 -1.107269  ...   
72715 -0.193825          1.002684       1.137561  0.006116  0.578610  ...   
72716  0.850772          0.698204       0.800524  0.005273  0.320829  ...   
72717  0.196053         -0.854465      -0.645063 -1.338104 -0.093582  ...   
72718 -0.754937         -1.171319      -0.645250 -1.650124 -0.583170  ...   

       Race_1.0  Race_4.0  Race_3.0  Race_2.0  Education   Smoking  \
15208       0.0  0.000000 -0.145400   0.00000  -0.656011 -0.319015   
25325       1.0  0.000000 -0.145400   0.00000   0.170835 -0.319015   
5132        1.0  0.000000 -0.145400   0.00000  -0.656011  0.680985   
17217       0.0  3.236622 -0.145400   0.00000  -0.065383  0.680985   
6382        0.0  3.236622 -0.145400   0.00000   0.525245  0.680985   
...         ...       ...       ...       ...        ...       ...   
72714       0.0  3.236622 -0.145400   0.00000   0.525245  0.672319   
72715       0.0  0.000000  0.854600   0.00000  -0.656011  0.680985   
72716       0.0  0.000000  0.452186   0.00000   0.409971  0.680985   
72717       0.0  0.000000 -0.030279   0.88488   1.115873  0.680985   
72718       0.0  0.000000  0.854600   0.00000  -0.067269 -0.315822   

       PhysicalActivity  HealthInsurance   Alcohol  HeartDisease  
15208          0.000000              0.0 -1.284779           0.0  
25325          0.000000              0.0  0.445085           0.0  
5132           0.000000             -1.0  0.118386           0.0  
17217          0.000000              0.0  0.445085           0.0  
6382           0.000000              0.0  0.451028           0.0  
...                 ...              ...       ...           ...  
72714          0.000000              0.0  0.115540           1.0  
72715          0.000000              0.0  0.077133           1.0  
72716          0.000000              0.0  0.430065           1.0  
72717          0.000000              0.0  0.364598           1.0  
72718          0.006717              0.0 -0.723887           1.0  

[59610 rows x 32 columns]
2025-12-03 12:14:37,576:INFO:get_config() successfully completed......................................
2025-12-03 12:14:37,576:INFO:Initializing get_config()
2025-12-03 12:14:37,576:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000278EABAEE90>, variable=target_param)
2025-12-03 12:14:37,576:INFO:Variable:  returned as HeartDisease
2025-12-03 12:14:37,576:INFO:get_config() successfully completed......................................
2025-12-03 12:14:47,794:INFO:Initializing get_config()
2025-12-03 12:14:47,794:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000278EABAEE90>, variable=X_test_transformed)
2025-12-03 12:14:47,874:INFO:Variable: X_test returned as             Age  IncomeRatio  SystolicBP       BMI  WaistCircumference  \
28456 -1.166627    -0.346668   -0.856028 -1.444817           -1.505144   
8993   0.144006     0.336748    1.661631  0.616912            0.650918   
34312  0.029038     0.094402    0.120974  0.320615            0.349792   
4802  -1.235607     0.337310   -0.679800 -0.555589           -0.935736   
25895  0.029038     1.529090   -0.455207 -0.552146           -0.411032   
...         ...          ...         ...       ...                 ...   
18045 -1.258601    -0.075240   -0.902556 -1.667039           -1.990961   
5425  -0.085930     0.470814    1.711734 -0.123829           -0.083830   
12819  0.235980     0.002310    0.478266  0.246541            0.711143   
33659 -1.212614     1.325519   -0.862074 -0.975681           -1.485069   
19531 -1.281594    -0.395137   -0.847590 -1.395434           -1.846420   

         Height  TotalCholesterol  Triglycerides       LDL       HDL  ...  \
28456 -1.817558         -0.075919      -0.645504 -0.018918  0.565429  ...   
8993  -0.645140          0.703061       0.628124  0.004972  0.591985  ...   
34312  0.583108         -0.117177       0.871284 -0.747548 -1.113897  ...   
4802  -0.974805         -0.177199      -0.485069  0.000613  0.052365  ...   
25895  0.081554          0.820238       1.262972  0.006556 -0.055073  ...   
...         ...               ...            ...       ...       ...  ...   
18045 -3.281529         -0.317991      -0.645314 -0.614949  0.543115  ...   
5425  -0.006203          0.398401      -0.206369  0.808141  0.297868  ...   
12819  1.513598         -0.679626      -0.644711 -0.152776 -0.819779  ...   
33659 -2.071891         -0.984285      -0.645722 -2.065437  0.297868  ...   
19531 -3.659929         -0.332706      -0.645328 -0.652405  0.543209  ...   

       Race_5.0  Race_1.0  Race_4.0  Race_3.0  Race_2.0  Education   Smoking  \
28456       1.0       0.0  0.000000   -0.1454       0.0  -0.023013 -0.319015   
8993        0.0       0.0  3.236622   -0.1454       0.0   0.525245  0.680985   
34312       0.0       0.0  0.000000    0.8546       0.0  -0.656011 -0.319015   
4802        1.0       0.0  0.000000   -0.1454       0.0   0.246788 -0.245402   
25895       0.0       0.0  0.000000    0.8546       0.0   1.115873 -0.319015   
...         ...       ...       ...       ...       ...        ...       ...   
18045       0.0       0.0  0.000000    0.8546       0.0  -0.786652 -0.319015   
5425        0.0       0.0  3.236622   -0.1454       0.0   0.525245  0.680985   
12819       0.0       0.0  0.000000    0.8546       0.0   1.115873  0.680985   
33659       0.0       0.0  3.236622   -0.1454       0.0   0.242351 -0.319015   
19531       1.0       0.0  0.000000   -0.1454       0.0  -0.813970 -0.319015   

       PhysicalActivity  HealthInsurance   Alcohol  
28456          0.869504              0.0 -0.854408  
8993           0.000000              0.0 -0.112801  
34312          0.000000              0.0  0.445085  
4802           1.332660              0.0 -0.368621  
25895          0.000000              0.0 -1.284779  
...                 ...              ...       ...  
18045          1.190419              0.0 -0.812429  
5425           2.103596              0.0 -0.133319  
12819          2.103596              0.0  0.469341  
33659          1.530139              0.0 -0.428356  
19531          1.041572              0.0 -1.047058  

[13109 rows x 31 columns]
2025-12-03 12:14:47,875:INFO:get_config() successfully completed......................................
2025-12-03 12:14:47,904:INFO:Initializing get_config()
2025-12-03 12:14:47,904:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000278EABAEE90>, variable=y_test)
2025-12-03 12:14:47,904:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-12-03 12:14:47,904:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-12-03 12:14:47,909:INFO:Variable:  returned as 28456    0.0
8993     0.0
34312    0.0
4802     0.0
25895    0.0
        ... 
18045    0.0
5425     0.0
12819    0.0
33659    0.0
19531    0.0
Name: HeartDisease, Length: 13109, dtype: float32
2025-12-03 12:14:47,909:INFO:get_config() successfully completed......................................
2025-12-03 12:14:47,909:INFO:Initializing get_config()
2025-12-03 12:14:47,909:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000278EABAEE90>, variable=y_test)
2025-12-03 12:14:47,909:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-12-03 12:14:47,909:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-12-03 12:14:47,909:INFO:Variable:  returned as 28456    0.0
8993     0.0
34312    0.0
4802     0.0
25895    0.0
        ... 
18045    0.0
5425     0.0
12819    0.0
33659    0.0
19531    0.0
Name: HeartDisease, Length: 13109, dtype: float32
2025-12-03 12:14:47,909:INFO:get_config() successfully completed......................................
2025-12-03 12:14:47,921:INFO:Initializing get_config()
2025-12-03 12:14:47,922:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000278EABAEE90>, variable=X_test_transformed)
2025-12-03 12:14:48,026:INFO:Variable: X_test returned as             Age  IncomeRatio  SystolicBP       BMI  WaistCircumference  \
28456 -1.166627    -0.346668   -0.856028 -1.444817           -1.505144   
8993   0.144006     0.336748    1.661631  0.616912            0.650918   
34312  0.029038     0.094402    0.120974  0.320615            0.349792   
4802  -1.235607     0.337310   -0.679800 -0.555589           -0.935736   
25895  0.029038     1.529090   -0.455207 -0.552146           -0.411032   
...         ...          ...         ...       ...                 ...   
18045 -1.258601    -0.075240   -0.902556 -1.667039           -1.990961   
5425  -0.085930     0.470814    1.711734 -0.123829           -0.083830   
12819  0.235980     0.002310    0.478266  0.246541            0.711143   
33659 -1.212614     1.325519   -0.862074 -0.975681           -1.485069   
19531 -1.281594    -0.395137   -0.847590 -1.395434           -1.846420   

         Height  TotalCholesterol  Triglycerides       LDL       HDL  ...  \
28456 -1.817558         -0.075919      -0.645504 -0.018918  0.565429  ...   
8993  -0.645140          0.703061       0.628124  0.004972  0.591985  ...   
34312  0.583108         -0.117177       0.871284 -0.747548 -1.113897  ...   
4802  -0.974805         -0.177199      -0.485069  0.000613  0.052365  ...   
25895  0.081554          0.820238       1.262972  0.006556 -0.055073  ...   
...         ...               ...            ...       ...       ...  ...   
18045 -3.281529         -0.317991      -0.645314 -0.614949  0.543115  ...   
5425  -0.006203          0.398401      -0.206369  0.808141  0.297868  ...   
12819  1.513598         -0.679626      -0.644711 -0.152776 -0.819779  ...   
33659 -2.071891         -0.984285      -0.645722 -2.065437  0.297868  ...   
19531 -3.659929         -0.332706      -0.645328 -0.652405  0.543209  ...   

       Race_5.0  Race_1.0  Race_4.0  Race_3.0  Race_2.0  Education   Smoking  \
28456       1.0       0.0  0.000000   -0.1454       0.0  -0.023013 -0.319015   
8993        0.0       0.0  3.236622   -0.1454       0.0   0.525245  0.680985   
34312       0.0       0.0  0.000000    0.8546       0.0  -0.656011 -0.319015   
4802        1.0       0.0  0.000000   -0.1454       0.0   0.246788 -0.245402   
25895       0.0       0.0  0.000000    0.8546       0.0   1.115873 -0.319015   
...         ...       ...       ...       ...       ...        ...       ...   
18045       0.0       0.0  0.000000    0.8546       0.0  -0.786652 -0.319015   
5425        0.0       0.0  3.236622   -0.1454       0.0   0.525245  0.680985   
12819       0.0       0.0  0.000000    0.8546       0.0   1.115873  0.680985   
33659       0.0       0.0  3.236622   -0.1454       0.0   0.242351 -0.319015   
19531       1.0       0.0  0.000000   -0.1454       0.0  -0.813970 -0.319015   

       PhysicalActivity  HealthInsurance   Alcohol  
28456          0.869504              0.0 -0.854408  
8993           0.000000              0.0 -0.112801  
34312          0.000000              0.0  0.445085  
4802           1.332660              0.0 -0.368621  
25895          0.000000              0.0 -1.284779  
...                 ...              ...       ...  
18045          1.190419              0.0 -0.812429  
5425           2.103596              0.0 -0.133319  
12819          2.103596              0.0  0.469341  
33659          1.530139              0.0 -0.428356  
19531          1.041572              0.0 -1.047058  

[13109 rows x 31 columns]
2025-12-03 12:14:48,026:INFO:get_config() successfully completed......................................
2025-12-03 12:14:48,028:INFO:Initializing get_config()
2025-12-03 12:14:48,028:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000278EABAEE90>, variable=y_test)
2025-12-03 12:14:48,028:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-12-03 12:14:48,028:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-12-03 12:14:48,034:INFO:Variable:  returned as 28456    0.0
8993     0.0
34312    0.0
4802     0.0
25895    0.0
        ... 
18045    0.0
5425     0.0
12819    0.0
33659    0.0
19531    0.0
Name: HeartDisease, Length: 13109, dtype: float32
2025-12-03 12:14:48,034:INFO:get_config() successfully completed......................................
2025-12-03 12:14:48,035:INFO:Initializing get_config()
2025-12-03 12:14:48,035:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000278EABAEE90>, variable=y_test)
2025-12-03 12:14:48,035:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-12-03 12:14:48,035:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-12-03 12:14:48,039:INFO:Variable:  returned as 28456    0.0
8993     0.0
34312    0.0
4802     0.0
25895    0.0
        ... 
18045    0.0
5425     0.0
12819    0.0
33659    0.0
19531    0.0
Name: HeartDisease, Length: 13109, dtype: float32
2025-12-03 12:14:48,039:INFO:get_config() successfully completed......................................
2025-12-03 12:14:48,043:INFO:Initializing get_config()
2025-12-03 12:14:48,043:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000278EABAEE90>, variable=X_test_transformed)
2025-12-03 12:14:48,131:INFO:Variable: X_test returned as             Age  IncomeRatio  SystolicBP       BMI  WaistCircumference  \
28456 -1.166627    -0.346668   -0.856028 -1.444817           -1.505144   
8993   0.144006     0.336748    1.661631  0.616912            0.650918   
34312  0.029038     0.094402    0.120974  0.320615            0.349792   
4802  -1.235607     0.337310   -0.679800 -0.555589           -0.935736   
25895  0.029038     1.529090   -0.455207 -0.552146           -0.411032   
...         ...          ...         ...       ...                 ...   
18045 -1.258601    -0.075240   -0.902556 -1.667039           -1.990961   
5425  -0.085930     0.470814    1.711734 -0.123829           -0.083830   
12819  0.235980     0.002310    0.478266  0.246541            0.711143   
33659 -1.212614     1.325519   -0.862074 -0.975681           -1.485069   
19531 -1.281594    -0.395137   -0.847590 -1.395434           -1.846420   

         Height  TotalCholesterol  Triglycerides       LDL       HDL  ...  \
28456 -1.817558         -0.075919      -0.645504 -0.018918  0.565429  ...   
8993  -0.645140          0.703061       0.628124  0.004972  0.591985  ...   
34312  0.583108         -0.117177       0.871284 -0.747548 -1.113897  ...   
4802  -0.974805         -0.177199      -0.485069  0.000613  0.052365  ...   
25895  0.081554          0.820238       1.262972  0.006556 -0.055073  ...   
...         ...               ...            ...       ...       ...  ...   
18045 -3.281529         -0.317991      -0.645314 -0.614949  0.543115  ...   
5425  -0.006203          0.398401      -0.206369  0.808141  0.297868  ...   
12819  1.513598         -0.679626      -0.644711 -0.152776 -0.819779  ...   
33659 -2.071891         -0.984285      -0.645722 -2.065437  0.297868  ...   
19531 -3.659929         -0.332706      -0.645328 -0.652405  0.543209  ...   

       Race_5.0  Race_1.0  Race_4.0  Race_3.0  Race_2.0  Education   Smoking  \
28456       1.0       0.0  0.000000   -0.1454       0.0  -0.023013 -0.319015   
8993        0.0       0.0  3.236622   -0.1454       0.0   0.525245  0.680985   
34312       0.0       0.0  0.000000    0.8546       0.0  -0.656011 -0.319015   
4802        1.0       0.0  0.000000   -0.1454       0.0   0.246788 -0.245402   
25895       0.0       0.0  0.000000    0.8546       0.0   1.115873 -0.319015   
...         ...       ...       ...       ...       ...        ...       ...   
18045       0.0       0.0  0.000000    0.8546       0.0  -0.786652 -0.319015   
5425        0.0       0.0  3.236622   -0.1454       0.0   0.525245  0.680985   
12819       0.0       0.0  0.000000    0.8546       0.0   1.115873  0.680985   
33659       0.0       0.0  3.236622   -0.1454       0.0   0.242351 -0.319015   
19531       1.0       0.0  0.000000   -0.1454       0.0  -0.813970 -0.319015   

       PhysicalActivity  HealthInsurance   Alcohol  
28456          0.869504              0.0 -0.854408  
8993           0.000000              0.0 -0.112801  
34312          0.000000              0.0  0.445085  
4802           1.332660              0.0 -0.368621  
25895          0.000000              0.0 -1.284779  
...                 ...              ...       ...  
18045          1.190419              0.0 -0.812429  
5425           2.103596              0.0 -0.133319  
12819          2.103596              0.0  0.469341  
33659          1.530139              0.0 -0.428356  
19531          1.041572              0.0 -1.047058  

[13109 rows x 31 columns]
2025-12-03 12:14:48,131:INFO:get_config() successfully completed......................................
2025-12-03 12:14:48,211:INFO:Initializing get_config()
2025-12-03 12:14:48,212:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000278EABAEE90>, variable=y_test)
2025-12-03 12:14:48,212:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-12-03 12:14:48,212:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-12-03 12:14:48,217:INFO:Variable:  returned as 28456    0.0
8993     0.0
34312    0.0
4802     0.0
25895    0.0
        ... 
18045    0.0
5425     0.0
12819    0.0
33659    0.0
19531    0.0
Name: HeartDisease, Length: 13109, dtype: float32
2025-12-03 12:14:48,218:INFO:get_config() successfully completed......................................
2025-12-03 12:14:48,219:INFO:Initializing get_config()
2025-12-03 12:14:48,219:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000278EABAEE90>, variable=y_test)
2025-12-03 12:14:48,219:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-12-03 12:14:48,219:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-12-03 12:14:48,224:INFO:Variable:  returned as 28456    0.0
8993     0.0
34312    0.0
4802     0.0
25895    0.0
        ... 
18045    0.0
5425     0.0
12819    0.0
33659    0.0
19531    0.0
Name: HeartDisease, Length: 13109, dtype: float32
2025-12-03 12:14:48,224:INFO:get_config() successfully completed......................................
2025-12-03 12:14:48,407:INFO:Initializing get_config()
2025-12-03 12:14:48,407:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000278EABAEE90>, variable=X_test_transformed)
2025-12-03 12:14:48,494:INFO:Variable: X_test returned as             Age  IncomeRatio  SystolicBP       BMI  WaistCircumference  \
28456 -1.166627    -0.346668   -0.856028 -1.444817           -1.505144   
8993   0.144006     0.336748    1.661631  0.616912            0.650918   
34312  0.029038     0.094402    0.120974  0.320615            0.349792   
4802  -1.235607     0.337310   -0.679800 -0.555589           -0.935736   
25895  0.029038     1.529090   -0.455207 -0.552146           -0.411032   
...         ...          ...         ...       ...                 ...   
18045 -1.258601    -0.075240   -0.902556 -1.667039           -1.990961   
5425  -0.085930     0.470814    1.711734 -0.123829           -0.083830   
12819  0.235980     0.002310    0.478266  0.246541            0.711143   
33659 -1.212614     1.325519   -0.862074 -0.975681           -1.485069   
19531 -1.281594    -0.395137   -0.847590 -1.395434           -1.846420   

         Height  TotalCholesterol  Triglycerides       LDL       HDL  ...  \
28456 -1.817558         -0.075919      -0.645504 -0.018918  0.565429  ...   
8993  -0.645140          0.703061       0.628124  0.004972  0.591985  ...   
34312  0.583108         -0.117177       0.871284 -0.747548 -1.113897  ...   
4802  -0.974805         -0.177199      -0.485069  0.000613  0.052365  ...   
25895  0.081554          0.820238       1.262972  0.006556 -0.055073  ...   
...         ...               ...            ...       ...       ...  ...   
18045 -3.281529         -0.317991      -0.645314 -0.614949  0.543115  ...   
5425  -0.006203          0.398401      -0.206369  0.808141  0.297868  ...   
12819  1.513598         -0.679626      -0.644711 -0.152776 -0.819779  ...   
33659 -2.071891         -0.984285      -0.645722 -2.065437  0.297868  ...   
19531 -3.659929         -0.332706      -0.645328 -0.652405  0.543209  ...   

       Race_5.0  Race_1.0  Race_4.0  Race_3.0  Race_2.0  Education   Smoking  \
28456       1.0       0.0  0.000000   -0.1454       0.0  -0.023013 -0.319015   
8993        0.0       0.0  3.236622   -0.1454       0.0   0.525245  0.680985   
34312       0.0       0.0  0.000000    0.8546       0.0  -0.656011 -0.319015   
4802        1.0       0.0  0.000000   -0.1454       0.0   0.246788 -0.245402   
25895       0.0       0.0  0.000000    0.8546       0.0   1.115873 -0.319015   
...         ...       ...       ...       ...       ...        ...       ...   
18045       0.0       0.0  0.000000    0.8546       0.0  -0.786652 -0.319015   
5425        0.0       0.0  3.236622   -0.1454       0.0   0.525245  0.680985   
12819       0.0       0.0  0.000000    0.8546       0.0   1.115873  0.680985   
33659       0.0       0.0  3.236622   -0.1454       0.0   0.242351 -0.319015   
19531       1.0       0.0  0.000000   -0.1454       0.0  -0.813970 -0.319015   

       PhysicalActivity  HealthInsurance   Alcohol  
28456          0.869504              0.0 -0.854408  
8993           0.000000              0.0 -0.112801  
34312          0.000000              0.0  0.445085  
4802           1.332660              0.0 -0.368621  
25895          0.000000              0.0 -1.284779  
...                 ...              ...       ...  
18045          1.190419              0.0 -0.812429  
5425           2.103596              0.0 -0.133319  
12819          2.103596              0.0  0.469341  
33659          1.530139              0.0 -0.428356  
19531          1.041572              0.0 -1.047058  

[13109 rows x 31 columns]
2025-12-03 12:14:48,494:INFO:get_config() successfully completed......................................
2025-12-03 12:14:48,523:INFO:Initializing get_config()
2025-12-03 12:14:48,523:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000278EABAEE90>, variable=y_test)
2025-12-03 12:14:48,523:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-12-03 12:14:48,523:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-12-03 12:14:48,529:INFO:Variable:  returned as 28456    0.0
8993     0.0
34312    0.0
4802     0.0
25895    0.0
        ... 
18045    0.0
5425     0.0
12819    0.0
33659    0.0
19531    0.0
Name: HeartDisease, Length: 13109, dtype: float32
2025-12-03 12:14:48,529:INFO:get_config() successfully completed......................................
2025-12-03 12:14:48,795:INFO:Initializing get_config()
2025-12-03 12:14:48,795:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000278EABAEE90>, variable=y_test)
2025-12-03 12:14:48,795:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-12-03 12:14:48,796:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-12-03 12:14:48,804:INFO:Variable:  returned as 28456    0.0
8993     0.0
34312    0.0
4802     0.0
25895    0.0
        ... 
18045    0.0
5425     0.0
12819    0.0
33659    0.0
19531    0.0
Name: HeartDisease, Length: 13109, dtype: float32
2025-12-03 12:14:48,804:INFO:get_config() successfully completed......................................
2025-12-03 12:14:48,804:INFO:Initializing get_config()
2025-12-03 12:14:48,804:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000278EABAEE90>, variable=X_test_transformed)
2025-12-03 12:14:48,883:INFO:Variable: X_test returned as             Age  IncomeRatio  SystolicBP       BMI  WaistCircumference  \
28456 -1.166627    -0.346668   -0.856028 -1.444817           -1.505144   
8993   0.144006     0.336748    1.661631  0.616912            0.650918   
34312  0.029038     0.094402    0.120974  0.320615            0.349792   
4802  -1.235607     0.337310   -0.679800 -0.555589           -0.935736   
25895  0.029038     1.529090   -0.455207 -0.552146           -0.411032   
...         ...          ...         ...       ...                 ...   
18045 -1.258601    -0.075240   -0.902556 -1.667039           -1.990961   
5425  -0.085930     0.470814    1.711734 -0.123829           -0.083830   
12819  0.235980     0.002310    0.478266  0.246541            0.711143   
33659 -1.212614     1.325519   -0.862074 -0.975681           -1.485069   
19531 -1.281594    -0.395137   -0.847590 -1.395434           -1.846420   

         Height  TotalCholesterol  Triglycerides       LDL       HDL  ...  \
28456 -1.817558         -0.075919      -0.645504 -0.018918  0.565429  ...   
8993  -0.645140          0.703061       0.628124  0.004972  0.591985  ...   
34312  0.583108         -0.117177       0.871284 -0.747548 -1.113897  ...   
4802  -0.974805         -0.177199      -0.485069  0.000613  0.052365  ...   
25895  0.081554          0.820238       1.262972  0.006556 -0.055073  ...   
...         ...               ...            ...       ...       ...  ...   
18045 -3.281529         -0.317991      -0.645314 -0.614949  0.543115  ...   
5425  -0.006203          0.398401      -0.206369  0.808141  0.297868  ...   
12819  1.513598         -0.679626      -0.644711 -0.152776 -0.819779  ...   
33659 -2.071891         -0.984285      -0.645722 -2.065437  0.297868  ...   
19531 -3.659929         -0.332706      -0.645328 -0.652405  0.543209  ...   

       Race_5.0  Race_1.0  Race_4.0  Race_3.0  Race_2.0  Education   Smoking  \
28456       1.0       0.0  0.000000   -0.1454       0.0  -0.023013 -0.319015   
8993        0.0       0.0  3.236622   -0.1454       0.0   0.525245  0.680985   
34312       0.0       0.0  0.000000    0.8546       0.0  -0.656011 -0.319015   
4802        1.0       0.0  0.000000   -0.1454       0.0   0.246788 -0.245402   
25895       0.0       0.0  0.000000    0.8546       0.0   1.115873 -0.319015   
...         ...       ...       ...       ...       ...        ...       ...   
18045       0.0       0.0  0.000000    0.8546       0.0  -0.786652 -0.319015   
5425        0.0       0.0  3.236622   -0.1454       0.0   0.525245  0.680985   
12819       0.0       0.0  0.000000    0.8546       0.0   1.115873  0.680985   
33659       0.0       0.0  3.236622   -0.1454       0.0   0.242351 -0.319015   
19531       1.0       0.0  0.000000   -0.1454       0.0  -0.813970 -0.319015   

       PhysicalActivity  HealthInsurance   Alcohol  
28456          0.869504              0.0 -0.854408  
8993           0.000000              0.0 -0.112801  
34312          0.000000              0.0  0.445085  
4802           1.332660              0.0 -0.368621  
25895          0.000000              0.0 -1.284779  
...                 ...              ...       ...  
18045          1.190419              0.0 -0.812429  
5425           2.103596              0.0 -0.133319  
12819          2.103596              0.0  0.469341  
33659          1.530139              0.0 -0.428356  
19531          1.041572              0.0 -1.047058  

[13109 rows x 31 columns]
2025-12-03 12:14:48,883:INFO:get_config() successfully completed......................................
2025-12-03 12:14:48,979:INFO:Initializing get_config()
2025-12-03 12:14:48,979:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000278EABAEE90>, variable=X_train_transformed)
2025-12-03 12:14:49,031:INFO:Variable: X_train returned as             Age  IncomeRatio  SystolicBP       BMI  WaistCircumference  \
15208  0.281967     1.073479   -0.029334  0.320615           -0.184205   
25325 -0.959685     0.336748   -1.131593 -1.420125           -1.360604   
5132  -0.499814    -0.472688   -0.718246 -0.222594           -0.051710   
17217 -0.177904    -0.894370   -0.355002 -0.592965           -0.099890   
6382  -0.108923     0.093300    0.697155  2.851479            1.783151   
...         ...          ...         ...       ...                 ...   
72714  0.209599    -0.574548    0.093968 -0.084224            0.048339   
72715  0.410044     0.140941    1.545471  0.784710            0.534682   
72716  0.336375     0.706350   -0.225611 -0.316094            0.087200   
72717  0.465916     0.152440   -0.649398  0.648433            0.661659   
72718  0.465916     0.204596    0.822492 -0.260262           -0.112576   

         Height  TotalCholesterol  Triglycerides       LDL       HDL  ...  \
15208 -0.949100          0.573893       0.496366  0.004515  0.470102  ...   
25325 -0.676156          0.027513      -0.418808  0.000788  0.460074  ...   
5132   0.887068          0.164048       0.383587  0.688473 -1.055073  ...   
17217  0.856051          0.206410       0.239340  0.002372 -0.072797  ...   
6382   0.111659          0.796802       0.552888  0.002599  0.944927  ...   
...         ...               ...            ...       ...       ...  ...   
72714  0.529966          0.966537       0.338163  2.847690 -1.107269  ...   
72715 -0.193825          1.002684       1.137561  0.006116  0.578610  ...   
72716  0.850772          0.698204       0.800524  0.005273  0.320829  ...   
72717  0.196053         -0.854465      -0.645063 -1.338104 -0.093582  ...   
72718 -0.754937         -1.171319      -0.645250 -1.650124 -0.583170  ...   

       Race_5.0  Race_1.0  Race_4.0  Race_3.0  Race_2.0  Education   Smoking  \
15208  1.000000       0.0  0.000000 -0.145400   0.00000  -0.656011 -0.319015   
25325  0.000000       1.0  0.000000 -0.145400   0.00000   0.170835 -0.319015   
5132   0.000000       1.0  0.000000 -0.145400   0.00000  -0.656011  0.680985   
17217  0.000000       0.0  3.236622 -0.145400   0.00000  -0.065383  0.680985   
6382   0.000000       0.0  3.236622 -0.145400   0.00000   0.525245  0.680985   
...         ...       ...       ...       ...       ...        ...       ...   
72714  0.000000       0.0  3.236622 -0.145400   0.00000   0.525245  0.672319   
72715  0.000000       0.0  0.000000  0.854600   0.00000  -0.656011  0.680985   
72716  0.402414       0.0  0.000000  0.452186   0.00000   0.409971  0.680985   
72717  0.000000       0.0  0.000000 -0.030279   0.88488   1.115873  0.680985   
72718  0.000000       0.0  0.000000  0.854600   0.00000  -0.067269 -0.315822   

       PhysicalActivity  HealthInsurance   Alcohol  
15208          0.000000              0.0 -1.284779  
25325          0.000000              0.0  0.445085  
5132           0.000000             -1.0  0.118386  
17217          0.000000              0.0  0.445085  
6382           0.000000              0.0  0.451028  
...                 ...              ...       ...  
72714          0.000000              0.0  0.115540  
72715          0.000000              0.0  0.077133  
72716          0.000000              0.0  0.430065  
72717          0.000000              0.0  0.364598  
72718          0.006717              0.0 -0.723887  

[59610 rows x 31 columns]
2025-12-03 12:14:49,031:INFO:get_config() successfully completed......................................
2025-12-03 12:14:49,063:INFO:Initializing tune_model()
2025-12-03 12:14:49,063:INFO:tune_model(estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...), fold=None, round=4, n_iter=20, custom_grid=None, optimize=Recall, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=False, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000278EABAEE90>)
2025-12-03 12:14:49,063:INFO:Checking exceptions
2025-12-03 12:14:49,082:INFO:Copying training dataset
2025-12-03 12:14:49,101:INFO:Checking base model
2025-12-03 12:14:49,102:INFO:Base model : Extreme Gradient Boosting
2025-12-03 12:14:49,103:INFO:Declaring metric variables
2025-12-03 12:14:49,103:INFO:Defining Hyperparameters
2025-12-03 12:14:49,275:INFO:Tuning with n_jobs=1
2025-12-03 12:14:49,275:INFO:Initializing RandomizedSearchCV
2025-12-03 12:19:34,220:INFO:best_params: {'actual_estimator__subsample': 0.7, 'actual_estimator__scale_pos_weight': 12.9, 'actual_estimator__reg_lambda': 0.05, 'actual_estimator__reg_alpha': 2, 'actual_estimator__n_estimators': 100, 'actual_estimator__min_child_weight': 2, 'actual_estimator__max_depth': 4, 'actual_estimator__learning_rate': 1e-06, 'actual_estimator__colsample_bytree': 0.9}
2025-12-03 12:19:34,220:INFO:Hyperparameter search completed
2025-12-03 12:19:34,220:INFO:SubProcess create_model() called ==================================
2025-12-03 12:19:34,220:INFO:Initializing create_model()
2025-12-03 12:19:34,220:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000278EABAEE90>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000278862FF2E0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'subsample': 0.7, 'scale_pos_weight': 12.9, 'reg_lambda': 0.05, 'reg_alpha': 2, 'n_estimators': 100, 'min_child_weight': 2, 'max_depth': 4, 'learning_rate': 1e-06, 'colsample_bytree': 0.9})
2025-12-03 12:19:34,220:INFO:Checking exceptions
2025-12-03 12:19:34,220:INFO:Importing libraries
2025-12-03 12:19:34,220:INFO:Copying training dataset
2025-12-03 12:19:34,244:INFO:Defining folds
2025-12-03 12:19:34,244:INFO:Declaring metric variables
2025-12-03 12:19:34,244:INFO:Importing untrained model
2025-12-03 12:19:34,244:INFO:Declaring custom model
2025-12-03 12:19:34,244:INFO:Extreme Gradient Boosting Imported successfully
2025-12-03 12:19:34,244:INFO:Starting cross validation
2025-12-03 12:19:34,244:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-12-03 12:19:43,460:INFO:Calculating mean and std
2025-12-03 12:19:43,460:INFO:Creating metrics dataframe
2025-12-03 12:19:43,462:INFO:Finalizing model
2025-12-03 12:19:43,534:INFO:Warning: No categorical columns found. Calling 'transform' will only return input data.
2025-12-03 12:19:44,397:INFO:Uploading results into container
2025-12-03 12:19:44,397:INFO:Uploading model into container now
2025-12-03 12:19:44,398:INFO:_master_model_container: 4
2025-12-03 12:19:44,398:INFO:_display_container: 5
2025-12-03 12:19:44,399:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=0.9, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=1e-06, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=4, max_leaves=None,
              min_child_weight=2, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=100, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2025-12-03 12:19:44,399:INFO:create_model() successfully completed......................................
2025-12-03 12:19:44,584:INFO:SubProcess create_model() end ==================================
2025-12-03 12:19:44,584:INFO:choose_better activated
2025-12-03 12:19:44,584:INFO:SubProcess create_model() called ==================================
2025-12-03 12:19:44,584:INFO:Initializing create_model()
2025-12-03 12:19:44,584:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000278EABAEE90>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-03 12:19:44,584:INFO:Checking exceptions
2025-12-03 12:19:44,588:INFO:Importing libraries
2025-12-03 12:19:44,589:INFO:Copying training dataset
2025-12-03 12:19:44,608:INFO:Defining folds
2025-12-03 12:19:44,608:INFO:Declaring metric variables
2025-12-03 12:19:44,608:INFO:Importing untrained model
2025-12-03 12:19:44,608:INFO:Declaring custom model
2025-12-03 12:19:44,608:INFO:Extreme Gradient Boosting Imported successfully
2025-12-03 12:19:44,608:INFO:Starting cross validation
2025-12-03 12:19:44,608:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-12-03 12:19:56,488:INFO:Calculating mean and std
2025-12-03 12:19:56,491:INFO:Creating metrics dataframe
2025-12-03 12:19:56,492:INFO:Finalizing model
2025-12-03 12:19:56,562:INFO:Warning: No categorical columns found. Calling 'transform' will only return input data.
2025-12-03 12:19:57,710:INFO:Uploading results into container
2025-12-03 12:19:57,711:INFO:Uploading model into container now
2025-12-03 12:19:57,711:INFO:_master_model_container: 5
2025-12-03 12:19:57,711:INFO:_display_container: 6
2025-12-03 12:19:57,711:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2025-12-03 12:19:57,711:INFO:create_model() successfully completed......................................
2025-12-03 12:19:57,894:INFO:SubProcess create_model() end ==================================
2025-12-03 12:19:57,895:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...) result for Recall is 0.3624
2025-12-03 12:19:57,896:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=0.9, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=1e-06, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=4, max_leaves=None,
              min_child_weight=2, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=100, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...) result for Recall is 1.0
2025-12-03 12:19:57,897:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=0.9, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=1e-06, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=4, max_leaves=None,
              min_child_weight=2, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=100, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...) is best model
2025-12-03 12:19:57,897:INFO:choose_better completed
2025-12-03 12:19:57,897:INFO:_master_model_container: 5
2025-12-03 12:19:57,897:INFO:_display_container: 5
2025-12-03 12:19:57,898:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=0.9, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=1e-06, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=4, max_leaves=None,
              min_child_weight=2, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=100, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2025-12-03 12:19:57,898:INFO:tune_model() successfully completed......................................
2025-12-03 12:21:32,313:INFO:Initializing get_config()
2025-12-03 12:21:32,313:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000278EABAEE90>, variable=X_test_transformed)
2025-12-03 12:21:32,395:INFO:Variable: X_test returned as             Age  IncomeRatio  SystolicBP       BMI  WaistCircumference  \
28456 -1.166627    -0.346668   -0.856028 -1.444817           -1.505144   
8993   0.144006     0.336748    1.661631  0.616912            0.650918   
34312  0.029038     0.094402    0.120974  0.320615            0.349792   
4802  -1.235607     0.337310   -0.679800 -0.555589           -0.935736   
25895  0.029038     1.529090   -0.455207 -0.552146           -0.411032   
...         ...          ...         ...       ...                 ...   
18045 -1.258601    -0.075240   -0.902556 -1.667039           -1.990961   
5425  -0.085930     0.470814    1.711734 -0.123829           -0.083830   
12819  0.235980     0.002310    0.478266  0.246541            0.711143   
33659 -1.212614     1.325519   -0.862074 -0.975681           -1.485069   
19531 -1.281594    -0.395137   -0.847590 -1.395434           -1.846420   

         Height  TotalCholesterol  Triglycerides       LDL       HDL  ...  \
28456 -1.817558         -0.075919      -0.645504 -0.018918  0.565429  ...   
8993  -0.645140          0.703061       0.628124  0.004972  0.591985  ...   
34312  0.583108         -0.117177       0.871284 -0.747548 -1.113897  ...   
4802  -0.974805         -0.177199      -0.485069  0.000613  0.052365  ...   
25895  0.081554          0.820238       1.262972  0.006556 -0.055073  ...   
...         ...               ...            ...       ...       ...  ...   
18045 -3.281529         -0.317991      -0.645314 -0.614949  0.543115  ...   
5425  -0.006203          0.398401      -0.206369  0.808141  0.297868  ...   
12819  1.513598         -0.679626      -0.644711 -0.152776 -0.819779  ...   
33659 -2.071891         -0.984285      -0.645722 -2.065437  0.297868  ...   
19531 -3.659929         -0.332706      -0.645328 -0.652405  0.543209  ...   

       Race_5.0  Race_1.0  Race_4.0  Race_3.0  Race_2.0  Education   Smoking  \
28456       1.0       0.0  0.000000   -0.1454       0.0  -0.023013 -0.319015   
8993        0.0       0.0  3.236622   -0.1454       0.0   0.525245  0.680985   
34312       0.0       0.0  0.000000    0.8546       0.0  -0.656011 -0.319015   
4802        1.0       0.0  0.000000   -0.1454       0.0   0.246788 -0.245402   
25895       0.0       0.0  0.000000    0.8546       0.0   1.115873 -0.319015   
...         ...       ...       ...       ...       ...        ...       ...   
18045       0.0       0.0  0.000000    0.8546       0.0  -0.786652 -0.319015   
5425        0.0       0.0  3.236622   -0.1454       0.0   0.525245  0.680985   
12819       0.0       0.0  0.000000    0.8546       0.0   1.115873  0.680985   
33659       0.0       0.0  3.236622   -0.1454       0.0   0.242351 -0.319015   
19531       1.0       0.0  0.000000   -0.1454       0.0  -0.813970 -0.319015   

       PhysicalActivity  HealthInsurance   Alcohol  
28456          0.869504              0.0 -0.854408  
8993           0.000000              0.0 -0.112801  
34312          0.000000              0.0  0.445085  
4802           1.332660              0.0 -0.368621  
25895          0.000000              0.0 -1.284779  
...                 ...              ...       ...  
18045          1.190419              0.0 -0.812429  
5425           2.103596              0.0 -0.133319  
12819          2.103596              0.0  0.469341  
33659          1.530139              0.0 -0.428356  
19531          1.041572              0.0 -1.047058  

[13109 rows x 31 columns]
2025-12-03 12:21:32,395:INFO:get_config() successfully completed......................................
2025-12-03 12:21:32,395:INFO:Initializing get_config()
2025-12-03 12:21:32,395:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000278EABAEE90>, variable=y_test)
2025-12-03 12:21:32,395:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-12-03 12:21:32,395:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-12-03 12:21:32,400:INFO:Variable:  returned as 28456    0.0
8993     0.0
34312    0.0
4802     0.0
25895    0.0
        ... 
18045    0.0
5425     0.0
12819    0.0
33659    0.0
19531    0.0
Name: HeartDisease, Length: 13109, dtype: float32
2025-12-03 12:21:32,400:INFO:get_config() successfully completed......................................
2025-12-03 12:21:40,183:INFO:Initializing interpret_model()
2025-12-03 12:21:40,184:INFO:interpret_model(estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=0.9, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=1e-06, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=4, max_leaves=None,
              min_child_weight=2, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=100, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...), use_train_data=False, X_new_sample=None, y_new_sample=None, feature=None, kwargs={}, observation=None, plot=summary, save=False, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000278EABAEE90>)
2025-12-03 12:21:40,184:INFO:Checking exceptions
2025-12-03 12:21:40,184:INFO:Soft dependency imported: shap: 0.49.1
2025-12-03 12:21:40,256:INFO:plot type: summary
2025-12-03 12:21:40,256:INFO:Creating TreeExplainer
2025-12-03 12:21:40,260:INFO:Compiling shap values
2025-12-03 12:21:41,349:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:4145: FutureWarning: The NumPy global RNG was seeded by calling `np.random.seed`. In a future version this function will no longer use the global RNG. Pass `rng` explicitly to opt-in to the new behaviour and silence this warning.

2025-12-03 12:21:42,534:INFO:Visual Rendered Successfully
2025-12-03 12:21:42,534:INFO:interpret_model() successfully completed......................................
2025-12-03 12:24:01,022:INFO:Initializing get_config()
2025-12-03 12:24:01,022:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000278EABAEE90>, variable=X_test_transformed)
2025-12-03 12:24:01,103:INFO:Variable: X_test returned as             Age  IncomeRatio  SystolicBP       BMI  WaistCircumference  \
28456 -1.166627    -0.346668   -0.856028 -1.444817           -1.505144   
8993   0.144006     0.336748    1.661631  0.616912            0.650918   
34312  0.029038     0.094402    0.120974  0.320615            0.349792   
4802  -1.235607     0.337310   -0.679800 -0.555589           -0.935736   
25895  0.029038     1.529090   -0.455207 -0.552146           -0.411032   
...         ...          ...         ...       ...                 ...   
18045 -1.258601    -0.075240   -0.902556 -1.667039           -1.990961   
5425  -0.085930     0.470814    1.711734 -0.123829           -0.083830   
12819  0.235980     0.002310    0.478266  0.246541            0.711143   
33659 -1.212614     1.325519   -0.862074 -0.975681           -1.485069   
19531 -1.281594    -0.395137   -0.847590 -1.395434           -1.846420   

         Height  TotalCholesterol  Triglycerides       LDL       HDL  ...  \
28456 -1.817558         -0.075919      -0.645504 -0.018918  0.565429  ...   
8993  -0.645140          0.703061       0.628124  0.004972  0.591985  ...   
34312  0.583108         -0.117177       0.871284 -0.747548 -1.113897  ...   
4802  -0.974805         -0.177199      -0.485069  0.000613  0.052365  ...   
25895  0.081554          0.820238       1.262972  0.006556 -0.055073  ...   
...         ...               ...            ...       ...       ...  ...   
18045 -3.281529         -0.317991      -0.645314 -0.614949  0.543115  ...   
5425  -0.006203          0.398401      -0.206369  0.808141  0.297868  ...   
12819  1.513598         -0.679626      -0.644711 -0.152776 -0.819779  ...   
33659 -2.071891         -0.984285      -0.645722 -2.065437  0.297868  ...   
19531 -3.659929         -0.332706      -0.645328 -0.652405  0.543209  ...   

       Race_5.0  Race_1.0  Race_4.0  Race_3.0  Race_2.0  Education   Smoking  \
28456       1.0       0.0  0.000000   -0.1454       0.0  -0.023013 -0.319015   
8993        0.0       0.0  3.236622   -0.1454       0.0   0.525245  0.680985   
34312       0.0       0.0  0.000000    0.8546       0.0  -0.656011 -0.319015   
4802        1.0       0.0  0.000000   -0.1454       0.0   0.246788 -0.245402   
25895       0.0       0.0  0.000000    0.8546       0.0   1.115873 -0.319015   
...         ...       ...       ...       ...       ...        ...       ...   
18045       0.0       0.0  0.000000    0.8546       0.0  -0.786652 -0.319015   
5425        0.0       0.0  3.236622   -0.1454       0.0   0.525245  0.680985   
12819       0.0       0.0  0.000000    0.8546       0.0   1.115873  0.680985   
33659       0.0       0.0  3.236622   -0.1454       0.0   0.242351 -0.319015   
19531       1.0       0.0  0.000000   -0.1454       0.0  -0.813970 -0.319015   

       PhysicalActivity  HealthInsurance   Alcohol  
28456          0.869504              0.0 -0.854408  
8993           0.000000              0.0 -0.112801  
34312          0.000000              0.0  0.445085  
4802           1.332660              0.0 -0.368621  
25895          0.000000              0.0 -1.284779  
...                 ...              ...       ...  
18045          1.190419              0.0 -0.812429  
5425           2.103596              0.0 -0.133319  
12819          2.103596              0.0  0.469341  
33659          1.530139              0.0 -0.428356  
19531          1.041572              0.0 -1.047058  

[13109 rows x 31 columns]
2025-12-03 12:24:01,103:INFO:get_config() successfully completed......................................
2025-12-03 12:24:01,103:INFO:Initializing get_config()
2025-12-03 12:24:01,103:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000278EABAEE90>, variable=y_test)
2025-12-03 12:24:01,104:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-12-03 12:24:01,104:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-12-03 12:24:01,109:INFO:Variable:  returned as 28456    0.0
8993     0.0
34312    0.0
4802     0.0
25895    0.0
        ... 
18045    0.0
5425     0.0
12819    0.0
33659    0.0
19531    0.0
Name: HeartDisease, Length: 13109, dtype: float32
2025-12-03 12:24:01,109:INFO:get_config() successfully completed......................................
2025-12-03 12:24:09,730:INFO:Initializing interpret_model()
2025-12-03 12:24:09,730:INFO:interpret_model(estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=0.9, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=1e-06, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=4, max_leaves=None,
              min_child_weight=2, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=100, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...), use_train_data=False, X_new_sample=None, y_new_sample=None, feature=None, kwargs={}, observation=None, plot=summary, save=False, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000278EABAEE90>)
2025-12-03 12:24:09,730:INFO:Checking exceptions
2025-12-03 12:24:09,730:INFO:Soft dependency imported: shap: 0.49.1
2025-12-03 12:24:09,804:INFO:plot type: summary
2025-12-03 12:24:09,804:INFO:Creating TreeExplainer
2025-12-03 12:24:09,814:INFO:Compiling shap values
2025-12-03 12:24:10,922:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:4145: FutureWarning: The NumPy global RNG was seeded by calling `np.random.seed`. In a future version this function will no longer use the global RNG. Pass `rng` explicitly to opt-in to the new behaviour and silence this warning.

2025-12-03 12:24:12,088:INFO:Visual Rendered Successfully
2025-12-03 12:24:12,091:INFO:interpret_model() successfully completed......................................
2025-12-03 12:24:30,446:INFO:Initializing finalize_model()
2025-12-03 12:24:30,446:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000278EABAEE90>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=0.9, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=1e-06, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=4, max_leaves=None,
              min_child_weight=2, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=100, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2025-12-03 12:24:30,447:INFO:Finalizing XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=0.9, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=1e-06, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=4, max_leaves=None,
              min_child_weight=2, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=100, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2025-12-03 12:24:30,463:INFO:Initializing create_model()
2025-12-03 12:24:30,463:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000278EABAEE90>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=0.9, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=1e-06, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=4, max_leaves=None,
              min_child_weight=2, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=100, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2025-12-03 12:24:30,463:INFO:Checking exceptions
2025-12-03 12:24:30,464:INFO:Importing libraries
2025-12-03 12:24:30,465:INFO:Copying training dataset
2025-12-03 12:24:30,469:INFO:Defining folds
2025-12-03 12:24:30,469:INFO:Declaring metric variables
2025-12-03 12:24:30,469:INFO:Importing untrained model
2025-12-03 12:24:30,469:INFO:Declaring custom model
2025-12-03 12:24:30,471:INFO:Extreme Gradient Boosting Imported successfully
2025-12-03 12:24:30,472:INFO:Cross validation set to False
2025-12-03 12:24:30,472:INFO:Fitting Model
2025-12-03 12:24:30,586:INFO:Warning: No categorical columns found. Calling 'transform' will only return input data.
2025-12-03 12:24:31,870:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'IncomeRatio', 'SystolicBP',
                                             'BMI', 'WaistCircumference',
                                             'Height', 'TotalCholesterol',
                                             'Triglycerides', 'LDL', 'HDL',
                                             'HbA1c', 'Glucose', 'Creatinine',
                                             'UricAcid', 'ALT_Enzyme',
                                             'Albumin', 'Potassium', 'Sodium',
                                             'GGT_Enzyme', 'AST_Enzyme'],
                                    transformer=Si...
                               importance_type=None,
                               interaction_constraints=None,
                               learning_rate=1e-06, max_bin=None,
                               max_cat_threshold=None, max_cat_to_onehot=None,
                               max_delta_step=None, max_depth=4,
                               max_leaves=None, min_child_weight=2, missing=nan,
                               monotone_constraints=None, multi_strategy=None,
                               n_estimators=100, n_jobs=1,
                               num_parallel_tree=None,
                               objective='binary:logistic', ...))],
         verbose=False)
2025-12-03 12:24:31,870:INFO:create_model() successfully completed......................................
2025-12-03 12:24:32,044:INFO:_master_model_container: 5
2025-12-03 12:24:32,044:INFO:_display_container: 5
2025-12-03 12:24:32,061:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'IncomeRatio', 'SystolicBP',
                                             'BMI', 'WaistCircumference',
                                             'Height', 'TotalCholesterol',
                                             'Triglycerides', 'LDL', 'HDL',
                                             'HbA1c', 'Glucose', 'Creatinine',
                                             'UricAcid', 'ALT_Enzyme',
                                             'Albumin', 'Potassium', 'Sodium',
                                             'GGT_Enzyme', 'AST_Enzyme'],
                                    transformer=Si...
                               importance_type=None,
                               interaction_constraints=None,
                               learning_rate=1e-06, max_bin=None,
                               max_cat_threshold=None, max_cat_to_onehot=None,
                               max_delta_step=None, max_depth=4,
                               max_leaves=None, min_child_weight=2, missing=nan,
                               monotone_constraints=None, multi_strategy=None,
                               n_estimators=100, n_jobs=1,
                               num_parallel_tree=None,
                               objective='binary:logistic', ...))],
         verbose=False)
2025-12-03 12:24:32,061:INFO:finalize_model() successfully completed......................................
2025-12-03 12:24:32,259:INFO:Initializing save_model()
2025-12-03 12:24:32,259:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'IncomeRatio', 'SystolicBP',
                                             'BMI', 'WaistCircumference',
                                             'Height', 'TotalCholesterol',
                                             'Triglycerides', 'LDL', 'HDL',
                                             'HbA1c', 'Glucose', 'Creatinine',
                                             'UricAcid', 'ALT_Enzyme',
                                             'Albumin', 'Potassium', 'Sodium',
                                             'GGT_Enzyme', 'AST_Enzyme'],
                                    transformer=Si...
                               importance_type=None,
                               interaction_constraints=None,
                               learning_rate=1e-06, max_bin=None,
                               max_cat_threshold=None, max_cat_to_onehot=None,
                               max_delta_step=None, max_depth=4,
                               max_leaves=None, min_child_weight=2, missing=nan,
                               monotone_constraints=None, multi_strategy=None,
                               n_estimators=100, n_jobs=1,
                               num_parallel_tree=None,
                               objective='binary:logistic', ...))],
         verbose=False), model_name=../models\best_pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\OMAR\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'IncomeRatio', 'SystolicBP',
                                             'BMI', 'WaistCircumference',
                                             'Height', 'TotalCholesterol',
                                             'Triglycerides', 'LDL', 'HDL',
                                             'HbA1c', 'Glucose', 'Creatinine',
                                             'UricAcid', 'ALT_Enzyme',
                                             'Albumin', 'Potassium', 'Sodium',
                                             'G...
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              random_state=42,
                                                                              sampling_strategy='auto')))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=RobustScaler(copy=True,
                                                             quantile_range=(25.0,
                                                                             75.0),
                                                             unit_variance=False,
                                                             with_centering=True,
                                                             with_scaling=True)))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2025-12-03 12:24:32,259:INFO:Adding model into prep_pipe
2025-12-03 12:24:32,259:WARNING:Only Model saved as it was a pipeline.
2025-12-03 12:24:32,269:INFO:../models\best_pipeline.pkl saved in current working directory
2025-12-03 12:24:32,286:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'IncomeRatio', 'SystolicBP',
                                             'BMI', 'WaistCircumference',
                                             'Height', 'TotalCholesterol',
                                             'Triglycerides', 'LDL', 'HDL',
                                             'HbA1c', 'Glucose', 'Creatinine',
                                             'UricAcid', 'ALT_Enzyme',
                                             'Albumin', 'Potassium', 'Sodium',
                                             'GGT_Enzyme', 'AST_Enzyme'],
                                    transformer=Si...
                               importance_type=None,
                               interaction_constraints=None,
                               learning_rate=1e-06, max_bin=None,
                               max_cat_threshold=None, max_cat_to_onehot=None,
                               max_delta_step=None, max_depth=4,
                               max_leaves=None, min_child_weight=2, missing=nan,
                               monotone_constraints=None, multi_strategy=None,
                               n_estimators=100, n_jobs=1,
                               num_parallel_tree=None,
                               objective='binary:logistic', ...))],
         verbose=False)
2025-12-03 12:24:32,286:INFO:save_model() successfully completed......................................
2025-12-03 12:25:17,434:INFO:Initializing load_model()
2025-12-03 12:25:17,434:INFO:load_model(model_name=../models/best_pipeline, platform=None, authentication=None, verbose=True)
2025-12-03 12:25:17,526:INFO:Initializing predict_model()
2025-12-03 12:25:17,526:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000278061CC790>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Age', 'IncomeRatio', 'SystolicBP',
                                             'BMI', 'WaistCircumference',
                                             'Height', 'TotalCholesterol',
                                             'Triglycerides', 'LDL', 'HDL',
                                             'HbA1c', 'Glucose', 'Creatinine',
                                             'UricAcid', 'ALT_Enzyme',
                                             'Albumin', 'Potassium', 'Sodium',
                                             'GGT_Enzyme', 'AST_Enzyme'],
                                    transformer=SimpleImputer()...
                               feature_types=None, gamma=None, grow_policy=None,
                               importance_type=None,
                               interaction_constraints=None,
                               learning_rate=1e-06, max_bin=None,
                               max_cat_threshold=None, max_cat_to_onehot=None,
                               max_delta_step=None, max_depth=4,
                               max_leaves=None, min_child_weight=2, missing=nan,
                               monotone_constraints=None, multi_strategy=None,
                               n_estimators=100, n_jobs=1,
                               num_parallel_tree=None, random_state=42, ...))]), probability_threshold=None, encoded_labels=False, raw_score=True, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002786457ACB0>)
2025-12-03 12:25:17,526:INFO:Checking exceptions
2025-12-03 12:25:17,526:INFO:Preloading libraries
2025-12-03 12:25:17,526:INFO:Set up data.
2025-12-03 12:25:17,536:INFO:Set up index.
2025-12-03 12:25:17,879:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-03 12:25:17,883:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-03 12:25:17,886:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-03 12:34:32,894:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-12-03 12:34:32,894:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-12-03 12:34:32,894:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-12-03 12:34:32,894:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-12-03 12:34:34,657:INFO:PyCaret ClassificationExperiment
2025-12-03 12:34:34,657:INFO:Logging name: clf-default-name
2025-12-03 12:34:34,657:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-12-03 12:34:34,657:INFO:version 3.3.2
2025-12-03 12:34:34,657:INFO:Initializing setup()
2025-12-03 12:34:34,657:INFO:self.USI: 59aa
2025-12-03 12:34:34,657:INFO:self._variable_keys: {'X_test', 'fold_groups_param', 'X_train', 'is_multiclass', '_ml_usecase', 'USI', 'y', 'idx', 'target_param', 'pipeline', 'log_plots_param', '_available_plots', 'n_jobs_param', 'exp_name_log', 'seed', 'html_param', 'y_train', 'fold_shuffle_param', 'fix_imbalance', 'gpu_n_jobs_param', 'exp_id', 'X', 'memory', 'data', 'fold_generator', 'logging_param', 'gpu_param', 'y_test'}
2025-12-03 12:34:34,657:INFO:Checking environment
2025-12-03 12:34:34,657:INFO:python_version: 3.10.19
2025-12-03 12:34:34,657:INFO:python_build: ('main', 'Oct 21 2025 16:41:31')
2025-12-03 12:34:34,657:INFO:machine: AMD64
2025-12-03 12:34:34,657:INFO:platform: Windows-10-10.0.26100-SP0
2025-12-03 12:34:34,657:INFO:Memory: svmem(total=16282144768, available=4592091136, percent=71.8, used=11690053632, free=4592091136)
2025-12-03 12:34:34,657:INFO:Physical Core: 6
2025-12-03 12:34:34,657:INFO:Logical Core: 12
2025-12-03 12:34:34,657:INFO:Checking libraries
2025-12-03 12:34:34,657:INFO:System:
2025-12-03 12:34:34,657:INFO:    python: 3.10.19 | packaged by Anaconda, Inc. | (main, Oct 21 2025, 16:41:31) [MSC v.1929 64 bit (AMD64)]
2025-12-03 12:34:34,657:INFO:executable: c:\Users\OMAR\miniconda3\envs\xgb_env\python.exe
2025-12-03 12:34:34,657:INFO:   machine: Windows-10-10.0.26100-SP0
2025-12-03 12:34:34,657:INFO:PyCaret required dependencies:
2025-12-03 12:34:34,658:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-03 12:34:35,230:INFO:                 pip: 25.3
2025-12-03 12:34:35,230:INFO:          setuptools: 80.9.0
2025-12-03 12:34:35,230:INFO:             pycaret: 3.3.2
2025-12-03 12:34:35,230:INFO:             IPython: 8.37.0
2025-12-03 12:34:35,230:INFO:          ipywidgets: 8.1.8
2025-12-03 12:34:35,230:INFO:                tqdm: 4.67.1
2025-12-03 12:34:35,230:INFO:               numpy: 1.26.4
2025-12-03 12:34:35,230:INFO:              pandas: 2.1.4
2025-12-03 12:34:35,230:INFO:              jinja2: 3.1.6
2025-12-03 12:34:35,230:INFO:               scipy: 1.11.4
2025-12-03 12:34:35,230:INFO:              joblib: 1.3.2
2025-12-03 12:34:35,230:INFO:             sklearn: 1.4.2
2025-12-03 12:34:35,230:INFO:                pyod: 2.0.5
2025-12-03 12:34:35,230:INFO:            imblearn: 0.14.0
2025-12-03 12:34:35,230:INFO:   category_encoders: 2.7.0
2025-12-03 12:34:35,230:INFO:            lightgbm: 4.6.0
2025-12-03 12:34:35,230:INFO:               numba: 0.62.1
2025-12-03 12:34:35,230:INFO:            requests: 2.32.5
2025-12-03 12:34:35,230:INFO:          matplotlib: 3.7.5
2025-12-03 12:34:35,230:INFO:          scikitplot: 0.3.7
2025-12-03 12:34:35,230:INFO:         yellowbrick: 1.5
2025-12-03 12:34:35,230:INFO:              plotly: 5.24.1
2025-12-03 12:34:35,230:INFO:    plotly-resampler: Not installed
2025-12-03 12:34:35,230:INFO:             kaleido: 1.2.0
2025-12-03 12:34:35,230:INFO:           schemdraw: 0.15
2025-12-03 12:34:35,230:INFO:         statsmodels: 0.14.5
2025-12-03 12:34:35,230:INFO:              sktime: 0.26.0
2025-12-03 12:34:35,230:INFO:               tbats: 1.1.3
2025-12-03 12:34:35,230:INFO:            pmdarima: 2.0.4
2025-12-03 12:34:35,230:INFO:              psutil: 7.1.3
2025-12-03 12:34:35,230:INFO:          markupsafe: 3.0.3
2025-12-03 12:34:35,230:INFO:             pickle5: Not installed
2025-12-03 12:34:35,230:INFO:         cloudpickle: 3.1.2
2025-12-03 12:34:35,230:INFO:         deprecation: 2.1.0
2025-12-03 12:34:35,230:INFO:              xxhash: 3.6.0
2025-12-03 12:34:35,231:INFO:           wurlitzer: Not installed
2025-12-03 12:34:35,231:INFO:PyCaret optional dependencies:
2025-12-03 12:34:37,997:INFO:                shap: 0.49.1
2025-12-03 12:34:37,998:INFO:           interpret: 0.7.3
2025-12-03 12:34:37,998:INFO:                umap: 0.5.7
2025-12-03 12:34:37,998:INFO:     ydata_profiling: 4.18.0
2025-12-03 12:34:37,998:INFO:  explainerdashboard: 0.5.1
2025-12-03 12:34:37,998:INFO:             autoviz: Not installed
2025-12-03 12:34:37,998:INFO:           fairlearn: 0.7.0
2025-12-03 12:34:37,998:INFO:          deepchecks: Not installed
2025-12-03 12:34:37,998:INFO:             xgboost: 2.1.3
2025-12-03 12:34:37,998:INFO:            catboost: 1.2.8
2025-12-03 12:34:37,998:INFO:              kmodes: 0.12.2
2025-12-03 12:34:37,998:INFO:             mlxtend: 0.23.4
2025-12-03 12:34:37,998:INFO:       statsforecast: 1.5.0
2025-12-03 12:34:37,998:INFO:        tune_sklearn: Not installed
2025-12-03 12:34:37,998:INFO:                 ray: Not installed
2025-12-03 12:34:37,998:INFO:            hyperopt: 0.2.7
2025-12-03 12:34:37,998:INFO:              optuna: 4.6.0
2025-12-03 12:34:37,998:INFO:               skopt: 0.10.2
2025-12-03 12:34:37,998:INFO:              mlflow: 3.6.0
2025-12-03 12:34:37,998:INFO:              gradio: 6.0.1
2025-12-03 12:34:37,998:INFO:             fastapi: 0.123.0
2025-12-03 12:34:37,998:INFO:             uvicorn: 0.38.0
2025-12-03 12:34:37,998:INFO:              m2cgen: 0.10.0
2025-12-03 12:34:37,998:INFO:           evidently: 0.4.40
2025-12-03 12:34:37,999:INFO:               fugue: 0.8.7
2025-12-03 12:34:37,999:INFO:           streamlit: 1.51.0
2025-12-03 12:34:37,999:INFO:             prophet: Not installed
2025-12-03 12:34:37,999:INFO:None
2025-12-03 12:34:37,999:INFO:Set up data.
2025-12-03 12:34:38,013:INFO:Set up folding strategy.
2025-12-03 12:34:38,013:INFO:Set up train/test split.
2025-12-03 12:34:38,037:INFO:Set up index.
2025-12-03 12:34:38,039:INFO:Assigning column types.
2025-12-03 12:34:38,061:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-12-03 12:34:38,089:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-12-03 12:34:38,092:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-03 12:34:38,113:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-03 12:34:38,115:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-03 12:34:38,162:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-12-03 12:34:38,163:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-03 12:34:38,181:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-03 12:34:38,181:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-03 12:34:38,181:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-12-03 12:34:38,210:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-03 12:34:38,226:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-03 12:34:38,228:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-03 12:34:38,261:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-03 12:34:38,280:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-03 12:34:38,282:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-03 12:34:38,282:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-12-03 12:34:38,330:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-03 12:34:38,331:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-03 12:34:38,377:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-03 12:34:38,378:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-03 12:34:38,381:INFO:Preparing preprocessing pipeline...
2025-12-03 12:34:38,384:INFO:Set up simple imputation.
2025-12-03 12:34:38,397:INFO:Set up encoding of ordinal features.
2025-12-03 12:34:38,404:INFO:Set up encoding of categorical features.
2025-12-03 12:34:38,404:INFO:Set up polynomial features.
2025-12-03 12:34:38,404:INFO:Set up removing multicollinearity.
2025-12-03 12:34:38,404:INFO:Set up binning of numerical features.
2025-12-03 12:39:23,134:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-12-03 12:39:23,138:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-12-03 12:39:23,138:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-12-03 12:39:23,138:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-12-03 12:39:24,925:INFO:PyCaret ClassificationExperiment
2025-12-03 12:39:24,925:INFO:Logging name: clf-default-name
2025-12-03 12:39:24,925:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-12-03 12:39:24,925:INFO:version 3.3.2
2025-12-03 12:39:24,925:INFO:Initializing setup()
2025-12-03 12:39:24,925:INFO:self.USI: 2efe
2025-12-03 12:39:24,925:INFO:self._variable_keys: {'fix_imbalance', 'y_train', 'gpu_param', 'memory', 'is_multiclass', '_available_plots', 'seed', 'data', 'y', 'idx', 'logging_param', 'y_test', 'USI', 'n_jobs_param', 'target_param', 'X', 'fold_groups_param', '_ml_usecase', 'gpu_n_jobs_param', 'fold_generator', 'exp_name_log', 'pipeline', 'X_train', 'X_test', 'log_plots_param', 'html_param', 'fold_shuffle_param', 'exp_id'}
2025-12-03 12:39:24,925:INFO:Checking environment
2025-12-03 12:39:24,925:INFO:python_version: 3.10.19
2025-12-03 12:39:24,925:INFO:python_build: ('main', 'Oct 21 2025 16:41:31')
2025-12-03 12:39:24,925:INFO:machine: AMD64
2025-12-03 12:39:24,926:INFO:platform: Windows-10-10.0.26100-SP0
2025-12-03 12:39:24,926:INFO:Memory: svmem(total=16282144768, available=4650463232, percent=71.4, used=11631681536, free=4650463232)
2025-12-03 12:39:24,926:INFO:Physical Core: 6
2025-12-03 12:39:24,926:INFO:Logical Core: 12
2025-12-03 12:39:24,926:INFO:Checking libraries
2025-12-03 12:39:24,926:INFO:System:
2025-12-03 12:39:24,926:INFO:    python: 3.10.19 | packaged by Anaconda, Inc. | (main, Oct 21 2025, 16:41:31) [MSC v.1929 64 bit (AMD64)]
2025-12-03 12:39:24,926:INFO:executable: c:\Users\OMAR\miniconda3\envs\xgb_env\python.exe
2025-12-03 12:39:24,926:INFO:   machine: Windows-10-10.0.26100-SP0
2025-12-03 12:39:24,926:INFO:PyCaret required dependencies:
2025-12-03 12:39:24,926:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-03 12:39:25,505:INFO:                 pip: 25.3
2025-12-03 12:39:25,505:INFO:          setuptools: 80.9.0
2025-12-03 12:39:25,505:INFO:             pycaret: 3.3.2
2025-12-03 12:39:25,505:INFO:             IPython: 8.37.0
2025-12-03 12:39:25,505:INFO:          ipywidgets: 8.1.8
2025-12-03 12:39:25,505:INFO:                tqdm: 4.67.1
2025-12-03 12:39:25,505:INFO:               numpy: 1.26.4
2025-12-03 12:39:25,505:INFO:              pandas: 2.1.4
2025-12-03 12:39:25,505:INFO:              jinja2: 3.1.6
2025-12-03 12:39:25,505:INFO:               scipy: 1.11.4
2025-12-03 12:39:25,505:INFO:              joblib: 1.3.2
2025-12-03 12:39:25,505:INFO:             sklearn: 1.4.2
2025-12-03 12:39:25,505:INFO:                pyod: 2.0.5
2025-12-03 12:39:25,505:INFO:            imblearn: 0.14.0
2025-12-03 12:39:25,505:INFO:   category_encoders: 2.7.0
2025-12-03 12:39:25,505:INFO:            lightgbm: 4.6.0
2025-12-03 12:39:25,505:INFO:               numba: 0.62.1
2025-12-03 12:39:25,505:INFO:            requests: 2.32.5
2025-12-03 12:39:25,505:INFO:          matplotlib: 3.7.5
2025-12-03 12:39:25,505:INFO:          scikitplot: 0.3.7
2025-12-03 12:39:25,505:INFO:         yellowbrick: 1.5
2025-12-03 12:39:25,505:INFO:              plotly: 5.24.1
2025-12-03 12:39:25,505:INFO:    plotly-resampler: Not installed
2025-12-03 12:39:25,505:INFO:             kaleido: 1.2.0
2025-12-03 12:39:25,507:INFO:           schemdraw: 0.15
2025-12-03 12:39:25,507:INFO:         statsmodels: 0.14.5
2025-12-03 12:39:25,507:INFO:              sktime: 0.26.0
2025-12-03 12:39:25,507:INFO:               tbats: 1.1.3
2025-12-03 12:39:25,507:INFO:            pmdarima: 2.0.4
2025-12-03 12:39:25,507:INFO:              psutil: 7.1.3
2025-12-03 12:39:25,507:INFO:          markupsafe: 3.0.3
2025-12-03 12:39:25,507:INFO:             pickle5: Not installed
2025-12-03 12:39:25,507:INFO:         cloudpickle: 3.1.2
2025-12-03 12:39:25,507:INFO:         deprecation: 2.1.0
2025-12-03 12:39:25,507:INFO:              xxhash: 3.6.0
2025-12-03 12:39:25,507:INFO:           wurlitzer: Not installed
2025-12-03 12:39:25,507:INFO:PyCaret optional dependencies:
2025-12-03 12:39:28,260:INFO:                shap: 0.49.1
2025-12-03 12:39:28,260:INFO:           interpret: 0.7.3
2025-12-03 12:39:28,260:INFO:                umap: 0.5.7
2025-12-03 12:39:28,260:INFO:     ydata_profiling: 4.18.0
2025-12-03 12:39:28,260:INFO:  explainerdashboard: 0.5.1
2025-12-03 12:39:28,260:INFO:             autoviz: Not installed
2025-12-03 12:39:28,260:INFO:           fairlearn: 0.7.0
2025-12-03 12:39:28,260:INFO:          deepchecks: Not installed
2025-12-03 12:39:28,260:INFO:             xgboost: 2.1.3
2025-12-03 12:39:28,260:INFO:            catboost: 1.2.8
2025-12-03 12:39:28,260:INFO:              kmodes: 0.12.2
2025-12-03 12:39:28,260:INFO:             mlxtend: 0.23.4
2025-12-03 12:39:28,260:INFO:       statsforecast: 1.5.0
2025-12-03 12:39:28,260:INFO:        tune_sklearn: Not installed
2025-12-03 12:39:28,260:INFO:                 ray: Not installed
2025-12-03 12:39:28,260:INFO:            hyperopt: 0.2.7
2025-12-03 12:39:28,260:INFO:              optuna: 4.6.0
2025-12-03 12:39:28,260:INFO:               skopt: 0.10.2
2025-12-03 12:39:28,260:INFO:              mlflow: 3.6.0
2025-12-03 12:39:28,260:INFO:              gradio: 6.0.1
2025-12-03 12:39:28,260:INFO:             fastapi: 0.123.0
2025-12-03 12:39:28,260:INFO:             uvicorn: 0.38.0
2025-12-03 12:39:28,260:INFO:              m2cgen: 0.10.0
2025-12-03 12:39:28,260:INFO:           evidently: 0.4.40
2025-12-03 12:39:28,260:INFO:               fugue: 0.8.7
2025-12-03 12:39:28,260:INFO:           streamlit: 1.51.0
2025-12-03 12:39:28,260:INFO:             prophet: Not installed
2025-12-03 12:39:28,260:INFO:None
2025-12-03 12:39:28,260:INFO:Set up data.
2025-12-03 12:39:28,276:INFO:Set up folding strategy.
2025-12-03 12:39:28,276:INFO:Set up train/test split.
2025-12-03 12:39:28,300:INFO:Set up index.
2025-12-03 12:39:28,301:INFO:Assigning column types.
2025-12-03 12:39:28,322:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-12-03 12:39:28,344:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-12-03 12:39:28,350:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-03 12:39:28,371:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-03 12:39:28,375:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-03 12:39:28,421:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-12-03 12:39:28,421:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-03 12:39:28,438:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-03 12:39:28,438:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-03 12:39:28,441:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-12-03 12:39:28,470:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-03 12:39:28,488:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-03 12:39:28,488:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-03 12:39:28,517:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-03 12:39:28,533:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-03 12:39:28,535:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-03 12:39:28,536:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-12-03 12:39:28,576:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-03 12:39:28,578:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-03 12:39:28,620:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-03 12:39:28,622:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-03 12:39:28,623:INFO:Preparing preprocessing pipeline...
2025-12-03 12:39:28,626:INFO:Set up simple imputation.
2025-12-03 12:39:28,638:INFO:Set up encoding of ordinal features.
2025-12-03 12:39:28,644:INFO:Set up encoding of categorical features.
2025-12-03 12:39:28,644:INFO:Set up polynomial features.
2025-12-03 12:39:28,644:INFO:Set up removing multicollinearity.
2025-12-03 12:39:28,644:INFO:Set up binning of numerical features.
2025-12-03 12:39:28,651:INFO:Set up imbalanced handling.
2025-12-03 12:39:28,652:INFO:Set up feature normalization.
2025-12-03 12:42:08,284:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-12-03 12:42:08,284:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-12-03 12:42:08,284:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-12-03 12:42:08,284:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-12-03 12:42:10,073:INFO:PyCaret ClassificationExperiment
2025-12-03 12:42:10,073:INFO:Logging name: clf-default-name
2025-12-03 12:42:10,073:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-12-03 12:42:10,073:INFO:version 3.3.2
2025-12-03 12:42:10,073:INFO:Initializing setup()
2025-12-03 12:42:10,073:INFO:self.USI: 9426
2025-12-03 12:42:10,073:INFO:self._variable_keys: {'logging_param', 'fold_shuffle_param', 'pipeline', 'y_train', 'memory', 'gpu_n_jobs_param', 'html_param', 'target_param', 'n_jobs_param', 'X', 'X_test', 'USI', 'seed', 'exp_id', 'is_multiclass', 'log_plots_param', '_available_plots', 'exp_name_log', 'fix_imbalance', 'gpu_param', 'X_train', 'fold_generator', 'fold_groups_param', 'idx', 'y_test', '_ml_usecase', 'data', 'y'}
2025-12-03 12:42:10,073:INFO:Checking environment
2025-12-03 12:42:10,074:INFO:python_version: 3.10.19
2025-12-03 12:42:10,074:INFO:python_build: ('main', 'Oct 21 2025 16:41:31')
2025-12-03 12:42:10,074:INFO:machine: AMD64
2025-12-03 12:42:10,074:INFO:platform: Windows-10-10.0.26100-SP0
2025-12-03 12:42:10,074:INFO:Memory: svmem(total=16282144768, available=4619894784, percent=71.6, used=11662249984, free=4619894784)
2025-12-03 12:42:10,074:INFO:Physical Core: 6
2025-12-03 12:42:10,074:INFO:Logical Core: 12
2025-12-03 12:42:10,074:INFO:Checking libraries
2025-12-03 12:42:10,074:INFO:System:
2025-12-03 12:42:10,074:INFO:    python: 3.10.19 | packaged by Anaconda, Inc. | (main, Oct 21 2025, 16:41:31) [MSC v.1929 64 bit (AMD64)]
2025-12-03 12:42:10,074:INFO:executable: c:\Users\OMAR\miniconda3\envs\xgb_env\python.exe
2025-12-03 12:42:10,074:INFO:   machine: Windows-10-10.0.26100-SP0
2025-12-03 12:42:10,074:INFO:PyCaret required dependencies:
2025-12-03 12:42:10,075:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-03 12:42:10,652:INFO:                 pip: 25.3
2025-12-03 12:42:10,652:INFO:          setuptools: 80.9.0
2025-12-03 12:42:10,652:INFO:             pycaret: 3.3.2
2025-12-03 12:42:10,652:INFO:             IPython: 8.37.0
2025-12-03 12:42:10,652:INFO:          ipywidgets: 8.1.8
2025-12-03 12:42:10,652:INFO:                tqdm: 4.67.1
2025-12-03 12:42:10,652:INFO:               numpy: 1.26.4
2025-12-03 12:42:10,652:INFO:              pandas: 2.1.4
2025-12-03 12:42:10,652:INFO:              jinja2: 3.1.6
2025-12-03 12:42:10,652:INFO:               scipy: 1.11.4
2025-12-03 12:42:10,652:INFO:              joblib: 1.3.2
2025-12-03 12:42:10,652:INFO:             sklearn: 1.4.2
2025-12-03 12:42:10,652:INFO:                pyod: 2.0.5
2025-12-03 12:42:10,652:INFO:            imblearn: 0.14.0
2025-12-03 12:42:10,652:INFO:   category_encoders: 2.7.0
2025-12-03 12:42:10,652:INFO:            lightgbm: 4.6.0
2025-12-03 12:42:10,652:INFO:               numba: 0.62.1
2025-12-03 12:42:10,652:INFO:            requests: 2.32.5
2025-12-03 12:42:10,652:INFO:          matplotlib: 3.7.5
2025-12-03 12:42:10,652:INFO:          scikitplot: 0.3.7
2025-12-03 12:42:10,652:INFO:         yellowbrick: 1.5
2025-12-03 12:42:10,652:INFO:              plotly: 5.24.1
2025-12-03 12:42:10,652:INFO:    plotly-resampler: Not installed
2025-12-03 12:42:10,652:INFO:             kaleido: 1.2.0
2025-12-03 12:42:10,652:INFO:           schemdraw: 0.15
2025-12-03 12:42:10,652:INFO:         statsmodels: 0.14.5
2025-12-03 12:42:10,652:INFO:              sktime: 0.26.0
2025-12-03 12:42:10,652:INFO:               tbats: 1.1.3
2025-12-03 12:42:10,653:INFO:            pmdarima: 2.0.4
2025-12-03 12:42:10,653:INFO:              psutil: 7.1.3
2025-12-03 12:42:10,653:INFO:          markupsafe: 3.0.3
2025-12-03 12:42:10,653:INFO:             pickle5: Not installed
2025-12-03 12:42:10,653:INFO:         cloudpickle: 3.1.2
2025-12-03 12:42:10,653:INFO:         deprecation: 2.1.0
2025-12-03 12:42:10,653:INFO:              xxhash: 3.6.0
2025-12-03 12:42:10,653:INFO:           wurlitzer: Not installed
2025-12-03 12:42:10,653:INFO:PyCaret optional dependencies:
2025-12-03 12:42:13,427:INFO:                shap: 0.49.1
2025-12-03 12:42:13,427:INFO:           interpret: 0.7.3
2025-12-03 12:42:13,427:INFO:                umap: 0.5.7
2025-12-03 12:42:13,427:INFO:     ydata_profiling: 4.18.0
2025-12-03 12:42:13,428:INFO:  explainerdashboard: 0.5.1
2025-12-03 12:42:13,428:INFO:             autoviz: Not installed
2025-12-03 12:42:13,428:INFO:           fairlearn: 0.7.0
2025-12-03 12:42:13,428:INFO:          deepchecks: Not installed
2025-12-03 12:42:13,428:INFO:             xgboost: 2.1.3
2025-12-03 12:42:13,428:INFO:            catboost: 1.2.8
2025-12-03 12:42:13,428:INFO:              kmodes: 0.12.2
2025-12-03 12:42:13,428:INFO:             mlxtend: 0.23.4
2025-12-03 12:42:13,428:INFO:       statsforecast: 1.5.0
2025-12-03 12:42:13,428:INFO:        tune_sklearn: Not installed
2025-12-03 12:42:13,428:INFO:                 ray: Not installed
2025-12-03 12:42:13,428:INFO:            hyperopt: 0.2.7
2025-12-03 12:42:13,428:INFO:              optuna: 4.6.0
2025-12-03 12:42:13,428:INFO:               skopt: 0.10.2
2025-12-03 12:42:13,428:INFO:              mlflow: 3.6.0
2025-12-03 12:42:13,428:INFO:              gradio: 6.0.1
2025-12-03 12:42:13,428:INFO:             fastapi: 0.123.0
2025-12-03 12:42:13,428:INFO:             uvicorn: 0.38.0
2025-12-03 12:42:13,428:INFO:              m2cgen: 0.10.0
2025-12-03 12:42:13,428:INFO:           evidently: 0.4.40
2025-12-03 12:42:13,428:INFO:               fugue: 0.8.7
2025-12-03 12:42:13,428:INFO:           streamlit: 1.51.0
2025-12-03 12:42:13,428:INFO:             prophet: Not installed
2025-12-03 12:42:13,428:INFO:None
2025-12-03 12:42:13,428:INFO:Set up data.
2025-12-03 12:42:13,445:INFO:Set up folding strategy.
2025-12-03 12:42:13,445:INFO:Set up train/test split.
2025-12-03 12:42:13,470:INFO:Set up index.
2025-12-03 12:42:13,470:INFO:Assigning column types.
2025-12-03 12:42:13,494:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-12-03 12:42:13,522:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-12-03 12:42:13,526:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-03 12:42:13,546:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-03 12:42:13,549:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-03 12:42:13,594:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-12-03 12:42:13,594:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-03 12:42:13,609:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-03 12:42:13,609:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-03 12:42:13,616:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-12-03 12:42:13,641:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-03 12:42:13,657:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-03 12:42:13,659:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-03 12:42:13,684:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-03 12:42:13,700:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-03 12:42:13,702:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-03 12:42:13,702:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-12-03 12:42:13,744:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-03 12:42:13,744:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-03 12:42:13,790:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-03 12:42:13,791:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-03 12:42:13,794:INFO:Preparing preprocessing pipeline...
2025-12-03 12:42:13,798:INFO:Set up simple imputation.
2025-12-03 12:42:13,809:INFO:Set up encoding of ordinal features.
2025-12-03 12:42:13,816:INFO:Set up encoding of categorical features.
2025-12-03 12:42:13,816:INFO:Set up polynomial features.
2025-12-03 12:42:13,816:INFO:Set up removing multicollinearity.
2025-12-03 12:42:13,816:INFO:Set up imbalanced handling.
2025-12-03 12:42:13,816:INFO:Set up feature normalization.
2025-12-03 12:42:14,200:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\joblib\externals\loky\backend\context.py:136: UserWarning: Could not find the number of physical cores for the following reason:
[WinError 2] El sistema no puede encontrar el archivo especificado
Returning the number of logical cores instead. You can silence this warning by setting LOKY_MAX_CPU_COUNT to the number of cores you want to use.

2025-12-03 12:42:15,094:INFO:Finished creating preprocessing pipeline.
2025-12-03 12:42:15,112:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\OMAR\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'IncomeRatio', 'SystolicBP',
                                             'BMI', 'WaistCircumference',
                                             'Height', 'TotalCholesterol',
                                             'Triglycerides', 'LDL', 'HDL',
                                             'HbA1c', 'Glucose', 'Creatinine',
                                             'UricAcid', 'ALT_Enzyme',
                                             'Albumin', 'Potassium', 'Sodium',
                                             'G...
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              random_state=42,
                                                                              sampling_strategy='auto')))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=RobustScaler(copy=True,
                                                             quantile_range=(25.0,
                                                                             75.0),
                                                             unit_variance=False,
                                                             with_centering=True,
                                                             with_scaling=True)))],
         verbose=False)
2025-12-03 12:42:15,112:INFO:Creating final display dataframe.
2025-12-03 12:42:16,919:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target      HeartDisease
2                   Target type            Binary
3           Original data shape       (43695, 28)
4        Transformed data shape      (72719, 287)
5   Transformed train set shape      (59610, 287)
6    Transformed test set shape      (13109, 287)
7              Numeric features                20
8          Categorical features                 7
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15          Polynomial features              True
16            Polynomial degree                 2
17     Remove multicollinearity              True
18  Multicollinearity threshold              0.95
19                Fix imbalance              True
20         Fix imbalance method             SMOTE
21                    Normalize              True
22             Normalize method            robust
23               Fold Generator   StratifiedKFold
24                  Fold Number                10
25                     CPU Jobs                 1
26                      Use GPU             False
27               Log Experiment             False
28              Experiment Name  clf-default-name
29                          USI              9426
2025-12-03 12:42:16,972:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-03 12:42:16,973:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-03 12:42:17,016:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-03 12:42:17,018:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-03 12:42:17,019:INFO:setup() successfully completed in 6.96s...............
2025-12-03 12:42:17,019:INFO:Initializing create_model()
2025-12-03 12:42:17,020:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021421AA2680>, estimator=xgboost, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-03 12:42:17,020:INFO:Checking exceptions
2025-12-03 12:42:17,021:INFO:Importing libraries
2025-12-03 12:42:17,021:INFO:Copying training dataset
2025-12-03 12:42:17,044:INFO:Defining folds
2025-12-03 12:42:17,044:INFO:Declaring metric variables
2025-12-03 12:42:17,044:INFO:Importing untrained model
2025-12-03 12:42:17,044:INFO:Extreme Gradient Boosting Imported successfully
2025-12-03 12:42:17,044:INFO:Starting cross validation
2025-12-03 12:42:17,044:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-12-03 12:45:05,107:INFO:Calculating mean and std
2025-12-03 12:45:05,107:INFO:Creating metrics dataframe
2025-12-03 12:45:05,108:INFO:Finalizing model
2025-12-03 12:45:05,176:INFO:Warning: No categorical columns found. Calling 'transform' will only return input data.
2025-12-03 12:51:57,412:INFO:PyCaret ClassificationExperiment
2025-12-03 12:51:57,412:INFO:Logging name: clf-default-name
2025-12-03 12:51:57,412:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-12-03 12:51:57,412:INFO:version 3.3.2
2025-12-03 12:51:57,412:INFO:Initializing setup()
2025-12-03 12:51:57,412:INFO:self.USI: 24e5
2025-12-03 12:51:57,412:INFO:self._variable_keys: {'logging_param', 'fold_shuffle_param', 'pipeline', 'y_train', 'memory', 'gpu_n_jobs_param', 'html_param', 'target_param', 'n_jobs_param', 'X', 'X_test', 'USI', 'seed', 'exp_id', 'is_multiclass', 'log_plots_param', '_available_plots', 'exp_name_log', 'fix_imbalance', 'gpu_param', 'X_train', 'fold_generator', 'fold_groups_param', 'idx', 'y_test', '_ml_usecase', 'data', 'y'}
2025-12-03 12:51:57,412:INFO:Checking environment
2025-12-03 12:51:57,413:INFO:python_version: 3.10.19
2025-12-03 12:51:57,413:INFO:python_build: ('main', 'Oct 21 2025 16:41:31')
2025-12-03 12:51:57,413:INFO:machine: AMD64
2025-12-03 12:51:57,413:INFO:platform: Windows-10-10.0.26100-SP0
2025-12-03 12:51:57,413:INFO:Memory: svmem(total=16282144768, available=3826839552, percent=76.5, used=12455305216, free=3826839552)
2025-12-03 12:51:57,413:INFO:Physical Core: 6
2025-12-03 12:51:57,413:INFO:Logical Core: 12
2025-12-03 12:51:57,413:INFO:Checking libraries
2025-12-03 12:51:57,413:INFO:System:
2025-12-03 12:51:57,413:INFO:    python: 3.10.19 | packaged by Anaconda, Inc. | (main, Oct 21 2025, 16:41:31) [MSC v.1929 64 bit (AMD64)]
2025-12-03 12:51:57,413:INFO:executable: c:\Users\OMAR\miniconda3\envs\xgb_env\python.exe
2025-12-03 12:51:57,413:INFO:   machine: Windows-10-10.0.26100-SP0
2025-12-03 12:51:57,413:INFO:PyCaret required dependencies:
2025-12-03 12:51:57,413:INFO:                 pip: 25.3
2025-12-03 12:51:57,413:INFO:          setuptools: 80.9.0
2025-12-03 12:51:57,413:INFO:             pycaret: 3.3.2
2025-12-03 12:51:57,413:INFO:             IPython: 8.37.0
2025-12-03 12:51:57,413:INFO:          ipywidgets: 8.1.8
2025-12-03 12:51:57,413:INFO:                tqdm: 4.67.1
2025-12-03 12:51:57,413:INFO:               numpy: 1.26.4
2025-12-03 12:51:57,413:INFO:              pandas: 2.1.4
2025-12-03 12:51:57,413:INFO:              jinja2: 3.1.6
2025-12-03 12:51:57,413:INFO:               scipy: 1.11.4
2025-12-03 12:51:57,413:INFO:              joblib: 1.3.2
2025-12-03 12:51:57,413:INFO:             sklearn: 1.4.2
2025-12-03 12:51:57,413:INFO:                pyod: 2.0.5
2025-12-03 12:51:57,413:INFO:            imblearn: 0.14.0
2025-12-03 12:51:57,413:INFO:   category_encoders: 2.7.0
2025-12-03 12:51:57,413:INFO:            lightgbm: 4.6.0
2025-12-03 12:51:57,413:INFO:               numba: 0.62.1
2025-12-03 12:51:57,413:INFO:            requests: 2.32.5
2025-12-03 12:51:57,413:INFO:          matplotlib: 3.7.5
2025-12-03 12:51:57,413:INFO:          scikitplot: 0.3.7
2025-12-03 12:51:57,413:INFO:         yellowbrick: 1.5
2025-12-03 12:51:57,413:INFO:              plotly: 5.24.1
2025-12-03 12:51:57,413:INFO:    plotly-resampler: Not installed
2025-12-03 12:51:57,413:INFO:             kaleido: 1.2.0
2025-12-03 12:51:57,413:INFO:           schemdraw: 0.15
2025-12-03 12:51:57,413:INFO:         statsmodels: 0.14.5
2025-12-03 12:51:57,414:INFO:              sktime: 0.26.0
2025-12-03 12:51:57,414:INFO:               tbats: 1.1.3
2025-12-03 12:51:57,414:INFO:            pmdarima: 2.0.4
2025-12-03 12:51:57,414:INFO:              psutil: 7.1.3
2025-12-03 12:51:57,414:INFO:          markupsafe: 3.0.3
2025-12-03 12:51:57,414:INFO:             pickle5: Not installed
2025-12-03 12:51:57,414:INFO:         cloudpickle: 3.1.2
2025-12-03 12:51:57,414:INFO:         deprecation: 2.1.0
2025-12-03 12:51:57,414:INFO:              xxhash: 3.6.0
2025-12-03 12:51:57,414:INFO:           wurlitzer: Not installed
2025-12-03 12:51:57,414:INFO:PyCaret optional dependencies:
2025-12-03 12:51:57,414:INFO:                shap: 0.49.1
2025-12-03 12:51:57,414:INFO:           interpret: 0.7.3
2025-12-03 12:51:57,414:INFO:                umap: 0.5.7
2025-12-03 12:51:57,414:INFO:     ydata_profiling: 4.18.0
2025-12-03 12:51:57,414:INFO:  explainerdashboard: 0.5.1
2025-12-03 12:51:57,414:INFO:             autoviz: Not installed
2025-12-03 12:51:57,414:INFO:           fairlearn: 0.7.0
2025-12-03 12:51:57,414:INFO:          deepchecks: Not installed
2025-12-03 12:51:57,414:INFO:             xgboost: 2.1.3
2025-12-03 12:51:57,414:INFO:            catboost: 1.2.8
2025-12-03 12:51:57,414:INFO:              kmodes: 0.12.2
2025-12-03 12:51:57,414:INFO:             mlxtend: 0.23.4
2025-12-03 12:51:57,414:INFO:       statsforecast: 1.5.0
2025-12-03 12:51:57,414:INFO:        tune_sklearn: Not installed
2025-12-03 12:51:57,414:INFO:                 ray: Not installed
2025-12-03 12:51:57,414:INFO:            hyperopt: 0.2.7
2025-12-03 12:51:57,414:INFO:              optuna: 4.6.0
2025-12-03 12:51:57,414:INFO:               skopt: 0.10.2
2025-12-03 12:51:57,414:INFO:              mlflow: 3.6.0
2025-12-03 12:51:57,414:INFO:              gradio: 6.0.1
2025-12-03 12:51:57,414:INFO:             fastapi: 0.123.0
2025-12-03 12:51:57,414:INFO:             uvicorn: 0.38.0
2025-12-03 12:51:57,414:INFO:              m2cgen: 0.10.0
2025-12-03 12:51:57,414:INFO:           evidently: 0.4.40
2025-12-03 12:51:57,414:INFO:               fugue: 0.8.7
2025-12-03 12:51:57,414:INFO:           streamlit: 1.51.0
2025-12-03 12:51:57,414:INFO:             prophet: Not installed
2025-12-03 12:51:57,414:INFO:None
2025-12-03 12:51:57,414:INFO:Set up data.
2025-12-03 12:51:57,432:INFO:Set up folding strategy.
2025-12-03 12:51:57,434:INFO:Set up train/test split.
2025-12-03 12:51:57,456:INFO:Set up index.
2025-12-03 12:51:57,457:INFO:Assigning column types.
2025-12-03 12:51:57,473:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-12-03 12:51:57,499:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-12-03 12:51:57,499:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-03 12:51:57,514:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-03 12:51:57,516:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-03 12:51:57,543:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-12-03 12:51:57,544:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-03 12:51:57,560:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-03 12:51:57,562:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-03 12:51:57,562:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-12-03 12:51:57,588:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-03 12:51:57,604:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-03 12:51:57,607:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-03 12:51:57,634:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-03 12:51:57,650:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-03 12:51:57,652:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-03 12:51:57,653:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-12-03 12:51:57,694:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-03 12:51:57,694:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-03 12:51:57,743:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-03 12:51:57,746:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-03 12:51:57,748:INFO:Preparing preprocessing pipeline...
2025-12-03 12:51:57,750:INFO:Set up simple imputation.
2025-12-03 12:51:57,762:INFO:Set up encoding of ordinal features.
2025-12-03 12:51:57,769:INFO:Set up encoding of categorical features.
2025-12-03 12:51:57,769:INFO:Set up polynomial features.
2025-12-03 12:51:57,769:INFO:Set up removing multicollinearity.
2025-12-03 12:51:57,769:INFO:Set up imbalanced handling.
2025-12-03 12:51:57,769:INFO:Set up feature normalization.
2025-12-03 12:51:58,212:INFO:Finished creating preprocessing pipeline.
2025-12-03 12:51:58,228:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\OMAR\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'IncomeRatio', 'SystolicBP',
                                             'BMI', 'WaistCircumference',
                                             'Height', 'TotalCholesterol',
                                             'Triglycerides', 'LDL', 'HDL',
                                             'HbA1c', 'Glucose', 'Creatinine',
                                             'UricAcid', 'ALT_Enzyme',
                                             'Albumin', 'Potassium', 'Sodium',
                                             'G...
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              random_state=42,
                                                                              sampling_strategy='auto')))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=RobustScaler(copy=True,
                                                             quantile_range=(25.0,
                                                                             75.0),
                                                             unit_variance=False,
                                                             with_centering=True,
                                                             with_scaling=True)))],
         verbose=False)
2025-12-03 12:51:58,230:INFO:Creating final display dataframe.
2025-12-03 12:51:59,225:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target      HeartDisease
2                   Target type            Binary
3           Original data shape       (43695, 28)
4        Transformed data shape      (72719, 287)
5   Transformed train set shape      (59610, 287)
6    Transformed test set shape      (13109, 287)
7              Numeric features                20
8          Categorical features                 7
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15          Polynomial features              True
16            Polynomial degree                 2
17     Remove multicollinearity              True
18  Multicollinearity threshold              0.95
19                Fix imbalance              True
20         Fix imbalance method             SMOTE
21                    Normalize              True
22             Normalize method            robust
23               Fold Generator   StratifiedKFold
24                  Fold Number                10
25                     CPU Jobs                 1
26                      Use GPU             False
27               Log Experiment             False
28              Experiment Name  clf-default-name
29                          USI              24e5
2025-12-03 12:51:59,273:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-03 12:51:59,275:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-03 12:51:59,319:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-03 12:51:59,320:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-03 12:51:59,320:INFO:setup() successfully completed in 1.92s...............
2025-12-03 12:51:59,320:INFO:Initializing create_model()
2025-12-03 12:51:59,323:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002144B992080>, estimator=xgboost, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-03 12:51:59,323:INFO:Checking exceptions
2025-12-03 12:51:59,325:INFO:Importing libraries
2025-12-03 12:51:59,325:INFO:Copying training dataset
2025-12-03 12:51:59,346:INFO:Defining folds
2025-12-03 12:51:59,346:INFO:Declaring metric variables
2025-12-03 12:51:59,346:INFO:Importing untrained model
2025-12-03 12:51:59,347:INFO:Extreme Gradient Boosting Imported successfully
2025-12-03 12:51:59,347:INFO:Starting cross validation
2025-12-03 12:51:59,349:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-12-03 12:53:37,725:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-12-03 12:53:37,725:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-12-03 12:53:37,725:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-12-03 12:53:37,725:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-12-03 12:53:39,491:INFO:PyCaret ClassificationExperiment
2025-12-03 12:53:39,491:INFO:Logging name: clf-default-name
2025-12-03 12:53:39,491:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-12-03 12:53:39,491:INFO:version 3.3.2
2025-12-03 12:53:39,491:INFO:Initializing setup()
2025-12-03 12:53:39,494:INFO:self.USI: 5ba3
2025-12-03 12:53:39,494:INFO:self._variable_keys: {'exp_id', 'n_jobs_param', '_ml_usecase', 'fold_groups_param', 'logging_param', 'seed', 'log_plots_param', 'y_test', 'target_param', 'fix_imbalance', 'y', '_available_plots', 'exp_name_log', 'html_param', 'X_test', 'USI', 'pipeline', 'X', 'fold_shuffle_param', 'y_train', 'gpu_param', 'is_multiclass', 'fold_generator', 'idx', 'data', 'gpu_n_jobs_param', 'memory', 'X_train'}
2025-12-03 12:53:39,494:INFO:Checking environment
2025-12-03 12:53:39,494:INFO:python_version: 3.10.19
2025-12-03 12:53:39,494:INFO:python_build: ('main', 'Oct 21 2025 16:41:31')
2025-12-03 12:53:39,494:INFO:machine: AMD64
2025-12-03 12:53:39,494:INFO:platform: Windows-10-10.0.26100-SP0
2025-12-03 12:53:39,494:INFO:Memory: svmem(total=16282144768, available=4400513024, percent=73.0, used=11881631744, free=4400513024)
2025-12-03 12:53:39,494:INFO:Physical Core: 6
2025-12-03 12:53:39,494:INFO:Logical Core: 12
2025-12-03 12:53:39,494:INFO:Checking libraries
2025-12-03 12:53:39,494:INFO:System:
2025-12-03 12:53:39,494:INFO:    python: 3.10.19 | packaged by Anaconda, Inc. | (main, Oct 21 2025, 16:41:31) [MSC v.1929 64 bit (AMD64)]
2025-12-03 12:53:39,494:INFO:executable: c:\Users\OMAR\miniconda3\envs\xgb_env\python.exe
2025-12-03 12:53:39,494:INFO:   machine: Windows-10-10.0.26100-SP0
2025-12-03 12:53:39,494:INFO:PyCaret required dependencies:
2025-12-03 12:53:39,494:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-03 12:53:40,044:INFO:                 pip: 25.3
2025-12-03 12:53:40,044:INFO:          setuptools: 80.9.0
2025-12-03 12:53:40,044:INFO:             pycaret: 3.3.2
2025-12-03 12:53:40,044:INFO:             IPython: 8.37.0
2025-12-03 12:53:40,044:INFO:          ipywidgets: 8.1.8
2025-12-03 12:53:40,044:INFO:                tqdm: 4.67.1
2025-12-03 12:53:40,044:INFO:               numpy: 1.26.4
2025-12-03 12:53:40,044:INFO:              pandas: 2.1.4
2025-12-03 12:53:40,044:INFO:              jinja2: 3.1.6
2025-12-03 12:53:40,044:INFO:               scipy: 1.11.4
2025-12-03 12:53:40,044:INFO:              joblib: 1.3.2
2025-12-03 12:53:40,044:INFO:             sklearn: 1.4.2
2025-12-03 12:53:40,044:INFO:                pyod: 2.0.5
2025-12-03 12:53:40,044:INFO:            imblearn: 0.14.0
2025-12-03 12:53:40,044:INFO:   category_encoders: 2.7.0
2025-12-03 12:53:40,044:INFO:            lightgbm: 4.6.0
2025-12-03 12:53:40,044:INFO:               numba: 0.62.1
2025-12-03 12:53:40,044:INFO:            requests: 2.32.5
2025-12-03 12:53:40,044:INFO:          matplotlib: 3.7.5
2025-12-03 12:53:40,044:INFO:          scikitplot: 0.3.7
2025-12-03 12:53:40,044:INFO:         yellowbrick: 1.5
2025-12-03 12:53:40,044:INFO:              plotly: 5.24.1
2025-12-03 12:53:40,044:INFO:    plotly-resampler: Not installed
2025-12-03 12:53:40,044:INFO:             kaleido: 1.2.0
2025-12-03 12:53:40,044:INFO:           schemdraw: 0.15
2025-12-03 12:53:40,044:INFO:         statsmodels: 0.14.5
2025-12-03 12:53:40,044:INFO:              sktime: 0.26.0
2025-12-03 12:53:40,044:INFO:               tbats: 1.1.3
2025-12-03 12:53:40,044:INFO:            pmdarima: 2.0.4
2025-12-03 12:53:40,044:INFO:              psutil: 7.1.3
2025-12-03 12:53:40,044:INFO:          markupsafe: 3.0.3
2025-12-03 12:53:40,044:INFO:             pickle5: Not installed
2025-12-03 12:53:40,044:INFO:         cloudpickle: 3.1.2
2025-12-03 12:53:40,044:INFO:         deprecation: 2.1.0
2025-12-03 12:53:40,044:INFO:              xxhash: 3.6.0
2025-12-03 12:53:40,044:INFO:           wurlitzer: Not installed
2025-12-03 12:53:40,044:INFO:PyCaret optional dependencies:
2025-12-03 12:53:42,760:INFO:                shap: 0.49.1
2025-12-03 12:53:42,760:INFO:           interpret: 0.7.3
2025-12-03 12:53:42,760:INFO:                umap: 0.5.7
2025-12-03 12:53:42,760:INFO:     ydata_profiling: 4.18.0
2025-12-03 12:53:42,760:INFO:  explainerdashboard: 0.5.1
2025-12-03 12:53:42,760:INFO:             autoviz: Not installed
2025-12-03 12:53:42,760:INFO:           fairlearn: 0.7.0
2025-12-03 12:53:42,760:INFO:          deepchecks: Not installed
2025-12-03 12:53:42,760:INFO:             xgboost: 2.1.3
2025-12-03 12:53:42,760:INFO:            catboost: 1.2.8
2025-12-03 12:53:42,760:INFO:              kmodes: 0.12.2
2025-12-03 12:53:42,760:INFO:             mlxtend: 0.23.4
2025-12-03 12:53:42,760:INFO:       statsforecast: 1.5.0
2025-12-03 12:53:42,760:INFO:        tune_sklearn: Not installed
2025-12-03 12:53:42,760:INFO:                 ray: Not installed
2025-12-03 12:53:42,760:INFO:            hyperopt: 0.2.7
2025-12-03 12:53:42,760:INFO:              optuna: 4.6.0
2025-12-03 12:53:42,760:INFO:               skopt: 0.10.2
2025-12-03 12:53:42,760:INFO:              mlflow: 3.6.0
2025-12-03 12:53:42,760:INFO:              gradio: 6.0.1
2025-12-03 12:53:42,760:INFO:             fastapi: 0.123.0
2025-12-03 12:53:42,760:INFO:             uvicorn: 0.38.0
2025-12-03 12:53:42,760:INFO:              m2cgen: 0.10.0
2025-12-03 12:53:42,760:INFO:           evidently: 0.4.40
2025-12-03 12:53:42,760:INFO:               fugue: 0.8.7
2025-12-03 12:53:42,760:INFO:           streamlit: 1.51.0
2025-12-03 12:53:42,760:INFO:             prophet: Not installed
2025-12-03 12:53:42,760:INFO:None
2025-12-03 12:53:42,760:INFO:Set up data.
2025-12-03 12:53:42,782:INFO:Set up folding strategy.
2025-12-03 12:53:42,782:INFO:Set up train/test split.
2025-12-03 12:53:42,807:INFO:Set up index.
2025-12-03 12:53:42,809:INFO:Assigning column types.
2025-12-03 12:53:42,826:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-12-03 12:53:42,852:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-12-03 12:53:42,854:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-03 12:53:42,875:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-03 12:53:42,876:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-03 12:53:42,920:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-12-03 12:53:42,920:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-03 12:53:42,935:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-03 12:53:42,938:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-03 12:53:42,938:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-12-03 12:53:42,958:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-03 12:53:42,978:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-03 12:53:42,980:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-03 12:53:43,006:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-03 12:53:43,020:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-03 12:53:43,024:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-03 12:53:43,024:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-12-03 12:53:43,062:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-03 12:53:43,068:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-03 12:53:43,113:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-03 12:53:43,114:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-03 12:53:43,115:INFO:Preparing preprocessing pipeline...
2025-12-03 12:53:43,120:INFO:Set up simple imputation.
2025-12-03 12:53:43,132:INFO:Set up encoding of ordinal features.
2025-12-03 12:53:43,141:INFO:Set up encoding of categorical features.
2025-12-03 12:53:43,142:INFO:Set up polynomial features.
2025-12-03 12:53:43,142:INFO:Set up removing multicollinearity.
2025-12-03 12:53:43,142:INFO:Set up imbalanced handling.
2025-12-03 12:53:43,142:INFO:Set up feature normalization.
2025-12-03 12:53:43,565:INFO:Finished creating preprocessing pipeline.
2025-12-03 12:53:43,582:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\OMAR\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'IncomeRatio', 'SystolicBP',
                                             'BMI', 'WaistCircumference',
                                             'Height', 'TotalCholesterol',
                                             'Triglycerides', 'LDL', 'HDL',
                                             'HbA1c', 'Glucose', 'Creatinine',
                                             'UricAcid', 'ALT_Enzyme',
                                             'Albumin', 'Potassium', 'Sodium',
                                             'G...
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              random_state=42,
                                                                              sampling_strategy='auto')))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=RobustScaler(copy=True,
                                                             quantile_range=(25.0,
                                                                             75.0),
                                                             unit_variance=False,
                                                             with_centering=True,
                                                             with_scaling=True)))],
         verbose=False)
2025-12-03 12:53:43,582:INFO:Creating final display dataframe.
2025-12-03 12:53:43,920:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target      HeartDisease
2                   Target type            Binary
3           Original data shape       (43695, 28)
4        Transformed data shape      (72719, 287)
5   Transformed train set shape      (59610, 287)
6    Transformed test set shape      (13109, 287)
7              Numeric features                20
8          Categorical features                 7
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15          Polynomial features              True
16            Polynomial degree                 2
17     Remove multicollinearity              True
18  Multicollinearity threshold              0.95
19                Fix imbalance              True
20         Fix imbalance method             SMOTE
21                    Normalize              True
22             Normalize method            robust
23               Fold Generator   StratifiedKFold
24                  Fold Number                10
25                     CPU Jobs                 1
26                      Use GPU             False
27               Log Experiment             False
28              Experiment Name  clf-default-name
29                          USI              5ba3
2025-12-03 12:53:43,971:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-03 12:53:43,973:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-03 12:53:44,014:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-03 12:53:44,015:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-03 12:53:44,017:INFO:setup() successfully completed in 4.54s...............
2025-12-03 12:53:44,085:INFO:Initializing create_model()
2025-12-03 12:53:44,085:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A6529B2620>, estimator=xgboost, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-03 12:53:44,085:INFO:Checking exceptions
2025-12-03 12:53:44,086:INFO:Importing libraries
2025-12-03 12:53:44,086:INFO:Copying training dataset
2025-12-03 12:53:44,121:INFO:Defining folds
2025-12-03 12:53:44,121:INFO:Declaring metric variables
2025-12-03 12:53:44,122:INFO:Importing untrained model
2025-12-03 12:53:44,123:INFO:Extreme Gradient Boosting Imported successfully
2025-12-03 12:53:44,123:INFO:Starting cross validation
2025-12-03 12:53:44,126:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-12-03 12:53:53,291:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\joblib\externals\loky\backend\context.py:136: UserWarning: Could not find the number of physical cores for the following reason:
[WinError 2] El sistema no puede encontrar el archivo especificado
Returning the number of logical cores instead. You can silence this warning by setting LOKY_MAX_CPU_COUNT to the number of cores you want to use.

2025-12-03 12:53:53,296:WARNING:  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\joblib\externals\loky\backend\context.py", line 257, in _count_physical_cores
2025-12-03 12:53:53,298:WARNING:    cpu_info = subprocess.run(
2025-12-03 12:53:53,298:WARNING:  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\subprocess.py", line 503, in run
2025-12-03 12:53:53,298:WARNING:    with Popen(*popenargs, **kwargs) as process:
2025-12-03 12:53:53,298:WARNING:  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\subprocess.py", line 971, in __init__
2025-12-03 12:53:53,298:WARNING:    self._execute_child(args, executable, preexec_fn, close_fds,
2025-12-03 12:53:53,298:WARNING:  File "c:\Users\OMAR\miniconda3\envs\xgb_env\lib\subprocess.py", line 1456, in _execute_child
2025-12-03 12:53:53,298:WARNING:    hp, ht, pid, tid = _winapi.CreateProcess(executable, args,
2025-12-03 12:56:36,164:INFO:Calculating mean and std
2025-12-03 12:56:36,164:INFO:Creating metrics dataframe
2025-12-03 12:56:36,165:INFO:Finalizing model
2025-12-03 12:56:36,240:INFO:Warning: No categorical columns found. Calling 'transform' will only return input data.
2025-12-03 12:56:54,444:INFO:Uploading results into container
2025-12-03 12:56:54,445:INFO:Uploading model into container now
2025-12-03 12:56:54,445:INFO:_master_model_container: 1
2025-12-03 12:56:54,445:INFO:_display_container: 2
2025-12-03 12:56:54,446:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2025-12-03 12:56:54,446:INFO:create_model() successfully completed......................................
2025-12-03 12:56:54,634:INFO:Initializing tune_model()
2025-12-03 12:56:54,634:INFO:tune_model(estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...), fold=None, round=4, n_iter=5, custom_grid={'learning_rate': [0.01, 0.05, 0.1], 'n_estimators': [100, 200, 300], 'max_depth': [3, 4, 5, 6], 'scale_pos_weight': [38.153225806451616, 57.22983870967742], 'max_delta_step': [1, 2, 5], 'subsample': [0.7, 0.8, 0.9], 'colsample_bytree': [0.7, 0.8, 0.9]}, optimize=Recall, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A6529B2620>)
2025-12-03 12:56:54,634:INFO:Checking exceptions
2025-12-03 12:56:54,665:INFO:Copying training dataset
2025-12-03 12:56:54,682:INFO:Checking base model
2025-12-03 12:56:54,682:INFO:Base model : Extreme Gradient Boosting
2025-12-03 12:56:54,686:INFO:Declaring metric variables
2025-12-03 12:56:54,688:INFO:Defining Hyperparameters
2025-12-03 12:56:54,882:INFO:custom_grid: {'actual_estimator__learning_rate': [0.01, 0.05, 0.1], 'actual_estimator__n_estimators': [100, 200, 300], 'actual_estimator__max_depth': [3, 4, 5, 6], 'actual_estimator__scale_pos_weight': [38.153225806451616, 57.22983870967742], 'actual_estimator__max_delta_step': [1, 2, 5], 'actual_estimator__subsample': [0.7, 0.8, 0.9], 'actual_estimator__colsample_bytree': [0.7, 0.8, 0.9]}
2025-12-03 12:56:54,882:INFO:Tuning with n_jobs=1
2025-12-03 12:56:54,882:INFO:Initializing RandomizedSearchCV
2025-12-03 13:11:38,191:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-12-03 13:11:38,191:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-12-03 13:11:38,191:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-12-03 13:11:38,191:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-12-03 13:11:39,936:INFO:PyCaret ClassificationExperiment
2025-12-03 13:11:39,936:INFO:Logging name: clf-default-name
2025-12-03 13:11:39,936:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-12-03 13:11:39,936:INFO:version 3.3.2
2025-12-03 13:11:39,936:INFO:Initializing setup()
2025-12-03 13:11:39,937:INFO:self.USI: 5af7
2025-12-03 13:11:39,937:INFO:self._variable_keys: {'X_train', 'X', 'exp_id', 'USI', 'gpu_n_jobs_param', 'n_jobs_param', 'gpu_param', 'fold_groups_param', '_available_plots', '_ml_usecase', 'y', 'y_test', 'seed', 'exp_name_log', 'logging_param', 'fold_generator', 'is_multiclass', 'pipeline', 'log_plots_param', 'html_param', 'y_train', 'target_param', 'X_test', 'idx', 'fix_imbalance', 'memory', 'fold_shuffle_param', 'data'}
2025-12-03 13:11:39,937:INFO:Checking environment
2025-12-03 13:11:39,937:INFO:python_version: 3.10.19
2025-12-03 13:11:39,937:INFO:python_build: ('main', 'Oct 21 2025 16:41:31')
2025-12-03 13:11:39,937:INFO:machine: AMD64
2025-12-03 13:11:39,937:INFO:platform: Windows-10-10.0.26100-SP0
2025-12-03 13:11:39,937:INFO:Memory: svmem(total=16282144768, available=4468416512, percent=72.6, used=11813728256, free=4468416512)
2025-12-03 13:11:39,937:INFO:Physical Core: 6
2025-12-03 13:11:39,937:INFO:Logical Core: 12
2025-12-03 13:11:39,937:INFO:Checking libraries
2025-12-03 13:11:39,937:INFO:System:
2025-12-03 13:11:39,937:INFO:    python: 3.10.19 | packaged by Anaconda, Inc. | (main, Oct 21 2025, 16:41:31) [MSC v.1929 64 bit (AMD64)]
2025-12-03 13:11:39,937:INFO:executable: c:\Users\OMAR\miniconda3\envs\xgb_env\python.exe
2025-12-03 13:11:39,937:INFO:   machine: Windows-10-10.0.26100-SP0
2025-12-03 13:11:39,937:INFO:PyCaret required dependencies:
2025-12-03 13:11:39,938:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-03 13:11:40,479:INFO:                 pip: 25.3
2025-12-03 13:11:40,479:INFO:          setuptools: 80.9.0
2025-12-03 13:11:40,479:INFO:             pycaret: 3.3.2
2025-12-03 13:11:40,479:INFO:             IPython: 8.37.0
2025-12-03 13:11:40,479:INFO:          ipywidgets: 8.1.8
2025-12-03 13:11:40,479:INFO:                tqdm: 4.67.1
2025-12-03 13:11:40,479:INFO:               numpy: 1.26.4
2025-12-03 13:11:40,479:INFO:              pandas: 2.1.4
2025-12-03 13:11:40,479:INFO:              jinja2: 3.1.6
2025-12-03 13:11:40,479:INFO:               scipy: 1.11.4
2025-12-03 13:11:40,479:INFO:              joblib: 1.3.2
2025-12-03 13:11:40,479:INFO:             sklearn: 1.4.2
2025-12-03 13:11:40,479:INFO:                pyod: 2.0.5
2025-12-03 13:11:40,479:INFO:            imblearn: 0.14.0
2025-12-03 13:11:40,479:INFO:   category_encoders: 2.7.0
2025-12-03 13:11:40,479:INFO:            lightgbm: 4.6.0
2025-12-03 13:11:40,479:INFO:               numba: 0.62.1
2025-12-03 13:11:40,479:INFO:            requests: 2.32.5
2025-12-03 13:11:40,479:INFO:          matplotlib: 3.7.5
2025-12-03 13:11:40,479:INFO:          scikitplot: 0.3.7
2025-12-03 13:11:40,479:INFO:         yellowbrick: 1.5
2025-12-03 13:11:40,479:INFO:              plotly: 5.24.1
2025-12-03 13:11:40,479:INFO:    plotly-resampler: Not installed
2025-12-03 13:11:40,479:INFO:             kaleido: 1.2.0
2025-12-03 13:11:40,479:INFO:           schemdraw: 0.15
2025-12-03 13:11:40,479:INFO:         statsmodels: 0.14.5
2025-12-03 13:11:40,479:INFO:              sktime: 0.26.0
2025-12-03 13:11:40,479:INFO:               tbats: 1.1.3
2025-12-03 13:11:40,479:INFO:            pmdarima: 2.0.4
2025-12-03 13:11:40,479:INFO:              psutil: 7.1.3
2025-12-03 13:11:40,479:INFO:          markupsafe: 3.0.3
2025-12-03 13:11:40,479:INFO:             pickle5: Not installed
2025-12-03 13:11:40,479:INFO:         cloudpickle: 3.1.2
2025-12-03 13:11:40,479:INFO:         deprecation: 2.1.0
2025-12-03 13:11:40,479:INFO:              xxhash: 3.6.0
2025-12-03 13:11:40,479:INFO:           wurlitzer: Not installed
2025-12-03 13:11:40,479:INFO:PyCaret optional dependencies:
2025-12-03 13:11:43,167:INFO:                shap: 0.49.1
2025-12-03 13:11:43,167:INFO:           interpret: 0.7.3
2025-12-03 13:11:43,167:INFO:                umap: 0.5.7
2025-12-03 13:11:43,167:INFO:     ydata_profiling: 4.18.0
2025-12-03 13:11:43,167:INFO:  explainerdashboard: 0.5.1
2025-12-03 13:11:43,167:INFO:             autoviz: Not installed
2025-12-03 13:11:43,167:INFO:           fairlearn: 0.7.0
2025-12-03 13:11:43,167:INFO:          deepchecks: Not installed
2025-12-03 13:11:43,167:INFO:             xgboost: 2.1.3
2025-12-03 13:11:43,167:INFO:            catboost: 1.2.8
2025-12-03 13:11:43,167:INFO:              kmodes: 0.12.2
2025-12-03 13:11:43,167:INFO:             mlxtend: 0.23.4
2025-12-03 13:11:43,167:INFO:       statsforecast: 1.5.0
2025-12-03 13:11:43,167:INFO:        tune_sklearn: Not installed
2025-12-03 13:11:43,167:INFO:                 ray: Not installed
2025-12-03 13:11:43,167:INFO:            hyperopt: 0.2.7
2025-12-03 13:11:43,167:INFO:              optuna: 4.6.0
2025-12-03 13:11:43,167:INFO:               skopt: 0.10.2
2025-12-03 13:11:43,167:INFO:              mlflow: 3.6.0
2025-12-03 13:11:43,167:INFO:              gradio: 6.0.1
2025-12-03 13:11:43,167:INFO:             fastapi: 0.123.0
2025-12-03 13:11:43,167:INFO:             uvicorn: 0.38.0
2025-12-03 13:11:43,167:INFO:              m2cgen: 0.10.0
2025-12-03 13:11:43,167:INFO:           evidently: 0.4.40
2025-12-03 13:11:43,167:INFO:               fugue: 0.8.7
2025-12-03 13:11:43,167:INFO:           streamlit: 1.51.0
2025-12-03 13:11:43,167:INFO:             prophet: Not installed
2025-12-03 13:11:43,167:INFO:None
2025-12-03 13:11:43,167:INFO:Set up data.
2025-12-03 13:11:43,182:INFO:Set up folding strategy.
2025-12-03 13:11:43,182:INFO:Set up train/test split.
2025-12-03 13:11:43,207:INFO:Set up index.
2025-12-03 13:11:43,209:INFO:Assigning column types.
2025-12-03 13:11:43,231:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-12-03 13:11:43,257:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-12-03 13:11:43,259:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-03 13:11:43,280:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-03 13:11:43,281:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-03 13:11:43,328:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-12-03 13:11:43,328:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-03 13:11:43,344:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-03 13:11:43,346:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-03 13:11:43,346:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-12-03 13:11:43,374:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-03 13:11:43,391:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-03 13:11:43,393:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-03 13:11:43,420:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-03 13:11:43,438:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-03 13:11:43,439:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-03 13:11:43,439:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-12-03 13:11:43,483:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-03 13:11:43,483:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-03 13:11:43,526:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-03 13:11:43,529:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-03 13:11:43,529:INFO:Preparing preprocessing pipeline...
2025-12-03 13:11:43,533:INFO:Set up simple imputation.
2025-12-03 13:11:43,546:INFO:Set up encoding of ordinal features.
2025-12-03 13:11:43,553:INFO:Set up encoding of categorical features.
2025-12-03 13:11:43,553:INFO:Set up removing multicollinearity.
2025-12-03 13:11:43,553:INFO:Set up imbalanced handling.
2025-12-03 13:11:43,553:INFO:Set up feature normalization.
2025-12-03 13:11:43,744:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\joblib\externals\loky\backend\context.py:136: UserWarning: Could not find the number of physical cores for the following reason:
[WinError 2] El sistema no puede encontrar el archivo especificado
Returning the number of logical cores instead. You can silence this warning by setting LOKY_MAX_CPU_COUNT to the number of cores you want to use.

2025-12-03 13:11:43,867:INFO:Finished creating preprocessing pipeline.
2025-12-03 13:11:43,886:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\OMAR\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'IncomeRatio', 'SystolicBP',
                                             'BMI', 'WaistCircumference',
                                             'Height', 'TotalCholesterol',
                                             'Triglycerides', 'LDL', 'HDL',
                                             'HbA1c', 'Glucose', 'Creatinine',
                                             'UricAcid', 'ALT_Enzyme',
                                             'Albumin', 'Potassium', 'Sodium',
                                             'G...
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              random_state=42,
                                                                              sampling_strategy='auto')))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=RobustScaler(copy=True,
                                                             quantile_range=(25.0,
                                                                             75.0),
                                                             unit_variance=False,
                                                             with_centering=True,
                                                             with_scaling=True)))],
         verbose=False)
2025-12-03 13:11:43,887:INFO:Creating final display dataframe.
2025-12-03 13:11:44,334:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target      HeartDisease
2                   Target type            Binary
3           Original data shape       (43695, 28)
4        Transformed data shape       (72719, 31)
5   Transformed train set shape       (59610, 31)
6    Transformed test set shape       (13109, 31)
7              Numeric features                20
8          Categorical features                 7
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15     Remove multicollinearity              True
16  Multicollinearity threshold               0.9
17                Fix imbalance              True
18         Fix imbalance method             SMOTE
19                    Normalize              True
20             Normalize method            robust
21               Fold Generator   StratifiedKFold
22                  Fold Number                10
23                     CPU Jobs                 1
24                      Use GPU             False
25               Log Experiment             False
26              Experiment Name  clf-default-name
27                          USI              5af7
2025-12-03 13:11:44,387:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-03 13:11:44,388:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-03 13:11:44,441:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-03 13:11:44,444:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-03 13:11:44,445:INFO:setup() successfully completed in 4.52s...............
2025-12-03 13:11:44,536:INFO:Initializing create_model()
2025-12-03 13:11:44,537:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027D049C2380>, estimator=xgboost, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-03 13:11:44,537:INFO:Checking exceptions
2025-12-03 13:11:44,537:INFO:Importing libraries
2025-12-03 13:11:44,537:INFO:Copying training dataset
2025-12-03 13:11:44,570:INFO:Defining folds
2025-12-03 13:11:44,570:INFO:Declaring metric variables
2025-12-03 13:11:44,570:INFO:Importing untrained model
2025-12-03 13:11:44,571:INFO:Extreme Gradient Boosting Imported successfully
2025-12-03 13:11:44,571:INFO:Starting cross validation
2025-12-03 13:11:44,573:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-12-03 13:11:55,176:INFO:Calculating mean and std
2025-12-03 13:11:55,176:INFO:Creating metrics dataframe
2025-12-03 13:11:55,178:INFO:Finalizing model
2025-12-03 13:11:55,248:INFO:Warning: No categorical columns found. Calling 'transform' will only return input data.
2025-12-03 13:11:56,259:INFO:Uploading results into container
2025-12-03 13:11:56,259:INFO:Uploading model into container now
2025-12-03 13:11:56,260:INFO:_master_model_container: 1
2025-12-03 13:11:56,260:INFO:_display_container: 2
2025-12-03 13:11:56,260:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2025-12-03 13:11:56,260:INFO:create_model() successfully completed......................................
2025-12-03 13:11:56,432:INFO:Initializing tune_model()
2025-12-03 13:11:56,432:INFO:tune_model(estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...), fold=None, round=4, n_iter=10, custom_grid={'learning_rate': [0.05, 0.1], 'n_estimators': [100, 200], 'max_depth': [3, 5], 'scale_pos_weight': [38.153225806451616, 57.22983870967742], 'max_delta_step': [1]}, optimize=Recall, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027D049C2380>)
2025-12-03 13:11:56,432:INFO:Checking exceptions
2025-12-03 13:11:56,461:INFO:Copying training dataset
2025-12-03 13:11:56,479:INFO:Checking base model
2025-12-03 13:11:56,479:INFO:Base model : Extreme Gradient Boosting
2025-12-03 13:11:56,485:INFO:Declaring metric variables
2025-12-03 13:11:56,488:INFO:Defining Hyperparameters
2025-12-03 13:11:56,674:INFO:custom_grid: {'actual_estimator__learning_rate': [0.05, 0.1], 'actual_estimator__n_estimators': [100, 200], 'actual_estimator__max_depth': [3, 5], 'actual_estimator__scale_pos_weight': [38.153225806451616, 57.22983870967742], 'actual_estimator__max_delta_step': [1]}
2025-12-03 13:11:56,675:INFO:Tuning with n_jobs=1
2025-12-03 13:11:56,675:INFO:Initializing RandomizedSearchCV
2025-12-03 13:12:29,735:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-12-03 13:12:29,735:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-12-03 13:12:29,735:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-12-03 13:12:29,735:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-12-03 13:12:31,430:INFO:PyCaret ClassificationExperiment
2025-12-03 13:12:31,430:INFO:Logging name: clf-default-name
2025-12-03 13:12:31,430:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-12-03 13:12:31,430:INFO:version 3.3.2
2025-12-03 13:12:31,430:INFO:Initializing setup()
2025-12-03 13:12:31,430:INFO:self.USI: 0379
2025-12-03 13:12:31,430:INFO:self._variable_keys: {'fold_groups_param', 'gpu_param', 'n_jobs_param', 'exp_id', '_available_plots', 'USI', 'X', '_ml_usecase', 'seed', 'memory', 'X_train', 'y_test', 'log_plots_param', 'target_param', 'y', 'gpu_n_jobs_param', 'pipeline', 'X_test', 'idx', 'exp_name_log', 'fix_imbalance', 'fold_generator', 'logging_param', 'is_multiclass', 'data', 'fold_shuffle_param', 'html_param', 'y_train'}
2025-12-03 13:12:31,430:INFO:Checking environment
2025-12-03 13:12:31,430:INFO:python_version: 3.10.19
2025-12-03 13:12:31,430:INFO:python_build: ('main', 'Oct 21 2025 16:41:31')
2025-12-03 13:12:31,430:INFO:machine: AMD64
2025-12-03 13:12:31,430:INFO:platform: Windows-10-10.0.26100-SP0
2025-12-03 13:12:31,430:INFO:Memory: svmem(total=16282144768, available=4691587072, percent=71.2, used=11590557696, free=4691587072)
2025-12-03 13:12:31,430:INFO:Physical Core: 6
2025-12-03 13:12:31,430:INFO:Logical Core: 12
2025-12-03 13:12:31,430:INFO:Checking libraries
2025-12-03 13:12:31,430:INFO:System:
2025-12-03 13:12:31,431:INFO:    python: 3.10.19 | packaged by Anaconda, Inc. | (main, Oct 21 2025, 16:41:31) [MSC v.1929 64 bit (AMD64)]
2025-12-03 13:12:31,431:INFO:executable: c:\Users\OMAR\miniconda3\envs\xgb_env\python.exe
2025-12-03 13:12:31,431:INFO:   machine: Windows-10-10.0.26100-SP0
2025-12-03 13:12:31,431:INFO:PyCaret required dependencies:
2025-12-03 13:12:31,431:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-03 13:12:31,965:INFO:                 pip: 25.3
2025-12-03 13:12:31,965:INFO:          setuptools: 80.9.0
2025-12-03 13:12:31,966:INFO:             pycaret: 3.3.2
2025-12-03 13:12:31,966:INFO:             IPython: 8.37.0
2025-12-03 13:12:31,966:INFO:          ipywidgets: 8.1.8
2025-12-03 13:12:31,966:INFO:                tqdm: 4.67.1
2025-12-03 13:12:31,966:INFO:               numpy: 1.26.4
2025-12-03 13:12:31,966:INFO:              pandas: 2.1.4
2025-12-03 13:12:31,966:INFO:              jinja2: 3.1.6
2025-12-03 13:12:31,966:INFO:               scipy: 1.11.4
2025-12-03 13:12:31,966:INFO:              joblib: 1.3.2
2025-12-03 13:12:31,966:INFO:             sklearn: 1.4.2
2025-12-03 13:12:31,966:INFO:                pyod: 2.0.5
2025-12-03 13:12:31,966:INFO:            imblearn: 0.14.0
2025-12-03 13:12:31,966:INFO:   category_encoders: 2.7.0
2025-12-03 13:12:31,966:INFO:            lightgbm: 4.6.0
2025-12-03 13:12:31,966:INFO:               numba: 0.62.1
2025-12-03 13:12:31,966:INFO:            requests: 2.32.5
2025-12-03 13:12:31,966:INFO:          matplotlib: 3.7.5
2025-12-03 13:12:31,966:INFO:          scikitplot: 0.3.7
2025-12-03 13:12:31,966:INFO:         yellowbrick: 1.5
2025-12-03 13:12:31,966:INFO:              plotly: 5.24.1
2025-12-03 13:12:31,966:INFO:    plotly-resampler: Not installed
2025-12-03 13:12:31,966:INFO:             kaleido: 1.2.0
2025-12-03 13:12:31,966:INFO:           schemdraw: 0.15
2025-12-03 13:12:31,966:INFO:         statsmodels: 0.14.5
2025-12-03 13:12:31,966:INFO:              sktime: 0.26.0
2025-12-03 13:12:31,966:INFO:               tbats: 1.1.3
2025-12-03 13:12:31,966:INFO:            pmdarima: 2.0.4
2025-12-03 13:12:31,966:INFO:              psutil: 7.1.3
2025-12-03 13:12:31,966:INFO:          markupsafe: 3.0.3
2025-12-03 13:12:31,966:INFO:             pickle5: Not installed
2025-12-03 13:12:31,966:INFO:         cloudpickle: 3.1.2
2025-12-03 13:12:31,966:INFO:         deprecation: 2.1.0
2025-12-03 13:12:31,966:INFO:              xxhash: 3.6.0
2025-12-03 13:12:31,966:INFO:           wurlitzer: Not installed
2025-12-03 13:12:31,966:INFO:PyCaret optional dependencies:
2025-12-03 13:12:34,636:INFO:                shap: 0.49.1
2025-12-03 13:12:34,637:INFO:           interpret: 0.7.3
2025-12-03 13:12:34,637:INFO:                umap: 0.5.7
2025-12-03 13:12:34,637:INFO:     ydata_profiling: 4.18.0
2025-12-03 13:12:34,637:INFO:  explainerdashboard: 0.5.1
2025-12-03 13:12:34,637:INFO:             autoviz: Not installed
2025-12-03 13:12:34,637:INFO:           fairlearn: 0.7.0
2025-12-03 13:12:34,637:INFO:          deepchecks: Not installed
2025-12-03 13:12:34,637:INFO:             xgboost: 2.1.3
2025-12-03 13:12:34,637:INFO:            catboost: 1.2.8
2025-12-03 13:12:34,637:INFO:              kmodes: 0.12.2
2025-12-03 13:12:34,637:INFO:             mlxtend: 0.23.4
2025-12-03 13:12:34,637:INFO:       statsforecast: 1.5.0
2025-12-03 13:12:34,637:INFO:        tune_sklearn: Not installed
2025-12-03 13:12:34,637:INFO:                 ray: Not installed
2025-12-03 13:12:34,637:INFO:            hyperopt: 0.2.7
2025-12-03 13:12:34,637:INFO:              optuna: 4.6.0
2025-12-03 13:12:34,637:INFO:               skopt: 0.10.2
2025-12-03 13:12:34,637:INFO:              mlflow: 3.6.0
2025-12-03 13:12:34,637:INFO:              gradio: 6.0.1
2025-12-03 13:12:34,637:INFO:             fastapi: 0.123.0
2025-12-03 13:12:34,637:INFO:             uvicorn: 0.38.0
2025-12-03 13:12:34,637:INFO:              m2cgen: 0.10.0
2025-12-03 13:12:34,637:INFO:           evidently: 0.4.40
2025-12-03 13:12:34,637:INFO:               fugue: 0.8.7
2025-12-03 13:12:34,637:INFO:           streamlit: 1.51.0
2025-12-03 13:12:34,637:INFO:             prophet: Not installed
2025-12-03 13:12:34,637:INFO:None
2025-12-03 13:12:34,637:INFO:Set up data.
2025-12-03 13:12:34,647:INFO:Set up folding strategy.
2025-12-03 13:12:34,647:INFO:Set up train/test split.
2025-12-03 13:12:34,678:INFO:Set up index.
2025-12-03 13:12:34,680:INFO:Assigning column types.
2025-12-03 13:12:34,699:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-12-03 13:12:34,729:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-12-03 13:12:34,729:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-03 13:12:34,756:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-03 13:12:34,757:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-03 13:12:34,803:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-12-03 13:12:34,804:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-03 13:12:34,820:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-03 13:12:34,822:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-03 13:12:34,822:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-12-03 13:12:34,846:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-03 13:12:34,863:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-03 13:12:34,865:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-03 13:12:34,894:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-03 13:12:34,909:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-03 13:12:34,912:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-03 13:12:34,913:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-12-03 13:12:34,956:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-03 13:12:34,957:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-03 13:12:34,997:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-03 13:12:35,006:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-03 13:12:35,009:INFO:Preparing preprocessing pipeline...
2025-12-03 13:12:35,014:INFO:Set up simple imputation.
2025-12-03 13:12:35,025:INFO:Set up encoding of ordinal features.
2025-12-03 13:12:35,034:INFO:Set up encoding of categorical features.
2025-12-03 13:12:35,034:INFO:Set up removing multicollinearity.
2025-12-03 13:12:35,034:INFO:Set up imbalanced handling.
2025-12-03 13:12:35,034:INFO:Set up feature normalization.
2025-12-03 13:12:35,249:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\joblib\externals\loky\backend\context.py:136: UserWarning: Could not find the number of physical cores for the following reason:
[WinError 2] El sistema no puede encontrar el archivo especificado
Returning the number of logical cores instead. You can silence this warning by setting LOKY_MAX_CPU_COUNT to the number of cores you want to use.

2025-12-03 13:12:35,370:INFO:Finished creating preprocessing pipeline.
2025-12-03 13:12:35,388:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\OMAR\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'IncomeRatio', 'SystolicBP',
                                             'BMI', 'WaistCircumference',
                                             'Height', 'TotalCholesterol',
                                             'Triglycerides', 'LDL', 'HDL',
                                             'HbA1c', 'Glucose', 'Creatinine',
                                             'UricAcid', 'ALT_Enzyme',
                                             'Albumin', 'Potassium', 'Sodium',
                                             'G...
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              random_state=42,
                                                                              sampling_strategy='auto')))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=RobustScaler(copy=True,
                                                             quantile_range=(25.0,
                                                                             75.0),
                                                             unit_variance=False,
                                                             with_centering=True,
                                                             with_scaling=True)))],
         verbose=False)
2025-12-03 13:12:35,388:INFO:Creating final display dataframe.
2025-12-03 13:12:35,638:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target      HeartDisease
2                   Target type            Binary
3           Original data shape       (43695, 28)
4        Transformed data shape       (72719, 31)
5   Transformed train set shape       (59610, 31)
6    Transformed test set shape       (13109, 31)
7              Numeric features                20
8          Categorical features                 7
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15     Remove multicollinearity              True
16  Multicollinearity threshold               0.9
17                Fix imbalance              True
18         Fix imbalance method             SMOTE
19                    Normalize              True
20             Normalize method            robust
21               Fold Generator   StratifiedKFold
22                  Fold Number                10
23                     CPU Jobs                 1
24                      Use GPU             False
25               Log Experiment             False
26              Experiment Name  clf-default-name
27                          USI              0379
2025-12-03 13:12:35,687:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-03 13:12:35,690:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-03 13:12:35,733:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-03 13:12:35,735:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-03 13:12:35,737:INFO:setup() successfully completed in 4.32s...............
2025-12-03 13:12:35,801:INFO:Initializing create_model()
2025-12-03 13:12:35,802:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028B5BCF25F0>, estimator=xgboost, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-03 13:12:35,802:INFO:Checking exceptions
2025-12-03 13:12:35,803:INFO:Importing libraries
2025-12-03 13:12:35,803:INFO:Copying training dataset
2025-12-03 13:12:35,832:INFO:Defining folds
2025-12-03 13:12:35,832:INFO:Declaring metric variables
2025-12-03 13:12:35,832:INFO:Importing untrained model
2025-12-03 13:12:35,832:INFO:Extreme Gradient Boosting Imported successfully
2025-12-03 13:12:35,832:INFO:Starting cross validation
2025-12-03 13:12:35,832:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-12-03 13:12:46,396:INFO:Calculating mean and std
2025-12-03 13:12:46,396:INFO:Creating metrics dataframe
2025-12-03 13:12:46,396:INFO:Finalizing model
2025-12-03 13:12:46,474:INFO:Warning: No categorical columns found. Calling 'transform' will only return input data.
2025-12-03 13:12:47,501:INFO:Uploading results into container
2025-12-03 13:12:47,502:INFO:Uploading model into container now
2025-12-03 13:12:47,502:INFO:_master_model_container: 1
2025-12-03 13:12:47,503:INFO:_display_container: 2
2025-12-03 13:12:47,503:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2025-12-03 13:12:47,503:INFO:create_model() successfully completed......................................
2025-12-03 13:12:47,679:INFO:Initializing tune_model()
2025-12-03 13:12:47,679:INFO:tune_model(estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...), fold=None, round=4, n_iter=2, custom_grid={'learning_rate': [0.05, 0.1], 'n_estimators': [100, 200], 'max_depth': [3, 5], 'scale_pos_weight': [38.153225806451616, 57.22983870967742], 'max_delta_step': [1]}, optimize=Recall, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028B5BCF25F0>)
2025-12-03 13:12:47,679:INFO:Checking exceptions
2025-12-03 13:12:47,711:INFO:Copying training dataset
2025-12-03 13:12:47,732:INFO:Checking base model
2025-12-03 13:12:47,734:INFO:Base model : Extreme Gradient Boosting
2025-12-03 13:12:47,736:INFO:Declaring metric variables
2025-12-03 13:12:47,739:INFO:Defining Hyperparameters
2025-12-03 13:12:47,922:INFO:custom_grid: {'actual_estimator__learning_rate': [0.05, 0.1], 'actual_estimator__n_estimators': [100, 200], 'actual_estimator__max_depth': [3, 5], 'actual_estimator__scale_pos_weight': [38.153225806451616, 57.22983870967742], 'actual_estimator__max_delta_step': [1]}
2025-12-03 13:12:47,922:INFO:Tuning with n_jobs=1
2025-12-03 13:12:47,922:INFO:Initializing RandomizedSearchCV
2025-12-03 13:13:11,839:INFO:best_params: {'actual_estimator__scale_pos_weight': 57.22983870967742, 'actual_estimator__n_estimators': 200, 'actual_estimator__max_depth': 3, 'actual_estimator__max_delta_step': 1, 'actual_estimator__learning_rate': 0.05}
2025-12-03 13:13:11,841:INFO:Hyperparameter search completed
2025-12-03 13:13:11,841:INFO:SubProcess create_model() called ==================================
2025-12-03 13:13:11,842:INFO:Initializing create_model()
2025-12-03 13:13:11,842:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028B5BCF25F0>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000028B63ECFE20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'scale_pos_weight': 57.22983870967742, 'n_estimators': 200, 'max_depth': 3, 'max_delta_step': 1, 'learning_rate': 0.05})
2025-12-03 13:13:11,842:INFO:Checking exceptions
2025-12-03 13:13:11,843:INFO:Importing libraries
2025-12-03 13:13:11,843:INFO:Copying training dataset
2025-12-03 13:13:11,867:INFO:Defining folds
2025-12-03 13:13:11,867:INFO:Declaring metric variables
2025-12-03 13:13:11,869:INFO:Importing untrained model
2025-12-03 13:13:11,869:INFO:Declaring custom model
2025-12-03 13:13:11,872:INFO:Extreme Gradient Boosting Imported successfully
2025-12-03 13:13:11,879:INFO:Starting cross validation
2025-12-03 13:13:11,881:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-12-03 13:13:21,869:INFO:Calculating mean and std
2025-12-03 13:13:21,872:INFO:Creating metrics dataframe
2025-12-03 13:13:21,875:INFO:Finalizing model
2025-12-03 13:13:21,948:INFO:Warning: No categorical columns found. Calling 'transform' will only return input data.
2025-12-03 13:13:22,949:INFO:Uploading results into container
2025-12-03 13:13:22,950:INFO:Uploading model into container now
2025-12-03 13:13:22,950:INFO:_master_model_container: 2
2025-12-03 13:13:22,950:INFO:_display_container: 3
2025-12-03 13:13:22,950:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=0.05, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None, max_delta_step=1,
              max_depth=3, max_leaves=None, min_child_weight=None, missing=nan,
              monotone_constraints=None, multi_strategy=None, n_estimators=200,
              n_jobs=1, num_parallel_tree=None, objective='binary:logistic', ...)
2025-12-03 13:13:22,950:INFO:create_model() successfully completed......................................
2025-12-03 13:13:23,146:INFO:SubProcess create_model() end ==================================
2025-12-03 13:13:23,146:INFO:choose_better activated
2025-12-03 13:13:23,150:INFO:SubProcess create_model() called ==================================
2025-12-03 13:13:23,150:INFO:Initializing create_model()
2025-12-03 13:13:23,150:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028B5BCF25F0>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-03 13:13:23,150:INFO:Checking exceptions
2025-12-03 13:13:23,150:INFO:Importing libraries
2025-12-03 13:13:23,150:INFO:Copying training dataset
2025-12-03 13:13:23,175:INFO:Defining folds
2025-12-03 13:13:23,176:INFO:Declaring metric variables
2025-12-03 13:13:23,176:INFO:Importing untrained model
2025-12-03 13:13:23,176:INFO:Declaring custom model
2025-12-03 13:13:23,176:INFO:Extreme Gradient Boosting Imported successfully
2025-12-03 13:13:23,177:INFO:Starting cross validation
2025-12-03 13:13:23,177:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-12-03 13:13:33,796:INFO:Calculating mean and std
2025-12-03 13:13:33,796:INFO:Creating metrics dataframe
2025-12-03 13:13:33,796:INFO:Finalizing model
2025-12-03 13:13:33,871:INFO:Warning: No categorical columns found. Calling 'transform' will only return input data.
2025-12-03 13:13:34,906:INFO:Uploading results into container
2025-12-03 13:13:34,907:INFO:Uploading model into container now
2025-12-03 13:13:34,907:INFO:_master_model_container: 3
2025-12-03 13:13:34,907:INFO:_display_container: 4
2025-12-03 13:13:34,908:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2025-12-03 13:13:34,908:INFO:create_model() successfully completed......................................
2025-12-03 13:13:35,086:INFO:SubProcess create_model() end ==================================
2025-12-03 13:13:35,087:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...) result for Recall is 0.1344
2025-12-03 13:13:35,087:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=0.05, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None, max_delta_step=1,
              max_depth=3, max_leaves=None, min_child_weight=None, missing=nan,
              monotone_constraints=None, multi_strategy=None, n_estimators=200,
              n_jobs=1, num_parallel_tree=None, objective='binary:logistic', ...) result for Recall is 0.9603
2025-12-03 13:13:35,087:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=0.05, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None, max_delta_step=1,
              max_depth=3, max_leaves=None, min_child_weight=None, missing=nan,
              monotone_constraints=None, multi_strategy=None, n_estimators=200,
              n_jobs=1, num_parallel_tree=None, objective='binary:logistic', ...) is best model
2025-12-03 13:13:35,087:INFO:choose_better completed
2025-12-03 13:13:35,096:INFO:_master_model_container: 3
2025-12-03 13:13:35,096:INFO:_display_container: 3
2025-12-03 13:13:35,096:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=0.05, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None, max_delta_step=1,
              max_depth=3, max_leaves=None, min_child_weight=None, missing=nan,
              monotone_constraints=None, multi_strategy=None, n_estimators=200,
              n_jobs=1, num_parallel_tree=None, objective='binary:logistic', ...)
2025-12-03 13:13:35,096:INFO:tune_model() successfully completed......................................
2025-12-03 13:13:35,273:INFO:Initializing calibrate_model()
2025-12-03 13:13:35,273:INFO:calibrate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028B5BCF25F0>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=0.05, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None, max_delta_step=1,
              max_depth=3, max_leaves=None, min_child_weight=None, missing=nan,
              monotone_constraints=None, multi_strategy=None, n_estimators=200,
              n_jobs=1, num_parallel_tree=None, objective='binary:logistic', ...), method=isotonic, calibrate_fold=5, fold=None, round=4, fit_kwargs=None, groups=None, verbose=True, return_train_score=False)
2025-12-03 13:13:35,275:INFO:Checking exceptions
2025-12-03 13:13:35,286:INFO:Preloading libraries
2025-12-03 13:13:35,287:INFO:Preparing display monitor
2025-12-03 13:13:35,296:INFO:Getting model name
2025-12-03 13:13:35,296:INFO:Base model : Extreme Gradient Boosting
2025-12-03 13:13:35,304:INFO:Importing untrained CalibratedClassifierCV
2025-12-03 13:13:35,304:INFO:SubProcess create_model() called ==================================
2025-12-03 13:13:35,306:INFO:Initializing create_model()
2025-12-03 13:13:35,306:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028B5BCF25F0>, estimator=CalibratedClassifierCV(cv=5, ensemble=True,
                       estimator=XGBClassifier(base_score=None,
                                               booster='gbtree', callbacks=None,
                                               colsample_bylevel=None,
                                               colsample_bynode=None,
                                               colsample_bytree=None,
                                               device='cpu',
                                               early_stopping_rounds=None,
                                               enable_categorical=False,
                                               eval_metric=None,
                                               feature_types=None, gamma=None,
                                               grow_policy=None,
                                               importance_type=None,
                                               interaction_constraints=None,
                                               learning_rate=0.05, max_bin=None,
                                               max_cat_threshold=None,
                                               max_cat_to_onehot=None,
                                               max_delta_step=1, max_depth=3,
                                               max_leaves=None,
                                               min_child_weight=None,
                                               missing=nan,
                                               monotone_constraints=None,
                                               multi_strategy=None,
                                               n_estimators=200, n_jobs=1,
                                               num_parallel_tree=None,
                                               objective='binary:logistic', ...),
                       method='isotonic', n_jobs=None), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000028B63F069E0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-03 13:13:35,306:INFO:Checking exceptions
2025-12-03 13:13:35,306:INFO:Importing libraries
2025-12-03 13:13:35,306:INFO:Copying training dataset
2025-12-03 13:13:35,332:INFO:Defining folds
2025-12-03 13:13:35,332:INFO:Declaring metric variables
2025-12-03 13:13:35,337:INFO:Importing untrained model
2025-12-03 13:13:35,337:INFO:Declaring custom model
2025-12-03 13:13:35,342:INFO:Extreme Gradient Boosting Imported successfully
2025-12-03 13:13:35,349:INFO:Starting cross validation
2025-12-03 13:13:35,350:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-12-03 13:14:10,099:INFO:Calculating mean and std
2025-12-03 13:14:10,104:INFO:Creating metrics dataframe
2025-12-03 13:14:10,107:INFO:Finalizing model
2025-12-03 13:14:10,187:INFO:Warning: No categorical columns found. Calling 'transform' will only return input data.
2025-12-03 13:14:13,869:INFO:Uploading results into container
2025-12-03 13:14:13,869:INFO:Uploading model into container now
2025-12-03 13:14:13,872:INFO:_master_model_container: 4
2025-12-03 13:14:13,872:INFO:_display_container: 4
2025-12-03 13:14:13,873:INFO:CalibratedClassifierCV(cv=5, ensemble=True,
                       estimator=XGBClassifier(base_score=None,
                                               booster='gbtree', callbacks=None,
                                               colsample_bylevel=None,
                                               colsample_bynode=None,
                                               colsample_bytree=None,
                                               device='cpu',
                                               early_stopping_rounds=None,
                                               enable_categorical=False,
                                               eval_metric=None,
                                               feature_types=None, gamma=None,
                                               grow_policy=None,
                                               importance_type=None,
                                               interaction_constraints=None,
                                               learning_rate=0.05, max_bin=None,
                                               max_cat_threshold=None,
                                               max_cat_to_onehot=None,
                                               max_delta_step=1, max_depth=3,
                                               max_leaves=None,
                                               min_child_weight=None,
                                               missing=nan,
                                               monotone_constraints=None,
                                               multi_strategy=None,
                                               n_estimators=200, n_jobs=1,
                                               num_parallel_tree=None,
                                               objective='binary:logistic', ...),
                       method='isotonic', n_jobs=None)
2025-12-03 13:14:13,873:INFO:create_model() successfully completed......................................
2025-12-03 13:14:14,036:INFO:SubProcess create_model() end ==================================
2025-12-03 13:14:14,049:INFO:_master_model_container: 4
2025-12-03 13:14:14,049:INFO:_display_container: 4
2025-12-03 13:14:14,050:INFO:CalibratedClassifierCV(cv=5, ensemble=True,
                       estimator=XGBClassifier(base_score=None,
                                               booster='gbtree', callbacks=None,
                                               colsample_bylevel=None,
                                               colsample_bynode=None,
                                               colsample_bytree=None,
                                               device='cpu',
                                               early_stopping_rounds=None,
                                               enable_categorical=False,
                                               eval_metric=None,
                                               feature_types=None, gamma=None,
                                               grow_policy=None,
                                               importance_type=None,
                                               interaction_constraints=None,
                                               learning_rate=0.05, max_bin=None,
                                               max_cat_threshold=None,
                                               max_cat_to_onehot=None,
                                               max_delta_step=1, max_depth=3,
                                               max_leaves=None,
                                               min_child_weight=None,
                                               missing=nan,
                                               monotone_constraints=None,
                                               multi_strategy=None,
                                               n_estimators=200, n_jobs=1,
                                               num_parallel_tree=None,
                                               objective='binary:logistic', ...),
                       method='isotonic', n_jobs=None)
2025-12-03 13:14:14,050:INFO:calibrate_model() successfully completed......................................
2025-12-03 13:14:14,254:INFO:Initializing plot_model()
2025-12-03 13:14:14,254:INFO:plot_model(plot=auc, fold=None, verbose=True, display=None, display_format=None, estimator=CalibratedClassifierCV(cv=5, ensemble=True,
                       estimator=XGBClassifier(base_score=None,
                                               booster='gbtree', callbacks=None,
                                               colsample_bylevel=None,
                                               colsample_bynode=None,
                                               colsample_bytree=None,
                                               device='cpu',
                                               early_stopping_rounds=None,
                                               enable_categorical=False,
                                               eval_metric=None,
                                               feature_types=None, gamma=None,
                                               grow_policy=None,
                                               importance_type=None,
                                               interaction_constraints=None,
                                               learning_rate=0.05, max_bin=None,
                                               max_cat_threshold=None,
                                               max_cat_to_onehot=None,
                                               max_delta_step=1, max_depth=3,
                                               max_leaves=None,
                                               min_child_weight=None,
                                               missing=nan,
                                               monotone_constraints=None,
                                               multi_strategy=None,
                                               n_estimators=200, n_jobs=1,
                                               num_parallel_tree=None,
                                               objective='binary:logistic', ...),
                       method='isotonic', n_jobs=None), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028B5BCF25F0>, system=True)
2025-12-03 13:14:14,254:INFO:Checking exceptions
2025-12-03 13:14:14,269:INFO:Preloading libraries
2025-12-03 13:14:14,297:INFO:Copying training dataset
2025-12-03 13:14:14,297:INFO:Plot type: auc
2025-12-03 13:14:14,525:INFO:Fitting Model
2025-12-03 13:14:14,528:INFO:Scoring test/hold-out set
2025-12-03 13:14:14,903:INFO:Visual Rendered Successfully
2025-12-03 13:14:15,066:INFO:plot_model() successfully completed......................................
2025-12-03 13:14:15,067:INFO:Initializing get_config()
2025-12-03 13:14:15,067:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028B5BCF25F0>, variable=X_test_transformed)
2025-12-03 13:14:15,171:INFO:Variable: X_test returned as             Age  IncomeRatio  SystolicBP  WaistCircumference    Height  \
28456 -1.166682    -0.347193   -0.857495           -1.507527 -1.819875   
8993   0.143689     0.336722    1.662729            0.648015 -0.645962   
34312  0.028744     0.094199    0.120503            0.346962  0.583851   
4802  -1.235649     0.337285   -0.681087           -0.938256 -0.976048   
25895  0.028744     1.529936   -0.456265           -0.413678  0.081658   
...         ...          ...         ...                 ...       ...   
18045 -1.258638    -0.075567   -0.904070           -1.993226 -3.285713   
5425  -0.086201     0.470887    1.712883           -0.086555 -0.006211   
12819  0.235645     0.002041    0.478158            0.708225  1.515528   
33659 -1.212660     1.326217   -0.863547           -1.487456 -2.074533   
19531 -1.281627    -0.395697   -0.849048           -1.848720 -3.664595   

       TotalCholesterol  Triglycerides       LDL       HDL     HbA1c  ...  \
28456         -0.077253      -0.647020 -0.018927  0.563922 -0.617463  ...   
8993           0.702398       0.630424  0.004953  0.590479  0.121825  ...   
34312         -0.118546       0.874313 -0.747277 -1.115404  0.666895  ...   
4802          -0.178619      -0.486105  0.000596  0.050858 -0.563915  ...   
25895          0.819676       1.267174  0.006537 -0.056580 -0.314232  ...   
...                 ...            ...       ...       ...       ...  ...   
18045         -0.319533      -0.646830 -0.614729  0.541608 -0.630163  ...   
5425           0.397476      -0.206569  0.807814  0.296361 -0.096204  ...   
12819         -0.681479      -0.646225 -0.152735 -0.821286  0.121825  ...   
33659         -0.986401      -0.647239 -2.064660  0.296361 -0.699939  ...   
19531         -0.334260      -0.646844 -0.652171  0.541702 -0.458463  ...   

       Race_5.0  Race_1.0  Race_4.0  Race_3.0  Race_2.0  Education   Smoking  \
28456       1.0       0.0  0.000000 -0.147343       0.0  -0.020637 -0.322757   
8993        0.0       0.0  3.165789 -0.147343       0.0   0.527633  0.677243   
34312       0.0       0.0  0.000000  0.852657       0.0  -0.653648 -0.322757   
4802        1.0       0.0  0.000000 -0.147343       0.0   0.249169 -0.249145   
25895       0.0       0.0  0.000000  0.852657       0.0   1.118273 -0.322757   
...         ...       ...       ...       ...       ...        ...       ...   
18045       0.0       0.0  0.000000  0.852657       0.0  -0.784293 -0.322757   
5425        0.0       0.0  3.165789 -0.147343       0.0   0.527633  0.677243   
12819       0.0       0.0  0.000000  0.852657       0.0   1.118273  0.677243   
33659       0.0       0.0  3.165789 -0.147343       0.0   0.244733 -0.322757   
19531       1.0       0.0  0.000000 -0.147343       0.0  -0.811611 -0.322757   

       PhysicalActivity  HealthInsurance   Alcohol  
28456          0.867745              0.0 -0.852427  
8993           0.000000              0.0 -0.111403  
34312          0.000000              0.0  0.446044  
4802           1.329964              0.0 -0.367022  
25895          0.000000              0.0 -1.282459  
...                 ...              ...       ...  
18045          1.188011              0.0 -0.810481  
5425           2.099341              0.0 -0.131905  
12819          2.099341              0.0  0.470282  
33659          1.527044              0.0 -0.426709  
19531          1.039465              0.0 -1.044925  

[13109 rows x 30 columns]
2025-12-03 13:14:15,171:INFO:get_config() successfully completed......................................
2025-12-03 13:14:15,171:INFO:Initializing get_config()
2025-12-03 13:14:15,171:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028B5BCF25F0>, variable=y_test)
2025-12-03 13:14:15,171:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-12-03 13:14:15,171:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-12-03 13:14:15,179:INFO:Variable:  returned as 28456    0.0
8993     0.0
34312    0.0
4802     0.0
25895    0.0
        ... 
18045    0.0
5425     0.0
12819    0.0
33659    0.0
19531    0.0
Name: HeartDisease, Length: 13109, dtype: float32
2025-12-03 13:14:15,179:INFO:get_config() successfully completed......................................
2025-12-03 13:14:15,332:INFO:Initializing plot_model()
2025-12-03 13:14:15,332:INFO:plot_model(plot=pr, fold=None, verbose=True, display=None, display_format=None, estimator=CalibratedClassifierCV(cv=5, ensemble=True,
                       estimator=XGBClassifier(base_score=None,
                                               booster='gbtree', callbacks=None,
                                               colsample_bylevel=None,
                                               colsample_bynode=None,
                                               colsample_bytree=None,
                                               device='cpu',
                                               early_stopping_rounds=None,
                                               enable_categorical=False,
                                               eval_metric=None,
                                               feature_types=None, gamma=None,
                                               grow_policy=None,
                                               importance_type=None,
                                               interaction_constraints=None,
                                               learning_rate=0.05, max_bin=None,
                                               max_cat_threshold=None,
                                               max_cat_to_onehot=None,
                                               max_delta_step=1, max_depth=3,
                                               max_leaves=None,
                                               min_child_weight=None,
                                               missing=nan,
                                               monotone_constraints=None,
                                               multi_strategy=None,
                                               n_estimators=200, n_jobs=1,
                                               num_parallel_tree=None,
                                               objective='binary:logistic', ...),
                       method='isotonic', n_jobs=None), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028B5BCF25F0>, system=True)
2025-12-03 13:14:15,332:INFO:Checking exceptions
2025-12-03 13:14:15,341:INFO:Preloading libraries
2025-12-03 13:14:15,371:INFO:Copying training dataset
2025-12-03 13:14:15,372:INFO:Plot type: pr
2025-12-03 13:14:15,593:INFO:Fitting Model
2025-12-03 13:14:15,596:INFO:Scoring test/hold-out set
2025-12-03 13:14:15,913:INFO:Visual Rendered Successfully
2025-12-03 13:14:16,072:INFO:plot_model() successfully completed......................................
2025-12-03 13:14:16,099:INFO:Initializing plot_model()
2025-12-03 13:14:16,099:INFO:plot_model(plot=confusion_matrix, fold=None, verbose=True, display=None, display_format=None, estimator=CalibratedClassifierCV(cv=5, ensemble=True,
                       estimator=XGBClassifier(base_score=None,
                                               booster='gbtree', callbacks=None,
                                               colsample_bylevel=None,
                                               colsample_bynode=None,
                                               colsample_bytree=None,
                                               device='cpu',
                                               early_stopping_rounds=None,
                                               enable_categorical=False,
                                               eval_metric=None,
                                               feature_types=None, gamma=None,
                                               grow_policy=None,
                                               importance_type=None,
                                               interaction_constraints=None,
                                               learning_rate=0.05, max_bin=None,
                                               max_cat_threshold=None,
                                               max_cat_to_onehot=None,
                                               max_delta_step=1, max_depth=3,
                                               max_leaves=None,
                                               min_child_weight=None,
                                               missing=nan,
                                               monotone_constraints=None,
                                               multi_strategy=None,
                                               n_estimators=200, n_jobs=1,
                                               num_parallel_tree=None,
                                               objective='binary:logistic', ...),
                       method='isotonic', n_jobs=None), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028B5BCF25F0>, system=True)
2025-12-03 13:14:16,099:INFO:Checking exceptions
2025-12-03 13:14:16,111:INFO:Preloading libraries
2025-12-03 13:14:16,162:INFO:Copying training dataset
2025-12-03 13:14:16,162:INFO:Plot type: confusion_matrix
2025-12-03 13:14:16,389:INFO:Fitting Model
2025-12-03 13:14:16,391:INFO:Scoring test/hold-out set
2025-12-03 13:14:16,681:INFO:Visual Rendered Successfully
2025-12-03 13:14:16,852:INFO:plot_model() successfully completed......................................
2025-12-03 13:14:16,879:INFO:Initializing plot_model()
2025-12-03 13:14:16,880:INFO:plot_model(plot=error, fold=None, verbose=True, display=None, display_format=None, estimator=CalibratedClassifierCV(cv=5, ensemble=True,
                       estimator=XGBClassifier(base_score=None,
                                               booster='gbtree', callbacks=None,
                                               colsample_bylevel=None,
                                               colsample_bynode=None,
                                               colsample_bytree=None,
                                               device='cpu',
                                               early_stopping_rounds=None,
                                               enable_categorical=False,
                                               eval_metric=None,
                                               feature_types=None, gamma=None,
                                               grow_policy=None,
                                               importance_type=None,
                                               interaction_constraints=None,
                                               learning_rate=0.05, max_bin=None,
                                               max_cat_threshold=None,
                                               max_cat_to_onehot=None,
                                               max_delta_step=1, max_depth=3,
                                               max_leaves=None,
                                               min_child_weight=None,
                                               missing=nan,
                                               monotone_constraints=None,
                                               multi_strategy=None,
                                               n_estimators=200, n_jobs=1,
                                               num_parallel_tree=None,
                                               objective='binary:logistic', ...),
                       method='isotonic', n_jobs=None), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028B5BCF25F0>, system=True)
2025-12-03 13:14:16,880:INFO:Checking exceptions
2025-12-03 13:14:16,889:INFO:Preloading libraries
2025-12-03 13:14:16,920:INFO:Copying training dataset
2025-12-03 13:14:16,920:INFO:Plot type: error
2025-12-03 13:14:17,148:INFO:Fitting Model
2025-12-03 13:14:17,148:INFO:Scoring test/hold-out set
2025-12-03 13:14:17,472:INFO:Visual Rendered Successfully
2025-12-03 13:14:17,635:INFO:plot_model() successfully completed......................................
2025-12-03 13:14:17,665:INFO:Initializing plot_model()
2025-12-03 13:14:17,665:INFO:plot_model(plot=calibration, fold=None, verbose=True, display=None, display_format=None, estimator=CalibratedClassifierCV(cv=5, ensemble=True,
                       estimator=XGBClassifier(base_score=None,
                                               booster='gbtree', callbacks=None,
                                               colsample_bylevel=None,
                                               colsample_bynode=None,
                                               colsample_bytree=None,
                                               device='cpu',
                                               early_stopping_rounds=None,
                                               enable_categorical=False,
                                               eval_metric=None,
                                               feature_types=None, gamma=None,
                                               grow_policy=None,
                                               importance_type=None,
                                               interaction_constraints=None,
                                               learning_rate=0.05, max_bin=None,
                                               max_cat_threshold=None,
                                               max_cat_to_onehot=None,
                                               max_delta_step=1, max_depth=3,
                                               max_leaves=None,
                                               min_child_weight=None,
                                               missing=nan,
                                               monotone_constraints=None,
                                               multi_strategy=None,
                                               n_estimators=200, n_jobs=1,
                                               num_parallel_tree=None,
                                               objective='binary:logistic', ...),
                       method='isotonic', n_jobs=None), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028B5BCF25F0>, system=True)
2025-12-03 13:14:17,665:INFO:Checking exceptions
2025-12-03 13:14:17,675:INFO:Preloading libraries
2025-12-03 13:14:17,733:INFO:Copying training dataset
2025-12-03 13:14:17,733:INFO:Plot type: calibration
2025-12-03 13:14:17,745:INFO:Scoring test/hold-out set
2025-12-03 13:14:18,109:INFO:Visual Rendered Successfully
2025-12-03 13:14:18,272:INFO:plot_model() successfully completed......................................
2025-12-03 13:14:18,301:INFO:Initializing get_config()
2025-12-03 13:14:18,301:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028B5BCF25F0>, variable=X_test_transformed)
2025-12-03 13:14:18,379:INFO:Variable: X_test returned as             Age  IncomeRatio  SystolicBP  WaistCircumference    Height  \
28456 -1.166682    -0.347193   -0.857495           -1.507527 -1.819875   
8993   0.143689     0.336722    1.662729            0.648015 -0.645962   
34312  0.028744     0.094199    0.120503            0.346962  0.583851   
4802  -1.235649     0.337285   -0.681087           -0.938256 -0.976048   
25895  0.028744     1.529936   -0.456265           -0.413678  0.081658   
...         ...          ...         ...                 ...       ...   
18045 -1.258638    -0.075567   -0.904070           -1.993226 -3.285713   
5425  -0.086201     0.470887    1.712883           -0.086555 -0.006211   
12819  0.235645     0.002041    0.478158            0.708225  1.515528   
33659 -1.212660     1.326217   -0.863547           -1.487456 -2.074533   
19531 -1.281627    -0.395697   -0.849048           -1.848720 -3.664595   

       TotalCholesterol  Triglycerides       LDL       HDL     HbA1c  ...  \
28456         -0.077253      -0.647020 -0.018927  0.563922 -0.617463  ...   
8993           0.702398       0.630424  0.004953  0.590479  0.121825  ...   
34312         -0.118546       0.874313 -0.747277 -1.115404  0.666895  ...   
4802          -0.178619      -0.486105  0.000596  0.050858 -0.563915  ...   
25895          0.819676       1.267174  0.006537 -0.056580 -0.314232  ...   
...                 ...            ...       ...       ...       ...  ...   
18045         -0.319533      -0.646830 -0.614729  0.541608 -0.630163  ...   
5425           0.397476      -0.206569  0.807814  0.296361 -0.096204  ...   
12819         -0.681479      -0.646225 -0.152735 -0.821286  0.121825  ...   
33659         -0.986401      -0.647239 -2.064660  0.296361 -0.699939  ...   
19531         -0.334260      -0.646844 -0.652171  0.541702 -0.458463  ...   

       Race_5.0  Race_1.0  Race_4.0  Race_3.0  Race_2.0  Education   Smoking  \
28456       1.0       0.0  0.000000 -0.147343       0.0  -0.020637 -0.322757   
8993        0.0       0.0  3.165789 -0.147343       0.0   0.527633  0.677243   
34312       0.0       0.0  0.000000  0.852657       0.0  -0.653648 -0.322757   
4802        1.0       0.0  0.000000 -0.147343       0.0   0.249169 -0.249145   
25895       0.0       0.0  0.000000  0.852657       0.0   1.118273 -0.322757   
...         ...       ...       ...       ...       ...        ...       ...   
18045       0.0       0.0  0.000000  0.852657       0.0  -0.784293 -0.322757   
5425        0.0       0.0  3.165789 -0.147343       0.0   0.527633  0.677243   
12819       0.0       0.0  0.000000  0.852657       0.0   1.118273  0.677243   
33659       0.0       0.0  3.165789 -0.147343       0.0   0.244733 -0.322757   
19531       1.0       0.0  0.000000 -0.147343       0.0  -0.811611 -0.322757   

       PhysicalActivity  HealthInsurance   Alcohol  
28456          0.867745              0.0 -0.852427  
8993           0.000000              0.0 -0.111403  
34312          0.000000              0.0  0.446044  
4802           1.329964              0.0 -0.367022  
25895          0.000000              0.0 -1.282459  
...                 ...              ...       ...  
18045          1.188011              0.0 -0.810481  
5425           2.099341              0.0 -0.131905  
12819          2.099341              0.0  0.470282  
33659          1.527044              0.0 -0.426709  
19531          1.039465              0.0 -1.044925  

[13109 rows x 30 columns]
2025-12-03 13:14:18,379:INFO:get_config() successfully completed......................................
2025-12-03 13:14:18,380:INFO:Initializing get_config()
2025-12-03 13:14:18,380:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028B5BCF25F0>, variable=y_test)
2025-12-03 13:14:18,380:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-12-03 13:14:18,380:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-12-03 13:14:18,384:INFO:Variable:  returned as 28456    0.0
8993     0.0
34312    0.0
4802     0.0
25895    0.0
        ... 
18045    0.0
5425     0.0
12819    0.0
33659    0.0
19531    0.0
Name: HeartDisease, Length: 13109, dtype: float32
2025-12-03 13:14:18,384:INFO:get_config() successfully completed......................................
2025-12-03 13:14:19,394:INFO:Initializing finalize_model()
2025-12-03 13:14:19,394:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028B5BCF25F0>, estimator=CalibratedClassifierCV(cv=5, ensemble=True,
                       estimator=XGBClassifier(base_score=None,
                                               booster='gbtree', callbacks=None,
                                               colsample_bylevel=None,
                                               colsample_bynode=None,
                                               colsample_bytree=None,
                                               device='cpu',
                                               early_stopping_rounds=None,
                                               enable_categorical=False,
                                               eval_metric=None,
                                               feature_types=None, gamma=None,
                                               grow_policy=None,
                                               importance_type=None,
                                               interaction_constraints=None,
                                               learning_rate=0.05, max_bin=None,
                                               max_cat_threshold=None,
                                               max_cat_to_onehot=None,
                                               max_delta_step=1, max_depth=3,
                                               max_leaves=None,
                                               min_child_weight=None,
                                               missing=nan,
                                               monotone_constraints=None,
                                               multi_strategy=None,
                                               n_estimators=200, n_jobs=1,
                                               num_parallel_tree=None,
                                               objective='binary:logistic', ...),
                       method='isotonic', n_jobs=None), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2025-12-03 13:14:19,398:INFO:Finalizing CalibratedClassifierCV(cv=5, ensemble=True,
                       estimator=XGBClassifier(base_score=None,
                                               booster='gbtree', callbacks=None,
                                               colsample_bylevel=None,
                                               colsample_bynode=None,
                                               colsample_bytree=None,
                                               device='cpu',
                                               early_stopping_rounds=None,
                                               enable_categorical=False,
                                               eval_metric=None,
                                               feature_types=None, gamma=None,
                                               grow_policy=None,
                                               importance_type=None,
                                               interaction_constraints=None,
                                               learning_rate=0.05, max_bin=None,
                                               max_cat_threshold=None,
                                               max_cat_to_onehot=None,
                                               max_delta_step=1, max_depth=3,
                                               max_leaves=None,
                                               min_child_weight=None,
                                               missing=nan,
                                               monotone_constraints=None,
                                               multi_strategy=None,
                                               n_estimators=200, n_jobs=1,
                                               num_parallel_tree=None,
                                               objective='binary:logistic', ...),
                       method='isotonic', n_jobs=None)
2025-12-03 13:14:19,421:INFO:Initializing create_model()
2025-12-03 13:14:19,421:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028B5BCF25F0>, estimator=CalibratedClassifierCV(cv=5, ensemble=True,
                       estimator=XGBClassifier(base_score=None,
                                               booster='gbtree', callbacks=None,
                                               colsample_bylevel=None,
                                               colsample_bynode=None,
                                               colsample_bytree=None,
                                               device='cpu',
                                               early_stopping_rounds=None,
                                               enable_categorical=False,
                                               eval_metric=None,
                                               feature_types=None, gamma=None,
                                               grow_policy=None,
                                               importance_type=None,
                                               interaction_constraints=None,
                                               learning_rate=0.05, max_bin=None,
                                               max_cat_threshold=None,
                                               max_cat_to_onehot=None,
                                               max_delta_step=1, max_depth=3,
                                               max_leaves=None,
                                               min_child_weight=None,
                                               missing=nan,
                                               monotone_constraints=None,
                                               multi_strategy=None,
                                               n_estimators=200, n_jobs=1,
                                               num_parallel_tree=None,
                                               objective='binary:logistic', ...),
                       method='isotonic', n_jobs=None), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2025-12-03 13:14:19,421:INFO:Checking exceptions
2025-12-03 13:14:19,423:INFO:Importing libraries
2025-12-03 13:14:19,423:INFO:Copying training dataset
2025-12-03 13:14:19,426:INFO:Defining folds
2025-12-03 13:14:19,426:INFO:Declaring metric variables
2025-12-03 13:14:19,426:INFO:Importing untrained model
2025-12-03 13:14:19,426:INFO:Declaring custom model
2025-12-03 13:14:19,426:INFO:Extreme Gradient Boosting Imported successfully
2025-12-03 13:14:19,428:INFO:Cross validation set to False
2025-12-03 13:14:19,428:INFO:Fitting Model
2025-12-03 13:14:19,530:INFO:Warning: No categorical columns found. Calling 'transform' will only return input data.
2025-12-03 13:14:24,573:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'IncomeRatio', 'SystolicBP',
                                             'BMI', 'WaistCircumference',
                                             'Height', 'TotalCholesterol',
                                             'Triglycerides', 'LDL', 'HDL',
                                             'HbA1c', 'Glucose', 'Creatinine',
                                             'UricAcid', 'ALT_Enzyme',
                                             'Albumin', 'Potassium', 'Sodium',
                                             'GGT_Enzyme', 'AST_Enzyme'],
                                    transformer=Si...
                                                                interaction_constraints=None,
                                                                learning_rate=0.05,
                                                                max_bin=None,
                                                                max_cat_threshold=None,
                                                                max_cat_to_onehot=None,
                                                                max_delta_step=1,
                                                                max_depth=3,
                                                                max_leaves=None,
                                                                min_child_weight=None,
                                                                missing=nan,
                                                                monotone_constraints=None,
                                                                multi_strategy=None,
                                                                n_estimators=200,
                                                                n_jobs=1,
                                                                num_parallel_tree=None,
                                                                objective='binary:logistic', ...),
                                        method='isotonic', n_jobs=None))],
         verbose=False)
2025-12-03 13:14:24,573:INFO:create_model() successfully completed......................................
2025-12-03 13:14:24,730:INFO:_master_model_container: 4
2025-12-03 13:14:24,730:INFO:_display_container: 4
2025-12-03 13:14:24,749:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'IncomeRatio', 'SystolicBP',
                                             'BMI', 'WaistCircumference',
                                             'Height', 'TotalCholesterol',
                                             'Triglycerides', 'LDL', 'HDL',
                                             'HbA1c', 'Glucose', 'Creatinine',
                                             'UricAcid', 'ALT_Enzyme',
                                             'Albumin', 'Potassium', 'Sodium',
                                             'GGT_Enzyme', 'AST_Enzyme'],
                                    transformer=Si...
                                                                interaction_constraints=None,
                                                                learning_rate=0.05,
                                                                max_bin=None,
                                                                max_cat_threshold=None,
                                                                max_cat_to_onehot=None,
                                                                max_delta_step=1,
                                                                max_depth=3,
                                                                max_leaves=None,
                                                                min_child_weight=None,
                                                                missing=nan,
                                                                monotone_constraints=None,
                                                                multi_strategy=None,
                                                                n_estimators=200,
                                                                n_jobs=1,
                                                                num_parallel_tree=None,
                                                                objective='binary:logistic', ...),
                                        method='isotonic', n_jobs=None))],
         verbose=False)
2025-12-03 13:14:24,749:INFO:finalize_model() successfully completed......................................
2025-12-03 13:14:24,936:INFO:Initializing save_model()
2025-12-03 13:14:24,936:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'IncomeRatio', 'SystolicBP',
                                             'BMI', 'WaistCircumference',
                                             'Height', 'TotalCholesterol',
                                             'Triglycerides', 'LDL', 'HDL',
                                             'HbA1c', 'Glucose', 'Creatinine',
                                             'UricAcid', 'ALT_Enzyme',
                                             'Albumin', 'Potassium', 'Sodium',
                                             'GGT_Enzyme', 'AST_Enzyme'],
                                    transformer=Si...
                                                                interaction_constraints=None,
                                                                learning_rate=0.05,
                                                                max_bin=None,
                                                                max_cat_threshold=None,
                                                                max_cat_to_onehot=None,
                                                                max_delta_step=1,
                                                                max_depth=3,
                                                                max_leaves=None,
                                                                min_child_weight=None,
                                                                missing=nan,
                                                                monotone_constraints=None,
                                                                multi_strategy=None,
                                                                n_estimators=200,
                                                                n_jobs=1,
                                                                num_parallel_tree=None,
                                                                objective='binary:logistic', ...),
                                        method='isotonic', n_jobs=None))],
         verbose=False), model_name=../models\best_pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\OMAR\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'IncomeRatio', 'SystolicBP',
                                             'BMI', 'WaistCircumference',
                                             'Height', 'TotalCholesterol',
                                             'Triglycerides', 'LDL', 'HDL',
                                             'HbA1c', 'Glucose', 'Creatinine',
                                             'UricAcid', 'ALT_Enzyme',
                                             'Albumin', 'Potassium', 'Sodium',
                                             'G...
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              random_state=42,
                                                                              sampling_strategy='auto')))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=RobustScaler(copy=True,
                                                             quantile_range=(25.0,
                                                                             75.0),
                                                             unit_variance=False,
                                                             with_centering=True,
                                                             with_scaling=True)))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2025-12-03 13:14:24,936:INFO:Adding model into prep_pipe
2025-12-03 13:14:24,936:WARNING:Only Model saved as it was a pipeline.
2025-12-03 13:14:24,954:INFO:../models\best_pipeline.pkl saved in current working directory
2025-12-03 13:14:24,972:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'IncomeRatio', 'SystolicBP',
                                             'BMI', 'WaistCircumference',
                                             'Height', 'TotalCholesterol',
                                             'Triglycerides', 'LDL', 'HDL',
                                             'HbA1c', 'Glucose', 'Creatinine',
                                             'UricAcid', 'ALT_Enzyme',
                                             'Albumin', 'Potassium', 'Sodium',
                                             'GGT_Enzyme', 'AST_Enzyme'],
                                    transformer=Si...
                                                                interaction_constraints=None,
                                                                learning_rate=0.05,
                                                                max_bin=None,
                                                                max_cat_threshold=None,
                                                                max_cat_to_onehot=None,
                                                                max_delta_step=1,
                                                                max_depth=3,
                                                                max_leaves=None,
                                                                min_child_weight=None,
                                                                missing=nan,
                                                                monotone_constraints=None,
                                                                multi_strategy=None,
                                                                n_estimators=200,
                                                                n_jobs=1,
                                                                num_parallel_tree=None,
                                                                objective='binary:logistic', ...),
                                        method='isotonic', n_jobs=None))],
         verbose=False)
2025-12-03 13:14:24,972:INFO:save_model() successfully completed......................................
2025-12-03 13:16:42,933:INFO:PyCaret ClassificationExperiment
2025-12-03 13:16:42,933:INFO:Logging name: clf-default-name
2025-12-03 13:16:42,933:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-12-03 13:16:42,934:INFO:version 3.3.2
2025-12-03 13:16:42,934:INFO:Initializing setup()
2025-12-03 13:16:42,934:INFO:self.USI: 7972
2025-12-03 13:16:42,934:INFO:self._variable_keys: {'fold_groups_param', 'gpu_param', 'n_jobs_param', 'exp_id', '_available_plots', 'USI', 'X', '_ml_usecase', 'seed', 'memory', 'X_train', 'y_test', 'log_plots_param', 'target_param', 'y', 'gpu_n_jobs_param', 'pipeline', 'X_test', 'idx', 'exp_name_log', 'fix_imbalance', 'fold_generator', 'logging_param', 'is_multiclass', 'data', 'fold_shuffle_param', 'html_param', 'y_train'}
2025-12-03 13:16:42,934:INFO:Checking environment
2025-12-03 13:16:42,934:INFO:python_version: 3.10.19
2025-12-03 13:16:42,934:INFO:python_build: ('main', 'Oct 21 2025 16:41:31')
2025-12-03 13:16:42,934:INFO:machine: AMD64
2025-12-03 13:16:42,934:INFO:platform: Windows-10-10.0.26100-SP0
2025-12-03 13:16:42,934:INFO:Memory: svmem(total=16282144768, available=3965497344, percent=75.6, used=12316647424, free=3965497344)
2025-12-03 13:16:42,934:INFO:Physical Core: 6
2025-12-03 13:16:42,934:INFO:Logical Core: 12
2025-12-03 13:16:42,934:INFO:Checking libraries
2025-12-03 13:16:42,934:INFO:System:
2025-12-03 13:16:42,934:INFO:    python: 3.10.19 | packaged by Anaconda, Inc. | (main, Oct 21 2025, 16:41:31) [MSC v.1929 64 bit (AMD64)]
2025-12-03 13:16:42,934:INFO:executable: c:\Users\OMAR\miniconda3\envs\xgb_env\python.exe
2025-12-03 13:16:42,934:INFO:   machine: Windows-10-10.0.26100-SP0
2025-12-03 13:16:42,934:INFO:PyCaret required dependencies:
2025-12-03 13:16:42,934:INFO:                 pip: 25.3
2025-12-03 13:16:42,934:INFO:          setuptools: 80.9.0
2025-12-03 13:16:42,934:INFO:             pycaret: 3.3.2
2025-12-03 13:16:42,934:INFO:             IPython: 8.37.0
2025-12-03 13:16:42,934:INFO:          ipywidgets: 8.1.8
2025-12-03 13:16:42,934:INFO:                tqdm: 4.67.1
2025-12-03 13:16:42,934:INFO:               numpy: 1.26.4
2025-12-03 13:16:42,934:INFO:              pandas: 2.1.4
2025-12-03 13:16:42,934:INFO:              jinja2: 3.1.6
2025-12-03 13:16:42,934:INFO:               scipy: 1.11.4
2025-12-03 13:16:42,934:INFO:              joblib: 1.3.2
2025-12-03 13:16:42,934:INFO:             sklearn: 1.4.2
2025-12-03 13:16:42,934:INFO:                pyod: 2.0.5
2025-12-03 13:16:42,934:INFO:            imblearn: 0.14.0
2025-12-03 13:16:42,934:INFO:   category_encoders: 2.7.0
2025-12-03 13:16:42,934:INFO:            lightgbm: 4.6.0
2025-12-03 13:16:42,934:INFO:               numba: 0.62.1
2025-12-03 13:16:42,934:INFO:            requests: 2.32.5
2025-12-03 13:16:42,934:INFO:          matplotlib: 3.7.5
2025-12-03 13:16:42,934:INFO:          scikitplot: 0.3.7
2025-12-03 13:16:42,934:INFO:         yellowbrick: 1.5
2025-12-03 13:16:42,934:INFO:              plotly: 5.24.1
2025-12-03 13:16:42,934:INFO:    plotly-resampler: Not installed
2025-12-03 13:16:42,934:INFO:             kaleido: 1.2.0
2025-12-03 13:16:42,934:INFO:           schemdraw: 0.15
2025-12-03 13:16:42,934:INFO:         statsmodels: 0.14.5
2025-12-03 13:16:42,934:INFO:              sktime: 0.26.0
2025-12-03 13:16:42,934:INFO:               tbats: 1.1.3
2025-12-03 13:16:42,934:INFO:            pmdarima: 2.0.4
2025-12-03 13:16:42,934:INFO:              psutil: 7.1.3
2025-12-03 13:16:42,934:INFO:          markupsafe: 3.0.3
2025-12-03 13:16:42,934:INFO:             pickle5: Not installed
2025-12-03 13:16:42,934:INFO:         cloudpickle: 3.1.2
2025-12-03 13:16:42,934:INFO:         deprecation: 2.1.0
2025-12-03 13:16:42,934:INFO:              xxhash: 3.6.0
2025-12-03 13:16:42,934:INFO:           wurlitzer: Not installed
2025-12-03 13:16:42,934:INFO:PyCaret optional dependencies:
2025-12-03 13:16:42,936:INFO:                shap: 0.49.1
2025-12-03 13:16:42,936:INFO:           interpret: 0.7.3
2025-12-03 13:16:42,936:INFO:                umap: 0.5.7
2025-12-03 13:16:42,936:INFO:     ydata_profiling: 4.18.0
2025-12-03 13:16:42,936:INFO:  explainerdashboard: 0.5.1
2025-12-03 13:16:42,936:INFO:             autoviz: Not installed
2025-12-03 13:16:42,936:INFO:           fairlearn: 0.7.0
2025-12-03 13:16:42,936:INFO:          deepchecks: Not installed
2025-12-03 13:16:42,936:INFO:             xgboost: 2.1.3
2025-12-03 13:16:42,936:INFO:            catboost: 1.2.8
2025-12-03 13:16:42,936:INFO:              kmodes: 0.12.2
2025-12-03 13:16:42,936:INFO:             mlxtend: 0.23.4
2025-12-03 13:16:42,936:INFO:       statsforecast: 1.5.0
2025-12-03 13:16:42,936:INFO:        tune_sklearn: Not installed
2025-12-03 13:16:42,936:INFO:                 ray: Not installed
2025-12-03 13:16:42,936:INFO:            hyperopt: 0.2.7
2025-12-03 13:16:42,936:INFO:              optuna: 4.6.0
2025-12-03 13:16:42,936:INFO:               skopt: 0.10.2
2025-12-03 13:16:42,936:INFO:              mlflow: 3.6.0
2025-12-03 13:16:42,936:INFO:              gradio: 6.0.1
2025-12-03 13:16:42,936:INFO:             fastapi: 0.123.0
2025-12-03 13:16:42,936:INFO:             uvicorn: 0.38.0
2025-12-03 13:16:42,936:INFO:              m2cgen: 0.10.0
2025-12-03 13:16:42,936:INFO:           evidently: 0.4.40
2025-12-03 13:16:42,936:INFO:               fugue: 0.8.7
2025-12-03 13:16:42,936:INFO:           streamlit: 1.51.0
2025-12-03 13:16:42,936:INFO:             prophet: Not installed
2025-12-03 13:16:42,936:INFO:None
2025-12-03 13:16:42,936:INFO:Set up data.
2025-12-03 13:16:42,951:INFO:Set up folding strategy.
2025-12-03 13:16:42,951:INFO:Set up train/test split.
2025-12-03 13:16:42,976:INFO:Set up index.
2025-12-03 13:16:42,978:INFO:Assigning column types.
2025-12-03 13:16:42,994:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-12-03 13:16:43,020:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-12-03 13:16:43,020:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-03 13:16:43,037:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-03 13:16:43,038:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-03 13:16:43,065:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-12-03 13:16:43,067:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-03 13:16:43,082:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-03 13:16:43,085:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-03 13:16:43,085:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-12-03 13:16:43,111:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-03 13:16:43,128:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-03 13:16:43,129:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-03 13:16:43,156:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-03 13:16:43,172:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-03 13:16:43,172:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-03 13:16:43,172:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-12-03 13:16:43,215:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-03 13:16:43,218:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-03 13:16:43,262:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-03 13:16:43,263:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-03 13:16:43,265:INFO:Preparing preprocessing pipeline...
2025-12-03 13:16:43,268:INFO:Set up simple imputation.
2025-12-03 13:16:43,280:INFO:Set up encoding of ordinal features.
2025-12-03 13:16:43,287:INFO:Set up encoding of categorical features.
2025-12-03 13:16:43,287:INFO:Set up removing multicollinearity.
2025-12-03 13:16:43,287:INFO:Set up imbalanced handling.
2025-12-03 13:16:43,287:INFO:Set up feature normalization.
2025-12-03 13:16:43,607:INFO:Finished creating preprocessing pipeline.
2025-12-03 13:16:43,624:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\OMAR\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'IncomeRatio', 'SystolicBP',
                                             'BMI', 'WaistCircumference',
                                             'Height', 'TotalCholesterol',
                                             'Triglycerides', 'LDL', 'HDL',
                                             'HbA1c', 'Glucose', 'Creatinine',
                                             'UricAcid', 'ALT_Enzyme',
                                             'Albumin', 'Potassium', 'Sodium',
                                             'G...
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              random_state=42,
                                                                              sampling_strategy='auto')))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=RobustScaler(copy=True,
                                                             quantile_range=(25.0,
                                                                             75.0),
                                                             unit_variance=False,
                                                             with_centering=True,
                                                             with_scaling=True)))],
         verbose=False)
2025-12-03 13:16:43,624:INFO:Creating final display dataframe.
2025-12-03 13:16:43,854:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target      HeartDisease
2                   Target type            Binary
3           Original data shape       (43695, 28)
4        Transformed data shape       (72719, 31)
5   Transformed train set shape       (59610, 31)
6    Transformed test set shape       (13109, 31)
7              Numeric features                20
8          Categorical features                 7
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15     Remove multicollinearity              True
16  Multicollinearity threshold               0.9
17                Fix imbalance              True
18         Fix imbalance method             SMOTE
19                    Normalize              True
20             Normalize method            robust
21               Fold Generator   StratifiedKFold
22                  Fold Number                10
23                     CPU Jobs                 1
24                      Use GPU             False
25               Log Experiment             False
26              Experiment Name  clf-default-name
27                          USI              7972
2025-12-03 13:16:43,903:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-03 13:16:43,905:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-03 13:16:43,950:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-03 13:16:43,952:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-03 13:16:43,953:INFO:setup() successfully completed in 1.03s...............
2025-12-03 13:16:43,986:INFO:Initializing create_model()
2025-12-03 13:16:43,986:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028B65B40790>, estimator=xgboost, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-03 13:16:43,986:INFO:Checking exceptions
2025-12-03 13:16:43,988:INFO:Importing libraries
2025-12-03 13:16:43,988:INFO:Copying training dataset
2025-12-03 13:16:44,009:INFO:Defining folds
2025-12-03 13:16:44,009:INFO:Declaring metric variables
2025-12-03 13:16:44,009:INFO:Importing untrained model
2025-12-03 13:16:44,011:INFO:Extreme Gradient Boosting Imported successfully
2025-12-03 13:16:44,011:INFO:Starting cross validation
2025-12-03 13:16:44,012:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-12-03 13:16:54,532:INFO:Calculating mean and std
2025-12-03 13:16:54,533:INFO:Creating metrics dataframe
2025-12-03 13:16:54,534:INFO:Finalizing model
2025-12-03 13:16:54,607:INFO:Warning: No categorical columns found. Calling 'transform' will only return input data.
2025-12-03 13:16:55,613:INFO:Uploading results into container
2025-12-03 13:16:55,615:INFO:Uploading model into container now
2025-12-03 13:16:55,616:INFO:_master_model_container: 1
2025-12-03 13:16:55,616:INFO:_display_container: 2
2025-12-03 13:16:55,616:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2025-12-03 13:16:55,616:INFO:create_model() successfully completed......................................
2025-12-03 13:16:55,794:INFO:Initializing tune_model()
2025-12-03 13:16:55,794:INFO:tune_model(estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...), fold=None, round=4, n_iter=10, custom_grid={'learning_rate': [0.05, 0.1], 'n_estimators': [100, 200], 'max_depth': [3, 5], 'scale_pos_weight': [38.153225806451616, 57.22983870967742], 'max_delta_step': [1]}, optimize=Recall, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028B65B40790>)
2025-12-03 13:16:55,794:INFO:Checking exceptions
2025-12-03 13:16:55,819:INFO:Copying training dataset
2025-12-03 13:16:55,837:INFO:Checking base model
2025-12-03 13:16:55,839:INFO:Base model : Extreme Gradient Boosting
2025-12-03 13:16:55,843:INFO:Declaring metric variables
2025-12-03 13:16:55,846:INFO:Defining Hyperparameters
2025-12-03 13:16:56,034:INFO:custom_grid: {'actual_estimator__learning_rate': [0.05, 0.1], 'actual_estimator__n_estimators': [100, 200], 'actual_estimator__max_depth': [3, 5], 'actual_estimator__scale_pos_weight': [38.153225806451616, 57.22983870967742], 'actual_estimator__max_delta_step': [1]}
2025-12-03 13:16:56,034:INFO:Tuning with n_jobs=1
2025-12-03 13:16:56,034:INFO:Initializing RandomizedSearchCV
2025-12-03 13:18:42,540:INFO:best_params: {'actual_estimator__scale_pos_weight': 57.22983870967742, 'actual_estimator__n_estimators': 100, 'actual_estimator__max_depth': 5, 'actual_estimator__max_delta_step': 1, 'actual_estimator__learning_rate': 0.05}
2025-12-03 13:18:42,541:INFO:Hyperparameter search completed
2025-12-03 13:18:42,541:INFO:SubProcess create_model() called ==================================
2025-12-03 13:18:42,541:INFO:Initializing create_model()
2025-12-03 13:18:42,543:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028B65B40790>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000028B65AB5060>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'scale_pos_weight': 57.22983870967742, 'n_estimators': 100, 'max_depth': 5, 'max_delta_step': 1, 'learning_rate': 0.05})
2025-12-03 13:18:42,543:INFO:Checking exceptions
2025-12-03 13:18:42,543:INFO:Importing libraries
2025-12-03 13:18:42,543:INFO:Copying training dataset
2025-12-03 13:18:42,574:INFO:Defining folds
2025-12-03 13:18:42,574:INFO:Declaring metric variables
2025-12-03 13:18:42,576:INFO:Importing untrained model
2025-12-03 13:18:42,576:INFO:Declaring custom model
2025-12-03 13:18:42,581:INFO:Extreme Gradient Boosting Imported successfully
2025-12-03 13:18:42,587:INFO:Starting cross validation
2025-12-03 13:18:42,589:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-12-03 13:18:52,884:INFO:Calculating mean and std
2025-12-03 13:18:52,886:INFO:Creating metrics dataframe
2025-12-03 13:18:52,891:INFO:Finalizing model
2025-12-03 13:18:52,975:INFO:Warning: No categorical columns found. Calling 'transform' will only return input data.
2025-12-03 13:18:53,900:INFO:Uploading results into container
2025-12-03 13:18:53,901:INFO:Uploading model into container now
2025-12-03 13:18:53,901:INFO:_master_model_container: 2
2025-12-03 13:18:53,902:INFO:_display_container: 3
2025-12-03 13:18:53,902:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=0.05, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None, max_delta_step=1,
              max_depth=5, max_leaves=None, min_child_weight=None, missing=nan,
              monotone_constraints=None, multi_strategy=None, n_estimators=100,
              n_jobs=1, num_parallel_tree=None, objective='binary:logistic', ...)
2025-12-03 13:18:53,903:INFO:create_model() successfully completed......................................
2025-12-03 13:18:54,107:INFO:SubProcess create_model() end ==================================
2025-12-03 13:18:54,107:INFO:choose_better activated
2025-12-03 13:18:54,110:INFO:SubProcess create_model() called ==================================
2025-12-03 13:18:54,110:INFO:Initializing create_model()
2025-12-03 13:18:54,110:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028B65B40790>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-03 13:18:54,110:INFO:Checking exceptions
2025-12-03 13:18:54,112:INFO:Importing libraries
2025-12-03 13:18:54,112:INFO:Copying training dataset
2025-12-03 13:18:54,138:INFO:Defining folds
2025-12-03 13:18:54,138:INFO:Declaring metric variables
2025-12-03 13:18:54,139:INFO:Importing untrained model
2025-12-03 13:18:54,139:INFO:Declaring custom model
2025-12-03 13:18:54,140:INFO:Extreme Gradient Boosting Imported successfully
2025-12-03 13:18:54,140:INFO:Starting cross validation
2025-12-03 13:18:54,142:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-12-03 13:19:05,576:INFO:Calculating mean and std
2025-12-03 13:19:05,576:INFO:Creating metrics dataframe
2025-12-03 13:19:05,578:INFO:Finalizing model
2025-12-03 13:19:05,656:INFO:Warning: No categorical columns found. Calling 'transform' will only return input data.
2025-12-03 13:19:06,778:INFO:Uploading results into container
2025-12-03 13:19:06,781:INFO:Uploading model into container now
2025-12-03 13:19:06,781:INFO:_master_model_container: 3
2025-12-03 13:19:06,781:INFO:_display_container: 4
2025-12-03 13:19:06,782:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2025-12-03 13:19:06,782:INFO:create_model() successfully completed......................................
2025-12-03 13:19:06,970:INFO:SubProcess create_model() end ==================================
2025-12-03 13:19:06,972:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...) result for Recall is 0.1344
2025-12-03 13:19:06,972:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=0.05, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None, max_delta_step=1,
              max_depth=5, max_leaves=None, min_child_weight=None, missing=nan,
              monotone_constraints=None, multi_strategy=None, n_estimators=100,
              n_jobs=1, num_parallel_tree=None, objective='binary:logistic', ...) result for Recall is 0.9628
2025-12-03 13:19:06,973:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=0.05, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None, max_delta_step=1,
              max_depth=5, max_leaves=None, min_child_weight=None, missing=nan,
              monotone_constraints=None, multi_strategy=None, n_estimators=100,
              n_jobs=1, num_parallel_tree=None, objective='binary:logistic', ...) is best model
2025-12-03 13:19:06,973:INFO:choose_better completed
2025-12-03 13:19:06,982:INFO:_master_model_container: 3
2025-12-03 13:19:06,982:INFO:_display_container: 3
2025-12-03 13:19:06,983:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=0.05, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None, max_delta_step=1,
              max_depth=5, max_leaves=None, min_child_weight=None, missing=nan,
              monotone_constraints=None, multi_strategy=None, n_estimators=100,
              n_jobs=1, num_parallel_tree=None, objective='binary:logistic', ...)
2025-12-03 13:19:06,983:INFO:tune_model() successfully completed......................................
2025-12-03 13:19:07,188:INFO:Initializing calibrate_model()
2025-12-03 13:19:07,188:INFO:calibrate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028B65B40790>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=0.05, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None, max_delta_step=1,
              max_depth=5, max_leaves=None, min_child_weight=None, missing=nan,
              monotone_constraints=None, multi_strategy=None, n_estimators=100,
              n_jobs=1, num_parallel_tree=None, objective='binary:logistic', ...), method=isotonic, calibrate_fold=5, fold=None, round=4, fit_kwargs=None, groups=None, verbose=True, return_train_score=False)
2025-12-03 13:19:07,188:INFO:Checking exceptions
2025-12-03 13:19:07,200:INFO:Preloading libraries
2025-12-03 13:19:07,200:INFO:Preparing display monitor
2025-12-03 13:19:07,212:INFO:Getting model name
2025-12-03 13:19:07,213:INFO:Base model : Extreme Gradient Boosting
2025-12-03 13:19:07,220:INFO:Importing untrained CalibratedClassifierCV
2025-12-03 13:19:07,222:INFO:SubProcess create_model() called ==================================
2025-12-03 13:19:07,224:INFO:Initializing create_model()
2025-12-03 13:19:07,224:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028B65B40790>, estimator=CalibratedClassifierCV(cv=5, ensemble=True,
                       estimator=XGBClassifier(base_score=None,
                                               booster='gbtree', callbacks=None,
                                               colsample_bylevel=None,
                                               colsample_bynode=None,
                                               colsample_bytree=None,
                                               device='cpu',
                                               early_stopping_rounds=None,
                                               enable_categorical=False,
                                               eval_metric=None,
                                               feature_types=None, gamma=None,
                                               grow_policy=None,
                                               importance_type=None,
                                               interaction_constraints=None,
                                               learning_rate=0.05, max_bin=None,
                                               max_cat_threshold=None,
                                               max_cat_to_onehot=None,
                                               max_delta_step=1, max_depth=5,
                                               max_leaves=None,
                                               min_child_weight=None,
                                               missing=nan,
                                               monotone_constraints=None,
                                               multi_strategy=None,
                                               n_estimators=100, n_jobs=1,
                                               num_parallel_tree=None,
                                               objective='binary:logistic', ...),
                       method='isotonic', n_jobs=None), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000028B58110670>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-03 13:19:07,224:INFO:Checking exceptions
2025-12-03 13:19:07,224:INFO:Importing libraries
2025-12-03 13:19:07,224:INFO:Copying training dataset
2025-12-03 13:19:07,261:INFO:Defining folds
2025-12-03 13:19:07,262:INFO:Declaring metric variables
2025-12-03 13:19:07,265:INFO:Importing untrained model
2025-12-03 13:19:07,265:INFO:Declaring custom model
2025-12-03 13:19:07,271:INFO:Extreme Gradient Boosting Imported successfully
2025-12-03 13:19:07,280:INFO:Starting cross validation
2025-12-03 13:19:07,283:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-12-03 13:19:42,378:INFO:Calculating mean and std
2025-12-03 13:19:42,379:INFO:Creating metrics dataframe
2025-12-03 13:19:42,383:INFO:Finalizing model
2025-12-03 13:19:42,489:INFO:Warning: No categorical columns found. Calling 'transform' will only return input data.
2025-12-03 13:19:46,274:INFO:Uploading results into container
2025-12-03 13:19:46,274:INFO:Uploading model into container now
2025-12-03 13:19:46,274:INFO:_master_model_container: 4
2025-12-03 13:19:46,275:INFO:_display_container: 4
2025-12-03 13:19:46,277:INFO:CalibratedClassifierCV(cv=5, ensemble=True,
                       estimator=XGBClassifier(base_score=None,
                                               booster='gbtree', callbacks=None,
                                               colsample_bylevel=None,
                                               colsample_bynode=None,
                                               colsample_bytree=None,
                                               device='cpu',
                                               early_stopping_rounds=None,
                                               enable_categorical=False,
                                               eval_metric=None,
                                               feature_types=None, gamma=None,
                                               grow_policy=None,
                                               importance_type=None,
                                               interaction_constraints=None,
                                               learning_rate=0.05, max_bin=None,
                                               max_cat_threshold=None,
                                               max_cat_to_onehot=None,
                                               max_delta_step=1, max_depth=5,
                                               max_leaves=None,
                                               min_child_weight=None,
                                               missing=nan,
                                               monotone_constraints=None,
                                               multi_strategy=None,
                                               n_estimators=100, n_jobs=1,
                                               num_parallel_tree=None,
                                               objective='binary:logistic', ...),
                       method='isotonic', n_jobs=None)
2025-12-03 13:19:46,277:INFO:create_model() successfully completed......................................
2025-12-03 13:19:46,466:INFO:SubProcess create_model() end ==================================
2025-12-03 13:19:46,481:INFO:_master_model_container: 4
2025-12-03 13:19:46,482:INFO:_display_container: 4
2025-12-03 13:19:46,483:INFO:CalibratedClassifierCV(cv=5, ensemble=True,
                       estimator=XGBClassifier(base_score=None,
                                               booster='gbtree', callbacks=None,
                                               colsample_bylevel=None,
                                               colsample_bynode=None,
                                               colsample_bytree=None,
                                               device='cpu',
                                               early_stopping_rounds=None,
                                               enable_categorical=False,
                                               eval_metric=None,
                                               feature_types=None, gamma=None,
                                               grow_policy=None,
                                               importance_type=None,
                                               interaction_constraints=None,
                                               learning_rate=0.05, max_bin=None,
                                               max_cat_threshold=None,
                                               max_cat_to_onehot=None,
                                               max_delta_step=1, max_depth=5,
                                               max_leaves=None,
                                               min_child_weight=None,
                                               missing=nan,
                                               monotone_constraints=None,
                                               multi_strategy=None,
                                               n_estimators=100, n_jobs=1,
                                               num_parallel_tree=None,
                                               objective='binary:logistic', ...),
                       method='isotonic', n_jobs=None)
2025-12-03 13:19:46,483:INFO:calibrate_model() successfully completed......................................
2025-12-03 13:19:46,725:INFO:Initializing plot_model()
2025-12-03 13:19:46,726:INFO:plot_model(plot=auc, fold=None, verbose=True, display=None, display_format=None, estimator=CalibratedClassifierCV(cv=5, ensemble=True,
                       estimator=XGBClassifier(base_score=None,
                                               booster='gbtree', callbacks=None,
                                               colsample_bylevel=None,
                                               colsample_bynode=None,
                                               colsample_bytree=None,
                                               device='cpu',
                                               early_stopping_rounds=None,
                                               enable_categorical=False,
                                               eval_metric=None,
                                               feature_types=None, gamma=None,
                                               grow_policy=None,
                                               importance_type=None,
                                               interaction_constraints=None,
                                               learning_rate=0.05, max_bin=None,
                                               max_cat_threshold=None,
                                               max_cat_to_onehot=None,
                                               max_delta_step=1, max_depth=5,
                                               max_leaves=None,
                                               min_child_weight=None,
                                               missing=nan,
                                               monotone_constraints=None,
                                               multi_strategy=None,
                                               n_estimators=100, n_jobs=1,
                                               num_parallel_tree=None,
                                               objective='binary:logistic', ...),
                       method='isotonic', n_jobs=None), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028B65B40790>, system=True)
2025-12-03 13:19:46,726:INFO:Checking exceptions
2025-12-03 13:19:46,740:INFO:Preloading libraries
2025-12-03 13:19:46,769:INFO:Copying training dataset
2025-12-03 13:19:46,769:INFO:Plot type: auc
2025-12-03 13:19:47,012:INFO:Fitting Model
2025-12-03 13:19:47,015:INFO:Scoring test/hold-out set
2025-12-03 13:19:47,371:INFO:Visual Rendered Successfully
2025-12-03 13:19:47,556:INFO:plot_model() successfully completed......................................
2025-12-03 13:19:47,558:INFO:Initializing get_config()
2025-12-03 13:19:47,558:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028B65B40790>, variable=X_test_transformed)
2025-12-03 13:19:47,637:INFO:Variable: X_test returned as             Age  IncomeRatio  SystolicBP  WaistCircumference    Height  \
28456 -1.166682    -0.347193   -0.857495           -1.507527 -1.819875   
8993   0.143689     0.336722    1.662729            0.648015 -0.645962   
34312  0.028744     0.094199    0.120503            0.346962  0.583851   
4802  -1.235649     0.337285   -0.681087           -0.938256 -0.976048   
25895  0.028744     1.529936   -0.456265           -0.413678  0.081658   
...         ...          ...         ...                 ...       ...   
18045 -1.258638    -0.075567   -0.904070           -1.993226 -3.285713   
5425  -0.086201     0.470887    1.712883           -0.086555 -0.006211   
12819  0.235645     0.002041    0.478158            0.708225  1.515528   
33659 -1.212660     1.326217   -0.863547           -1.487456 -2.074533   
19531 -1.281627    -0.395697   -0.849048           -1.848720 -3.664595   

       TotalCholesterol  Triglycerides       LDL       HDL     HbA1c  ...  \
28456         -0.077253      -0.647020 -0.018927  0.563922 -0.617463  ...   
8993           0.702398       0.630424  0.004953  0.590479  0.121825  ...   
34312         -0.118546       0.874313 -0.747277 -1.115404  0.666895  ...   
4802          -0.178619      -0.486105  0.000596  0.050858 -0.563915  ...   
25895          0.819676       1.267174  0.006537 -0.056580 -0.314232  ...   
...                 ...            ...       ...       ...       ...  ...   
18045         -0.319533      -0.646830 -0.614729  0.541608 -0.630163  ...   
5425           0.397476      -0.206569  0.807814  0.296361 -0.096204  ...   
12819         -0.681479      -0.646225 -0.152735 -0.821286  0.121825  ...   
33659         -0.986401      -0.647239 -2.064660  0.296361 -0.699939  ...   
19531         -0.334260      -0.646844 -0.652171  0.541702 -0.458463  ...   

       Race_5.0  Race_1.0  Race_4.0  Race_3.0  Race_2.0  Education   Smoking  \
28456       1.0       0.0  0.000000 -0.147343       0.0  -0.020637 -0.322757   
8993        0.0       0.0  3.165789 -0.147343       0.0   0.527633  0.677243   
34312       0.0       0.0  0.000000  0.852657       0.0  -0.653648 -0.322757   
4802        1.0       0.0  0.000000 -0.147343       0.0   0.249169 -0.249145   
25895       0.0       0.0  0.000000  0.852657       0.0   1.118273 -0.322757   
...         ...       ...       ...       ...       ...        ...       ...   
18045       0.0       0.0  0.000000  0.852657       0.0  -0.784293 -0.322757   
5425        0.0       0.0  3.165789 -0.147343       0.0   0.527633  0.677243   
12819       0.0       0.0  0.000000  0.852657       0.0   1.118273  0.677243   
33659       0.0       0.0  3.165789 -0.147343       0.0   0.244733 -0.322757   
19531       1.0       0.0  0.000000 -0.147343       0.0  -0.811611 -0.322757   

       PhysicalActivity  HealthInsurance   Alcohol  
28456          0.867745              0.0 -0.852427  
8993           0.000000              0.0 -0.111403  
34312          0.000000              0.0  0.446044  
4802           1.329964              0.0 -0.367022  
25895          0.000000              0.0 -1.282459  
...                 ...              ...       ...  
18045          1.188011              0.0 -0.810481  
5425           2.099341              0.0 -0.131905  
12819          2.099341              0.0  0.470282  
33659          1.527044              0.0 -0.426709  
19531          1.039465              0.0 -1.044925  

[13109 rows x 30 columns]
2025-12-03 13:19:47,637:INFO:get_config() successfully completed......................................
2025-12-03 13:19:47,638:INFO:Initializing get_config()
2025-12-03 13:19:47,638:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028B65B40790>, variable=y_test)
2025-12-03 13:19:47,638:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-12-03 13:19:47,638:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-12-03 13:19:47,643:INFO:Variable:  returned as 28456    0.0
8993     0.0
34312    0.0
4802     0.0
25895    0.0
        ... 
18045    0.0
5425     0.0
12819    0.0
33659    0.0
19531    0.0
Name: HeartDisease, Length: 13109, dtype: float32
2025-12-03 13:19:47,643:INFO:get_config() successfully completed......................................
2025-12-03 13:19:47,787:INFO:Initializing plot_model()
2025-12-03 13:19:47,787:INFO:plot_model(plot=pr, fold=None, verbose=True, display=None, display_format=None, estimator=CalibratedClassifierCV(cv=5, ensemble=True,
                       estimator=XGBClassifier(base_score=None,
                                               booster='gbtree', callbacks=None,
                                               colsample_bylevel=None,
                                               colsample_bynode=None,
                                               colsample_bytree=None,
                                               device='cpu',
                                               early_stopping_rounds=None,
                                               enable_categorical=False,
                                               eval_metric=None,
                                               feature_types=None, gamma=None,
                                               grow_policy=None,
                                               importance_type=None,
                                               interaction_constraints=None,
                                               learning_rate=0.05, max_bin=None,
                                               max_cat_threshold=None,
                                               max_cat_to_onehot=None,
                                               max_delta_step=1, max_depth=5,
                                               max_leaves=None,
                                               min_child_weight=None,
                                               missing=nan,
                                               monotone_constraints=None,
                                               multi_strategy=None,
                                               n_estimators=100, n_jobs=1,
                                               num_parallel_tree=None,
                                               objective='binary:logistic', ...),
                       method='isotonic', n_jobs=None), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028B65B40790>, system=True)
2025-12-03 13:19:47,787:INFO:Checking exceptions
2025-12-03 13:19:47,799:INFO:Preloading libraries
2025-12-03 13:19:47,831:INFO:Copying training dataset
2025-12-03 13:19:47,831:INFO:Plot type: pr
2025-12-03 13:19:48,079:INFO:Fitting Model
2025-12-03 13:19:48,081:INFO:Scoring test/hold-out set
2025-12-03 13:19:48,428:INFO:Visual Rendered Successfully
2025-12-03 13:19:48,589:INFO:plot_model() successfully completed......................................
2025-12-03 13:19:48,619:INFO:Initializing plot_model()
2025-12-03 13:19:48,619:INFO:plot_model(plot=confusion_matrix, fold=None, verbose=True, display=None, display_format=None, estimator=CalibratedClassifierCV(cv=5, ensemble=True,
                       estimator=XGBClassifier(base_score=None,
                                               booster='gbtree', callbacks=None,
                                               colsample_bylevel=None,
                                               colsample_bynode=None,
                                               colsample_bytree=None,
                                               device='cpu',
                                               early_stopping_rounds=None,
                                               enable_categorical=False,
                                               eval_metric=None,
                                               feature_types=None, gamma=None,
                                               grow_policy=None,
                                               importance_type=None,
                                               interaction_constraints=None,
                                               learning_rate=0.05, max_bin=None,
                                               max_cat_threshold=None,
                                               max_cat_to_onehot=None,
                                               max_delta_step=1, max_depth=5,
                                               max_leaves=None,
                                               min_child_weight=None,
                                               missing=nan,
                                               monotone_constraints=None,
                                               multi_strategy=None,
                                               n_estimators=100, n_jobs=1,
                                               num_parallel_tree=None,
                                               objective='binary:logistic', ...),
                       method='isotonic', n_jobs=None), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028B65B40790>, system=True)
2025-12-03 13:19:48,619:INFO:Checking exceptions
2025-12-03 13:19:48,633:INFO:Preloading libraries
2025-12-03 13:19:48,685:INFO:Copying training dataset
2025-12-03 13:19:48,685:INFO:Plot type: confusion_matrix
2025-12-03 13:19:48,933:INFO:Fitting Model
2025-12-03 13:19:48,934:INFO:Scoring test/hold-out set
2025-12-03 13:19:49,261:INFO:Visual Rendered Successfully
2025-12-03 13:19:49,427:INFO:plot_model() successfully completed......................................
2025-12-03 13:19:49,457:INFO:Initializing plot_model()
2025-12-03 13:19:49,457:INFO:plot_model(plot=error, fold=None, verbose=True, display=None, display_format=None, estimator=CalibratedClassifierCV(cv=5, ensemble=True,
                       estimator=XGBClassifier(base_score=None,
                                               booster='gbtree', callbacks=None,
                                               colsample_bylevel=None,
                                               colsample_bynode=None,
                                               colsample_bytree=None,
                                               device='cpu',
                                               early_stopping_rounds=None,
                                               enable_categorical=False,
                                               eval_metric=None,
                                               feature_types=None, gamma=None,
                                               grow_policy=None,
                                               importance_type=None,
                                               interaction_constraints=None,
                                               learning_rate=0.05, max_bin=None,
                                               max_cat_threshold=None,
                                               max_cat_to_onehot=None,
                                               max_delta_step=1, max_depth=5,
                                               max_leaves=None,
                                               min_child_weight=None,
                                               missing=nan,
                                               monotone_constraints=None,
                                               multi_strategy=None,
                                               n_estimators=100, n_jobs=1,
                                               num_parallel_tree=None,
                                               objective='binary:logistic', ...),
                       method='isotonic', n_jobs=None), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028B65B40790>, system=True)
2025-12-03 13:19:49,457:INFO:Checking exceptions
2025-12-03 13:19:49,471:INFO:Preloading libraries
2025-12-03 13:19:49,500:INFO:Copying training dataset
2025-12-03 13:19:49,500:INFO:Plot type: error
2025-12-03 13:19:49,733:INFO:Fitting Model
2025-12-03 13:19:49,734:INFO:Scoring test/hold-out set
2025-12-03 13:19:50,073:INFO:Visual Rendered Successfully
2025-12-03 13:19:50,263:INFO:plot_model() successfully completed......................................
2025-12-03 13:19:50,300:INFO:Initializing plot_model()
2025-12-03 13:19:50,301:INFO:plot_model(plot=calibration, fold=None, verbose=True, display=None, display_format=None, estimator=CalibratedClassifierCV(cv=5, ensemble=True,
                       estimator=XGBClassifier(base_score=None,
                                               booster='gbtree', callbacks=None,
                                               colsample_bylevel=None,
                                               colsample_bynode=None,
                                               colsample_bytree=None,
                                               device='cpu',
                                               early_stopping_rounds=None,
                                               enable_categorical=False,
                                               eval_metric=None,
                                               feature_types=None, gamma=None,
                                               grow_policy=None,
                                               importance_type=None,
                                               interaction_constraints=None,
                                               learning_rate=0.05, max_bin=None,
                                               max_cat_threshold=None,
                                               max_cat_to_onehot=None,
                                               max_delta_step=1, max_depth=5,
                                               max_leaves=None,
                                               min_child_weight=None,
                                               missing=nan,
                                               monotone_constraints=None,
                                               multi_strategy=None,
                                               n_estimators=100, n_jobs=1,
                                               num_parallel_tree=None,
                                               objective='binary:logistic', ...),
                       method='isotonic', n_jobs=None), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028B65B40790>, system=True)
2025-12-03 13:19:50,301:INFO:Checking exceptions
2025-12-03 13:19:50,315:INFO:Preloading libraries
2025-12-03 13:19:50,343:INFO:Copying training dataset
2025-12-03 13:19:50,343:INFO:Plot type: calibration
2025-12-03 13:19:50,354:INFO:Scoring test/hold-out set
2025-12-03 13:19:50,725:INFO:Visual Rendered Successfully
2025-12-03 13:19:50,887:INFO:plot_model() successfully completed......................................
2025-12-03 13:19:50,914:INFO:Initializing get_config()
2025-12-03 13:19:50,914:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028B65B40790>, variable=X_test_transformed)
2025-12-03 13:19:51,028:INFO:Variable: X_test returned as             Age  IncomeRatio  SystolicBP  WaistCircumference    Height  \
28456 -1.166682    -0.347193   -0.857495           -1.507527 -1.819875   
8993   0.143689     0.336722    1.662729            0.648015 -0.645962   
34312  0.028744     0.094199    0.120503            0.346962  0.583851   
4802  -1.235649     0.337285   -0.681087           -0.938256 -0.976048   
25895  0.028744     1.529936   -0.456265           -0.413678  0.081658   
...         ...          ...         ...                 ...       ...   
18045 -1.258638    -0.075567   -0.904070           -1.993226 -3.285713   
5425  -0.086201     0.470887    1.712883           -0.086555 -0.006211   
12819  0.235645     0.002041    0.478158            0.708225  1.515528   
33659 -1.212660     1.326217   -0.863547           -1.487456 -2.074533   
19531 -1.281627    -0.395697   -0.849048           -1.848720 -3.664595   

       TotalCholesterol  Triglycerides       LDL       HDL     HbA1c  ...  \
28456         -0.077253      -0.647020 -0.018927  0.563922 -0.617463  ...   
8993           0.702398       0.630424  0.004953  0.590479  0.121825  ...   
34312         -0.118546       0.874313 -0.747277 -1.115404  0.666895  ...   
4802          -0.178619      -0.486105  0.000596  0.050858 -0.563915  ...   
25895          0.819676       1.267174  0.006537 -0.056580 -0.314232  ...   
...                 ...            ...       ...       ...       ...  ...   
18045         -0.319533      -0.646830 -0.614729  0.541608 -0.630163  ...   
5425           0.397476      -0.206569  0.807814  0.296361 -0.096204  ...   
12819         -0.681479      -0.646225 -0.152735 -0.821286  0.121825  ...   
33659         -0.986401      -0.647239 -2.064660  0.296361 -0.699939  ...   
19531         -0.334260      -0.646844 -0.652171  0.541702 -0.458463  ...   

       Race_5.0  Race_1.0  Race_4.0  Race_3.0  Race_2.0  Education   Smoking  \
28456       1.0       0.0  0.000000 -0.147343       0.0  -0.020637 -0.322757   
8993        0.0       0.0  3.165789 -0.147343       0.0   0.527633  0.677243   
34312       0.0       0.0  0.000000  0.852657       0.0  -0.653648 -0.322757   
4802        1.0       0.0  0.000000 -0.147343       0.0   0.249169 -0.249145   
25895       0.0       0.0  0.000000  0.852657       0.0   1.118273 -0.322757   
...         ...       ...       ...       ...       ...        ...       ...   
18045       0.0       0.0  0.000000  0.852657       0.0  -0.784293 -0.322757   
5425        0.0       0.0  3.165789 -0.147343       0.0   0.527633  0.677243   
12819       0.0       0.0  0.000000  0.852657       0.0   1.118273  0.677243   
33659       0.0       0.0  3.165789 -0.147343       0.0   0.244733 -0.322757   
19531       1.0       0.0  0.000000 -0.147343       0.0  -0.811611 -0.322757   

       PhysicalActivity  HealthInsurance   Alcohol  
28456          0.867745              0.0 -0.852427  
8993           0.000000              0.0 -0.111403  
34312          0.000000              0.0  0.446044  
4802           1.329964              0.0 -0.367022  
25895          0.000000              0.0 -1.282459  
...                 ...              ...       ...  
18045          1.188011              0.0 -0.810481  
5425           2.099341              0.0 -0.131905  
12819          2.099341              0.0  0.470282  
33659          1.527044              0.0 -0.426709  
19531          1.039465              0.0 -1.044925  

[13109 rows x 30 columns]
2025-12-03 13:19:51,028:INFO:get_config() successfully completed......................................
2025-12-03 13:19:51,029:INFO:Initializing get_config()
2025-12-03 13:19:51,029:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028B65B40790>, variable=y_test)
2025-12-03 13:19:51,029:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-12-03 13:19:51,029:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-12-03 13:19:51,033:INFO:Variable:  returned as 28456    0.0
8993     0.0
34312    0.0
4802     0.0
25895    0.0
        ... 
18045    0.0
5425     0.0
12819    0.0
33659    0.0
19531    0.0
Name: HeartDisease, Length: 13109, dtype: float32
2025-12-03 13:19:51,033:INFO:get_config() successfully completed......................................
2025-12-03 13:19:52,173:INFO:Initializing finalize_model()
2025-12-03 13:19:52,173:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028B65B40790>, estimator=CalibratedClassifierCV(cv=5, ensemble=True,
                       estimator=XGBClassifier(base_score=None,
                                               booster='gbtree', callbacks=None,
                                               colsample_bylevel=None,
                                               colsample_bynode=None,
                                               colsample_bytree=None,
                                               device='cpu',
                                               early_stopping_rounds=None,
                                               enable_categorical=False,
                                               eval_metric=None,
                                               feature_types=None, gamma=None,
                                               grow_policy=None,
                                               importance_type=None,
                                               interaction_constraints=None,
                                               learning_rate=0.05, max_bin=None,
                                               max_cat_threshold=None,
                                               max_cat_to_onehot=None,
                                               max_delta_step=1, max_depth=5,
                                               max_leaves=None,
                                               min_child_weight=None,
                                               missing=nan,
                                               monotone_constraints=None,
                                               multi_strategy=None,
                                               n_estimators=100, n_jobs=1,
                                               num_parallel_tree=None,
                                               objective='binary:logistic', ...),
                       method='isotonic', n_jobs=None), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2025-12-03 13:19:52,175:INFO:Finalizing CalibratedClassifierCV(cv=5, ensemble=True,
                       estimator=XGBClassifier(base_score=None,
                                               booster='gbtree', callbacks=None,
                                               colsample_bylevel=None,
                                               colsample_bynode=None,
                                               colsample_bytree=None,
                                               device='cpu',
                                               early_stopping_rounds=None,
                                               enable_categorical=False,
                                               eval_metric=None,
                                               feature_types=None, gamma=None,
                                               grow_policy=None,
                                               importance_type=None,
                                               interaction_constraints=None,
                                               learning_rate=0.05, max_bin=None,
                                               max_cat_threshold=None,
                                               max_cat_to_onehot=None,
                                               max_delta_step=1, max_depth=5,
                                               max_leaves=None,
                                               min_child_weight=None,
                                               missing=nan,
                                               monotone_constraints=None,
                                               multi_strategy=None,
                                               n_estimators=100, n_jobs=1,
                                               num_parallel_tree=None,
                                               objective='binary:logistic', ...),
                       method='isotonic', n_jobs=None)
2025-12-03 13:19:52,194:INFO:Initializing create_model()
2025-12-03 13:19:52,194:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028B65B40790>, estimator=CalibratedClassifierCV(cv=5, ensemble=True,
                       estimator=XGBClassifier(base_score=None,
                                               booster='gbtree', callbacks=None,
                                               colsample_bylevel=None,
                                               colsample_bynode=None,
                                               colsample_bytree=None,
                                               device='cpu',
                                               early_stopping_rounds=None,
                                               enable_categorical=False,
                                               eval_metric=None,
                                               feature_types=None, gamma=None,
                                               grow_policy=None,
                                               importance_type=None,
                                               interaction_constraints=None,
                                               learning_rate=0.05, max_bin=None,
                                               max_cat_threshold=None,
                                               max_cat_to_onehot=None,
                                               max_delta_step=1, max_depth=5,
                                               max_leaves=None,
                                               min_child_weight=None,
                                               missing=nan,
                                               monotone_constraints=None,
                                               multi_strategy=None,
                                               n_estimators=100, n_jobs=1,
                                               num_parallel_tree=None,
                                               objective='binary:logistic', ...),
                       method='isotonic', n_jobs=None), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2025-12-03 13:19:52,196:INFO:Checking exceptions
2025-12-03 13:19:52,196:INFO:Importing libraries
2025-12-03 13:19:52,196:INFO:Copying training dataset
2025-12-03 13:19:52,196:INFO:Defining folds
2025-12-03 13:19:52,196:INFO:Declaring metric variables
2025-12-03 13:19:52,196:INFO:Importing untrained model
2025-12-03 13:19:52,196:INFO:Declaring custom model
2025-12-03 13:19:52,201:INFO:Extreme Gradient Boosting Imported successfully
2025-12-03 13:19:52,203:INFO:Cross validation set to False
2025-12-03 13:19:52,203:INFO:Fitting Model
2025-12-03 13:19:52,298:INFO:Warning: No categorical columns found. Calling 'transform' will only return input data.
2025-12-03 13:19:57,064:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'IncomeRatio', 'SystolicBP',
                                             'BMI', 'WaistCircumference',
                                             'Height', 'TotalCholesterol',
                                             'Triglycerides', 'LDL', 'HDL',
                                             'HbA1c', 'Glucose', 'Creatinine',
                                             'UricAcid', 'ALT_Enzyme',
                                             'Albumin', 'Potassium', 'Sodium',
                                             'GGT_Enzyme', 'AST_Enzyme'],
                                    transformer=Si...
                                                                interaction_constraints=None,
                                                                learning_rate=0.05,
                                                                max_bin=None,
                                                                max_cat_threshold=None,
                                                                max_cat_to_onehot=None,
                                                                max_delta_step=1,
                                                                max_depth=5,
                                                                max_leaves=None,
                                                                min_child_weight=None,
                                                                missing=nan,
                                                                monotone_constraints=None,
                                                                multi_strategy=None,
                                                                n_estimators=100,
                                                                n_jobs=1,
                                                                num_parallel_tree=None,
                                                                objective='binary:logistic', ...),
                                        method='isotonic', n_jobs=None))],
         verbose=False)
2025-12-03 13:19:57,064:INFO:create_model() successfully completed......................................
2025-12-03 13:19:57,231:INFO:_master_model_container: 4
2025-12-03 13:19:57,232:INFO:_display_container: 4
2025-12-03 13:19:57,254:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'IncomeRatio', 'SystolicBP',
                                             'BMI', 'WaistCircumference',
                                             'Height', 'TotalCholesterol',
                                             'Triglycerides', 'LDL', 'HDL',
                                             'HbA1c', 'Glucose', 'Creatinine',
                                             'UricAcid', 'ALT_Enzyme',
                                             'Albumin', 'Potassium', 'Sodium',
                                             'GGT_Enzyme', 'AST_Enzyme'],
                                    transformer=Si...
                                                                interaction_constraints=None,
                                                                learning_rate=0.05,
                                                                max_bin=None,
                                                                max_cat_threshold=None,
                                                                max_cat_to_onehot=None,
                                                                max_delta_step=1,
                                                                max_depth=5,
                                                                max_leaves=None,
                                                                min_child_weight=None,
                                                                missing=nan,
                                                                monotone_constraints=None,
                                                                multi_strategy=None,
                                                                n_estimators=100,
                                                                n_jobs=1,
                                                                num_parallel_tree=None,
                                                                objective='binary:logistic', ...),
                                        method='isotonic', n_jobs=None))],
         verbose=False)
2025-12-03 13:19:57,254:INFO:finalize_model() successfully completed......................................
2025-12-03 13:19:57,458:INFO:Initializing save_model()
2025-12-03 13:19:57,458:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'IncomeRatio', 'SystolicBP',
                                             'BMI', 'WaistCircumference',
                                             'Height', 'TotalCholesterol',
                                             'Triglycerides', 'LDL', 'HDL',
                                             'HbA1c', 'Glucose', 'Creatinine',
                                             'UricAcid', 'ALT_Enzyme',
                                             'Albumin', 'Potassium', 'Sodium',
                                             'GGT_Enzyme', 'AST_Enzyme'],
                                    transformer=Si...
                                                                interaction_constraints=None,
                                                                learning_rate=0.05,
                                                                max_bin=None,
                                                                max_cat_threshold=None,
                                                                max_cat_to_onehot=None,
                                                                max_delta_step=1,
                                                                max_depth=5,
                                                                max_leaves=None,
                                                                min_child_weight=None,
                                                                missing=nan,
                                                                monotone_constraints=None,
                                                                multi_strategy=None,
                                                                n_estimators=100,
                                                                n_jobs=1,
                                                                num_parallel_tree=None,
                                                                objective='binary:logistic', ...),
                                        method='isotonic', n_jobs=None))],
         verbose=False), model_name=../models\best_pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\OMAR\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'IncomeRatio', 'SystolicBP',
                                             'BMI', 'WaistCircumference',
                                             'Height', 'TotalCholesterol',
                                             'Triglycerides', 'LDL', 'HDL',
                                             'HbA1c', 'Glucose', 'Creatinine',
                                             'UricAcid', 'ALT_Enzyme',
                                             'Albumin', 'Potassium', 'Sodium',
                                             'G...
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              random_state=42,
                                                                              sampling_strategy='auto')))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=RobustScaler(copy=True,
                                                             quantile_range=(25.0,
                                                                             75.0),
                                                             unit_variance=False,
                                                             with_centering=True,
                                                             with_scaling=True)))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2025-12-03 13:19:57,458:INFO:Adding model into prep_pipe
2025-12-03 13:19:57,458:WARNING:Only Model saved as it was a pipeline.
2025-12-03 13:19:57,472:INFO:../models\best_pipeline.pkl saved in current working directory
2025-12-03 13:19:57,491:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'IncomeRatio', 'SystolicBP',
                                             'BMI', 'WaistCircumference',
                                             'Height', 'TotalCholesterol',
                                             'Triglycerides', 'LDL', 'HDL',
                                             'HbA1c', 'Glucose', 'Creatinine',
                                             'UricAcid', 'ALT_Enzyme',
                                             'Albumin', 'Potassium', 'Sodium',
                                             'GGT_Enzyme', 'AST_Enzyme'],
                                    transformer=Si...
                                                                interaction_constraints=None,
                                                                learning_rate=0.05,
                                                                max_bin=None,
                                                                max_cat_threshold=None,
                                                                max_cat_to_onehot=None,
                                                                max_delta_step=1,
                                                                max_depth=5,
                                                                max_leaves=None,
                                                                min_child_weight=None,
                                                                missing=nan,
                                                                monotone_constraints=None,
                                                                multi_strategy=None,
                                                                n_estimators=100,
                                                                n_jobs=1,
                                                                num_parallel_tree=None,
                                                                objective='binary:logistic', ...),
                                        method='isotonic', n_jobs=None))],
         verbose=False)
2025-12-03 13:19:57,491:INFO:save_model() successfully completed......................................
2025-12-03 13:21:36,419:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-12-03 13:21:36,419:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-12-03 13:21:36,419:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-12-03 13:21:36,419:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-12-03 13:21:38,233:INFO:PyCaret ClassificationExperiment
2025-12-03 13:21:38,234:INFO:Logging name: clf-default-name
2025-12-03 13:21:38,234:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-12-03 13:21:38,234:INFO:version 3.3.2
2025-12-03 13:21:38,234:INFO:Initializing setup()
2025-12-03 13:21:38,234:INFO:self.USI: 134b
2025-12-03 13:21:38,234:INFO:self._variable_keys: {'fix_imbalance', 'X_train', 'memory', 'X', 'exp_name_log', 'seed', '_available_plots', 'pipeline', 'fold_shuffle_param', 'exp_id', 'USI', 'gpu_param', 'html_param', 'logging_param', 'fold_groups_param', 'data', 'y', 'X_test', 'is_multiclass', 'y_test', 'fold_generator', 'log_plots_param', 'gpu_n_jobs_param', 'idx', 'y_train', 'target_param', 'n_jobs_param', '_ml_usecase'}
2025-12-03 13:21:38,234:INFO:Checking environment
2025-12-03 13:21:38,234:INFO:python_version: 3.10.19
2025-12-03 13:21:38,235:INFO:python_build: ('main', 'Oct 21 2025 16:41:31')
2025-12-03 13:21:38,235:INFO:machine: AMD64
2025-12-03 13:21:38,235:INFO:platform: Windows-10-10.0.26100-SP0
2025-12-03 13:21:38,235:INFO:Memory: svmem(total=16282144768, available=4149092352, percent=74.5, used=12133052416, free=4149092352)
2025-12-03 13:21:38,235:INFO:Physical Core: 6
2025-12-03 13:21:38,235:INFO:Logical Core: 12
2025-12-03 13:21:38,235:INFO:Checking libraries
2025-12-03 13:21:38,235:INFO:System:
2025-12-03 13:21:38,235:INFO:    python: 3.10.19 | packaged by Anaconda, Inc. | (main, Oct 21 2025, 16:41:31) [MSC v.1929 64 bit (AMD64)]
2025-12-03 13:21:38,235:INFO:executable: c:\Users\OMAR\miniconda3\envs\xgb_env\python.exe
2025-12-03 13:21:38,235:INFO:   machine: Windows-10-10.0.26100-SP0
2025-12-03 13:21:38,235:INFO:PyCaret required dependencies:
2025-12-03 13:21:38,236:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-03 13:21:38,876:INFO:                 pip: 25.3
2025-12-03 13:21:38,876:INFO:          setuptools: 80.9.0
2025-12-03 13:21:38,876:INFO:             pycaret: 3.3.2
2025-12-03 13:21:38,876:INFO:             IPython: 8.37.0
2025-12-03 13:21:38,876:INFO:          ipywidgets: 8.1.8
2025-12-03 13:21:38,876:INFO:                tqdm: 4.67.1
2025-12-03 13:21:38,876:INFO:               numpy: 1.26.4
2025-12-03 13:21:38,876:INFO:              pandas: 2.1.4
2025-12-03 13:21:38,876:INFO:              jinja2: 3.1.6
2025-12-03 13:21:38,876:INFO:               scipy: 1.11.4
2025-12-03 13:21:38,876:INFO:              joblib: 1.3.2
2025-12-03 13:21:38,876:INFO:             sklearn: 1.4.2
2025-12-03 13:21:38,876:INFO:                pyod: 2.0.5
2025-12-03 13:21:38,876:INFO:            imblearn: 0.14.0
2025-12-03 13:21:38,876:INFO:   category_encoders: 2.7.0
2025-12-03 13:21:38,876:INFO:            lightgbm: 4.6.0
2025-12-03 13:21:38,876:INFO:               numba: 0.62.1
2025-12-03 13:21:38,876:INFO:            requests: 2.32.5
2025-12-03 13:21:38,876:INFO:          matplotlib: 3.7.5
2025-12-03 13:21:38,876:INFO:          scikitplot: 0.3.7
2025-12-03 13:21:38,876:INFO:         yellowbrick: 1.5
2025-12-03 13:21:38,876:INFO:              plotly: 5.24.1
2025-12-03 13:21:38,876:INFO:    plotly-resampler: Not installed
2025-12-03 13:21:38,876:INFO:             kaleido: 1.2.0
2025-12-03 13:21:38,876:INFO:           schemdraw: 0.15
2025-12-03 13:21:38,876:INFO:         statsmodels: 0.14.5
2025-12-03 13:21:38,876:INFO:              sktime: 0.26.0
2025-12-03 13:21:38,876:INFO:               tbats: 1.1.3
2025-12-03 13:21:38,876:INFO:            pmdarima: 2.0.4
2025-12-03 13:21:38,876:INFO:              psutil: 7.1.3
2025-12-03 13:21:38,876:INFO:          markupsafe: 3.0.3
2025-12-03 13:21:38,876:INFO:             pickle5: Not installed
2025-12-03 13:21:38,876:INFO:         cloudpickle: 3.1.2
2025-12-03 13:21:38,876:INFO:         deprecation: 2.1.0
2025-12-03 13:21:38,876:INFO:              xxhash: 3.6.0
2025-12-03 13:21:38,876:INFO:           wurlitzer: Not installed
2025-12-03 13:21:38,876:INFO:PyCaret optional dependencies:
2025-12-03 13:21:41,807:INFO:                shap: 0.49.1
2025-12-03 13:21:41,807:INFO:           interpret: 0.7.3
2025-12-03 13:21:41,807:INFO:                umap: 0.5.7
2025-12-03 13:21:41,811:INFO:     ydata_profiling: 4.18.0
2025-12-03 13:21:41,811:INFO:  explainerdashboard: 0.5.1
2025-12-03 13:21:41,811:INFO:             autoviz: Not installed
2025-12-03 13:21:41,811:INFO:           fairlearn: 0.7.0
2025-12-03 13:21:41,811:INFO:          deepchecks: Not installed
2025-12-03 13:21:41,811:INFO:             xgboost: 2.1.3
2025-12-03 13:21:41,811:INFO:            catboost: 1.2.8
2025-12-03 13:21:41,811:INFO:              kmodes: 0.12.2
2025-12-03 13:21:41,811:INFO:             mlxtend: 0.23.4
2025-12-03 13:21:41,811:INFO:       statsforecast: 1.5.0
2025-12-03 13:21:41,811:INFO:        tune_sklearn: Not installed
2025-12-03 13:21:41,811:INFO:                 ray: Not installed
2025-12-03 13:21:41,811:INFO:            hyperopt: 0.2.7
2025-12-03 13:21:41,811:INFO:              optuna: 4.6.0
2025-12-03 13:21:41,811:INFO:               skopt: 0.10.2
2025-12-03 13:21:41,811:INFO:              mlflow: 3.6.0
2025-12-03 13:21:41,811:INFO:              gradio: 6.0.1
2025-12-03 13:21:41,811:INFO:             fastapi: 0.123.0
2025-12-03 13:21:41,811:INFO:             uvicorn: 0.38.0
2025-12-03 13:21:41,811:INFO:              m2cgen: 0.10.0
2025-12-03 13:21:41,811:INFO:           evidently: 0.4.40
2025-12-03 13:21:41,811:INFO:               fugue: 0.8.7
2025-12-03 13:21:41,811:INFO:           streamlit: 1.51.0
2025-12-03 13:21:41,811:INFO:             prophet: Not installed
2025-12-03 13:21:41,811:INFO:None
2025-12-03 13:21:41,811:INFO:Set up data.
2025-12-03 13:21:41,827:INFO:Set up folding strategy.
2025-12-03 13:21:41,827:INFO:Set up train/test split.
2025-12-03 13:21:41,849:INFO:Set up index.
2025-12-03 13:21:41,851:INFO:Assigning column types.
2025-12-03 13:21:41,871:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-12-03 13:21:41,896:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-12-03 13:21:41,900:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-03 13:21:41,925:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-03 13:21:41,926:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-03 13:21:41,969:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-12-03 13:21:41,972:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-03 13:21:41,987:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-03 13:21:41,987:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-03 13:21:41,987:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-12-03 13:21:42,017:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-03 13:21:42,035:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-03 13:21:42,037:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-03 13:21:42,068:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-03 13:21:42,088:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-03 13:21:42,089:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-03 13:21:42,090:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-12-03 13:21:42,133:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-03 13:21:42,134:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-03 13:21:42,177:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-03 13:21:42,179:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-03 13:21:42,181:INFO:Preparing preprocessing pipeline...
2025-12-03 13:21:42,185:INFO:Set up simple imputation.
2025-12-03 13:21:42,196:INFO:Set up encoding of ordinal features.
2025-12-03 13:21:42,205:INFO:Set up encoding of categorical features.
2025-12-03 13:21:42,205:INFO:Set up removing multicollinearity.
2025-12-03 13:21:42,205:INFO:Set up imbalanced handling.
2025-12-03 13:21:42,206:INFO:Set up feature normalization.
2025-12-03 13:21:42,429:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\joblib\externals\loky\backend\context.py:136: UserWarning: Could not find the number of physical cores for the following reason:
[WinError 2] El sistema no puede encontrar el archivo especificado
Returning the number of logical cores instead. You can silence this warning by setting LOKY_MAX_CPU_COUNT to the number of cores you want to use.

2025-12-03 13:21:42,562:INFO:Finished creating preprocessing pipeline.
2025-12-03 13:21:42,579:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\OMAR\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'IncomeRatio', 'SystolicBP',
                                             'BMI', 'WaistCircumference',
                                             'Height', 'TotalCholesterol',
                                             'Triglycerides', 'LDL', 'HDL',
                                             'HbA1c', 'Glucose', 'Creatinine',
                                             'UricAcid', 'ALT_Enzyme',
                                             'Albumin', 'Potassium', 'Sodium',
                                             'G...
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              random_state=42,
                                                                              sampling_strategy='auto')))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=RobustScaler(copy=True,
                                                             quantile_range=(25.0,
                                                                             75.0),
                                                             unit_variance=False,
                                                             with_centering=True,
                                                             with_scaling=True)))],
         verbose=False)
2025-12-03 13:21:42,579:INFO:Creating final display dataframe.
2025-12-03 13:21:42,815:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target      HeartDisease
2                   Target type            Binary
3           Original data shape       (43695, 28)
4        Transformed data shape       (72719, 31)
5   Transformed train set shape       (59610, 31)
6    Transformed test set shape       (13109, 31)
7              Numeric features                20
8          Categorical features                 7
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15     Remove multicollinearity              True
16  Multicollinearity threshold               0.9
17                Fix imbalance              True
18         Fix imbalance method             SMOTE
19                    Normalize              True
20             Normalize method            robust
21               Fold Generator   StratifiedKFold
22                  Fold Number                10
23                     CPU Jobs                 1
24                      Use GPU             False
25               Log Experiment             False
26              Experiment Name  clf-default-name
27                          USI              134b
2025-12-03 13:21:42,874:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-03 13:21:42,876:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-03 13:21:42,919:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-03 13:21:42,920:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-03 13:21:42,922:INFO:setup() successfully completed in 4.71s...............
2025-12-03 13:21:43,047:INFO:Initializing create_model()
2025-12-03 13:21:43,048:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002532F1126B0>, estimator=xgboost, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-03 13:21:43,048:INFO:Checking exceptions
2025-12-03 13:21:43,050:INFO:Importing libraries
2025-12-03 13:21:43,050:INFO:Copying training dataset
2025-12-03 13:21:43,089:INFO:Defining folds
2025-12-03 13:21:43,089:INFO:Declaring metric variables
2025-12-03 13:21:43,089:INFO:Importing untrained model
2025-12-03 13:21:43,091:INFO:Extreme Gradient Boosting Imported successfully
2025-12-03 13:21:43,091:INFO:Starting cross validation
2025-12-03 13:21:43,094:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-12-03 13:21:54,591:INFO:Calculating mean and std
2025-12-03 13:21:54,591:INFO:Creating metrics dataframe
2025-12-03 13:21:54,592:INFO:Finalizing model
2025-12-03 13:21:54,678:INFO:Warning: No categorical columns found. Calling 'transform' will only return input data.
2025-12-03 13:21:55,778:INFO:Uploading results into container
2025-12-03 13:21:55,779:INFO:Uploading model into container now
2025-12-03 13:21:55,779:INFO:_master_model_container: 1
2025-12-03 13:21:55,779:INFO:_display_container: 2
2025-12-03 13:21:55,780:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2025-12-03 13:21:55,780:INFO:create_model() successfully completed......................................
2025-12-03 13:21:55,964:INFO:Initializing tune_model()
2025-12-03 13:21:55,964:INFO:tune_model(estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...), fold=None, round=4, n_iter=20, custom_grid={'learning_rate': [0.05, 0.1], 'n_estimators': [100, 200], 'max_depth': [3, 5], 'scale_pos_weight': [38.153225806451616, 57.22983870967742], 'max_delta_step': [1]}, optimize=Recall, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002532F1126B0>)
2025-12-03 13:21:55,964:INFO:Checking exceptions
2025-12-03 13:21:55,996:INFO:Copying training dataset
2025-12-03 13:21:56,023:INFO:Checking base model
2025-12-03 13:21:56,023:INFO:Base model : Extreme Gradient Boosting
2025-12-03 13:21:56,028:INFO:Declaring metric variables
2025-12-03 13:21:56,031:INFO:Defining Hyperparameters
2025-12-03 13:21:56,210:INFO:custom_grid: {'actual_estimator__learning_rate': [0.05, 0.1], 'actual_estimator__n_estimators': [100, 200], 'actual_estimator__max_depth': [3, 5], 'actual_estimator__scale_pos_weight': [38.153225806451616, 57.22983870967742], 'actual_estimator__max_delta_step': [1]}
2025-12-03 13:21:56,211:INFO:Tuning with n_jobs=1
2025-12-03 13:21:56,211:INFO:Initializing RandomizedSearchCV
2025-12-03 13:21:56,213:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\model_selection\_search.py:318: UserWarning: The total space of parameters 16 is smaller than n_iter=20. Running 16 iterations. For exhaustive searches, use GridSearchCV.

2025-12-03 13:24:51,252:INFO:best_params: {'actual_estimator__scale_pos_weight': 57.22983870967742, 'actual_estimator__n_estimators': 100, 'actual_estimator__max_depth': 3, 'actual_estimator__max_delta_step': 1, 'actual_estimator__learning_rate': 0.05}
2025-12-03 13:24:51,254:INFO:Hyperparameter search completed
2025-12-03 13:24:51,254:INFO:SubProcess create_model() called ==================================
2025-12-03 13:24:51,255:INFO:Initializing create_model()
2025-12-03 13:24:51,255:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002532F1126B0>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000253346F50C0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'scale_pos_weight': 57.22983870967742, 'n_estimators': 100, 'max_depth': 3, 'max_delta_step': 1, 'learning_rate': 0.05})
2025-12-03 13:24:51,256:INFO:Checking exceptions
2025-12-03 13:24:51,256:INFO:Importing libraries
2025-12-03 13:24:51,256:INFO:Copying training dataset
2025-12-03 13:24:51,288:INFO:Defining folds
2025-12-03 13:24:51,288:INFO:Declaring metric variables
2025-12-03 13:24:51,291:INFO:Importing untrained model
2025-12-03 13:24:51,291:INFO:Declaring custom model
2025-12-03 13:24:51,296:INFO:Extreme Gradient Boosting Imported successfully
2025-12-03 13:24:51,301:INFO:Starting cross validation
2025-12-03 13:24:51,304:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-12-03 13:24:59,110:INFO:Calculating mean and std
2025-12-03 13:24:59,111:INFO:Creating metrics dataframe
2025-12-03 13:24:59,117:INFO:Finalizing model
2025-12-03 13:24:59,229:INFO:Warning: No categorical columns found. Calling 'transform' will only return input data.
2025-12-03 13:24:59,946:INFO:Uploading results into container
2025-12-03 13:24:59,947:INFO:Uploading model into container now
2025-12-03 13:24:59,948:INFO:_master_model_container: 2
2025-12-03 13:24:59,948:INFO:_display_container: 3
2025-12-03 13:24:59,949:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=0.05, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None, max_delta_step=1,
              max_depth=3, max_leaves=None, min_child_weight=None, missing=nan,
              monotone_constraints=None, multi_strategy=None, n_estimators=100,
              n_jobs=1, num_parallel_tree=None, objective='binary:logistic', ...)
2025-12-03 13:24:59,949:INFO:create_model() successfully completed......................................
2025-12-03 13:25:00,131:INFO:SubProcess create_model() end ==================================
2025-12-03 13:25:00,131:INFO:choose_better activated
2025-12-03 13:25:00,136:INFO:SubProcess create_model() called ==================================
2025-12-03 13:25:00,137:INFO:Initializing create_model()
2025-12-03 13:25:00,137:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002532F1126B0>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-03 13:25:00,137:INFO:Checking exceptions
2025-12-03 13:25:00,139:INFO:Importing libraries
2025-12-03 13:25:00,139:INFO:Copying training dataset
2025-12-03 13:25:00,165:INFO:Defining folds
2025-12-03 13:25:00,165:INFO:Declaring metric variables
2025-12-03 13:25:00,166:INFO:Importing untrained model
2025-12-03 13:25:00,166:INFO:Declaring custom model
2025-12-03 13:25:00,167:INFO:Extreme Gradient Boosting Imported successfully
2025-12-03 13:25:00,168:INFO:Starting cross validation
2025-12-03 13:25:00,169:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-12-03 13:25:11,148:INFO:Calculating mean and std
2025-12-03 13:25:11,148:INFO:Creating metrics dataframe
2025-12-03 13:25:11,148:INFO:Finalizing model
2025-12-03 13:25:11,223:INFO:Warning: No categorical columns found. Calling 'transform' will only return input data.
2025-12-03 13:25:12,261:INFO:Uploading results into container
2025-12-03 13:25:12,262:INFO:Uploading model into container now
2025-12-03 13:25:12,262:INFO:_master_model_container: 3
2025-12-03 13:25:12,262:INFO:_display_container: 4
2025-12-03 13:25:12,263:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2025-12-03 13:25:12,263:INFO:create_model() successfully completed......................................
2025-12-03 13:25:12,438:INFO:SubProcess create_model() end ==================================
2025-12-03 13:25:12,438:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...) result for Recall is 0.1344
2025-12-03 13:25:12,440:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=0.05, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None, max_delta_step=1,
              max_depth=3, max_leaves=None, min_child_weight=None, missing=nan,
              monotone_constraints=None, multi_strategy=None, n_estimators=100,
              n_jobs=1, num_parallel_tree=None, objective='binary:logistic', ...) result for Recall is 0.9859
2025-12-03 13:25:12,440:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=0.05, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None, max_delta_step=1,
              max_depth=3, max_leaves=None, min_child_weight=None, missing=nan,
              monotone_constraints=None, multi_strategy=None, n_estimators=100,
              n_jobs=1, num_parallel_tree=None, objective='binary:logistic', ...) is best model
2025-12-03 13:25:12,440:INFO:choose_better completed
2025-12-03 13:25:12,446:INFO:_master_model_container: 3
2025-12-03 13:25:12,446:INFO:_display_container: 3
2025-12-03 13:25:12,446:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=0.05, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None, max_delta_step=1,
              max_depth=3, max_leaves=None, min_child_weight=None, missing=nan,
              monotone_constraints=None, multi_strategy=None, n_estimators=100,
              n_jobs=1, num_parallel_tree=None, objective='binary:logistic', ...)
2025-12-03 13:25:12,446:INFO:tune_model() successfully completed......................................
2025-12-03 13:25:12,694:INFO:Initializing calibrate_model()
2025-12-03 13:25:12,694:INFO:calibrate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002532F1126B0>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=0.05, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None, max_delta_step=1,
              max_depth=3, max_leaves=None, min_child_weight=None, missing=nan,
              monotone_constraints=None, multi_strategy=None, n_estimators=100,
              n_jobs=1, num_parallel_tree=None, objective='binary:logistic', ...), method=isotonic, calibrate_fold=5, fold=None, round=4, fit_kwargs=None, groups=None, verbose=True, return_train_score=False)
2025-12-03 13:25:12,694:INFO:Checking exceptions
2025-12-03 13:25:12,708:INFO:Preloading libraries
2025-12-03 13:25:12,708:INFO:Preparing display monitor
2025-12-03 13:25:12,719:INFO:Getting model name
2025-12-03 13:25:12,722:INFO:Base model : Extreme Gradient Boosting
2025-12-03 13:25:12,729:INFO:Importing untrained CalibratedClassifierCV
2025-12-03 13:25:12,729:INFO:SubProcess create_model() called ==================================
2025-12-03 13:25:12,732:INFO:Initializing create_model()
2025-12-03 13:25:12,732:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002532F1126B0>, estimator=CalibratedClassifierCV(cv=5, ensemble=True,
                       estimator=XGBClassifier(base_score=None,
                                               booster='gbtree', callbacks=None,
                                               colsample_bylevel=None,
                                               colsample_bynode=None,
                                               colsample_bytree=None,
                                               device='cpu',
                                               early_stopping_rounds=None,
                                               enable_categorical=False,
                                               eval_metric=None,
                                               feature_types=None, gamma=None,
                                               grow_policy=None,
                                               importance_type=None,
                                               interaction_constraints=None,
                                               learning_rate=0.05, max_bin=None,
                                               max_cat_threshold=None,
                                               max_cat_to_onehot=None,
                                               max_delta_step=1, max_depth=3,
                                               max_leaves=None,
                                               min_child_weight=None,
                                               missing=nan,
                                               monotone_constraints=None,
                                               multi_strategy=None,
                                               n_estimators=100, n_jobs=1,
                                               num_parallel_tree=None,
                                               objective='binary:logistic', ...),
                       method='isotonic', n_jobs=None), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002532C6CAF50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-03 13:25:12,732:INFO:Checking exceptions
2025-12-03 13:25:12,732:INFO:Importing libraries
2025-12-03 13:25:12,732:INFO:Copying training dataset
2025-12-03 13:25:12,766:INFO:Defining folds
2025-12-03 13:25:12,766:INFO:Declaring metric variables
2025-12-03 13:25:12,770:INFO:Importing untrained model
2025-12-03 13:25:12,770:INFO:Declaring custom model
2025-12-03 13:25:12,776:INFO:Extreme Gradient Boosting Imported successfully
2025-12-03 13:25:12,783:INFO:Starting cross validation
2025-12-03 13:25:12,785:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-12-03 13:25:37,000:INFO:Calculating mean and std
2025-12-03 13:25:37,001:INFO:Creating metrics dataframe
2025-12-03 13:25:37,008:INFO:Finalizing model
2025-12-03 13:25:37,107:INFO:Warning: No categorical columns found. Calling 'transform' will only return input data.
2025-12-03 13:25:39,563:INFO:Uploading results into container
2025-12-03 13:25:39,565:INFO:Uploading model into container now
2025-12-03 13:25:39,565:INFO:_master_model_container: 4
2025-12-03 13:25:39,565:INFO:_display_container: 4
2025-12-03 13:25:39,568:INFO:CalibratedClassifierCV(cv=5, ensemble=True,
                       estimator=XGBClassifier(base_score=None,
                                               booster='gbtree', callbacks=None,
                                               colsample_bylevel=None,
                                               colsample_bynode=None,
                                               colsample_bytree=None,
                                               device='cpu',
                                               early_stopping_rounds=None,
                                               enable_categorical=False,
                                               eval_metric=None,
                                               feature_types=None, gamma=None,
                                               grow_policy=None,
                                               importance_type=None,
                                               interaction_constraints=None,
                                               learning_rate=0.05, max_bin=None,
                                               max_cat_threshold=None,
                                               max_cat_to_onehot=None,
                                               max_delta_step=1, max_depth=3,
                                               max_leaves=None,
                                               min_child_weight=None,
                                               missing=nan,
                                               monotone_constraints=None,
                                               multi_strategy=None,
                                               n_estimators=100, n_jobs=1,
                                               num_parallel_tree=None,
                                               objective='binary:logistic', ...),
                       method='isotonic', n_jobs=None)
2025-12-03 13:25:39,568:INFO:create_model() successfully completed......................................
2025-12-03 13:25:39,731:INFO:SubProcess create_model() end ==================================
2025-12-03 13:25:39,746:INFO:_master_model_container: 4
2025-12-03 13:25:39,746:INFO:_display_container: 4
2025-12-03 13:25:39,746:INFO:CalibratedClassifierCV(cv=5, ensemble=True,
                       estimator=XGBClassifier(base_score=None,
                                               booster='gbtree', callbacks=None,
                                               colsample_bylevel=None,
                                               colsample_bynode=None,
                                               colsample_bytree=None,
                                               device='cpu',
                                               early_stopping_rounds=None,
                                               enable_categorical=False,
                                               eval_metric=None,
                                               feature_types=None, gamma=None,
                                               grow_policy=None,
                                               importance_type=None,
                                               interaction_constraints=None,
                                               learning_rate=0.05, max_bin=None,
                                               max_cat_threshold=None,
                                               max_cat_to_onehot=None,
                                               max_delta_step=1, max_depth=3,
                                               max_leaves=None,
                                               min_child_weight=None,
                                               missing=nan,
                                               monotone_constraints=None,
                                               multi_strategy=None,
                                               n_estimators=100, n_jobs=1,
                                               num_parallel_tree=None,
                                               objective='binary:logistic', ...),
                       method='isotonic', n_jobs=None)
2025-12-03 13:25:39,746:INFO:calibrate_model() successfully completed......................................
2025-12-03 13:25:39,970:INFO:Initializing plot_model()
2025-12-03 13:25:39,970:INFO:plot_model(plot=auc, fold=None, verbose=True, display=None, display_format=None, estimator=CalibratedClassifierCV(cv=5, ensemble=True,
                       estimator=XGBClassifier(base_score=None,
                                               booster='gbtree', callbacks=None,
                                               colsample_bylevel=None,
                                               colsample_bynode=None,
                                               colsample_bytree=None,
                                               device='cpu',
                                               early_stopping_rounds=None,
                                               enable_categorical=False,
                                               eval_metric=None,
                                               feature_types=None, gamma=None,
                                               grow_policy=None,
                                               importance_type=None,
                                               interaction_constraints=None,
                                               learning_rate=0.05, max_bin=None,
                                               max_cat_threshold=None,
                                               max_cat_to_onehot=None,
                                               max_delta_step=1, max_depth=3,
                                               max_leaves=None,
                                               min_child_weight=None,
                                               missing=nan,
                                               monotone_constraints=None,
                                               multi_strategy=None,
                                               n_estimators=100, n_jobs=1,
                                               num_parallel_tree=None,
                                               objective='binary:logistic', ...),
                       method='isotonic', n_jobs=None), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002532F1126B0>, system=True)
2025-12-03 13:25:39,970:INFO:Checking exceptions
2025-12-03 13:25:39,987:INFO:Preloading libraries
2025-12-03 13:25:40,010:INFO:Copying training dataset
2025-12-03 13:25:40,010:INFO:Plot type: auc
2025-12-03 13:25:40,246:INFO:Fitting Model
2025-12-03 13:25:40,248:INFO:Scoring test/hold-out set
2025-12-03 13:25:40,526:INFO:Visual Rendered Successfully
2025-12-03 13:25:40,681:INFO:plot_model() successfully completed......................................
2025-12-03 13:25:40,682:INFO:Initializing get_config()
2025-12-03 13:25:40,687:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002532F1126B0>, variable=X_test_transformed)
2025-12-03 13:25:40,772:INFO:Variable: X_test returned as             Age  IncomeRatio  SystolicBP  WaistCircumference    Height  \
28456 -1.166682    -0.347193   -0.857495           -1.507527 -1.819875   
8993   0.143689     0.336722    1.662729            0.648015 -0.645962   
34312  0.028744     0.094199    0.120503            0.346962  0.583851   
4802  -1.235649     0.337285   -0.681087           -0.938256 -0.976048   
25895  0.028744     1.529936   -0.456265           -0.413678  0.081658   
...         ...          ...         ...                 ...       ...   
18045 -1.258638    -0.075567   -0.904070           -1.993226 -3.285713   
5425  -0.086201     0.470887    1.712883           -0.086555 -0.006211   
12819  0.235645     0.002041    0.478158            0.708225  1.515528   
33659 -1.212660     1.326217   -0.863547           -1.487456 -2.074533   
19531 -1.281627    -0.395697   -0.849048           -1.848720 -3.664595   

       TotalCholesterol  Triglycerides       LDL       HDL     HbA1c  ...  \
28456         -0.077253      -0.647020 -0.018927  0.563922 -0.617463  ...   
8993           0.702398       0.630424  0.004953  0.590479  0.121825  ...   
34312         -0.118546       0.874313 -0.747277 -1.115404  0.666895  ...   
4802          -0.178619      -0.486105  0.000596  0.050858 -0.563915  ...   
25895          0.819676       1.267174  0.006537 -0.056580 -0.314232  ...   
...                 ...            ...       ...       ...       ...  ...   
18045         -0.319533      -0.646830 -0.614729  0.541608 -0.630163  ...   
5425           0.397476      -0.206569  0.807814  0.296361 -0.096204  ...   
12819         -0.681479      -0.646225 -0.152735 -0.821286  0.121825  ...   
33659         -0.986401      -0.647239 -2.064660  0.296361 -0.699939  ...   
19531         -0.334260      -0.646844 -0.652171  0.541702 -0.458463  ...   

       Race_5.0  Race_1.0  Race_4.0  Race_3.0  Race_2.0  Education   Smoking  \
28456       1.0       0.0  0.000000 -0.147343       0.0  -0.020637 -0.322757   
8993        0.0       0.0  3.165789 -0.147343       0.0   0.527633  0.677243   
34312       0.0       0.0  0.000000  0.852657       0.0  -0.653648 -0.322757   
4802        1.0       0.0  0.000000 -0.147343       0.0   0.249169 -0.249145   
25895       0.0       0.0  0.000000  0.852657       0.0   1.118273 -0.322757   
...         ...       ...       ...       ...       ...        ...       ...   
18045       0.0       0.0  0.000000  0.852657       0.0  -0.784293 -0.322757   
5425        0.0       0.0  3.165789 -0.147343       0.0   0.527633  0.677243   
12819       0.0       0.0  0.000000  0.852657       0.0   1.118273  0.677243   
33659       0.0       0.0  3.165789 -0.147343       0.0   0.244733 -0.322757   
19531       1.0       0.0  0.000000 -0.147343       0.0  -0.811611 -0.322757   

       PhysicalActivity  HealthInsurance   Alcohol  
28456          0.867745              0.0 -0.852427  
8993           0.000000              0.0 -0.111403  
34312          0.000000              0.0  0.446044  
4802           1.329964              0.0 -0.367022  
25895          0.000000              0.0 -1.282459  
...                 ...              ...       ...  
18045          1.188011              0.0 -0.810481  
5425           2.099341              0.0 -0.131905  
12819          2.099341              0.0  0.470282  
33659          1.527044              0.0 -0.426709  
19531          1.039465              0.0 -1.044925  

[13109 rows x 30 columns]
2025-12-03 13:25:40,772:INFO:get_config() successfully completed......................................
2025-12-03 13:25:40,772:INFO:Initializing get_config()
2025-12-03 13:25:40,772:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002532F1126B0>, variable=y_test)
2025-12-03 13:25:40,772:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-12-03 13:25:40,775:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-12-03 13:25:40,778:INFO:Variable:  returned as 28456    0.0
8993     0.0
34312    0.0
4802     0.0
25895    0.0
        ... 
18045    0.0
5425     0.0
12819    0.0
33659    0.0
19531    0.0
Name: HeartDisease, Length: 13109, dtype: float32
2025-12-03 13:25:40,778:INFO:get_config() successfully completed......................................
2025-12-03 13:25:40,890:INFO:Initializing plot_model()
2025-12-03 13:25:40,891:INFO:plot_model(plot=pr, fold=None, verbose=True, display=None, display_format=None, estimator=CalibratedClassifierCV(cv=5, ensemble=True,
                       estimator=XGBClassifier(base_score=None,
                                               booster='gbtree', callbacks=None,
                                               colsample_bylevel=None,
                                               colsample_bynode=None,
                                               colsample_bytree=None,
                                               device='cpu',
                                               early_stopping_rounds=None,
                                               enable_categorical=False,
                                               eval_metric=None,
                                               feature_types=None, gamma=None,
                                               grow_policy=None,
                                               importance_type=None,
                                               interaction_constraints=None,
                                               learning_rate=0.05, max_bin=None,
                                               max_cat_threshold=None,
                                               max_cat_to_onehot=None,
                                               max_delta_step=1, max_depth=3,
                                               max_leaves=None,
                                               min_child_weight=None,
                                               missing=nan,
                                               monotone_constraints=None,
                                               multi_strategy=None,
                                               n_estimators=100, n_jobs=1,
                                               num_parallel_tree=None,
                                               objective='binary:logistic', ...),
                       method='isotonic', n_jobs=None), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002532F1126B0>, system=True)
2025-12-03 13:25:40,891:INFO:Checking exceptions
2025-12-03 13:25:40,906:INFO:Preloading libraries
2025-12-03 13:25:40,945:INFO:Copying training dataset
2025-12-03 13:25:40,945:INFO:Plot type: pr
2025-12-03 13:25:41,194:INFO:Fitting Model
2025-12-03 13:25:41,196:INFO:Scoring test/hold-out set
2025-12-03 13:25:41,447:INFO:Visual Rendered Successfully
2025-12-03 13:25:41,616:INFO:plot_model() successfully completed......................................
2025-12-03 13:25:41,660:INFO:Initializing plot_model()
2025-12-03 13:25:41,661:INFO:plot_model(plot=confusion_matrix, fold=None, verbose=True, display=None, display_format=None, estimator=CalibratedClassifierCV(cv=5, ensemble=True,
                       estimator=XGBClassifier(base_score=None,
                                               booster='gbtree', callbacks=None,
                                               colsample_bylevel=None,
                                               colsample_bynode=None,
                                               colsample_bytree=None,
                                               device='cpu',
                                               early_stopping_rounds=None,
                                               enable_categorical=False,
                                               eval_metric=None,
                                               feature_types=None, gamma=None,
                                               grow_policy=None,
                                               importance_type=None,
                                               interaction_constraints=None,
                                               learning_rate=0.05, max_bin=None,
                                               max_cat_threshold=None,
                                               max_cat_to_onehot=None,
                                               max_delta_step=1, max_depth=3,
                                               max_leaves=None,
                                               min_child_weight=None,
                                               missing=nan,
                                               monotone_constraints=None,
                                               multi_strategy=None,
                                               n_estimators=100, n_jobs=1,
                                               num_parallel_tree=None,
                                               objective='binary:logistic', ...),
                       method='isotonic', n_jobs=None), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002532F1126B0>, system=True)
2025-12-03 13:25:41,661:INFO:Checking exceptions
2025-12-03 13:25:41,674:INFO:Preloading libraries
2025-12-03 13:25:41,697:INFO:Copying training dataset
2025-12-03 13:25:41,697:INFO:Plot type: confusion_matrix
2025-12-03 13:25:41,919:INFO:Fitting Model
2025-12-03 13:25:41,922:INFO:Scoring test/hold-out set
2025-12-03 13:25:42,157:INFO:Visual Rendered Successfully
2025-12-03 13:25:42,329:INFO:plot_model() successfully completed......................................
2025-12-03 13:25:42,355:INFO:Initializing plot_model()
2025-12-03 13:25:42,355:INFO:plot_model(plot=error, fold=None, verbose=True, display=None, display_format=None, estimator=CalibratedClassifierCV(cv=5, ensemble=True,
                       estimator=XGBClassifier(base_score=None,
                                               booster='gbtree', callbacks=None,
                                               colsample_bylevel=None,
                                               colsample_bynode=None,
                                               colsample_bytree=None,
                                               device='cpu',
                                               early_stopping_rounds=None,
                                               enable_categorical=False,
                                               eval_metric=None,
                                               feature_types=None, gamma=None,
                                               grow_policy=None,
                                               importance_type=None,
                                               interaction_constraints=None,
                                               learning_rate=0.05, max_bin=None,
                                               max_cat_threshold=None,
                                               max_cat_to_onehot=None,
                                               max_delta_step=1, max_depth=3,
                                               max_leaves=None,
                                               min_child_weight=None,
                                               missing=nan,
                                               monotone_constraints=None,
                                               multi_strategy=None,
                                               n_estimators=100, n_jobs=1,
                                               num_parallel_tree=None,
                                               objective='binary:logistic', ...),
                       method='isotonic', n_jobs=None), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002532F1126B0>, system=True)
2025-12-03 13:25:42,355:INFO:Checking exceptions
2025-12-03 13:25:42,369:INFO:Preloading libraries
2025-12-03 13:25:42,404:INFO:Copying training dataset
2025-12-03 13:25:42,404:INFO:Plot type: error
2025-12-03 13:25:42,641:INFO:Fitting Model
2025-12-03 13:25:42,643:INFO:Scoring test/hold-out set
2025-12-03 13:25:42,912:INFO:Visual Rendered Successfully
2025-12-03 13:25:43,075:INFO:plot_model() successfully completed......................................
2025-12-03 13:25:43,103:INFO:Initializing plot_model()
2025-12-03 13:25:43,103:INFO:plot_model(plot=calibration, fold=None, verbose=True, display=None, display_format=None, estimator=CalibratedClassifierCV(cv=5, ensemble=True,
                       estimator=XGBClassifier(base_score=None,
                                               booster='gbtree', callbacks=None,
                                               colsample_bylevel=None,
                                               colsample_bynode=None,
                                               colsample_bytree=None,
                                               device='cpu',
                                               early_stopping_rounds=None,
                                               enable_categorical=False,
                                               eval_metric=None,
                                               feature_types=None, gamma=None,
                                               grow_policy=None,
                                               importance_type=None,
                                               interaction_constraints=None,
                                               learning_rate=0.05, max_bin=None,
                                               max_cat_threshold=None,
                                               max_cat_to_onehot=None,
                                               max_delta_step=1, max_depth=3,
                                               max_leaves=None,
                                               min_child_weight=None,
                                               missing=nan,
                                               monotone_constraints=None,
                                               multi_strategy=None,
                                               n_estimators=100, n_jobs=1,
                                               num_parallel_tree=None,
                                               objective='binary:logistic', ...),
                       method='isotonic', n_jobs=None), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002532F1126B0>, system=True)
2025-12-03 13:25:43,103:INFO:Checking exceptions
2025-12-03 13:25:43,117:INFO:Preloading libraries
2025-12-03 13:25:43,143:INFO:Copying training dataset
2025-12-03 13:25:43,143:INFO:Plot type: calibration
2025-12-03 13:25:43,153:INFO:Scoring test/hold-out set
2025-12-03 13:25:43,479:INFO:Visual Rendered Successfully
2025-12-03 13:25:43,637:INFO:plot_model() successfully completed......................................
2025-12-03 13:25:43,681:INFO:Initializing get_config()
2025-12-03 13:25:43,681:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002532F1126B0>, variable=X_test_transformed)
2025-12-03 13:25:43,799:INFO:Variable: X_test returned as             Age  IncomeRatio  SystolicBP  WaistCircumference    Height  \
28456 -1.166682    -0.347193   -0.857495           -1.507527 -1.819875   
8993   0.143689     0.336722    1.662729            0.648015 -0.645962   
34312  0.028744     0.094199    0.120503            0.346962  0.583851   
4802  -1.235649     0.337285   -0.681087           -0.938256 -0.976048   
25895  0.028744     1.529936   -0.456265           -0.413678  0.081658   
...         ...          ...         ...                 ...       ...   
18045 -1.258638    -0.075567   -0.904070           -1.993226 -3.285713   
5425  -0.086201     0.470887    1.712883           -0.086555 -0.006211   
12819  0.235645     0.002041    0.478158            0.708225  1.515528   
33659 -1.212660     1.326217   -0.863547           -1.487456 -2.074533   
19531 -1.281627    -0.395697   -0.849048           -1.848720 -3.664595   

       TotalCholesterol  Triglycerides       LDL       HDL     HbA1c  ...  \
28456         -0.077253      -0.647020 -0.018927  0.563922 -0.617463  ...   
8993           0.702398       0.630424  0.004953  0.590479  0.121825  ...   
34312         -0.118546       0.874313 -0.747277 -1.115404  0.666895  ...   
4802          -0.178619      -0.486105  0.000596  0.050858 -0.563915  ...   
25895          0.819676       1.267174  0.006537 -0.056580 -0.314232  ...   
...                 ...            ...       ...       ...       ...  ...   
18045         -0.319533      -0.646830 -0.614729  0.541608 -0.630163  ...   
5425           0.397476      -0.206569  0.807814  0.296361 -0.096204  ...   
12819         -0.681479      -0.646225 -0.152735 -0.821286  0.121825  ...   
33659         -0.986401      -0.647239 -2.064660  0.296361 -0.699939  ...   
19531         -0.334260      -0.646844 -0.652171  0.541702 -0.458463  ...   

       Race_5.0  Race_1.0  Race_4.0  Race_3.0  Race_2.0  Education   Smoking  \
28456       1.0       0.0  0.000000 -0.147343       0.0  -0.020637 -0.322757   
8993        0.0       0.0  3.165789 -0.147343       0.0   0.527633  0.677243   
34312       0.0       0.0  0.000000  0.852657       0.0  -0.653648 -0.322757   
4802        1.0       0.0  0.000000 -0.147343       0.0   0.249169 -0.249145   
25895       0.0       0.0  0.000000  0.852657       0.0   1.118273 -0.322757   
...         ...       ...       ...       ...       ...        ...       ...   
18045       0.0       0.0  0.000000  0.852657       0.0  -0.784293 -0.322757   
5425        0.0       0.0  3.165789 -0.147343       0.0   0.527633  0.677243   
12819       0.0       0.0  0.000000  0.852657       0.0   1.118273  0.677243   
33659       0.0       0.0  3.165789 -0.147343       0.0   0.244733 -0.322757   
19531       1.0       0.0  0.000000 -0.147343       0.0  -0.811611 -0.322757   

       PhysicalActivity  HealthInsurance   Alcohol  
28456          0.867745              0.0 -0.852427  
8993           0.000000              0.0 -0.111403  
34312          0.000000              0.0  0.446044  
4802           1.329964              0.0 -0.367022  
25895          0.000000              0.0 -1.282459  
...                 ...              ...       ...  
18045          1.188011              0.0 -0.810481  
5425           2.099341              0.0 -0.131905  
12819          2.099341              0.0  0.470282  
33659          1.527044              0.0 -0.426709  
19531          1.039465              0.0 -1.044925  

[13109 rows x 30 columns]
2025-12-03 13:25:43,799:INFO:get_config() successfully completed......................................
2025-12-03 13:25:43,799:INFO:Initializing get_config()
2025-12-03 13:25:43,799:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002532F1126B0>, variable=y_test)
2025-12-03 13:25:43,799:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-12-03 13:25:43,799:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-12-03 13:25:43,805:INFO:Variable:  returned as 28456    0.0
8993     0.0
34312    0.0
4802     0.0
25895    0.0
        ... 
18045    0.0
5425     0.0
12819    0.0
33659    0.0
19531    0.0
Name: HeartDisease, Length: 13109, dtype: float32
2025-12-03 13:25:43,805:INFO:get_config() successfully completed......................................
2025-12-03 13:25:44,865:INFO:Initializing finalize_model()
2025-12-03 13:25:44,865:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002532F1126B0>, estimator=CalibratedClassifierCV(cv=5, ensemble=True,
                       estimator=XGBClassifier(base_score=None,
                                               booster='gbtree', callbacks=None,
                                               colsample_bylevel=None,
                                               colsample_bynode=None,
                                               colsample_bytree=None,
                                               device='cpu',
                                               early_stopping_rounds=None,
                                               enable_categorical=False,
                                               eval_metric=None,
                                               feature_types=None, gamma=None,
                                               grow_policy=None,
                                               importance_type=None,
                                               interaction_constraints=None,
                                               learning_rate=0.05, max_bin=None,
                                               max_cat_threshold=None,
                                               max_cat_to_onehot=None,
                                               max_delta_step=1, max_depth=3,
                                               max_leaves=None,
                                               min_child_weight=None,
                                               missing=nan,
                                               monotone_constraints=None,
                                               multi_strategy=None,
                                               n_estimators=100, n_jobs=1,
                                               num_parallel_tree=None,
                                               objective='binary:logistic', ...),
                       method='isotonic', n_jobs=None), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2025-12-03 13:25:44,866:INFO:Finalizing CalibratedClassifierCV(cv=5, ensemble=True,
                       estimator=XGBClassifier(base_score=None,
                                               booster='gbtree', callbacks=None,
                                               colsample_bylevel=None,
                                               colsample_bynode=None,
                                               colsample_bytree=None,
                                               device='cpu',
                                               early_stopping_rounds=None,
                                               enable_categorical=False,
                                               eval_metric=None,
                                               feature_types=None, gamma=None,
                                               grow_policy=None,
                                               importance_type=None,
                                               interaction_constraints=None,
                                               learning_rate=0.05, max_bin=None,
                                               max_cat_threshold=None,
                                               max_cat_to_onehot=None,
                                               max_delta_step=1, max_depth=3,
                                               max_leaves=None,
                                               min_child_weight=None,
                                               missing=nan,
                                               monotone_constraints=None,
                                               multi_strategy=None,
                                               n_estimators=100, n_jobs=1,
                                               num_parallel_tree=None,
                                               objective='binary:logistic', ...),
                       method='isotonic', n_jobs=None)
2025-12-03 13:25:44,881:INFO:Initializing create_model()
2025-12-03 13:25:44,881:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002532F1126B0>, estimator=CalibratedClassifierCV(cv=5, ensemble=True,
                       estimator=XGBClassifier(base_score=None,
                                               booster='gbtree', callbacks=None,
                                               colsample_bylevel=None,
                                               colsample_bynode=None,
                                               colsample_bytree=None,
                                               device='cpu',
                                               early_stopping_rounds=None,
                                               enable_categorical=False,
                                               eval_metric=None,
                                               feature_types=None, gamma=None,
                                               grow_policy=None,
                                               importance_type=None,
                                               interaction_constraints=None,
                                               learning_rate=0.05, max_bin=None,
                                               max_cat_threshold=None,
                                               max_cat_to_onehot=None,
                                               max_delta_step=1, max_depth=3,
                                               max_leaves=None,
                                               min_child_weight=None,
                                               missing=nan,
                                               monotone_constraints=None,
                                               multi_strategy=None,
                                               n_estimators=100, n_jobs=1,
                                               num_parallel_tree=None,
                                               objective='binary:logistic', ...),
                       method='isotonic', n_jobs=None), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2025-12-03 13:25:44,881:INFO:Checking exceptions
2025-12-03 13:25:44,881:INFO:Importing libraries
2025-12-03 13:25:44,881:INFO:Copying training dataset
2025-12-03 13:25:44,889:INFO:Defining folds
2025-12-03 13:25:44,889:INFO:Declaring metric variables
2025-12-03 13:25:44,889:INFO:Importing untrained model
2025-12-03 13:25:44,889:INFO:Declaring custom model
2025-12-03 13:25:44,891:INFO:Extreme Gradient Boosting Imported successfully
2025-12-03 13:25:44,893:INFO:Cross validation set to False
2025-12-03 13:25:44,893:INFO:Fitting Model
2025-12-03 13:25:44,994:INFO:Warning: No categorical columns found. Calling 'transform' will only return input data.
2025-12-03 13:25:48,260:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'IncomeRatio', 'SystolicBP',
                                             'BMI', 'WaistCircumference',
                                             'Height', 'TotalCholesterol',
                                             'Triglycerides', 'LDL', 'HDL',
                                             'HbA1c', 'Glucose', 'Creatinine',
                                             'UricAcid', 'ALT_Enzyme',
                                             'Albumin', 'Potassium', 'Sodium',
                                             'GGT_Enzyme', 'AST_Enzyme'],
                                    transformer=Si...
                                                                interaction_constraints=None,
                                                                learning_rate=0.05,
                                                                max_bin=None,
                                                                max_cat_threshold=None,
                                                                max_cat_to_onehot=None,
                                                                max_delta_step=1,
                                                                max_depth=3,
                                                                max_leaves=None,
                                                                min_child_weight=None,
                                                                missing=nan,
                                                                monotone_constraints=None,
                                                                multi_strategy=None,
                                                                n_estimators=100,
                                                                n_jobs=1,
                                                                num_parallel_tree=None,
                                                                objective='binary:logistic', ...),
                                        method='isotonic', n_jobs=None))],
         verbose=False)
2025-12-03 13:25:48,260:INFO:create_model() successfully completed......................................
2025-12-03 13:25:48,419:INFO:_master_model_container: 4
2025-12-03 13:25:48,419:INFO:_display_container: 4
2025-12-03 13:25:48,439:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'IncomeRatio', 'SystolicBP',
                                             'BMI', 'WaistCircumference',
                                             'Height', 'TotalCholesterol',
                                             'Triglycerides', 'LDL', 'HDL',
                                             'HbA1c', 'Glucose', 'Creatinine',
                                             'UricAcid', 'ALT_Enzyme',
                                             'Albumin', 'Potassium', 'Sodium',
                                             'GGT_Enzyme', 'AST_Enzyme'],
                                    transformer=Si...
                                                                interaction_constraints=None,
                                                                learning_rate=0.05,
                                                                max_bin=None,
                                                                max_cat_threshold=None,
                                                                max_cat_to_onehot=None,
                                                                max_delta_step=1,
                                                                max_depth=3,
                                                                max_leaves=None,
                                                                min_child_weight=None,
                                                                missing=nan,
                                                                monotone_constraints=None,
                                                                multi_strategy=None,
                                                                n_estimators=100,
                                                                n_jobs=1,
                                                                num_parallel_tree=None,
                                                                objective='binary:logistic', ...),
                                        method='isotonic', n_jobs=None))],
         verbose=False)
2025-12-03 13:25:48,439:INFO:finalize_model() successfully completed......................................
2025-12-03 13:25:48,625:INFO:Initializing save_model()
2025-12-03 13:25:48,626:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'IncomeRatio', 'SystolicBP',
                                             'BMI', 'WaistCircumference',
                                             'Height', 'TotalCholesterol',
                                             'Triglycerides', 'LDL', 'HDL',
                                             'HbA1c', 'Glucose', 'Creatinine',
                                             'UricAcid', 'ALT_Enzyme',
                                             'Albumin', 'Potassium', 'Sodium',
                                             'GGT_Enzyme', 'AST_Enzyme'],
                                    transformer=Si...
                                                                interaction_constraints=None,
                                                                learning_rate=0.05,
                                                                max_bin=None,
                                                                max_cat_threshold=None,
                                                                max_cat_to_onehot=None,
                                                                max_delta_step=1,
                                                                max_depth=3,
                                                                max_leaves=None,
                                                                min_child_weight=None,
                                                                missing=nan,
                                                                monotone_constraints=None,
                                                                multi_strategy=None,
                                                                n_estimators=100,
                                                                n_jobs=1,
                                                                num_parallel_tree=None,
                                                                objective='binary:logistic', ...),
                                        method='isotonic', n_jobs=None))],
         verbose=False), model_name=../models\best_pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\OMAR\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'IncomeRatio', 'SystolicBP',
                                             'BMI', 'WaistCircumference',
                                             'Height', 'TotalCholesterol',
                                             'Triglycerides', 'LDL', 'HDL',
                                             'HbA1c', 'Glucose', 'Creatinine',
                                             'UricAcid', 'ALT_Enzyme',
                                             'Albumin', 'Potassium', 'Sodium',
                                             'G...
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              random_state=42,
                                                                              sampling_strategy='auto')))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=RobustScaler(copy=True,
                                                             quantile_range=(25.0,
                                                                             75.0),
                                                             unit_variance=False,
                                                             with_centering=True,
                                                             with_scaling=True)))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2025-12-03 13:25:48,626:INFO:Adding model into prep_pipe
2025-12-03 13:25:48,626:WARNING:Only Model saved as it was a pipeline.
2025-12-03 13:25:48,638:INFO:../models\best_pipeline.pkl saved in current working directory
2025-12-03 13:25:48,657:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'IncomeRatio', 'SystolicBP',
                                             'BMI', 'WaistCircumference',
                                             'Height', 'TotalCholesterol',
                                             'Triglycerides', 'LDL', 'HDL',
                                             'HbA1c', 'Glucose', 'Creatinine',
                                             'UricAcid', 'ALT_Enzyme',
                                             'Albumin', 'Potassium', 'Sodium',
                                             'GGT_Enzyme', 'AST_Enzyme'],
                                    transformer=Si...
                                                                interaction_constraints=None,
                                                                learning_rate=0.05,
                                                                max_bin=None,
                                                                max_cat_threshold=None,
                                                                max_cat_to_onehot=None,
                                                                max_delta_step=1,
                                                                max_depth=3,
                                                                max_leaves=None,
                                                                min_child_weight=None,
                                                                missing=nan,
                                                                monotone_constraints=None,
                                                                multi_strategy=None,
                                                                n_estimators=100,
                                                                n_jobs=1,
                                                                num_parallel_tree=None,
                                                                objective='binary:logistic', ...),
                                        method='isotonic', n_jobs=None))],
         verbose=False)
2025-12-03 13:25:48,657:INFO:save_model() successfully completed......................................
2025-12-03 13:29:09,287:INFO:Initializing load_model()
2025-12-03 13:29:09,287:INFO:load_model(model_name=../models/best_pipeline, platform=None, authentication=None, verbose=True)
2025-12-03 13:29:09,397:INFO:Initializing predict_model()
2025-12-03 13:29:09,397:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000278061CF8B0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Age', 'IncomeRatio', 'SystolicBP',
                                             'BMI', 'WaistCircumference',
                                             'Height', 'TotalCholesterol',
                                             'Triglycerides', 'LDL', 'HDL',
                                             'HbA1c', 'Glucose', 'Creatinine',
                                             'UricAcid', 'ALT_Enzyme',
                                             'Albumin', 'Potassium', 'Sodium',
                                             'GGT_Enzyme', 'AST_Enzyme'],
                                    transformer=SimpleImputer()...
                                                                grow_policy=None,
                                                                importance_type=None,
                                                                interaction_constraints=None,
                                                                learning_rate=0.05,
                                                                max_bin=None,
                                                                max_cat_threshold=None,
                                                                max_cat_to_onehot=None,
                                                                max_delta_step=1,
                                                                max_depth=3,
                                                                max_leaves=None,
                                                                min_child_weight=None,
                                                                missing=nan,
                                                                monotone_constraints=None,
                                                                multi_strategy=None,
                                                                n_estimators=100,
                                                                n_jobs=1,
                                                                num_parallel_tree=None,
                                                                random_state=42, ...),
                                        method='isotonic'))]), probability_threshold=None, encoded_labels=False, raw_score=True, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000278061D0C10>)
2025-12-03 13:29:09,397:INFO:Checking exceptions
2025-12-03 13:29:09,397:INFO:Preloading libraries
2025-12-03 13:29:09,397:INFO:Set up data.
2025-12-03 13:29:09,411:INFO:Set up index.
2025-12-03 13:29:09,882:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-03 13:29:09,888:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-03 13:29:09,890:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-03 13:34:05,069:INFO:Initializing interpret_model()
2025-12-03 13:34:05,069:INFO:interpret_model(estimator=CalibratedClassifierCV(cv=5, ensemble=True,
                       estimator=XGBClassifier(base_score=None,
                                               booster='gbtree', callbacks=None,
                                               colsample_bylevel=None,
                                               colsample_bynode=None,
                                               colsample_bytree=None,
                                               device='cpu',
                                               early_stopping_rounds=None,
                                               enable_categorical=False,
                                               eval_metric=None,
                                               feature_types=None, gamma=None,
                                               grow_policy=None,
                                               importance_type=None,
                                               interaction_constraints=None,
                                               learning_rate=0.05, max_bin=None,
                                               max_cat_threshold=None,
                                               max_cat_to_onehot=None,
                                               max_delta_step=1, max_depth=3,
                                               max_leaves=None,
                                               min_child_weight=None,
                                               missing=nan,
                                               monotone_constraints=None,
                                               multi_strategy=None,
                                               n_estimators=100, n_jobs=1,
                                               num_parallel_tree=None,
                                               objective='binary:logistic', ...),
                       method='isotonic', n_jobs=None), use_train_data=False, X_new_sample=None, y_new_sample=None, feature=None, kwargs={}, observation=None, plot=summary, save=False, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002532F1126B0>)
2025-12-03 13:34:05,070:INFO:Checking exceptions
2025-12-03 13:34:05,070:INFO:Soft dependency imported: shap: 0.49.1
2025-12-03 13:34:39,230:INFO:PyCaret ClassificationExperiment
2025-12-03 13:34:39,230:INFO:Logging name: clf-default-name
2025-12-03 13:34:39,230:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-12-03 13:34:39,230:INFO:version 3.3.2
2025-12-03 13:34:39,230:INFO:Initializing setup()
2025-12-03 13:34:39,230:INFO:self.USI: 9e86
2025-12-03 13:34:39,230:INFO:self._variable_keys: {'fix_imbalance', 'X_train', 'memory', 'X', 'exp_name_log', 'seed', '_available_plots', 'pipeline', 'fold_shuffle_param', 'exp_id', 'USI', 'gpu_param', 'html_param', 'logging_param', 'fold_groups_param', 'data', 'y', 'X_test', 'is_multiclass', 'y_test', 'fold_generator', 'log_plots_param', 'gpu_n_jobs_param', 'idx', 'y_train', 'target_param', 'n_jobs_param', '_ml_usecase'}
2025-12-03 13:34:39,230:INFO:Checking environment
2025-12-03 13:34:39,230:INFO:python_version: 3.10.19
2025-12-03 13:34:39,230:INFO:python_build: ('main', 'Oct 21 2025 16:41:31')
2025-12-03 13:34:39,230:INFO:machine: AMD64
2025-12-03 13:34:39,230:INFO:platform: Windows-10-10.0.26100-SP0
2025-12-03 13:34:39,231:INFO:Memory: svmem(total=16282144768, available=3776491520, percent=76.8, used=12505653248, free=3776491520)
2025-12-03 13:34:39,231:INFO:Physical Core: 6
2025-12-03 13:34:39,231:INFO:Logical Core: 12
2025-12-03 13:34:39,231:INFO:Checking libraries
2025-12-03 13:34:39,231:INFO:System:
2025-12-03 13:34:39,231:INFO:    python: 3.10.19 | packaged by Anaconda, Inc. | (main, Oct 21 2025, 16:41:31) [MSC v.1929 64 bit (AMD64)]
2025-12-03 13:34:39,231:INFO:executable: c:\Users\OMAR\miniconda3\envs\xgb_env\python.exe
2025-12-03 13:34:39,231:INFO:   machine: Windows-10-10.0.26100-SP0
2025-12-03 13:34:39,231:INFO:PyCaret required dependencies:
2025-12-03 13:34:39,231:INFO:                 pip: 25.3
2025-12-03 13:34:39,231:INFO:          setuptools: 80.9.0
2025-12-03 13:34:39,231:INFO:             pycaret: 3.3.2
2025-12-03 13:34:39,231:INFO:             IPython: 8.37.0
2025-12-03 13:34:39,231:INFO:          ipywidgets: 8.1.8
2025-12-03 13:34:39,231:INFO:                tqdm: 4.67.1
2025-12-03 13:34:39,231:INFO:               numpy: 1.26.4
2025-12-03 13:34:39,231:INFO:              pandas: 2.1.4
2025-12-03 13:34:39,231:INFO:              jinja2: 3.1.6
2025-12-03 13:34:39,231:INFO:               scipy: 1.11.4
2025-12-03 13:34:39,231:INFO:              joblib: 1.3.2
2025-12-03 13:34:39,231:INFO:             sklearn: 1.4.2
2025-12-03 13:34:39,231:INFO:                pyod: 2.0.5
2025-12-03 13:34:39,231:INFO:            imblearn: 0.14.0
2025-12-03 13:34:39,231:INFO:   category_encoders: 2.7.0
2025-12-03 13:34:39,231:INFO:            lightgbm: 4.6.0
2025-12-03 13:34:39,231:INFO:               numba: 0.62.1
2025-12-03 13:34:39,231:INFO:            requests: 2.32.5
2025-12-03 13:34:39,231:INFO:          matplotlib: 3.7.5
2025-12-03 13:34:39,231:INFO:          scikitplot: 0.3.7
2025-12-03 13:34:39,232:INFO:         yellowbrick: 1.5
2025-12-03 13:34:39,232:INFO:              plotly: 5.24.1
2025-12-03 13:34:39,232:INFO:    plotly-resampler: Not installed
2025-12-03 13:34:39,232:INFO:             kaleido: 1.2.0
2025-12-03 13:34:39,232:INFO:           schemdraw: 0.15
2025-12-03 13:34:39,232:INFO:         statsmodels: 0.14.5
2025-12-03 13:34:39,232:INFO:              sktime: 0.26.0
2025-12-03 13:34:39,232:INFO:               tbats: 1.1.3
2025-12-03 13:34:39,232:INFO:            pmdarima: 2.0.4
2025-12-03 13:34:39,232:INFO:              psutil: 7.1.3
2025-12-03 13:34:39,232:INFO:          markupsafe: 3.0.3
2025-12-03 13:34:39,232:INFO:             pickle5: Not installed
2025-12-03 13:34:39,232:INFO:         cloudpickle: 3.1.2
2025-12-03 13:34:39,232:INFO:         deprecation: 2.1.0
2025-12-03 13:34:39,232:INFO:              xxhash: 3.6.0
2025-12-03 13:34:39,232:INFO:           wurlitzer: Not installed
2025-12-03 13:34:39,232:INFO:PyCaret optional dependencies:
2025-12-03 13:34:39,232:INFO:                shap: 0.49.1
2025-12-03 13:34:39,232:INFO:           interpret: 0.7.3
2025-12-03 13:34:39,232:INFO:                umap: 0.5.7
2025-12-03 13:34:39,232:INFO:     ydata_profiling: 4.18.0
2025-12-03 13:34:39,232:INFO:  explainerdashboard: 0.5.1
2025-12-03 13:34:39,232:INFO:             autoviz: Not installed
2025-12-03 13:34:39,232:INFO:           fairlearn: 0.7.0
2025-12-03 13:34:39,232:INFO:          deepchecks: Not installed
2025-12-03 13:34:39,232:INFO:             xgboost: 2.1.3
2025-12-03 13:34:39,232:INFO:            catboost: 1.2.8
2025-12-03 13:34:39,232:INFO:              kmodes: 0.12.2
2025-12-03 13:34:39,232:INFO:             mlxtend: 0.23.4
2025-12-03 13:34:39,232:INFO:       statsforecast: 1.5.0
2025-12-03 13:34:39,232:INFO:        tune_sklearn: Not installed
2025-12-03 13:34:39,232:INFO:                 ray: Not installed
2025-12-03 13:34:39,232:INFO:            hyperopt: 0.2.7
2025-12-03 13:34:39,232:INFO:              optuna: 4.6.0
2025-12-03 13:34:39,232:INFO:               skopt: 0.10.2
2025-12-03 13:34:39,232:INFO:              mlflow: 3.6.0
2025-12-03 13:34:39,232:INFO:              gradio: 6.0.1
2025-12-03 13:34:39,232:INFO:             fastapi: 0.123.0
2025-12-03 13:34:39,232:INFO:             uvicorn: 0.38.0
2025-12-03 13:34:39,232:INFO:              m2cgen: 0.10.0
2025-12-03 13:34:39,232:INFO:           evidently: 0.4.40
2025-12-03 13:34:39,232:INFO:               fugue: 0.8.7
2025-12-03 13:34:39,232:INFO:           streamlit: 1.51.0
2025-12-03 13:34:39,232:INFO:             prophet: Not installed
2025-12-03 13:34:39,232:INFO:None
2025-12-03 13:34:39,232:INFO:Set up data.
2025-12-03 13:34:39,255:INFO:Set up folding strategy.
2025-12-03 13:34:39,255:INFO:Set up train/test split.
2025-12-03 13:34:39,287:INFO:Set up index.
2025-12-03 13:34:39,288:INFO:Assigning column types.
2025-12-03 13:34:39,306:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-12-03 13:34:39,331:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-12-03 13:34:39,331:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-03 13:34:39,347:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-03 13:34:39,349:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-03 13:34:39,373:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-12-03 13:34:39,373:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-03 13:34:39,389:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-03 13:34:39,392:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-03 13:34:39,392:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-12-03 13:34:39,419:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-03 13:34:39,439:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-03 13:34:39,441:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-03 13:34:39,468:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-12-03 13:34:39,486:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-03 13:34:39,488:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-03 13:34:39,488:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-12-03 13:34:39,531:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-03 13:34:39,533:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-03 13:34:39,577:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-03 13:34:39,578:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-03 13:34:39,579:INFO:Preparing preprocessing pipeline...
2025-12-03 13:34:39,582:INFO:Set up simple imputation.
2025-12-03 13:34:39,594:INFO:Set up encoding of ordinal features.
2025-12-03 13:34:39,602:INFO:Set up encoding of categorical features.
2025-12-03 13:34:39,603:INFO:Set up removing multicollinearity.
2025-12-03 13:34:39,603:INFO:Set up imbalanced handling.
2025-12-03 13:34:39,603:INFO:Set up feature normalization.
2025-12-03 13:34:39,980:INFO:Finished creating preprocessing pipeline.
2025-12-03 13:34:39,996:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\OMAR\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'IncomeRatio', 'SystolicBP',
                                             'BMI', 'WaistCircumference',
                                             'Height', 'TotalCholesterol',
                                             'Triglycerides', 'LDL', 'HDL',
                                             'HbA1c', 'Glucose', 'Creatinine',
                                             'UricAcid', 'ALT_Enzyme',
                                             'Albumin', 'Potassium', 'Sodium',
                                             'G...
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              random_state=42,
                                                                              sampling_strategy='auto')))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=RobustScaler(copy=True,
                                                             quantile_range=(25.0,
                                                                             75.0),
                                                             unit_variance=False,
                                                             with_centering=True,
                                                             with_scaling=True)))],
         verbose=False)
2025-12-03 13:34:39,997:INFO:Creating final display dataframe.
2025-12-03 13:34:40,232:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target      HeartDisease
2                   Target type            Binary
3           Original data shape       (43695, 28)
4        Transformed data shape       (72719, 31)
5   Transformed train set shape       (59610, 31)
6    Transformed test set shape       (13109, 31)
7              Numeric features                20
8          Categorical features                 7
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15     Remove multicollinearity              True
16  Multicollinearity threshold               0.9
17                Fix imbalance              True
18         Fix imbalance method             SMOTE
19                    Normalize              True
20             Normalize method            robust
21               Fold Generator   StratifiedKFold
22                  Fold Number                10
23                     CPU Jobs                 1
24                      Use GPU             False
25               Log Experiment             False
26              Experiment Name  clf-default-name
27                          USI              9e86
2025-12-03 13:34:40,284:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-03 13:34:40,286:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-03 13:34:40,328:INFO:Soft dependency imported: xgboost: 2.1.3
2025-12-03 13:34:40,331:INFO:Soft dependency imported: catboost: 1.2.8
2025-12-03 13:34:40,331:INFO:setup() successfully completed in 1.12s...............
2025-12-03 13:34:40,362:INFO:Initializing create_model()
2025-12-03 13:34:40,362:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002532B532F50>, estimator=xgboost, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-03 13:34:40,362:INFO:Checking exceptions
2025-12-03 13:34:40,364:INFO:Importing libraries
2025-12-03 13:34:40,364:INFO:Copying training dataset
2025-12-03 13:34:40,391:INFO:Defining folds
2025-12-03 13:34:40,391:INFO:Declaring metric variables
2025-12-03 13:34:40,392:INFO:Importing untrained model
2025-12-03 13:34:40,393:INFO:Extreme Gradient Boosting Imported successfully
2025-12-03 13:34:40,393:INFO:Starting cross validation
2025-12-03 13:34:40,394:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-12-03 13:34:51,061:INFO:Calculating mean and std
2025-12-03 13:34:51,062:INFO:Creating metrics dataframe
2025-12-03 13:34:51,063:INFO:Finalizing model
2025-12-03 13:34:51,131:INFO:Warning: No categorical columns found. Calling 'transform' will only return input data.
2025-12-03 13:34:52,124:INFO:Uploading results into container
2025-12-03 13:34:52,125:INFO:Uploading model into container now
2025-12-03 13:34:52,126:INFO:_master_model_container: 1
2025-12-03 13:34:52,126:INFO:_display_container: 2
2025-12-03 13:34:52,126:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2025-12-03 13:34:52,126:INFO:create_model() successfully completed......................................
2025-12-03 13:34:52,305:INFO:Initializing tune_model()
2025-12-03 13:34:52,305:INFO:tune_model(estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...), fold=None, round=4, n_iter=5, custom_grid={'learning_rate': [0.05, 0.1], 'n_estimators': [100, 200], 'max_depth': [3, 5], 'scale_pos_weight': [38.153225806451616, 57.22983870967742], 'max_delta_step': [1]}, optimize=Recall, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002532B532F50>)
2025-12-03 13:34:52,305:INFO:Checking exceptions
2025-12-03 13:34:52,329:INFO:Copying training dataset
2025-12-03 13:34:52,345:INFO:Checking base model
2025-12-03 13:34:52,346:INFO:Base model : Extreme Gradient Boosting
2025-12-03 13:34:52,346:INFO:Declaring metric variables
2025-12-03 13:34:52,352:INFO:Defining Hyperparameters
2025-12-03 13:34:52,559:INFO:custom_grid: {'actual_estimator__learning_rate': [0.05, 0.1], 'actual_estimator__n_estimators': [100, 200], 'actual_estimator__max_depth': [3, 5], 'actual_estimator__scale_pos_weight': [38.153225806451616, 57.22983870967742], 'actual_estimator__max_delta_step': [1]}
2025-12-03 13:34:52,559:INFO:Tuning with n_jobs=1
2025-12-03 13:34:52,559:INFO:Initializing RandomizedSearchCV
2025-12-03 13:35:53,507:INFO:best_params: {'actual_estimator__scale_pos_weight': 57.22983870967742, 'actual_estimator__n_estimators': 200, 'actual_estimator__max_depth': 3, 'actual_estimator__max_delta_step': 1, 'actual_estimator__learning_rate': 0.05}
2025-12-03 13:35:53,508:INFO:Hyperparameter search completed
2025-12-03 13:35:53,508:INFO:SubProcess create_model() called ==================================
2025-12-03 13:35:53,509:INFO:Initializing create_model()
2025-12-03 13:35:53,509:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002532B532F50>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002532F1135B0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'scale_pos_weight': 57.22983870967742, 'n_estimators': 200, 'max_depth': 3, 'max_delta_step': 1, 'learning_rate': 0.05})
2025-12-03 13:35:53,509:INFO:Checking exceptions
2025-12-03 13:35:53,509:INFO:Importing libraries
2025-12-03 13:35:53,509:INFO:Copying training dataset
2025-12-03 13:35:53,541:INFO:Defining folds
2025-12-03 13:35:53,541:INFO:Declaring metric variables
2025-12-03 13:35:53,543:INFO:Importing untrained model
2025-12-03 13:35:53,543:INFO:Declaring custom model
2025-12-03 13:35:53,546:INFO:Extreme Gradient Boosting Imported successfully
2025-12-03 13:35:53,554:INFO:Starting cross validation
2025-12-03 13:35:53,557:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-12-03 13:36:04,167:INFO:Calculating mean and std
2025-12-03 13:36:04,167:INFO:Creating metrics dataframe
2025-12-03 13:36:04,172:INFO:Finalizing model
2025-12-03 13:36:04,281:INFO:Warning: No categorical columns found. Calling 'transform' will only return input data.
2025-12-03 13:36:05,335:INFO:Uploading results into container
2025-12-03 13:36:05,336:INFO:Uploading model into container now
2025-12-03 13:36:05,336:INFO:_master_model_container: 2
2025-12-03 13:36:05,336:INFO:_display_container: 3
2025-12-03 13:36:05,336:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=0.05, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None, max_delta_step=1,
              max_depth=3, max_leaves=None, min_child_weight=None, missing=nan,
              monotone_constraints=None, multi_strategy=None, n_estimators=200,
              n_jobs=1, num_parallel_tree=None, objective='binary:logistic', ...)
2025-12-03 13:36:05,336:INFO:create_model() successfully completed......................................
2025-12-03 13:36:05,548:INFO:SubProcess create_model() end ==================================
2025-12-03 13:36:05,548:INFO:choose_better activated
2025-12-03 13:36:05,551:INFO:SubProcess create_model() called ==================================
2025-12-03 13:36:05,551:INFO:Initializing create_model()
2025-12-03 13:36:05,552:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002532B532F50>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-03 13:36:05,552:INFO:Checking exceptions
2025-12-03 13:36:05,553:INFO:Importing libraries
2025-12-03 13:36:05,553:INFO:Copying training dataset
2025-12-03 13:36:05,586:INFO:Defining folds
2025-12-03 13:36:05,586:INFO:Declaring metric variables
2025-12-03 13:36:05,586:INFO:Importing untrained model
2025-12-03 13:36:05,587:INFO:Declaring custom model
2025-12-03 13:36:05,588:INFO:Extreme Gradient Boosting Imported successfully
2025-12-03 13:36:05,588:INFO:Starting cross validation
2025-12-03 13:36:05,589:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-12-03 13:36:16,689:INFO:Calculating mean and std
2025-12-03 13:36:16,691:INFO:Creating metrics dataframe
2025-12-03 13:36:16,692:INFO:Finalizing model
2025-12-03 13:36:16,782:INFO:Warning: No categorical columns found. Calling 'transform' will only return input data.
2025-12-03 13:36:17,848:INFO:Uploading results into container
2025-12-03 13:36:17,849:INFO:Uploading model into container now
2025-12-03 13:36:17,849:INFO:_master_model_container: 3
2025-12-03 13:36:17,849:INFO:_display_container: 4
2025-12-03 13:36:17,849:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2025-12-03 13:36:17,851:INFO:create_model() successfully completed......................................
2025-12-03 13:36:18,029:INFO:SubProcess create_model() end ==================================
2025-12-03 13:36:18,030:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=1,
              num_parallel_tree=None, objective='binary:logistic', ...) result for Recall is 0.1344
2025-12-03 13:36:18,031:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=0.05, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None, max_delta_step=1,
              max_depth=3, max_leaves=None, min_child_weight=None, missing=nan,
              monotone_constraints=None, multi_strategy=None, n_estimators=200,
              n_jobs=1, num_parallel_tree=None, objective='binary:logistic', ...) result for Recall is 0.9603
2025-12-03 13:36:18,031:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=0.05, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None, max_delta_step=1,
              max_depth=3, max_leaves=None, min_child_weight=None, missing=nan,
              monotone_constraints=None, multi_strategy=None, n_estimators=200,
              n_jobs=1, num_parallel_tree=None, objective='binary:logistic', ...) is best model
2025-12-03 13:36:18,031:INFO:choose_better completed
2025-12-03 13:36:18,039:INFO:_master_model_container: 3
2025-12-03 13:36:18,041:INFO:_display_container: 3
2025-12-03 13:36:18,041:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=0.05, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None, max_delta_step=1,
              max_depth=3, max_leaves=None, min_child_weight=None, missing=nan,
              monotone_constraints=None, multi_strategy=None, n_estimators=200,
              n_jobs=1, num_parallel_tree=None, objective='binary:logistic', ...)
2025-12-03 13:36:18,042:INFO:tune_model() successfully completed......................................
2025-12-03 13:36:18,279:INFO:Initializing calibrate_model()
2025-12-03 13:36:18,280:INFO:calibrate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002532B532F50>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=0.05, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None, max_delta_step=1,
              max_depth=3, max_leaves=None, min_child_weight=None, missing=nan,
              monotone_constraints=None, multi_strategy=None, n_estimators=200,
              n_jobs=1, num_parallel_tree=None, objective='binary:logistic', ...), method=isotonic, calibrate_fold=5, fold=None, round=4, fit_kwargs=None, groups=None, verbose=True, return_train_score=False)
2025-12-03 13:36:18,280:INFO:Checking exceptions
2025-12-03 13:36:18,293:INFO:Preloading libraries
2025-12-03 13:36:18,293:INFO:Preparing display monitor
2025-12-03 13:36:18,307:INFO:Getting model name
2025-12-03 13:36:18,307:INFO:Base model : Extreme Gradient Boosting
2025-12-03 13:36:18,313:INFO:Importing untrained CalibratedClassifierCV
2025-12-03 13:36:18,315:INFO:SubProcess create_model() called ==================================
2025-12-03 13:36:18,317:INFO:Initializing create_model()
2025-12-03 13:36:18,317:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002532B532F50>, estimator=CalibratedClassifierCV(cv=5, ensemble=True,
                       estimator=XGBClassifier(base_score=None,
                                               booster='gbtree', callbacks=None,
                                               colsample_bylevel=None,
                                               colsample_bynode=None,
                                               colsample_bytree=None,
                                               device='cpu',
                                               early_stopping_rounds=None,
                                               enable_categorical=False,
                                               eval_metric=None,
                                               feature_types=None, gamma=None,
                                               grow_policy=None,
                                               importance_type=None,
                                               interaction_constraints=None,
                                               learning_rate=0.05, max_bin=None,
                                               max_cat_threshold=None,
                                               max_cat_to_onehot=None,
                                               max_delta_step=1, max_depth=3,
                                               max_leaves=None,
                                               min_child_weight=None,
                                               missing=nan,
                                               monotone_constraints=None,
                                               multi_strategy=None,
                                               n_estimators=200, n_jobs=1,
                                               num_parallel_tree=None,
                                               objective='binary:logistic', ...),
                       method='isotonic', n_jobs=None), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002531013FCA0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-12-03 13:36:18,317:INFO:Checking exceptions
2025-12-03 13:36:18,317:INFO:Importing libraries
2025-12-03 13:36:18,317:INFO:Copying training dataset
2025-12-03 13:36:18,351:INFO:Defining folds
2025-12-03 13:36:18,352:INFO:Declaring metric variables
2025-12-03 13:36:18,356:INFO:Importing untrained model
2025-12-03 13:36:18,356:INFO:Declaring custom model
2025-12-03 13:36:18,361:INFO:Extreme Gradient Boosting Imported successfully
2025-12-03 13:36:18,369:INFO:Starting cross validation
2025-12-03 13:36:18,369:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-12-03 13:36:53,531:INFO:Calculating mean and std
2025-12-03 13:36:53,531:INFO:Creating metrics dataframe
2025-12-03 13:36:53,541:INFO:Finalizing model
2025-12-03 13:36:53,625:INFO:Warning: No categorical columns found. Calling 'transform' will only return input data.
2025-12-03 13:36:57,176:INFO:Uploading results into container
2025-12-03 13:36:57,176:INFO:Uploading model into container now
2025-12-03 13:36:57,176:INFO:_master_model_container: 4
2025-12-03 13:36:57,176:INFO:_display_container: 4
2025-12-03 13:36:57,179:INFO:CalibratedClassifierCV(cv=5, ensemble=True,
                       estimator=XGBClassifier(base_score=None,
                                               booster='gbtree', callbacks=None,
                                               colsample_bylevel=None,
                                               colsample_bynode=None,
                                               colsample_bytree=None,
                                               device='cpu',
                                               early_stopping_rounds=None,
                                               enable_categorical=False,
                                               eval_metric=None,
                                               feature_types=None, gamma=None,
                                               grow_policy=None,
                                               importance_type=None,
                                               interaction_constraints=None,
                                               learning_rate=0.05, max_bin=None,
                                               max_cat_threshold=None,
                                               max_cat_to_onehot=None,
                                               max_delta_step=1, max_depth=3,
                                               max_leaves=None,
                                               min_child_weight=None,
                                               missing=nan,
                                               monotone_constraints=None,
                                               multi_strategy=None,
                                               n_estimators=200, n_jobs=1,
                                               num_parallel_tree=None,
                                               objective='binary:logistic', ...),
                       method='isotonic', n_jobs=None)
2025-12-03 13:36:57,179:INFO:create_model() successfully completed......................................
2025-12-03 13:36:57,371:INFO:SubProcess create_model() end ==================================
2025-12-03 13:36:57,387:INFO:_master_model_container: 4
2025-12-03 13:36:57,387:INFO:_display_container: 4
2025-12-03 13:36:57,389:INFO:CalibratedClassifierCV(cv=5, ensemble=True,
                       estimator=XGBClassifier(base_score=None,
                                               booster='gbtree', callbacks=None,
                                               colsample_bylevel=None,
                                               colsample_bynode=None,
                                               colsample_bytree=None,
                                               device='cpu',
                                               early_stopping_rounds=None,
                                               enable_categorical=False,
                                               eval_metric=None,
                                               feature_types=None, gamma=None,
                                               grow_policy=None,
                                               importance_type=None,
                                               interaction_constraints=None,
                                               learning_rate=0.05, max_bin=None,
                                               max_cat_threshold=None,
                                               max_cat_to_onehot=None,
                                               max_delta_step=1, max_depth=3,
                                               max_leaves=None,
                                               min_child_weight=None,
                                               missing=nan,
                                               monotone_constraints=None,
                                               multi_strategy=None,
                                               n_estimators=200, n_jobs=1,
                                               num_parallel_tree=None,
                                               objective='binary:logistic', ...),
                       method='isotonic', n_jobs=None)
2025-12-03 13:36:57,389:INFO:calibrate_model() successfully completed......................................
2025-12-03 13:36:57,642:INFO:Initializing plot_model()
2025-12-03 13:36:57,642:INFO:plot_model(plot=auc, fold=None, verbose=True, display=None, display_format=None, estimator=CalibratedClassifierCV(cv=5, ensemble=True,
                       estimator=XGBClassifier(base_score=None,
                                               booster='gbtree', callbacks=None,
                                               colsample_bylevel=None,
                                               colsample_bynode=None,
                                               colsample_bytree=None,
                                               device='cpu',
                                               early_stopping_rounds=None,
                                               enable_categorical=False,
                                               eval_metric=None,
                                               feature_types=None, gamma=None,
                                               grow_policy=None,
                                               importance_type=None,
                                               interaction_constraints=None,
                                               learning_rate=0.05, max_bin=None,
                                               max_cat_threshold=None,
                                               max_cat_to_onehot=None,
                                               max_delta_step=1, max_depth=3,
                                               max_leaves=None,
                                               min_child_weight=None,
                                               missing=nan,
                                               monotone_constraints=None,
                                               multi_strategy=None,
                                               n_estimators=200, n_jobs=1,
                                               num_parallel_tree=None,
                                               objective='binary:logistic', ...),
                       method='isotonic', n_jobs=None), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002532B532F50>, system=True)
2025-12-03 13:36:57,642:INFO:Checking exceptions
2025-12-03 13:36:57,657:INFO:Preloading libraries
2025-12-03 13:36:57,696:INFO:Copying training dataset
2025-12-03 13:36:57,696:INFO:Plot type: auc
2025-12-03 13:36:57,946:INFO:Fitting Model
2025-12-03 13:36:57,946:INFO:Scoring test/hold-out set
2025-12-03 13:36:58,308:INFO:Visual Rendered Successfully
2025-12-03 13:36:58,479:INFO:plot_model() successfully completed......................................
2025-12-03 13:36:58,481:INFO:Initializing get_config()
2025-12-03 13:36:58,481:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002532B532F50>, variable=X_test_transformed)
2025-12-03 13:36:58,556:INFO:Variable: X_test returned as             Age  IncomeRatio  SystolicBP  WaistCircumference    Height  \
28456 -1.166682    -0.347193   -0.857495           -1.507527 -1.819875   
8993   0.143689     0.336722    1.662729            0.648015 -0.645962   
34312  0.028744     0.094199    0.120503            0.346962  0.583851   
4802  -1.235649     0.337285   -0.681087           -0.938256 -0.976048   
25895  0.028744     1.529936   -0.456265           -0.413678  0.081658   
...         ...          ...         ...                 ...       ...   
18045 -1.258638    -0.075567   -0.904070           -1.993226 -3.285713   
5425  -0.086201     0.470887    1.712883           -0.086555 -0.006211   
12819  0.235645     0.002041    0.478158            0.708225  1.515528   
33659 -1.212660     1.326217   -0.863547           -1.487456 -2.074533   
19531 -1.281627    -0.395697   -0.849048           -1.848720 -3.664595   

       TotalCholesterol  Triglycerides       LDL       HDL     HbA1c  ...  \
28456         -0.077253      -0.647020 -0.018927  0.563922 -0.617463  ...   
8993           0.702398       0.630424  0.004953  0.590479  0.121825  ...   
34312         -0.118546       0.874313 -0.747277 -1.115404  0.666895  ...   
4802          -0.178619      -0.486105  0.000596  0.050858 -0.563915  ...   
25895          0.819676       1.267174  0.006537 -0.056580 -0.314232  ...   
...                 ...            ...       ...       ...       ...  ...   
18045         -0.319533      -0.646830 -0.614729  0.541608 -0.630163  ...   
5425           0.397476      -0.206569  0.807814  0.296361 -0.096204  ...   
12819         -0.681479      -0.646225 -0.152735 -0.821286  0.121825  ...   
33659         -0.986401      -0.647239 -2.064660  0.296361 -0.699939  ...   
19531         -0.334260      -0.646844 -0.652171  0.541702 -0.458463  ...   

       Race_5.0  Race_1.0  Race_4.0  Race_3.0  Race_2.0  Education   Smoking  \
28456       1.0       0.0  0.000000 -0.147343       0.0  -0.020637 -0.322757   
8993        0.0       0.0  3.165789 -0.147343       0.0   0.527633  0.677243   
34312       0.0       0.0  0.000000  0.852657       0.0  -0.653648 -0.322757   
4802        1.0       0.0  0.000000 -0.147343       0.0   0.249169 -0.249145   
25895       0.0       0.0  0.000000  0.852657       0.0   1.118273 -0.322757   
...         ...       ...       ...       ...       ...        ...       ...   
18045       0.0       0.0  0.000000  0.852657       0.0  -0.784293 -0.322757   
5425        0.0       0.0  3.165789 -0.147343       0.0   0.527633  0.677243   
12819       0.0       0.0  0.000000  0.852657       0.0   1.118273  0.677243   
33659       0.0       0.0  3.165789 -0.147343       0.0   0.244733 -0.322757   
19531       1.0       0.0  0.000000 -0.147343       0.0  -0.811611 -0.322757   

       PhysicalActivity  HealthInsurance   Alcohol  
28456          0.867745              0.0 -0.852427  
8993           0.000000              0.0 -0.111403  
34312          0.000000              0.0  0.446044  
4802           1.329964              0.0 -0.367022  
25895          0.000000              0.0 -1.282459  
...                 ...              ...       ...  
18045          1.188011              0.0 -0.810481  
5425           2.099341              0.0 -0.131905  
12819          2.099341              0.0  0.470282  
33659          1.527044              0.0 -0.426709  
19531          1.039465              0.0 -1.044925  

[13109 rows x 30 columns]
2025-12-03 13:36:58,556:INFO:get_config() successfully completed......................................
2025-12-03 13:36:58,556:INFO:Initializing get_config()
2025-12-03 13:36:58,556:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002532B532F50>, variable=y_test)
2025-12-03 13:36:58,556:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-12-03 13:36:58,556:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-12-03 13:36:58,561:INFO:Variable:  returned as 28456    0.0
8993     0.0
34312    0.0
4802     0.0
25895    0.0
        ... 
18045    0.0
5425     0.0
12819    0.0
33659    0.0
19531    0.0
Name: HeartDisease, Length: 13109, dtype: float32
2025-12-03 13:36:58,561:INFO:get_config() successfully completed......................................
2025-12-03 13:36:58,720:INFO:Initializing plot_model()
2025-12-03 13:36:58,720:INFO:plot_model(plot=pr, fold=None, verbose=True, display=None, display_format=None, estimator=CalibratedClassifierCV(cv=5, ensemble=True,
                       estimator=XGBClassifier(base_score=None,
                                               booster='gbtree', callbacks=None,
                                               colsample_bylevel=None,
                                               colsample_bynode=None,
                                               colsample_bytree=None,
                                               device='cpu',
                                               early_stopping_rounds=None,
                                               enable_categorical=False,
                                               eval_metric=None,
                                               feature_types=None, gamma=None,
                                               grow_policy=None,
                                               importance_type=None,
                                               interaction_constraints=None,
                                               learning_rate=0.05, max_bin=None,
                                               max_cat_threshold=None,
                                               max_cat_to_onehot=None,
                                               max_delta_step=1, max_depth=3,
                                               max_leaves=None,
                                               min_child_weight=None,
                                               missing=nan,
                                               monotone_constraints=None,
                                               multi_strategy=None,
                                               n_estimators=200, n_jobs=1,
                                               num_parallel_tree=None,
                                               objective='binary:logistic', ...),
                       method='isotonic', n_jobs=None), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002532B532F50>, system=True)
2025-12-03 13:36:58,720:INFO:Checking exceptions
2025-12-03 13:36:58,735:INFO:Preloading libraries
2025-12-03 13:36:58,794:INFO:Copying training dataset
2025-12-03 13:36:58,796:INFO:Plot type: pr
2025-12-03 13:36:59,046:INFO:Fitting Model
2025-12-03 13:36:59,048:INFO:Scoring test/hold-out set
2025-12-03 13:36:59,389:INFO:Visual Rendered Successfully
2025-12-03 13:36:59,578:INFO:plot_model() successfully completed......................................
2025-12-03 13:36:59,641:INFO:Initializing plot_model()
2025-12-03 13:36:59,641:INFO:plot_model(plot=confusion_matrix, fold=None, verbose=True, display=None, display_format=None, estimator=CalibratedClassifierCV(cv=5, ensemble=True,
                       estimator=XGBClassifier(base_score=None,
                                               booster='gbtree', callbacks=None,
                                               colsample_bylevel=None,
                                               colsample_bynode=None,
                                               colsample_bytree=None,
                                               device='cpu',
                                               early_stopping_rounds=None,
                                               enable_categorical=False,
                                               eval_metric=None,
                                               feature_types=None, gamma=None,
                                               grow_policy=None,
                                               importance_type=None,
                                               interaction_constraints=None,
                                               learning_rate=0.05, max_bin=None,
                                               max_cat_threshold=None,
                                               max_cat_to_onehot=None,
                                               max_delta_step=1, max_depth=3,
                                               max_leaves=None,
                                               min_child_weight=None,
                                               missing=nan,
                                               monotone_constraints=None,
                                               multi_strategy=None,
                                               n_estimators=200, n_jobs=1,
                                               num_parallel_tree=None,
                                               objective='binary:logistic', ...),
                       method='isotonic', n_jobs=None), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002532B532F50>, system=True)
2025-12-03 13:36:59,641:INFO:Checking exceptions
2025-12-03 13:36:59,653:INFO:Preloading libraries
2025-12-03 13:36:59,689:INFO:Copying training dataset
2025-12-03 13:36:59,689:INFO:Plot type: confusion_matrix
2025-12-03 13:36:59,971:INFO:Fitting Model
2025-12-03 13:36:59,972:INFO:Scoring test/hold-out set
2025-12-03 13:37:00,323:INFO:Visual Rendered Successfully
2025-12-03 13:37:00,506:INFO:plot_model() successfully completed......................................
2025-12-03 13:37:00,533:INFO:Initializing plot_model()
2025-12-03 13:37:00,533:INFO:plot_model(plot=error, fold=None, verbose=True, display=None, display_format=None, estimator=CalibratedClassifierCV(cv=5, ensemble=True,
                       estimator=XGBClassifier(base_score=None,
                                               booster='gbtree', callbacks=None,
                                               colsample_bylevel=None,
                                               colsample_bynode=None,
                                               colsample_bytree=None,
                                               device='cpu',
                                               early_stopping_rounds=None,
                                               enable_categorical=False,
                                               eval_metric=None,
                                               feature_types=None, gamma=None,
                                               grow_policy=None,
                                               importance_type=None,
                                               interaction_constraints=None,
                                               learning_rate=0.05, max_bin=None,
                                               max_cat_threshold=None,
                                               max_cat_to_onehot=None,
                                               max_delta_step=1, max_depth=3,
                                               max_leaves=None,
                                               min_child_weight=None,
                                               missing=nan,
                                               monotone_constraints=None,
                                               multi_strategy=None,
                                               n_estimators=200, n_jobs=1,
                                               num_parallel_tree=None,
                                               objective='binary:logistic', ...),
                       method='isotonic', n_jobs=None), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002532B532F50>, system=True)
2025-12-03 13:37:00,533:INFO:Checking exceptions
2025-12-03 13:37:00,548:INFO:Preloading libraries
2025-12-03 13:37:00,585:INFO:Copying training dataset
2025-12-03 13:37:00,586:INFO:Plot type: error
2025-12-03 13:37:00,867:INFO:Fitting Model
2025-12-03 13:37:00,869:INFO:Scoring test/hold-out set
2025-12-03 13:37:01,229:INFO:Visual Rendered Successfully
2025-12-03 13:37:01,410:INFO:plot_model() successfully completed......................................
2025-12-03 13:37:01,451:INFO:Initializing plot_model()
2025-12-03 13:37:01,451:INFO:plot_model(plot=calibration, fold=None, verbose=True, display=None, display_format=None, estimator=CalibratedClassifierCV(cv=5, ensemble=True,
                       estimator=XGBClassifier(base_score=None,
                                               booster='gbtree', callbacks=None,
                                               colsample_bylevel=None,
                                               colsample_bynode=None,
                                               colsample_bytree=None,
                                               device='cpu',
                                               early_stopping_rounds=None,
                                               enable_categorical=False,
                                               eval_metric=None,
                                               feature_types=None, gamma=None,
                                               grow_policy=None,
                                               importance_type=None,
                                               interaction_constraints=None,
                                               learning_rate=0.05, max_bin=None,
                                               max_cat_threshold=None,
                                               max_cat_to_onehot=None,
                                               max_delta_step=1, max_depth=3,
                                               max_leaves=None,
                                               min_child_weight=None,
                                               missing=nan,
                                               monotone_constraints=None,
                                               multi_strategy=None,
                                               n_estimators=200, n_jobs=1,
                                               num_parallel_tree=None,
                                               objective='binary:logistic', ...),
                       method='isotonic', n_jobs=None), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002532B532F50>, system=True)
2025-12-03 13:37:01,451:INFO:Checking exceptions
2025-12-03 13:37:01,464:INFO:Preloading libraries
2025-12-03 13:37:01,499:INFO:Copying training dataset
2025-12-03 13:37:01,499:INFO:Plot type: calibration
2025-12-03 13:37:01,514:INFO:Scoring test/hold-out set
2025-12-03 13:37:01,929:INFO:Visual Rendered Successfully
2025-12-03 13:37:02,100:INFO:plot_model() successfully completed......................................
2025-12-03 13:37:02,133:INFO:Initializing interpret_model()
2025-12-03 13:37:02,133:INFO:interpret_model(estimator=CalibratedClassifierCV(cv=5, ensemble=True,
                       estimator=XGBClassifier(base_score=None,
                                               booster='gbtree', callbacks=None,
                                               colsample_bylevel=None,
                                               colsample_bynode=None,
                                               colsample_bytree=None,
                                               device='cpu',
                                               early_stopping_rounds=None,
                                               enable_categorical=False,
                                               eval_metric=None,
                                               feature_types=None, gamma=None,
                                               grow_policy=None,
                                               importance_type=None,
                                               interaction_constraints=None,
                                               learning_rate=0.05, max_bin=None,
                                               max_cat_threshold=None,
                                               max_cat_to_onehot=None,
                                               max_delta_step=1, max_depth=3,
                                               max_leaves=None,
                                               min_child_weight=None,
                                               missing=nan,
                                               monotone_constraints=None,
                                               multi_strategy=None,
                                               n_estimators=200, n_jobs=1,
                                               num_parallel_tree=None,
                                               objective='binary:logistic', ...),
                       method='isotonic', n_jobs=None), use_train_data=False, X_new_sample=None, y_new_sample=None, feature=None, kwargs={}, observation=None, plot=summary, save=False, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002532B532F50>)
2025-12-03 13:37:02,133:INFO:Checking exceptions
2025-12-03 13:37:02,133:INFO:Soft dependency imported: shap: 0.49.1
2025-12-03 13:37:02,189:INFO:Initializing get_config()
2025-12-03 13:37:02,189:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002532B532F50>, variable=X_test_transformed)
2025-12-03 13:37:02,320:INFO:Variable: X_test returned as             Age  IncomeRatio  SystolicBP  WaistCircumference    Height  \
28456 -1.166682    -0.347193   -0.857495           -1.507527 -1.819875   
8993   0.143689     0.336722    1.662729            0.648015 -0.645962   
34312  0.028744     0.094199    0.120503            0.346962  0.583851   
4802  -1.235649     0.337285   -0.681087           -0.938256 -0.976048   
25895  0.028744     1.529936   -0.456265           -0.413678  0.081658   
...         ...          ...         ...                 ...       ...   
18045 -1.258638    -0.075567   -0.904070           -1.993226 -3.285713   
5425  -0.086201     0.470887    1.712883           -0.086555 -0.006211   
12819  0.235645     0.002041    0.478158            0.708225  1.515528   
33659 -1.212660     1.326217   -0.863547           -1.487456 -2.074533   
19531 -1.281627    -0.395697   -0.849048           -1.848720 -3.664595   

       TotalCholesterol  Triglycerides       LDL       HDL     HbA1c  ...  \
28456         -0.077253      -0.647020 -0.018927  0.563922 -0.617463  ...   
8993           0.702398       0.630424  0.004953  0.590479  0.121825  ...   
34312         -0.118546       0.874313 -0.747277 -1.115404  0.666895  ...   
4802          -0.178619      -0.486105  0.000596  0.050858 -0.563915  ...   
25895          0.819676       1.267174  0.006537 -0.056580 -0.314232  ...   
...                 ...            ...       ...       ...       ...  ...   
18045         -0.319533      -0.646830 -0.614729  0.541608 -0.630163  ...   
5425           0.397476      -0.206569  0.807814  0.296361 -0.096204  ...   
12819         -0.681479      -0.646225 -0.152735 -0.821286  0.121825  ...   
33659         -0.986401      -0.647239 -2.064660  0.296361 -0.699939  ...   
19531         -0.334260      -0.646844 -0.652171  0.541702 -0.458463  ...   

       Race_5.0  Race_1.0  Race_4.0  Race_3.0  Race_2.0  Education   Smoking  \
28456       1.0       0.0  0.000000 -0.147343       0.0  -0.020637 -0.322757   
8993        0.0       0.0  3.165789 -0.147343       0.0   0.527633  0.677243   
34312       0.0       0.0  0.000000  0.852657       0.0  -0.653648 -0.322757   
4802        1.0       0.0  0.000000 -0.147343       0.0   0.249169 -0.249145   
25895       0.0       0.0  0.000000  0.852657       0.0   1.118273 -0.322757   
...         ...       ...       ...       ...       ...        ...       ...   
18045       0.0       0.0  0.000000  0.852657       0.0  -0.784293 -0.322757   
5425        0.0       0.0  3.165789 -0.147343       0.0   0.527633  0.677243   
12819       0.0       0.0  0.000000  0.852657       0.0   1.118273  0.677243   
33659       0.0       0.0  3.165789 -0.147343       0.0   0.244733 -0.322757   
19531       1.0       0.0  0.000000 -0.147343       0.0  -0.811611 -0.322757   

       PhysicalActivity  HealthInsurance   Alcohol  
28456          0.867745              0.0 -0.852427  
8993           0.000000              0.0 -0.111403  
34312          0.000000              0.0  0.446044  
4802           1.329964              0.0 -0.367022  
25895          0.000000              0.0 -1.282459  
...                 ...              ...       ...  
18045          1.188011              0.0 -0.810481  
5425           2.099341              0.0 -0.131905  
12819          2.099341              0.0  0.470282  
33659          1.527044              0.0 -0.426709  
19531          1.039465              0.0 -1.044925  

[13109 rows x 30 columns]
2025-12-03 13:37:02,320:INFO:get_config() successfully completed......................................
2025-12-03 13:37:02,321:INFO:Initializing get_config()
2025-12-03 13:37:02,321:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002532B532F50>, variable=y_test)
2025-12-03 13:37:02,321:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-12-03 13:37:02,321:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-12-03 13:37:02,328:INFO:Variable:  returned as 28456    0.0
8993     0.0
34312    0.0
4802     0.0
25895    0.0
        ... 
18045    0.0
5425     0.0
12819    0.0
33659    0.0
19531    0.0
Name: HeartDisease, Length: 13109, dtype: float32
2025-12-03 13:37:02,328:INFO:get_config() successfully completed......................................
2025-12-03 13:37:03,413:INFO:Initializing finalize_model()
2025-12-03 13:37:03,413:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002532B532F50>, estimator=CalibratedClassifierCV(cv=5, ensemble=True,
                       estimator=XGBClassifier(base_score=None,
                                               booster='gbtree', callbacks=None,
                                               colsample_bylevel=None,
                                               colsample_bynode=None,
                                               colsample_bytree=None,
                                               device='cpu',
                                               early_stopping_rounds=None,
                                               enable_categorical=False,
                                               eval_metric=None,
                                               feature_types=None, gamma=None,
                                               grow_policy=None,
                                               importance_type=None,
                                               interaction_constraints=None,
                                               learning_rate=0.05, max_bin=None,
                                               max_cat_threshold=None,
                                               max_cat_to_onehot=None,
                                               max_delta_step=1, max_depth=3,
                                               max_leaves=None,
                                               min_child_weight=None,
                                               missing=nan,
                                               monotone_constraints=None,
                                               multi_strategy=None,
                                               n_estimators=200, n_jobs=1,
                                               num_parallel_tree=None,
                                               objective='binary:logistic', ...),
                       method='isotonic', n_jobs=None), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2025-12-03 13:37:03,413:INFO:Finalizing CalibratedClassifierCV(cv=5, ensemble=True,
                       estimator=XGBClassifier(base_score=None,
                                               booster='gbtree', callbacks=None,
                                               colsample_bylevel=None,
                                               colsample_bynode=None,
                                               colsample_bytree=None,
                                               device='cpu',
                                               early_stopping_rounds=None,
                                               enable_categorical=False,
                                               eval_metric=None,
                                               feature_types=None, gamma=None,
                                               grow_policy=None,
                                               importance_type=None,
                                               interaction_constraints=None,
                                               learning_rate=0.05, max_bin=None,
                                               max_cat_threshold=None,
                                               max_cat_to_onehot=None,
                                               max_delta_step=1, max_depth=3,
                                               max_leaves=None,
                                               min_child_weight=None,
                                               missing=nan,
                                               monotone_constraints=None,
                                               multi_strategy=None,
                                               n_estimators=200, n_jobs=1,
                                               num_parallel_tree=None,
                                               objective='binary:logistic', ...),
                       method='isotonic', n_jobs=None)
2025-12-03 13:37:03,430:INFO:Initializing create_model()
2025-12-03 13:37:03,430:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002532B532F50>, estimator=CalibratedClassifierCV(cv=5, ensemble=True,
                       estimator=XGBClassifier(base_score=None,
                                               booster='gbtree', callbacks=None,
                                               colsample_bylevel=None,
                                               colsample_bynode=None,
                                               colsample_bytree=None,
                                               device='cpu',
                                               early_stopping_rounds=None,
                                               enable_categorical=False,
                                               eval_metric=None,
                                               feature_types=None, gamma=None,
                                               grow_policy=None,
                                               importance_type=None,
                                               interaction_constraints=None,
                                               learning_rate=0.05, max_bin=None,
                                               max_cat_threshold=None,
                                               max_cat_to_onehot=None,
                                               max_delta_step=1, max_depth=3,
                                               max_leaves=None,
                                               min_child_weight=None,
                                               missing=nan,
                                               monotone_constraints=None,
                                               multi_strategy=None,
                                               n_estimators=200, n_jobs=1,
                                               num_parallel_tree=None,
                                               objective='binary:logistic', ...),
                       method='isotonic', n_jobs=None), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2025-12-03 13:37:03,430:INFO:Checking exceptions
2025-12-03 13:37:03,432:INFO:Importing libraries
2025-12-03 13:37:03,432:INFO:Copying training dataset
2025-12-03 13:37:03,434:INFO:Defining folds
2025-12-03 13:37:03,434:INFO:Declaring metric variables
2025-12-03 13:37:03,434:INFO:Importing untrained model
2025-12-03 13:37:03,435:INFO:Declaring custom model
2025-12-03 13:37:03,436:INFO:Extreme Gradient Boosting Imported successfully
2025-12-03 13:37:03,437:INFO:Cross validation set to False
2025-12-03 13:37:03,437:INFO:Fitting Model
2025-12-03 13:37:03,547:INFO:Warning: No categorical columns found. Calling 'transform' will only return input data.
2025-12-03 13:37:08,479:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'IncomeRatio', 'SystolicBP',
                                             'BMI', 'WaistCircumference',
                                             'Height', 'TotalCholesterol',
                                             'Triglycerides', 'LDL', 'HDL',
                                             'HbA1c', 'Glucose', 'Creatinine',
                                             'UricAcid', 'ALT_Enzyme',
                                             'Albumin', 'Potassium', 'Sodium',
                                             'GGT_Enzyme', 'AST_Enzyme'],
                                    transformer=Si...
                                                                interaction_constraints=None,
                                                                learning_rate=0.05,
                                                                max_bin=None,
                                                                max_cat_threshold=None,
                                                                max_cat_to_onehot=None,
                                                                max_delta_step=1,
                                                                max_depth=3,
                                                                max_leaves=None,
                                                                min_child_weight=None,
                                                                missing=nan,
                                                                monotone_constraints=None,
                                                                multi_strategy=None,
                                                                n_estimators=200,
                                                                n_jobs=1,
                                                                num_parallel_tree=None,
                                                                objective='binary:logistic', ...),
                                        method='isotonic', n_jobs=None))],
         verbose=False)
2025-12-03 13:37:08,479:INFO:create_model() successfully completed......................................
2025-12-03 13:37:08,637:INFO:_master_model_container: 4
2025-12-03 13:37:08,637:INFO:_display_container: 4
2025-12-03 13:37:08,657:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'IncomeRatio', 'SystolicBP',
                                             'BMI', 'WaistCircumference',
                                             'Height', 'TotalCholesterol',
                                             'Triglycerides', 'LDL', 'HDL',
                                             'HbA1c', 'Glucose', 'Creatinine',
                                             'UricAcid', 'ALT_Enzyme',
                                             'Albumin', 'Potassium', 'Sodium',
                                             'GGT_Enzyme', 'AST_Enzyme'],
                                    transformer=Si...
                                                                interaction_constraints=None,
                                                                learning_rate=0.05,
                                                                max_bin=None,
                                                                max_cat_threshold=None,
                                                                max_cat_to_onehot=None,
                                                                max_delta_step=1,
                                                                max_depth=3,
                                                                max_leaves=None,
                                                                min_child_weight=None,
                                                                missing=nan,
                                                                monotone_constraints=None,
                                                                multi_strategy=None,
                                                                n_estimators=200,
                                                                n_jobs=1,
                                                                num_parallel_tree=None,
                                                                objective='binary:logistic', ...),
                                        method='isotonic', n_jobs=None))],
         verbose=False)
2025-12-03 13:37:08,657:INFO:finalize_model() successfully completed......................................
2025-12-03 13:37:08,846:INFO:Initializing save_model()
2025-12-03 13:37:08,846:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'IncomeRatio', 'SystolicBP',
                                             'BMI', 'WaistCircumference',
                                             'Height', 'TotalCholesterol',
                                             'Triglycerides', 'LDL', 'HDL',
                                             'HbA1c', 'Glucose', 'Creatinine',
                                             'UricAcid', 'ALT_Enzyme',
                                             'Albumin', 'Potassium', 'Sodium',
                                             'GGT_Enzyme', 'AST_Enzyme'],
                                    transformer=Si...
                                                                interaction_constraints=None,
                                                                learning_rate=0.05,
                                                                max_bin=None,
                                                                max_cat_threshold=None,
                                                                max_cat_to_onehot=None,
                                                                max_delta_step=1,
                                                                max_depth=3,
                                                                max_leaves=None,
                                                                min_child_weight=None,
                                                                missing=nan,
                                                                monotone_constraints=None,
                                                                multi_strategy=None,
                                                                n_estimators=200,
                                                                n_jobs=1,
                                                                num_parallel_tree=None,
                                                                objective='binary:logistic', ...),
                                        method='isotonic', n_jobs=None))],
         verbose=False), model_name=../models\best_pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\OMAR\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'IncomeRatio', 'SystolicBP',
                                             'BMI', 'WaistCircumference',
                                             'Height', 'TotalCholesterol',
                                             'Triglycerides', 'LDL', 'HDL',
                                             'HbA1c', 'Glucose', 'Creatinine',
                                             'UricAcid', 'ALT_Enzyme',
                                             'Albumin', 'Potassium', 'Sodium',
                                             'G...
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              random_state=42,
                                                                              sampling_strategy='auto')))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=RobustScaler(copy=True,
                                                             quantile_range=(25.0,
                                                                             75.0),
                                                             unit_variance=False,
                                                             with_centering=True,
                                                             with_scaling=True)))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2025-12-03 13:37:08,846:INFO:Adding model into prep_pipe
2025-12-03 13:37:08,846:WARNING:Only Model saved as it was a pipeline.
2025-12-03 13:37:08,861:INFO:../models\best_pipeline.pkl saved in current working directory
2025-12-03 13:37:08,881:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'IncomeRatio', 'SystolicBP',
                                             'BMI', 'WaistCircumference',
                                             'Height', 'TotalCholesterol',
                                             'Triglycerides', 'LDL', 'HDL',
                                             'HbA1c', 'Glucose', 'Creatinine',
                                             'UricAcid', 'ALT_Enzyme',
                                             'Albumin', 'Potassium', 'Sodium',
                                             'GGT_Enzyme', 'AST_Enzyme'],
                                    transformer=Si...
                                                                interaction_constraints=None,
                                                                learning_rate=0.05,
                                                                max_bin=None,
                                                                max_cat_threshold=None,
                                                                max_cat_to_onehot=None,
                                                                max_delta_step=1,
                                                                max_depth=3,
                                                                max_leaves=None,
                                                                min_child_weight=None,
                                                                missing=nan,
                                                                monotone_constraints=None,
                                                                multi_strategy=None,
                                                                n_estimators=200,
                                                                n_jobs=1,
                                                                num_parallel_tree=None,
                                                                objective='binary:logistic', ...),
                                        method='isotonic', n_jobs=None))],
         verbose=False)
2025-12-03 13:37:08,881:INFO:save_model() successfully completed......................................
2025-12-03 13:47:03,789:INFO:Initializing interpret_model()
2025-12-03 13:47:03,789:INFO:interpret_model(estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=0.05, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None, max_delta_step=1,
              max_depth=3, max_leaves=None, min_child_weight=None, missing=nan,
              monotone_constraints=None, multi_strategy=None, n_estimators=200,
              n_jobs=1, num_parallel_tree=None, objective='binary:logistic', ...), use_train_data=False, X_new_sample=None, y_new_sample=None, feature=None, kwargs={}, observation=None, plot=summary, save=False, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002532B532F50>)
2025-12-03 13:47:03,789:INFO:Checking exceptions
2025-12-03 13:47:03,789:INFO:Soft dependency imported: shap: 0.49.1
2025-12-03 13:47:03,868:INFO:plot type: summary
2025-12-03 13:47:03,868:INFO:Creating TreeExplainer
2025-12-03 13:47:03,885:INFO:Compiling shap values
2025-12-03 13:47:04,853:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:4145: FutureWarning: The NumPy global RNG was seeded by calling `np.random.seed`. In a future version this function will no longer use the global RNG. Pass `rng` explicitly to opt-in to the new behaviour and silence this warning.

2025-12-03 13:47:05,963:INFO:Visual Rendered Successfully
2025-12-03 13:47:05,963:INFO:interpret_model() successfully completed......................................
2025-12-03 13:54:40,849:INFO:Initializing load_model()
2025-12-03 13:54:40,849:INFO:load_model(model_name=../models/best_pipeline, platform=None, authentication=None, verbose=True)
2025-12-03 13:54:40,955:INFO:Initializing predict_model()
2025-12-03 13:54:40,955:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027809D6FD60>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Age', 'IncomeRatio', 'SystolicBP',
                                             'BMI', 'WaistCircumference',
                                             'Height', 'TotalCholesterol',
                                             'Triglycerides', 'LDL', 'HDL',
                                             'HbA1c', 'Glucose', 'Creatinine',
                                             'UricAcid', 'ALT_Enzyme',
                                             'Albumin', 'Potassium', 'Sodium',
                                             'GGT_Enzyme', 'AST_Enzyme'],
                                    transformer=SimpleImputer()...
                                                                grow_policy=None,
                                                                importance_type=None,
                                                                interaction_constraints=None,
                                                                learning_rate=0.05,
                                                                max_bin=None,
                                                                max_cat_threshold=None,
                                                                max_cat_to_onehot=None,
                                                                max_delta_step=1,
                                                                max_depth=3,
                                                                max_leaves=None,
                                                                min_child_weight=None,
                                                                missing=nan,
                                                                monotone_constraints=None,
                                                                multi_strategy=None,
                                                                n_estimators=200,
                                                                n_jobs=1,
                                                                num_parallel_tree=None,
                                                                random_state=42, ...),
                                        method='isotonic'))]), probability_threshold=None, encoded_labels=False, raw_score=True, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000027805F46440>)
2025-12-03 13:54:40,955:INFO:Checking exceptions
2025-12-03 13:54:40,955:INFO:Preloading libraries
2025-12-03 13:54:40,955:INFO:Set up data.
2025-12-03 13:54:40,965:INFO:Set up index.
2025-12-03 13:54:41,417:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-03 13:54:41,421:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-03 13:54:41,422:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-03 13:57:21,372:INFO:Initializing load_model()
2025-12-03 13:57:21,372:INFO:load_model(model_name=../models/best_pipeline, platform=None, authentication=None, verbose=True)
2025-12-03 13:57:21,472:INFO:Initializing predict_model()
2025-12-03 13:57:21,472:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027806407EE0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Age', 'IncomeRatio', 'SystolicBP',
                                             'BMI', 'WaistCircumference',
                                             'Height', 'TotalCholesterol',
                                             'Triglycerides', 'LDL', 'HDL',
                                             'HbA1c', 'Glucose', 'Creatinine',
                                             'UricAcid', 'ALT_Enzyme',
                                             'Albumin', 'Potassium', 'Sodium',
                                             'GGT_Enzyme', 'AST_Enzyme'],
                                    transformer=SimpleImputer()...
                                                                grow_policy=None,
                                                                importance_type=None,
                                                                interaction_constraints=None,
                                                                learning_rate=0.05,
                                                                max_bin=None,
                                                                max_cat_threshold=None,
                                                                max_cat_to_onehot=None,
                                                                max_delta_step=1,
                                                                max_depth=3,
                                                                max_leaves=None,
                                                                min_child_weight=None,
                                                                missing=nan,
                                                                monotone_constraints=None,
                                                                multi_strategy=None,
                                                                n_estimators=200,
                                                                n_jobs=1,
                                                                num_parallel_tree=None,
                                                                random_state=42, ...),
                                        method='isotonic'))]), probability_threshold=None, encoded_labels=False, raw_score=True, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002780611BE20>)
2025-12-03 13:57:21,472:INFO:Checking exceptions
2025-12-03 13:57:21,472:INFO:Preloading libraries
2025-12-03 13:57:21,472:INFO:Set up data.
2025-12-03 13:57:21,482:INFO:Set up index.
2025-12-03 13:57:21,933:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-03 13:57:21,939:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-03 13:57:21,941:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-03 13:57:50,394:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-12-03 13:57:50,394:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-12-03 13:57:50,394:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-12-03 13:57:50,394:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-12-03 13:57:52,263:INFO:Initializing load_model()
2025-12-03 13:57:52,265:INFO:load_model(model_name=../models/best_pipeline, platform=None, authentication=None, verbose=True)
2025-12-03 13:57:52,308:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-03 13:57:52,969:INFO:Initializing predict_model()
2025-12-03 13:57:52,969:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000154B257D030>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Age', 'IncomeRatio', 'SystolicBP',
                                             'BMI', 'WaistCircumference',
                                             'Height', 'TotalCholesterol',
                                             'Triglycerides', 'LDL', 'HDL',
                                             'HbA1c', 'Glucose', 'Creatinine',
                                             'UricAcid', 'ALT_Enzyme',
                                             'Albumin', 'Potassium', 'Sodium',
                                             'GGT_Enzyme', 'AST_Enzyme'],
                                    transformer=SimpleImputer()...
                                                                grow_policy=None,
                                                                importance_type=None,
                                                                interaction_constraints=None,
                                                                learning_rate=0.05,
                                                                max_bin=None,
                                                                max_cat_threshold=None,
                                                                max_cat_to_onehot=None,
                                                                max_delta_step=1,
                                                                max_depth=3,
                                                                max_leaves=None,
                                                                min_child_weight=None,
                                                                missing=nan,
                                                                monotone_constraints=None,
                                                                multi_strategy=None,
                                                                n_estimators=200,
                                                                n_jobs=1,
                                                                num_parallel_tree=None,
                                                                random_state=42, ...),
                                        method='isotonic'))]), probability_threshold=None, encoded_labels=False, raw_score=True, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000154B142D360>)
2025-12-03 13:57:52,969:INFO:Checking exceptions
2025-12-03 13:57:52,969:INFO:Preloading libraries
2025-12-03 13:57:52,969:INFO:Set up data.
2025-12-03 13:57:53,108:INFO:Set up index.
2025-12-03 13:57:53,536:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-03 13:57:53,542:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-03 13:57:53,544:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-03 14:13:03,148:INFO:Initializing load_model()
2025-12-03 14:13:03,148:INFO:load_model(model_name=../models/best_pipeline, platform=None, authentication=None, verbose=True)
2025-12-03 14:13:03,253:INFO:Initializing predict_model()
2025-12-03 14:13:03,255:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000154D68094B0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Age', 'IncomeRatio', 'SystolicBP',
                                             'BMI', 'WaistCircumference',
                                             'Height', 'TotalCholesterol',
                                             'Triglycerides', 'LDL', 'HDL',
                                             'HbA1c', 'Glucose', 'Creatinine',
                                             'UricAcid', 'ALT_Enzyme',
                                             'Albumin', 'Potassium', 'Sodium',
                                             'GGT_Enzyme', 'AST_Enzyme'],
                                    transformer=SimpleImputer()...
                                                                grow_policy=None,
                                                                importance_type=None,
                                                                interaction_constraints=None,
                                                                learning_rate=0.05,
                                                                max_bin=None,
                                                                max_cat_threshold=None,
                                                                max_cat_to_onehot=None,
                                                                max_delta_step=1,
                                                                max_depth=3,
                                                                max_leaves=None,
                                                                min_child_weight=None,
                                                                missing=nan,
                                                                monotone_constraints=None,
                                                                multi_strategy=None,
                                                                n_estimators=200,
                                                                n_jobs=1,
                                                                num_parallel_tree=None,
                                                                random_state=42, ...),
                                        method='isotonic'))]), probability_threshold=None, encoded_labels=False, raw_score=True, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000154B142D480>)
2025-12-03 14:13:03,255:INFO:Checking exceptions
2025-12-03 14:13:03,255:INFO:Preloading libraries
2025-12-03 14:13:03,255:INFO:Set up data.
2025-12-03 14:13:03,266:INFO:Set up index.
2025-12-03 14:13:03,709:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-03 14:13:03,714:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-03 14:13:03,716:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-03 14:13:23,863:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-12-03 14:13:23,863:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-12-03 14:13:23,863:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-12-03 14:13:23,863:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-12-03 14:13:25,707:INFO:Initializing load_model()
2025-12-03 14:13:25,707:INFO:load_model(model_name=../models/best_pipeline, platform=None, authentication=None, verbose=True)
2025-12-03 14:13:25,763:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-12-03 14:13:26,417:INFO:Initializing predict_model()
2025-12-03 14:13:26,417:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002290B9CF6A0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Age', 'IncomeRatio', 'SystolicBP',
                                             'BMI', 'WaistCircumference',
                                             'Height', 'TotalCholesterol',
                                             'Triglycerides', 'LDL', 'HDL',
                                             'HbA1c', 'Glucose', 'Creatinine',
                                             'UricAcid', 'ALT_Enzyme',
                                             'Albumin', 'Potassium', 'Sodium',
                                             'GGT_Enzyme', 'AST_Enzyme'],
                                    transformer=SimpleImputer()...
                                                                grow_policy=None,
                                                                importance_type=None,
                                                                interaction_constraints=None,
                                                                learning_rate=0.05,
                                                                max_bin=None,
                                                                max_cat_threshold=None,
                                                                max_cat_to_onehot=None,
                                                                max_delta_step=1,
                                                                max_depth=3,
                                                                max_leaves=None,
                                                                min_child_weight=None,
                                                                missing=nan,
                                                                monotone_constraints=None,
                                                                multi_strategy=None,
                                                                n_estimators=200,
                                                                n_jobs=1,
                                                                num_parallel_tree=None,
                                                                random_state=42, ...),
                                        method='isotonic'))]), probability_threshold=None, encoded_labels=False, raw_score=True, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002296ACDD6C0>)
2025-12-03 14:13:26,417:INFO:Checking exceptions
2025-12-03 14:13:26,417:INFO:Preloading libraries
2025-12-03 14:13:26,417:INFO:Set up data.
2025-12-03 14:13:26,546:INFO:Set up index.
2025-12-03 14:13:27,006:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-03 14:13:27,011:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-12-03 14:13:27,014:WARNING:c:\Users\OMAR\miniconda3\envs\xgb_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

