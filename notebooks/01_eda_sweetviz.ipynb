{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análisis Exploratorio de Datos (EDA) Clínico - NHANES\n",
    "\n",
    "Este notebook realiza un análisis exploratorio detallado sobre el nuevo dataset clínico **NHANES**. \n",
    "El objetivo es validar la calidad de los biomarcadores, analizar sus distribuciones y entender su relación con la variable objetivo `HeartDisease`.\n",
    "\n",
    "## Variables Clave\n",
    "1. **Biomarcadores Numéricos:** SystolicBP, TotalCholesterol, LDL, Triglycerides, HbA1c, Glucose, UricAcid, Creatinine, WaistCircumference, BMI.\n",
    "2. **Variables Categóricas:** Sex, Smoking, PhysicalActivity, HeartDisease (Target).\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Importación de Librerías\n",
    "import pandas as pd\n",
    "import sweetviz as sv\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Configuración visual\n",
    "sns.set_style(\"whitegrid\")\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Carga y Preparación de Datos\n",
    "# Ruta al dataset procesado (ajustar según entorno)\n",
    "DATA_PATH = \"../data/02_intermediate/process_data.parquet\"\n",
    "\n",
    "try:\n",
    "    df = pd.read_parquet(DATA_PATH)\n",
    "    print(f\"Dataset cargado. Dimensiones: {df.shape}\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"ERROR: No se encontró el archivo en {DATA_PATH}. Verifica que el pipeline de datos se haya ejecutado.\")\n",
    "    # En caso de emergencia, intentar ruta absoluta o alternativa si existe\n",
    "    # df = pd.read_parquet(\"data/02_intermediate/process_data.parquet\")\n",
    "\n",
    "# Mapeo de columnas (Español -> Inglés) para estandarizar reporte\n",
    "column_mapping = {\n",
    "    'Presion_Sistolica': 'SystolicBP',\n",
    "    'Colesterol_Total': 'TotalCholesterol',\n",
    "    'Trigliceridos': 'Triglycerides',\n",
    "    'Glucosa': 'Glucose',\n",
    "    'Acido_Urico': 'UricAcid',\n",
    "    'Creatinina': 'Creatinine',\n",
    "    'Cintura': 'WaistCircumference',\n",
    "    'Sexo': 'Sex',\n",
    "    'Fumador': 'Smoking',\n",
    "    'Actividad_Fisica': 'PhysicalActivity',\n",
    "    'TARGET': 'HeartDisease'\n",
    "}\n",
    "\n",
    "df_renamed = df.rename(columns=column_mapping)\n",
    "\n",
    "# Definición de variables de interés\n",
    "biomarkers = [\n",
    "    'SystolicBP', 'TotalCholesterol', 'LDL', 'Triglicerides', \n",
    "    'HbA1c', 'Glucose', 'UricAcid', 'Creatinine', \n",
    "    'WaistCircumference', 'BMI'\n",
    "]\n",
    "\n",
    "categorical_vars = ['Sex', 'Smoking', 'PhysicalActivity', 'HeartDisease']\n",
    "\n",
    "# Verificación de existencia de columnas\n",
    "available_cols = df_renamed.columns.tolist()\n",
    "missing = [col for col in biomarkers + categorical_vars if col not in available_cols]\n",
    "\n",
    "if missing:\n",
    "    print(f\"\\nADVERTENCIA: Las siguientes variables esperadas NO están en el dataset: {missing}\")\n",
    "    # Actualizamos la lista de biomarcadores a lo que sí existe para evitar errores\n",
    "    biomarkers = [b for b in biomarkers if b in available_cols]\n",
    "    categorical_vars = [c for c in categorical_vars if c in available_cols]\n",
    "\n",
    "print(\"\\nColumnas listas para análisis:\")\n",
    "print(df_renamed.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Validación de Calidad de Datos (Biomarcadores)\n",
    "Revisamos estadísticas descriptivas para detectar valores atípicos imposibles (ej. Glucosa negativa o Presión 0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--- Estadísticas Descriptivas (Biomarcadores) ---\")\n",
    "desc_stats = df_renamed[biomarkers].describe().T\n",
    "display(desc_stats)\n",
    "\n",
    "# Validación rápida de rangos fisiológicos mínimos\n",
    "print(\"\\n--- Chequeo de Valores <= 0 (Posibles Errores) ---\")\n",
    "potential_errors = {}\n",
    "for b in biomarkers:\n",
    "    # Asumimos que la mayoría de estos biomarcadores deben ser > 0\n",
    "    count_zeros = df_renamed[df_renamed[b] <= 0].shape[0]\n",
    "    if count_zeros > 0:\n",
    "        potential_errors[b] = count_zeros\n",
    "\n",
    "if potential_errors:\n",
    "    print(f\"¡ALERTA! Se detectaron valores <= 0 en: {potential_errors}\")\n",
    "else:\n",
    "    print(\"Validación exitosa: Todos los biomarcadores tienen valores positivos.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Análisis de Correlación\n",
    "Calculamos la correlación de Pearson para detectar colinealidad entre biomarcadores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(biomarkers) > 1:\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    corr_matrix = df_renamed[biomarkers].corr()\n",
    "    \n",
    "    sns.heatmap(corr_matrix, annot=True, fmt=\".2f\", cmap='RdBu_r', vmin=-1, vmax=1)\n",
    "    plt.title(\"Matriz de Correlación de Biomarcadores Clínicos\")\n",
    "    plt.show()\n",
    "    \n",
    "    # Identificar correlaciones altas\n",
    "    print(\"Parejas con correlación absoluta > 0.7:\")\n",
    "    corr_pairs = corr_matrix.unstack().sort_values(key=abs, ascending=False)\n",
    "    # Filtramos la diagonal (correlación 1.0) y duplicados\n",
    "    high_corr = corr_pairs[(abs(corr_pairs) > 0.7) & (abs(corr_pairs) < 1.0)]\n",
    "    if not high_corr.empty:\n",
    "        print(high_corr[::2]) # Imprimimos cada 2 para evitar (A,B) y (B,A)\n",
    "    else:\n",
    "        print(\"No se detectaron correlaciones lineales fuertes (>0.7).\")\n",
    "else:\n",
    "    print(\"Insuficientes biomarcadores para análisis de correlación.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Generación de Reporte Visual (Sweetviz)\n",
    "Generamos un reporte HTML comparativo separando la población por `HeartDisease` (Target)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "REPORT_FILENAME = \"NHANES_Clinical_Analysis.html\"\n",
    "\n",
    "# Configuración de features para asegurar correcta interpretación\n",
    "# Forzamos categóricas si tienen pocos valores únicos numéricos, aunque Sweetviz es inteligente\n",
    "# Aseguramos que el Target sea tratado adecuadamente\n",
    "feature_config = sv.FeatureConfig(force_cat=categorical_vars)\n",
    "\n",
    "print(f\"Iniciando generación de reporte Sweetviz... (Target: HeartDisease)\")\n",
    "\n",
    "if 'HeartDisease' in df_renamed.columns:\n",
    "    analysis = sv.analyze(\n",
    "        [df_renamed, \"NHANES Data\"],\n",
    "        target_feat='HeartDisease',\n",
    "        feat_cfg=feature_config,\n",
    "        pairwise_analysis='off' # Apagado para eficiencia, ya hicimos correlación arriba\n",
    "    )\n",
    "    \n",
    "    analysis.show_html(filepath=REPORT_FILENAME)\n",
    "    print(f\"\\n¡Reporte generado exitosamente! Abrir archivo: {REPORT_FILENAME}\")\n",
    "else:\n",
    "    print(\"ERROR CRÍTICO: No se encuentra la columna 'HeartDisease' para el análisis comparativo.\")\n",
    "    # Fallback sin target\n",
    "    analysis = sv.analyze([df_renamed, \"NHANES Data\"], pairwise_analysis='off')\n",
    "    analysis.show_html(filepath=REPORT_FILENAME)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xgb_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
