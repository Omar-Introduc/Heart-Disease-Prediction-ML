# Estado del Arte y Revisi贸n Bibliogr谩fica

Este documento resume los recursos clave y hallazgos del estado del arte para el proyecto, con 茅nfasis en aplicaciones m茅dicas, XGBoost y manejo de desbalance de clases.

## 1. Implementaci贸n Te贸rica de XGBoost
| Categor铆a | Recurso Sugerido | Descripci贸n / Por qu茅 leerlo |
| :--- | :--- | :--- |
|  **Paper Original** | **XGBoost: A Scalable Tree Boosting System** <br> (*T. Chen, C. Guestrin*) <br> [Enlace](https://arxiv.org/pdf/1603.02754.pdf) | Documento can贸nico. Explica la formulaci贸n matem谩tica, el algoritmo de divisi贸n y las optimizaciones del sistema. Esencial para un entendimiento profundo. |
| **Fundamentos** | **A Gentle Introduction to Gradient Boosting** <br> (*Machine Learning Mastery*) <br> [Enlace](https://machinelearningmastery.com/gentle-introduction-gradient-boosting-algorithm-machine-learning/) | Explica la intuici贸n detr谩s del Gradient Boosting de forma accesible, aclarando c贸mo se corrigen los errores de los modelos anteriores. |
| **Fundamentos** | **Gradient Boosting Explained** <br> (*Art铆culo visual interactivo*) <br> [Enlace](http://explained.ai/gradient-boosting/index.html) | Una de las mejores explicaciones visuales. Permite jugar con los par谩metros para ver su efecto en tiempo real. |

## 2. Aplicaciones en Salud y Cardiolog铆a
| Categor铆a | Recurso Sugerido (Paper) | Descripci贸n / Aporte al Proyecto |
| :--- | :--- | :--- |
| ┖ **Aplicaci贸n Directa** | **An Explainable Artificial Intelligence (XAI) Methodology for Heart Disease Classification** <br> (*O. M. Yaseen & M. M. Rashid, 2025*) | **Modelo a seguir.** Aplica XGBoost para clasificaci贸n card铆aca integrando directamente XAI con **SHAP y LIME**. Muestra c贸mo conectar la predicci贸n con la interpretaci贸n cl铆nica. |
|  **Comparativa** | **Comparative Study of Machine Learning Algorithms in Detecting Cardiovascular Diseases** <br> (*Dayana K et al.*) <br> [Enlace](https://arxiv.org/pdf/2405.17059)| Compara XGBoost con Regresi贸n Log铆stica y Random Forest. Sirve de plantilla para nuestra fase de benchmarking y justificaci贸n de elecci贸n de modelo. |
|  **XAI Avanzado** | **Explainable SHAP-XGBoost models for in-hospital mortality...** <br> (*C. Tarabanis et al., 2023*) | Se enfoca en la interpretabilidad de XGBoost usando SHAP. Gu铆a perfecta para generar y explicar gr谩ficos de importancia, dependencia e interacci贸n. |

## 3. Manejo de Desbalance de Clases (Imbalance Handling)

Dado que los datasets m茅dicos (como BRFSS) suelen tener muchos m谩s casos negativos (sanos) que positivos (enfermos), el manejo del desbalance es cr铆tico.

### Estrategias Identificadas en la Literatura:

1.  **Algorithmic Level (Dentro de XGBoost):**
    *   **`scale_pos_weight`:** Es la t茅cnica m谩s recomendada y eficiente para XGBoost.
        *   *F贸rmula:* `sum(negative instances) / sum(positive instances)`
        *   *Efecto:* Modifica el c谩lculo del gradiente para penalizar m谩s los errores en la clase minoritaria (positiva). Es computacionalmente m谩s barato que el re-sampling.
    *   **Referencia:** La documentaci贸n oficial de XGBoost recomienda esto sobre SMOTE para rendimiento puro en 谩rboles.

2.  **Data Level (Re-sampling):**
    *   **SMOTE (Synthetic Minority Over-sampling Technique):** Genera ejemplos sint茅ticos de la clase minoritaria interpolando entre vecinos cercanos.
        *   *Pros:* Aumenta la variedad de datos de entrenamiento.
        *   *Contras:* Puede introducir ruido y aumentar el tiempo de entrenamiento.
    *   **Random Undersampling:** Eliminar aleatoriamente ejemplos de la clase mayoritaria.
        *   *Uso:* til si el dataset es masivo (millones de filas) para reducir carga computacional, pero se pierde informaci贸n.

### Recomendaci贸n para el Proyecto:
Priorizar el uso de **`scale_pos_weight`** como primera opci贸n debido a su integraci贸n nativa con XGBoost y eficiencia. Explorar **SMOTE** solo si el rendimiento de recall es insuficiente con la ponderaci贸n de pesos.

## 4. Ingenier铆a de Caracter铆sticas y Benchmarking
| Categor铆a | Recurso | Aporte |
| :--- | :--- | :--- |
| К **Selecci贸n** | **Optimized Ensemble Learning Approach with Explainable AI...** <br> (*I. D. Mienye & N. Jere, 2024*) | Gu铆a pr谩ctica para aplicar SHAP *despu茅s* del modelo optimizado para justificar qu茅 variables son relevantes. |
|  **Benchmark** | **Cardiovascular disease risk prediction using automated machine learning** <br> (*A. Alaa et al., 2019*) | Estudio en UK Biobank. til para identificar predictores no tradicionales y establecer un est谩ndar de rendimiento alto (AUC > 0.85). |
